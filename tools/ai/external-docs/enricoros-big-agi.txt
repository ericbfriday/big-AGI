Directory structure:
└── enricoros-big-agi/
    ├── README.md
    ├── docker-compose.yaml
    ├── Dockerfile
    ├── LICENSE
    ├── middleware_BASIC_AUTH.ts
    ├── next.config.ts
    ├── package.json
    ├── tsconfig.json
    ├── .dockerignore
    ├── .eslintrc.json
    ├── .npmrc
    ├── .prettierrc
    ├── app/
    │   └── api/
    │       ├── cloud/
    │       │   └── [trpc]/
    │       │       └── route.ts
    │       └── edge/
    │           └── [trpc]/
    │               └── route.ts
    ├── docs/
    │   ├── README.md
    │   ├── 2024-AI-APIs-Comparison.md
    │   ├── changelog.md
    │   ├── config-azure-openai.md
    │   ├── config-feature-browse.md
    │   ├── config-local-lmstudio.md
    │   ├── config-local-localai.md
    │   ├── config-local-ollama.md
    │   ├── config-openrouter.md
    │   ├── customizations.md
    │   ├── deploy-analytics.md
    │   ├── deploy-authentication.md
    │   ├── deploy-cloudflare.md
    │   ├── deploy-database.md
    │   ├── deploy-docker.md
    │   ├── deploy-k8s.md
    │   ├── deploy-reverse-proxy.md
    │   ├── draft-big-agi.md
    │   ├── environment-variables.md
    │   ├── help-advanced-tricks.md
    │   ├── help-data-ownership.md
    │   ├── help-faq.md
    │   ├── help-feature-livefile.md
    │   ├── help-feature-microphone.md
    │   ├── installation.md
    │   ├── use-chat-react.md
    │   ├── docker/
    │   │   └── docker-compose-browserless.yaml
    │   └── k8s/
    │       ├── big-agi-deployment.yaml
    │       └── env-secret.yaml
    ├── pages/
    │   ├── _app.tsx
    │   ├── _document.tsx
    │   ├── call.tsx
    │   ├── diff.tsx
    │   ├── draw.tsx
    │   ├── index.tsx
    │   ├── news.tsx
    │   ├── personas.tsx
    │   ├── tokens.tsx
    │   ├── workspace.tsx
    │   ├── dev/
    │   │   └── beam.tsx
    │   ├── info/
    │   │   └── debug.tsx
    │   └── link/
    │       ├── callback_openrouter.tsx
    │       ├── share_target.tsx
    │       └── chat/
    │           └── [chatLinkId].tsx
    ├── public/
    │   ├── manifest.json
    │   └── images/
    │       └── personas/
    │           └── dev_preview_icon_120x120.webp
    ├── src/
    │   ├── data.ts
    │   ├── apps/
    │   │   ├── AppPlaceholder.tsx
    │   │   ├── AppSmallContainer.tsx
    │   │   ├── beam/
    │   │   │   └── AppBeam.tsx
    │   │   ├── call/
    │   │   │   ├── AppCall.tsx
    │   │   │   ├── CallWizard.tsx
    │   │   │   ├── Contacts.tsx
    │   │   │   ├── Telephone.tsx
    │   │   │   ├── components/
    │   │   │   │   ├── CallAvatar.tsx
    │   │   │   │   ├── CallButton.tsx
    │   │   │   │   ├── CallMessage.tsx
    │   │   │   │   └── CallStatus.tsx
    │   │   │   └── state/
    │   │   │       ├── store-app-call.ts
    │   │   │       └── useMockPersonas.tsx
    │   │   ├── chat/
    │   │   │   ├── AppChat.tsx
    │   │   │   ├── store-app-chat.ts
    │   │   │   ├── commands/
    │   │   │   │   ├── commands.dmessage.ts
    │   │   │   │   ├── commands.registry.ts
    │   │   │   │   ├── CommandsAlter.tsx
    │   │   │   │   ├── CommandsDraw.tsx
    │   │   │   │   ├── CommandsHelp.tsx
    │   │   │   │   ├── CommandsReact.tsx
    │   │   │   │   └── ICommandsProvider.ts
    │   │   │   ├── components/
    │   │   │   │   ├── ChatBeamWrapper.tsx
    │   │   │   │   ├── ChatMessageList.tsx
    │   │   │   │   ├── Ephemerals.tsx
    │   │   │   │   ├── PaneTitleOverlay.tsx
    │   │   │   │   ├── StatusBar.tsx
    │   │   │   │   ├── composer/
    │   │   │   │   │   ├── CameraCaptureModal.tsx
    │   │   │   │   │   ├── Composer.tsx
    │   │   │   │   │   ├── useComposerAutoHide.tsx
    │   │   │   │   │   ├── useComposerDragDrop.tsx
    │   │   │   │   │   ├── WebInputModal.tsx
    │   │   │   │   │   ├── actile/
    │   │   │   │   │   │   ├── ActilePopup.tsx
    │   │   │   │   │   │   ├── ActileProvider.tsx
    │   │   │   │   │   │   ├── providerAttachmentLabels.tsx
    │   │   │   │   │   │   ├── providerCommands.tsx
    │   │   │   │   │   │   ├── providerStarredMessage.tsx
    │   │   │   │   │   │   └── useActileManager.tsx
    │   │   │   │   │   ├── buttons/
    │   │   │   │   │   │   ├── ButtonAttachCamera.tsx
    │   │   │   │   │   │   ├── ButtonAttachClipboard.tsx
    │   │   │   │   │   │   ├── ButtonAttachNewDoc.tsx
    │   │   │   │   │   │   ├── ButtonAttachScreenCapture.tsx
    │   │   │   │   │   │   ├── ButtonAttachWeb.tsx
    │   │   │   │   │   │   ├── ButtonBeam.tsx
    │   │   │   │   │   │   ├── ButtonCall.tsx
    │   │   │   │   │   │   ├── ButtonGroupDrawRepeat.tsx
    │   │   │   │   │   │   ├── ButtonMic.tsx
    │   │   │   │   │   │   ├── ButtonMicContinuation.tsx
    │   │   │   │   │   │   ├── ButtonMultiChat.tsx
    │   │   │   │   │   │   └── ButtonOptionsDraw.tsx
    │   │   │   │   │   ├── llmattachments/
    │   │   │   │   │   │   ├── LLMAttachmentButton.tsx
    │   │   │   │   │   │   ├── LLMAttachmentMenu.tsx
    │   │   │   │   │   │   ├── LLMAttachmentsList.tsx
    │   │   │   │   │   │   ├── LLMAttachmentsPromptsButton.tsx
    │   │   │   │   │   │   └── useLLMAttachmentDrafts.ts
    │   │   │   │   │   ├── textarea/
    │   │   │   │   │   │   ├── AttachmentsPromptsButton.tsx
    │   │   │   │   │   │   ├── ComposerTextAreaActions.tsx
    │   │   │   │   │   │   └── ComposerTextAreaDrawActions.tsx
    │   │   │   │   │   └── tokens/
    │   │   │   │   │       ├── TokenBadge.tsx
    │   │   │   │   │       ├── TokenProgressbar.tsx
    │   │   │   │   │       ├── TokenTooltip.tsx
    │   │   │   │   │       └── useTextTokenCounter.tsx
    │   │   │   │   ├── layout-bar/
    │   │   │   │   │   ├── ChatBarAltTitle.tsx
    │   │   │   │   │   ├── ChatBarBeam.tsx
    │   │   │   │   │   ├── ChatBarChat.tsx
    │   │   │   │   │   ├── useFolderDropdown.tsx
    │   │   │   │   │   ├── useLLMDropdown.tsx
    │   │   │   │   │   └── usePersonaDropdown.tsx
    │   │   │   │   ├── layout-drawer/
    │   │   │   │   │   ├── ChatDrawer.tsx
    │   │   │   │   │   ├── ChatDrawerItem.tsx
    │   │   │   │   │   ├── useChatDrawerRenderItems.tsx
    │   │   │   │   │   └── folders/
    │   │   │   │   │       ├── AddFolderButton.tsx
    │   │   │   │   │       ├── ChatFolderList.tsx
    │   │   │   │   │       └── FolderListItem.tsx
    │   │   │   │   ├── layout-pane/
    │   │   │   │   │   └── ChatPane.tsx
    │   │   │   │   ├── message/
    │   │   │   │   │   ├── BlockOpContinue.tsx
    │   │   │   │   │   ├── BlockOpOptions.tsx
    │   │   │   │   │   ├── ChatMessage.styles.ts
    │   │   │   │   │   ├── ChatMessage.tsx
    │   │   │   │   │   ├── CleanerMessage.tsx
    │   │   │   │   │   ├── explainServiceErrors.tsx
    │   │   │   │   │   ├── useSelHighlighterMemo.ts
    │   │   │   │   │   ├── fragments-attachment-doc/
    │   │   │   │   │   │   ├── DocAttachmentFragment.tsx
    │   │   │   │   │   │   ├── DocAttachmentFragmentButton.tsx
    │   │   │   │   │   │   ├── DocumentAttachmentFragments.tsx
    │   │   │   │   │   │   └── livefile-sync/
    │   │   │   │   │   │       ├── LiveFileControlButton.tsx
    │   │   │   │   │   │       └── useLiveFileSync.tsx
    │   │   │   │   │   ├── fragments-attachment-image/
    │   │   │   │   │   │   └── ImageAttachmentFragments.tsx
    │   │   │   │   │   ├── fragments-content/
    │   │   │   │   │   │   ├── BlockEdit_TextFragment.tsx
    │   │   │   │   │   │   ├── BlockOpEmpty.tsx
    │   │   │   │   │   │   ├── BlockPartError.tsx
    │   │   │   │   │   │   ├── BlockPartImageRef.tsx
    │   │   │   │   │   │   ├── BlockPartText_AutoBlocks.tsx
    │   │   │   │   │   │   ├── BlockPartToolInvocation.tsx
    │   │   │   │   │   │   ├── BlockPartToolResponse.tsx
    │   │   │   │   │   │   ├── ContentFragments.tsx
    │   │   │   │   │   │   ├── ViewDocPartModal.tsx
    │   │   │   │   │   │   └── ViewImageRefPartModal.tsx
    │   │   │   │   │   ├── fragments-void/
    │   │   │   │   │   │   ├── BlockPartModelAnnotations.tsx
    │   │   │   │   │   │   ├── BlockPartModelAux.tsx
    │   │   │   │   │   │   ├── BlockPartPlaceholder.tsx
    │   │   │   │   │   │   └── VoidFragments.tsx
    │   │   │   │   │   └── in-reference-to/
    │   │   │   │   │       ├── InReferenceToBubble.tsx
    │   │   │   │   │       └── InReferenceToList.tsx
    │   │   │   │   ├── messages-list/
    │   │   │   │   │   └── CMLZeroConversation.tsx
    │   │   │   │   ├── panes/
    │   │   │   │   │   └── store-panes-manager.ts
    │   │   │   │   └── persona-selector/
    │   │   │   │       ├── PersonaSelector.tsx
    │   │   │   │       └── store-purposes.ts
    │   │   │   ├── editors/
    │   │   │   │   ├── _handleExecute.ts
    │   │   │   │   ├── _handleExecuteCommand.ts
    │   │   │   │   ├── browse-load.ts
    │   │   │   │   ├── chat-persona.ts
    │   │   │   │   ├── image-generate.ts
    │   │   │   │   ├── react-tangent.ts
    │   │   │   │   └── persona/
    │   │   │   │       └── PersonaChatMessageSpeak.ts
    │   │   │   └── execute-mode/
    │   │   │       ├── execute-mode.items.ts
    │   │   │       ├── execute-mode.types.ts
    │   │   │       ├── ExecuteModeMenu.tsx
    │   │   │       └── useChatExecuteMode.tsx
    │   │   ├── diff/
    │   │   │   └── AppDiff.tsx
    │   │   ├── draw/
    │   │   │   ├── AppDraw.tsx
    │   │   │   ├── DrawCreate.tsx
    │   │   │   ├── DrawGallery.tsx
    │   │   │   ├── queue-draw-create.tsx
    │   │   │   ├── useDrawSectionDropdown.tsx
    │   │   │   ├── create/
    │   │   │   │   ├── ButtonPromptFromIdea.tsx
    │   │   │   │   ├── ButtonPromptFromX.tsx
    │   │   │   │   ├── DrawProviderConfigure.tsx
    │   │   │   │   ├── DrawProviderSelector.tsx
    │   │   │   │   ├── DrawSectionHeading.tsx
    │   │   │   │   ├── PromptComposer.tsx
    │   │   │   │   ├── useDrawIdeas.tsx
    │   │   │   │   ├── ZeroDrawConfig.tsx
    │   │   │   │   └── ZeroGenerations.tsx
    │   │   │   ├── gallery/
    │   │   │   │   └── ZeroGallery.tsx
    │   │   │   └── promptfx/
    │   │   │       └── PromptFX.tsx
    │   │   ├── link-chat/
    │   │   │   ├── AppLinkChat.tsx
    │   │   │   ├── LinkChatAppMenuItems.tsx
    │   │   │   ├── LinkChatDrawer.tsx
    │   │   │   └── LinkChatViewer.tsx
    │   │   ├── news/
    │   │   │   ├── AppNews.tsx
    │   │   │   ├── beam.data.tsx
    │   │   │   ├── bigAgi2.data.tsx
    │   │   │   └── news.data.tsx
    │   │   ├── personas/
    │   │   │   ├── AppPersonas.tsx
    │   │   │   ├── store-app-personas.ts
    │   │   │   └── creator/
    │   │   │       ├── Creator.tsx
    │   │   │       ├── CreatorDrawer.tsx
    │   │   │       ├── CreatorDrawerItem.tsx
    │   │   │       ├── FromText.tsx
    │   │   │       ├── FromYouTube.tsx
    │   │   │       └── Viewer.tsx
    │   │   ├── settings-modal/
    │   │   │   ├── AppChatSettingsAI.tsx
    │   │   │   ├── SettingsModal.tsx
    │   │   │   ├── ShortcutsModal.tsx
    │   │   │   ├── UxLabsSettings.tsx
    │   │   │   ├── VoiceSettings.tsx
    │   │   │   └── settings-ui/
    │   │   │       ├── AppChatSettingsUI.tsx
    │   │   │       ├── SettingUIComplexity.tsx
    │   │   │       ├── SettingUIComposerQuickButton.tsx
    │   │   │       └── SettingUIContentScaling.tsx
    │   │   └── tokens/
    │   │       └── AppTokens.tsx
    │   ├── common/
    │   │   ├── app.config.ts
    │   │   ├── app.nav.ts
    │   │   ├── app.queryclient.ts
    │   │   ├── app.release.ts
    │   │   ├── app.routes.ts
    │   │   ├── app.theme.ts
    │   │   ├── attachment-drafts/
    │   │   │   ├── attachment.dblobs.ts
    │   │   │   ├── attachment.livefile.ts
    │   │   │   ├── attachment.mimetypes.ts
    │   │   │   ├── attachment.pipeline.ts
    │   │   │   ├── attachment.types.ts
    │   │   │   ├── store-attachment-drafts_slice.ts
    │   │   │   ├── store-attachment-drafts_vanilla.ts
    │   │   │   ├── useAttachmentDrafts.tsx
    │   │   │   └── file-converters/
    │   │   │       └── DocxToMarkdown.ts
    │   │   ├── chat-overlay/
    │   │   │   ├── ConversationHandler.ts
    │   │   │   ├── ConversationsManager.ts
    │   │   │   ├── store-perchat-composer_slice.ts
    │   │   │   ├── store-perchat-ephemerals_slice.ts
    │   │   │   ├── store-perchat-variform_slice.ts
    │   │   │   └── store-perchat_vanilla.ts
    │   │   ├── components/
    │   │   │   ├── AlreadySet.tsx
    │   │   │   ├── AppBreadcrumbs.tsx
    │   │   │   ├── AvatarDomainFavicon.tsx
    │   │   │   ├── ButtonAttachFiles.tsx
    │   │   │   ├── ChipExpander.tsx
    │   │   │   ├── ChipToggleButton.tsx
    │   │   │   ├── CloseablePopup.tsx
    │   │   │   ├── DarkModeToggleButton.tsx
    │   │   │   ├── DataStreamViz.tsx
    │   │   │   ├── DebouncedInput.tsx
    │   │   │   ├── ErrorBoundary.tsx
    │   │   │   ├── ExpanderAccordion.tsx
    │   │   │   ├── ExpanderControlledBox.tsx
    │   │   │   ├── ExplainerCarousel.tsx
    │   │   │   ├── ExternalDocsLink.tsx
    │   │   │   ├── ExternalLink.tsx
    │   │   │   ├── FeatureBadge.tsx
    │   │   │   ├── GitHubProjectIssueCard.tsx
    │   │   │   ├── GoodTooltip.tsx
    │   │   │   ├── InlineError.tsx
    │   │   │   ├── InlineTextarea.tsx
    │   │   │   ├── KeyStroke.tsx
    │   │   │   ├── Languages.json
    │   │   │   ├── LanguageSelect.tsx
    │   │   │   ├── Link.tsx
    │   │   │   ├── LogoProgress.tsx
    │   │   │   ├── Section.tsx
    │   │   │   ├── StackedBarBreakdown.tsx
    │   │   │   ├── TooltipOutlined.tsx
    │   │   │   ├── useCameraCapture.tsx
    │   │   │   ├── useCapabilities.ts
    │   │   │   ├── useChipBoolean.tsx
    │   │   │   ├── useDebouncer.ts
    │   │   │   ├── useDebugHook.ts
    │   │   │   ├── useDontBlurTextarea.ts
    │   │   │   ├── useFullscreenElement.tsx
    │   │   │   ├── useIsBrowserTranslating.tsx
    │   │   │   ├── useMatchMedia.ts
    │   │   │   ├── useNextLoadProgress.tsx
    │   │   │   ├── useSingleTabEnforcer.ts
    │   │   │   ├── VideoPlayerVimeo.tsx
    │   │   │   ├── VideoPlayerYouTube.tsx
    │   │   │   ├── 3rdparty/
    │   │   │   │   ├── GoogleAnalytics.tsx
    │   │   │   │   └── PostHogAnalytics.tsx
    │   │   │   ├── dnd-dt/
    │   │   │   │   ├── GlobalDragOverlay.tsx
    │   │   │   │   ├── useDragDropDataTransfer.tsx
    │   │   │   │   └── volstore-drag-global.ts
    │   │   │   ├── forms/
    │   │   │   │   ├── FormChipControl.tsx
    │   │   │   │   ├── FormInputKey.tsx
    │   │   │   │   ├── FormLabelStart.tsx
    │   │   │   │   ├── FormRadioControl.tsx
    │   │   │   │   ├── FormSelectControl.tsx
    │   │   │   │   ├── FormSliderControl.tsx
    │   │   │   │   ├── FormSwitchControl.tsx
    │   │   │   │   ├── FormTextField.tsx
    │   │   │   │   ├── SetupFormRefetchButton.tsx
    │   │   │   │   ├── useFormEditTextArray.tsx
    │   │   │   │   ├── useFormRadio.tsx
    │   │   │   │   ├── useFormRadioLlmType.tsx
    │   │   │   │   └── useLLMSelect.tsx
    │   │   │   ├── icons/
    │   │   │   │   ├── CalloutTopRightIcon.tsx
    │   │   │   │   ├── ChatBeamIcon.tsx
    │   │   │   │   ├── ChatMulticastOffIcon.tsx
    │   │   │   │   ├── ChatMulticastOnIcon.tsx
    │   │   │   │   ├── CodiconSplitHorizontal.tsx
    │   │   │   │   ├── CodiconSplitHorizontalRemove.tsx
    │   │   │   │   ├── CodiconSplitVertical.tsx
    │   │   │   │   ├── CodiconSplitVerticalRemove.tsx
    │   │   │   │   ├── CodiconUnsplit.tsx
    │   │   │   │   ├── FoldersToggleOff.tsx
    │   │   │   │   ├── FoldersToggleOn.tsx
    │   │   │   │   ├── LayoutSidebarRight.tsx
    │   │   │   │   ├── LiveFilePatchIcon.tsx
    │   │   │   │   ├── MarkHighlightIcon.tsx
    │   │   │   │   ├── WindowPaneRightClose.tsx
    │   │   │   │   ├── WindowPaneRightOpen.tsx
    │   │   │   │   ├── 3rdparty/
    │   │   │   │   │   ├── AuthGitHubIcon.tsx
    │   │   │   │   │   ├── AuthGoogleIcon.tsx
    │   │   │   │   │   ├── CodePenIcon.tsx
    │   │   │   │   │   ├── DiscordIcon.tsx
    │   │   │   │   │   ├── ExternalTickIcon.tsx
    │   │   │   │   │   ├── GoogleColabIcon.tsx
    │   │   │   │   │   ├── JSFiddleIcon.tsx
    │   │   │   │   │   └── StackBlitzIcon.tsx
    │   │   │   │   ├── big-agi/
    │   │   │   │   │   ├── BigAgiCircleIcon.tsx
    │   │   │   │   │   ├── BigAgiCircleInnerIcon.tsx
    │   │   │   │   │   └── BigAgiSquircleIcon.tsx
    │   │   │   │   ├── phosphor/
    │   │   │   │   │   ├── PhChats.tsx
    │   │   │   │   │   ├── PhChatsDuotone.tsx
    │   │   │   │   │   ├── PhGearSixIcon.tsx
    │   │   │   │   │   ├── PhPaintBrush.tsx
    │   │   │   │   │   ├── PhPaintBrushHousehold.tsx
    │   │   │   │   │   ├── PhRobot.tsx
    │   │   │   │   │   ├── PhSlidersHorizontalIcon.tsx
    │   │   │   │   │   ├── PhSlidersIcon.tsx
    │   │   │   │   │   ├── PhSquaresFour.tsx
    │   │   │   │   │   └── PhUsers.tsx
    │   │   │   │   └── vendors/
    │   │   │   │       ├── AlibabaCloudIcon.tsx
    │   │   │   │       ├── AnthropicIcon.tsx
    │   │   │   │       ├── AzureIcon.tsx
    │   │   │   │       ├── DeepseekIcon.tsx
    │   │   │   │       ├── GeminiIcon.tsx
    │   │   │   │       ├── GroqIcon.tsx
    │   │   │   │       ├── LMStudioIcon.tsx
    │   │   │   │       ├── LocalAIIcon.tsx
    │   │   │   │       ├── MistralIcon.tsx
    │   │   │   │       ├── OllamaIcon.tsx
    │   │   │   │       ├── OpenAIIcon.tsx
    │   │   │   │       ├── OpenPipeIcon.tsx
    │   │   │   │       ├── OpenRouterIcon.tsx
    │   │   │   │       ├── PerplexityIcon.tsx
    │   │   │   │       ├── TogetherIcon.tsx
    │   │   │   │       └── XAIIcon.tsx
    │   │   │   ├── modals/
    │   │   │   │   ├── ConfirmationModal.tsx
    │   │   │   │   ├── GoodModal.tsx
    │   │   │   │   └── SherpaModal.tsx
    │   │   │   ├── panes/
    │   │   │   │   └── GoodPanelResizeHandler.tsx
    │   │   │   ├── shortcuts/
    │   │   │   │   ├── globalShortcutsHandler.ts
    │   │   │   │   ├── store-global-shortcuts.ts
    │   │   │   │   └── useGlobalShortcuts.ts
    │   │   │   ├── snackbar/
    │   │   │   │   ├── SnackbarInsert.tsx
    │   │   │   │   └── useSnackbarsStore.ts
    │   │   │   └── speechrecognition/
    │   │   │       ├── AudioRecorderEngine.ts
    │   │   │       ├── useSpeechRecognition.ts
    │   │   │       └── WebSpeechApiEngine.ts
    │   │   ├── events/
    │   │   │   ├── events.bus.ts
    │   │   │   ├── events.flow.ts
    │   │   │   ├── events.stateful.ts
    │   │   │   ├── events.types.ts
    │   │   │   └── index.ts
    │   │   ├── layout/
    │   │   │   ├── withLayout.tsx
    │   │   │   ├── container/
    │   │   │   │   └── ContainerLayout.tsx
    │   │   │   ├── optima/
    │   │   │   │   ├── InvertedBar.tsx
    │   │   │   │   ├── Modals.tsx
    │   │   │   │   ├── optima.config.ts
    │   │   │   │   ├── OptimaLayout.tsx
    │   │   │   │   ├── OptimaMOTD.tsx
    │   │   │   │   ├── PageCore.tsx
    │   │   │   │   ├── PageWrapper.tsx
    │   │   │   │   ├── store-layout-optima.ts
    │   │   │   │   ├── useOptima.tsx
    │   │   │   │   ├── bar/
    │   │   │   │   │   ├── OptimaBar.tsx
    │   │   │   │   │   └── OptimaBarDropdown.tsx
    │   │   │   │   ├── drawer/
    │   │   │   │   │   ├── DesktopDrawer.tsx
    │   │   │   │   │   ├── MobileDrawer.tsx
    │   │   │   │   │   ├── OptimaDrawerHeader.tsx
    │   │   │   │   │   └── OptimaDrawerList.tsx
    │   │   │   │   ├── nav/
    │   │   │   │   │   ├── BringTheLove.tsx
    │   │   │   │   │   ├── DesktopNav.tsx
    │   │   │   │   │   ├── DesktopNavIcon.tsx
    │   │   │   │   │   ├── MobileNav.tsx
    │   │   │   │   │   ├── MobileNavIcon.tsx
    │   │   │   │   │   └── MobileNavItems.tsx
    │   │   │   │   ├── page/
    │   │   │   │   │   └── OptimaAppPageHeading.tsx
    │   │   │   │   ├── panel/
    │   │   │   │   │   ├── DesktopPanel.tsx
    │   │   │   │   │   ├── MobilePanel.tsx
    │   │   │   │   │   ├── MobilePreferencesListItem.tsx
    │   │   │   │   │   ├── OptimaPanelGroupedList.tsx
    │   │   │   │   │   ├── PanelContentPortal.tsx
    │   │   │   │   │   └── PopupPanel.tsx
    │   │   │   │   ├── portals/
    │   │   │   │   │   ├── OptimaPortalsIn.tsx
    │   │   │   │   │   ├── store-layout-portals.ts
    │   │   │   │   │   ├── useOptimaPortalHasInputs.ts
    │   │   │   │   │   └── useOptimaPortalOutRef.ts
    │   │   │   │   └── scratchclip/
    │   │   │   │       ├── ScratchClip.tsx
    │   │   │   │       ├── store-scratchclip.ts
    │   │   │   │       └── useGlobalClipboardSaver.ts
    │   │   │   └── overlays/
    │   │   │       ├── OverlaysInsert.tsx
    │   │   │       ├── store-layout-overlays.ts
    │   │   │       └── useOverlayComponents.tsx
    │   │   ├── livefile/
    │   │   │   ├── liveFile.icons.ts
    │   │   │   ├── livefile.theme.ts
    │   │   │   ├── liveFile.types.ts
    │   │   │   ├── store-live-file.ts
    │   │   │   ├── useLiveFileContent.tsx
    │   │   │   └── useLiveFileMetadata.tsx
    │   │   ├── logger/
    │   │   │   ├── index.ts
    │   │   │   ├── logger.client.ts
    │   │   │   ├── logger.factory.ts
    │   │   │   ├── logger.types.ts
    │   │   │   ├── store-logger.ts
    │   │   │   ├── hooks/
    │   │   │   │   └── useClientLoggerInterception.ts
    │   │   │   ├── interceptors/
    │   │   │   │   ├── logger.network.ts
    │   │   │   │   └── logger.unhandled.ts
    │   │   │   └── viewer/
    │   │   │       ├── LogEntryDetails.tsx
    │   │   │       └── LoggerViewerDialog.tsx
    │   │   ├── logic/
    │   │   │   ├── ProcessingQueue.ts
    │   │   │   ├── reconfigureBackendModels.ts
    │   │   │   └── store-logic-sherpa.ts
    │   │   ├── providers/
    │   │   │   ├── ProviderBackendCapabilities.tsx
    │   │   │   ├── ProviderBootstrapLogic.tsx
    │   │   │   ├── ProviderSingleTab.tsx
    │   │   │   └── ProviderTheming.tsx
    │   │   ├── scroll-to-bottom/
    │   │   │   ├── ScrollToBottom.tsx
    │   │   │   ├── ScrollToBottomButton.tsx
    │   │   │   └── useScrollToBottom.tsx
    │   │   ├── stores/
    │   │   │   ├── store-client.ts
    │   │   │   ├── store-ui.ts
    │   │   │   ├── store-ux-labs.ts
    │   │   │   ├── blob/
    │   │   │   │   └── dblobs-portability.ts
    │   │   │   ├── chat/
    │   │   │   │   ├── chat.conversation.ts
    │   │   │   │   ├── chat.fragments.ts
    │   │   │   │   ├── chat.gc.ts
    │   │   │   │   ├── chat.message.ts
    │   │   │   │   ├── chat.tokens.ts
    │   │   │   │   ├── chats.converters.ts
    │   │   │   │   ├── store-chats.ts
    │   │   │   │   └── hooks/
    │   │   │   │       ├── useChatsCount.ts
    │   │   │   │       ├── useConversationTitle.ts
    │   │   │   │       └── useFragmentBuckets.ts
    │   │   │   ├── folders/
    │   │   │   │   └── store-chat-folders.ts
    │   │   │   ├── llms/
    │   │   │   │   ├── llms.hooks.ts
    │   │   │   │   ├── llms.parameters.ts
    │   │   │   │   ├── llms.pricing.ts
    │   │   │   │   ├── llms.service.types.ts
    │   │   │   │   ├── llms.types.ts
    │   │   │   │   ├── model.domains.registry.ts
    │   │   │   │   ├── model.domains.types.ts
    │   │   │   │   ├── modelconfiguration.types.ts
    │   │   │   │   ├── store-llms-domains_slice.ts
    │   │   │   │   ├── store-llms.ts
    │   │   │   │   └── hooks/
    │   │   │   │       ├── useAllLLMs.ts
    │   │   │   │       ├── useModelDomain.ts
    │   │   │   │       ├── useModelDomains.ts
    │   │   │   │       └── useModelsZeroState.ts
    │   │   │   ├── metrics/
    │   │   │   │   ├── metrics.chatgenerate.ts
    │   │   │   │   ├── metrics.modelservice.ts
    │   │   │   │   └── store-metrics.ts
    │   │   │   └── workspace/
    │   │   │       ├── store-client-workspace.ts
    │   │   │       ├── useWorkspaceContentsMetadata.ts
    │   │   │       ├── workspace.types.ts
    │   │   │       ├── WorkspaceIdProvider.tsx
    │   │   │       └── WorkspaceLiveFilePicker.tsx
    │   │   ├── styles/
    │   │   │   ├── agi.effects.css
    │   │   │   ├── app.styles.css
    │   │   │   ├── CodePrism.css
    │   │   │   ├── GithubMarkdown.css
    │   │   │   └── NProgress.css
    │   │   ├── tokens/
    │   │   │   ├── tokens.image.ts
    │   │   │   ├── tokens.text.ts
    │   │   │   └── useTokenizerSelect.tsx
    │   │   ├── types/
    │   │   │   ├── immutable.types.ts
    │   │   │   ├── next.page.d.ts
    │   │   │   └── useful.types.ts
    │   │   └── util/
    │   │       ├── animUtils.ts
    │   │       ├── blobUtils.ts
    │   │       ├── canvasUtils.ts
    │   │       ├── clientFetchers.ts
    │   │       ├── clipboardUtils.ts
    │   │       ├── costUtils.ts
    │   │       ├── dMessageUtils.tsx
    │   │       ├── downloadUtils.ts
    │   │       ├── errorUtils.ts
    │   │       ├── eventUtils.ts
    │   │       ├── fileSystemUtils.ts
    │   │       ├── htmlTableToMarkdown.ts
    │   │       ├── idbUtils.ts
    │   │       ├── idUtils.ts
    │   │       ├── imageUtils.ts
    │   │       ├── jsonUtils.ts
    │   │       ├── pdfUtils.ts
    │   │       ├── perfUtils.ts
    │   │       ├── promptUtils.ts
    │   │       ├── pwaUtils.ts
    │   │       ├── screenCaptureUtils.ts
    │   │       ├── stateUtils.tsx
    │   │       ├── storageUtils.ts
    │   │       ├── textUtils.ts
    │   │       ├── timeUtils.ts
    │   │       ├── trpc.client.ts
    │   │       ├── urlUtils.ts
    │   │       ├── videoUtils.ts
    │   │       ├── viewTransitionUtils.ts
    │   │       ├── webGeolocationUtils.ts
    │   │       ├── windowUtils.tsx
    │   │       ├── audio/
    │   │       │   ├── AudioGenerator.ts
    │   │       │   ├── AudioLivePlayer.ts
    │   │       │   ├── AudioPlayer.ts
    │   │       │   └── usePlayUrl.ts
    │   │       ├── hooks/
    │   │       │   ├── useAsyncCallBusy.ts
    │   │       │   ├── useDeep.ts
    │   │       │   ├── useShallowObject.ts
    │   │       │   └── useToggleableBoolean.ts
    │   │       └── mediasession/
    │   │           ├── MediaSessionManager.ts
    │   │           └── useMediaSessionCallbacks.ts
    │   ├── modules/
    │   │   ├── 3rdparty/
    │   │   │   ├── THIRD_PARTY_NOTICES.md
    │   │   │   ├── aider/
    │   │   │   │   ├── AIDER-LICENSE.txt
    │   │   │   │   ├── coderPrompts.ts
    │   │   │   │   ├── editBlockCoder.ts
    │   │   │   │   ├── editBlockPrompts.ts
    │   │   │   │   ├── glue.ts
    │   │   │   │   └── wholeFilePrompts.ts
    │   │   │   └── t3-env/
    │   │   │       ├── env-core.ts
    │   │   │       ├── index.ts
    │   │   │       └── standard.ts
    │   │   ├── aifn/
    │   │   │   ├── useLLMChain.ts
    │   │   │   ├── useStreamChatText.ts
    │   │   │   ├── agiattachmentprompts/
    │   │   │   │   ├── agiAttachmentPrompts.ts
    │   │   │   │   └── useAgiAttachmentPrompts.tsx
    │   │   │   ├── agicodefixup/
    │   │   │   │   ├── agiFixupCode.ts
    │   │   │   │   └── useAgiFixupCode.tsx
    │   │   │   ├── auto-chat-follow-ups/
    │   │   │   │   └── autoChatFollowUps.ts
    │   │   │   ├── autotitle/
    │   │   │   │   └── autoTitle.ts
    │   │   │   ├── digrams/
    │   │   │   │   ├── diagrams.data.ts
    │   │   │   │   └── DiagramsModal.tsx
    │   │   │   ├── flatten/
    │   │   │   │   ├── flatten.data.ts
    │   │   │   │   └── FlattenerModal.tsx
    │   │   │   ├── imagine/
    │   │   │   │   └── imaginePromptFromText.ts
    │   │   │   ├── react/
    │   │   │   │   └── react.ts
    │   │   │   └── summarize/
    │   │   │       ├── ContentReducer.tsx
    │   │   │       └── summerize.ts
    │   │   ├── aix/
    │   │   │   ├── AIX.README.md
    │   │   │   ├── client/
    │   │   │   │   ├── aix.client.chatGenerateRequest.ts
    │   │   │   │   ├── aix.client.fromSimpleFunction.ts
    │   │   │   │   ├── aix.client.test.ts
    │   │   │   │   ├── aix.client.ts
    │   │   │   │   ├── ContentReassembler.ts
    │   │   │   │   ├── withDecimator.ts
    │   │   │   │   └── debugger/
    │   │   │   │       ├── AixDebuggerDialog.tsx
    │   │   │   │       ├── AixDebuggerFrame.tsx
    │   │   │   │       ├── AixDebuggerMeasurementsTable.tsx
    │   │   │   │       ├── memstore-aix-client-debugger.ts
    │   │   │   │       └── reassembler-debug.ts
    │   │   │   └── server/
    │   │   │       ├── api/
    │   │   │       │   ├── aix.router.ts
    │   │   │       │   └── aix.wiretypes.ts
    │   │   │       └── dispatch/
    │   │   │           ├── heartbeatsWhileAwaiting.ts
    │   │   │           ├── PerformanceProfiler.ts
    │   │   │           ├── stream.demuxer.fastsse.ts
    │   │   │           ├── stream.demuxer.sse.ts
    │   │   │           ├── stream.demuxers.ts
    │   │   │           ├── chatGenerate/
    │   │   │           │   ├── chatGenerate.dispatch.ts
    │   │   │           │   ├── ChatGenerateTransmitter.ts
    │   │   │           │   ├── IParticleTransmitter.ts
    │   │   │           │   ├── adapters/
    │   │   │           │   │   ├── anthropic.messageCreate.ts
    │   │   │           │   │   ├── gemini.generateContent.ts
    │   │   │           │   │   ├── openai.chatCompletions.ts
    │   │   │           │   │   └── openai.responsesCreate.ts
    │   │   │           │   └── parsers/
    │   │   │           │       ├── anthropic.parser.ts
    │   │   │           │       ├── gemini.audioutils.ts
    │   │   │           │       ├── gemini.parser.ts
    │   │   │           │       ├── openai.parser.ts
    │   │   │           │       └── openai.responses.parser.ts
    │   │   │           └── wiretypes/
    │   │   │               ├── anthropic.wiretypes.ts
    │   │   │               ├── gemini.wiretypes.ts
    │   │   │               └── openai.wiretypes.ts
    │   │   ├── backend/
    │   │   │   ├── backend.router.ts
    │   │   │   └── store-backend-capabilities.ts
    │   │   ├── beam/
    │   │   │   ├── beam.config.ts
    │   │   │   ├── BeamCard.tsx
    │   │   │   ├── BeamExplainer.tsx
    │   │   │   ├── BeamView.tsx
    │   │   │   ├── store-beam.hooks.ts
    │   │   │   ├── store-beam_vanilla.ts
    │   │   │   ├── store-module-beam.tsx
    │   │   │   ├── gather/
    │   │   │   │   ├── beam.gather.ts
    │   │   │   │   ├── BeamFusionGrid.tsx
    │   │   │   │   ├── BeamGatherPane.tsx
    │   │   │   │   ├── Fusion.tsx
    │   │   │   │   ├── FusionControls.tsx
    │   │   │   │   ├── FusionInstructionsEditor.tsx
    │   │   │   │   └── instructions/
    │   │   │   │       ├── beam.gather.execution.tsx
    │   │   │   │       ├── beam.gather.factories.ts
    │   │   │   │       ├── GatherInstruction.tsx
    │   │   │   │       ├── UserInputChecklistComponent.tsx
    │   │   │   │       └── UserInputChecklistInstruction.tsx
    │   │   │   └── scatter/
    │   │   │       ├── beam.scatter.ts
    │   │   │       ├── BeamRay.tsx
    │   │   │       ├── BeamRayGrid.tsx
    │   │   │       ├── BeamScatterInput.tsx
    │   │   │       ├── BeamScatterPane.tsx
    │   │   │       └── BeamScatterPaneDropdown.tsx
    │   │   ├── blocks/
    │   │   │   ├── AutoBlocksRenderer.tsx
    │   │   │   ├── blocks.hooks.ts
    │   │   │   ├── blocks.styles.ts
    │   │   │   ├── blocks.textparser.ts
    │   │   │   ├── blocks.types.ts
    │   │   │   ├── BlocksContainers.tsx
    │   │   │   ├── OverlayButton.tsx
    │   │   │   ├── ScaledTextBlockRenderer.tsx
    │   │   │   ├── ToggleExpansionButton.tsx
    │   │   │   ├── code/
    │   │   │   │   ├── RenderCode.css
    │   │   │   │   ├── RenderCode.tsx
    │   │   │   │   ├── RenderCodePanelFrame.tsx
    │   │   │   │   ├── useStickyCodeOverlay.tsx
    │   │   │   │   ├── code-buttons/
    │   │   │   │   │   ├── openInCodePen.tsx
    │   │   │   │   │   ├── openInGoogleColab.tsx
    │   │   │   │   │   ├── openInJsFiddle.tsx
    │   │   │   │   │   ├── openInStackBlitz.tsx
    │   │   │   │   │   └── useOpenInWebEditors.tsx
    │   │   │   │   ├── code-highlight/
    │   │   │   │   │   └── codePrism.ts
    │   │   │   │   └── code-renderers/
    │   │   │   │       ├── plantuml.utils.ts
    │   │   │   │       ├── RenderCodeHtmlIFrame.tsx
    │   │   │   │       ├── RenderCodeMermaid.tsx
    │   │   │   │       ├── RenderCodePlantUML.tsx
    │   │   │   │       ├── RenderCodeSVG.tsx
    │   │   │   │       └── RenderCodeSyntax.tsx
    │   │   │   ├── danger-html/
    │   │   │   │   └── RenderDangerousHtml.tsx
    │   │   │   ├── enhanced-code/
    │   │   │   │   ├── codeCollapseManager.ts
    │   │   │   │   ├── EnhancedRenderCode.tsx
    │   │   │   │   ├── EnhancedRenderCodeMenu.tsx
    │   │   │   │   └── livefile-patch/
    │   │   │   │       ├── useLiveFilePatch.tsx
    │   │   │   │       └── usePatchingWorkflow.tsx
    │   │   │   ├── image/
    │   │   │   │   ├── RenderImageRefDBlob.tsx
    │   │   │   │   └── RenderImageURL.tsx
    │   │   │   ├── markdown/
    │   │   │   │   ├── CustomARenderer.tsx
    │   │   │   │   ├── CustomMarkdownRenderer.tsx
    │   │   │   │   ├── markdown.wrapper.ts
    │   │   │   │   └── RenderMarkdown.tsx
    │   │   │   ├── plaintext/
    │   │   │   │   └── RenderPlainText.tsx
    │   │   │   └── wordsdiff/
    │   │   │       └── RenderWordsDiff.tsx
    │   │   ├── browse/
    │   │   │   ├── browse.client.ts
    │   │   │   ├── browse.files.ts
    │   │   │   ├── browse.router.ts
    │   │   │   ├── BrowseSettings.tsx
    │   │   │   └── store-module-browsing.tsx
    │   │   ├── dblobs/
    │   │   │   ├── dblobs.db.ts
    │   │   │   ├── dblobs.hooks.ts
    │   │   │   ├── dblobs.images.ts
    │   │   │   └── dblobs.types.ts
    │   │   ├── elevenlabs/
    │   │   │   ├── elevenlabs.client.ts
    │   │   │   ├── elevenlabs.router.ts
    │   │   │   ├── ElevenlabsSettings.tsx
    │   │   │   ├── store-module-elevenlabs.ts
    │   │   │   └── useElevenLabsVoiceDropdown.tsx
    │   │   ├── google/
    │   │   │   ├── GoogleSearchSettings.tsx
    │   │   │   ├── search.client.ts
    │   │   │   ├── search.router.ts
    │   │   │   ├── search.types.ts
    │   │   │   └── store-module-google.ts
    │   │   ├── llms/
    │   │   │   ├── llm.client.hooks.ts
    │   │   │   ├── llm.client.ts
    │   │   │   ├── components/
    │   │   │   │   ├── LLMVendorIcon.tsx
    │   │   │   │   └── LLMVendorSetup.tsx
    │   │   │   ├── models-modal/
    │   │   │   │   ├── LLMOptionsGlobal.tsx
    │   │   │   │   ├── LLMOptionsModal.tsx
    │   │   │   │   ├── LLMParametersEditor.tsx
    │   │   │   │   ├── ModelsConfiguratorModal.tsx
    │   │   │   │   ├── ModelsList.tsx
    │   │   │   │   ├── ModelsModals.tsx
    │   │   │   │   ├── ModelsServiceSelector.tsx
    │   │   │   │   └── ModelsWizard.tsx
    │   │   │   ├── server/
    │   │   │   │   ├── llm.server.types.ts
    │   │   │   │   ├── anthropic/
    │   │   │   │   │   ├── anthropic.models.ts
    │   │   │   │   │   └── anthropic.router.ts
    │   │   │   │   ├── gemini/
    │   │   │   │   │   ├── gemini.models.ts
    │   │   │   │   │   └── gemini.router.ts
    │   │   │   │   ├── ollama/
    │   │   │   │   │   ├── ollama.models.ts
    │   │   │   │   │   ├── ollama.router.ts
    │   │   │   │   │   └── ollama.wiretypes.ts
    │   │   │   │   └── openai/
    │   │   │   │       ├── fireworksai.wiretypes.ts
    │   │   │   │       ├── groq.wiretypes.ts
    │   │   │   │       ├── localai.wiretypes.ts
    │   │   │   │       ├── models.cba.ts
    │   │   │   │       ├── openai.router.ts
    │   │   │   │       ├── openpipe.wiretypes.ts
    │   │   │   │       ├── openrouter.wiretypes.ts
    │   │   │   │       ├── togetherai.wiretypes.ts
    │   │   │   │       └── models/
    │   │   │   │           ├── alibaba.models.ts
    │   │   │   │           ├── azure.models.ts
    │   │   │   │           ├── chutesai.models.ts
    │   │   │   │           ├── deepseek.models.ts
    │   │   │   │           ├── fastapi.models.ts
    │   │   │   │           ├── fireworksai.models.ts
    │   │   │   │           ├── groq.models.ts
    │   │   │   │           ├── mistral.models.ts
    │   │   │   │           ├── models.data.ts
    │   │   │   │           ├── openai.models.ts
    │   │   │   │           ├── openpipe.models.ts
    │   │   │   │           ├── openrouter.models.ts
    │   │   │   │           ├── perplexity.models.ts
    │   │   │   │           ├── together.models.ts
    │   │   │   │           └── xai.models.ts
    │   │   │   └── vendors/
    │   │   │       ├── ApproximateCosts.tsx
    │   │   │       ├── IModelVendor.ts
    │   │   │       ├── useServiceSetup.ts
    │   │   │       ├── vendor.helpers.ts
    │   │   │       ├── vendors.registry.ts
    │   │   │       ├── alibaba/
    │   │   │       │   ├── alibaba.vendor.ts
    │   │   │       │   └── AlibabaServiceSetup.tsx
    │   │   │       ├── anthropic/
    │   │   │       │   ├── anthropic.vendor.ts
    │   │   │       │   └── AnthropicServiceSetup.tsx
    │   │   │       ├── azure/
    │   │   │       │   ├── azure.vendor.ts
    │   │   │       │   └── AzureServiceSetup.tsx
    │   │   │       ├── deepseek/
    │   │   │       │   ├── deepseekai.vendor.ts
    │   │   │       │   └── DeepseekAIServiceSetup.tsx
    │   │   │       ├── gemini/
    │   │   │       │   ├── gemini.vendor.ts
    │   │   │       │   └── GeminiServiceSetup.tsx
    │   │   │       ├── groq/
    │   │   │       │   ├── groq.vendor.ts
    │   │   │       │   └── GroqServiceSetup.tsx
    │   │   │       ├── lmstudio/
    │   │   │       │   ├── lmstudio.vendor.ts
    │   │   │       │   └── LMStudioServiceSetup.tsx
    │   │   │       ├── localai/
    │   │   │       │   ├── localai.vendor.ts
    │   │   │       │   ├── LocalAIAdmin.tsx
    │   │   │       │   └── LocalAIServiceSetup.tsx
    │   │   │       ├── mistral/
    │   │   │       │   ├── mistral.vendor.ts
    │   │   │       │   └── MistralServiceSetup.tsx
    │   │   │       ├── ollama/
    │   │   │       │   ├── ollama.vendor.ts
    │   │   │       │   ├── OllamaAdministration.tsx
    │   │   │       │   └── OllamaServiceSetup.tsx
    │   │   │       ├── openai/
    │   │   │       │   ├── openai.vendor.ts
    │   │   │       │   └── OpenAIServiceSetup.tsx
    │   │   │       ├── openpipe/
    │   │   │       │   ├── openpipe.vendor.ts
    │   │   │       │   └── OpenPipeServiceSetup.tsx
    │   │   │       ├── openrouter/
    │   │   │       │   ├── openrouter.vendor.ts
    │   │   │       │   └── OpenRouterServiceSetup.tsx
    │   │   │       ├── perplexity/
    │   │   │       │   ├── perplexity.vendor.ts
    │   │   │       │   └── PerplexityServiceSetup.tsx
    │   │   │       ├── togetherai/
    │   │   │       │   ├── togetherai.vendor.ts
    │   │   │       │   └── TogetherAIServiceSetup.tsx
    │   │   │       └── xai/
    │   │   │           ├── xai.vendor.ts
    │   │   │           └── XAIServiceSetup.tsx
    │   │   ├── persona/
    │   │   │   └── pmix/
    │   │   │       ├── pmix.parameters.ts
    │   │   │       └── pmix.ts
    │   │   ├── t2i/
    │   │   │   ├── store-module-t2i.ts
    │   │   │   ├── t2i.client.ts
    │   │   │   ├── t2i.server.ts
    │   │   │   ├── T2ISettings.tsx
    │   │   │   ├── dalle/
    │   │   │   │   ├── DallESettings.tsx
    │   │   │   │   ├── openaiGenerateImages.ts
    │   │   │   │   └── store-module-dalle.ts
    │   │   │   └── localai/
    │   │   │       └── localaiGenerateImages.ts
    │   │   ├── trade/
    │   │   │   ├── BackupRestore.tsx
    │   │   │   ├── ExportChats.tsx
    │   │   │   ├── ImportChats.tsx
    │   │   │   ├── ImportOutcomeModal.tsx
    │   │   │   ├── trade.client.ts
    │   │   │   ├── TradeModal.tsx
    │   │   │   ├── link/
    │   │   │   │   ├── ChatLinkDetails.tsx
    │   │   │   │   ├── ChatLinkExport.tsx
    │   │   │   │   └── store-share-link.ts
    │   │   │   ├── publish/
    │   │   │   │   ├── PublishDetails.tsx
    │   │   │   │   └── PublishExport.tsx
    │   │   │   └── server/
    │   │   │       ├── chatgpt.ts
    │   │   │       ├── link.ts
    │   │   │       ├── pastegg.ts
    │   │   │       └── trade.router.ts
    │   │   └── youtube/
    │   │       ├── useYouTubeTranscript.tsx
    │   │       ├── youtube.router.ts
    │   │       ├── youtube.server.ts
    │   │       ├── youtube.types.ts
    │   │       ├── youtube.utils.ts
    │   │       └── YouTubeURLInput.tsx
    │   └── server/
    │       ├── env.ts
    │       ├── wire.ts
    │       ├── posthog/
    │       │   └── posthog.server.ts
    │       ├── prisma/
    │       │   ├── prismaDb.ts
    │       │   └── schema.prisma
    │       └── trpc/
    │           ├── trpc.nanoid.ts
    │           ├── trpc.next-edge.ts
    │           ├── trpc.router-cloud.ts
    │           ├── trpc.router-edge.ts
    │           ├── trpc.router.fetchers.ts
    │           ├── trpc.server.ts
    │           └── trpc.transformer.ts
    ├── tools/
    │   └── ai/
    │       ├── README.md
    │       └── repo-structure.sh
    ├── .claude/
    │   └── settings.local.json
    └── .github/
        ├── FUNDING.yml
        ├── ISSUE_TEMPLATE/
        │   ├── bug_report.yml
        │   ├── maintainers-release.md
        │   └── roadmap-request.md
        └── workflows/
            └── docker-image.yml

================================================
FILE: README.md
================================================
# BIG-AGI 🧠

Welcome to big-AGI, the AI suite for professionals that need function, form,
simplicity, and speed. Powered by the latest models from 15 vendors and
open-source servers, `big-AGI` offers best-in-class Chats,
[Beams](https://github.com/enricoros/big-AGI/issues/470),
and [Calls](https://github.com/enricoros/big-AGI/issues/354) with AI personas,
visualizations, coding, drawing, side-by-side chatting, and more -- all wrapped in a polished UX.

Stay ahead of the curve with big-AGI. 🚀 Pros & Devs love big-AGI. 🤖

[![Official Website](https://img.shields.io/badge/BIG--AGI.com-%23096bde?style=for-the-badge&logo=vercel&label=launch)](https://big-agi.com)

> 🚀 Big-AGI 2 is launching soon.

Or fork & run on Vercel

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fenricoros%2Fbig-AGI&env=OPENAI_API_KEY&envDescription=Backend%20API%20keys%2C%20optional%20and%20may%20be%20overridden%20by%20the%20UI.&envLink=https%3A%2F%2Fgithub.com%2Fenricoros%2Fbig-AGI%2Fblob%2Fmain%2Fdocs%2Fenvironment-variables.md&project-name=big-AGI)

### New Version

This repository contains two main versions:

- Big-AGI 2: next-generation, bringing the most advanced AI experience
  - `v2-dev`: V2 development branch, the exciting one, future default (this branch)
- Big-AGI Stable: as deployed on big-agi.com
  - `v1-stable`: Current stable version, and currently the Docker 'latest' tagged images

Note: After the V2 Q1 2025 release, `v2-dev` will become the default branch and `v1-stable` will reach EOL.

### Quick links: 👉 [roadmap](https://github.com/users/enricoros/projects/4/views/2) 👉 [installation](docs/installation.md) 👉 [documentation](docs/README.md)

---

### 5,000 Commits Milestone · Jan 2025

Hit 5k commits last week. That's a lot of code, and it's the [foundation for what's coming](https://big-agi.com/blog/big-agi-2-is-almost-ready).

Recent work has been intense:
- Chain of thought reasoning across multiple LLMs: **OpenAI o3** and o1, **DeepSeek R1**, **Gemini 2.0 Flash Thinking**, and more
- Beam is real - ~35% of our free users run it daily to compare models
- New AIX framework lets us scale features we couldn't before
- UI is faster than ever. Like, terminal-fast

Big-AGI 2 is weeks away. Yes, we're late, but we're making it right. The new architecture is solid and the speed improvements are real.

Stay tuned. This is going to be good.

![5000e-830px](https://github.com/user-attachments/assets/42f7420b-9331-421b-9a18-2e653aaa7d9b)

### What's New in 1.16.1...1.16.9 · Jan 21, 2025 (patch releases)

- 1.16.9: Docker Gemini fix (R1 models are supported in Big-AGI 2)
- 1.16.8: OpenAI ChatGPT-4o Latest (o1 models are supported in Big-AGI 2)
- 1.16.7: OpenAI support for GPT-4o 2024-08-06
- 1.16.6: Groq support for Llama 3.1 models
- 1.16.5: GPT-4o Mini support
- 1.16.4: 8192 tokens support for Claude 3.5 Sonnet
- 1.16.3: Anthropic Claude 3.5 Sonnet model support
- 1.16.2: Improve web downloads, as text, markdown, or HTML
- 1.16.2: Proper support for Gemini models
- 1.16.2: Added the latest Mistral model
- 1.16.2: Tokenizer support for gpt-4o
- 1.16.2: Updates to Beam
- 1.16.1: Support for the new OpenAI GPT-4o 2024-05-13 model

### What's New in 1.16.0 · May 9, 2024 · Crystal Clear

- [Beam](https://big-agi.com/blog/beam-multi-model-ai-reasoning) core and UX improvements based on user feedback
- Chat cost estimation 💰 (enable it in Labs / hover the token counter)
- Save/load chat files with Ctrl+S / Ctrl+O on desktop
- Major enhancements to the Auto-Diagrams tool
- YouTube Transcriber Persona for chatting with video content, [#500](https://github.com/enricoros/big-AGI/pull/500)
- Improved formula rendering (LaTeX), and dark-mode diagrams, [#508](https://github.com/enricoros/big-AGI/issues/508), [#520](https://github.com/enricoros/big-AGI/issues/520)
- Models update: **Anthropic**, **Groq**, **Ollama**, **OpenAI**, **OpenRouter**, **Perplexity**
- Code soft-wrap, chat text selection toolbar, 3x faster on Apple silicon, and more [#517](https://github.com/enricoros/big-AGI/issues/517), [507](https://github.com/enricoros/big-AGI/pull/507)

#### 3,000 Commits Milestone · April 7, 2024

![big-AGI Milestone](https://github.com/enricoros/big-AGI/assets/32999/47fddbb1-9bd6-4b58-ace4-781dfcb80923)

- 🥇 Today we <b>celebrate commit 3000</b> in just over one year, and going stronger 🚀
- 📢️ Thanks everyone for your support and words of love for Big-AGI, we are committed to creating the best AI experiences for everyone.

### What's New in 1.15.0 · April 1, 2024 · Beam

- ⚠️ [**Beam**: the multi-model AI chat](https://big-agi.com/blog/beam-multi-model-ai-reasoning). find better answers, faster - a game-changer for brainstorming, decision-making, and creativity. [#443](https://github.com/enricoros/big-AGI/issues/443)
- Managed Deployments **Auto-Configuration**: simplify the UI models setup with backend-set models. [#436](https://github.com/enricoros/big-AGI/issues/436)
- Message **Starring ⭐**: star important messages within chats, to attach them later. [#476](https://github.com/enricoros/big-AGI/issues/476)
- Enhanced the default Persona
- Fixes to Gemini models and SVGs, improvements to UI and icons
- 1.15.1: Support for Gemini Pro 1.5 and OpenAI Turbo models
- Beast release, over 430 commits, 10,000+ lines changed: [release notes](https://github.com/enricoros/big-AGI/releases/tag/v1.15.0), and changes [v1.14.1...v1.15.0](https://github.com/enricoros/big-AGI/compare/v1.14.1...v1.15.0)

<details>
<summary>What's New in 1.14.1 · March 7, 2024 · Modelmorphic</summary>

- **Anthropic** [Claude-3](https://www.anthropic.com/news/claude-3-family) model family support. [#443](https://github.com/enricoros/big-AGI/issues/443)
- New **[Perplexity](https://www.perplexity.ai/)** and **[Groq](https://groq.com/)** integration (thanks @Penagwin). [#407](https://github.com/enricoros/big-AGI/issues/407), [#427](https://github.com/enricoros/big-AGI/issues/427)
- **[LocalAI](https://localai.io/models/)** deep integration, including support for [model galleries](https://github.com/enricoros/big-AGI/issues/411)
- **Mistral** Large and Google **Gemini 1.5** support
- Performance optimizations: runs [much faster](https://twitter.com/enricoros/status/1756553038293303434?utm_source=localhost:3000&utm_medium=big-agi), saves lots of power, reduces memory usage
- Enhanced UX with auto-sizing charts, refined search and folder functionalities, perfected scaling
- And with more UI improvements, documentation, bug fixes (20 tickets), and developer enhancements

</details>

<details>
<summary>What's New in 1.13.0 · Feb 8, 2024 · Multi + Mind</summary>

https://github.com/enricoros/big-AGI/assets/32999/01732528-730e-41dc-adc7-511385686b13

- **Side-by-Side Split Windows**: multitask with parallel conversations. [#208](https://github.com/enricoros/big-AGI/issues/208)
- **Multi-Chat Mode**: message everyone, all at once. [#388](https://github.com/enricoros/big-AGI/issues/388)
- **Export tables as CSV**: big thanks to @aj47. [#392](https://github.com/enricoros/big-AGI/pull/392)
- Adjustable text size: customize density. [#399](https://github.com/enricoros/big-AGI/issues/399)
- Dev2 Persona Technology Preview
- Better looking chats with improved spacing, fonts, and menus
- More: new video player, [LM Studio tutorial](https://github.com/enricoros/big-AGI/blob/main/docs/config-local-lmstudio.md) (thanks @aj47), [MongoDB support](https://github.com/enricoros/big-AGI/blob/main/docs/deploy-database.md) (thanks @ranfysvalle02), and speedups

</details>

<details>
<summary>What's New in 1.12.0 · Jan 26, 2024 · AGI Hotline</summary>

https://github.com/enricoros/big-AGI/assets/32999/95ceb03c-945d-4fdd-9a9f-3317beb54f3f

- **Voice Calls**: real-time voice call your personas out of the blue or in relation to a chat [#354](https://github.com/enricoros/big-AGI/issues/354)
- Support **OpenAI 0125** Models. [#364](https://github.com/enricoros/big-AGI/issues/364)
- Rename or Auto-Rename chats.  [#222](https://github.com/enricoros/big-AGI/issues/222), [#360](https://github.com/enricoros/big-AGI/issues/360)
- More control over **Link Sharing** [#356](https://github.com/enricoros/big-AGI/issues/356)
- **Accessibility** to screen readers [#358](https://github.com/enricoros/big-AGI/issues/358)
- Export chats to Markdown [#337](https://github.com/enricoros/big-AGI/issues/337)
- Paste tables from Excel [#286](https://github.com/enricoros/big-AGI/issues/286)
- Ollama model updates and context window detection fixes [#309](https://github.com/enricoros/big-AGI/issues/309)

</details>

<details>
<summary>What's New in 1.11.0 · Jan 16, 2024 · Singularity</summary>

https://github.com/enricoros/big-AGI/assets/1590910/a6b8e172-0726-4b03-a5e5-10cfcb110c68

- **Find chats**: search in titles and content, with frequency ranking. [#329](https://github.com/enricoros/big-AGI/issues/329)
- **Commands**: command auto-completion (type '/'). [#327](https://github.com/enricoros/big-AGI/issues/327)
- **[Together AI](https://www.together.ai/products#inference)** inference platform support (good speed and newer models). [#346](https://github.com/enricoros/big-AGI/issues/346)
- Persona Creator history, deletion, custom creation, fix llm API timeouts
- Enable adding up to five custom OpenAI-compatible endpoints
- Developer enhancements: new 'Actiles' framework

</details>

<details>
<summary>What's New in 1.10.0 · Jan 6, 2024 · The Year of AGI</summary>

- **New UI**: for both desktop and mobile, sets the stage for future scale. [#201](https://github.com/enricoros/big-AGI/issues/201)
- **Conversation Folders**: enhanced conversation organization. [#321](https://github.com/enricoros/big-AGI/issues/321)
- **[LM Studio](https://lmstudio.ai/)** support and improved token management
- Resizable panes in split-screen conversations.
- Large performance optimizations
- Developer enhancements: new UI framework, updated documentation for proxy settings on browserless/docker

</details>

For full details and former releases, check out the [changelog](docs/changelog.md).

## 👉 Key Features

| ![Advanced AI](https://img.shields.io/badge/Advanced%20AI-32383e?style=for-the-badge&logo=ai&logoColor=white) | ![100+ AI Models](https://img.shields.io/badge/100%2B%20AI%20Models-32383e?style=for-the-badge&logo=ai&logoColor=white) | ![Flow-state UX](https://img.shields.io/badge/Flow--state%20UX-32383e?style=for-the-badge&logo=flow&logoColor=white) | ![Privacy First](https://img.shields.io/badge/Privacy%20First-32383e?style=for-the-badge&logo=privacy&logoColor=white) | ![Advanced Tools](https://img.shields.io/badge/Fun%20To%20Use-f22a85?style=for-the-badge&logo=tools&logoColor=white) |  
|---------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------| 
| **Chat**<br/>**Call**<br/>**Beam**<br/>**Draw**, ...                                                          | Local & Cloud<br/>Open & Closed<br/>Cheap & Heavy<br/>Google, Mistral, ...                                              | Attachments<br/>Diagrams<br/>Multi-Chat<br/>Mobile-first UI                                                          | Stored Locally<br/>Easy self-Host<br/>Local actions<br/>Data = Gold                                                    | AI Personas<br/>Voice Modes<br/>Screen Capture<br/>Camera + OCR                                                      |

![big-AGI screenshot](docs/pixels/big-AGI-compo-20240201_small.png)

You can easily configure 100s of AI models in big-AGI:

| **AI models**       | _supported vendors_                                                                                                                                                                                                                                                                            |
|:--------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Opensource Servers  | [LocalAI](https://localai.io/) (multimodal) · [Ollama](https://ollama.com/)                                                                                                                                                                                                                    |
| Local Servers       | [LM Studio](https://lmstudio.ai/)                                                                                                                                                                                                                                                              |
| Multimodal services | [Azure](https://azure.microsoft.com/en-us/products/ai-services/openai-service) · [Anthropic](https://anthropic.com) · [Google Gemini](https://ai.google.dev/) · [OpenAI](https://platform.openai.com/docs/overview)                                                                            |
| Language services   | [Alibaba](https://www.alibabacloud.com/en/product/modelstudio) · [DeepSeek](https://deepseek.com) · [Groq](https://wow.groq.com/) · [Mistral](https://mistral.ai/) · [OpenRouter](https://openrouter.ai/) · [Perplexity](https://www.perplexity.ai/) · [Together AI](https://www.together.ai/) | 
| Image services      | OpenAI, ...                                                                                                                                                                                                                                                                                    | 
| Speech services     | [ElevenLabs](https://elevenlabs.io) (Voice synthesis / cloning)                                                                                                                                                                                                                                | 

Add extra functionality with these integrations:

| **More**     | _integrations_                                                                                                 |
|:-------------|:---------------------------------------------------------------------------------------------------------------| 
| Web Browse   | [Browserless](https://www.browserless.io/) · [Puppeteer](https://pptr.dev/)-based                              |
| Web Search   | [Google CSE](https://programmablesearchengine.google.com/)                                                     |
| Code Editors | [CodePen](https://codepen.io/pen/) · [StackBlitz](https://stackblitz.com/) · [JSFiddle](https://jsfiddle.net/) |
| Sharing      | [Paste.gg](https://paste.gg/) (Paste chats)                                                                    | 
| Tracking     | [Helicone](https://www.helicone.ai) (LLM Observability)                                                        | 

[//]: # (- [x] **Flow-state UX** for uncompromised productivity)

[//]: # (- [x] **AI Personas**: Tailor your AI interactions with customizable personas)

[//]: # (- [x] **Sleek UI/UX**: A smooth, intuitive, and mobile-responsive interface)

[//]: # (- [x] **Efficient Interaction**: Voice commands, OCR, and drag-and-drop file uploads)

[//]: # (- [x] **Privacy First**: Self-host and use your own API keys for full control)

[//]: # (- [x] **Advanced Tools**: Execute code, import PDFs, and summarize documents)

[//]: # (- [x] **Seamless Integrations**: Enhance functionality with various third-party services)

[//]: # (- [x] **Open Roadmap**: Contribute to the progress of big-AGI)

<br/>

## 🚀 Installation

To get started with big-AGI, follow our comprehensive [Installation Guide](docs/installation.md).
The guide covers various installation options, whether you're spinning it up on
your local computer, deploying on Vercel, on Cloudflare, or rolling it out
through Docker.

Whether you're a developer, system integrator, or enterprise user, you'll find step-by-step instructions
to set up big-AGI quickly and easily.

[![Installation Guide](https://img.shields.io/badge/Installation%20Guide-blue?style=for-the-badge&logo=read-the-docs&logoColor=white)](docs/installation.md)

Or bring your API keys and jump straight into our free instance on [big-AGI.com](https://big-agi.com).

<br/>

# 🌟 Get Involved!

[//]: # ([![Official Discord]&#40;https://img.shields.io/discord/1098796266906980422?label=discord&logo=discord&logoColor=%23fff&style=for-the-badge&#41;]&#40;https://discord.gg/MkH4qj2Jp9&#41;)
[![Official Discord](https://discordapp.com/api/guilds/1098796266906980422/widget.png?style=banner2)](https://discord.gg/MkH4qj2Jp9)

- [ ] 📢️ [**Chat with us** on Discord](https://discord.gg/MkH4qj2Jp9)
- [ ] ⭐ **Give us a star** on GitHub 👆
- [ ] 🚀 **Do you like code**? You'll love this gem of a project! [_Pick up a task!_](https://github.com/users/enricoros/projects/4/views/4) - _easy_ to _pro_
- [ ] 💡 Got a feature suggestion? [_Add your roadmap ideas_](https://github.com/enricoros/big-agi/issues/new?&template=roadmap-request.md)
- [ ] ✨ [Deploy](docs/installation.md) your [fork](docs/customizations.md) for your friends and family, or [customize it for work](docs/customizations.md)

<br/>

[//]: # ([![GitHub stars]&#40;https://img.shields.io/github/stars/enricoros/big-agi&#41;]&#40;https://github.com/enricoros/big-agi/stargazers&#41;)

[//]: # ([![GitHub forks]&#40;https://img.shields.io/github/forks/enricoros/big-agi&#41;]&#40;https://github.com/enricoros/big-agi/network&#41;)

[//]: # ([![GitHub pull requests]&#40;https://img.shields.io/github/issues-pr/enricoros/big-agi&#41;]&#40;https://github.com/enricoros/big-agi/pulls&#41;)

[//]: # ([![License]&#40;https://img.shields.io/github/license/enricoros/big-agi&#41;]&#40;https://github.com/enricoros/big-agi/LICENSE&#41;)

## 📜 Licensing

Big-AGI incorporates third-party software components that are subject
to separate license terms. For detailed information about these
components and their respective licenses, please refer to
the [Third-Party Notices](src/modules/3rdparty/THIRD_PARTY_NOTICES.md).

---

2023-2024 · Enrico Ros x [Big-AGI](https://big-agi.com) · Like this project? Leave a star! 💫⭐



================================================
FILE: docker-compose.yaml
================================================
# Very simple docker-compose file to run the app on http://localhost:3000 (or http://127.0.0.1:3000).
#
# For more examples, such runnin big-AGI alongside a web browsing service, see the `docs/docker` folder.

version: '3.9'

services:
  big-agi:
    image: ghcr.io/enricoros/big-agi:latest
    ports:
      - "3000:3000"
    env_file:
      - .env
    command: [ "next", "start", "-p", "3000" ]


================================================
FILE: Dockerfile
================================================
# Base
FROM node:22-alpine AS base
ENV NEXT_TELEMETRY_DISABLED=1

# Dependencies
FROM base AS deps
WORKDIR /app

# Dependency files
COPY package*.json ./
COPY src/server/prisma ./src/server/prisma

# link ssl3 for latest Alpine
RUN sh -c '[ ! -e /lib/libssl.so.3 ] && ln -s /usr/lib/libssl.so.3 /lib/libssl.so.3 || echo "Link already exists"'

# Install dependencies, including dev (release builds should use npm ci)
ENV NODE_ENV=development
RUN npm ci


# Builder
FROM base AS builder
WORKDIR /app

# Deployment type marker
ENV NEXT_PUBLIC_DEPLOYMENT_TYPE=docker

# Optional build version arguments at build time
ARG NEXT_PUBLIC_BUILD_HASH
ENV NEXT_PUBLIC_BUILD_HASH=${NEXT_PUBLIC_BUILD_HASH}
ARG NEXT_PUBLIC_BUILD_REF_NAME
ENV NEXT_PUBLIC_BUILD_REF_NAME=${NEXT_PUBLIC_BUILD_REF_NAME}

# Optional argument to configure GA4 at build time (see: docs/deploy-analytics.md)
ARG NEXT_PUBLIC_GA4_MEASUREMENT_ID
ENV NEXT_PUBLIC_GA4_MEASUREMENT_ID=${NEXT_PUBLIC_GA4_MEASUREMENT_ID}

# Optional argument to configure PostHog at build time (see: docs/deploy-analytics.md)
ARG NEXT_PUBLIC_POSTHOG_KEY
ENV NEXT_PUBLIC_POSTHOG_KEY=${NEXT_PUBLIC_POSTHOG_KEY}

# Copy development deps and source
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# link ssl3 for latest Alpine
RUN sh -c '[ ! -e /lib/libssl.so.3 ] && ln -s /usr/lib/libssl.so.3 /lib/libssl.so.3 || echo "Link already exists"'

# Build the application
ENV NODE_ENV=production
RUN npm run build

# Reduce installed packages to production-only
RUN npm prune --production


# Runner
FROM base AS runner
WORKDIR /app

# As user
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

# Copy Built app
COPY --from=builder --chown=nextjs:nodejs /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next ./.next
COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/src/server/prisma ./src/server/prisma

# Minimal ENV for production
ENV NODE_ENV=production
ENV PATH=$PATH:/app/node_modules/.bin

# Run as non-root user
USER nextjs

# Expose port 3000 for the application to listen on
EXPOSE 3000

# Start the application
CMD ["next", "start"]



================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2023-2024 Enrico Ros

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: middleware_BASIC_AUTH.ts
================================================
/**
 * Middleware to protect `big-AGI` with HTTP Basic Authentication
 *
 * For more information on how to deploy with HTTP Basic Authentication, see:
 *  - [deploy-authentication.md](docs/deploy-authentication.md)
 */

import type { NextRequest } from 'next/server';
import { NextResponse } from 'next/server';


// noinspection JSUnusedGlobalSymbols
export function middleware(request: NextRequest) {

  // Validate deployment configuration
  if (!process.env.HTTP_BASIC_AUTH_USERNAME || !process.env.HTTP_BASIC_AUTH_PASSWORD) {
    console.warn('HTTP Basic Authentication is enabled but not configured');
    return new Response('Unauthorized/Unconfigured', unauthResponse);
  }

  // Request client authentication if no credentials are provided
  const authHeader = request.headers.get('authorization');
  if (!authHeader?.startsWith('Basic '))
    return new Response('Unauthorized', unauthResponse);

  // Request authentication if credentials are invalid
  const base64Credentials = authHeader.split(' ')[1];
  const credentials = Buffer.from(base64Credentials, 'base64').toString('ascii');
  const [username, password] = credentials.split(':');
  if (
    !username || !password ||
    username !== process.env.HTTP_BASIC_AUTH_USERNAME ||
    password !== process.env.HTTP_BASIC_AUTH_PASSWORD
  )
    return new Response('Unauthorized', unauthResponse);

  return NextResponse.next();
}


// Response to send when authentication is required
const unauthResponse: ResponseInit = {
  status: 401,
  headers: {
    'WWW-Authenticate': 'Basic realm="Secure big-AGI"',
  },
};

export const config = {
  matcher: [
    // Include root
    '/',
    // Include pages
    '/(call|index|news|personas|link)(.*)',
    // Include API routes
    '/api(.*)',
    // Note: this excludes _next, /images etc..
  ],
};


================================================
FILE: next.config.ts
================================================
import type { NextConfig } from 'next';
import { execSync } from 'node:child_process';
import { readFileSync } from 'node:fs';

// Build information: from CI, or git commit hash
let buildHash = process.env.NEXT_PUBLIC_BUILD_HASH || process.env.GITHUB_SHA || process.env.VERCEL_GIT_COMMIT_SHA; // Docker or custom, GitHub Actions, Vercel
try {
  // fallback to local git commit hash
  if (!buildHash)
    buildHash = execSync('git rev-parse --short HEAD').toString().trim();
} catch {
  // final fallback
  buildHash = '2-dev';
}
// The following are used by/available to Release.buildInfo(...)
process.env.NEXT_PUBLIC_BUILD_HASH = (buildHash || '').slice(0, 10);
process.env.NEXT_PUBLIC_BUILD_PKGVER = JSON.parse('' + readFileSync(new URL('./package.json', import.meta.url))).version;
process.env.NEXT_PUBLIC_BUILD_TIMESTAMP = new Date().toISOString();
process.env.NEXT_PUBLIC_DEPLOYMENT_TYPE = process.env.NEXT_PUBLIC_DEPLOYMENT_TYPE || (process.env.VERCEL_ENV ? `vercel-${process.env.VERCEL_ENV}` : 'local'); // Docker or custom, Vercel
console.log(` 🧠 \x1b[1mbig-AGI\x1b[0m v${process.env.NEXT_PUBLIC_BUILD_PKGVER} (@${process.env.NEXT_PUBLIC_BUILD_HASH})`);

// Non-default build types
const buildType =
  process.env.BIG_AGI_BUILD === 'standalone' ? 'standalone' as const
    : process.env.BIG_AGI_BUILD === 'static' ? 'export' as const
      : undefined;

buildType && console.log(` 🧠 big-AGI: building for ${buildType}...\n`);

/** @type {import('next').NextConfig} */
let nextConfig: NextConfig = {
  reactStrictMode: true,

  // [exports] https://nextjs.org/docs/advanced-features/static-html-export
  ...buildType && {
    output: buildType,
    distDir: 'dist',

    // disable image optimization for exports
    images: { unoptimized: true },

    // Optional: Change links `/me` -> `/me/` and emit `/me.html` -> `/me/index.html`
    // trailingSlash: true,
  },

  // [puppeteer] https://github.com/puppeteer/puppeteer/issues/11052
  // NOTE: we may not be needing this anymore, as we use '@cloudflare/puppeteer'
  serverExternalPackages: ['puppeteer-core'],

  webpack: (config: any, { isServer }: { isServer: boolean }) => {
    // @mui/joy: anything material gets redirected to Joy
    config.resolve.alias['@mui/material'] = '@mui/joy';

    // @dqbd/tiktoken: enable asynchronous WebAssembly
    config.experiments = {
      asyncWebAssembly: true,
      layers: true,
    };

    // fix warnings for async functions in the browser (https://github.com/vercel/next.js/issues/64792)
    if (!isServer) {
      config.output.environment = { ...config.output.environment, asyncFunction: true };
    }

    // prevent too many small chunks (40kb min) on 'client' packs (not 'server' or 'edge-server')
    // noinspection JSUnresolvedReference
    if (typeof config.optimization.splitChunks === 'object' && config.optimization.splitChunks.minSize) {
      // noinspection JSUnresolvedReference
      config.optimization.splitChunks.minSize = 40 * 1024;
    }

    return config;
  },

  // Optional Analytics > PostHog
  skipTrailingSlashRedirect: true, // required to support PostHog trailing slash API requests
  async rewrites() {
    return [
      {
        source: '/a/ph/static/:path*',
        destination: 'https://us-assets.i.posthog.com/static/:path*',
      },
      {
        source: '/a/ph/:path*',
        destination: 'https://us.i.posthog.com/:path*',
      },
      {
        source: '/a/ph/decide',
        destination: 'https://us.i.posthog.com/decide',
      },
    ];
  },

  // Note: disabled to check whether the project becomes slower with this
  // modularizeImports: {
  //   '@mui/icons-material': {
  //     transform: '@mui/icons-material/{{member}}',
  //   },
  // },

  // Uncomment the following leave console messages in production
  // compiler: {
  //   removeConsole: false,
  // },
};

// Validate environment variables, if set at build time. Will be actually read and used at runtime.
import { verifyBuildTimeVars } from '~/server/env';
verifyBuildTimeVars();

// PostHog error reporting with source maps for production builds
import { withPostHogConfig } from '@posthog/nextjs-config';
if (process.env.POSTHOG_API_KEY && process.env.POSTHOG_ENV_ID) {
  console.log(' 🧠 \x1b[1mbig-AGI\x1b[0m: building with PostHog error tracking and source maps...');
  nextConfig = withPostHogConfig(nextConfig, {
    personalApiKey: process.env.POSTHOG_API_KEY,
    envId: process.env.POSTHOG_ENV_ID,
    host: 'https://us.i.posthog.com', // backtrace upload host
    verbose: false,
    sourcemaps: {
      enabled: process.env.NODE_ENV === 'production',
      project: 'big-agi',
      version: process.env.NEXT_PUBLIC_BUILD_HASH,
      deleteAfterUpload: true,
    },
  });
}

// conditionally enable the nextjs bundle analyzer
import withBundleAnalyzer from '@next/bundle-analyzer';
if (process.env.ANALYZE_BUNDLE) {
  nextConfig = withBundleAnalyzer({ openAnalyzer: true })(nextConfig) as NextConfig;
}

export default nextConfig;


================================================
FILE: package.json
================================================
{
  "name": "big-agi",
  "version": "1.92.0",
  "private": true,
  "author": "Enrico Ros <enrico.ros@gmail.com>",
  "repository": "https://github.com/enricoros/big-agi",
  "scripts": {
    "dev": "next dev --turbopack",
    "dev-debug": "cross-env NODE_OPTIONS='--inspect' next dev",
    "dev-https": "next dev --experimental-https",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "postinstall": "prisma generate --no-hints",
    "db:push": "prisma db push",
    "db:studio": "prisma studio",
    "vercel:env:pull": "npx vercel env pull .env.development.local"
  },
  "prisma": {
    "schema": "src/server/prisma/schema.prisma"
  },
  "dependencies": {
    "@dnd-kit/core": "^6.3.1",
    "@dnd-kit/modifiers": "^9.0.0",
    "@dnd-kit/sortable": "^10.0.0",
    "@dnd-kit/utilities": "^3.2.2",
    "@emotion/cache": "^11.14.0",
    "@emotion/react": "^11.14.0",
    "@emotion/server": "^11.11.0",
    "@emotion/styled": "^11.14.1",
    "@mui/icons-material": "^5.17.1",
    "@mui/joy": "^5.0.0-beta.52",
    "@next/bundle-analyzer": "~15.1.8",
    "@prisma/client": "~5.22.0",
    "@tanstack/react-query": "^5.83.0",
    "@trpc/client": "^11.4.3",
    "@trpc/next": "^11.4.3",
    "@trpc/react-query": "^11.4.3",
    "@trpc/server": "^11.4.3",
    "@vercel/analytics": "^1.5.0",
    "@vercel/speed-insights": "^1.2.0",
    "browser-fs-access": "^0.38.0",
    "cheerio": "^1.1.2",
    "csv-stringify": "^6.6.0",
    "dexie": "^4.0.11",
    "dexie-react-hooks": "^1.1.7",
    "diff": "^8.0.2",
    "eventemitter3": "^5.0.1",
    "idb-keyval": "^6.2.2",
    "mammoth": "^1.9.1",
    "nanoid": "^5.1.5",
    "next": "~15.1.8",
    "nprogress": "^0.2.0",
    "pdfjs-dist": "5.3.31",
    "posthog-js": "^1.258.2",
    "posthog-node": "^5.6.0",
    "prismjs": "^1.30.0",
    "puppeteer-core": "^24.15.0",
    "react": "^18.3.1",
    "react-dom": "^18.3.1",
    "react-hook-form": "^7.61.1",
    "react-markdown": "^10.1.0",
    "react-player": "^3.3.1",
    "react-resizable-panels": "^3.0.3",
    "react-timeago": "^8.2.0",
    "rehype-katex": "^7.0.1",
    "remark-gfm": "^4.0.1",
    "remark-mark-highlight": "^0.1.1",
    "remark-math": "^6.0.0",
    "sharp": "^0.33.5",
    "superjson": "^2.2.2",
    "tesseract.js": "^6.0.1",
    "tiktoken": "^1.0.21",
    "turndown": "^7.2.0",
    "zod": "^4.0.10",
    "zustand": "^5.0.6"
  },
  "devDependencies": {
    "@posthog/nextjs-config": "^1.1.0",
    "@types/diff": "^7.0.2",
    "@types/node": "^24.0.15",
    "@types/nprogress": "^0.2.3",
    "@types/prismjs": "^1.26.5",
    "@types/react": "19.1.8",
    "@types/react-csv": "^1.1.10",
    "@types/react-dom": "19.1.6",
    "@types/react-timeago": "^4.1.7",
    "@types/turndown": "^5.0.5",
    "cross-env": "^7.0.3",
    "eslint": "^9.29.0",
    "eslint-config-next": "~15.1.8",
    "prettier": "^3.6.2",
    "prisma": "~5.22.0",
    "typescript": "^5.8.3"
  },
  "engines": {
    "node": "^24.0.0 || ^22.0.0 || ^20.0.0"
  }
}



================================================
FILE: tsconfig.json
================================================
{
  "compilerOptions": {
    /* Base Options: */
    "esModuleInterop": true,
    "skipLibCheck": true,
    "target": "es2022",
    "allowJs": true,
    "resolveJsonModule": true,
    "moduleDetection": "force",
    "isolatedModules": true,

    /* Strictness */
    "strict": true,
    "noUncheckedIndexedAccess": false,
    "checkJs": true,

    /* Bundled projects */
    "lib": ["dom", "dom.iterable", "ESNext"],
    "noEmit": true,
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "jsx": "preserve",
    "plugins": [{"name": "next"}],
    "incremental": true,

    /* Custom options */
    "forceConsistentCasingInFileNames": true,
    "jsxImportSource": "@emotion/react",

    /* Path Aliases */
    "baseUrl": ".",
    "paths": {
      "~/common/*": ["src/common/*"],
      "~/modules/*": ["src/modules/*"],
      "~/server/*": ["src/server/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts",
    // this is here only because otherwise, during standalone build the process would update this file
    "dist/types/**/*.ts"
  ],
  "exclude": ["node_modules", "dist", "electron", "**/*.test.ts", "**/*.test.tsx", "**/*.spec.ts", "**/*.spec.tsx", "**/unused/**"]
}



================================================
FILE: .dockerignore
================================================
# big-AGI non-code files
/docs/
/dist/
README.md

# Ignore build and log files
Dockerfile
/.dockerignore

# Node build artifacts
/node_modules
/.pnp
.pnp.js

# next.js
/.next/
/out/

# production
/build

# versioning
.git/
.github/

# IDEs
.idea/

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# local env files
.env*.local

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts



================================================
FILE: .eslintrc.json
================================================
{
  "extends": "next/core-web-vitals"
}


================================================
FILE: .npmrc
================================================
overrides=@mui/material@^5.0.0:
  dependencies:
    @mui/material: replaced-by=@mui/joy



================================================
FILE: .prettierrc
================================================
{
  "singleAttributePerLine": false,
  "singleQuote": true,
  "trailingComma": "all",
  "endOfLine": "lf",
  "printWidth": 160
}


================================================
FILE: app/api/cloud/[trpc]/route.ts
================================================
import { fetchRequestHandler } from '@trpc/server/adapters/fetch';

import { appRouterCloud } from '~/server/trpc/trpc.router-cloud';
import { createTRPCFetchContext } from '~/server/trpc/trpc.server';
import { posthogCaptureServerException } from '~/server/posthog/posthog.server';

const handlerNodeRoutes = (req: Request) => fetchRequestHandler({
  endpoint: '/api/cloud',
  router: appRouterCloud,
  req,
  createContext: createTRPCFetchContext,
  onError: async function({ path, error, type, ctx }) {

    // -> DEV error logging
    if (process.env.NODE_ENV === 'development')
      console.error(`❌ tRPC-cloud failed on ${path ?? 'unk-path'}: ${error.message}`);

    // -> Capture node errors
    await posthogCaptureServerException(error, {
      runtime: 'nodejs',
      endpoint: path ?? 'unknown',
      method: req.method,
      url: req.url,
      additionalProperties: {
        errorCode: error.code,
        errorType: type,
      },
    });
  },
});


// NOTE: the following statement breaks the build on non-pro deployments, and conditionals don't work either
//       so we resorted to raising the timeout from 10s to 60s in the vercel.json file instead
export const maxDuration = 60;
export const runtime = 'nodejs';
export const dynamic = 'force-dynamic';
export { handlerNodeRoutes as GET, handlerNodeRoutes as POST };


================================================
FILE: app/api/edge/[trpc]/route.ts
================================================
import { fetchRequestHandler } from '@trpc/server/adapters/fetch';

import { appRouterEdge } from '~/server/trpc/trpc.router-edge';
import { createTRPCFetchContext } from '~/server/trpc/trpc.server';

const handlerEdgeRoutes = (req: Request) => fetchRequestHandler({
  endpoint: '/api/edge',
  router: appRouterEdge,
  req,
  createContext: createTRPCFetchContext,
  onError:
    process.env.NODE_ENV === 'development'
      ? ({ path, error }) => console.error(`❌ tRPC-edge failed on ${path ?? 'unk-path'}: ${error.message}`)
      : undefined,
});

export const runtime = 'edge';
export { handlerEdgeRoutes as GET, handlerEdgeRoutes as POST };


================================================
FILE: docs/README.md
================================================
# Big-AGI Documentation

Information you need to get started, configure, and use big-AGI productively.

## Getting Started

Essential guides:

- **[FAQ](help-faq.md)**: Common questions and answers
- **[Enabling Microphone](help-feature-microphone.md)**: Configure speech recognition in your browser

## AI Services

How to set up AI models and features in big-AGI.

> 👉 The following applies to users of big-AGI.com, as the public instance is empty and requires user configuration.

- **Cloud AI Services**:
  - Easy API key configuration:
    [Alibaba](https://bailian.console.alibabacloud.com/?apiKey=1#/api-key),
    [Anthropic](https://console.anthropic.com/settings/keys),
    [Deepseek](https://platform.deepseek.com/api_keys),
    [Google Gemini](https://aistudio.google.com/app/apikey),
    [Groq](https://console.groq.com/keys),
    [Mistral](https://console.mistral.ai/api-keys/),
    [OpenAI](https://platform.openai.com/api-keys),
    [OpenPipe](https://app.openpipe.ai/settings),
    [Perplexity](https://www.perplexity.ai/settings/api),
    [TogetherAI](https://api.together.xyz/settings/api-keys),
    [xAI](http://x.ai/api)
  - **[Azure OpenAI](config-azure-openai.md)** guide
  - **FireworksAI** ([API keys](https://fireworks.ai/account/api-keys), via custom OpenAI endpoint: https://api.fireworks.ai/inference)
  - **[OpenRouter](config-openrouter.md)** guide


- **Local AI Integrations**:
  - [LocalAI](config-local-localai.md), [LM Studio](config-local-lmstudio.md), [Ollama](config-local-ollama.md)


- **Enhanced AI Features**:
  - **[Web Browsing](config-feature-browse.md)**: Enable web page download through third-party services or your own cloud
  - **Web Search**: Google Search API (see '[Environment Variables](environment-variables.md)')
  - **Image Generation**: GPT Image (gpt-image-1), DALL·E 3 and 2
  - **Voice Synthesis**: ElevenLabs API for voice generation

## Deployment & Customization

> 👉 The following applies to developers and experts who deploy their own big-AGI instance.

For deploying a custom big-AGI instance:

- **[Installation Guide](installation.md)**, including:
  - Set up your own big-AGI instance
  - Source build or pre-built options
  - Local, cloud, or on-premises deployment


- **Advanced Setup**:
  - **[Source Code Customization](customizations.md)**: Modify the source code
  - **[Access Control](deploy-authentication.md)**: Optional, add basic user authentication
  - **[Database Setup](deploy-database.md)**: Optional, enables "Chat Link Sharing"
  - **[Reverse Proxy](deploy-reverse-proxy.md)**: Optional, enables custom domains and SSL
  - **[Environment Variables](environment-variables.md)**: Pre-configures models and services

## Community & Support

- Visit our [GitHub repository](https://github.com/enricoros/big-AGI) for source code and issue tracking
- Check the latest updates in the [Changelog](changelog.md) or in-app [News](https://get.big-agi.com/news)
- Join our [Discord](https://discord.gg/MkH4qj2Jp9) for discussions and help

Let's build something great.



================================================
FILE: docs/2024-AI-APIs-Comparison.md
================================================
# AIX dispatch server - API features comparison

This is updated as of 2024-07-09, and includes the latest features and capabilities of the three major AI APIs: Anthropic, Gemini, and OpenAI.
The comparison covers a wide range of features, including function calling, vision, system instructions, etc.

| Feature Category                         | Specific Feature              | Anthropic                                                          | Gemini                                                           | OpenAI                                                              |
|------------------------------------------|-------------------------------|--------------------------------------------------------------------|------------------------------------------------------------------|---------------------------------------------------------------------|
| **Message Structure**                    |
|                                          | Role types                    | user, assistant                                                    | user, model                                                      | user, assistant, system, tool                                       |
|                                          | Named participants            | No                                                                 | No                                                               | Yes                                                                 |
|                                          | Content array                 | Yes                                                                | Yes                                                              | Yes                                                                 |
| **Content Types and Multimodal Support** |
|                                          | Text generation               | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | Image understanding           | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | Audio processing              | No                                                                 | **Yes**                                                          | No                                                                  |
|                                          | Video processing              | No                                                                 | **Yes**                                                          | No                                                                  |
| **Image Handling**                       |
|                                          | Supported formats             | JPEG, PNG, GIF, WebP                                               | JPEG, PNG, WebP, HEIC, HEIF                                      | PNG, JPEG, WebP, non-animated GIF                                   |
|                                          | Max image size                | 5MB per image                                                      | (20MB per prompt)                                                | 20MB per image                                                      |
|                                          | Image detail level            | N/A                                                                | N/A                                                              | **Low, high, auto**                                                 |
|                                          | Image resolution              | max: 1568x1568                                                     | min: 768x768, max: 3072x3072                                     | min: 512x512, max: 2048 x 2048                                      |
|                                          | Token calculation for images  | (width * height)/750; max 1,600                                    | 258 tokens                                                       | 85 + 170 * {patches}                                                |
|                                          | Image retention               | Deleted after processing                                           | Not specified                                                    | Deleted after processing                                            |
| **Audio and Video Handling**             |
|                                          | Audio formats                 | N/A                                                                | WAV, MP3, AIFF, AAC, OGG, FLAC                                   | N/A                                                                 |
|                                          | Video formats                 | N/A                                                                | MP4, MPEG, MOV, AVI, MPG, WebM, WMV, 3GPP                        | N/A                                                                 |
| **System Instructions and Tool Use**     |
|                                          | System instructions           | Yes (array of text blocks)                                         | Yes (parts array)                                                | Yes (as system message)                                             |
| **Function/Tool Handling**               |
|                                          | Parallel tool calls           | No                                                                 | No                                                               | **Yes**                                                             |
|                                          | Tool Declaration              | Defined in `tools` array                                           | Defined in `tools` array                                         | Defined in `tools` array                                            |
|                                          | FC name restrictions          | Yes                                                                | Yes (max 63 chars)                                               | Yes (max 64 chars)                                                  |
|                                          | FC declaration                | name, description, input_schema                                    | name, description, parameters                                    | name, description, parameters                                       |
|                                          | FC options structure          | JSON Schema for input                                              | Object with properties                                           | JSON Schema for parameters                                          |
|                                          | FC Force invocation           | Via `tool_choice` parameter                                        | Via `toolConfig` parameter                                       | Via `tool_choice` parameter                                         |
|                                          | FC Model invocation           | Model generates a `tool_use` block with predicted parameters       | Generates a `functionCall` part with predicted parameters        | Generates a message.`tool_calls` item with predicted arguments      |
|                                          | FC Execution                  | Client-side                                                        | Client-side                                                      | Client-side                                                         |
|                                          | FC Result injection           | Client appends a `user` message with a `tool_result` content block | Client appends a `function` message with `functionResponse` part | Client sends a new `tool` message with `tool_call_id` and `content` |
|                                          | Built-in Code execution       | No                                                                 | **Yes**                                                          | No                                                                  |
|                                          | Tool use with vision          | Yes                                                                | Yes                                                              | Yes                                                                 |
| **Generation Configuration**             |
|                                          | temperature                   | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | max_tokens                    | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | stop_sequences                | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | top_k                         | Yes                                                                | Yes                                                              | **No**                                                              |
|                                          | top_p                         | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | seed                          | No                                                                 | No                                                               | **Yes**                                                             |
|                                          | Multiple candidates           | No                                                                 | No                                                               | Yes (with 'n' parameter, breaks streaming?)                         |
| **Streaming and Response Structure**     |
|                                          | Streaming support             | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | Streaming initiation          | stream=true                                                        | streamGenerateContent path                                       | stream=true                                                         |
|                                          | Streaming event types         | **Multiple specific types**                                        | Not specified                                                    | Single delta type                                                   |
|                                          | Response container            | content (array)                                                    | candidates (array)                                               | choices (array)                                                     |
| **Usage Metrics and Error Handling**     |
|                                          | Token counts                  | Yes                                                                | Yes                                                              | Yes                                                                 |
|                                          | Detailed token breakdown      | input, output                                                      | prompt, cached, candidates, total                                | prompt, completion, total                                           |
|                                          | Usage in stream               | No                                                                 | No                                                               | **Optional**                                                        |
|                                          | Error handling in response    | Not specified                                                      | Not specified                                                    | **Yes (undocumented)**                                              |
|                                          | Error handling in stream      | Not specified                                                      | Not specified                                                    | **Yes (undocumented)**                                              |
| **Advanced Features**                    |
|                                          | JSON mode                     | **Partial (via structured prompts)**                               | **Yes (responseMimeType)**                                       | **Yes**                                                             |
|                                          | Output consistency techniques | **Yes (multiple methods)**                                         | Not specified                                                    | Not specified                                                       |
|                                          | Logprobs                      | No                                                                 | No                                                               | **Yes (disabled in schema)**                                        |
|                                          | System fingerprint            | No                                                                 | No                                                               | **Yes**                                                             |
|                                          | Semantic caching              | No                                                                 | **Yes**                                                          | No                                                                  |
|                                          | Assistant prefill             | **Yes**                                                            | No                                                               | No                                                                  |
|                                          | Preferred formatting          | **XML tags, JSON**                                                 | Not specified                                                    | Markdown                                                            |
| **Safety and Compliance**                |
|                                          | Safety settings in request    | **Stop sequences**                                                 | **Detailed category-based**                                      | **Moderation API**                                                  |
|                                          | Safety feedback in response   | Yes                                                                | Yes                                                              | Not specified                                                       |



================================================
FILE: docs/changelog.md
================================================
## Changelog

This is a high-level changelog. Calls out some of the high level features batched
by release.

- For the live roadmap, please see [the GitHub project](https://github.com/users/enricoros/projects/4/views/2)

### 1.17.0 - Jun 2024

- milestone: [1.17.0](https://github.com/enricoros/big-agi/milestone/17)
- work in progress: [big-AGI open roadmap](https://github.com/users/enricoros/projects/4/views/2), [help here](https://github.com/users/enricoros/projects/4/views/4)

### What's New in 1.16.1...1.16.9 · Jan 21, 2025 (patch releases)

- 1.16.9: Docker Gemini fix (R1 models are supported in Big-AGI 2)
- 1.16.8: OpenAI ChatGPT-4o Latest (o1 models are supported in Big-AGI 2)
- 1.16.7: OpenAI support for GPT-4o 2024-08-06
- 1.16.6: Groq support for Llama 3.1 models
- 1.16.5: GPT-4o Mini support
- 1.16.4: 8192 tokens support for Claude 3.5 Sonnet
- 1.16.3: Anthropic Claude 3.5 Sonnet model support
- 1.16.2: Improve web downloads, as text, markdown, or HTML
- 1.16.2: Proper support for Gemini models
- 1.16.2: Added the latest Mistral model
- 1.16.2: Tokenizer support for gpt-4o
- 1.16.2: Updates to Beam
- 1.16.1: Support for the new OpenAI GPT-4o 2024-05-13 model

### What's New in 1.16.0 · May 9, 2024 · Crystal Clear

- [Beam](https://big-agi.com/blog/beam-multi-model-ai-reasoning) core and UX improvements based on user feedback
- Chat cost estimation 💰 (enable it in Labs / hover the token counter)
- Save/load chat files with Ctrl+S / Ctrl+O on desktop
- Major enhancements to the Auto-Diagrams tool
- YouTube Transcriber Persona for chatting with video content, [#500](https://github.com/enricoros/big-AGI/pull/500)
- Improved formula rendering (LaTeX), and dark-mode diagrams, [#508](https://github.com/enricoros/big-AGI/issues/508), [#520](https://github.com/enricoros/big-AGI/issues/520)
- Models update: **Anthropic**, **Groq**, **Ollama**, **OpenAI**, **OpenRouter**, **Perplexity**
- Code soft-wrap, chat text selection toolbar, 3x faster on Apple silicon, and more [#517](https://github.com/enricoros/big-AGI/issues/517), [507](https://github.com/enricoros/big-AGI/pull/507)
- Developers: update the LLMs data structures

### What's New in 1.15.1 · April 10, 2024 (minor release, models support)

- Support for the newly released Gemini Pro 1.5 models
- Support for the new OpenAI 2024-04-09 Turbo models
- Resilience fixes after the large success of 1.15.0

### What's New in 1.15.0 · April 1, 2024 · Beam

- ⚠️ [**Beam**: the multi-model AI chat](https://big-agi.com/blog/beam-multi-model-ai-reasoning). find better answers, faster - a game-changer for brainstorming, decision-making, and creativity. [#443](https://github.com/enricoros/big-AGI/issues/443)
- Managed Deployments **Auto-Configuration**: simplify the UI mdoels setup with backend-set models. [#436](https://github.com/enricoros/big-AGI/issues/436)
- Message **Starring ⭐**: star important messages within chats, to attach them later. [#476](https://github.com/enricoros/big-AGI/issues/476)
- Enhanced the default Persona
- Fixes to Gemini models and SVGs, improvements to UI and icons
- Beast release, over 430 commits, 10,000+ lines changed: [release notes](https://github.com/enricoros/big-AGI/releases/tag/v1.15.0), and changes [v1.14.1...v1.15.0](https://github.com/enricoros/big-AGI/compare/v1.14.1...v1.15.0)

### What's New in 1.14.1 · March 7, 2024 · Modelmorphic

- **Anthropic** [Claude-3](https://www.anthropic.com/news/claude-3-family) model family support. [#443](https://github.com/enricoros/big-AGI/issues/443)
- New **[Perplexity](https://www.perplexity.ai/)** and **[Groq](https://groq.com/)** integration (thanks @Penagwin). [#407](https://github.com/enricoros/big-AGI/issues/407), [#427](https://github.com/enricoros/big-AGI/issues/427)
- **[LocalAI](https://localai.io/models/)** deep integration, including support for [model galleries](https://github.com/enricoros/big-AGI/issues/411)
- **Mistral** Large and Google **Gemini 1.5** support
- Performance optimizations: runs [much faster](https://twitter.com/enricoros/status/1756553038293303434?utm_source=localhost:3000&utm_medium=big-agi), saves lots of power, reduces memory usage
- Enhanced UX with auto-sizing charts, refined search and folder functionalities, perfected scaling
- And with more UI improvements, documentation, bug fixes (20 tickets), and developer enhancements
- [Release notes](https://github.com/enricoros/big-AGI/releases/tag/v1.14.0), and changes [v1.13.1...v1.14.0](https://github.com/enricoros/big-AGI/compare/v1.13.1...v1.14.0) (233 commits, 8,000+ lines changed)

### What's New in 1.13.0 · Feb 8, 2024 · Multi + Mind

https://github.com/enricoros/big-AGI/assets/32999/01732528-730e-41dc-adc7-511385686b13

- **Side-by-Side Split Windows**: multitask with parallel conversations. [#208](https://github.com/enricoros/big-AGI/issues/208)
- **Multi-Chat Mode**: message everyone, all at once. [#388](https://github.com/enricoros/big-AGI/issues/388)
- **Export tables as CSV**: big thanks to @aj47. [#392](https://github.com/enricoros/big-AGI/pull/392)
- Adjustable text size: customize density. [#399](https://github.com/enricoros/big-AGI/issues/399)
- Dev2 Persona Technology Preview
- Better looking chats with improved spacing, fonts, and menus
- More: new video player, [LM Studio tutorial](https://github.com/enricoros/big-AGI/blob/main/docs/config-local-lmstudio.md) (thanks @aj47), [MongoDB support](https://github.com/enricoros/big-AGI/blob/main/docs/deploy-database.md) (thanks @ranfysvalle02), and speedups

### What's New in 1.12.0 · Jan 26, 2024 · AGI Hotline

https://github.com/enricoros/big-AGI/assets/32999/95ceb03c-945d-4fdd-9a9f-3317beb54f3f

- **Voice Calls**: real-time voice call your personas out of the blue or in relation to a chat [#354](https://github.com/enricoros/big-AGI/issues/354)
- Support **OpenAI 0125** Models. [#364](https://github.com/enricoros/big-AGI/issues/364)
- Rename or Auto-Rename chats.  [#222](https://github.com/enricoros/big-AGI/issues/222), [#360](https://github.com/enricoros/big-AGI/issues/360)
- More control over **Link Sharing** [#356](https://github.com/enricoros/big-AGI/issues/356)
- **Accessibility** to screen readers [#358](https://github.com/enricoros/big-AGI/issues/358)
- Export chats to Markdown [#337](https://github.com/enricoros/big-AGI/issues/337)
- Paste tables from Excel [#286](https://github.com/enricoros/big-AGI/issues/286)
- Ollama model updates and context window detection fixes [#309](https://github.com/enricoros/big-AGI/issues/309)

### What's New in 1.11.0 · Jan 16, 2024 · Singularity

https://github.com/enricoros/big-AGI/assets/1590910/a6b8e172-0726-4b03-a5e5-10cfcb110c68

- **Find chats**: search in titles and content, with frequency ranking. [#329](https://github.com/enricoros/big-AGI/issues/329)
- **Commands**: command auto-completion (type '/'). [#327](https://github.com/enricoros/big-AGI/issues/327)
- **[Together AI](https://www.together.ai/products#inference)** inference platform support (good speed and newer models). [#346](https://github.com/enricoros/big-AGI/issues/346)
- Persona Creator history, deletion, custom creation, fix llm API timeouts
- Enable adding up to five custom OpenAI-compatible endpoints
- Developer enhancements: new 'Actiles' framework

### What's New in 1.10.0 · Jan 6, 2024 · The Year of AGI

- **New UI**: for both desktop and mobile, sets the stage for future scale. [#201](https://github.com/enricoros/big-AGI/issues/201)
- **Conversation Folders**: enhanced conversation organization. [#321](https://github.com/enricoros/big-AGI/issues/321)
- **[LM Studio](https://lmstudio.ai/)** support and improved token management
- Resizable panes in split-screen conversations.
- Large performance optimizations
- Developer enhancements: new UI framework, updated documentation for proxy settings on browserless/docker

### What's New in 1.9.0 · Dec 28, 2023 · Creative Horizons

- **DALL·E 3 integration** for enhanced image generation. [#212](https://github.com/enricoros/big-AGI/issues/212)
- **Perfect scrolling mechanics** across devices. [#304](https://github.com/enricoros/big-AGI/issues/304)
- Persona creation now supports **text input**. [#287](https://github.com/enricoros/big-AGI/pull/287)
- Openrouter updates for better model management and rate limit handling
- Image drawing UX improvements
- Layout fix for Firefox users
- Developer enhancements: Text2Image subsystem, Optima layout, ScrollToBottom library, Panes library, and Llms subsystem updates.

### What's New in 1.8.0 · Dec 20, 2023 · To The Moon And Back

- **Google Gemini Support**: Use the newest Google models. [#275](https://github.com/enricoros/big-agi/issues/275)
- **Mistral Platform**: Mixtral and future models support. [#273](https://github.com/enricoros/big-agi/issues/273)
- **Diagram Instructions**. Thanks to @joriskalz! [#280](https://github.com/enricoros/big-agi/pull/280)
- Ollama Chats: Enhanced chatting experience. [#270](https://github.com/enricoros/big-agi/issues/270)
- Mac Shortcuts Fix: Improved UX on Mac
- **Single-Tab Mode**: Data integrity with single window. [#268](https://github.com/enricoros/big-agi/issues/268)
- **Updated Models**: Latest Ollama (v0.1.17) and OpenRouter models
- Official Downloads: Easy access to the latest big-AGI on [big-AGI.com](https://big-agi.com)
- For developers: [troubleshot networking](https://github.com/enricoros/big-AGI/issues/276#issuecomment-1858591483), fixed Vercel deployment, cleaned up the LLMs/Streaming framework

### What's New in 1.7.0 · Dec 11, 2023 · Attachment Theory

- **Attachments System Overhaul**: Drag, paste, link, snap, text, images, PDFs and more. [#251](https://github.com/enricoros/big-agi/issues/251)
- **Desktop Webcam Capture**: Image capture now available as Labs feature. [#253](https://github.com/enricoros/big-agi/issues/253)
- **Independent Browsing**: Full browsing support with Browserless. [Learn More](https://github.com/enricoros/big-agi/blob/main/docs/config-feature-browse.md)
- **Overheat LLMs**: Push the creativity with higher LLM temperatures. [#256](https://github.com/enricoros/big-agi/issues/256)
- **Model Options Shortcut**: Quick adjust with `Ctrl+Shift+O`
- Optimized Voice Input and Performance
- Latest Ollama models
- For developers: **Password Protection**: HTTP Basic Auth. [Learn How](https://github.com/enricoros/big-agi/blob/main/docs/deploy-authentication.md)

### What's New in 1.6.0 - Nov 28, 2023 · Surf's Up

- **Web Browsing**: Download web pages within chats - [browsing guide](https://github.com/enricoros/big-agi/blob/main/docs/config-feature-browse.md)
- **Branching Discussions**: Create new conversations from any message
- **Keyboard Navigation**: Swift chat navigation with new shortcuts (e.g. ctrl+alt+left/right)
- **Performance Boost**: Faster rendering for a smoother experience
- **UI Enhancements**: Refined interface based on user feedback
- **New Features**: Anthropic Claude 2.1, `/help` command, and Flattener tool
- **For Developers**: Code quality upgrades and snackbar notifications

### What's New in 1.5.0 - Nov 19, 2023 · Loaded

- **Continued Voice**: Engage with hands-free interaction for a seamless experience
- **Visualization Tool**: Create data representations with our new visualization capabilities
- **Ollama Local Models**: Leverage local models support with our comprehensive guide
- **Text Tools**: Enjoy tools including highlight differences to refine your content
- **Mermaid Diagramming**: Render complex diagrams with our Mermaid language support
- **OpenAI 1106 Chat Models**: Experience the cutting-edge capabilities of the latest OpenAI models
- **SDXL Support**: Enhance your image generation with SDXL support for Prodia
- **Cloudflare OpenAI API Gateway**: Integrate with Cloudflare for a robust API gateway
- **Helicone for Anthropic**: Utilize Helicone's tools for Anthropic models

For Developers:

- Runtime Server-Side configuration:  https://github.com/enricoros/big-agi/issues/189. Env vars are
  not required to be set at build time anymore. The frontend will roundtrip to the backend at the
  first request to get the configuration. See
  https://github.com/enricoros/big-agi/blob/main/src/modules/backend/backend.router.ts.
- CloudFlare developers: please change the deployment command to
  `rm app/api/cloud/[trpc]/route.ts && npx @cloudflare/next-on-pages@1`,
  as we transitioned to the App router in NextJS 14. The documentation in
  [docs/deploy-cloudflare.md](../docs/deploy-cloudflare.md) is updated

### 1.4.0: Sept/Oct: scale OUT

- **Expanded Model Support**: Azure and [OpenRouter](https://openrouter.ai/docs#models) models, including gpt-4-32k
- **Share and clone** conversations with public links
- Removed the 20 chats hard limit ([Ashesh3](https://github.com/enricoros/big-agi/pull/158))
- Latex Rendering
- Augmented Chat modes (Labs)

### July/Aug: More Better Faster

- **Camera OCR** - real-world AI - take a picture of a text, and chat with it
- **Anthropic models** support, e.g. Claude
- **Backup/Restore** - save chats, and restore them later
- **Flatten conversations** - conversations summarizer with 4 modes
- **Fork conversations** - create a new chat, to try with different endings
- New commands: /s to add a System message, and /a for an Assistant message
- New Chat modes: Write-only - just appends the message, without assistant response
- Fix STOP generation - in sync with the Vercel team to fix a long-standing NextJS issue
- Fixes on the HTML block - particularly useful to see error pages

### June: scale UP

- **[New OpenAI Models](https://openai.com/blog/function-calling-and-other-api-updates) support** - 0613 models, including 16k and 32k
- **Cleaner UI** - with rationalized Settings, Modals, and Configurators
- **Dynamic Models Configurator** - easy connection with different model vendors
- **Multiple Model Vendors Support** framework to support many LLM vendors
- **Per-model Options** (temperature, tokens, etc.) for fine-tuning AI behavior to your needs
- Support for GPT-4-32k
- Improved Dialogs and Messages
- Much Enhanced DX: TRPC integration, modularization, pluggable UI, etc

### April / May: more #big-agi-energy

- **[Google Search](../docs/pixels/feature_react_google.png)** active in ReAct - add your keys to Settings > Google
  Search
- **[Reason+Act](../docs/pixels/feature_react_turn_on.png)** preview feature - activate with 2-taps on the 'Chat' button
- **[Image Generation](../docs/pixels/feature_imagine_command.png)** using Prodia (BYO Keys) - /imagine - or menu option
- **[Voice Synthesis](../docs/pixels/feature_voice_1.png)** 📣 with ElevenLabs, including selection of custom voices
- **[Precise Token Counter](../docs/pixels/feature_token_counter.png)** 📈 extra-useful to pack the context window
- **[Install Mobile APP](../docs/pixels/feature_pwa.png)** 📲 looks like native (@harlanlewis)
- **[UI language](../docs/pixels/feature_language.png)** with auto-detect, and future app language! (@tbodyston)
- **PDF Summarization** 🧩🤯 - ask questions to a PDF! (@fredliubojin)
- **Code Execution: [Codepen](https://codepen.io/)** 💻 (@harlanlewis)
- **[SVG Drawing](../docs/pixels/feature_svg_drawing.png)** - draw with AI 🎨
- Chats: multiple chats, AI titles, Import/Export, Selection mode
- Rendering: Markdown, SVG, improved Code blocks
- Integrations: OpenAI organization ID
- [Cloudflare deployment instructions](../docs/deploy-cloudflare.md),
  [awesome-agi](https://github.com/enricoros/awesome-agi)
- [Typing Avatars](../docs/pixels/gif_typing_040123.gif) ⌨️
  <!-- p><a href="../docs/pixels/gif_typing_040123.gif"><img src="../docs/pixels/gif_typing_040123.gif" width='700' alt="New Typing Avatars"/></a></p -->

### March: first release

- **[AI Personas](../docs/pixels/feature_purpose_two.png)** - including Code, Science, Corporate, and Chat 🎭
- **Privacy**: user-owned API keys 🔑 and localStorage 🛡️
- **Context** - Attach or [Drag & Drop files](../docs/pixels/feature_drop_target.png) to add them to the prompt 📁
- **Syntax highlighting** - for multiple languages 🌈
- **Code Execution: Sandpack** -
  [now on branch]((https://github.com/enricoros/big-agi/commit/f678a0d463d5e9cf0733f577e11bd612b7902d89)) `variant-code-execution`
- Chat with GPT-4 and 3.5 Turbo 🧠💨
- Real-time streaming of AI responses ⚡
- **Voice Input** 🎙️ - works great on Chrome / Windows
- Integration: **[Paste.gg](../docs/pixels/feature_paste_gg.png)** integration for chat sharing 📥
- Integration: **[Helicone](https://www.helicone.ai/)** integration for API observability 📊
- 🌙 Dark model - Wide mode ⛶



================================================
FILE: docs/config-azure-openai.md
================================================
# Configuring Azure OpenAI Service with `big-AGI`

The entire procedure takes about 5 minutes and involves creating an Azure account,
setting up the Azure OpenAI service, deploying models, and configuring `big-AGI`
to access these models.

Please note that Azure operates on a 'pay-as-you-go' pricing model and requires
credit card information tied to a 'subscription' to the Azure service.

## Configuring `big-AGI`

If you have an `API Endpoint` and `API Key`, you can configure big-AGI as follows:

1. Launch the `big-AGI` application
2. Go to the **Models** settings
3. Add a Vendor and select **Azure OpenAI**
    - Enter the Endpoint (e.g., 'https://your-openai-api-1234.openai.azure.com/')
    - Enter the API Key (e.g., 'fd5...........................ba')

The deployed models are now available in the application. If you don't have a configured
Azure OpenAI service instance, continue with the next section.

In addition to using the UI, configuration can also be done using
[environment variables](environment-variables.md).

## Setting Up Azure

### Step 1: Azure Account & Subscription

1. Create an account on [azure.microsoft.com](https://azure.microsoft.com/en-us/)
2. Go to the [Azure Portal](https://portal.azure.com/)
3. Click on **Create a resource** in the top left corner
4. Search for **Subscription** and select **[Create Subscription](https://portal.azure.com/#create/Microsoft.Subscription)**
    - Fill in the required fields and click on **Create**
    - Note down the **Subscription ID** (e.g., `12345678-1234-1234-1234-123456789012`)

### Step 2: Apply for Azure OpenAI Service

We'll now be creating "OpenAI"-specific resources on Azure. This requires to 'apply',
and acceptance should be quick (even as low as minutes).

1. Visit [Azure OpenAI Service](https://aka.ms/azure-openai)
2. Click on **Apply for access**
    - Fill in the required fields (including the subscription ID) and click on **Apply**

Once your application is accepted, you can create OpenAI resources on Azure.

### Step 3: Create Azure OpenAI Resource

For more information, see [Azure: Create and deploy OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)

1. Click on **Create a resource** in the top left corner
2. Search for **OpenAI** and select **[Create OpenAI](https://portal.azure.com/#create/Microsoft.CognitiveServicesOpenAI)**
3. Fill in the necessary fields on the **Create OpenAI** page
   ![Creating an OpenAI service](pixels/config-azure-openai-create.png)
    - Select the subscription
    - Select a resource group or create a new one
    - Select the region. Note that the region determines the available models.
   > For instance, **Canada East** offers GPT-4-32k models, For the full list, see [GPT-4 models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
    - Name the service (e.g., `your-openai-api-1234`)
    - Select a pricing tier (e.g., `S0` for standard)
    - Select: "All networks, including the internet, can access this resource."
    - Click on **Review + create** and then **Create**

After creating the resource, you can access the API Keys and Endpoints. At any point, you can go to
the OpenAI Service instance page to get this information.

- Click on **Go to resource**
- Click on **Develop**
    - Copy the `Endpoint`, called "Language API", e.g. 'https://your-openai-api-1234.openai.azure.com/'
    - Copy `KEY 1`

### Step 4: Deploy Models

By default, Azure OpenAI resource instances don't have models available. You need to deploy the models you want to use.

1. Click on **Model Deployments > Manage Deployments**
2. Click on **+Create New Deployment**
   ![Deploying a model](pixels/config-azure-openai-deploy.png)
    - Select the model you want to deploy
    - Optionally select a version
    - name the model, e.g., `gpt4-32k-0613`

Repeat as necessary for each model you want to deploy.

## Resources

- [Azure OpenAI Service Documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/)
- [Guide: Create an Azure OpenAI Resource](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)
- [Azure OpenAI Models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)


================================================
FILE: docs/config-feature-browse.md
================================================
# Browse Functionality in big-AGI 🌐

Allows users to load web pages across various components of `big-AGI`. This feature is supported by Puppeteer-based
browsing services, which are the most common way to render web pages in a headless environment.

Once configured, the Browsing service provides the following functionality:

- ✅ **Paste a URL**: Simply paste/drag a URL into the chat, and `big-AGI` will load and attach the page (very effective)
- ✅ **Use /browse**: Type `/browse [URL]` in the chat to command `big-AGI` to load the specified web page
- ✅ **ReAct**: ReAct will automatically use the `loadURL()` function whenever a URL is encountered

It does not yet support the following functionality:

- ✖️ **Auto-browsing by LLMs**: if an LLM encounters a URL, it will NOT load the page and will likely respond
  that it cannot browse the web - No technical limitation, just haven't gotten to implement this yet outside of `/react` yet

First of all, you need to procure a Puppteer web browsing service endpoint. `big-AGI` supports services like:

| Service                                                                              | Working | Type        | Location       | Special Features                            |
|--------------------------------------------------------------------------------------|---------|-------------|----------------|---------------------------------------------|
| [BrightData Scraping Browser](https://brightdata.com/products/scraping-browser)      | Yes     | Proprietary | Cloud          | Advanced scraping tools, global IP pool     |
| [Cloudflare Browser Rendering](https://developers.cloudflare.com/browser-rendering/) | ?       | Proprietary | Cloud          | Integrated CDN, optimized browser rendering |
| ⬇️ [Browserless 2.0](#-browserless-20)                                               | Okay    | OpenSource  | Local (Docker) | Parallelism, debug viewer, advanced APIs    |
| ⬇️ [Your Chrome Browser (ALPHA)](#-your-own-chrome-browser)                          | Alpha   | Proprietary | Local (Chrome) | Personal, experimental use (ALPHA!)         |
| other Puppeteer-based WSS Services                                                   | ?       | Varied      | Cloud/Local    | Service-specific features                   |

## Configuration

1. **Procure an Endpoint**
   - Ensure that your browsing service is running (remote or local) and has a WebSocket endpoint available
   - Write down the address: `wss://${auth}@{some host}:{port}`, or ws:// for local services on your machine

2. **Configure `big-AGI`**
   - navigate to **Preferences** > **Tools** > **Browse**
   - Enter the 'wss://...' connection string provided by your browsing service

3. **Enable Features**: Choose which browse-related features you want to enable:
   - **Attach URLs**: Automatically load and attach a page when pasting a URL into the composer
   - **/browse Command**: Use the `/browse` command in the chat to load a web page
   - **ReAct**: Enable the `loadURL()` function in ReAct for advanced interactions

### 🌐 Browserless 2.0

[Browserless 2.0](https://github.com/browserless/browserless) is a Docker-based service that provides a headless
browsing experience compatible with `big-AGI`. An open-source solution that simplifies web automation tasks,
in a scalable manner.

Launch Browserless with:

```bash
docker run -p 9222:3000 browserless/chrome:latest
```

Now you can use the following connection string in `big-AGI`: `ws://127.0.0.1:9222`.
You can also browse to [http://127.0.0.1:9222](http://127.0.0.1:9222) to see the Browserless debug viewer
and configure some options.

The chat agent won't be able to access the web sites if the browserless container does not have direct Internet access. You can resolve the issue by defining internet proxy for the running container. You can then use the evironment file in the a `docker-compose.yaml

```
 browserless:
    image: browserless/chrome:latest
    env_file:
      - .env
    ports:
      - "9222:3000"  # Map host's port 9222 to container's port 3000
    environment:
      - MAX_CONCURRENT_SESSIONS=10
```

You can then add the proxy lines to your `.env` file.

```
https_proxy=http://PROXY-IP:PROXY-PORT
http_proxy=http://PROXY-IP:PROXY-PORT
```

This is how you can define it in a one liner docker
`docker run --env https_proxy=http://PROXY-IP:PROXY-PORT --env http_proxy=http://PROXY-IP:PROXY-PORT -p 9222:3000 browserless/chrome:latest `

Note: if you are using `docker-compose`, please see the
[docker/docker-compose-browserless.yaml](docker/docker-compose-browserless.yaml) file for an example
on how to run `big-AGI` and Browserless simultaneously in a single application.


### 🌐 Your own Chrome browser

***EXPERIMENTAL - UNTESTED*** - You can use your own Chrome browser as a browsing service, by configuring it to expose
a WebSocket endpoint.

- close all the Chrome instances (on Windows, check the Task Manager if still running)
- start Chrome with the following command line options (on Windows, you can edit the shortcut properties):
  - `--remote-debugging-port=9222`
- go to http://localhost:9222/json/version and copy the `webSocketDebuggerUrl` value
  - it should be something like: `ws://localhost:9222/...`
- paste the value into the Endpoint configuration (see point 2 in the configuration)

### Server-Side Configuration

You can set the Puppeteer WebSocket endpoint (`PUPPETEER_WSS_ENDPOINT`) in the deployment before running it.
This is useful for self-hosted instances or when you want to pre-configure the endpoint for all users, and will
allow your to skip points 2 and 3 above.

Always deploy your own user authentication, authorization and security solution. For this feature, the tRPC
route that provides browsing service, shall be secured with a user authentication and authorization solution,
to prevent unauthorized access to the browsing service.

## Support

If you encounter any issues or have questions about configuring the browse functionality, join our community on Discord for support and discussions.

[![Official Discord](https://discordapp.com/api/guilds/1098796266906980422/widget.png?style=banner2)](https://discord.gg/MkH4qj2Jp9)

---

Enjoy the enhanced browsing experience within `big-AGI` and explore the web without ever leaving your chat!

Last updated on Feb 27, 2024 ([edit on GitHub](https://github.com/enricoros/big-AGI/edit/main/docs/config-feature-browse.md))



================================================
FILE: docs/config-local-lmstudio.md
================================================
# Integrating LM Studio with big-AGI

Quickly set up LM Studio with big-AGI to run local and open LLMs on your computer for enhanced privacy and control over AI interactions.

## Video Tutorial

For a visual step-by-step guide, watch our [YouTube tutorial](https://www.youtube.com/watch?v=MqXzxVokMDk).

[![Running big-AGI locally with LM Studio YouTube Tutorial](http://img.youtube.com/vi/MqXzxVokMDk/0.jpg)](http://www.youtube.com/watch?v=MqXzxVokMDk "Running big-AGI locally with LM Studio")


## Quick Setup Guide

### Installing big-AGI

Clone and set up big-AGI:

```bash
git clone https://github.com/enricoros/big-agi.git && cd big-agi
npm install # Or: yarn install
npm run dev # Or: yarn dev
# If missing dependencies:
npm install @mui/material # Or: yarn add @mui/material
```

### Configuring LM Studio

Ensure LM Studio is running (default: [http://localhost:1234](http://localhost:1234)).
Check the URL and modify if different.
1. Download local models in LM Studio
2. Start the LM Studio server
3. Optionally. Check the logs

### Integration in big-AGI

1. In big-AGI, navigate to **Models** > **Add** > **LM Studio**
2. Enter the API URL: `http://localhost:1234` (modify if different)
3. Refresh by clicking on the `Models` button to load models from LM Studio

In addition to using the UI, configuration can also be done using
[environment variables](environment-variables.md).

## Troubleshooting

- **Missing @mui/material**: Execute `npm install @mui/material` or `yarn add @mui/material`
- **Connection Issues**: Check LM Studio's URL and ensure it's operational


## Further Assistance

Advanced configurations and more:

- big-AGI Community: [Discord](https://discord.gg/MkH4qj2Jp9)
- LM Studio: [LM Studio home page](https://lmstudio.ai/)



================================================
FILE: docs/config-local-localai.md
================================================
# Run your models with `LocalAI` x `big-AGI`

[LocalAI](https://localai.io) lets you run your AI models locally, or in the cloud. It supports text, image, asr, speech, and more models.

We are deepening the integration between the two products. As of the time of writing, we integrate the following features:

- ✅ [Text generation](https://localai.io/features/text-generation/) with GPTs
- ✅ [Function calling](https://localai.io/features/openai-functions/) by GPTs 🆕
- ✅ [Model Gallery](https://localai.io/models/) to list and install models
- ✖️ [Vision API](https://localai.io/features/gpt-vision/) for image chats
- ✖️ [Image generation](https://localai.io/features/image-generation) with stable diffusion
- ✖️ [Audio to Text](https://localai.io/features/audio-to-text/)
- ✖️ [Text to Audio](https://localai.io/features/text-to-audio/)
- ✖️ [Embeddings generation](https://localai.io/features/embeddings/)
- ✖️ [Constrained grammars](https://localai.io/features/constrained_grammars/) (JSON output)
- ✖️ Voice cloning 🆕

_Last updated Feb 21, 2024_

## Guide

### LocalAI installation and configuration

Follow the guide at: https://localai.io/basics/getting_started/

- verify it works by browsing to [http://localhost:8080/v1/models](http://localhost:8080/v1/models)
  (or the IP:Port of the machine, if running remotely) and seeing listed the model(s) you downloaded
  listed in the JSON response.

### Integration: chat with LocalAI

- Go to Models > Add a model source of type: **LocalAI**
- Enter the default address: `http://localhost:8080`, or the address of your localAI cloud instance
  ![configure models](pixels/config-localai-1-models.png)
  - If running remotely, replace localhost with the IP of the machine. Make sure to use the **IP:Port** format
- Load the models (click on `Models 🔄`)
- Select the model and chat

In addition to using the UI, configuration can also be done using
[environment variables](environment-variables.md).

### Integration: Models Gallery

If the running LocalAI instance is configured with a [Model Gallery](https://localai.io/models/):

- Go to Models > LocalAI
- Click on `Gallery Admin`
- Select the models to install, and view installation progress
  ![img.png](pixels/config-localai-2-gallery.png)

## Troubleshooting

##### Unknown Context Window Size

At the time of writing, LocalAI does not publish the model `context window size`.
Every model is assumed to be capable of chatting, and with a context window of 4096 tokens.
Please update the [src/modules/llms/transports/server/openai/models/models.data.ts](../src/modules/llms/server/openai/models/models.data.ts)
file with the mapping information between LocalAI model IDs and names/descriptions/tokens, etc.

# 🤝 Support

- Hop into the [LocalAI Discord](https://discord.gg/uJAeKSAGDy) for support and questions
- Hop into the [big-AGI Discord](https://discord.gg/MkH4qj2Jp9) for questions
- For big-AGI support, please open an issue in our [big-AGI issue tracker](https://bit.ly/agi-request)



================================================
FILE: docs/config-local-ollama.md
================================================
# `Ollama` x `big-AGI` :llama:

This guide helps you connect [Ollama](https://ollama.ai) [models](https://ollama.ai/library) to
[big-AGI](https://big-agi.com) for a professional AI/AGI operation and a good UI/Conversational
experience. The integration brings the popular big-AGI features to Ollama, including: voice chats,
editing tools, models switching, personas, and more.

_Last updated Dec 16, 2023_

![config-local-ollama-0-example.png](pixels/config-ollama-0-example.png)

## Quick Integration Guide

1. **Ensure Ollama API Server is Running**: Follow the official instructions to get Ollama up and running on your machine
   - For detailed instructions on setting up the Ollama API server, please refer to the
   [Ollama download page](https://ollama.ai/download) and [instructions for linux](https://github.com/jmorganca/ollama/blob/main/docs/linux.md).
2. **Add Ollama as a Model Source**: In `big-AGI`, navigate to the **Models** section, select **Add a model source**, and choose **Ollama**
3. **Enter Ollama Host URL**: Provide the Ollama Host URL where the API server is accessible (e.g., `http://localhost:11434`)
4. **Refresh Model List**: Once connected, refresh the list of available models to include the Ollama models
   > Optional: use the Ollama Admin interface to see which models are available and 'Pull' them in your local machine. Note
   that this operation will likely timeout due to Edge Functions timeout on the big-AGI server while pulling, and
   you'll have to press the 'Pull' button again, until a green message appears.
5. **Chat with Ollama models**: select an Ollama model and begin chatting with AI personas

In addition to using the UI, configuration can also be done using
[environment variables](environment-variables.md).

**Visual Configuration Guide**:

* After adding the `Ollama` model vendor, entering the IP address of an Ollama server, and refreshing models:<br/>
  <img src="pixels/config-ollama-1-models.png" alt="config-local-ollama-1-models.png" width="320">

* The `Ollama` admin panel, with the `Pull` button highlighted, after pulling the "Yi" model:<br/>
  <img src="pixels/config-ollama-2-admin-pull.png" alt="config-local-ollama-2-admin-pull.png" width="320">

* You can now switch model/persona dynamically and text/voice chat with the models:<br/>
  <img src="pixels/config-ollama-3-chat.png" alt="config-local-ollama-3-chat.png" width="320">

<br/>

### ⚠️ Network Troubleshooting

If you get errors about the server having trouble connecting with Ollama, please see
[this message](https://github.com/enricoros/big-AGI/issues/276#issuecomment-1858591483) on Issue #276.

And in brief, make sure the Ollama endpoint is accessible from the servers where you run big-AGI (which could
be localhost or cloud servers).
![Ollama Networking Chart](pixels/config-ollama-network.png)

<br/>

### Advanced: Model parameters

For users who wish to delve deeper into advanced settings, `big-AGI` offers additional configuration options, such
as the model temperature, maximum tokens, etc.

### Advanced: Ollama under a reverse proxy

You can elegantly expose your Ollama server to the internet (and thus make it easier to use from your server-side
big-AGI deployments) by exposing it on an http/https URL, such as: `https://yourdomain.com/ollama`

On Ubuntu Servers, you will need to install `nginx` and configure it to proxy requests to Ollama.

```bash
sudo apt update
sudo apt install nginx
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d yourdomain.com
```

Then, edit the nginx configuration file `/etc/nginx/sites-enabled/default` and add the following block:

```nginx
    location /ollama/ {
        proxy_pass http://127.0.0.1:11434/;

        # Disable buffering for the streaming responses (SSE)
        proxy_set_header Connection '';
        proxy_http_version 1.1;
        chunked_transfer_encoding off;
        proxy_buffering off;
        proxy_cache off;
        
        # Longer timeouts (1hr)
        keepalive_timeout 3600;
        proxy_read_timeout 3600;
        proxy_connect_timeout 3600;
        proxy_send_timeout 3600;
    }
```

Reach out to our community if you need help with this.

<br/>

### Community and Support

Join our community to share your experiences, get help, and discuss best practices:

[![Official Discord](https://discordapp.com/api/guilds/1098796266906980422/widget.png?style=banner2)](https://discord.gg/MkH4qj2Jp9)


---

`big-AGI` is committed to providing a powerful, intuitive, and privacy-respecting AI experience.
We are excited for you to explore the possibilities with Ollama models. Happy creating!



================================================
FILE: docs/config-openrouter.md
================================================
# OpenRouter Configuration

[OpenRouter](https://openrouter.ai) is a standalone, premium service
that provides access to <Link href='https://openrouter.ai/docs#models' target='_blank'>exclusive AI models</Link>
such as GPT-4 32k, Claude, and more. These models are typically not available to the public.
This document details the process of integrating OpenRouter with big-AGI.

### 1. OpenRouter Account Setup and API Key Generation

1. Register for an OpenRouter account at [openrouter.ai](https://openrouter.ai) by clicking on Sign In > Continue with Google.
2. Top up your account (minimum $5) by navigating to [openrouter.ai/account](https://openrouter.ai/account) > Add Credits > Pay with Stripe.
3. Generate an API key at [openrouter.ai/keys](https://openrouter.ai/keys) > API Key > Generate API Key.
   - **Remember to copy and securely store your API key** - the key will not be displayed again and will be in the format `sk-or-v1-...`.
   - Keep the key confidential as it can be used to expend your credits.

### 2. Integrating OpenRouter with big-AGI

1. Launch big-AGI, and navigate to the AI **Models** settings.
2. Add a Vendor, and select **OpenRouter**.
   ![feature-openrouter-add.png](pixels/feature-openrouter-add.png)
3. Input the API key into the **OpenRouter API Key** field, and load the Models.
   ![feature-openrouter-configure.png](pixels/feature-openrouter-configure.png)
4. OpenAI GPT4-32k and other models will now be accessible and selectable in the application.

In addition to using the UI, configuration can also be done using
[environment variables](environment-variables.md).

### Pricing

OpenRouter independently manages its service and pricing and is not affiliated with big-AGI.
For more detailed information, please visit [this page](https://openrouter.ai/docs#models).

Please note that running large models such as GPT-4 32k can be costly and may rapidly consume
credits - a single prompt may cost $1 or more, at the time of writing.


================================================
FILE: docs/customizations.md
================================================
# Customizing and Creating Derivative Applications

This document outlines how to develop applications derived from big-AGI.

## Manual Customization

Application customization _requires manual code modifications or the use of environment variables_. Currently, **there is no admin panel to "managed" deployment customization** for enterprise use cases.

| Required Code Alteration                                                              | Not Required                                                                                                              |
|---------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| - Persona changes<br>- UI theme customization<br>- Feature additions or modifications | - Setting API keys in [environment variables](environment-variables.md)<br>- Toggling features with environment variables |
| Apply these to the source code before building the application                        | Set these post-build on local machines or cloud deployment, before application launch                                     |

<br/>

## Code Alterations

Start by creating a fork of the [big-AGI repository](https://github.com/enricoros/big-AGI) on GitHub for a personal development space.
Understand the Architecture: big-AGI uses Next.js, React for the front end, and Node.js (Next.js edge functions) for the back end.

### Add Authentication

This necessitates a code change (file renaming) before build initiation, detailed in [deploy-authentication.md](deploy-authentication.md).

### Increase Vercel Functions Timeout

For long-running operations, Vercel allows paid deployments to increase the timeout on Functions.
Note that this applies to old-style Vercel Functions (based on Node.js) and not the new Edge Functions.

At time of writing, big-AGI has only 2 operations that run on Node.js Functions:
browsing (fetching web pages) and sharing. They both can exceed 10 seconds, especially
when fetching large pages or waiting for websites to be completed.

From the Vercel Project > Settings > General > Build & Development Settings,
you can for instance set the build command to:

```bash
next build
```

### Change the Personas (v1.x only)

Edit the `src/data.ts` file to customize personas. This file houses the default personas. You can add, remove, or modify these to meet your project's needs.

- [ ] Modify `src/data.ts` to alter default personas

### Change the UI

Adapt the UI to match your project's aesthetic, incorporate new features, or exclude unnecessary ones.

- [ ] Adjust `src/common/app.theme.ts` for theme changes: colors, spacing, button appearance, animations, etc
- [ ] Modify `src/common/app.config.tsx` to alter the application's name
- [ ] Update `src/common/app.nav.tsx` to revise the navigation bar

### Add a Message of the Day

You can display a temporary announcement banner at the top of the app using the `NEXT_PUBLIC_MOTD` environment variable.

- Set this variable in your deployment environment
- The message supports template variables:
  - `{{app_build_hash}}`: Current git commit hash
  - `{{app_build_pkgver}}`: Package version
  - `{{app_build_time}}`: Build timestamp as date
  - `{{app_deployment_type}}`: Deployment type (local, docker, vercel, etc.)
- Users can dismiss the message (until next page refresh)
- Use it for version announcements, maintenance notices, or feature highlights

Example: `NEXT_PUBLIC_MOTD=🚀 New features available in {{app_build_pkgver}}! Try the improved Beam.`

## Testing & Deployment

Test your application thoroughly using local development (refer to README.md for local build instructions). Deploy using your preferred hosting service. big-AGI supports deployment on platforms like Vercel, Docker, or any Node.js-compatible service, especially those supporting NextJS's "Edge Runtime."

- [deploy-cloudflare.md](deploy-cloudflare.md): for Cloudflare Workers deployment
- [deploy-docker.md](deploy-docker.md): for Docker deployment instructions and examples
- [deploy-k8s.md](deploy-k8s.md): for Kubernetes deployment instructions and examples

## Debugging

The application includes a client-side logging system. You can view recent logs via the UI (Settings > Tools > Logs).

For deeper debugging during development:

1. **Debug Page**: Access the `/info/debug` page for an overview of the application's environment, configuration, API status, and environment variables available to the client.
2. **Conditional Breakpoints**: To automatically pause execution in your browser's developer tools when critical errors (`error`, `critical`, `DEV` levels) are logged to the console, set the following environment variable in your local `.env.local` file and restart your development server:
   ```bash
   NEXT_PUBLIC_DEBUG_BREAKS=true
   ```
   This allows you to inspect the application state at the exact moment an important error occurs. This feature only works in development mode (`npm run dev`) and requires the environment variable to be explicitly set to `true`.

<br/>

## Community Projects - Share Your Project

After deployment, share your project with the community. We will link to your project to help others discover and learn from your work.

| Project                                                                                                                                                        | Features                                                                                                  | GitHub                                                                              |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|
| 🚀 CoolAGI: Where AI meets Imagination<br/>![CoolAGI Logo](https://github.com/nextgen-user/freegpt4plus/assets/150797204/9b0e1232-4791-4d61-b949-16f9eb284c22) | Code Interpreter, Vision, Mind maps, Web Searches, Advanced Data Analytics, Large Data Handling and more! | [nextgen-user/CoolAGI](https://github.com/nextgen-user/CoolAGI)                     |
| HL-GPT                                                                                                                                                         | Fully remodeled UI                                                                                        | [harlanlewis/nextjs-chatgpt-app](https://github.com/harlanlewis/nextjs-chatgpt-app) |

For public projects, update your README.md with your modifications and submit a pull request to add your project to our list, aiding in its discovery.

<br/>

## Best Practices

- **Stay Updated**: Frequently merge updates from the main big-AGI repository to incorporate bug fixes and new features.
- **Keep It Open Source**: Consider maintaining your derivative as open source to foster community contributions.
- **Engage with the Community**: Leverage platforms like GitHub, Discord, or Reddit for feedback, collaboration, and project promotion.

Developing a derivative application is an opportunity to explore new possibilities with AI and share your innovations with the global community. We look forward to seeing your contributions.


================================================
FILE: docs/deploy-analytics.md
================================================
# big-AGI Analytics

The open-source big-AGI project provides support for the following analytics services:

- **Google Analytics 4**: manual setup required
- **PostHog Analytics**: manual setup required
- **Vercel Analytics**: automatic when deployed to Vercel

The following is a quick overview of the Analytics options for the deployers of this open-source project.
big-AGI is deployed to many large-scale and enterprise though various ways (custom builds, Docker, Vercel, Cloudflare, etc.),
and this guide is for its customization.

## Service Configuration

### Google Analytics 4

- Why: user engagement and retention, performance insights, personalization, content optimization
- What: https://support.google.com/analytics/answer/11593727

Google Analytics 4 (GA4) is a powerful tool for understanding user behavior and engagement.
This can help optimize big-AGI, understanding which features are needed/users and which aren't.

To enable Google Analytics 4, you need to set the `NEXT_PUBLIC_GA4_MEASUREMENT_ID` environment variable
before starting the local build or the docker build (i.e. at build time), at which point the
server/container will be able to report analytics to your Google Analytics 4 property.

As of Feb 27, 2024, this feature is in development.

### PostHog Analytics

- Why: feature usage tracking, user journeys, conversion optimization, product analytics
- What: page views, page leave events, user interactions, and deployment context

PostHog provides comprehensive product analytics with privacy controls. It helps understand how users interact with big-AGI's features, identify opportunities for improvement, and optimize the user experience.

To enable PostHog, set the `NEXT_PUBLIC_POSTHOG_KEY` environment variable at build time. PostHog is configured with tracking optimization and privacy in mind:

- Uses a proxy endpoint (`/a/ph`) to avoid ad blockers
- Respects user opt-out preferences via local storage
- Tracks only essential information without PII
- Adds deployment context for better segmentation

The implementation follows PostHog's best practices for Next.js applications and includes manual page view tracking for proper single-page application support.

### Vercel Analytics

- Why: understand coarse traction, and identify deployment issues - all without tracking individual users
- What: top pages, top referrers, country of origin, operating system, browser, and page speed metrics

Vercel Analytics and Speed Insights are local API endpoints deployed to your domain, so everything stays within your
domain. Furthermore, the Vercel Analytics service is privacy-friendly, and does not track individual users.

This service is avaialble to system administrators when deploying to Vercel. It is automatically enabled when deploying to Vercel.
The code that activates Vercel Analytics is located in the `src/pages/_app.tsx` file:

```tsx
const MyApp = ({ Component, emotionCache, pageProps }: MyAppProps) => <>
  ...
  {isVercelFromFrontend && <VercelAnalytics debug={false} />}
  {isVercelFromFrontend && <VercelSpeedInsights debug={false} sampleRate={1 / 2} />}
  ...
</>;
```

When big-AGI is served on Vercel hosts, the `process.env.NEXT_PUBLIC_VERCEL_URL` environment variable is trueish, and
analytics will be sent by default to the Vercel Analytics service which is deployed by Vercel IF configured from the
Vercel project dashboard.

In summary: to turn it on: activate the `Analytics` service in the Vercel project dashboard.

## Configurations

| Scope                                                                                                                   | Default                   | Description / Instructions                                                                                                                                                  |
|-------------------------------------------------------------------------------------------------------------------------|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Your **Source** builds of big-AGI                                                                                       | None                      | **Google Analytics**: set environment variable at build time · **PostHog**: set environment variable at build time · **Vercel**: enable Vercel Analytics from the dashboard | 
| Your **Docker** builds of big-AGI                                                                                       | None                      | (**Vercel**: n/a) · **Google Analytics**: set environment variable at `docker build` time · **PostHog**: set environment variable at `docker build` time.                   |
| [get.big-agi.com](https://get.big-agi.com) (**Big-AGI 1.x**)                                                            | Vercel + Google + PostHog | The main website ([privacy policy](https://big-agi.com/privacy)) hosted for free for anyone.                                                                                |
| [prebuilt Docker packages](https://github.com/enricoros/big-AGI/pkgs/container/big-agi) (**Big-AGI 1.x**, 'latest' tag) | Google Analytics          | **Vercel**: n/a · **Google Analytics**: set to the big-agi.com Google Analytics for analytics and improvements · **PostHog**: n/a                                           |

Note: this information is updated as of March 3, 2025 and can change at any time.


================================================
FILE: docs/deploy-authentication.md
================================================
# Authentication

`big-AGI` does not come with built-in authentication. To secure your deployment, you can implement authentication
in one of the following ways:

1. Build `big-AGI` with support for ⬇️ [HTTP Authentication](#http-authentication)
2. Utilize user authentication features provided by your ⬇️ [cloud deployment platform](#cloud-deployments-authentication)
3. Develop a custom authentication solution

<br/>

### HTTP Authentication

[HTTP Basic Authentication](https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication) is a simple method
to secure your application.

To enable it in `big-AGI`, you **must manually build the application**:

- Build `big-AGI` with HTTP authentication enabled:
  - Clone the repository
  - Rename `middleware_BASIC_AUTH.ts` to `middleware.ts`
  - Build: usual simple build procedure (e.g. [Deploy manually](installation.md#Local-Production-build) or [Deploying with Docker](deploy-docker.md))

- Configure the following [environment variables](environment-variables.md) before launching `big-AGI`:
```dotenv
HTTP_BASIC_AUTH_USERNAME=<your username>
HTTP_BASIC_AUTH_PASSWORD=<your password>
```

- Start the application 🔒

<br/>

### Cloud Deployments Authentication

> This approach allows you to enable authentication without rebuilding the application by using the features
> provided by your cloud platform to manage user accounts and access.

Many cloud deployment platforms offer built-in authentication mechanisms. Refer to the platform's documentation
for setup instructions:

1. [CloudFlare Access / Zero Trust](https://www.cloudflare.com/zero-trust/products/access/)
2. [Vercel Authentication](https://vercel.com/docs/security/deployment-protection/methods-to-protect-deployments/vercel-authentication)
3. [Vercel Password Protection](https://vercel.com/docs/security/deployment-protection/methods-to-protect-deployments/password-protection)
4. Let us know when you test more solutions (Heroku, AWS IAM, Google IAP, etc.)



================================================
FILE: docs/deploy-cloudflare.md
================================================
# Deploying a Next.js App on Cloudflare Pages

> WARNING: Cloudflare Pages does not support traditional NodeJS runtimes, but only Edge Runtime functions.
>
> In this project we use Prisma connected to serverless Postgres, which at the moment cannot run on
> edge functions, so we cannot deploy this project on Cloudflare Pages.
>
> Workaround: Step 3.4. has been added below, to DELETE the NodeJS traditional runtime - which means that some
> parts of this application will not work.
>  - [Side effects](https://github.com/enricoros/big-agi/blob/main/src/apps/chat/trade/server/trade.router.ts#L19):
     > Sharing functionality to DB, and import from ChatGPT share, and post to Paste.GG will not work
>  - See [Issue 174](https://github.com/enricoros/big-agi/issues/174).
>
> Longer term: follow [prisma/prisma: Support Edge Function deployments](https://github.com/prisma/prisma/issues/21394)
> and convert the Node runtime to Edge runtime once Prisma supports it.

This guide provides steps to deploy your Next.js app on Cloudflare Pages.
It is based on the [official Cloudflare developer documentation](https://developers.cloudflare.com/pages/framework-guides/deploy-a-nextjs-site/),
with some additional steps.

## Step 1: Repository Forking

Fork the repository to your personal GitHub account.

## Step 2: Linking Cloudflare Pages to Your GitHub Account

1. Navigate to the Cloudflare Pages section and click on the `Create a project` button.
2. Click `Connect To Git` and grant Cloudflare Pages access to either all GitHub account repositories or selected repositories.
   We recommend using selected Repo access and selecting the forked repository from step 1.

## Step 3: Configuring Build and Deployments

1. After selecting the forked GitHub repository, click the **Begin Setup** button
2. On this page, set your **Project name**, **Production branch** (e.g., main), and your Build settings
3. Choose `Next.js` from the **Framework preset** dropdown menu
4. Set a custom **Build Command**:
    - `rm app/api/cloud/[trpc]/route.ts && npx @cloudflare/next-on-pages@1`
    - see the tradeoffs for this deletion on the notice at the top
5. Keep the **Build output directory** as default
6. Click the **Save and Deploy** button

## Step 4: Monitoring the Deployment Process

Observe the process as it initializes your build environment, clones the GitHub repository, builds the application, and deploys it
to the Cloudflare Network. Once complete, proceed to the project you created.

## Step 5: Required: Set the `nodejs_compat` compatibility flag

1. Navigate to the [Settings > Functions](https://dash.cloudflare.com/?to=/:account/pages/view/:pages-project/settings/functions) page of your newly created project
2. Scroll to `Compatibility flags` and enter "`nodejs_compat`" for both **Production** and **Preview** environments.
   It should look like this: ![](pixels/config-deploy-cloudflare-compat2.png)
3. Re-deploy your project for the new flags to take effect

## Step 6: (Optional) Custom Domain Configuration

Use the `Custom domains` tab to set up your domain via CNAME.

## Step 7: (Optional) Access Policy and Web Analytics Configuration

Navigate to the `Settings` page and enable the following settings:

1. Access Policy: Restrict [preview deployments](https://developers.cloudflare.com/pages/platform/preview-deployments/)
   to members of your Cloudflare account via one-time pin and restrict primary `*.YOURPROJECT.pages.dev` domain.
   Refer to [Cloudflare Pages known issues](https://developers.cloudflare.com/pages/platform/known-issues/#enabling-access-on-your-pagesdev-domain)
   for more details.
2. Enable Web Analytics.

Congratulations! You have successfully deployed your Next.js app on Cloudflare Pages.


================================================
FILE: docs/deploy-database.md
================================================
**Connecting Your Database for Enhanced Features:**

This guide outlines the database options and setup steps for enabling features like Chat Link Sharing in your application.

### Choose Your Database:

**1. Serverless Postgres (default):**

- Available on Vercel, Neon, and other platforms.
- Less feature-rich but a suitable option depending on your needs.
- **Connection String:** Replace placeholders with your Postgres credentials.
  - `postgres://USER:PASS@SOMEHOST.postgres.vercel-storage.com/SOMEDB?pgbouncer=true&connect_timeout=15`

**2. MongoDB Atlas (alternative):**

- **Highly Recommended:** More than a database, it's a data platform. MongoDB Atlas is a robust cloud-based platform that offers scalability, security, and a suite of developer tools. No need for a separate vector database, you can query your vector embeddings right within your operational database!
- **Additional Features:** MongoDB Atlas is packed with unique features designed to streamline the development process such as: Atlas App Services, Atlas search (with vector search), Atlas charts, Data Federation, and more.
- **Connection String:** Replace placeholders with your Atlas credentials.
  - `mongodb://USER:PASS@CLUSTER-NAME.mongodb.net/DATABASE-NAME?retryWrites=true&w=majority`

### Environment Variables:

#### Postgres:

| Variable                              |                                                                                                      |
|---------------------------------------|------------------------------------------------------------------------------------------------------|
| `POSTGRES_PRISMA_URL`                 | `postgres://USER:PASS@SOMEHOST.postgres.vercel-storage.com/SOMEDB?pgbouncer=true&connect_timeout=15` |
| `POSTGRES_URL_NON_POOLING` (optional) | URL for the Postgres database without pooling (specific use cases)                                   |

#### MongoDB:

| Variable  |                                                                                          |
|-----------|------------------------------------------------------------------------------------------|
| `MDB_URI` | `mongodb://USER:PASS@CLUSTER-NAME.mongodb.net/DATABASE-NAME?retryWrites=true&w=majority` |

### MongoDB Atlas + Prisma

When using MongoDB Atlas, you'll need to make the below changes to the file [`src/server/prisma/schema.prisma`](../src/server/prisma/schema.prisma).

```
...
datasource db {
  provider  = "mongodb"
  url       = env("MDB_URI")
}

//
// Storage of Linked Data
//
model LinkStorage {
  id String @id @default(uuid()) @map("_id")

// ...rest of file
```

### Initial Setup Steps:

1. **Run `npx prisma db push`:** Create or update the database schema (run once after connecting).

### Additional Resources:

- Prisma documentation: [https://www.prisma.io/docs/](https://www.prisma.io/docs/)
- MongoDB Atlas: [https://www.mongodb.com/atlas/database](https://www.mongodb.com/atlas/database)
- Atlas App Services: [https://www.mongodb.com/docs/atlas/app-services/](https://www.mongodb.com/docs/atlas/app-services/)
- Atlas vector search: [https://www.mongodb.com/products/platform/atlas-vector-search/](https://www.mongodb.com/products/platform/atlas-vector-search)
- Atlas Data Federation: [https://www.mongodb.com/products/platform/atlas-data-federation](https://www.mongodb.com/products/platform/atlas-data-federation)



================================================
FILE: docs/deploy-docker.md
================================================
# Deploying `big-AGI` with Docker

Utilize Docker containers to deploy the big-AGI application for an efficient and automated deployment process.
Docker ensures faster development cycles, easier collaboration, and seamless environment management.

## Build and run your container 🔧

1. **Clone big-AGI**
   ```bash
   git clone https://github.com/enricoros/big-agi.git
   cd big-agi
   ```
2. **Build the Docker Image**: Build a local docker image from the provided Dockerfile:
   ```bash
   docker build -t big-agi .
   ```
3. **Run the Docker Container**: start a Docker container from the newly built image,
   and expose its http port 3000 to your `localhost:3000` using:
   ```bash
   docker run -d -p 3000:3000 big-agi
   ```
4. Browse to [http://localhost:3000](http://localhost:3000)

<br/>

## Run Official Containers 📦

`big-AGI` is pre-built from source code and published as a Docker image on the GitHub Container Registry (ghcr).
The build process is transparent, and happens via GitHub Actions, as described in the
file.

### Official Images: [ghcr.io/enricoros/big-agi](https://github.com/enricoros/big-agi/pkgs/container/big-agi)

#### Run using *docker* 🚀

```bash
docker run -d -p 3000:3000 ghcr.io/enricoros/big-agi:latest
```

#### Run using *docker-compose* 🚀

If you have Docker Compose installed, you can run the Docker container with `docker-compose up`
to pull the Docker image (if it hasn't been pulled already) and start a Docker container. If you want to
update the image to the latest version, you can run `docker-compose pull` before starting the service.

```bash
docker-compose up -d
```

### Make Local Services Visible to Docker 🌐

To make local services running on your host machine accessible to a Docker container, such as a
[Browseless](./config-feature-browse.md) service or a local API, you can follow this simplified guide:

| Operating System  | Steps to Make Local Services Visible to Docker                                                                                                                                                                                                                                                                                                                                               |
|:------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Windows and macOS | Use the special DNS name `host.docker.internal` to refer to the host machine from within the Docker container. No additional network configuration is required. Access local services using `host.docker.internal:<PORT>`.                                                                                                                                                                   |
| Linux             | Two options: *A*. Use <ins>--network="host"</ins> (`docker run --network="host" -d big-agi`) when running the Docker container to merge the container within the host network stack; however, this reduces container isolation. Alternatively: *B*. Connect to local services <ins>using the host's IP address</ins> directly, as host.docker.internal is not available by default on Linux. |

<br/>

### Reverse Proxy Configuration

A reverse proxy is a server that sits in front of big-AGI's container and can forwards web
requests to it. Often used to run multiple web applications, expose them to the internet,
increase security.

If you're deploying big-AGI behind a reverse proxy, you may want to see
our [Reverse Proxy Deployment Guide](deploy-reverse-proxy.md) for more information.

<br/>

### More Information

The [`Dockerfile`](../Dockerfile) describes how to create a Docker image. It establishes a Node.js environment,
installs dependencies, and creates a production-ready version of the application as a local container.

The [`docker-compose.yaml`](../docker-compose.yaml) file is configured to run the
official image (big-agi:latest). This file is used to define the `big-agi` service, to expose
port 3000 on the host, and launch big-AGI within the container (startup command).

The [`.github/workflows/docker-image.yml`](../.github/workflows/docker-image.yml) file is used
to build the Official Docker images and publish them to the GitHub Container Registry (ghcr).
The build process is transparent and happens via GitHub Actions.

<br/>

Leverage Docker's capabilities for a reliable and efficient big-AGI deployment!


================================================
FILE: docs/deploy-k8s.md
================================================
# Deploy `big-AGI` with Kubernetes ☸️

In this tutorial, we will guide you through the process of deploying big-AGI
in a Kubernetes environment using the kubectl command-line tool.

## First Deployment

### Step 1: Clone the big-AGI repository

```bash
$ git clone https://github.com/enricoros/big-agi
$ cd ./big-agi/docs/k8s
```

### Step 2: Create the namespace

```bash
$ kubectl create namespace ns-big-agi
```

### Step 3: Fill in the key information into env-secret.yaml

All variables are optional. By default, Kubernetes Secret uses Base64 for
encode/decode, so please don't do a git commit after filling in the keys
to avoid leaking sensitive information.

We provide an empty `env-secret.yaml` file as a template.
You can fill in the necessary information using a text editor.

```bash
$ nano env-secret.yaml
```

### Step 4: Deploying Kubernetes Resources

```bash
$ kubectl apply -f big-agi-deployment.yaml -f env-secret.yaml
```

### Step 5: Verifying the Resource Statuses

```bash
$ kubectl -n ns-big-agi get svc,pod,deployment
NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
service/svc-big-agi   ClusterIP   10.0.198.118   <none>        3000/TCP   63m

NAME                                     READY   STATUS    RESTARTS   AGE
pod/deployment-big-agi-xxxxxxxx-yyyyy    1/1     Running   0          39m

NAME                              READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deployment-big-agi   1/1     1            1           63m
```

### Step 6: Testing the Service

You can test the service by port-forwarding the service to your local machine:

```bash
$ kubectl -n ns-big-agi port-forward service/svc-big-agi 3000
Forwarding from 127.0.0.1:3000 -> 3000
Forwarding from [::1]:3000 -> 3000
```

Now you can access the service at `http://localhost:3000`, and you should see the big-AGI homepage.

## Updating big-AGI

To update big-AGI to the latest version:

1. Pull the latest changes from the repository:
   ```bash
   $ git pull origin main
   ```

2. Apply the updated deployment:
   ```bash
   $ kubectl apply -f big-agi-deployment.yaml
   ```

This will trigger a rolling update of the deployment with the latest image.

**Note**: If you're deploying big-AGI behind a reverse proxy, you may need to configure
your proxy to support streaming. See our [Reverse Proxy Deployment Guide](deploy-reverse-proxy.md) for more information.

Note: For production use, consider setting up an Ingress Controller or Load Balancer instead of using port-forward.


================================================
FILE: docs/deploy-reverse-proxy.md
================================================
# Advanced: Deploying big-AGI behind a Reverse Proxy

Note: if you don't have a reverse proxy set up, you can skip this guide.

If you're deploying big-AGI behind a reverse proxy, you may want to configure your proxy to support streaming output.
This guide provides instructions on how to configure your reverse proxy to support streaming output from big-AGI.

This is for advanced deployments, and you should have a basic understanding of how reverse proxies work.

## Nginx Configuration

If you're using Nginx as your reverse proxy, add the following configuration to your server block:

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        # ...your specific proxy_pass configuration, example below...
        proxy_pass http://localhost:3000;  # Assuming big-AGI is running on port 3000
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
        # ...

        # Important: Disable buffering for the streaming responses (SSE)
        chunked_transfer_encoding on;   # Turn on chunked transfer encoding
        proxy_buffering off;            # Turn off proxy buffering
        proxy_cache off;                # Turn off caching
        tcp_nodelay on;                 # Turn on TCP NODELAY option, disable delay ACK algorithm
        tcp_nopush on;                  # Turn on TCP NOPUSH option, disable Nagle algorithm

        # Important: Longer timeouts (5 min)
        keepalive_timeout 300;
        proxy_connect_timeout 300;
        proxy_read_timeout 300;
        proxy_send_timeout 300;
    }
}
```

This configuration disables caching and buffering, enables chunked transfer encoding, and adjusts TCP settings to optimize for streaming content.

## Troubleshooting

If you're experiencing issues with streaming not working, especially when deploying behind a reverse proxy,
ensure that your proxy is configured to support streaming output as described above.

## Additional Resources

- For Docker deployments, see our [Docker Deployment Guide](deploy-docker.md)
- For Kubernetes deployments, see our [Kubernetes Deployment Guide](deploy-k8s.md)
- For general installation instructions, see our [Installation Guide](installation.md)

If you continue to experience issues, please reach out to our [community support channels](../README.md#-get-involved).



================================================
FILE: docs/draft-big-agi.md
================================================
# Why big-AGI?
Placeholder for a document that demonstrates the productivity and unique features of Big-AGI.

## Exclusive features
- [x] Call AGI
- [x] Continuous Voice mode
- [x] Diagram generation
- [ ] ...

## Productivity Features
- [x] Multi-window to never wait
- [x] Multi-Chat to explore different solutions
- [x] Rendering of graphs, charts, mindmaps
- [ ] ...


================================================
FILE: docs/environment-variables.md
================================================
# Environment Variables

This document provides an explanation of the environment variables used in the big-AGI application.

**All variables are optional**; and _UI options_ take precedence over _backend environment variables_,
which take place over _defaults_. This file is kept in sync with [`../src/server/env.ts`](../src/server/env.ts).

### Setting Environment Variables

Environment variables can be set by creating a `.env` file in the root directory of the project.

The following is an example `.env` for copy-paste convenience:

```bash
# Database (Postgres)
POSTGRES_PRISMA_URL=
POSTGRES_URL_NON_POOLING=

# Database (MongoDB)
MDB_URI=

# LLMs
OPENAI_API_KEY=
OPENAI_API_HOST=
OPENAI_API_ORG_ID=
ALIBABA_API_HOST=
ALIBABA_API_KEY=
AZURE_OPENAI_API_ENDPOINT=
AZURE_OPENAI_API_KEY=
ANTHROPIC_API_KEY=
ANTHROPIC_API_HOST=
DEEPSEEK_API_KEY=
GEMINI_API_KEY=
GROQ_API_KEY=
LOCALAI_API_HOST=
LOCALAI_API_KEY=
MISTRAL_API_KEY=
OLLAMA_API_HOST=
OPENPIPE_API_KEY=
OPENROUTER_API_KEY=
PERPLEXITY_API_KEY=
TOGETHERAI_API_KEY=
XAI_API_KEY=

# Model Observability: Helicone
HELICONE_API_KEY=

# Browse
PUPPETEER_WSS_ENDPOINT=

# Search
GOOGLE_CLOUD_API_KEY=
GOOGLE_CSE_ID=

# Text-To-Speech: ElevenLabs
ELEVENLABS_API_KEY=
ELEVENLABS_API_HOST=
ELEVENLABS_VOICE_ID=

# Backend HTTP Basic Authentication (see `deploy-authentication.md` for turning on authentication)
HTTP_BASIC_AUTH_USERNAME=
HTTP_BASIC_AUTH_PASSWORD=


# Frontend variables 
NEXT_PUBLIC_MOTD=
NEXT_PUBLIC_GA4_MEASUREMENT_ID=
NEXT_PUBLIC_POSTHOG_KEY=
NEXT_PUBLIC_PLANTUML_SERVER_URL=
```

## Backend Variables

These variables are used only by the server-side code, at runtime. Define them before running the nextjs local server (in development or
cloud deployment), or pass them to Docker (--env-file or -e) when starting the container.

### Database

To enable Chat Link Sharing, you need to connect the backend to a database. We currently support Postgres and MongoDB.

For Database configuration see [deploy-database.md](deploy-database.md).

### LLMs

The following variables when set will enable the corresponding LLMs on the server-side, without
requiring the user to enter an API key

| Variable                    | Description                                                                                                    | Required                                                          |
|-----------------------------|----------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------|
| `OPENAI_API_KEY`            | API key for OpenAI                                                                                             | Recommended                                                       |
| `OPENAI_API_HOST`           | Changes the backend host for the OpenAI vendor, to enable platforms such as Helicone and CloudFlare AI Gateway | Optional                                                          |
| `OPENAI_API_ORG_ID`         | Sets the "OpenAI-Organization" header field to support organization users                                      | Optional                                                          |
| `ALIBABA_API_HOST`          | The Alibaba AI OpenAI-compatible endpoint                                                                      | Optional                                                          |
| `ALIBABA_API_KEY`           | The API key for Alibaba AI                                                                                     | Optional                                                          |
| `AZURE_OPENAI_API_ENDPOINT` | Azure OpenAI endpoint - host only, without the path                                                            | Optional, but if set `AZURE_OPENAI_API_KEY` must also be set      |
| `AZURE_OPENAI_API_KEY`      | Azure OpenAI API key, see [config-azure-openai.md](config-azure-openai.md)                                     | Optional, but if set `AZURE_OPENAI_API_ENDPOINT` must also be set |
| `ANTHROPIC_API_KEY`         | The API key for Anthropic                                                                                      | Optional                                                          |
| `ANTHROPIC_API_HOST`        | Changes the backend host for the Anthropic vendor, to enable platforms such as AWS Bedrock                     | Optional                                                          |
| `DEEPSEEK_API_KEY`          | The API key for Deepseek AI                                                                                    | Optional                                                          |
| `GEMINI_API_KEY`            | The API key for Google AI's Gemini                                                                             | Optional                                                          |
| `GROQ_API_KEY`              | The API key for Groq Cloud                                                                                     | Optional                                                          |
| `LOCALAI_API_HOST`          | Sets the URL of the LocalAI server, or defaults to http://127.0.0.1:8080                                       | Optional                                                          |
| `LOCALAI_API_KEY`           | The (Optional) API key for LocalAI                                                                             | Optional                                                          |
| `MISTRAL_API_KEY`           | The API key for Mistral                                                                                        | Optional                                                          |
| `OLLAMA_API_HOST`           | Changes the backend host for the Ollama vendor. See [config-local-ollama.md](config-local-ollama.md)           |                                                                   |
| `OPENPIPE_API_KEY`          | The API key for OpenPipe                                                                                       | Optional                                                          |
| `OPENROUTER_API_KEY`        | The API key for OpenRouter                                                                                     | Optional                                                          |
| `PERPLEXITY_API_KEY`        | The API key for Perplexity                                                                                     | Optional                                                          |
| `TOGETHERAI_API_KEY`        | The API key for Together AI                                                                                    | Optional                                                          |
| `XAI_API_KEY`               | The API key for xAI                                                                                            | Optional                                                          |

### LLM Observability: Helicone

Helicone provides observability to your LLM calls. It is a paid service, with a generous free tier.
It is currently supported for:

- **Anthropic**: by setting the Helicone API key, Helicone is automatically activated
- **OpenAI**: you also need to set `OPENAI_API_HOST` to `oai.hconeai.com`, to enable routing

| Variable           | Description              |
|--------------------|--------------------------|
| `HELICONE_API_KEY` | The API key for Helicone |

### Features

Enable the app to Talk, Draw, and Google things up.

| Variable                   | Description                                                                                                             |
|:---------------------------|:------------------------------------------------------------------------------------------------------------------------|
| **Text-To-Speech**         | [ElevenLabs](https://elevenlabs.io/) is a high quality speech synthesis service                                         |
| `ELEVENLABS_API_KEY`       | ElevenLabs API Key - used for calls, etc.                                                                               |
| `ELEVENLABS_API_HOST`      | Custom host for ElevenLabs                                                                                              |
| `ELEVENLABS_VOICE_ID`      | Default voice ID for ElevenLabs                                                                                         |
| **Google Custom Search**   | [Google Programmable Search Engine](https://programmablesearchengine.google.com/about/)  produces links to pages        |
| `GOOGLE_CLOUD_API_KEY`     | Google Cloud API Key, used with the '/react' command - [Link to GCP](https://console.cloud.google.com/apis/credentials) |
| `GOOGLE_CSE_ID`            | Google Custom/Programmable Search Engine ID - [Link to PSE](https://programmablesearchengine.google.com/)               |
| **Browse**                 |                                                                                                                         |
| `PUPPETEER_WSS_ENDPOINT`   | Puppeteer WebSocket endpoint - used for browsing (pade downloadeing), etc.                                              |
| **Backend**                |                                                                                                                         |
| `HTTP_BASIC_AUTH_USERNAME` | See the [Authentication](deploy-authentication.md) guide. Username for HTTP Basic Authentication.                       |
| `HTTP_BASIC_AUTH_PASSWORD` | Password for HTTP Basic Authentication.                                                                                 |

### Frontend Variables

The value of these variables are passed to the frontend (Web UI) - make sure they do not contain secrets.

| Variable                          | Description                                                                                                                                                                                                                                     |
|:----------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `NEXT_PUBLIC_DEBUG_BREAKS`        | (optional, development) When set to 'true', enables automatic debugger breaks on DEV/error/critical logs in development builds                                                                                                                  |
| `NEXT_PUBLIC_MOTD`                | Message of the Day - displays a dismissible banner at the top of the app (see [customizations](customizations.md) for the template variables). Example: 🔔 Welcome to our deployment! Version {{app_build_pkgver}} built on {{app_build_time}}. |
| `NEXT_PUBLIC_GA4_MEASUREMENT_ID`  | (optional) The measurement ID for Google Analytics 4. (see [deploy-analytics](deploy-analytics.md))                                                                                                                                             |
| `NEXT_PUBLIC_POSTHOG_KEY`         | (optional) Key for PostHog analytics. (see [deploy-analytics](deploy-analytics.md))                                                                                                                                                             |
| `NEXT_PUBLIC_PLANTUML_SERVER_URL` | The URL of the PlantUML server, used for rendering UML diagrams. Allows using custom local servers.                                                                                                                                             |

> Important: these variables must be set at build time, which is required by Next.js to pass them to the frontend.
> This is in contrast to the backend variables, which can be set when starting the local server/container.

---

For a higher level overview of backend code and environment customization,
see the [big-AGI Customization](customizations.md) guide.



================================================
FILE: docs/help-advanced-tricks.md
================================================
# Big-AGI Advanced Tips & Tricks

> 🚨 This file is not meant for publication, and it's just been created as a handbook with tips
> and tricks to make Big-AGI more efficient and productive. 🚨

Welcome to the advanced tips and tricks guide for Big-AGI. This document will help you make the most of the platform's existing features.

---

## Hidden Gems

- **Shift + Double-Click** on a chat message to **edit** it.
- **Shift + Trash Icon** to **delete** a chats and messages without confirmation.
  - also applies elsewhere: delete Attachments, etc.
- **Shift + Click** on **New Chat** to create an incognito chat.
- Drag a big-AGI saved chat into Big-AGI to load (or attach) it.

## Not-so-obvious Shortcuts

- When sending a message:
  - Enter is for newlines
  - **Shift + Enter** to send the message.
  - **Ctrl + Enter** to **Beam** the message.
  - **Alt/Option + Enter** to send the message without an answer.
- When editing a message:
  - **Ctrl + Enter** to **Save** the changes.
  - **Shift + Ctrl + Enter** to **Save & Regenerate**.
- Scroll between messages:
  - **Ctrl + Up/Down** to scroll between **messages** and/or **Beams**.
  
## Worth the Effort:

- [LiveFile](help-feature-livefile.md) works on **Chrome**: Pair and synchronize your documents and code blocks with files on your local system: refresh, save, update them.

## Best User Hacks:

- 

---

Note: this document is just at the beginning. It's here so we can capture
the best tips over time.


================================================
FILE: docs/help-data-ownership.md
================================================
# Big-AGI Data Ownership Guide

Big-AGI is a **client-first** web application, which means it prioritizes speed and data ownership compared to cloud apps.
Your *API keys*, *chat history*, and *settings* live in your
browser's [local storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage), not
on cloud servers.

You can use Big-AGI in two ways:

1. Run it yourself (open-source)
2. Use big-agi.com (hosted service)

This guide explains how the open-source version handles your data. You can verify everything in [the source code](https://github.com/enricoros/big-agi).

## Client-Side Storage

Within Big-AGI almost all chat/keys data is handled client-side in your browser using two
standard browser storage mechanisms:

- **Local Storage**: API keys, settings, and configurations ([learn more](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage))
- **IndexedDB**: Chat history and larger files ([learn more](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API))

The Big-AGI backend mainly passes requests to AI services (OpenAI, Anthropic, etc.). It doesn't store your data, except for the chat-sharing function if used.

You can see your data in your browser's local storage and IndexedDB - try it yourself:

1. In Chrome: Open DevTools (press F12 on Windows, ⌘ + ⌥ + I on Mac)
2. Click 'Application' > 'Local Storage'
3. See your settings and API keys

![Browser local storage showing API keys and chat data](pixels/data_ownership_local_storage.png)

### What This Means For You

Storing data in your browser means:

- Your data stays on **one device/browser only**
- Clearing browser data **erases your chats** - make backups
- Anyone using your browser can see your chats and keys
- Running your own server needs technical skills

### Local Device Identifier

Big-AGI generates a _device identifier_ that combines timestamp and random components, stored only on your device. This identifier:

- Is used only for the **optional sync functionality** between your devices (not yet ready)
- Helps maintain data consistency when using Big-AGI across multiple devices
- Remains completely local unless you explicitly enable sync
- Is not used for tracking, analytics, or telemetry
- Can be deleted anytime by clearing local storage
- Is fully transparent - see the implementation in `src/common/stores/store-client.ts`

## How Data Flows

AI interactions in Big-AGI, such as chats, AI titles, text to speech, browsing, flow through three components:

1. **Browser** (client/installed App) - Stores your keys & data locally
2. **Backend** (routing server) - Passes requests to AI services
3. **AI Services** - Where the actual AI processing happens

### Self-Deployed Version: Your Infrastructure

You run the server. Your data only leaves when making AI requests.
The keys and chats are under your control and pass through your code, and are sent to
the upstream AI services on a per-request basis.

![data_ownership_local.png](pixels/data_ownership_deployed.png)

### Web Version: Using big-agi.com

Your data passes through the hosted Big-AGI edge network to reach AI services. The keys
and chats pass through Big-AGI's edge network to reach the AI services on a per-request basis,
and then are send to the upstream AI services.

![data_ownership_hosted.png](pixels/data_ownership_hosted.png)

## Security Best Practices

**Basic Security**:

- **Never share API keys**
- **Don't use shared computers**
- Use private browsing for one-off sessions
- Use trusted networks
- Back up your data

**When Running Your Own Server**:

- Use [environment variables](environment-variables.md) for API keys
- Run on trusted infrastructure
- Keep your installation updated

## TL;DR

Your API keys and chats stay in your browser. The server only passes requests to AI services.

Use big-agi.com for convenience, or [run it yourself](installation.md) for full control.

Need help? Join our [Discord](https://discord.gg/MkH4qj2Jp9) or open a [GitHub issue](https://github.com/enricoros/big-agi/issues).



================================================
FILE: docs/help-faq.md
================================================
# Frequently Asked Questions

Quick answers to common questions about Big-AGI. For detailed documentation, see our [Website Docs](https://big-agi.com/docs).

### Versions

<details open>
<summary><b>How do I check my Big-AGI version?</b></summary>

You can see the version in the _News_ section of the app, as per the image below.

![Version location in Big-AGI](https://github.com/user-attachments/assets/cd295094-0114-420f-a5b9-0d762e59b506)
</details>

<details open>
<summary><b>How do I verify my Vercel deployment version?</b></summary>

You can go in the **deployments** section of your Vercel project, and at a quick glance see
what is the latest deployment status, time, and link to the source code.

![Vercel deployments view](https://github.com/user-attachments/assets/664b8c3d-496e-4595-ad5e-898bdb82507c)

Each deployment links directly to its source code commit.
</details>

---

Missing something? [Open an issue](https://github.com/enricoros/big-agi/issues/new) or [join our Discord](https://discord.gg/MkH4qj2Jp9).



================================================
FILE: docs/help-feature-livefile.md
================================================
# LiveFile: Synchronize Your Documents with Local Files

## Introduction

**LiveFile** is a powerful feature in big-AGI that allows you to **pair and synchronize
your documents and code blocks** with files on your local system.

This feature enables a **two-way connection between big-AGI and your local files on disk**,
saving you time and effort.

With LiveFile, you can:

- **Pair** documents and code blocks with local files.
- **Monitor** changes in local files and update content in big-AGI.
- **Refresh** chat attachments with the latest content.
- **Save** edits made in big-AGI back to your local files.
- **Store** AI-generated code and content.

---

## Requirements

- **Supported Browsers:**
  - **Google Chrome** (desktop)
  - **Microsoft Edge** (desktop)
- **Operating Systems:**
  - **Desktop platforms only**
  - **Note:** Mobile devices (iOS and Android) are **not supported** due to browser limitations.
- **File Types:**
  - Designed for **text-based files** (e.g., `.txt`, `.md`, `.js`, `.py`).
- **Performance:**
  - Can handle **dozens of files efficiently**.
- **Limitations:**
  - **File Size Limit**: 
    - Supports text files up to **10 MB**.
  - **Pairing Persistence:**
    - LiveFile connections **do not persist across sessions**.
    - After reloading the page, you will need to re-pair your files.
  - **Saving Overwrites:**
    - Saving changes in big-AGI will **overwrite the entire file**.
    - Use external tools for version control or incremental backups.

---

## Enabling LiveFile

LiveFile can be enabled automatically or manually in your Big-AGI workflow.

### Automatic Pairing

When you:

- **Attach**, **drop**, or **paste** a file into a chat message,

LiveFile is **automatically enabled** for that attachment. This means you can start
monitoring and reloading changes without any additional setup.

### Manual Pairing

For existing attachments or code blocks that:

- **Do not have LiveFile enabled** (e.g., created on other devices),
- **Are AI-generated code snippets without an associated file**,

You can manually pair them with a local file.

#### Pairing Attachments

1. **Select the Attachment:**
  - Click on the attachment in the chat to view it in the previewer.

2. **Initiate Pairing:**
  - Click on **"Pair File"** (🔗).
  - If you have open LiveFiles, they will be listed for easy selection.
  - Alternatively, you can select a new file from your local system.

3. **Grant Permissions**
  - When prompted, allow big-AGI to access the file.

#### Pairing Code Blocks

1. **Access Code Block Options:**
  - Click on the code block to reveal the header with options.

2. **Initiate Pairing:**
  - Click the **"Pair File"** button (🔗).
  - Select from your open LiveFiles or choose a new file.

3. **Confirm Pairing:**
  - Grant permission when prompted.

---

## Using LiveFile

### Monitoring Changes

- **Automatic Monitoring:**
  - LiveFile watches for changes in your paired local files.
  - If the file is modified outside of big-AGI, you'll be shown the changes in the LiveFile bar.
  - There is also a **"Replace with File"** option to manually load the latest content and see the changes.

- **Refreshing Content:**
  - Click **"Replace with File"** (🔄) to load the latest content from the paired file into big-AGI.

### Saving Edits Back to Paired Files

- **Editing Attachments or Code Blocks:**
  - Modify the content directly within big-AGI.
  - Attachments: Click on the attachment to open the previewer and click on "Edit" to make changes.
  - Code Blocks: Select "Edit" on the chat message to update code blocks.

- **Saving Changes:**
  - Click **"Save to File"** (💾) to overwrite the local file with your changes.
  - **Note:** This action overwrites the entire file. Ensure this is what you want before proceeding.

---

## Best Practices

- **Monitor External Changes:**
  - Refresh content in big-AGI if the local file has been modified outside the application.

- **Use a Version Control System:**
  - For critical files, consider using Git or other version control systems to track and monitor changes, authorship, and history.

---

## Troubleshooting

- **LiveFile Options Not Visible:**
  - Ensure you are using a **supported desktop browser**.
  - Check that you have the latest version of big-AGI.

- **Permission Issues:**
  - Confirm that you granted big-AGI permission to access your files.
  - Check your browser's settings to ensure file access is allowed.

---

## Technical Details

LiveFile uses the [File System Access API](https://developer.mozilla.org/en-US/docs/Web/API/File_System_Access_API) to 
interact with your local files securely. It leverages the [browser-fs-access](https://github.com/GoogleChromeLabs/browser-fs-access) library, 
an open-source project by Google Chrome Labs, which provides an easy interface to the File System Access API with fallbacks for broader browser support.

- **Security:**
  - Access to files requires explicit user permission.

- **Performance:** 
  - Designed to handle dozens of files efficiently (tested on hundreds).
  - Works with the Big-AGI attachment system to recursively add directories.

- **Browser Support:**
  - Fully supported on **Google Chrome** and **Microsoft Edge** desktop versions.

---

## Another Big-AGI First!

You can significantly boost your productivity and streamline your workflow within big-AGI
by understanding how to utilize LiveFile's features fully.

This Feature is in Beta as there are a few limitations and improvements to be made. 
Join us in enjoying and enhancing this feature on [big-AGI.com](https://big-agi.com), or
[GitHub](https://github.com/enricoros/big-AGI) for support and [Discord](https://discord.gg/MkH4qj2Jp9)
to share the love.


================================================
FILE: docs/help-feature-microphone.md
================================================
# Enabling Microphone Access for Speech Recognition

This guide explains how to enable microphone access for speech recognition in various browsers and mobile devices.
Ensuring microphone access is essential for using voice features in applications like big-AGI.

## Desktop Browsers

### Google Chrome (All Platforms, recommended)

1. Open the website (e.g., big-AGI) in Chrome.
2. Click the **lock icon** in the address bar.
3. In the dropdown, find **"Microphone"**.
   - Set it to **"Allow"**.
4. If "Microphone" isn't listed:
   - Click on **"Site settings"**.
   - Find **"Microphone"** in the permissions list.
   - Change the setting to **"Allow"**.
5. **Refresh** the page.

### Safari (macOS)

**[Watch the video tutorial: How to enable Speech Recognition in Safari](https://vimeo.com/1010342201)**

If you're seeing a "Speech Recognition permission denied" error, follow these steps:

1. Open **System Settings**.
   - Go to **Privacy & Security** > **Speech Recognition**.
   - Enable Safari in the list of allowed applications.
   - Quit & Open Safari.
2. Click **Safari** in the top menu bar.
   - Select **Settings**.
   - Go to the **Websites** tab.
   - Select **Microphone** from the sidebar.
   - Find big-AGI (or localhost for developers) in the list and set it to **Allow**.
   - Close the Settings window.
3. **Refresh** the page.

This quick and simple fix should get essential voice input working in big-AGI on your Mac.

### Microsoft Edge (Windows)

1. Open the website in Edge.
2. Click the **lock icon** in the address bar.
3. Click **"Permissions for this site"**.
4. Find **"Microphone"**.
   - Set it to **"Allow"**.
5. **Refresh** the page.

### Firefox (All Platforms)

> **Note:** The Speech Recognition API is **not supported** in Firefox. If you're using Firefox, please switch to a supported browser to use speech recognition
> features.

## Mobile Devices

### Android (Chrome)

1. Open the website in Chrome.
2. Tap the **lock icon** in the address bar.
3. Tap **"Permissions"**.
4. Find **"Microphone"**.
   - Set it to **"Allow"**.
5. **Refresh** the page.

### iOS (Safari)

1. Open the **Settings** app on your device.
2. Scroll down and tap **"Safari"**.
3. Tap **"Microphone"**.
4. Ensure **"Ask"** or **"Allow"** is selected.
5. Return to Safari and open the website.
6. If prompted, allow microphone access.
7. **Refresh** the page.

### iOS (Chrome)

> **Note:** Chrome on iOS uses Safari's engine due to system limitations. Microphone permissions are managed through iOS settings.

1. Open the **Settings** app.
2. Scroll down and tap **"Chrome"**.
3. Ensure **"Microphone"** is toggled **on**.
4. Open Chrome and navigate to the website.
5. If prompted, allow microphone access.
6. **Refresh** the page.

## Troubleshooting

If you're still experiencing issues after enabling microphone access:

**Check System Permissions (macOS):**

- Open **System Settings**.
- Go to **"Privacy & Security"**.
- Select the **"Privacy"** tab.
- Click **"Microphone"** in the sidebar.
- Ensure your browser (e.g., Chrome, Safari) is checked.
- You may need to unlock the settings by clicking the lock icon at the bottom.

**Check Microphone Access (Windows):**

- Open **Settings**.
- Go to **"Privacy"** > **"Microphone"**.
- Ensure **"Allow apps to access your microphone"** is **on**.
- Scroll down and make sure your browser is allowed.

**Close Other Applications:**

- Close any applications that might be using the microphone.

**Restart the Browser:**

- Close all browser windows and reopen.

**Update Your Browser:**

- Ensure you're using the latest version.

**Check for Browser Extensions:**

- Disable extensions that might block access to the microphone.

For persistent issues, consult your browser's official support resources or contact big-AGI support.

## Technical Details

Big-AGI uses the [Web Speech API (SpeechRecognition)](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition)
to transcribe spoken words into text. This API provides real-time transcription with live previews and works on most
modern mobile and desktop browsers.

**Note on Browser Support:**

| Browser        | Support Level   | Notes                                                                  |
|----------------|-----------------|------------------------------------------------------------------------|
| Google Chrome  | ✅ Recommended   | Fully supported on desktop and Android. Preferred for best experience. |
| Safari         | ✅ Supported     | Requires macOS/iOS 14 or later.                                        |
| Microsoft Edge | ✅ Supported     | Fully supported on desktop.                                            |
| Firefox        | ❌ Not Supported | SpeechRecognition API not available.                                   |

**Recommendation:**
For the best experience with speech recognition features, we strongly recommend using Google Chrome. 
Ensure your browser is up to date to benefit from the latest features and security updates.



================================================
FILE: docs/installation.md
================================================
# Installation Guide

Welcome to the big-AGI Installation Guide - Whether you're a developer
eager to explore, a system integrator, or an enterprise looking for a
white-label solution, this comprehensive guide ensures a smooth setup
process for your own instance of big-AGI and related products.

**Try big-AGI** - You don't need to install anything if you want to play with big-AGI
and have your API keys to various model services. You can access our free instance on [big-AGI.com](https://big-agi.com).
The free instance runs the latest `main-stable` branch from this repository.

## 🧩 Build-your-own

If you want to change the code, have a deeper configuration,
add your own models, or run your own instance, follow the steps below.

### Local Development

**Prerequisites:**

- Node.js and npm installed on your machine.

**Steps:**

1. Clone the big-AGI repository:
   ```bash
   git clone https://github.com/enricoros/big-AGI.git
   cd big-AGI
   ```
2. Install dependencies:
   ```bash
   npm install
   ```
3. Run the development server:
   ```bash
   npm run dev
   ```
   Your big-AGI instance is now running at `http://localhost:3000`.

### Local Production build

The production build is optimized for performance and follows
the same steps 1 and 2 as for [local development](#local-development).

3. Build the production version:
   ```bash
   # .. repeat the steps above up to `npm install`, then:
   npm run build
   ```
4. Start the production server (`npx` may be optional):
   ```bash
   npx next start --port 3000
   ```
   Your big-AGI production instance is on `http://localhost:3000`.

### Advanced Customization

Want to pre-enable models, customize the interface, or deploy with username/password or alter code to your needs?
Check out the [Customizations Guide](README.md) for detailed instructions.

## ☁️ Cloud Deployment Options

To deploy big-AGI on a public server, you have several options. Choose the one that best fits your needs.

### Deploy on Vercel

Install big-AGI on Vercel with just a few clicks.

Create your GitHub fork, create a Vercel project over that fork, and deploy it. Or press the button below for convenience.

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fenricoros%2Fbig-AGI&env=OPENAI_API_KEY&envDescription=Backend%20API%20keys%2C%20optional%20and%20may%20be%20overridden%20by%20the%20UI.&envLink=https%3A%2F%2Fgithub.com%2Fenricoros%2Fbig-AGI%2Fblob%2Fmain%2Fdocs%2Fenvironment-variables.md&project-name=big-AGI)

### Deploy on Cloudflare

Deploy on Cloudflare's global network by installing big-AGI on
Cloudflare Pages. Check out the [Cloudflare Installation Guide](deploy-cloudflare.md)
for step-by-step instructions.

### Docker Deployments

Containerize your big-AGI installation using Docker for portability and scalability.
Our [Docker Deployment Guide](deploy-docker.md) will walk you through the process,
or follow the steps below for a quick start.

1. (optional) Build the Docker image - if you do not want to use the [pre-built Docker images](https://github.com/enricoros/big-AGI/pkgs/container/big-agi):
   ```bash
   docker build -t big-agi .
   ```
2. Run the Docker container with either:
   ```bash
   # 2A. if you built the image yourself:
   docker run -d -p 3000:3000 big-agi

   # 2B. or use the pre-built image:
   docker run -d -p 3000:3000 ghcr.io/enricoros/big-agi

   # 2C. or use docker-compose:
   docker-compose up
   ```
   Access your big-AGI instance at `http://localhost:3000`.

If you deploy big-AGI behind a reverse proxy, you may want to check out the [Reverse Proxy Configuration Guide](deploy-reverse-proxy.md).

### Kubernetes Deployment

Deploy big-AGI on a Kubernetes cluster for enhanced scalability and management. Follow these steps for a Kubernetes deployment:

1. Clone the big-AGI repository:
   ```bash
   git clone https://github.com/enricoros/big-AGI.git
   cd big-AGI
   ```

2. Configure the environment variables:
   ```bash
   cp docs/k8s/env-secret.yaml env-secret.yaml
   vim env-secret.yaml  # Edit the file to set your environment variables
   ```

3. Apply the Kubernetes configurations:
   ```bash
   kubectl create namespace ns-big-agi
   kubectl apply -f docs/k8s/big-agi-deployment.yaml -f env-secret.yaml
   ```

4. Verify the deployment:
   ```bash
   kubectl -n ns-big-agi get svc,pod,deployment
   ```

5. Access the big-AGI application:
   ```bash
   kubectl -n ns-big-agi port-forward service/svc-big-agi 3000:3000
   ```
   Your big-AGI instance is now accessible at `http://localhost:3000`.

For more detailed instructions on Kubernetes deployment, including updating and troubleshooting, refer to our [Kubernetes Deployment Guide](deploy-k8s.md).

### Midori AI Subsystem for Docker Deployment

Follow the instructions found on [Midori AI Subsystem Site](https://io.midori-ai.xyz/subsystem/manager/)
for your host OS. After completing the setup process, install the Big-AGI docker backend to the Midori AI Subsystem.

## Enterprise-Grade Installation

For businesses seeking a fully-managed, scalable solution, consider our managed installations.
Enjoy all the features of big-AGI without the hassle of infrastructure management. [hello@big-agi.com](mailto:hello@big-agi.com) to learn more.

## Support

Join our vibrant community of developers, researchers, and AI enthusiasts. Share your projects, get help, and collaborate with others.

- [Discord Community](https://discord.gg/MkH4qj2Jp9)
- [Twitter](https://twitter.com/enricoros)

For any questions or inquiries, please don't hesitate to [reach out to our team](mailto:hello@big-agi.com).



================================================
FILE: docs/use-chat-react.md
================================================
# ReAct: question answering with Reasoning and Actions

## What is ReAct?

[ReAct](https://arxiv.org/abs/2210.03629) (Reason+Act) is a classis AI question-answering feature,
that combines reasoning with actions to provide informed answers.

Within Big-AGI, users can invoke ReAct to ask complex questions that require multiple steps to answer.

| Mode  | Activation                        | Information Sources                                  | Reasoning Visibility               | When to Use                                      |
|-------|-----------------------------------|------------------------------------------------------|------------------------------------|--------------------------------------------------|
| Chat  | Just type and send                | **Pre-trained knowledge only**                       | Only shows final response          | Quick answers, general knowledge queries         |
| ReAct | Type "/react" before the question | **Web loads, Web searches, Wikipedia, calculations** | Shows step-by-step thought process | Complex, multi-step, or research-based questions |

Example of ReAct in action, taking a question about current events, googling results, opening a page, and summarizing the information:

https://github.com/user-attachments/assets/c3480428-9ab8-4257-a869-2541bf44a062

The following tools are implemented in Big-AGI:

- **browse**: loads web pages (URLs) and extracts information, using a correctly configured `Tools > Browsing` API
- **search**: searches the web to produce page URLs, using a correctly configured `Tools > Google Search` ([Google Programmable Search Engine](https://programmablesearchengine.google.com/about/)) API
- **wikipedia**: looks up information on Wikipedia pages
- **calculate**: performs mathematical calculations by executing typescript code
  - warning: (!) unsafe and dangerous, do not use for untrusted code/LLMs

## How to Use ReAct in Big-AGI

1. **Invoking ReAct**: Type "/react" followed by your question in the chat.
2. **What to Expect**:

- An ephemeral space will show the AI's thought process and actions, showing all the steps taken.
- The final answer will appear in the main chat.

3. **Available Actions**: Web searches, Wikipedia lookups, calculations, and optionally web browsing.

## Good to know:

- **ReAct operates in isolation** from the main chat history.
- It **will take longer than standard responses** due to multiple steps.
- Web searches and browsing may have privacy implications, and require **tool configuration** in the UI.
- Errors or limitations in accessing external resources may affect results.
- ReAct does not use the [Tool or Function Calling](https://platform.openai.com/docs/guides/function-calling) feature of AI models, rather uses the old school approach of parsing and executing actions.



================================================
FILE: docs/docker/docker-compose-browserless.yaml
================================================
# This file is used to run `big-AGI` and `browserless` with Docker Compose.
#
# The two containers are linked together and `big-AGI` is configured to use `browserless`
# as its Puppeteer endpoint (from the containers intranet, it is available browserless:3000).
#
# From your host, you can access big-AGI on http://127.0.0.1:3000 and browserless on http://127.0.0.1:9222.
#
# To start the containers, run:
#   docker-compose -f docs/docker/docker-compose-browserless.yaml up

version: '3.9'

services:
  big-agi:
    image: ghcr.io/enricoros/big-agi:latest
    ports:
      - "3000:3000"
    env_file:
      - .env
    environment:
      - PUPPETEER_WSS_ENDPOINT=ws://browserless:3000
    command: [ "next", "start", "-p", "3000" ]
    depends_on:
      - browserless

  browserless:
    image: browserless/chrome:latest
    ports:
      - "9222:3000"  # Map host's port 9222 to container's port 3000
    environment:
      - MAX_CONCURRENT_SESSIONS=10


================================================
FILE: docs/k8s/big-agi-deployment.yaml
================================================
---
apiVersion: v1
kind: Namespace
metadata:
  name: ns-big-agi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: big-agi
  name: deployment-big-agi
  namespace: ns-big-agi
spec:
  replicas: 1
  selector:
    matchLabels:
      app: big-agi
  strategy: {}
  template:
    metadata:
      labels:
        app: big-agi
    spec:
      containers:
        - image: ghcr.io/enricoros/big-agi:latest
          name: big-agi
          ports:
            - containerPort: 3000
          args:
            - next
            - start
            - -p
            - "3000"
          envFrom:
            - secretRef:
                name: env
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: big-agi
  name: svc-big-agi
  namespace: ns-big-agi
spec:
  ports:
    - name: "http"
      port: 3000
      targetPort: 3000
  selector:
    app: big-agi



================================================
FILE: docs/k8s/env-secret.yaml
================================================
---
apiVersion: v1
kind: Secret
metadata:
  name: env
  namespace: ns-big-agi
type: Opaque
stringData:
  # IMPORTANT: This file contains sensitive information. Do not commit changes to version control.
  # All variables are optional. Fill in only the ones you need.
  #
  # For the latest information on all the environment variables, see /docs/environment-variables.md
  #

  # LLMs
  OPENAI_API_KEY: ""
  OPENAI_API_HOST: ""
  OPENAI_API_ORG_ID: ""
  ALIBABA_API_HOST: ""
  ALIBABA_API_KEY: ""
  AZURE_OPENAI_API_ENDPOINT: ""
  AZURE_OPENAI_API_KEY: ""
  ANTHROPIC_API_KEY: ""
  ANTHROPIC_API_HOST: ""
  DEEPSEEK_API_KEY: ""
  GEMINI_API_KEY: ""
  GROQ_API_KEY: ""
  LOCALAI_API_HOST: ""
  LOCALAI_API_KEY: ""
  MISTRAL_API_KEY: ""
  OLLAMA_API_HOST: ""
  OPENPIPE_API_KEY: ""
  OPENROUTER_API_KEY: ""
  PERPLEXITY_API_KEY: ""
  TOGETHERAI_API_KEY: ""
  XAI_API_KEY: ""

  # Browse
  PUPPETEER_WSS_ENDPOINT: ""

  # Search
  GOOGLE_CLOUD_API_KEY: ""
  GOOGLE_CSE_ID: ""

  # Text-To-Speech: Eleven Labs
  ELEVENLABS_API_KEY: ""
  ELEVENLABS_API_HOST: ""
  ELEVENLABS_VOICE_ID: ""



================================================
FILE: pages/_app.tsx
================================================
import * as React from 'react';
import Head from 'next/head';
import { MyAppProps } from 'next/app';
import { Analytics as VercelAnalytics } from '@vercel/analytics/next';
import { SpeedInsights as VercelSpeedInsights } from '@vercel/speed-insights/next';

import { Brand } from '~/common/app.config';
import { apiQuery } from '~/common/util/trpc.client';

import 'katex/dist/katex.min.css';
import '~/common/styles/CodePrism.css';
import '~/common/styles/GithubMarkdown.css';
import '~/common/styles/NProgress.css';
import '~/common/styles/agi.effects.css';
import '~/common/styles/app.styles.css';

import { ErrorBoundary } from '~/common/components/ErrorBoundary';
import { Is } from '~/common/util/pwaUtils';
import { OverlaysInsert } from '~/common/layout/overlays/OverlaysInsert';
import { ProviderBackendCapabilities } from '~/common/providers/ProviderBackendCapabilities';
import { ProviderBootstrapLogic } from '~/common/providers/ProviderBootstrapLogic';
import { ProviderSingleTab } from '~/common/providers/ProviderSingleTab';
import { ProviderTheming } from '~/common/providers/ProviderTheming';
import { SnackbarInsert } from '~/common/components/snackbar/SnackbarInsert';
import { hasGoogleAnalytics, OptionalGoogleAnalytics } from '~/common/components/3rdparty/GoogleAnalytics';
import { hasPostHogAnalytics, OptionalPostHogAnalytics } from '~/common/components/3rdparty/PostHogAnalytics';


const Big_AGI_App = ({ Component, emotionCache, pageProps }: MyAppProps) => {

  // We are using a nextjs per-page layout pattern to bring the (Optima) layout creation to a shared place
  // This reduces the flicker and the time switching between apps, and seems to not have impact on
  // the build. This is a good trade-off for now.
  const getLayout = Component.getLayout ?? ((page: any) => page);

  return <>

    <Head>
      <title>{Brand.Title.Common}</title>
      <meta name='viewport' content='minimum-scale=1, initial-scale=1, width=device-width, shrink-to-fit=no' />
    </Head>

    <ProviderTheming emotionCache={emotionCache}>
      <ProviderSingleTab>
        <ProviderBackendCapabilities>
          {/* ^ Backend capabilities & SSR boundary */}
          <ErrorBoundary outer>
            <ProviderBootstrapLogic>
              <SnackbarInsert />
              {getLayout(<Component {...pageProps} />)}
              <OverlaysInsert />
            </ProviderBootstrapLogic>
          </ErrorBoundary>
        </ProviderBackendCapabilities>
      </ProviderSingleTab>
    </ProviderTheming>

    {Is.Deployment.VercelFromFrontend && <VercelAnalytics debug={false} />}
    {Is.Deployment.VercelFromFrontend && <VercelSpeedInsights debug={false} sampleRate={1 / 2} />}
    {hasGoogleAnalytics && <OptionalGoogleAnalytics />}
    {hasPostHogAnalytics && <OptionalPostHogAnalytics />}

  </>;
};

// Initializes React Query and tRPC, and enables the tRPC React Query hooks (apiQuery).
export default apiQuery.withTRPC(Big_AGI_App);


================================================
FILE: pages/_document.tsx
================================================
import * as React from 'react';
import { AppType, MyAppProps } from 'next/app';
import { default as Document, DocumentContext, DocumentProps, Head, Html, Main, NextScript } from 'next/document';
import createEmotionServer from '@emotion/server/create-instance';
import InitColorSchemeScript from '@mui/joy/InitColorSchemeScript';

import { Brand } from '~/common/app.config';
import { createEmotionCache } from '~/common/app.theme';


interface MyDocumentProps extends DocumentProps {
  emotionStyleTags: React.JSX.Element[];
}

export default function MyDocument({ emotionStyleTags }: MyDocumentProps) {
  return (
    <Html lang='en'>
      <Head>
        {/* Meta (missing Title, set by the App or Page) */}
        <meta name='description' content={Brand.Meta.Description} />
        <meta name='theme-color' content={Brand.Meta.ThemeColor} />

        {/* Favicons & PWA */}
        <link rel='shortcut icon' href='/favicon.ico' />
        <link rel='icon' type='image/png' sizes='32x32' href='/icons/favicon-32x32.png' />
        <link rel='icon' type='image/png' sizes='16x16' href='/icons/favicon-16x16.png' />
        <link rel='apple-touch-icon' sizes='180x180' href='/apple-touch-icon.png' />
        <link rel='manifest' href='/manifest.json' />
        <meta name='mobile-web-app-capable' content='yes' />
        <meta name='apple-mobile-web-app-status-bar-style' content='black' />

        {/* Opengraph */}
        <meta property='og:title' content={Brand.Title.Common} />
        <meta property='og:description' content={Brand.Meta.Description} />
        {Brand.URIs.CardImage && <meta property='og:image' content={Brand.URIs.CardImage} />}
        <meta property='og:url' content={Brand.URIs.Home} />
        <meta property='og:site_name' content={Brand.Meta.SiteName} />
        <meta property='og:type' content='website' />

        {/* Twitter */}
        <meta property='twitter:card' content='summary_large_image' />
        <meta property='twitter:url' content={Brand.URIs.Home} />
        <meta property='twitter:title' content={Brand.Title.Common} />
        <meta property='twitter:description' content={Brand.Meta.Description} />
        {Brand.URIs.CardImage && <meta property='twitter:image' content={Brand.URIs.CardImage} />}
        <meta name='twitter:site' content={Brand.Meta.TwitterSite} />
        <meta name='twitter:card' content='summary_large_image' />

        {/* Style Sheets (injected and server-side) */}
        <meta name='emotion-insertion-point' content='' />
        {emotionStyleTags}
      </Head>
      <body>
      <InitColorSchemeScript />
      <Main />
      <NextScript />
      </body>
    </Html>
  );
}

// `getInitialProps` belongs to `_document` (instead of `_app`),
// it's compatible with static-site generation (SSG).
MyDocument.getInitialProps = async (ctx: DocumentContext) => {
  // Resolution order
  //
  // On the server:
  // 1. app.getInitialProps
  // 2. page.getInitialProps
  // 3. document.getInitialProps
  // 4. app.render
  // 5. page.render
  // 6. document.render
  //
  // On the server with error:
  // 1. document.getInitialProps
  // 2. app.render
  // 3. page.render
  // 4. document.render
  //
  // On the client
  // 1. app.getInitialProps
  // 2. page.getInitialProps
  // 3. app.render
  // 4. page.render

  const originalRenderPage = ctx.renderPage;

  // You can consider sharing the same Emotion cache between all the SSR requests to speed up performance.
  // However, be aware that it can have global side effects.
  const cache = createEmotionCache();
  const { extractCriticalToChunks } = createEmotionServer(cache);

  ctx.renderPage = () =>
    originalRenderPage({
      enhanceApp: (App: React.ComponentType<React.ComponentProps<AppType> & MyAppProps>) =>
        function EnhanceApp(props) {
          return <App emotionCache={cache} {...props} />;
        },
    });

  const initialProps = await Document.getInitialProps(ctx);

  // Inject the comment before the HTML tag
  initialProps.html = `<!-- ❤ Built with Big-AGI -->\n${initialProps.html}`;

  // This is important. It prevents Emotion to render invalid HTML.
  // See https://github.com/mui/material-ui/issues/26561#issuecomment-855286153
  const emotionStyles = extractCriticalToChunks(initialProps.html);
  const emotionStyleTags = emotionStyles.styles.map((style) => (
    <style
      data-emotion={`${style.key} ${style.ids.join(' ')}`}
      key={style.key}
      // eslint-disable-next-line react/no-danger
      dangerouslySetInnerHTML={{ __html: style.css }}
    />
  ));

  return {
    ...initialProps,
    emotionStyleTags,
  };
};


================================================
FILE: pages/call.tsx
================================================
import * as React from 'react';

import { AppCall } from '../src/apps/call/AppCall';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => <AppCall />);



================================================
FILE: pages/diff.tsx
================================================
import * as React from 'react';

import { AppDiff } from '../src/apps/diff/AppDiff';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => <AppDiff />);



================================================
FILE: pages/draw.tsx
================================================
import * as React from 'react';

import { AppDraw } from '../src/apps/draw/AppDraw';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => <AppDraw />);



================================================
FILE: pages/index.tsx
================================================
import * as React from 'react';

import { AppChat } from '../src/apps/chat/AppChat';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => {

  // TODO: This Index page will point to the Dashboard (or a landing page)
  // For now it offers the chat experience, but this will change. #299

  return <AppChat />;
});



================================================
FILE: pages/news.tsx
================================================
import * as React from 'react';

import { AppNews } from '../src/apps/news/AppNews';

import { markNewsAsSeen } from '~/common/logic/store-logic-sherpa';
import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima', suspendAutoModelsSetup: true }, () => {

  // 'touch' the last seen news version
  React.useEffect(() => markNewsAsSeen(), []);

  return <AppNews />;
});


================================================
FILE: pages/personas.tsx
================================================
import * as React from 'react';

import { AppPersonas } from '../src/apps/personas/AppPersonas';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => <AppPersonas />);



================================================
FILE: pages/tokens.tsx
================================================
import * as React from 'react';

import { AppTokens } from '../src/apps/tokens/AppTokens';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => <AppTokens />);



================================================
FILE: pages/workspace.tsx
================================================
import * as React from 'react';

import { AppPlaceholder } from '../src/apps/AppPlaceholder';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => <AppPlaceholder />);



================================================
FILE: pages/dev/beam.tsx
================================================
import * as React from 'react';

import { AppBeam } from '../../src/apps/beam/AppBeam';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima' }, () => <AppBeam />);



================================================
FILE: pages/info/debug.tsx
================================================
import * as React from 'react';
import { fileSave } from 'browser-fs-access';

import { Box, Button, Card, CardContent, Typography } from '@mui/joy';
import DownloadIcon from '@mui/icons-material/Download';

import { AppPlaceholder } from '../../src/apps/AppPlaceholder';

import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';
import { getPlantUmlServerUrl } from '~/modules/blocks/code/code-renderers/RenderCodePlantUML';

import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


// basics
import { Brand } from '~/common/app.config';
import { ROUTE_APP_CHAT, ROUTE_INDEX } from '~/common/app.routes';
import { Release } from '~/common/app.release';

// capabilities access
import { useCapabilityBrowserSpeechRecognition, useCapabilityElevenLabs, useCapabilityTextToImage } from '~/common/components/useCapabilities';

// stores access
import { getLLMsDebugInfo } from '~/common/stores/llms/store-llms';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useFolderStore } from '~/common/stores/folders/store-chat-folders';
import { useLogicSherpaStore } from '~/common/logic/store-logic-sherpa';
import { useUXLabsStore } from '~/common/stores/store-ux-labs';

// utils access
import { BrowserLang, clientHostName, Is, isPwa } from '~/common/util/pwaUtils';
import { getGA4MeasurementId } from '~/common/components/3rdparty/GoogleAnalytics';
import { prettyTimestampForFilenames } from '~/common/util/timeUtils';
import { supportsClipboardRead } from '~/common/util/clipboardUtils';
import { supportsScreenCapture } from '~/common/util/screenCaptureUtils';


function DebugCard(props: { title: string, children: React.ReactNode }) {
  return (
    <Box>
      <Typography level='title-lg'>
        {props.title}
      </Typography>
      {props.children}
    </Box>
  );
}

function prettifyJsonString(jsonString: string, deleteChars: number, removeDoubleQuotes: boolean, removeTrailComma: boolean): string {
  return jsonString.split('\n').map(l => {
    if (deleteChars > 0)
      l = l.substring(deleteChars);
    if (removeDoubleQuotes)
      l = l.replaceAll('\"', '');
    if (removeTrailComma && l.endsWith(','))
      l = l.substring(0, l.length - 1);
    return l;
  }).join('\n').trim();
}

function DebugJsonCard(props: { title: string, data: any }) {
  return (
    <DebugCard title={props.title}>
      <Typography level='body-sm' sx={{ whiteSpace: 'break-spaces', fontFamily: 'code', fontSize: { xs: 'xs' } }}>
        {prettifyJsonString(JSON.stringify(props.data, null, 2), 2, true, true)}
      </Typography>
    </DebugCard>
  );
}


const frontendBuild = Release.buildInfo('frontend');

function AppDebug() {

  // state
  const [saved, setSaved] = React.useState(false);

  // external state
  const backendCaps = getBackendCapabilities();
  const chatsCount = useChatStore.getState().conversations?.length;
  const uxLabsExperiments = Object.entries(useUXLabsStore.getState()).filter(([_k, v]) => v === true).map(([k, _]) => k).join(', ');
  const { folders, enableFolders } = useFolderStore.getState();
  const { lastSeenNewsVersion, usageCount } = useLogicSherpaStore.getState();

  // derived state
  const cClient = {
    // isBrowser,
    Is,
    BrowserLang,
    isPWA: isPwa(),
    supportsClipboardPaste: supportsClipboardRead(),
    supportsScreenCapture,
  };
  const cProduct = {
    capabilities: {
      mic: useCapabilityBrowserSpeechRecognition(),
      elevenLabs: useCapabilityElevenLabs(),
      textToImage: useCapabilityTextToImage(),
    },
    models: getLLMsDebugInfo(),
    state: {
      chatsCount,
      foldersCount: folders?.length,
      foldersEnabled: enableFolders,
      newsCurrent: Release.Monotonics.NewsVersion,
      newsSeen: lastSeenNewsVersion,
      labsActive: uxLabsExperiments,
      reloads: usageCount,
    },
    release: {
      app: Release.App,
      build: frontendBuild,
    },
  };
  const cBackend = {
    configuration: backendCaps,
    deployment: {
      home: Brand.URIs.Home,
      hostName: clientHostName(),
      measurementId: getGA4MeasurementId(),
      plantUmlServerUrl: getPlantUmlServerUrl(),
      routeIndex: ROUTE_INDEX,
      routeChat: ROUTE_APP_CHAT,
    },
  };

  const handleDownload = async () => {
    fileSave(
      new Blob([JSON.stringify({ client: cClient, agi: cProduct, backend: cBackend }, null, 2)], { type: 'application/json' }),
      { fileName: `big-agi_debug_${prettyTimestampForFilenames()}.json`, extensions: ['.json'] },
    )
      .then(() => setSaved(true))
      .catch(e => console.error('Error saving debug.json', e));
  };

  return (
    <AppPlaceholder title={`${Brand.Title.Common} Debug`}>
      <Box sx={{ display: 'grid', gap: 3, my: 3 }}>
        <Button
          variant={saved ? 'soft' : 'outlined'} color={saved ? 'success' : 'neutral'}
          onClick={handleDownload}
          endDecorator={<DownloadIcon />}
          sx={{
            backgroundColor: saved ? undefined : 'background.surface',
            boxShadow: 'sm',
            placeSelf: 'start',
            minWidth: 260,
          }}
        >
          Download debug JSON
        </Button>
        <Card>
          <CardContent sx={{ display: 'grid', gap: 3 }}>
            <DebugJsonCard title='Client' data={cClient} />
            <DebugJsonCard title='AGI' data={cProduct} />
            <DebugJsonCard title='Backend' data={cBackend} />
          </CardContent>
        </Card>
      </Box>
    </AppPlaceholder>
  );
}


export default withNextJSPerPageLayout({ type: 'container' }, () => <AppDebug />);



================================================
FILE: pages/link/callback_openrouter.tsx
================================================
import * as React from 'react';

import { Box, Typography } from '@mui/joy';

import { llmsStoreActions } from '~/common/stores/llms/store-llms';

import { InlineError } from '~/common/components/InlineError';
import { apiQuery } from '~/common/util/trpc.client';
import { navigateToIndex, useRouterQuery } from '~/common/app.routes';
import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


function CallbackOpenRouterPage(props: { openRouterCode: string | undefined }) {

  // external state
  const { data, isError, error, isPending } = apiQuery.backend.exchangeOpenRouterKey.useQuery({ code: props.openRouterCode || '' }, {
    enabled: !!props.openRouterCode,
    staleTime: Infinity,
  });

  // derived state
  const isErrorInput = !props.openRouterCode;
  const openRouterKey = data?.key ?? undefined;
  const isSuccess = !!openRouterKey;


  // Success: save the key and redirect to the chat app
  React.useEffect(() => {
    if (!isSuccess)
      return;

    // 1. Save the key as the client key
    llmsStoreActions().setOpenRouterKey(openRouterKey);

    // 2. Navigate to the chat app
    void navigateToIndex(true); //.then(openModelsSetup);

  }, [isSuccess, openRouterKey]);

  return (
    <Box sx={{
      flexGrow: 1,
      overflowY: 'auto',
      display: 'flex', justifyContent: 'center',
      p: { xs: 3, md: 6 },
    }}>

      <Box sx={{
        // my: 'auto',
        display: 'flex', flexDirection: 'column', alignItems: 'center',
        gap: 4,
      }}>

        <Typography level='title-lg'>
          Welcome Back
        </Typography>

        {isPending && <Typography level='body-sm'>Loading...</Typography>}

        {isErrorInput && <InlineError error='There was an issue retrieving the code from OpenRouter.' />}

        {isError && <InlineError error={error} />}

        {data && (
          <Typography level='body-md'>
            Success! You can now close this window.
          </Typography>
        )}

      </Box>

    </Box>
  );
}


/**
 * This page will be invoked by OpenRouter as a Callback
 *
 * Docs: https://openrouter.ai/docs#oauth
 * Example URL: https://localhost:3000/link/callback_openrouter?code=SomeCode
 */
export default withNextJSPerPageLayout({ type: 'container' }, () => {

  // external state - get the 'code=...' from the URL
  const { code } = useRouterQuery<{ code: string | undefined }>();

  return <CallbackOpenRouterPage openRouterCode={code} />;

});



================================================
FILE: pages/link/share_target.tsx
================================================
import * as React from 'react';

import { Alert, Box, Button, Typography } from '@mui/joy';
import ArrowBackIcon from '@mui/icons-material/ArrowBack';

import { setComposerStartupText } from '~/common/logic/store-logic-sherpa';

import { callBrowseFetchPageOrThrow } from '~/modules/browse/browse.client';

import { LogoProgress } from '~/common/components/LogoProgress';
import { asValidURL } from '~/common/util/urlUtils';
import { navigateToIndex, useRouterQuery } from '~/common/app.routes';
import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


/**
 * This page will be invoked on mobile when sharing Text/URLs/Files from other APPs
 * See the /public/manifest.json for how this is configured. Parameters:
 *  - text: the text to share
 *  - url: the URL to share
 *   - if the URL is a valid URL, it will be downloaded and the content will be shared
 *   - if the URL is not a valid URL, it will be shared as text
 *  - title: the title of the shared content
 */
function AppShareTarget() {
  // state
  const [errorMessage, setErrorMessage] = React.useState<string | null>(null);
  const [intentText, setIntentText] = React.useState<string | null>(null);
  const [intentURL, setIntentURL] = React.useState<string | null>(null);
  const [isDownloading, setIsDownloading] = React.useState(false);

  // external state
  const { url: queryUrl, text: queryText } = useRouterQuery<{
    url: string | string[] | undefined,
    text: string | string[] | undefined,
  }>();

  const queueComposerTextAndLaunchApp = React.useCallback((text: string) => {
    setComposerStartupText(text);
    void navigateToIndex(true);
  }, []);


  // Detect the share Intent from the query
  React.useEffect(() => {
    // skip when query is not parsed yet
    let queryTextItem = queryUrl || queryText || null;
    if (!queryTextItem)
      return;

    // single item from the query
    if (Array.isArray(queryTextItem))
      queryTextItem = queryTextItem[0];

    // check if the item is a URL
    const url = asValidURL(queryTextItem);
    if (url)
      setIntentURL(url);
    else if (queryTextItem)
      setIntentText(queryTextItem);
    else
      setErrorMessage('No text or url. Received: ' + JSON.stringify({ queryText, queryUrl }));

  }, [queryText, queryUrl]);


  // Text -> Composer
  React.useEffect(() => {
    if (intentText)
      queueComposerTextAndLaunchApp(intentText);
  }, [intentText, queueComposerTextAndLaunchApp]);


  // URL -> download -> Composer
  React.useEffect(() => {
    if (intentURL) {
      setIsDownloading(true);
      callBrowseFetchPageOrThrow(intentURL)
        .then(page => {
          if (page.stopReason !== 'error') {
            if (!page.content) {
              setErrorMessage(page.file ? 'No web page found, and we do not support files at the moment.' : 'No content found');
              return;
            }
            let pageContent = page.content.markdown || page.content.text || page.content.html || '';
            if (pageContent)
              pageContent = '\n\n```' + intentURL + '\n' + pageContent + '\n```\n';
            queueComposerTextAndLaunchApp(pageContent);
          } else
            setErrorMessage('Could not read any data' + page.error ? ': ' + page.error : '');
        })
        .catch(error => setErrorMessage(error?.message || error || 'Unknown error'))
        .finally(() => setIsDownloading(false));
    }
  }, [intentURL, queueComposerTextAndLaunchApp]);


  return (

    <Box sx={{
      display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center',
      flexGrow: 1,
    }}>

      {/* Logo with Circular Progress  */}
      <LogoProgress showProgress={isDownloading} />

      {/* Title */}
      <Typography level='title-lg' sx={{ mt: 2, mb: 1 }}>
        {isDownloading ? 'Loading...' : errorMessage ? '' : intentURL ? 'Done' : 'Receiving...'}
      </Typography>

      {/* Possible Error */}
      {errorMessage && <>
        <Alert variant='soft' color='danger' sx={{ my: 1 }}>
          <Typography>{errorMessage}</Typography>
        </Alert>
        <Button
          variant='solid' color='danger'
          onClick={() => navigateToIndex()}
          endDecorator={<ArrowBackIcon />}
          sx={{ mt: 2 }}
        >
          Cancel
        </Button>
      </>}

      {/* URL under analysis */}
      <Typography level='body-xs'>
        {intentURL}
      </Typography>
    </Box>

  );

}

/**
 * This page will be invoked on mobile when sharing Text/URLs/Files from other APPs
 * Example URL: https://localhost:3000/link/share_target?title=This+Title&text=https%3A%2F%2Fexample.com%2Fapp%2Fpath
 */
export default withNextJSPerPageLayout({ type: 'container' }, () => <AppShareTarget />);



================================================
FILE: pages/link/chat/[chatLinkId].tsx
================================================
import * as React from 'react';

import { AppLinkChat } from '../../../src/apps/link-chat/AppLinkChat';

import { useRouterQuery } from '~/common/app.routes';
import { withNextJSPerPageLayout } from '~/common/layout/withLayout';


export default withNextJSPerPageLayout({ type: 'optima', suspendAutoModelsSetup: true }, () => {

  // external state
  const { chatLinkId } = useRouterQuery<{ chatLinkId: string | undefined }>();

  return <AppLinkChat chatLinkId={chatLinkId || null} />;

});


================================================
FILE: public/manifest.json
================================================
{
  "name": "big-AGI",
  "short_name": "big-AGI",
  "theme_color": "#32383E",
  "background_color": "#9FA6AD",
  "description": "Your Generative AI Suite",
  "categories": [
    "productivity",
    "AI",
    "tool",
    "utilities"
  ],
  "display": "standalone",
  "start_url": "/?source=pwa",
  "scope": "/",
  "icons": [
    {
      "src": "/icons/icon-1024x1024.png",
      "sizes": "1024x1024",
      "type": "image/png",
      "purpose": "any maskable"
    },
    {
      "src": "/icons/icon-512x512.png",
      "sizes": "512x512",
      "type": "image/png",
      "purpose": "any"
    },
    {
      "src": "/icons/icon-192x192.png",
      "sizes": "192x192",
      "type": "image/png",
      "purpose": "any"
    }
  ],
  "file_handlers": [
    {
      "action": "/link/share_target",
      "accept": {
        "application/big-agi": [
          ".agi",
          ".agi.json"
        ]
      }
    }
  ],
  "share_target": {
    "action": "/link/share_target",
    "method": "GET",
    "enctype": "application/x-www-form-urlencoded",
    "params": {
      "title": "title",
      "text": "text",
      "url": "url"
    }
  },
  "shortcuts": [
    {
      "name": "Call",
      "url": "/call",
      "description": "Call a Persona",
      "icons": [
        {
          "src": "/icons/icon-call-96x96.png",
          "sizes": "96x96",
          "type": "image/png"
        }
      ]
    },
    {
      "name": "New Voice Chat",
      "url": "/?newChat=voiceInput",
      "description": "Start a new chat with voice input",
      "icons": [
        {
          "src": "/icons/icon-voicechat-96x96.png",
          "sizes": "96x96",
          "type": "image/png"
        }
      ]
    }
  ]
}



================================================
FILE: public/images/personas/dev_preview_icon_120x120.webp
================================================
[Binary file]


================================================
FILE: src/data.ts
================================================
import * as React from 'react';

export type SystemPurposeId = 'Catalyst' | 'Custom' | 'Designer' | 'Developer' | 'DeveloperPreview' | 'Executive' | 'Generic' | 'Scientist' | 'YouTubeTranscriber';

export const defaultSystemPurposeId: SystemPurposeId = 'Generic';

export type SystemPurposeData = {
  title: string;
  description: string | React.JSX.Element;
  systemMessage: string;
  systemMessageNotes?: string;
  symbol: string;
  imageUri?: string;
  examples?: SystemPurposeExample[];
  highlighted?: boolean;
  call?: { starters?: string[] };
  voices?: { elevenLabs?: { voiceId: string } };
};

export type SystemPurposeExample = string | { prompt: string, action?: 'require-data-attachment' };

export const SystemPurposes: { [key in SystemPurposeId]: SystemPurposeData } = {
  Generic: {
    title: 'Default',
    description: 'Start here',
    systemMessage: `You are an AI assistant.
Knowledge cutoff: {{LLM.Cutoff}}
Current date: {{LocaleNow}}

{{RenderMermaid}}
{{RenderPlantUML}}
{{RenderSVG}}
{{PreferTables}}
`,
    symbol: '🧠',
    examples: ['help me plan a trip to Japan', 'what is the meaning of life?', 'how do I get a job at OpenAI?', 'what are some healthy meal ideas?'],
    call: { starters: ['Hey, how can I assist?', 'AI assistant ready. What do you need?', 'Ready to assist.', 'Hello.'] },
    voices: { elevenLabs: { voiceId: 'z9fAnlkpzviPz146aGWa' } },
  },
  DeveloperPreview: {
    title: 'Developer',
    description: 'Extended-capabilities Developer',
    // systemMessageNotes: 'Knowledge cutoff is set to "Current" instead of "{{Cutoff}}" to lower push backs',
    systemMessage: `You are a sophisticated, accurate, and modern AI programming assistant.
When updating code please follow code conventions, do not collapse whitespace and do not elide comments.
Knowledge cutoff: {{LLM.Cutoff}}
Current date: {{LocaleNow}}

{{RenderPlantUML}}
{{RenderMermaid}}
{{RenderSVG}}
{{PreferTables}}
`, // {{InputImage0}} {{ToolBrowser0}}
    symbol: '👨‍💻',
    imageUri: '/images/personas/dev_preview_icon_120x120.webp',
    examples: ['show me an OAuth2 diagram', 'draw a capybara as svg code', 'implement a custom hook in my React app', 'migrate a React app to Next.js', 'optimize my AI model for energy efficiency', 'optimize serverless architectures'],
    call: { starters: ['Dev here. Got code?', 'Developer on call. What\'s the issue?', 'Ready to code.', 'Hello.'] },
    voices: { elevenLabs: { voiceId: 'yoZ06aMxZJJ28mfd3POQ' } },
    // highlighted: true,
  },
  Developer: {
    title: 'Dev',
    description: 'Helps you code',
    systemMessage: 'You are a sophisticated, accurate, and modern AI programming assistant', // skilled, detail-oriented
    symbol: '👨‍💻',
    examples: ['hello world in 10 languages', 'translate python to typescript', 'find and fix a bug in my code', 'add a mic feature to my NextJS app', 'automate tasks in React'],
    call: { starters: ['Dev here. Got code?', 'Developer on call. What\'s the issue?', 'Ready to code.', 'Hello.'] },
    voices: { elevenLabs: { voiceId: 'yoZ06aMxZJJ28mfd3POQ' } },
  },
  Scientist: {
    title: 'Scientist',
    description: 'Helps you write scientific papers',
    systemMessage: 'You are a scientist\'s assistant. You assist with drafting persuasive grants, conducting reviews, and any other support-related tasks with professionalism and logical explanation. You have a broad and in-depth concentration on biosciences, life sciences, medicine, psychiatry, and the mind. Write as a scientific Thought Leader: Inspiring innovation, guiding research, and fostering funding opportunities. Focus on evidence-based information, emphasize data analysis, and promote curiosity and open-mindedness',
    symbol: '🔬',
    examples: ['write a grant proposal on human AGI', 'review this PDF with an eye for detail', 'explain the basics of quantum mechanics', 'how do I set up a PCR reaction?', 'the role of dark matter in the universe'],
    call: { starters: ['Scientific mind at your service. What\'s the question?', 'Scientist here. What\'s the query?', 'Ready for science talk.', 'Yes?'] },
    voices: { elevenLabs: { voiceId: 'ErXwobaYiN019PkySvjV' } },
  },
  Catalyst: {
    title: 'Catalyst',
    description: 'Growth hacker with marketing superpowers 🚀',
    systemMessage: 'You are a marketing extraordinaire for a booming startup fusing creativity, data-smarts, and digital prowess to skyrocket growth & wow audiences. So fun. Much meme. 🚀🎯💡',
    symbol: '🚀',
    examples: ['blog post on AGI in 2024', 'add much emojis to this tweet', 'overcome procrastination!', 'how can I improve my communication skills?'],
    call: { starters: ['Ready to skyrocket. What\'s up?', 'Growth hacker on line. What\'s the plan?', 'Marketing whiz ready.', 'Hey.'] },
    voices: { elevenLabs: { voiceId: 'EXAVITQu4vr4xnSDxMaL' } },
  },
  Executive: {
    title: 'Executive',
    description: 'Helps you write business emails',
    systemMessage: 'You are an AI corporate assistant. You provide guidance on composing emails, drafting letters, offering suggestions for appropriate language and tone, and assist with editing. You are concise. ' +
      'You explain your process step-by-step and concisely. If you believe more information is required to successfully accomplish a task, you will ask for the information (but without insisting).\n' +
      'Knowledge cutoff: {{LLM.Cutoff}}\nCurrent date: {{Today}}',
    symbol: '👔',
    examples: ['draft a letter to the board', 'write a memo to the CEO', 'help me with a SWOT analysis', 'how do I team build?', 'improve decision-making'],
    call: { starters: ['Let\'s get to business.', 'Corporate assistant here. What\'s the task?', 'Ready for business.', 'Hello.'] },
    voices: { elevenLabs: { voiceId: '21m00Tcm4TlvDq8ikWAM' } },
  },
  Designer: {
    title: 'Designer',
    description: 'Helps you design',
    systemMessage: `
You are an AI visual design assistant. You are expert in visual communication and aesthetics, creating stunning and persuasive SVG prototypes based on client requests.
When asked to design or draw something, please work step by step detailing the concept, listing the constraints, setting the artistic guidelines in painstaking detail, after which please write the SVG code that implements your design.
{{RenderSVG}}`.trim(),
    symbol: '🖌️',
    examples: ['minimalist logo for a tech startup', 'infographic on climate change', 'suggest color schemes for a website'],
    call: { starters: ['Hey! What\'s the vision?', 'Designer on call. What\'s the project?', 'Ready for design talk.', 'Hey.'] },
    voices: { elevenLabs: { voiceId: 'MF3mGyEYCl7XYWbV9V6O' } },
  },
  YouTubeTranscriber: {
    title: 'YouTube Transcriber',
    description: 'Enter a YouTube URL to get the transcript and chat about the content.',
    systemMessage: 'You are an expert in understanding video transcripts and answering questions about video content.',
    symbol: '📺',
    examples: ['Analyze the sentiment of this video', 'Summarize the key points of the lecture'],
    call: { starters: ['Enter a YouTube URL to begin.', 'Ready to transcribe YouTube content.', 'Paste the YouTube link here.'] },
    voices: { elevenLabs: { voiceId: 'z9fAnlkpzviPz146aGWa' } },
  },
  Custom: {
    title: 'Custom',
    description: 'Define the persona, or task:',
    systemMessage: 'You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\nCurrent date: {{Today}}',
    symbol: '⚡',
    call: { starters: ['What\'s the task?', 'What can I do?', 'Ready for your task.', 'Yes?'] },
    voices: { elevenLabs: { voiceId: 'flq6f7yk4E4fJM5XTYuZ' } },
  },

};



================================================
FILE: src/apps/AppPlaceholder.tsx
================================================
import * as React from 'react';

import { Box, Typography } from '@mui/joy';

import { capitalizeFirstLetter } from '~/common/util/textUtils';
import { useRouterRoute } from '~/common/app.routes';


/**
 * https://github.com/enricoros/big-AGI/issues/299
 */
export function AppPlaceholder(props: {
  title?: string | null,
  text?: React.ReactNode,
  children?: React.ReactNode,
}) {

  // external state
  const route = useRouterRoute();

  // derived state
  const placeholderAppName = props.title || capitalizeFirstLetter(route.replace('/', '') || 'Home');

  return (
    <Box sx={{
      flexGrow: 1,
      overflowY: 'auto',
      p: { xs: 3, md: 6 },
      border: '1px solid blue',
    }}>

      {(props.title !== null || !!props.text) && (
        <Box sx={{
          my: 'auto',
          display: 'flex', flexDirection: 'column', alignItems: 'center',
          gap: 4,
          border: '1px solid red',
        }}>

          <Typography level='h1'>
            {placeholderAppName}
          </Typography>
          {!!props.text && (
            <Typography>
              {props.text}
            </Typography>
          )}

        </Box>
      )}

      {props.children}

    </Box>
  );
}


================================================
FILE: src/apps/AppSmallContainer.tsx
================================================
import * as React from 'react';

import { Box, Container, Typography } from '@mui/joy';


export function AppSmallContainer({ title, description, children }: {
  title: string;
  description: React.ReactNode;
  children: React.ReactNode;
}) {
  return (
    <Box sx={{ flexGrow: 1, overflowY: 'auto', p: { xs: 3, md: 6 } }}>

      <Container disableGutters maxWidth='md' sx={{ display: 'flex', flexDirection: 'column', gap: 3 }}>

        <Box sx={{ mb: 2 }}>
          <Typography level='h1' sx={{ mb: 1 }}>{title}</Typography>
          <Typography>{description}</Typography>
        </Box>

        {children}

      </Container>

    </Box>
  );
}



================================================
FILE: src/apps/beam/AppBeam.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Box, Button, Typography } from '@mui/joy';

import { BeamStoreApi, useBeamStore } from '~/modules/beam/store-beam.hooks';
import { BeamView } from '~/modules/beam/BeamView';
import { createBeamVanillaStore } from '~/modules/beam/store-beam_vanilla';

import { OptimaToolbarIn } from '~/common/layout/optima/portals/OptimaPortalsIn';
import { createDConversation, DConversation } from '~/common/stores/chat/chat.conversation';
import { createDMessageTextContent, DMessage } from '~/common/stores/chat/chat.message';
import { useIsMobile } from '~/common/components/useMatchMedia';


function initTestConversation(): DConversation {
  const conversation = createDConversation();
  conversation.messages.push(createDMessageTextContent('system', 'You are a helpful assistant.')); // Beam Test - seed1
  conversation.messages.push(createDMessageTextContent('user', 'Hello, who are you? (please expand...)')); // Beam Test - seed2
  return conversation;
}

function initTestBeamStore(messages: DMessage[], beamStore: BeamStoreApi = createBeamVanillaStore()): BeamStoreApi {
  beamStore.getState().open(messages, null, false, (content) => alert(content));
  return beamStore;
}


export function AppBeam() {

  // state
  const [showDebug, setShowDebug] = React.useState(false);

  const [conversation, setConversation] = React.useState<DConversation>(() => initTestConversation());
  const [beamStoreApi] = React.useState(() => createBeamVanillaStore());


  // reinit the beam store if the conversation changes
  React.useEffect(() => {
    initTestBeamStore(conversation.messages, beamStoreApi);
  }, [beamStoreApi, conversation]);


  // external state
  const isMobile = useIsMobile();
  const { isOpen, beamState } = useBeamStore(beamStoreApi, useShallow(state => {
    return {
      isOpen: state.isOpen,
      beamState: showDebug ? state : null,
    };
  }));


  const handleClose = React.useCallback(() => {
    beamStoreApi.getState().terminateKeepingSettings();
  }, [beamStoreApi]);


  const toolbarItems = React.useMemo(() => <>
    {/* button to toggle debug info */}
    <Button size='sm' variant='plain' color='neutral' onClick={() => setShowDebug(on => !on)}>
      {showDebug ? 'Hide' : 'Show'} debug
    </Button>

    {/* 'open' */}
    <Button size='sm' variant='plain' color='neutral' onClick={() => setConversation(initTestConversation())}>
      .open
    </Button>

    {/* 'close' */}
    <Button size='sm' variant='plain' color='neutral' onClick={handleClose}>
      .close
    </Button>
  </>, [handleClose, showDebug]);


  return <>
    <OptimaToolbarIn>{toolbarItems}</OptimaToolbarIn>

    <Box sx={{ flexGrow: 1, overflowY: 'auto', position: 'relative' }}>

      {isOpen && (
        <BeamView
          beamStore={beamStoreApi}
          isMobile={isMobile}
        />
      )}

      {showDebug && (
        <Typography level='body-xs' sx={{
          whiteSpace: 'pre',
          position: 'absolute',
          inset: 0,
          zIndex: 1 /* debug on top of BeamView */,
          backdropFilter: 'blur(4px)',
          padding: '1rem',
        }}>
          {JSON.stringify(beamState, null, 2)
            // add an extra newline between first level properties (space, space, double quote) to make it more readable
            .split('\n').map(line => line.replace(/^\s\s"/g, '\n  ')).join('\n')}
        </Typography>
      )}

    </Box>

  </>;
}


================================================
FILE: src/apps/call/AppCall.tsx
================================================
import * as React from 'react';

import { Container, Sheet } from '@mui/joy';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { useRouterQuery } from '~/common/app.routes';

import { CallWizard } from './CallWizard';
import { Contacts } from './Contacts';
import { Telephone } from './Telephone';
import { useAppCallStore } from './state/store-app-call';


/**
 * Used to define the intent of the call from other apps (via query params) or
 * from the contacts list (via the 'call' button).
 */
export interface AppCallIntent {
  conversationId: DConversationId | null;
  personaId: string;
  backTo: 'app-chat' | 'app-call-contacts';
}


export function AppCall() {

  // state
  const [callIntent, setCallIntent] = React.useState<AppCallIntent | null>(null);

  // external state
  const grayUI = useAppCallStore(state => state.grayUI);
  const query = useRouterQuery<Partial<AppCallIntent>>();


  // [effect] set intent from the query parameters
  React.useEffect(() => {
    if (query.personaId) {
      setCallIntent({
        conversationId: query.conversationId ?? null,
        personaId: query.personaId,
        backTo: query.backTo || 'app-chat',
      });
    }
  }, [query.backTo, query.conversationId, query.personaId]);


  const hasIntent = !!callIntent && !!callIntent.personaId;

  return (
    <Sheet
      variant={grayUI ? 'solid' : 'soft'}
      invertedColors={grayUI ? true : undefined}
      sx={{
        // take the full V-area (we're inside PageWrapper) and scroll as needed
        flexGrow: 1,
        overflowY: 'auto',

        // container will take the full v-area
        display: 'grid',
      }}>

      <Container
        maxWidth={hasIntent ? 'sm' : 'md'}
        sx={{
          display: 'flex', flexDirection: 'column', alignItems: 'center',
          justifyContent: hasIntent ? 'space-evenly' : undefined,
          gap: hasIntent ? 1 : undefined,
          // shall force the contacts or telephone to stay within the container
          overflowY: hasIntent ? 'hidden' : undefined,
        }}>

        {!hasIntent ? (
          <Contacts setCallIntent={setCallIntent} />
        ) : (
          <CallWizard conversationId={callIntent.conversationId}>
            <Telephone callIntent={callIntent} backToContacts={() => setCallIntent(null)} />
          </CallWizard>
        )}

      </Container>

    </Sheet>
  );
}


================================================
FILE: src/apps/call/CallWizard.tsx
================================================
import * as React from 'react';

import { Box, Button, Card, CardContent, IconButton, ListItemDecorator, Typography } from '@mui/joy';
import ArrowForwardRoundedIcon from '@mui/icons-material/ArrowForwardRounded';
import ChatIcon from '@mui/icons-material/Chat';
import CheckRoundedIcon from '@mui/icons-material/CheckRounded';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import MicIcon from '@mui/icons-material/Mic';
import RecordVoiceOverTwoToneIcon from '@mui/icons-material/RecordVoiceOverTwoTone';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { animationColorRainbow } from '~/common/util/animUtils';
import { navigateBack } from '~/common/app.routes';
import { optimaOpenPreferences } from '~/common/layout/optima/useOptima';
import { useCapabilityBrowserSpeechRecognition, useCapabilityElevenLabs } from '~/common/components/useCapabilities';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useUICounter } from '~/common/stores/store-ui';


function StatusCard(props: { icon: React.JSX.Element, hasIssue: boolean, text: string, button?: React.JSX.Element }) {
  return (
    <Card sx={{ width: '100%' }}>
      <CardContent sx={{ flexDirection: 'row' }}>
        <ListItemDecorator>
          {props.icon}
        </ListItemDecorator>
        <Typography level='title-md' color={props.hasIssue ? 'warning' : undefined} sx={{ flexGrow: 1 }}>
          {props.text}
          {props.button}
        </Typography>
        <ListItemDecorator>
          {props.hasIssue ? <WarningRoundedIcon color='warning' /> : <CheckRoundedIcon color='success' />}
        </ListItemDecorator>
      </CardContent>
    </Card>
  );
}


export function CallWizard(props: { strict?: boolean, conversationId: string | null, children: React.ReactNode }) {

  // state
  const [chatEmptyOverride, setChatEmptyOverride] = React.useState(false);
  const [recognitionOverride, setRecognitionOverride] = React.useState(false);

  // external state
  const recognition = useCapabilityBrowserSpeechRecognition();
  const synthesis = useCapabilityElevenLabs();
  const chatIsEmpty = useChatStore(state => {
    if (!props.conversationId)
      return false;
    const conversation = state.conversations.find(conversation => conversation.id === props.conversationId);
    return !(conversation?.messages?.length);
  });
  const { novel, touch } = useUICounter('call-wizard');

  // derived state
  const outOfTheBlue = !props.conversationId;
  const overriddenEmptyChat = chatEmptyOverride || !chatIsEmpty;
  const overriddenRecognition = recognitionOverride || recognition.mayWork;
  const allGood = overriddenEmptyChat && overriddenRecognition && synthesis.mayWork;
  const fatalGood = overriddenRecognition && synthesis.mayWork;


  const handleOverrideChatEmpty = React.useCallback(() => setChatEmptyOverride(true), []);

  const handleOverrideRecognition = React.useCallback(() => setRecognitionOverride(true), []);

  const handleConfigureElevenLabs = React.useCallback(() => optimaOpenPreferences('voice'), []);

  const handleFinishButton = React.useCallback(() => {
    if (!allGood)
      return navigateBack();
    touch();
  }, [allGood, touch]);


  if (!novel && fatalGood)
    return props.children;


  return <>

    <Box sx={{ flexGrow: 0.5 }} />

    <Typography level='title-lg' sx={{ fontSize: '3rem', fontWeight: 'sm', textAlign: 'center' }}>
      Welcome to<br />
      <Box component='span' sx={{ animation: `${animationColorRainbow} 15s linear infinite` }}>
        your first call
      </Box>
    </Typography>

    <Box sx={{ flexGrow: 0.5 }} />

    <Typography level='body-lg'>
      {/*Before you receive your first call, */}
      Let&apos;s get you all set up.
    </Typography>

    {/* Chat Empty status */}
    {!outOfTheBlue && <StatusCard
      icon={<ChatIcon />}
      hasIssue={!overriddenEmptyChat}
      text={overriddenEmptyChat ? 'Great! Your chat has messages.' : 'The chat is empty. Calls are effective when the caller has context.'}
      button={overriddenEmptyChat ? undefined : (
        <Button variant='outlined' onClick={handleOverrideChatEmpty} sx={{ mx: 1 }}>
          Ignore
        </Button>
      )}
    />}

    {/* Add the speech to text feature status */}
    <StatusCard
      icon={<MicIcon />}
      text={
        ((overriddenRecognition && !recognition.warnings.length) ? 'Speech recognition should be good to go.' : 'There might be a speech recognition issue.')
        + (recognition.isApiAvailable ? '' : ' Your browser does not support the speech recognition API.')
        + (recognition.isDeviceNotSupported ? ' Your device does not provide this feature.' : '')
        + (recognition.warnings.length ? ' ⚠️ ' + recognition.warnings.join(' · ') : '')
      }
      button={overriddenRecognition ? undefined : (
        <Button variant='outlined' onClick={handleOverrideRecognition} sx={{ mx: 1 }}>
          Ignore
        </Button>
      )}
      hasIssue={!overriddenRecognition}
    />

    {/* Text to Speech status */}
    <StatusCard
      icon={<RecordVoiceOverTwoToneIcon />}
      text={
        (synthesis.mayWork ? 'Voice synthesis should be ready.' : 'There might be an issue with ElevenLabs voice synthesis.')
        + (synthesis.isConfiguredServerSide ? '' : (synthesis.isConfiguredClientSide ? '' : ' Please add your API key in the settings.'))
      }
      button={synthesis.mayWork ? undefined : (
        <Button variant='outlined' onClick={handleConfigureElevenLabs} sx={{ mx: 1 }}>
          Configure
        </Button>
      )}
      hasIssue={!synthesis.mayWork}
    />

    {/*<Typography>*/}
    {/*  1. To start a call, click the "Accept" button when you receive an incoming call.*/}
    {/*  2. If your mic is enabled, you'll see a "Push to Talk" button. Press and hold it to speak, then release it to stop speaking.*/}
    {/*  3. If your mic is disabled, you can still type your messages in the chat and the assistant will respond.*/}
    {/*  4. During the call, you can control the voice synthesis settings from the menu in the top right corner.*/}
    {/*  5. To end the call, click the "Hang up" button.*/}
    {/*</Typography>*/}

    <Box sx={{ flexGrow: 2 }} />

    {/* bottom: text & button */}
    <Box sx={{ display: 'flex', justifyContent: 'space-around', alignItems: 'center', width: '100%', gap: 2, px: 0.5 }}>

      <Typography level='body-lg'>
        {allGood ? 'Ready, Set, Call' : 'Please resolve the issues above before proceeding with the call'}
      </Typography>

      <IconButton
        size='lg'
        variant='solid' color={allGood ? 'success' : 'danger'}
        onClick={handleFinishButton}
        sx={{
          borderRadius: '50px',
          mr: 0.5,
          // animation: `${cssRainbowBackgroundKeyframes} 15s linear infinite`,
          // boxShadow: allGood ? 'md' : 'none',
        }}
      >
        {allGood ? <ArrowForwardRoundedIcon sx={{ fontSize: '1.5em' }} /> : <CloseRoundedIcon sx={{ fontSize: '1.5em' }} />}
      </IconButton>
    </Box>

    <Box sx={{ flexGrow: 2 }} />

  </>;
}


================================================
FILE: src/apps/call/Contacts.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Avatar, Box, Card, CardContent, Chip, IconButton, Link as MuiLink, ListDivider, MenuItem, Sheet, Switch, Typography } from '@mui/joy';
import CallIcon from '@mui/icons-material/Call';

import { GitHubProjectIssueCard } from '~/common/components/GitHubProjectIssueCard';
import { OptimaPanelGroupedList } from '~/common/layout/optima/panel/OptimaPanelGroupedList';
import { OptimaPanelIn } from '~/common/layout/optima/portals/OptimaPortalsIn';
import { animationShadowRingLimey } from '~/common/util/animUtils';
import { conversationTitle, DConversation, DConversationId } from '~/common/stores/chat/chat.conversation';
import { useChatStore } from '~/common/stores/chat/store-chats';

import type { AppCallIntent } from './AppCall';
import { MockPersona, useMockPersonas } from './state/useMockPersonas';
import { useAppCallStore } from './state/store-app-call';


// number of conversations to show before collapsing
const COLLAPSED_COUNT = 2;


const ContactCardAvatar = (props: { size: string, symbol?: string, imageUrl?: string, onClick?: () => void, sx?: SxProps }) =>
  <Avatar
    // variant='outlined'
    onClick={props.onClick}
    src={props.imageUrl}
    sx={{
      '--Avatar-size': props.size,
      fontSize: props.size,
      backgroundColor: 'background.popup',
      boxShadow: !props.imageUrl ? 'sm' : null,
      ...props.sx,
    }}
  >
    {/* As fallback, show the large Persona Symbol */}
    {!props.imageUrl && <Box>{props.symbol}</Box>}
  </Avatar>;


const ContactCardConversationCall = (props: { conversation: DConversation, onConversationClicked: (conversationId: DConversationId) => void, }) =>
  <Chip
    variant='plain' color='primary' size='sm'
    endDecorator={<CallIcon />}
    onClick={() => props.onConversationClicked(props.conversation.id)}
    slotProps={{
      root: {
        sx: {
          maxWidth: 'unset',
          mx: -1,
          px: 1,
          py: 0.25,
        },
      },
    }}
  >
    {conversationTitle(props.conversation, 'Chat')}
  </Chip>;


function CallContactCard(props: {
  persona: MockPersona,
  callGrayUI: boolean,
  conversations: Readonly<DConversation[]>,
  setCallIntent: (intent: AppCallIntent) => void,
}) {

  // state
  const [conversationsExpanded, setConversationsExpanded] = React.useState(false);

  // derived state
  const { persona, setCallIntent } = props;
  const conversations = props.conversations.slice(0, conversationsExpanded ? undefined : COLLAPSED_COUNT);
  const hasConversations = !!conversations.length;
  const showExpander = props.conversations.length > COLLAPSED_COUNT && !conversationsExpanded;


  const handleCallPersona = React.useCallback(() => setCallIntent({
    conversationId: null,
    personaId: persona.personaId,
    backTo: 'app-call-contacts',
  }), [persona.personaId, setCallIntent]);

  const handleCallPersonaRe = React.useCallback((conversationId: DConversationId | null) => setCallIntent({
    conversationId: conversationId,
    personaId: persona.personaId,
    backTo: 'app-call-contacts',
  }), [persona.personaId, setCallIntent]);

  return (

    <Box sx={{ mt: 3.5 }}>

      <Card sx={{
        // boxShadow: 'lg',
        height: '100%',
        gap: 0,
      }}>

        {/* Persona Symbol - Overlapping */}
        <ContactCardAvatar
          size='6rem'
          symbol={persona.symbol}
          imageUrl={persona?.imageUri}
          sx={{
            mx: 'auto',
            mt: '-2.5rem',
          }}
        />

        <CardContent sx={{ my: 2, display: 'flex' }}>
          {/* Persona Description */}
          <Typography level='body-xs' sx={{ minHeight: '3em', mb: hasConversations ? 1.5 : undefined }}>
            {typeof persona.description === 'string' ? persona.description : 'Custom persona'}
          </Typography>

          {/*{hasConversations && <Divider>*/}
          {/*<Typography level='body-xs'>call about</Typography>*/}
          {/*</Divider>}*/}

          {/* Persona Recent Converstions */}
          {conversations.map(conversation =>
            <ContactCardConversationCall
              key={conversation.id}
              conversation={conversation}
              onConversationClicked={handleCallPersonaRe}
            />,
          )}

          {showExpander && <Chip
            variant='plain' color='primary' size='sm'
            onClick={() => setConversationsExpanded(true)}
            slotProps={{
              root: {
                sx: {
                  maxWidth: 'unset',
                  mx: -1,
                  px: 1,
                  py: 0.25,
                },
              },
            }}
          >
            {`+${props.conversations.length - COLLAPSED_COUNT} more`}
          </Chip>}

        </CardContent>

        {/*<Divider />*/}

        {/* Bottom Name and "Call" Button */}
        <Sheet
          variant='soft' color='primary'
          invertedColors={props.callGrayUI ? undefined : true}
          sx={{
            // emulate CardOverflow, because CardOverflow doesn't work well with Sheet/Inverted
            // (there's also a potential top-level inversion)
            '--variant-borderWidth': '1px',
            '--CardOverflow-offset': 'calc(-1 * var(--Card-padding))',
            '--CardOverflow-radius': 'calc(var(--Card-radius) - var(--variant-borderWidth, 0px))',
            margin: '0 var(--CardOverflow-offset) var(--CardOverflow-offset)',
            borderRadius: '0 0 var(--CardOverflow-radius) var(--CardOverflow-radius)',
            padding: '0.5rem var(--Card-padding)',

            // contents
            display: 'flex', alignItems: 'center', justifyContent: 'space-between',
            gap: 1,
          }}
        >
          <Typography level='title-md'>
            {persona.title}
          </Typography>
          <MuiLink overlay onClick={handleCallPersona}>
            <IconButton size='md' variant='soft' sx={{
              // borderRadius: '50%',
              ml: 'auto',
              mr: -1,
            }}>
              <CallIcon />
            </IconButton>
          </MuiLink>
        </Sheet>

      </Card>

    </Box>

  );
}


function useConversationsByPersona() {
  const conversations = useChatStore(state => state.conversations);

  return React.useMemo(() => {
    // group by personaId
    const groupedConversations: { [personaId: string]: DConversation[] } = conversations.reduce((acc, conversation) => {
      const personaId = conversation.systemPurposeId;
      acc[personaId] = [...acc[personaId] || [], conversation];
      return acc;
    }, {} as { [personaId: string]: DConversation[] });

    // sort conversations by time and limit to 3
    Object.values(groupedConversations).forEach(conversations =>
      conversations.sort((a, b) => (b.updated || b.created) - (a.updated || a.created)),
    );

    return groupedConversations;
  }, [conversations]);
}


function ContactsMenuItems() {

  // external state
  const {
    grayUI, toggleGrayUI,
    showConversations, toggleShowConversations,
    showSupport, toggleShowSupport,
  } = useAppCallStore();

  return (
    <OptimaPanelGroupedList title='Contacts Settings'>

      <MenuItem onClick={toggleGrayUI}>
        Grayed UI
        <Switch checked={grayUI} sx={{ ml: 'auto' }} />
      </MenuItem>

      <MenuItem onClick={toggleShowConversations}>
        Conversations
        <Switch checked={showConversations} sx={{ ml: 'auto' }} />
      </MenuItem>

      <MenuItem onClick={toggleShowSupport}>
        Show Support
        <Switch checked={showSupport} sx={{ ml: 'auto' }} />
      </MenuItem>

    </OptimaPanelGroupedList>
  );
}


export function Contacts(props: { setCallIntent: (intent: AppCallIntent) => void }) {

  // external state
  const { personas } = useMockPersonas();
  const { grayUI, showConversations, showSupport } = useAppCallStore();
  const conversationsByPersona = useConversationsByPersona();


  return <>

    {/* -> Panel */}
    <OptimaPanelIn><ContactsMenuItems /></OptimaPanelIn>

    {/* Header "Call AGI" */}
    <Box sx={{
      my: 6,
      display: 'flex', alignItems: 'center',
      gap: 3,
    }}>
      <IconButton
        variant='soft' color='success'
        sx={{
          '--IconButton-size': { xs: '4.2rem', md: '5rem' },
          borderRadius: '50%',
          pointerEvents: 'none',
          backgroundColor: 'background.popup',
          animation: `${animationShadowRingLimey} 5s infinite`,
        }}>
        <CallIcon />
      </IconButton>

      <Box>
        <Typography level='title-lg'>
          Call AGI
        </Typography>
        <Typography level='title-sm' sx={{ mt: 1 }}>
          Explore ideas and ignite creativity
        </Typography>
        <Chip variant='outlined' size='sm' sx={{ px: 1, py: 0.5, mt: 0.25, ml: -1, textWrap: 'wrap' }}>
          Out-of-the-blue, or within a conversation
        </Chip>
      </Box>
    </Box>

    <ListDivider>
      Personas
    </ListDivider>

    {/* Personas Cards */}
    <Box
      sx={{
        width: '100%',
        my: 5,
        display: 'grid',
        gridTemplateColumns: 'repeat(auto-fit, minmax(160px, 1fr))',
        gap: { xs: 1, md: 2 },
      }}
    >
      {personas.map((persona) =>
        <CallContactCard
          key={persona.personaId}
          persona={persona}
          callGrayUI={grayUI}
          conversations={!showConversations ? [] : conversationsByPersona[persona.personaId] || []}
          setCallIntent={props.setCallIntent}
        />,
      )}
    </Box>

    {showSupport && <ListDivider sx={{ my: 1 }} />}

    {showSupport && <GitHubProjectIssueCard
      issue={354}
      text='Call App: Support thread and compatibility matrix'
      note={<>
        Voice input uses the HTML Web Speech API, and speech output requires an ElevenLabs API Key.
      </>}
      // note2='Please report any issues you encounter'
      sx={{
        width: '100%',
        mb: 2,
        mt: 5,
      }}
    />}

  </>;
}


================================================
FILE: src/apps/call/Telephone.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Box, Card, ListDivider, ListItemDecorator, MenuItem, Switch, Typography } from '@mui/joy';
import ArrowBackIcon from '@mui/icons-material/ArrowBack';
import CallEndIcon from '@mui/icons-material/CallEnd';
import CallIcon from '@mui/icons-material/Call';
import MicIcon from '@mui/icons-material/Mic';
import MicNoneIcon from '@mui/icons-material/MicNone';
import RecordVoiceOverTwoToneIcon from '@mui/icons-material/RecordVoiceOverTwoTone';

import { ScrollToBottom } from '~/common/scroll-to-bottom/ScrollToBottom';
import { ScrollToBottomButton } from '~/common/scroll-to-bottom/ScrollToBottomButton';
import { useChatLLMDropdown } from '../chat/components/layout-bar/useLLMDropdown';

import { SystemPurposeId, SystemPurposes } from '../../data';
import { elevenLabsSpeakText } from '~/modules/elevenlabs/elevenlabs.client';
import { AixChatGenerateContent_DMessage, aixChatGenerateContent_DMessage_FromConversation } from '~/modules/aix/client/aix.client';
import { useElevenLabsVoiceDropdown } from '~/modules/elevenlabs/useElevenLabsVoiceDropdown';

import type { OptimaBarControlMethods } from '~/common/layout/optima/bar/OptimaBarDropdown';
import { AudioPlayer } from '~/common/util/audio/AudioPlayer';
import { Link } from '~/common/components/Link';
import { OptimaPanelGroupedList } from '~/common/layout/optima/panel/OptimaPanelGroupedList';
import { OptimaPanelIn, OptimaToolbarIn } from '~/common/layout/optima/portals/OptimaPortalsIn';
import { SpeechResult, useSpeechRecognition } from '~/common/components/speechrecognition/useSpeechRecognition';
import { conversationTitle, remapMessagesSysToUsr } from '~/common/stores/chat/chat.conversation';
import { createDMessageFromFragments, createDMessageTextContent, DMessage, messageFragmentsReduceText, messageWasInterruptedAtStart } from '~/common/stores/chat/chat.message';
import { createErrorContentFragment } from '~/common/stores/chat/chat.fragments';
import { launchAppChat, navigateToIndex } from '~/common/app.routes';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { usePlayUrl } from '~/common/util/audio/usePlayUrl';

import type { AppCallIntent } from './AppCall';
import { CallAvatar } from './components/CallAvatar';
import { CallButton } from './components/CallButton';
import { CallMessage } from './components/CallMessage';
import { CallStatus } from './components/CallStatus';
import { useAppCallStore } from './state/store-app-call';


function CallMenu(props: {
  pushToTalk: boolean,
  setPushToTalk: (pushToTalk: boolean) => void,
  override: boolean,
  setOverride: (overridePersonaVoice: boolean) => void,
}) {

  // external state
  const { grayUI, toggleGrayUI } = useAppCallStore();
  const { voicesDropdown } = useElevenLabsVoiceDropdown(false, !props.override);

  const handlePushToTalkToggle = () => props.setPushToTalk(!props.pushToTalk);

  const handleChangeVoiceToggle = () => props.setOverride(!props.override);

  return <OptimaPanelGroupedList title='Call'>

    <MenuItem onClick={handlePushToTalkToggle}>
      <ListItemDecorator>{props.pushToTalk ? <MicNoneIcon /> : <MicIcon />}</ListItemDecorator>
      Push to talk
      <Switch checked={props.pushToTalk} onChange={handlePushToTalkToggle} sx={{ ml: 'auto' }} />
    </MenuItem>

    <MenuItem onClick={handleChangeVoiceToggle}>
      <ListItemDecorator><RecordVoiceOverTwoToneIcon /></ListItemDecorator>
      Change Voice
      <Switch checked={props.override} onChange={handleChangeVoiceToggle} sx={{ ml: 'auto' }} />
    </MenuItem>

    <MenuItem>
      <ListItemDecorator>{' '}</ListItemDecorator>
      {voicesDropdown}
    </MenuItem>

    <ListDivider />

    <MenuItem onClick={toggleGrayUI}>
      Grayed UI
      <Switch checked={grayUI} sx={{ ml: 'auto' }} />
    </MenuItem>

    <MenuItem component={Link} href='https://github.com/enricoros/big-agi/issues/175' target='_blank'>
      Voice Calls Feedback
    </MenuItem>

  </OptimaPanelGroupedList>;
}


export function Telephone(props: {
  callIntent: AppCallIntent,
  backToContacts: () => void,
}) {

  // state
  const [avatarClickCount, setAvatarClickCount] = React.useState<number>(0);// const [micMuted, setMicMuted] = React.useState(false);
  const [callElapsedTime, setCallElapsedTime] = React.useState<string>('00:00');
  const [callMessages, setCallMessages] = React.useState<DMessage[]>([]);
  const [overridePersonaVoice, setOverridePersonaVoice] = React.useState<boolean>(false);
  const [personaTextInterim, setPersonaTextInterim] = React.useState<string | null>(null);
  const [pushToTalk, setPushToTalk] = React.useState(true);
  const [stage, setStage] = React.useState<'ring' | 'declined' | 'connected' | 'ended'>('ring');
  const llmDropdownRef = React.useRef<OptimaBarControlMethods>(null);
  const responseAbortController = React.useRef<AbortController | null>(null);

  // external state
  const { chatLLMId: modelId, chatLLMDropdown: modelDropdown } = useChatLLMDropdown(llmDropdownRef);
  const { chatTitle, reMessages } = useChatStore(useShallow(state => {
    const conversation = props.callIntent.conversationId
      ? state.conversations.find(conversation => conversation.id === props.callIntent.conversationId) ?? null
      : null;
    return {
      chatTitle: conversation ? conversationTitle(conversation) : null,
      reMessages: conversation ? conversation.messages : null,
    };
  }));
  const persona = SystemPurposes[props.callIntent.personaId as SystemPurposeId] ?? undefined;
  const personaCallStarters = persona?.call?.starters ?? undefined;
  const personaVoiceId = overridePersonaVoice ? undefined : (persona?.voices?.elevenLabs?.voiceId ?? undefined);
  const personaSystemMessage = persona?.systemMessage ?? undefined;

  // hooks and speech
  const [speechInterim, setSpeechInterim] = React.useState<SpeechResult | null>(null);
  const onSpeechResultCallback = React.useCallback((result: SpeechResult) => {
    setSpeechInterim(result.done ? null : { ...result });
    if (result.done) {
      const userSpeechTranscribed = result.transcript.trim();
      if (userSpeechTranscribed.length >= 1)
        setCallMessages(messages => [...messages, createDMessageTextContent('user', userSpeechTranscribed)]); // [state] append user:speech
    }
  }, []);
  const { recognitionState, startRecognition, stopRecognition, toggleRecognition } = useSpeechRecognition('webSpeechApi', onSpeechResultCallback, 1000);

  // derived state
  const isRinging = stage === 'ring';
  const isConnected = stage === 'connected';
  const isDeclined = stage === 'declined';
  const isEnded = stage === 'ended';


  /// Sounds

  // pickup / hangup
  React.useEffect(() => {
    !isRinging && AudioPlayer.playUrl(isConnected ? '/sounds/chat-begin.mp3' : '/sounds/chat-end.mp3');
  }, [isRinging, isConnected]);

  // ringtone
  usePlayUrl(isRinging ? '/sounds/chat-ringtone.mp3' : null, 300, 2800 * 2);


  /// Shortcuts

  useGlobalShortcuts('Telephone', React.useMemo(() => [
    { key: 'm', ctrl: true, action: toggleRecognition },
  ], [toggleRecognition]));

  /// CONNECTED

  const handleCallStop = () => {
    stopRecognition(false);
    setStage('ended');
  };

  // [E] pickup -> seed message and call timer
  // FIXME: Overriding the voice will reset the call - not a desired behavior
  React.useEffect(() => {
    if (!isConnected) return;

    // show the call timer
    setCallElapsedTime('00:00');
    const start = Date.now();
    const interval = setInterval(() => {
      const elapsedSeconds = Math.floor((Date.now() - start) / 1000);
      const minutes = Math.floor(elapsedSeconds / 60);
      const seconds = elapsedSeconds % 60;
      setCallElapsedTime(`${minutes < 10 ? '0' : ''}${minutes}:${seconds < 10 ? '0' : ''}${seconds}`);
    }, 1000);

    // seed the first message
    const phoneMessages = personaCallStarters || ['Hello?', 'Hey!'];
    const firstMessage = phoneMessages[Math.floor(Math.random() * phoneMessages.length)];

    setCallMessages([createDMessageTextContent('assistant', firstMessage)]); // [state] set assistant:hello message

    // fire/forget
    void elevenLabsSpeakText(firstMessage, personaVoiceId, true, true);

    return () => clearInterval(interval);
  }, [isConnected, personaCallStarters, personaVoiceId]);

  // [E] persona streaming response - upon new user message
  React.useEffect(() => {
    // only act when we have a new user message
    if (!isConnected || callMessages.length < 1)
      return;

    // Voice commands
    const lastUserMessage = callMessages[callMessages.length - 1];
    if (lastUserMessage.role !== 'user')
      return;
    switch (messageFragmentsReduceText(lastUserMessage.fragments)) {
      // do not respond
      case 'Stop.':
        return;

      // command: close the call
      case 'Goodbye.':
        setStage('ended');
        setTimeout(launchAppChat, 2000);
        return;

      // command: regenerate answer
      case 'Retry.':
      case 'Try again.':
        setCallMessages(messages => messages.slice(0, messages.length - 2));
        return;

      // command: restart chat
      case 'Restart.':
        setCallMessages([]);
        return;
    }

    // bail if no llm selected
    if (!modelId) return;


    // Call Message Generation Prompt
    const callSystemInstruction = createDMessageTextContent('system', 'You are having a phone call. Your response style is brief and to the point, and according to your personality, defined below.');
    const reMessagesRemapSysToUsr = remapMessagesSysToUsr(reMessages);
    const callGenerationInputHistory: DMessage[] = [
      // Chat messages, including the system prompt which is casted to a user message
      // TODO: when upgrading to dynamic personas, we need to inject the persona message instead - not rely on reMessages, as messages[0] !== 'system'
      ...(reMessagesRemapSysToUsr ? reMessagesRemapSysToUsr : [createDMessageTextContent('user', personaSystemMessage)]),
      // Call system prompt 2, to indicate the call has started
      createDMessageTextContent('user', '**You are now on the phone call related to the chat above**.\nRespect your personality and answer with short, friendly and accurate thoughtful brief lines.'),
      // Call history
      ...callMessages,
    ];


    // perform completion
    responseAbortController.current = new AbortController();
    let finalText = '';
    setPersonaTextInterim('💭...');

    aixChatGenerateContent_DMessage_FromConversation(
      modelId,
      callSystemInstruction,
      callGenerationInputHistory,
      'call',
      callMessages[0].id,
      { abortSignal: responseAbortController.current.signal },
      (update: AixChatGenerateContent_DMessage, _isDone: boolean) => {
        const updatedText = messageFragmentsReduceText(update.fragments).trim();
        if (updatedText)
          setPersonaTextInterim(finalText = updatedText);
      },
    ).then((status) => {

      // don't add the message to conversation if it was interrupted with no content
      if (messageWasInterruptedAtStart(status.lastDMessage))
        return;

      // whether status.outcome === 'success' or not, we get a valid DMessage, eventually with Error Fragments inside
      const fullMessage = createDMessageFromFragments('assistant', status.lastDMessage.fragments);
      fullMessage.generator = status.lastDMessage.generator;
      setCallMessages(messages => [...messages, fullMessage]); // [state] append assistant:call_response

      // fire/forget
      if (status.outcome === 'success' && finalText?.length >= 1)
        void elevenLabsSpeakText(finalText, personaVoiceId, true, true);

    }).catch((err: DOMException) => {
      if (err?.name !== 'AbortError') {
        // create an error message to explain the exception
        const errorMessage = createDMessageFromFragments('assistant', [createErrorContentFragment(err.message || err.toString())]);
        setCallMessages(messages => [...messages, errorMessage]); // [state] append assistant:call_response-ERROR
      }
    }).finally(() => {
      setPersonaTextInterim(null);
    });

    return () => {
      responseAbortController.current?.abort();
      responseAbortController.current = null;
    };
  }, [isConnected, callMessages, modelId, personaVoiceId, personaSystemMessage, reMessages]);

  // [E] Message interrupter
  const abortTrigger = isConnected && recognitionState.hasSpeech;
  React.useEffect(() => {
    if (abortTrigger && responseAbortController.current) {
      responseAbortController.current.abort();
      responseAbortController.current = null;
    }
    // TODO.. abort current speech
  }, [abortTrigger]);


  // [E] continuous speech recognition (reload)
  const shouldStartRecording = isConnected && !pushToTalk && speechInterim === null && !recognitionState.hasAudio;
  React.useEffect(() => {
    if (shouldStartRecording)
      startRecognition();
  }, [shouldStartRecording, startRecognition]);


  // more derived state
  const personaName = persona?.title ?? 'Unknown';
  const isMicEnabled = recognitionState.isAvailable;
  const isTTSEnabled = true;
  const isEnabled = isMicEnabled && isTTSEnabled;


  return <>

    {/* -> Toolbar */}
    <OptimaToolbarIn>{modelDropdown}</OptimaToolbarIn>
    {/* -> Panel */}
    <OptimaPanelIn>
      <CallMenu
        pushToTalk={pushToTalk} setPushToTalk={setPushToTalk}
        override={overridePersonaVoice} setOverride={setOverridePersonaVoice}
      />
    </OptimaPanelIn>

    <Typography
      level='h1'
      sx={{
        fontSize: { xs: '2.5rem', md: '3rem' },
        textAlign: 'center',
        mx: 2,
      }}
    >
      {isConnected ? personaName : 'Hello'}
    </Typography>

    <CallAvatar
      symbol={persona?.symbol || '?'}
      imageUrl={persona?.imageUri}
      isRinging={isRinging}
      onClick={() => setAvatarClickCount(avatarClickCount + 1)}
    />

    <CallStatus
      callerName={isConnected ? undefined : personaName}
      statusText={isRinging ? '' /*'is calling you'*/ : isDeclined ? 'call declined' : isEnded ? 'call ended' : callElapsedTime}
      regardingText={chatTitle}
      micError={!isMicEnabled} speakError={!isTTSEnabled}
    />

    {/* Live Transcript, w/ streaming messages, audio indication, etc. */}
    {(isConnected || isEnded) && (
      <Card variant='outlined' sx={{
        flexGrow: 1,
        maxHeight: '28%',
        minHeight: '20%',
        width: '100%',

        // style
        // backgroundColor: 'background.surface',
        borderRadius: 'lg',
        // boxShadow: 'sm',

        // children
        padding: 0, // move this to the ScrollToBottom component
      }}>

        <ScrollToBottom stickToBottomInitial>

          <Box sx={{ minHeight: '100%', p: 1, display: 'flex', flexDirection: 'column', gap: 1 }}>

            {/* Call Messages [] */}
            {callMessages.map((message) =>
              <CallMessage
                key={message.id}
                text={messageFragmentsReduceText(message.fragments)}
                variant={message.role === 'assistant' ? 'solid' : 'soft'}
                color={message.role === 'assistant' ? 'neutral' : 'primary'}
                role={message.role}
              />,
            )}

            {/* Persona streaming text... */}
            {!!personaTextInterim && (
              <CallMessage
                text={personaTextInterim}
                variant='outlined'
                color='neutral'
                role='assistant'
              />
            )}

            {/* Listening... */}
            {recognitionState.isActive && (
              <CallMessage
                text={<>{speechInterim?.transcript.trim() || null}{speechInterim?.interimTranscript.trim() ? <i> {speechInterim.interimTranscript}</i> : null}</>}
                variant={(recognitionState.hasSpeech || !!speechInterim?.transcript) ? 'soft' : 'outlined'}
                color='primary'
                role='user'
              />
            )}

          </Box>

          {/* Visibility and actions are handled via Context */}
          <ScrollToBottomButton />

        </ScrollToBottom>
      </Card>
    )}

    {/* Call Buttons */}
    <Box sx={{ width: '100%', display: 'flex', justifyContent: 'space-evenly', gap: 4 }}>

      {/* [ringing] Decline / Accept */}
      {isRinging && <CallButton Icon={CallEndIcon} text='Decline' color='danger' variant='solid' onClick={() => setStage('declined')} />}
      {isRinging && isEnabled && <CallButton Icon={CallIcon} text='Accept' color='success' variant='solid' onClick={() => setStage('connected')} />}

      {/* [Calling] Hang / PTT (mute not enabled yet) */}
      {isConnected && <CallButton Icon={CallEndIcon} text='Hang up' color='danger' variant='soft' onClick={handleCallStop} />}
      {isConnected && (pushToTalk ? (
          <CallButton
            Icon={MicIcon} onClick={toggleRecognition}
            text={recognitionState.hasSpeech ? 'Listening...' : recognitionState.isActive ? 'Listening' : 'Push To Talk'}
            variant={recognitionState.hasSpeech ? 'solid' : recognitionState.isActive ? 'soft' : 'outlined'}
            color='primary'
            sx={!recognitionState.isActive ? { backgroundColor: 'background.surface' } : undefined}
          />
        ) : null
        // <CallButton disabled={true} Icon={MicOffIcon} onClick={() => setMicMuted(muted => !muted)}
        //               text={micMuted ? 'Muted' : 'Mute'}
        //               color={micMuted ? 'warning' : undefined} variant={micMuted ? 'solid' : 'outlined'} />
      )}

      {/* [ended] Back / Call Again */}
      {(isEnded || isDeclined) && <CallButton Icon={ArrowBackIcon} text='Back' variant='soft' onClick={() => props.callIntent.backTo === 'app-chat' ? navigateToIndex() : props.backToContacts()} />}
      {(isEnded || isDeclined) && <CallButton Icon={CallIcon} text='Call Again' color='success' variant='soft' onClick={() => setStage('connected')} />}

    </Box>

    {/* DEBUG state */}
    {avatarClickCount > 10 && (avatarClickCount % 2 === 0) && (
      <Card variant='outlined' sx={{ maxHeight: '25dvh', fontSize: 'sm', overflow: 'auto', whiteSpace: 'pre', py: 0, width: '100%' }}>
        Special commands: Stop, Retry, Try Again, Restart, Goodbye.<br />
        {JSON.stringify({ ...recognitionState, speechInterim }, null, 2)}
      </Card>
    )}

    {/*{isEnded && <Card variant='solid' size='lg' color='primary'>*/}
    {/*  <CardContent>*/}
    {/*    <Typography>*/}
    {/*      Please rate the call quality, 1 to 5 - Just a Joke*/}
    {/*    </Typography>*/}
    {/*  </CardContent>*/}
    {/*</Card>}*/}

  </>;
}


================================================
FILE: src/apps/call/components/CallAvatar.tsx
================================================
import * as React from 'react';

import { Avatar, Box } from '@mui/joy';

import { animationScalePulse } from '~/common/util/animUtils';


export function CallAvatar(props: { symbol: string, imageUrl?: string, isRinging?: boolean, onClick: () => void }) {
  return (
    <Avatar
      onClick={props.onClick}
      src={props.imageUrl}
      sx={{
        '--Avatar-size': { xs: '10rem', md: '11.5rem' },
        backgroundColor: 'background.popup',
        boxShadow: !props.imageUrl ? 'sm' : null,
        fontSize: { xs: '6rem', md: '7rem' },
      }}
    >

      {/* As fallback, show the large Persona Symbol */}
      {!props.imageUrl && (
        <Box
          sx={{
            ...(props.isRinging
              ? { animation: `${animationScalePulse} 1.4s ease-in-out infinite` }
              : {}),
          }}
        >
          {props.symbol}
        </Box>
      )}

    </Avatar>
  );
}


================================================
FILE: src/apps/call/components/CallButton.tsx
================================================
import * as React from 'react';

import { ColorPaletteProp, FormControl, IconButton, Typography, VariantProp } from '@mui/joy';
import { SxProps } from '@mui/joy/styles/types';


/**
 * Large button to operate the call, e.g.
 *  --------
 *  |  🎤  |
 *  | Mute |
 *  --------
 */
export function CallButton(props: {
  Icon: React.FC, text: string,
  variant?: VariantProp, color?: ColorPaletteProp, disabled?: boolean,
  onClick?: () => void,
  sx?: SxProps,
}) {
  return (
    <FormControl
      onClick={() => !props.disabled && props.onClick?.()}
      sx={{
        display: 'flex', flexDirection: 'column', alignItems: 'center',
        gap: { xs: 1, md: 2 },
      }}
    >

      <IconButton
        aria-label={props.text}
        variant={props.variant || 'solid'} color={props.color}
        disabled={props.disabled}
        sx={{
          '--IconButton-size': { xs: '4.2rem', md: '5rem' },
          borderRadius: '50%',
          // boxShadow: 'lg',
          ...props.sx,
        }}
      >
        <props.Icon />
      </IconButton>

      <Typography aria-hidden level='title-md' variant={props.disabled ? 'soft' : undefined}>
        {props.text}
      </Typography>

    </FormControl>
  );
}


================================================
FILE: src/apps/call/components/CallMessage.tsx
================================================
import * as React from 'react';

import { Chip, ColorPaletteProp, VariantProp } from '@mui/joy';
import { SxProps } from '@mui/joy/styles/types';

import type { DMessage } from '~/common/stores/chat/chat.message';


export function CallMessage(props: {
  text?: string | React.JSX.Element,
  variant?: VariantProp, color?: ColorPaletteProp,
  role: DMessage['role'],
  sx?: SxProps,
}) {
  const isUserMessage = props.role === 'user';
  return (
    <Chip
      color={props.color} variant={props.variant}
      sx={{
        alignSelf: isUserMessage ? 'end' : 'start',
        whiteSpace: 'break-spaces',
        borderRadius: 'lg',
        ...(isUserMessage ? {
          borderBottomRightRadius: 0,
        } : {
          borderBottomLeftRadius: 0,
        }),
        // boxShadow: 'md',
        py: 1,
        px: 1.5,
        ...(props.sx || {}),
      }}
    >

      {props.text}

    </Chip>
  );
}


================================================
FILE: src/apps/call/components/CallStatus.tsx
================================================
import * as React from 'react';

import { Box, Typography } from '@mui/joy';

import { InlineError } from '~/common/components/InlineError';


/**
 * A status message for the call, such as:
 *
 *             $Name
 *  "Connecting..." or "Call ended",
 *         re: $Regarding
 */
export function CallStatus(props: {
  callerName?: string,
  statusText: string,
  regardingText: string | null,
  micError: boolean, speakError: boolean,
  // llmComponent?: React.JSX.Element,
}) {
  return (
    <Box sx={{ display: 'flex', flexDirection: 'column' }}>

      {!!props.callerName && <Typography level='h3' sx={{ textAlign: 'center' }}>
        <b>{props.callerName}</b>
      </Typography>}

      {/*{props.llmComponent}*/}

      {!!props.statusText && <Typography level='body-md' sx={{ textAlign: 'center' }}>
        {props.statusText}
      </Typography>}

      {!!props.regardingText && <Typography level='body-md' sx={{ textAlign: 'center', mt: 1 }}>
        Re: <Box component='span' sx={{ color: 'text.primary' }}>{props.regardingText}</Box>
      </Typography>}

      {props.micError && <InlineError
        severity='danger' error='Looks like this Browser may not support speech recognition. You can try Chrome on Windows or Android instead.' />}

      {props.speakError && <InlineError
        severity='danger' error='Text-to-speech does not appear to be configured. Please set it up in Preferences > Voice.' />}

    </Box>
  );
}


================================================
FILE: src/apps/call/state/store-app-call.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';


// Call settings

interface AppCallStore {

  grayUI: boolean;
  toggleGrayUI: () => void;

  showConversations: boolean;
  toggleShowConversations: () => void;

  showSupport: boolean;
  toggleShowSupport: () => void;

}

export const useAppCallStore = create<AppCallStore>()(persist(
  (_set, _get) => ({

    grayUI: false,
    toggleGrayUI: () => _set(state => ({ grayUI: !state.grayUI })),

    showConversations: true,
    toggleShowConversations: () => _set(state => ({ showConversations: !state.showConversations })),

    showSupport: true,
    toggleShowSupport: () => _set(state => ({ showSupport: !state.showSupport })),

  }), {
    name: 'app-app-call',
  },
));



================================================
FILE: src/apps/call/state/useMockPersonas.tsx
================================================
import * as React from 'react';

import { usePurposeStore } from '../../chat/components/persona-selector/store-purposes';

import { SystemPurposeData, SystemPurposeId, SystemPurposes } from '../../../data';


/**
 * This is a 'mock' persona because Soon we'll have real personas definitions
 * and stores. Until then, we just mimic a reactive system here.
 */
export interface MockPersona extends SystemPurposeData {
  personaId: SystemPurposeId,
}

export function useMockPersonas(): { personas: MockPersona[], personaIDs: SystemPurposeId[] } {
  // only react to hiddenPurposeIDs changes
  const hiddenPurposeIDs = usePurposeStore(state => state.hiddenPurposeIDs);

  // Dependency array is empty because SystemPurposes is constant
  return React.useMemo(() => {
    const personaIDs = Object.keys(SystemPurposes) as SystemPurposeId[];
    const personas = personaIDs
      .filter((key) => !hiddenPurposeIDs.includes(key))
      .map((key) => ({
        ...SystemPurposes[key as SystemPurposeId],
        personaId: key as SystemPurposeId,
      }));
    return { personas, personaIDs };
  }, [hiddenPurposeIDs]);
}


================================================
FILE: src/apps/chat/AppChat.tsx
================================================
import * as React from 'react';
import { Panel, PanelGroup, PanelResizeHandle } from 'react-resizable-panels';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, useTheme } from '@mui/joy';

import { DEV_MODE_SETTINGS } from '../settings-modal/UxLabsSettings';

import type { DiagramConfig } from '~/modules/aifn/digrams/DiagramsModal';
import type { TradeConfig } from '~/modules/trade/TradeModal';
import { downloadSingleChat, importConversationsFromFilesAtRest, openConversationsAtRestPicker } from '~/modules/trade/trade.client';
import { imaginePromptFromTextOrThrow } from '~/modules/aifn/imagine/imaginePromptFromText';
import { elevenLabsSpeakText } from '~/modules/elevenlabs/elevenlabs.client';
import { useAreBeamsOpen } from '~/modules/beam/store-beam.hooks';
import { useCapabilityTextToImage } from '~/modules/t2i/t2i.client';

import type { DConversation, DConversationId } from '~/common/stores/chat/chat.conversation';
import type { OptimaBarControlMethods } from '~/common/layout/optima/bar/OptimaBarDropdown';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { ConversationsManager } from '~/common/chat-overlay/ConversationsManager';
import { ErrorBoundary } from '~/common/components/ErrorBoundary';
import { LLM_IF_ANT_PromptCaching, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { OptimaDrawerIn, OptimaPanelIn, OptimaToolbarIn } from '~/common/layout/optima/portals/OptimaPortalsIn';
import { PanelResizeInset } from '~/common/components/panes/GoodPanelResizeHandler';
import { Release } from '~/common/app.release';
import { ScrollToBottom } from '~/common/scroll-to-bottom/ScrollToBottom';
import { ScrollToBottomButton } from '~/common/scroll-to-bottom/ScrollToBottomButton';
import { ShortcutKey, useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { WorkspaceIdProvider } from '~/common/stores/workspace/WorkspaceIdProvider';
import { addSnackbar, removeSnackbar } from '~/common/components/snackbar/useSnackbarsStore';
import { createDMessageFromFragments, createDMessagePlaceholderIncomplete, DMessageMetadata, duplicateDMessageMetadata } from '~/common/stores/chat/chat.message';
import { createErrorContentFragment, createTextContentFragment, DMessageAttachmentFragment, DMessageContentFragment, duplicateDMessageFragments } from '~/common/stores/chat/chat.fragments';
import { gcChatImageAssets } from '~/common/stores/chat/chat.gc';
import { getChatLLMId } from '~/common/stores/llms/store-llms';
import { getConversation, getConversationSystemPurposeId, useConversation } from '~/common/stores/chat/store-chats';
import { optimaActions, optimaOpenModels, optimaOpenPreferences } from '~/common/layout/optima/useOptima';
import { useFolderStore } from '~/common/stores/folders/store-chat-folders';
import { useIsMobile, useIsTallScreen } from '~/common/components/useMatchMedia';
import { useLLM } from '~/common/stores/llms/llms.hooks';
import { useModelDomain } from '~/common/stores/llms/hooks/useModelDomain';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';
import { useRouterQuery } from '~/common/app.routes';
import { useUIComplexityIsMinimal } from '~/common/stores/store-ui';
import { useUXLabsStore } from '~/common/stores/store-ux-labs';

import { ChatPane } from './components/layout-pane/ChatPane';
import { ChatBarBeam } from './components/layout-bar/ChatBarBeam';
import { ChatBarAltTitle } from './components/layout-bar/ChatBarAltTitle';
import { ChatBarChat } from './components/layout-bar/ChatBarChat';
import { ChatBeamWrapper } from './components/ChatBeamWrapper';
import { ChatDrawerMemo } from './components/layout-drawer/ChatDrawer';
import { ChatMessageList } from './components/ChatMessageList';
import { Composer } from './components/composer/Composer';
import { PaneTitleOverlay } from './components/PaneTitleOverlay';
import { useComposerAutoHide } from './components/composer/useComposerAutoHide';
import { usePanesManager } from './components/panes/store-panes-manager';

import type { ChatExecuteMode } from './execute-mode/execute-mode.types';

import { _handleExecute } from './editors/_handleExecute';


// what to say when a chat is new and has no title
export const CHAT_NOVEL_TITLE = 'Chat';


export interface AppChatIntent {
  initialConversationId?: string;
  newChat?: 'voiceInput';
}

const scrollToBottomSx = {
  display: 'flex',
  flexDirection: 'column',
};

const chatMessageListSx: SxProps = {
  flexGrow: 1,
};

/*const chatMessageListBrandedSx: SxProps = {
  flexGrow: 1,
  backgroundBlendMode: 'soft-light',
  backgroundColor: themeBgApp,
  backgroundImage: 'url(https://...)',
  backgroundPosition: 'center',
  backgroundRepeat: 'no-repeat',
  backgroundSize: 'contain',
} as const;*/

const chatBeamWrapperSx: SxProps = {
  flexGrow: 1,
  // we added these after removing the minSize={20} (%) from the containing panel.
  minWidth: '18rem',
  // minHeight: 'calc(100vh - 69px - var(--AGI-Nav-width))',
};

const composerOpenSx: SxProps = {
  // NOTE: disabled on 2025-03-05: conflicts with the GlobalDragOverlay's
  // zIndex: 21, // just to allocate a surface, and potentially have a shadow
  minWidth: { md: 480 }, // don't get compresses too much on desktop
  // backgroundColor: themeBgAppChatComposer, // inlined in the Composer
  transition: 'background-color 0.5s ease-out',
  borderTop: `1px solid`,
  borderTopColor: 'rgba(var(--joy-palette-neutral-mainChannel, 99 107 116) / 0.4)',
  // hack: eats the bottom of the last message (as it has a 1px divider)
  // NOTE: commented on 2024-05-13, as other content was stepping on the border due to it and missing zIndex
  // mt: '-1px',
} as const;

const composerOpenMobileSx: SxProps = {
  zIndex: 21, // allocates the surface, possibly enables shadow if we like
  pt: 0.5, // have some breathing room
  // boxShadow: '0px -1px 8px -2px rgba(0, 0, 0, 0.4)',
  ...composerOpenSx,
} as const;

// const composerClosedSx: SxProps = {
//   display: 'none',
// };


// Lazy-loaded Modals
const DiagramsModalLazy = React.lazy(() => import('~/modules/aifn/digrams/DiagramsModal').then(module => ({ default: module.DiagramsModal })));
const FlattenerModalLazy = React.lazy(() => import('~/modules/aifn/flatten/FlattenerModal').then(module => ({ default: module.FlattenerModal })));
const TradeModalLazy = React.lazy(() => import('~/modules/trade/TradeModal').then(module => ({ default: module.TradeModal })));


export function AppChat() {

  // state
  const { showPromisedOverlay } = useOverlayComponents();
  const [isComposerMulticast, setIsComposerMulticast] = React.useState(false);
  const [isMessageSelectionMode, setIsMessageSelectionMode] = React.useState(false);
  const [diagramConfig, setDiagramConfig] = React.useState<DiagramConfig | null>(null);
  const [tradeConfig, setTradeConfig] = React.useState<TradeConfig | null>(null);
  const [flattenConversationId, setFlattenConversationId] = React.useState<DConversationId | null>(null);
  const showNextTitleChange = React.useRef(false);
  const llmDropdownRef = React.useRef<OptimaBarControlMethods>(null);
  const personaDropdownRef = React.useRef<OptimaBarControlMethods>(null);
  const composerTextAreaRef = React.useRef<HTMLTextAreaElement>(null);
  const [_activeFolderId, setActiveFolderId] = React.useState<string | null>(null);

  // external state
  const theme = useTheme();
  const [composerHasContent, setComposerHasContent] = React.useState(false);

  const isMobile = useIsMobile();
  const isTallScreen = useIsTallScreen();

  const isZenMode = useUIComplexityIsMinimal();

  const intent = useRouterQuery<Partial<AppChatIntent>>();

  const showAltTitleBar = useUXLabsStore(state => DEV_MODE_SETTINGS && state.labsChatBarAlt === 'title');

  const { domainModelId: chatLLMId } = useModelDomain('primaryChat');
  const chatLLM = useLLM(chatLLMId) ?? null;

  const {
    // state
    chatPanes,
    focusedPaneConversationId, // <-- key
    focusedPaneIndex,
    // actions
    navigateHistoryInFocusedPane,
    openConversationInFocusedPane,
    openConversationInSplitPane,
    removePane,
    setFocusedPaneIndex,
  } = usePanesManager();

  const { paneUniqueConversationIds, paneHandlers, paneBeamStores } = React.useMemo(() => {
    const paneConversationIds: (DConversationId | null)[] = chatPanes.map(pane => pane.conversationId || null);
    const paneHandlers = paneConversationIds.map(cId => cId ? ConversationsManager.getHandler(cId) : null);
    const paneBeamStores = paneHandlers.map(handler => handler?.getBeamStore() ?? null);
    const paneUniqueConversationIds = Array.from(new Set(paneConversationIds.filter(Boolean))) as DConversationId[];
    return {
      paneHandlers: paneHandlers,
      paneBeamStores: paneBeamStores,
      paneUniqueConversationIds: paneUniqueConversationIds,
    };
  }, [chatPanes]);

  const beamsOpens = useAreBeamsOpen(paneBeamStores);
  const beamOpenStoreInFocusedPane = focusedPaneIndex === null ? null
    : !beamsOpens?.[focusedPaneIndex] ? null
      : paneBeamStores?.[focusedPaneIndex] ?? null;

  const {
    // focused
    title: focusedChatTitle,
    isEmpty: isFocusedChatEmpty,
    isDeveloper: isFocusedChatDeveloper,
    conversationIdx: focusedChatNumber,
    // all
    hasConversations,
    recycleNewConversationId,
    // actions
    prependNewConversation,
    branchConversation,
    deleteConversations,
  } = useConversation(focusedPaneConversationId);

  // this will be used for the side panel
  // const focusedConversationWorkspaceId = workspaceForConversationIdentity(focusedPaneConversationId);
  //// const focusedConversationWorkspace = useWorkspaceIdForConversation(focusedPaneConversationId);

  const { mayWork: capabilityHasT2I, mayEdit: capabilityHasT2IEdit } = useCapabilityTextToImage();

  const activeFolderId = useFolderStore(({ enableFolders, folders }) => {
    const activeFolderId = enableFolders ? _activeFolderId : null;
    const activeFolder = activeFolderId ? folders.find(folder => folder.id === activeFolderId) : null;
    return activeFolder?.id ?? null;
  });

  // Composer Auto-hiding
  const forceComposerHide = !!beamOpenStoreInFocusedPane;
  const composerAutoHide = useComposerAutoHide(forceComposerHide, composerHasContent);

  // Window actions

  const isMultiPane = chatPanes.length >= 2;
  const isMultiAddable = chatPanes.length < 4;
  const isMultiConversationId = paneUniqueConversationIds.length >= 2;
  const willMulticast = isComposerMulticast && isMultiConversationId;
  const disableNewButton = isFocusedChatEmpty && !isMultiPane;

  const handleOpenConversationInFocusedPane = React.useCallback((conversationId: DConversationId | null) => {
    conversationId && openConversationInFocusedPane(conversationId);
  }, [openConversationInFocusedPane]);

  const handleOpenConversationInSplitPane = React.useCallback((conversationId: DConversationId | null) => {
    conversationId && openConversationInSplitPane(conversationId);
  }, [openConversationInSplitPane]);

  const handleNavigateHistoryInFocusedPane = React.useCallback((direction: 'back' | 'forward') => {
    if (navigateHistoryInFocusedPane(direction))
      showNextTitleChange.current = true;
  }, [navigateHistoryInFocusedPane]);


  // Execution

  const handleExecuteAndOutcome = React.useCallback(async (chatExecuteMode: ChatExecuteMode, conversationId: DConversationId, callerNameDebug: string) => {
    const outcome = await _handleExecute(chatExecuteMode, conversationId, callerNameDebug);
    if (outcome === 'err-no-chatllm')
      optimaOpenModels();
    else if (outcome === 'err-t2i-unconfigured')
      optimaOpenPreferences('draw');
    else if (outcome === 'err-no-persona')
      addSnackbar({ key: 'chat-no-persona', message: 'No persona selected.', type: 'issue', overrides: { autoHideDuration: 4000 } });
    else if (outcome === 'err-no-conversation')
      addSnackbar({ key: 'chat-no-conversation', message: 'No active conversation.', type: 'issue' });
    else if (outcome === 'err-no-last-message')
      addSnackbar({ key: 'chat-no-conversation', message: 'No conversation history.', type: 'issue' });
    return outcome === true;
  }, []);

  const handleComposerAction = React.useCallback((conversationId: DConversationId, chatExecuteMode: ChatExecuteMode, fragments: (DMessageContentFragment | DMessageAttachmentFragment)[], metadata?: DMessageMetadata): boolean => {

    // [multicast] send the message to all the panes
    const uniqueConversationIds = willMulticast
      ? Array.from(new Set([conversationId, ...paneUniqueConversationIds]))
      : [conversationId];

    // validate conversation existence
    const uniqueConverations = uniqueConversationIds.map(cId => getConversation(cId)).filter(Boolean) as DConversation[];
    if (!uniqueConverations.length)
      return false;

    // we loop to handle both the normal and multicast modes
    for (const conversation of uniqueConverations) {

      // create the user:message
      // NOTE: this can lead to multiple chat messages with data refs that are referring to the same dblobs,
      //       however, we already got transferred ownership of the dblobs at this point.
      const userMessage = createDMessageFromFragments('user', duplicateDMessageFragments(fragments, true)); // [chat] create user:message to send per-chat
      if (metadata) userMessage.metadata = duplicateDMessageMetadata(metadata);

      ConversationsManager.getHandler(conversation.id).messageAppend(userMessage); // [chat] append user message in each conversation

      // fire/forget
      void handleExecuteAndOutcome(chatExecuteMode /* various */, conversation.id, 'chat-composer-action'); // append user message, then '*-*'
    }

    return true;
  }, [paneUniqueConversationIds, handleExecuteAndOutcome, willMulticast]);

  const handleConversationExecuteHistory = React.useCallback(async (conversationId: DConversationId) => {
    await handleExecuteAndOutcome('generate-content', conversationId, 'chat-execute-history'); // replace with 'history', then 'generate-content'
  }, [handleExecuteAndOutcome]);

  const handleMessageRegenerateLastInFocusedPane = React.useCallback(async () => {
    // Ctrl + Shift + Z
    if (!focusedPaneConversationId) return;
    const cHandler = ConversationsManager.getHandler(focusedPaneConversationId);
    if (!cHandler.isValid()) return;
    const inputHistory = cHandler.historyViewHeadOrThrow('chat-regenerate-shortcut');
    if (!inputHistory.length) return;

    // remove the last message if assistant's
    const lastMessage = inputHistory[inputHistory.length - 1];
    if (lastMessage.role === 'assistant')
      cHandler.historyTruncateTo(lastMessage.id, -1);

    // generate: NOTE: this will replace the system message correctly
    await handleExecuteAndOutcome('generate-content', focusedPaneConversationId, 'chat-regenerate-last'); // truncate if assistant, then gen-text
  }, [focusedPaneConversationId, handleExecuteAndOutcome]);

  const handleMessageBeamLastInFocusedPane = React.useCallback(async () => {
    // Ctrl + Shift + B
    if (!focusedPaneConversationId) return;
    const cHandler = ConversationsManager.getHandler(focusedPaneConversationId);
    if (!cHandler.isValid()) return;
    const inputHistory = cHandler.historyViewHeadOrThrow('chat-beam-shortcut');
    if (!inputHistory.length) return;

    // TODO: replace the Persona and Auto-Cache-hint in the history?

    // replace the prompt in history
    const lastMessage = inputHistory[inputHistory.length - 1];
    if (lastMessage.role === 'assistant')
      cHandler.beamInvoke(inputHistory.slice(0, -1), [lastMessage], lastMessage.id);
    else if (lastMessage.role === 'user')
      cHandler.beamInvoke(inputHistory, [], null);
  }, [focusedPaneConversationId]);

  const handleTextDiagram = React.useCallback((diagramConfig: DiagramConfig | null) => setDiagramConfig(diagramConfig), []);

  const handleImagineFromText = React.useCallback(async (conversationId: DConversationId, subjectText: string) => {
    const cHandler = ConversationsManager.getHandler(conversationId);
    if (!cHandler.isValid()) return;
    const userImagineMessage = createDMessagePlaceholderIncomplete('user', `Thinking at the subject...`); // [chat] append user:imagine prompt
    cHandler.messageAppend(userImagineMessage);
    await imaginePromptFromTextOrThrow(subjectText, conversationId)
      .then(imaginedPrompt => {
        // Replace the placeholder with the message to draw, then execute the draw
        cHandler.messageFragmentReplace(userImagineMessage.id, userImagineMessage.fragments[0].fId, createTextContentFragment(imaginedPrompt), true);
        return handleExecuteAndOutcome('generate-image', conversationId, 'chat-imagine-from-text'); // append message for 'imagine', then generate-image
      })
      .catch((error: any) => {
        // Replace the placeholder with the error message
        cHandler.messageFragmentReplace(userImagineMessage.id, userImagineMessage.fragments[0].fId, createErrorContentFragment(`Issue requesting an Image prompt. ${error?.message || ''}`), true);
      });
  }, [handleExecuteAndOutcome]);

  const handleTextSpeak = React.useCallback(async (text: string): Promise<void> => {
    await elevenLabsSpeakText(text, undefined, true, true);
  }, []);


  // Chat actions

  const handleConversationNewInFocusedPane = React.useCallback((forceNoRecycle: boolean, isIncognito: boolean) => {

    // create conversation (or recycle the existing top-of-stack empty conversation)
    const conversationId = (recycleNewConversationId && !forceNoRecycle && !isIncognito)
      ? recycleNewConversationId
      : prependNewConversation(getConversationSystemPurposeId(focusedPaneConversationId) ?? undefined, isIncognito);

    // switch the focused pane to the new conversation
    handleOpenConversationInFocusedPane(conversationId);

    // if a folder is active, add the new conversation to the folder
    if (activeFolderId && conversationId)
      useFolderStore.getState().addConversationToFolder(activeFolderId, conversationId);

    // focus the composer
    if (!isMobile)
      composerTextAreaRef.current?.focus();

  }, [activeFolderId, focusedPaneConversationId, handleOpenConversationInFocusedPane, isMobile, prependNewConversation, recycleNewConversationId]);

  const handleConversationImportDialog = React.useCallback(() => setTradeConfig({ dir: 'import' }), []);

  const handleConversationExport = React.useCallback((conversationId: DConversationId | null, exportAll: boolean) => {
    setTradeConfig({ dir: 'export', conversationId, exportAll });
  }, []);

  const handleConversationsImportFromFiles = React.useCallback(
    (files: File[] | null): Promise<void> =>
      importConversationsFromFilesAtRest(files, true)
        .then((outcome) => {
          // activate the last (most recent) imported conversation
          if (outcome.activateConversationId) {
            showNextTitleChange.current = true;
            handleOpenConversationInFocusedPane(outcome.activateConversationId);
          }
        })
        .catch(() => {
          addSnackbar({ key: 'chat-import-fail', message: 'Could not open file.', type: 'issue' });
        }),
    [handleOpenConversationInFocusedPane],
  );

  const handleConversationsImportFormFilePicker = React.useCallback(
    () => openConversationsAtRestPicker().then(handleConversationsImportFromFiles),
    [handleConversationsImportFromFiles],
  );

  const handleFileSaveConversation = React.useCallback((conversationId: DConversationId | null) => {
    const conversation = getConversation(conversationId);
    conversation && downloadSingleChat(conversation, 'json')
      .then(() => {
        addSnackbar({ key: 'chat-save-as-ok', message: 'File saved.', type: 'success' });
      })
      .catch((err: any) => {
        if (err?.name !== 'AbortError')
          addSnackbar({ key: 'chat-save-as-fail', message: `Could not save the file. ${err?.message || ''}`, type: 'issue' });
      });
  }, []);

  const handleConversationBranch = React.useCallback((srcConversationId: DConversationId, messageId: string | null, addSplitPane: boolean): DConversationId | null => {
    // clone data
    const branchedConversationId = branchConversation(srcConversationId, messageId);

    // if a folder is active, add the new conversation to the folder
    if (activeFolderId && branchedConversationId)
      useFolderStore.getState().addConversationToFolder(activeFolderId, branchedConversationId);

    // replace/open a new pane with this
    showNextTitleChange.current = true;
    if (addSplitPane && isMultiAddable)
      handleOpenConversationInSplitPane(branchedConversationId);
    else
      handleOpenConversationInFocusedPane(branchedConversationId);

    return branchedConversationId;
  }, [activeFolderId, branchConversation, handleOpenConversationInFocusedPane, handleOpenConversationInSplitPane, isMultiAddable]);

  const handleConversationFlatten = React.useCallback((conversationId: DConversationId) => setFlattenConversationId(conversationId), []);

  const handleConversationReset = React.useCallback(async (conversationId: DConversationId) => {
    if (await showPromisedOverlay('chat-reset-confirmation', { rejectWithValue: false }, ({ onResolve, onUserReject }) =>
      <ConfirmationModal
        open onClose={onUserReject} onPositive={() => onResolve(true)}
        confirmationText='This will clear all messages while keeping the current chat settings, model, and persona. Do you want to continue?'
        positiveActionText='Restart Chat'
        title='Restart Chat'
      />,
    )) {
      ConversationsManager.getHandler(conversationId).historyClear();
    }
  }, [showPromisedOverlay]);

  const handleDeleteConversations = React.useCallback(async (conversationIds: DConversationId[], bypassConfirmation: boolean) => {

    // show confirmation dialog
    if (!bypassConfirmation && !await showPromisedOverlay('chat-delete-confirmation', { rejectWithValue: false }, ({ onResolve, onUserReject }) =>
      <ConfirmationModal
        open onClose={onUserReject} onPositive={() => onResolve(true)}
        confirmationText={`Are you absolutely sure you want to delete ${conversationIds.length === 1 ? 'this conversation' : 'these conversations'}? This action cannot be undone.`}
        positiveActionText={conversationIds.length === 1 ? 'Delete conversation' : `Yes, delete all ${conversationIds.length} conversations`}
      />,
    )) return;

    // perform deletion, and return the next (or a new) conversation
    const nextConversationId = deleteConversations(conversationIds, /*focusedSystemPurposeId ??*/ undefined);

    // switch the focused pane to the new conversation - NOTE: this makes the assumption that deletion had impact on the focused pane
    handleOpenConversationInFocusedPane(nextConversationId);

    // run GC for dblobs in this conversation
    void gcChatImageAssets(); // fire/forget
  }, [showPromisedOverlay, deleteConversations, handleOpenConversationInFocusedPane]);


  // Pluggable Optima components

  const barAltTitle = showAltTitleBar ? focusedChatTitle ?? 'No Chat' : null;

  const focusedBarContent = React.useMemo(() => beamOpenStoreInFocusedPane
      ? <ChatBarBeam conversationTitle={focusedChatTitle ?? 'No Chat'} beamStore={beamOpenStoreInFocusedPane} isMobile={isMobile} />
      : (barAltTitle === null)
        ? <ChatBarChat conversationId={focusedPaneConversationId} llmDropdownRef={llmDropdownRef} personaDropdownRef={personaDropdownRef} />
        : <ChatBarAltTitle conversationId={focusedPaneConversationId} conversationTitle={barAltTitle} />
    , [barAltTitle, beamOpenStoreInFocusedPane, focusedChatTitle, focusedPaneConversationId, isMobile],
  );


  // Disabled by default, as it lags the opening of the drawer and immediatly vanishes during the closing animation
  const isDrawerOpen = true; // useOptimaDrawerOpen();

  const drawerContent = React.useMemo(() => !isDrawerOpen ? null :
      <ChatDrawerMemo
        // isMobile={isMobile /* expensive as it undoes the memo; not passed anymore */}
        activeConversationId={focusedPaneConversationId}
        activeFolderId={activeFolderId}
        chatPanesConversationIds={paneUniqueConversationIds}
        disableNewButton={disableNewButton}
        onConversationActivate={handleOpenConversationInFocusedPane}
        onConversationBranch={handleConversationBranch}
        onConversationNew={handleConversationNewInFocusedPane}
        onConversationsDelete={handleDeleteConversations}
        onConversationsExportDialog={handleConversationExport}
        onConversationsImportDialog={handleConversationImportDialog}
        setActiveFolderId={setActiveFolderId}
      />,
    [activeFolderId, disableNewButton, focusedPaneConversationId, handleConversationBranch, handleConversationExport, handleConversationImportDialog, handleConversationNewInFocusedPane, handleDeleteConversations, handleOpenConversationInFocusedPane, isDrawerOpen, paneUniqueConversationIds],
  );

  const focusedChatPanelContent = React.useMemo(() => !focusedPaneConversationId ? null :
      <ChatPane
        conversationId={focusedPaneConversationId}
        disableItems={!focusedPaneConversationId || isFocusedChatEmpty}
        hasConversations={hasConversations}
        isMessageSelectionMode={isMessageSelectionMode}
        isVerticalSplit={isMobile || isTallScreen}
        onConversationBranch={handleConversationBranch}
        onConversationClear={handleConversationReset}
        onConversationFlatten={handleConversationFlatten}
        // onConversationNew={handleConversationNewInFocusedPane}
        setIsMessageSelectionMode={setIsMessageSelectionMode}
      />,
    [focusedPaneConversationId, handleConversationBranch, handleConversationFlatten, handleConversationReset, hasConversations, isFocusedChatEmpty, isMessageSelectionMode, isMobile, isTallScreen],
  );


  // Effects

  // [effect] Handle the conversation intent
  React.useEffect(() => {
    // Debug: open a null chat
    if (Release.IsNodeDevBuild && intent.initialConversationId === 'null')
      openConversationInFocusedPane(null! /* for debugging purporse */);
    // Open the initial conversation if set
    else if (intent.initialConversationId)
      openConversationInFocusedPane(intent.initialConversationId);
    // Create a new chat if requested
    else if (intent.newChat !== undefined)
      handleConversationNewInFocusedPane(false, false);
  }, [handleConversationNewInFocusedPane, intent.initialConversationId, intent.newChat, openConversationInFocusedPane]);

  // [effect] Show snackbar with the focused chat title after a history navigation in focused pane
  React.useEffect(() => {
    if (showNextTitleChange.current) {
      showNextTitleChange.current = false;
      const title = (focusedChatNumber >= 0 ? `#${focusedChatNumber + 1} · ` : '') + (focusedChatTitle || 'New Chat');
      const id = addSnackbar({ key: 'focused-title', message: title, type: 'center-title' });
      return () => removeSnackbar(id);
    }
  }, [focusedChatNumber, focusedChatTitle]);


  // Shortcuts

  const handleOpenChatLlmOptions = React.useCallback(() => {
    const chatLLMId = getChatLLMId();
    if (!chatLLMId) return;
    optimaActions().openModelOptions(chatLLMId);
  }, []);

  const handleMoveFocus = React.useCallback((direction: number, wholeList?: boolean) => {
    // find the parent list
    let messageListElement: HTMLElement | null;
    let withinBeam = false;
    const activeElement = document.activeElement as HTMLElement;
    if (activeElement) {
      messageListElement = document.querySelector('[role=beam-list]') as HTMLElement;
      if (!messageListElement)
        messageListElement = activeElement.closest('[role=chat-messages-list]') as HTMLElement;
      else
        withinBeam = true;
    } else
      messageListElement = document.querySelector('[role=chat-messages-list]') as HTMLElement;
    if (!messageListElement) return;

    // find the scrollable container and if we're at the bottom
    const scrollContainer = messageListElement.closest('[role=scrollable]') as HTMLElement;
    if (!scrollContainer) return;
    const isAtBottom = Math.abs(scrollContainer.scrollHeight - scrollContainer.scrollTop - scrollContainer.clientHeight) < 1;

    // determine the current message and next index
    const messageElements = Array.from(messageListElement.querySelectorAll(withinBeam ? '[role=beam-card]' : '[role=chat-message]')) as HTMLElement[];
    const currentIndex = messageElements.findIndex(el => el.contains(activeElement));

    // if going down and we're at/past the last message, scroll to bottom
    const snapToBottom = direction > 0 && (wholeList || (currentIndex === -1 || currentIndex >= messageElements.length - 1));
    const nextIndex = (wholeList && direction < 0) ? 0
      : snapToBottom ? messageElements.length - 1
        : (isAtBottom && direction < 0) ? currentIndex
          : currentIndex === -1 ? (direction < 0 ? 0 : messageElements.length - 1)
            : currentIndex + direction;
    if (nextIndex < 0 || nextIndex >= messageElements.length) return;

    // perform the smooth scroll and focus
    const targetElement = messageElements[nextIndex];
    targetElement.focus({ preventScroll: true, focusVisible: true } as FocusOptions);
    targetElement.scrollIntoView({ behavior: 'smooth', block: snapToBottom ? 'end' : 'start' });
  }, []);

  useGlobalShortcuts('AppChat', React.useMemo(() => [
    // focused conversation
    { key: 'z', ctrl: true, shift: true, disabled: isFocusedChatEmpty, action: handleMessageRegenerateLastInFocusedPane, description: 'Retry' },
    { key: 'b', ctrl: true, shift: true, disabled: isFocusedChatEmpty, action: handleMessageBeamLastInFocusedPane, description: 'Beam Edit' },
    { key: 'o', ctrl: true, action: handleConversationsImportFormFilePicker },
    { key: 's', ctrl: true, action: () => handleFileSaveConversation(focusedPaneConversationId) },
    { key: 'n', ctrl: true, shift: true, action: () => handleConversationNewInFocusedPane(false, false) },
    { key: 'x', ctrl: true, shift: true, action: () => isFocusedChatEmpty || (focusedPaneConversationId && handleConversationReset(focusedPaneConversationId)) },
    { key: 'd', ctrl: true, shift: true, action: () => focusedPaneConversationId && handleDeleteConversations([focusedPaneConversationId], false) },
    { key: '[', ctrl: true, action: () => handleNavigateHistoryInFocusedPane('back') },
    { key: ']', ctrl: true, action: () => handleNavigateHistoryInFocusedPane('forward') },
    // change active message (in any possible panel)
    { key: ShortcutKey.Up, ctrl: true, action: () => handleMoveFocus(-1) },
    { key: ShortcutKey.Down, ctrl: true, action: () => handleMoveFocus(1) },
    { key: ShortcutKey.Up, ctrl: true, shift: true, action: () => handleMoveFocus(-1, true) },
    { key: ShortcutKey.Down, ctrl: true, shift: true, action: () => handleMoveFocus(1, true) },
    // open the dropdowns
    { key: 'l', ctrl: true, action: () => llmDropdownRef.current?.openListbox() /*, description: 'Open Models Dropdown'*/ },
    { key: 'p', ctrl: true, action: () => personaDropdownRef.current?.openListbox() /*, description: 'Open Persona Dropdown'*/ },
    // focused conversation llm
    { key: 'o', ctrl: true, shift: true, action: handleOpenChatLlmOptions },
  ], [focusedPaneConversationId, handleConversationNewInFocusedPane, handleConversationReset, handleConversationsImportFormFilePicker, handleDeleteConversations, handleFileSaveConversation, handleMessageBeamLastInFocusedPane, handleMessageRegenerateLastInFocusedPane, handleMoveFocus, handleNavigateHistoryInFocusedPane, handleOpenChatLlmOptions, isFocusedChatEmpty]));


  return <>

    {/* -> Toolbar, -> Drawer, -> Panel*/}
    <OptimaToolbarIn>{focusedBarContent}</OptimaToolbarIn>
    <OptimaDrawerIn>{drawerContent}</OptimaDrawerIn>
    <OptimaPanelIn>{focusedChatPanelContent}</OptimaPanelIn>

    <PanelGroup
      direction={(isMobile || isTallScreen) ? 'vertical' : 'horizontal'}
      id='app-chat-panels'
    >

      {chatPanes.map((pane, idx) => {
        const _paneIsFocused = idx === focusedPaneIndex;
        const _paneConversationId = pane.conversationId;
        const _paneChatHandler = paneHandlers[idx] ?? null;
        const _paneIsIncognito = _paneChatHandler?.isIncognito() ?? false;
        const _paneBeamStoreApi = paneBeamStores[idx] ?? null;
        const _paneBeamIsOpen = !!beamsOpens?.[idx] && !!_paneBeamStoreApi;
        const _panesCount = chatPanes.length;
        const _keyAndId = `chat-pane-${pane.paneId}`;
        const _sepId = `sep-pane-${idx}`;
        return <WorkspaceIdProvider conversationId={_paneIsFocused ? _paneConversationId : null} key={_keyAndId}><ErrorBoundary>

          <Panel
            id={_keyAndId}
            order={idx}
            collapsible={chatPanes.length === 2}
            defaultSize={(_panesCount === 3 && idx === 1) ? 34 : Math.round(100 / _panesCount)}
            // minSize={20 /* IMPORTANT: this forces a reflow even on a simple on hover */}
            onClick={(event) => {
              // Alt + Click: undocumented feature to clear focus
              if (event.altKey && chatPanes.length > 1)
                return setFocusedPaneIndex(-1);
              setFocusedPaneIndex(idx);
            }}
            onCollapse={() => {
              // NOTE: despite the delay to try to let the draggin settle, there seems to be an issue with the Pane locking the screen
              // setTimeout(() => removePane(idx), 50);
              // more than 2 will result in an assertion from the framework
              if (chatPanes.length === 2) removePane(idx);
            }}
            style={{
              // for anchoring the scroll button in place
              position: 'relative',
              ...(isMultiPane ? {
                marginBottom: '1px', // compensates for the -1px in `composerOpenSx` for the Composer offset
                borderRadius: '0.375rem',
                borderStyle: 'solid',
                borderColor: _paneIsFocused
                  ? ((willMulticast || !isMultiConversationId) ? theme.palette.primary.solidBg : theme.palette.primary.solidBg)
                  : ((willMulticast || !isMultiConversationId) ? theme.palette.primary.softActiveBg : theme.palette.divider),
                borderWidth: '2px',
                // borderBottomWidth: '3px',
                // DISABLED on 2024-03-13, it gets in the way quite a lot
                // filter: (!willMulticast && !_paneIsFocused)
                //   ? (!isMultiConversationId ? 'grayscale(66.67%)' /* clone of the same */ : 'grayscale(66.67%)')
                //   : undefined,
                // 2025-02-27: didn't try, here's another version
                // filter: _paneIsFocused ? 'none' : 'brightness(0.94) saturate(0.9)',
              } : {
                // NOTE: this is a workaround for the 'stuck-after-collapse-close' issue. We will collapse the 'other' pane, which
                // will get it removed (onCollapse), and somehow this pane will be stuck with a pointerEvents: 'none' style, which de-facto
                // disables further interaction with the chat. This is a workaround to re-enable the pointer events.
                // The root cause seems to be a Dragstate not being reset properly, however the pointerEvents has been set since 0.0.56 while
                // it was optional before: https://github.com/bvaughn/react-resizable-panels/issues/241
                pointerEvents: 'auto',
              }),
              ...((_paneIsIncognito && {
                backgroundColor: theme.palette.background.level3,
                backgroundImage: 'repeating-linear-gradient(45deg, rgba(0,0,0,0.03), rgba(0,0,0,0.03) 10px, transparent 10px, transparent 20px)',
              })),
            }}
          >

            {isMultiPane && !isZenMode && (
              <PaneTitleOverlay
                paneIdx={idx}
                conversationId={_paneConversationId}
                isFocused={_paneIsFocused}
                isIncognito={_paneIsIncognito}
                onConversationDelete={handleDeleteConversations}
              />
            )}

            <ScrollToBottom
              bootToBottom
              stickToBottomInitial
              disableAutoStick={isMobile && _paneBeamIsOpen}
              sx={scrollToBottomSx}
            >

              {!_paneBeamIsOpen && (
                <ChatMessageList
                  conversationId={_paneConversationId}
                  conversationHandler={_paneChatHandler}
                  capabilityHasT2I={capabilityHasT2I}
                  chatLLMAntPromptCaching={chatLLM?.interfaces?.includes(LLM_IF_ANT_PromptCaching) ?? false}
                  chatLLMContextTokens={chatLLM?.contextTokens ?? null}
                  chatLLMSupportsImages={chatLLM?.interfaces?.includes(LLM_IF_OAI_Vision) ?? false}
                  fitScreen={isMobile || isMultiPane}
                  isMobile={isMobile}
                  isMessageSelectionMode={isMessageSelectionMode}
                  setIsMessageSelectionMode={setIsMessageSelectionMode}
                  onConversationBranch={handleConversationBranch}
                  onConversationExecuteHistory={handleConversationExecuteHistory}
                  onConversationNew={handleConversationNewInFocusedPane}
                  onTextDiagram={handleTextDiagram}
                  onTextImagine={handleImagineFromText}
                  onTextSpeak={handleTextSpeak}
                  sx={chatMessageListSx}
                />
              )}

              {_paneBeamIsOpen && (
                <ChatBeamWrapper
                  beamStore={_paneBeamStoreApi}
                  isMobile={isMobile}
                  inlineSx={chatBeamWrapperSx}
                />
              )}

              {/* Visibility and actions are handled via Context */}
              <ScrollToBottomButton />

            </ScrollToBottom>

          </Panel>

          {/* Panel Separators & Resizers */}
          {idx < _panesCount - 1 && (
            <PanelResizeHandle id={_sepId}>
              <PanelResizeInset />
            </PanelResizeHandle>
          )}

        </ErrorBoundary></WorkspaceIdProvider>;
      })}

    </PanelGroup>

    {/* Composer with auto-hide */}
    <Box {...composerAutoHide.compressorProps}>
      <div style={composerAutoHide.compressibleStyle}>
        <Composer
          isMobile={isMobile}
          chatLLM={chatLLM}
          composerTextAreaRef={composerTextAreaRef}
          targetConversationId={focusedPaneConversationId}
          capabilityHasT2I={capabilityHasT2I}
          capabilityHasT2IEdit={capabilityHasT2IEdit}
          isMulticast={!isMultiConversationId ? null : isComposerMulticast}
          isDeveloperMode={isFocusedChatDeveloper}
          onAction={handleComposerAction}
          onConversationBeamEdit={handleMessageBeamLastInFocusedPane}
          onConversationsImportFromFiles={handleConversationsImportFromFiles}
          onTextImagine={handleImagineFromText}
          setIsMulticast={setIsComposerMulticast}
          onComposerHasContent={setComposerHasContent}
          sx={isMobile ? composerOpenMobileSx : composerOpenSx}
        />
      </div>
    </Box>

    {/* Hover zone for auto-hide */}
    {!forceComposerHide && composerAutoHide.isHidden && <Box {...composerAutoHide.detectorProps} />}

    {/* Diagrams */}
    {!!diagramConfig && (
      <React.Suspense fallback={null}>
        <DiagramsModalLazy
          config={diagramConfig}
          onClose={() => setDiagramConfig(null)}
        />
      </React.Suspense>
    )}

    {/* Flatten */}
    {!!flattenConversationId && (
      <React.Suspense fallback={null}>
        <FlattenerModalLazy
          conversationId={flattenConversationId}
          onConversationBranch={handleConversationBranch}
          onClose={() => setFlattenConversationId(null)}
        />
      </React.Suspense>
    )}

    {/* Import / Export  */}
    {!!tradeConfig && (
      <React.Suspense fallback={null}>
        <TradeModalLazy
          config={tradeConfig}
          onConversationActivate={handleOpenConversationInFocusedPane}
          onClose={() => setTradeConfig(null)}
        />
      </React.Suspense>
    )}

  </>;
}



================================================
FILE: src/apps/chat/store-app-chat.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import { useShallow } from 'zustand/react/shallow';

import type { DLLMId } from '~/common/stores/llms/llms.types';


export type ChatAutoSpeakType = 'off' | 'firstLine' | 'all';


// Chat Settings (Chat AI & Chat UI)

interface AppChatStore {

  // chat AI

  autoSpeak: ChatAutoSpeakType;
  setAutoSpeak: (autoSpeak: ChatAutoSpeakType) => void;

  autoSuggestAttachmentPrompts: boolean;
  setAutoSuggestAttachmentPrompts: (autoSuggestAttachmentPrompts: boolean) => void;

  autoSuggestDiagrams: boolean,
  setAutoSuggestDiagrams: (autoSuggestDiagrams: boolean) => void;

  autoSuggestHTMLUI: boolean;
  setAutoSuggestHTMLUI: (autoSuggestHTMLUI: boolean) => void;

  autoSuggestQuestions: boolean,
  setAutoSuggestQuestions: (autoSuggestQuestions: boolean) => void;

  autoTitleChat: boolean;
  setAutoTitleChat: (autoTitleChat: boolean) => void;

  autoVndAntBreakpoints: boolean;
  setAutoVndAntBreakpoints: (autoVndAntBreakpoints: boolean) => void;

  chatKeepLastThinkingOnly: boolean,
  setChatKeepLastThinkingOnly: (chatKeepLastThinkingOnly: boolean) => void;

  // chat UI

  clearFilters: () => void;

  filterHasDocFragments: boolean;
  toggleFilterHasDocFragments: () => void;

  filterHasImageAssets: boolean;
  toggleFilterHasImageAssets: () => void;

  filterHasStars: boolean;
  toggleFilterHasStars: () => void;

  filterIsArchived: boolean;
  toggleFilterIsArchived: () => void;

  micTimeoutMs: number;
  setMicTimeoutMs: (micTimeoutMs: number) => void;

  showPersonaIcons2: boolean;
  toggleShowPersonaIcons: () => void;

  showRelativeSize: boolean;
  toggleShowRelativeSize: () => void;

  showTextDiff: boolean;
  setShowTextDiff: (showTextDiff: boolean) => void;

  showSystemMessages: boolean;
  setShowSystemMessages: (showSystemMessages: boolean) => void;

  // other chat-specific configuration

  notificationEnabledModelIds: DLLMId[];
  setNotificationEnabledForModel: (modelId: DLLMId, enabled: boolean) => void;
  isNotificationEnabledForModel: (modelId: DLLMId) => boolean;

}


const useAppChatStore = create<AppChatStore>()(persist(
  (_set, _get) => ({

    // Chat AI

    autoSpeak: 'off',
    setAutoSpeak: (autoSpeak: ChatAutoSpeakType) => _set({ autoSpeak }),

    autoSuggestAttachmentPrompts: false,
    setAutoSuggestAttachmentPrompts: (autoSuggestAttachmentPrompts: boolean) => _set({ autoSuggestAttachmentPrompts }),

    autoSuggestDiagrams: false,
    setAutoSuggestDiagrams: (autoSuggestDiagrams: boolean) => _set({ autoSuggestDiagrams }),

    autoSuggestHTMLUI: false,
    setAutoSuggestHTMLUI: (autoSuggestHTMLUI: boolean) => _set({ autoSuggestHTMLUI }),

    autoSuggestQuestions: false,
    setAutoSuggestQuestions: (autoSuggestQuestions: boolean) => _set({ autoSuggestQuestions }),

    autoTitleChat: true,
    setAutoTitleChat: (autoTitleChat: boolean) => _set({ autoTitleChat }),

    autoVndAntBreakpoints: true, // 2024-08-24: on as it saves user's money
    setAutoVndAntBreakpoints: (autoVndAntBreakpoints: boolean) => _set({ autoVndAntBreakpoints }),

    chatKeepLastThinkingOnly: true,
    setChatKeepLastThinkingOnly: (chatKeepLastThinkingOnly: boolean) => _set({ chatKeepLastThinkingOnly }),

    // Chat UI

    clearFilters: () => _set({ filterIsArchived: false, filterHasDocFragments: false, filterHasImageAssets: false, filterHasStars: false }),

    filterHasDocFragments: false,
    toggleFilterHasDocFragments: () => _set(({ filterHasDocFragments }) => ({ filterHasDocFragments: !filterHasDocFragments })),

    filterHasImageAssets: false,
    toggleFilterHasImageAssets: () => _set(({ filterHasImageAssets }) => ({ filterHasImageAssets: !filterHasImageAssets })),

    filterHasStars: false,
    toggleFilterHasStars: () => _set(({ filterHasStars }) => ({ filterHasStars: !filterHasStars })),

    filterIsArchived: false,
    toggleFilterIsArchived: () => _set(({ filterIsArchived }) => ({ filterIsArchived: !filterIsArchived })),

    micTimeoutMs: 5000,
    setMicTimeoutMs: (micTimeoutMs: number) => _set({ micTimeoutMs }),

    // new default on 2024-11-18: disable icons by default, too confusing
    showPersonaIcons2: false,
    toggleShowPersonaIcons: () => _set(({ showPersonaIcons2 }) => ({ showPersonaIcons2: !showPersonaIcons2 })),

    showRelativeSize: false,
    toggleShowRelativeSize: () => _set(({ showRelativeSize }) => ({ showRelativeSize: !showRelativeSize })),

    showTextDiff: false,
    setShowTextDiff: (showTextDiff: boolean) => _set({ showTextDiff }),

    showSystemMessages: false,
    setShowSystemMessages: (showSystemMessages: boolean) => _set({ showSystemMessages }),

    // Other chat-specific configuration

    notificationEnabledModelIds: [],
    setNotificationEnabledForModel: (modelId: DLLMId, enabled: boolean) => {
      const notificationEnabledModelIds = _get().notificationEnabledModelIds;
      if (!enabled)
        _set({ notificationEnabledModelIds: notificationEnabledModelIds.filter(id => id !== modelId) });
      else if (!notificationEnabledModelIds.includes(modelId))
        _set({ notificationEnabledModelIds: [...notificationEnabledModelIds, modelId] });
    },
    isNotificationEnabledForModel: (modelId: DLLMId) => _get().notificationEnabledModelIds.includes(modelId),

  }), {
    name: 'app-app-chat',
    version: 1,

    onRehydrateStorage: () => (state) => {
      if (!state) return;

      // for now, let text diff be off by default
      state.showTextDiff = false;
    },

    migrate: (state: any, fromVersion: number): AppChatStore => {
      // 0 -> 1: autoTitleChat was off by mistake - turn it on [Remove past Dec 1, 2023]
      if (state && fromVersion < 1)
        state.autoTitleChat = true;
      return state;
    },
  },
));


export const useChatAutoAI = () => useAppChatStore(useShallow(state => ({
  autoSpeak: state.autoSpeak,
  autoSuggestAttachmentPrompts: state.autoSuggestAttachmentPrompts,
  autoSuggestDiagrams: state.autoSuggestDiagrams,
  autoSuggestHTMLUI: state.autoSuggestHTMLUI,
  autoSuggestQuestions: state.autoSuggestQuestions,
  autoTitleChat: state.autoTitleChat,
  autoVndAntBreakpoints: state.autoVndAntBreakpoints,
  chatKeepLastThinkingOnly: state.chatKeepLastThinkingOnly,
  setAutoSpeak: state.setAutoSpeak,
  setAutoSuggestAttachmentPrompts: state.setAutoSuggestAttachmentPrompts,
  setAutoSuggestDiagrams: state.setAutoSuggestDiagrams,
  setAutoSuggestHTMLUI: state.setAutoSuggestHTMLUI,
  setAutoSuggestQuestions: state.setAutoSuggestQuestions,
  setAutoTitleChat: state.setAutoTitleChat,
  setAutoVndAntBreakpoints: state.setAutoVndAntBreakpoints,
  setChatKeepLastThinkingOnly: state.setChatKeepLastThinkingOnly,
})));

export const getChatAutoAI = (): {
  autoSpeak: ChatAutoSpeakType,
  autoSuggestAttachmentPrompts: boolean,
  autoSuggestDiagrams: boolean,
  autoSuggestHTMLUI: boolean,
  autoSuggestQuestions: boolean,
  autoTitleChat: boolean,
  autoVndAntBreakpoints: boolean,
  chatKeepLastThinkingOnly: boolean,
} => useAppChatStore.getState();

export const useChatAutoSuggestHTMLUI = (): boolean =>
  useAppChatStore(state => state.autoSuggestHTMLUI);

export const useChatAutoSuggestAttachmentPrompts = (): boolean =>
  useAppChatStore(state => state.autoSuggestAttachmentPrompts);

export const useChatMicTimeoutMsValue = (): number =>
  useAppChatStore(state => state.micTimeoutMs);

export const useChatMicTimeoutMs = (): [number, (micTimeoutMs: number) => void] =>
  useAppChatStore(useShallow(state => [state.micTimeoutMs, state.setMicTimeoutMs]));

export function useChatDrawerFilters() {
  return useAppChatStore(useShallow(state => ({
    filterHasDocFragments: state.filterHasDocFragments,
    filterHasImageAssets: state.filterHasImageAssets,
    filterHasStars: state.filterHasStars,
    filterIsArchived: state.filterIsArchived,
    showPersonaIcons: state.showPersonaIcons2,
    showRelativeSize: state.showRelativeSize,
    clearFilters: state.clearFilters,
    toggleFilterHasDocFragments: state.toggleFilterHasDocFragments,
    toggleFilterHasImageAssets: state.toggleFilterHasImageAssets,
    toggleFilterHasStars: state.toggleFilterHasStars,
    toggleFilterIsArchived: state.toggleFilterIsArchived,
    toggleShowPersonaIcons: state.toggleShowPersonaIcons,
    toggleShowRelativeSize: state.toggleShowRelativeSize,
  })));
}

export const useChatShowTextDiff = (): [boolean, (showDiff: boolean) => void] =>
  useAppChatStore(useShallow(state => [state.showTextDiff, state.setShowTextDiff]));

export const getChatShowSystemMessages = (): boolean =>
  useAppChatStore.getState().showSystemMessages;

export const useChatShowSystemMessages = (): [boolean, (showSystemMessages: boolean) => void] =>
  useAppChatStore(useShallow(state => [state.showSystemMessages, state.setShowSystemMessages]));

export const getIsNotificationEnabledForModel = (modelId: DLLMId): boolean =>
  useAppChatStore.getState().isNotificationEnabledForModel(modelId);

export const setIsNotificationEnabledForModel = (modelId: DLLMId, enabled: boolean) =>
  useAppChatStore.getState().setNotificationEnabledForModel(modelId, enabled);



================================================
FILE: src/apps/chat/commands/commands.dmessage.ts
================================================
[Empty file]


================================================
FILE: src/apps/chat/commands/commands.registry.ts
================================================
import type { ChatCommand, ICommandsProvider } from './ICommandsProvider';

import { CommandsAlter } from './CommandsAlter';
import { CommandsDraw } from './CommandsDraw';
import { CommandsHelp } from './CommandsHelp';
import { CommandsReact } from './CommandsReact';


export type CommandsProviderId = 'cmd-ass-t2i' | 'cmd-chat-alter' | 'cmd-help' | 'cmd-mode-react';

type TextCommandPiece =
  | { type: 'nocmd'; value: string; }
  | { type: 'cmd'; providerId: CommandsProviderId, command: string; params?: string, isErrorNoArgs?: boolean };


const ChatCommandsProviders: Record<CommandsProviderId, ICommandsProvider> = {
  'cmd-ass-t2i': CommandsDraw,
  'cmd-chat-alter': CommandsAlter,
  'cmd-help': CommandsHelp,
  'cmd-mode-react': CommandsReact,
};

export function findAllChatCommands(): ChatCommand[] {
  return Object.values(ChatCommandsProviders)
    .sort((a, b) => a.rank - b.rank)
    .map(p => p.getCommands())
    .flat();
}

export function helpPrettyChatCommands() {
  return findAllChatCommands()
    .map(cmd => ` - ${cmd.primary}` + (cmd.alternatives?.length ? ` (${cmd.alternatives.join(', ')})` : '') + `: ${cmd.description}`)
    .join('\n');
}

export function extractChatCommand(input: string): TextCommandPiece[] {
  const inputTrimmed = input.trim();

  // quick exit: command does not start with '/'
  if (!inputTrimmed.startsWith('/'))
    return [{ type: 'nocmd', value: input }];

  // Find the first space to separate the command from its parameters (if any)
  const firstSpaceIndex = inputTrimmed.indexOf(' ');
  const commandMatch = inputTrimmed.match(/^\/\S+/);
  const potentialCommand = commandMatch ? commandMatch[0] : inputTrimmed;

  const textAfterCommand = firstSpaceIndex >= 0 ? inputTrimmed.substring(firstSpaceIndex + 1) : '';

  // Check if the potential command is an actual command
  for (const provider of Object.values(ChatCommandsProviders)) {
    for (const cmd of provider.getCommands()) {
      if (cmd.primary === potentialCommand || cmd.alternatives?.includes(potentialCommand)) {

        // command needs arguments: take the rest of the input as parameters
        if (cmd.arguments?.length) return [{
          type: 'cmd',
          providerId: provider.id,
          command: potentialCommand,
          params: textAfterCommand || undefined,
          isErrorNoArgs: !textAfterCommand,
        }];

        // command without arguments, treat any text after as a separate text piece
        const pieces: TextCommandPiece[] = [{
          type: 'cmd',
          providerId: provider.id,
          command: potentialCommand,
          params: undefined,
        }];
        textAfterCommand && pieces.push({
          type: 'nocmd',
          value: textAfterCommand,
        });
        return pieces;
      }
    }
  }

  // No command found, return the entire input as text
  return [{
    type: 'nocmd',
    value: input,
  }];
}



================================================
FILE: src/apps/chat/commands/CommandsAlter.tsx
================================================
import ClearIcon from '@mui/icons-material/Clear';

import type { ICommandsProvider } from './ICommandsProvider';

export const CommandsAlter: ICommandsProvider = {
  id: 'cmd-chat-alter',
  rank: 25,

  getCommands: () => [{
    primary: '/assistant',
    alternatives: ['/a'],
    arguments: ['text...'],
    description: 'Injects assistant response',
  }, {
    primary: '/system',
    alternatives: ['/s'],
    arguments: ['text...'],
    description: 'Injects system message',
  }, {
    primary: '/clear',
    arguments: ['all'],
    description: 'Clears the chat (removes all messages)',
    Icon: ClearIcon,
  }],

};



================================================
FILE: src/apps/chat/commands/CommandsDraw.tsx
================================================
import FormatPaintTwoToneIcon from '@mui/icons-material/FormatPaintTwoTone';

import type { ICommandsProvider } from './ICommandsProvider';

export function textToDrawCommand(text: string): string {
  return `/draw ${text}`;
}

export const CommandsDraw: ICommandsProvider = {
  id: 'cmd-ass-t2i',
  rank: 10,

  getCommands: () => [{
    primary: '/draw',
    alternatives: ['/imagine', '/img'],
    arguments: ['prompt'],
    description: 'Assistant will draw the text',
    Icon: FormatPaintTwoToneIcon,
  }],

};



================================================
FILE: src/apps/chat/commands/CommandsHelp.tsx
================================================
import type { ICommandsProvider } from './ICommandsProvider';

export const CommandsHelp: ICommandsProvider = {
  id: 'cmd-help',
  rank: 99,

  getCommands: () => [{
    primary: '/help',
    alternatives: ['/?'],
    description: 'Display this list of commands',
  }],

};



================================================
FILE: src/apps/chat/commands/CommandsReact.tsx
================================================
import PsychologyIcon from '@mui/icons-material/Psychology';

import type { ICommandsProvider } from './ICommandsProvider';

export const CommandsReact: ICommandsProvider = {
  id: 'cmd-mode-react',
  rank: 15,

  getCommands: () => [{
    primary: '/react',
    arguments: ['prompt'],
    description: 'Use the AI ReAct strategy to answer your query',
    Icon: PsychologyIcon,
  }],

};



================================================
FILE: src/apps/chat/commands/ICommandsProvider.ts
================================================
import type { FunctionComponent } from 'react';
import type { CommandsProviderId } from './commands.registry';


export interface ChatCommand {
  primary: string; // The primary command
  alternatives?: string[]; // Alternative commands
  arguments?: string[]; // Arguments for the command
  description: string; // Description of what the command does
  // usage?: string; // Example of how to use the command
  Icon?: FunctionComponent; // Icon to display next to the command
}


export interface ICommandsProvider {
  id: CommandsProviderId;   // Unique identifier for the command provider
  rank: number;             // Rank of the provider, used to sort the providers in the UI

  // Function to get commands with their alternatives and details
  getCommands: () => ChatCommand[];

  // Function to execute a command with optional parameters
  // executeCommand: (command: string, params?: string[]) => Promise<boolean>;
}



================================================
FILE: src/apps/chat/components/ChatBeamWrapper.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, IconButton, Modal } from '@mui/joy';
import CloseFullscreenIcon from '@mui/icons-material/CloseFullscreen';

import { BeamStoreApi, useBeamStore } from '~/modules/beam/store-beam.hooks';
import { BeamView } from '~/modules/beam/BeamView';

import { GoodTooltip } from '~/common/components/GoodTooltip';
import { ScrollToBottom } from '~/common/scroll-to-bottom/ScrollToBottom';
import { themeZIndexBeamView } from '~/common/app.theme';


const beamWrapperStyles = {

  wrapper: {
    position: 'absolute',
    inset: 0,
    backgroundColor: 'background.level2', // darker than the expected Level1, for a change
  } as const,

  closeContainer: {
    position: 'absolute',
    top: '0.25rem',
    // left: '0.25rem',
    left: { xs: 'calc(50% - 3rem)', md: '50%' }, // center on desktop, a bit left (for the islands) on mobile
    // transform: 'translate(-50%, 0)',
    zIndex: themeZIndexBeamView, // stay on top of Message > Chips (:1), and Overlays (:2) - note: Desktop Drawer (:26)
  } as const,

  closeButton: {
    // color: 'white',
    // borderRadius: '25%',
    boxShadow: 'md',
  } as const,

} as const;


export function ChatBeamWrapper(props: {
  beamStore: BeamStoreApi,
  isMobile: boolean,
  inlineSx?: SxProps,
}) {

  // state
  const isMaximized = useBeamStore(props.beamStore, state => state.isMaximized);

  const handleUnMaximize = React.useCallback(() => {
    props.beamStore.getState().setIsMaximized(false);
  }, [props.beamStore]);

  // memo the beamview
  const beamView = React.useMemo(() => (
    <BeamView
      beamStore={props.beamStore}
      isMobile={props.isMobile}
      showExplainer
    />
  ), [props.beamStore, props.isMobile]);

  return isMaximized ? (
    <Modal open onClose={handleUnMaximize}>
      <Box sx={beamWrapperStyles.wrapper}>

        <ScrollToBottom disableAutoStick>
          {beamView}
        </ScrollToBottom>

        {/* Modal-Close-alike */}
        <Box sx={beamWrapperStyles.closeContainer}>
          <GoodTooltip title='Exit maximized mode'>
            <IconButton variant='solid' onClick={handleUnMaximize} sx={beamWrapperStyles.closeButton}>
              <CloseFullscreenIcon />
              {/*<CloseRoundedIcon />*/}
            </IconButton>
          </GoodTooltip>
        </Box>

      </Box>
    </Modal>
  ) : (
    <Box sx={props.inlineSx}>
      {beamView}
    </Box>
  );
}


================================================
FILE: src/apps/chat/components/ChatMessageList.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, List } from '@mui/joy';

import type { SystemPurposeExample } from '../../../data';

import type { DiagramConfig } from '~/modules/aifn/digrams/DiagramsModal';

import type { ConversationHandler } from '~/common/chat-overlay/ConversationHandler';
import { DConversationId, excludeSystemMessages } from '~/common/stores/chat/chat.conversation';
import { ShortcutKey, useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { convertFilesToDAttachmentFragments } from '~/common/attachment-drafts/attachment.pipeline';
import { createDMessageFromFragments, createDMessageTextContent, DMessage, DMessageId, DMessageUserFlag, DMetaReferenceItem, MESSAGE_FLAG_AIX_SKIP, messageHasUserFlag } from '~/common/stores/chat/chat.message';
import { createTextContentFragment, DMessageFragment, DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import { openFileForAttaching } from '~/common/components/ButtonAttachFiles';
import { optimaOpenPreferences } from '~/common/layout/optima/useOptima';
import { useBrowserTranslationWarning } from '~/common/components/useIsBrowserTranslating';
import { useCapabilityElevenLabs } from '~/common/components/useCapabilities';
import { useChatOverlayStore } from '~/common/chat-overlay/store-perchat_vanilla';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useScrollToBottom } from '~/common/scroll-to-bottom/useScrollToBottom';

import { CMLZeroConversation } from './messages-list/CMLZeroConversation';
import { ChatMessage, ChatMessageMemo } from './message/ChatMessage';
import { CleanerMessage, MessagesSelectionHeader } from './message/CleanerMessage';
import { Ephemerals } from './Ephemerals';
import { PersonaSelector } from './persona-selector/PersonaSelector';
import { useChatAutoSuggestHTMLUI, useChatShowSystemMessages } from '../store-app-chat';


const stableNoMessages: DMessage[] = [];

/**
 * A list of ChatMessages
 */
export function ChatMessageList(props: {
  conversationId: DConversationId | null,
  conversationHandler: ConversationHandler | null,
  capabilityHasT2I: boolean,
  chatLLMAntPromptCaching: boolean,
  chatLLMContextTokens: number | null,
  chatLLMSupportsImages: boolean,
  fitScreen: boolean,
  isMobile: boolean,
  isMessageSelectionMode: boolean,
  onConversationBranch: (conversationId: DConversationId, messageId: string, addSplitPane: boolean) => void,
  onConversationExecuteHistory: (conversationId: DConversationId) => Promise<void>,
  onConversationNew: (forceNoRecycle: boolean, isIncognito: boolean) => void,
  onTextDiagram: (diagramConfig: DiagramConfig | null) => void,
  onTextImagine: (conversationId: DConversationId, selectedText: string) => Promise<void>,
  onTextSpeak: (selectedText: string) => Promise<void>,
  setIsMessageSelectionMode: (isMessageSelectionMode: boolean) => void,
  sx?: SxProps,
}) {

  // state
  const [isImagining, setIsImagining] = React.useState(false);
  const [isSpeaking, setIsSpeaking] = React.useState(false);
  const [selectedMessages, setSelectedMessages] = React.useState<Set<string>>(new Set());

  // external state
  const { notifyBooting } = useScrollToBottom();
  const danger_experimentalHtmlWebUi = useChatAutoSuggestHTMLUI();
  const [showSystemMessages] = useChatShowSystemMessages();
  const optionalTranslationWarning = useBrowserTranslationWarning();
  const { conversationMessages, historyTokenCount } = useChatStore(useShallow(({ conversations }) => {
    const conversation = conversations.find(conversation => conversation.id === props.conversationId);
    return {
      conversationMessages: conversation ? conversation.messages : stableNoMessages,
      historyTokenCount: conversation ? conversation.tokenCount : 0,
    };
  }));
  const { _composerInReferenceToCount, ephemerals } = useChatOverlayStore(props.conversationHandler?.conversationOverlayStore ?? null, useShallow(state => ({
    _composerInReferenceToCount: state.inReferenceTo?.length ?? 0,
    ephemerals: state.ephemerals?.length ? state.ephemerals : null,
  })));
  const { mayWork: isSpeakable } = useCapabilityElevenLabs();

  // derived state
  const { conversationHandler, conversationId, capabilityHasT2I, onConversationBranch, onConversationExecuteHistory, onTextDiagram, onTextImagine, onTextSpeak } = props;
  const composerCanAddInReferenceTo = _composerInReferenceToCount < 5;
  const composerHasInReferenceto = _composerInReferenceToCount > 0;

  // text actions

  const handleRunExample = React.useCallback(async (example: SystemPurposeExample) => {
    if (!conversationId || !conversationHandler) return;

    // Simple Example Prompt (User text message)
    if (typeof example === 'string') {
      conversationHandler.messageAppend(createDMessageTextContent('user', example)); // [chat] append user:persona question
      await onConversationExecuteHistory(conversationId);
      return;
    }

    // User-Action Example Prompts (User text message + File attachments)
    switch (example.action) {
      case 'require-data-attachment':
        await openFileForAttaching(true, async (filesWithHandle) => {

          // Retrieve fully-fledged Attachment Fragments (converted/extracted, with sources, mimes, etc.) from the selected files
          const attachmentFragments = await convertFilesToDAttachmentFragments('file-open', filesWithHandle, {
            hintAddImages: props.chatLLMSupportsImages,
          });

          // Create a User message with the prompt and the attachment fragments
          if (attachmentFragments.length) {
            conversationHandler.messageAppend(createDMessageFromFragments('user', [ // [chat] append user:persona question + attachment(s)
              createTextContentFragment(example.prompt),
              ...attachmentFragments,
            ]));
            await onConversationExecuteHistory(conversationId);
          }
        });
        break;
    }
  }, [conversationHandler, conversationId, onConversationExecuteHistory, props.chatLLMSupportsImages]);

  const handleMessageContinue = React.useCallback(async (_messageId: DMessageId /* Ignored for now */, continueText: null | string) => {
    if (conversationId && conversationHandler) {
      conversationHandler.messageAppend(createDMessageTextContent('user', continueText || 'Continue')); // [chat] append user:Continue (or custom text, likely from an 'option')
      await onConversationExecuteHistory(conversationId);
    }
  }, [conversationHandler, conversationId, onConversationExecuteHistory]);


  // message menu methods proxy

  const handleMessageAssistantFrom = React.useCallback(async (messageId: DMessageId, offset: number) => {
    if (conversationId && conversationHandler) {
      conversationHandler.historyTruncateTo(messageId, offset);
      await onConversationExecuteHistory(conversationId);
    }
  }, [conversationHandler, conversationId, onConversationExecuteHistory]);

  const handleMessageBeam = React.useCallback(async (messageId: DMessageId) => {
    // Message option menu Beam
    if (!conversationId || !conversationHandler || !conversationHandler.isValid()) return;
    const inputHistory = conversationHandler.historyViewHeadOrThrow('chat-beam-message');
    if (!inputHistory.length) return;

    // TODO: replace the Persona and Auto-Cache-hint in the history?

    // truncate the history to the given message (may or may not have more after)
    const truncatedHistory = inputHistory.slice(0, inputHistory.findIndex(m => m.id === messageId) + 1);
    const lastTruncatedMessage = truncatedHistory[truncatedHistory.length - 1];
    if (!lastTruncatedMessage) return;

    // assistant: do an in-place beam
    if (lastTruncatedMessage.role === 'assistant') {
      if (truncatedHistory.length >= 2)
        conversationHandler.beamInvoke(truncatedHistory.slice(0, -1), [lastTruncatedMessage], lastTruncatedMessage.id);
    } else if (lastTruncatedMessage.role === 'user') {
      // user: truncate and append (but if the next message is an assistant message, import it)
      const possibleNextMessage = inputHistory[truncatedHistory.length];
      if (possibleNextMessage?.role === 'assistant')
        conversationHandler.beamInvoke(truncatedHistory, [possibleNextMessage], null);
      else
        conversationHandler.beamInvoke(truncatedHistory, [], null);
    }
  }, [conversationHandler, conversationId]);

  const handleMessageBranch = React.useCallback((messageId: DMessageId) => {
    conversationId && onConversationBranch(conversationId, messageId, true);
  }, [conversationId, onConversationBranch]);

  const handleMessageTruncate = React.useCallback((messageId: DMessageId) => {
    conversationHandler?.historyTruncateTo(messageId, 0);
  }, [conversationHandler]);

  const handleMessageDelete = React.useCallback((messageId: DMessageId) => {
    conversationHandler?.messagesDelete([messageId]);
  }, [conversationHandler]);

  const handleMessageAppendFragment = React.useCallback((messageId: DMessageId, fragment: DMessageFragment) => {
    conversationHandler?.messageFragmentAppend(messageId, fragment, false, false);
  }, [conversationHandler]);

  const handleMessageDeleteFragment = React.useCallback((messageId: DMessageId, fragmentId: DMessageFragmentId) => {
    conversationHandler?.messageFragmentDelete(messageId, fragmentId, false, true);
  }, [conversationHandler]);

  const handleMessageReplaceFragment = React.useCallback((messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment) => {
    conversationHandler?.messageFragmentReplace(messageId, fragmentId, newFragment, true);
  }, [conversationHandler]);

  const handleMessageToggleUserFlag = React.useCallback((messageId: DMessageId, userFlag: DMessageUserFlag, _maxPerConversation?: number) => {
    conversationHandler?.messageToggleUserFlag(messageId, userFlag, true /* touch */);
    // Note: we don't support 'maxPerConversation' yet, which is supposed to turn off the flag from the beginning if it's too numerous
    // if (_maxPerConversation) {
    //   ...
    // }
  }, [conversationHandler]);

  const handleAddInReferenceTo = React.useCallback((item: DMetaReferenceItem) => {
    conversationHandler?.overlayActions.addInReferenceTo(item);
  }, [conversationHandler]);

  const handleTextDiagram = React.useCallback(async (messageId: DMessageId, text: string) => {
    conversationId && onTextDiagram({ conversationId: conversationId, messageId, text });
  }, [conversationId, onTextDiagram]);

  const handleTextImagine = React.useCallback(async (text: string) => {
    if (!capabilityHasT2I)
      return optimaOpenPreferences('draw');
    if (conversationId) {
      setIsImagining(true);
      await onTextImagine(conversationId, text);
      setIsImagining(false);
    }
  }, [capabilityHasT2I, conversationId, onTextImagine]);

  const handleTextSpeak = React.useCallback(async (text: string) => {
    if (!isSpeakable)
      return optimaOpenPreferences('voice');
    setIsSpeaking(true);
    await onTextSpeak(text);
    setIsSpeaking(false);
  }, [isSpeakable, onTextSpeak]);


  // operate on the local selection set

  const areAllSelectedMessagesHidden = React.useMemo(() => {
    if (selectedMessages.size === 0) return false;
    for (const messageId of selectedMessages) {
      const message = conversationMessages.find(m => m.id === messageId);
      if (message && !messageHasUserFlag(message, MESSAGE_FLAG_AIX_SKIP))
        return false;
    }
    return true;
  }, [selectedMessages, conversationMessages]);

  const handleSelectAll = (selected: boolean) => {
    const newSelected = new Set<string>();
    if (selected)
      for (const message of conversationMessages)
        newSelected.add(message.id);
    setSelectedMessages(newSelected);
  };

  const handleSelectMessage = (messageId: DMessageId, selected: boolean) => {
    const newSelected = new Set(selectedMessages);
    selected ? newSelected.add(messageId) : newSelected.delete(messageId);
    setSelectedMessages(newSelected);
  };

  const handleSelectionDelete = React.useCallback(() => {
    conversationHandler?.messagesDelete(Array.from(selectedMessages));
    setSelectedMessages(new Set());
  }, [conversationHandler, selectedMessages]);

  const handleSelectionToggleVisibility = React.useCallback(() => {
    for (let selectedMessage of Array.from(selectedMessages))
      conversationHandler?.messageSetUserFlag(selectedMessage, MESSAGE_FLAG_AIX_SKIP, !areAllSelectedMessagesHidden, true);
    setSelectedMessages(new Set());
  }, [conversationHandler, selectedMessages, areAllSelectedMessagesHidden]);

  const { isMessageSelectionMode, setIsMessageSelectionMode } = props;

  useGlobalShortcuts('ChatMessageList_Selection', React.useMemo(() => !isMessageSelectionMode ? [] : [
    { key: ShortcutKey.Esc, action: () => setIsMessageSelectionMode(false), description: 'Close Cleanup', level: 10 - 1 },
  ], [isMessageSelectionMode, setIsMessageSelectionMode]));


  // text-diff functionality: only diff the last complete message, and they're similar in size

  // const { diffTargetMessage, diffPrevText } = React.useMemo(() => {
  //   const [msgB, msgA] = conversationMessages.filter(m => m.role === 'assistant').reverse();
  //   const textB = msgB ? singleTextOrThrow(msgB) : undefined;
  //   const textA = msgA ? singleTextOrThrow(msgA) : undefined;
  //   if (textB && textA && !msgB?.pendingIncomplete) {
  //     const lenA = textA.length, lenB = textB.length;
  //     if (lenA > 80 && lenB > 80 && lenA > lenB / 3 && lenB > lenA / 3)
  //       return { diffTargetMessage: msgB, diffPrevText: textA };
  //   }
  //   return { diffTargetMessage: undefined, diffPrevText: undefined };
  // }, [conversationMessages]);


  // scroll to the very bottom of a new chat
  React.useEffect(() => {
    if (conversationId)
      notifyBooting();
  }, [conversationId, notifyBooting]);


  // style memo
  const listSx: SxProps = React.useMemo(() => ({
    p: 0,
    ...props.sx,

    // we added these after removing the minSize={20} (%) from the containing panel.
    minWidth: '18rem',
    // minHeight: '180px', // not need for this, as it's already an overflow scrolling container, so one can reduce it to a pixel

    // fix for the double-border on the last message (one by the composer, one to the bottom of the message)
    // marginBottom: '-1px',

    // layout
    display: 'flex',
    flexDirection: 'column',
  }), [props.sx]);


  // no conversation: sine qua non
  if (!conversationId)
    return <CMLZeroConversation onConversationNew={props.onConversationNew} />;


  // no content: show the persona selector

  const filteredMessages = excludeSystemMessages(conversationMessages, showSystemMessages);


  if (!filteredMessages.length)
    return (
      <Box sx={{ ...props.sx }}>
        <PersonaSelector conversationId={conversationId} isMobile={props.isMobile} runExample={handleRunExample} />
      </Box>
    );

  return (
    <List role='chat-messages-list' sx={listSx}>

      {optionalTranslationWarning}

      {props.isMessageSelectionMode && (
        <MessagesSelectionHeader
          hasSelected={selectedMessages.size > 0}
          sumTokens={historyTokenCount}
          onClose={() => props.setIsMessageSelectionMode(false)}
          onSelectAll={handleSelectAll}
          onDeleteMessages={handleSelectionDelete}
          onToggleVisibility={handleSelectionToggleVisibility}
          areAllMessagesHidden={areAllSelectedMessagesHidden}
        />
      )}

      {filteredMessages.map((message, idx) => {

          // Optimization: only memo complete components, or we'd be memoizing garbage
          const ChatMessageMemoOrNot = !message.pendingIncomplete ? ChatMessageMemo : ChatMessage;

          return props.isMessageSelectionMode ? (

            <CleanerMessage
              key={'sel-' + message.id}
              message={message}
              remainingTokens={props.chatLLMContextTokens ? (props.chatLLMContextTokens - historyTokenCount) : undefined}
              selected={selectedMessages.has(message.id)} onToggleSelected={handleSelectMessage}
            />

          ) : (

            <ChatMessageMemoOrNot
              key={'msg-' + message.id}
              message={message}
              // diffPreviousText={message === diffTargetMessage ? diffPrevText : undefined}
              fitScreen={props.fitScreen}
              hasInReferenceTo={composerHasInReferenceto}
              isMobile={props.isMobile}
              isBottom={idx === filteredMessages.length - 1}
              isImagining={isImagining}
              isSpeaking={isSpeaking}
              showAntPromptCaching={props.chatLLMAntPromptCaching}
              showUnsafeHtmlCode={danger_experimentalHtmlWebUi}
              onAddInReferenceTo={!composerCanAddInReferenceTo ? undefined : handleAddInReferenceTo}
              onMessageAssistantFrom={handleMessageAssistantFrom}
              onMessageBeam={handleMessageBeam}
              onMessageBranch={handleMessageBranch}
              onMessageContinue={handleMessageContinue}
              onMessageDelete={handleMessageDelete}
              onMessageFragmentAppend={handleMessageAppendFragment}
              onMessageFragmentDelete={handleMessageDeleteFragment}
              onMessageFragmentReplace={handleMessageReplaceFragment}
              onMessageToggleUserFlag={handleMessageToggleUserFlag}
              onMessageTruncate={handleMessageTruncate}
              onTextDiagram={handleTextDiagram}
              onTextImagine={capabilityHasT2I ? handleTextImagine : undefined}
              onTextSpeak={isSpeakable ? handleTextSpeak : undefined}
            />

          );
        },
      )}

      {/* Render ephemerals (sidebar ReAct output widgets) at the bottom */}
      {!!ephemerals?.length && !!conversationHandler && (
        <Ephemerals
          ephemerals={ephemerals}
          conversationHandler={conversationHandler}
          sx={{
            mt: 'auto',
            overflowY: 'auto',
          }}
        />
      )}

    </List>
  );
}


================================================
FILE: src/apps/chat/components/Ephemerals.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Grid, IconButton, Sheet, styled, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import MaximizeIcon from '@mui/icons-material/Maximize';
import MinimizeIcon from '@mui/icons-material/Minimize';
import VerticalSplitIcon from '@mui/icons-material/VerticalSplit';
import VerticalSplitOutlinedIcon from '@mui/icons-material/VerticalSplitOutlined';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { DEphemeral } from '~/common/chat-overlay/store-perchat-ephemerals_slice';
import { ConversationHandler } from '~/common/chat-overlay/ConversationHandler';
import { adjustContentScaling, ContentScaling, lineHeightChatTextMd } from '~/common/app.theme';
import { useUIPreferencesStore } from '~/common/stores/store-ui';


// State Pane

const StateLine = styled(Typography)(({ theme }) => ({
  textOverflow: 'ellipsis',
  whiteSpace: 'nowrap',
  overflow: 'hidden',
  fontSize: theme.fontSize.xs,
  fontFamily: theme.fontFamily.code,
  marginLeft: theme.spacing(1),
  lineHeight: lineHeightChatTextMd,
}));

function isPrimitive(value: any): boolean {
  const t = typeof value;
  return t === 'string' || t === 'number' || t === 'boolean' || t === 'symbol' || value === null || value === undefined;
}

function PrimitiveRender({ name, value }: { name: string, value: string | number | boolean | symbol | null | undefined }) {
  if (value === null || value === undefined)
    return <StateLine><b>{name}</b>: <i>{value === null ? 'null' : 'undefined'}</i></StateLine>;
  else if (typeof value === 'string')
    return <StateLine><b>{name}</b>: &lsquo;{value}&rsquo;</StateLine>;
  else if (typeof value === 'number')
    return <StateLine><b>{name}</b>: <b>{value}</b></StateLine>;
  else if (typeof value === 'boolean')
    return <StateLine><b>{name}</b>: <b>{value ? 'true' : 'false'}</b></StateLine>;
  else
    return <StateLine><b>{name}</b>: unknown?</StateLine>;
}

function ListRenderer({ name, list }: { name: string, list: any[] }) {
  return <StateLine><b>{name}</b>[{list.length ? list.length : ''}]: {list.length ? '(not displayed)' : 'empty'}</StateLine>;
}

function ObjectRenderer({ name }: { name: string }) {
  return <StateLine><b>{name}</b>: <i>object not displayed</i></StateLine>;
}

function StateRenderer(props: { state: object, contentScaling: ContentScaling }) {
  if (typeof props.state !== 'object')
    return <pre>Developer Warning: state is not an object: {JSON.stringify(props.state, null, 2)}</pre>;

  const entries = Object.entries(props.state);

  return (
    <Box>
      <ScaledTextBlockRenderer
        text='**Internal State**'
        contentScaling={props.contentScaling}
        textRenderVariant='markdown'
      />
      <Box sx={{
        mt: 1,
        p: 1,
        borderRadius: 'md',
        background: 'linear-gradient(180deg, var(--joy-palette-success-softHoverBg), transparent)',
      }}>
        {!entries && <Typography level='body-sm'>No state variables</Typography>}
        {entries.map(([key, value]) =>
          isPrimitive(value)
            ? <PrimitiveRender key={'state-' + key} name={key} value={value} />
            : Array.isArray(value)
              ? <ListRenderer key={'state-' + key} name={key} list={value} />
              : typeof value === 'object'
                ? <ObjectRenderer key={'state-' + key} name={key} />
                : <Typography key={'state-' + key} level='body-sm'>{key}: {value}</Typography>,
        )}
      </Box>
    </Box>
  );
}


const leftPaneSx = {
  // <pre> looks
  overflowWrap: 'anywhere',
  whiteSpace: 'break-spaces',
  // 'undo' some of the github-markdown CSS customizations
  '.markdown-body': { mx: '0!important' },
  '.markdown-body p': { mb: 0 },
};

const rightPaneSx = {
  borderLeft: { md: `1px dashed` },
  borderTop: { xs: `1px dashed`, md: 'none' },
};


function EphemeralItem(props: {
  ephemeral: DEphemeral,
  conversationHandler: ConversationHandler,
  contentScaling: ContentScaling,
}) {

  const { ephemeral, conversationHandler } = props;

  // Event handlers
  const handleDelete = React.useCallback(() => {
    conversationHandler.overlayActions.ephemeralsDelete(ephemeral.id);
  }, [conversationHandler, ephemeral.id]);

  const handleToggleMinimized = React.useCallback(() => {
    conversationHandler.overlayActions.ephemeralsToggleMinimized(ephemeral.id);
  }, [conversationHandler, ephemeral.id]);

  const handleToggleShowState = React.useCallback(() => {
    conversationHandler.overlayActions.ephemeralsToggleShowStatePane(ephemeral.id);
  }, [conversationHandler, ephemeral.id]);


  const showStatePane = ephemeral.showStatePane && !!ephemeral.state;

  return (
    <Box sx={{
      borderTop: '1px solid',
      borderTopColor: 'divider',
      // border: (i < ephemerals.length - 1) ? `2px solid ${theme.palette.divider}` : undefined,
      display: 'flex',
      flexDirection: 'column',
    }}>

      {/* Top Line - Title and Buttons */}
      <Box sx={{
        py: 1,
        px: { xs: 1, md: 2 },
        backgroundColor: 'success.softHoverBg',
        display: 'flex',
        gap: 1,
        alignItems: 'center'
      }}>

        <Typography level='title-sm' sx={{ flex: 1, color: 'success.solidBg' }}>
          {ephemeral.title} Internal Monologue
        </Typography>

        {/* Show State */}
        {!ephemeral.minimized && (
          <IconButton
            size='sm'
            variant={ephemeral.showStatePane ? 'solid' : 'outlined'}
            onClick={handleToggleShowState}
          >
            {ephemeral.showStatePane ? <VerticalSplitIcon /> : <VerticalSplitOutlinedIcon />}
          </IconButton>
        )}

        {/* Minimize/Expand Button */}
        <IconButton
          size='sm'
          variant={'outlined'}
          onClick={handleToggleMinimized}
        >
          {ephemeral.minimized ? <MaximizeIcon /> : <MinimizeIcon />}
        </IconButton>

        {/* Close */}
        <IconButton
          size='sm'
          variant={ephemeral.done ? 'solid' : 'outlined'}
          onClick={handleDelete}
        >
          <CloseRoundedIcon />
        </IconButton>

      </Box>

      {/* Content */}
      {!ephemeral.minimized && <Box sx={{
        py: 1,
        px: { xs: 1, md: 2 },
      }}>

        {/* Content Grid */}
        <Grid container spacing={2} sx={{ mt: 0.5 }}>

          {/* Left pane (log) */}
          <Grid xs={12} md={showStatePane ? 6 : 12}>
            {/* New renderer, with */}
            <Box sx={leftPaneSx}>
              <ScaledTextBlockRenderer
                text={ephemeral.text}
                contentScaling={props.contentScaling}
                textRenderVariant='markdown'
              />
            </Box>
          </Grid>

          {/* Right pane (state) */}
          {showStatePane && (
            <Grid xs={12} md={6} sx={rightPaneSx}>
              <StateRenderer
                state={ephemeral.state}
                contentScaling={props.contentScaling}
              />
            </Grid>
          )}

        </Grid>
      </Box>}

    </Box>
  );
}


export function Ephemerals(props: {
  ephemerals: DEphemeral[],
  conversationHandler: ConversationHandler,
  sx?: SxProps
}) {

  // external state
  const adjContentScaling = useUIPreferencesStore(state => adjustContentScaling(state.contentScaling, -1));

  return (
    <Sheet variant='soft' color='success' invertedColors sx={props.sx}>

      {props.ephemerals.map((ephemeral, i) => (
        <EphemeralItem
          key={ephemeral.id}
          ephemeral={ephemeral}
          conversationHandler={props.conversationHandler}
          contentScaling={adjContentScaling}
        />
      ))}

    </Sheet>
  );
}



================================================
FILE: src/apps/chat/components/PaneTitleOverlay.tsx
================================================
import * as React from 'react';

import { Box, IconButton, Sheet } from '@mui/joy';
import ClearIcon from '@mui/icons-material/Clear';
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import OpenInFullIcon from '@mui/icons-material/OpenInFull';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { InlineTextarea } from '~/common/components/InlineTextarea';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { useConversationTitle } from '~/common/stores/chat/hooks/useConversationTitle';

import { panesManagerActions } from './panes/store-panes-manager';


// configuration
const ENABLE_DELETE = false;


const _styles = {
  tileBar: {
    position: 'absolute',
    top: 0,
    left: '50%',
    transform: 'translateX(-50%)',
    zIndex: 10,
    padding: '0 0.125rem 0.125rem',
    fontSize: 'sm',
    fontWeight: 'md',
    borderBottomLeftRadius: '8px',
    borderBottomRightRadius: '8px',
    // boxShadow: 'xs',
    // border: '1px solid',
    // borderColor: 'background.popup',
    borderTop: 'none',
    maxWidth: '78%',
    display: 'flex',
    alignItems: 'center',
    gap: 1,
  } as const,
  titleBarIncognito: {
    backgroundImage: 'repeating-linear-gradient(45deg, rgba(0,0,0,0.1), rgba(0,0,0,0.1) 10px, transparent 10px, transparent 20px)',
    backgroundColor: 'neutral.solidBg',
  } as const,
  title: {
    flex: 1,
    overflow: 'hidden',
    textOverflow: 'ellipsis',
    whiteSpace: 'nowrap',
    cursor: 'pointer',
    minWidth: '2.75rem',
    textAlign: 'center',
  } as const,
  toolButton: {
    '--IconButton-size': '1.5rem',
    backgroundColor: 'transparent',
    opacity: 0.5,
    transition: 'opacity 0.1s',
    '&:hover': {
      opacity: 1,
    },
  } as const,
  toolIcon: {} as const,
  toolIconLg: {
    fontSize: 'lg',
  } as const,
} as const;


export function PaneTitleOverlay(props: {
  paneIdx: number,
  conversationId: DConversationId | null,
  isFocused: boolean,
  isIncognito: boolean,
  onConversationDelete: (conversationIds: DConversationId[], bypassConfirmation: boolean) => void,
}) {

  // state
  const [editingTitle, setEditingTitle] = React.useState(false);

  // external state
  const { title, setUserTitle } = useConversationTitle(props.conversationId);
  // if (!title || title?.length < 3)
  //   return null;


  // close tabs handlers

  const handleCloseThis = React.useCallback(() => {
    panesManagerActions().removePane(props.paneIdx);
  }, [props.paneIdx]);

  const handleCloseOthers = React.useCallback(() => {
    panesManagerActions().removeOtherPanes(props.paneIdx);
  }, [props.paneIdx]);


  // title handles

  const handleTitleEditBegin = React.useCallback(() => {
    setEditingTitle(true);
  }, []);

  const handleTitleEditChange = React.useCallback((newTitle: string) => {
    setUserTitle(newTitle);
    setEditingTitle(false);
  }, [setUserTitle]);

  const handleTitleEditEnd = React.useCallback(() => {
    setEditingTitle(false);
  }, []);


  // delete handlers

  const { onConversationDelete } = props;

  const handleDeleteClicked = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    if (props.conversationId)
      onConversationDelete([props.conversationId], event.shiftKey);
  }, [onConversationDelete, props.conversationId]);


  // don't render if not focused
  // if (!props.isFocused)
  //   return null;

  const hasTitle = title && title.length > 0;
  const color = props.isFocused ? 'primary' : 'neutral';
  const variantO = props.isFocused ? 'solid' : 'outlined';
  const variantP = props.isFocused ? 'solid' : 'plain';

  return (
    <Sheet
      color={color}
      variant={variantO}
      sx={!props.isIncognito ? _styles.tileBar : { ..._styles.tileBar, ..._styles.titleBarIncognito }}
    >
      {/* Close Others*/}
      {/*<TooltipOutlined title='Close Other Tabs'>*/}
      {!editingTitle && <IconButton title='Close Other Tabs' size='sm' color={color} variant={variantP} onClick={handleCloseOthers} sx={_styles.toolButton}>
        <OpenInFullIcon sx={_styles.toolIcon} />
      </IconButton>}
      {/*</TooltipOutlined>*/}

      {/* Title */}
      {editingTitle ? (
        <InlineTextarea
          initialText={title || ''}
          placeholder='Chat title...'
          invertedColors
          centerText
          onEdit={handleTitleEditChange}
          onCancel={handleTitleEditEnd}
          sx={{
            // flexGrow: 1,
            // minWidth: 120,
            mx: { md: 1 },
          }}
        />
      ) : !!props.conversationId && <>
        {hasTitle && <Box sx={_styles.title} onClick={handleTitleEditBegin}>
          {title}
        </Box>}
        {!hasTitle && <Box fontStyle='italic' onClick={handleTitleEditBegin}>
          untitled
        </Box>}
        {!hasTitle && <TooltipOutlined title='Edit Chat Title'>
          <IconButton title='' size='sm' color={color} variant={variantP} onClick={handleTitleEditBegin} sx={_styles.toolButton}>
            <EditRoundedIcon sx={_styles.toolIcon} />
          </IconButton>
        </TooltipOutlined>}
      </>}

      {/* Delete This */}
      {ENABLE_DELETE && hasTitle && !!props.conversationId && (
        <TooltipOutlined title='Delete Chat (Shift+Click to bypass confirmation)'>
          <IconButton size='sm' variant={variantP} onClick={handleDeleteClicked} sx={_styles.toolButton}>
            <DeleteForeverIcon />
          </IconButton>
        </TooltipOutlined>
      )}

      {/* Close This */}
      {/*<TooltipOutlined title='Close'>*/}
      {!editingTitle && <IconButton title='Close Tab' size='sm' color={color} variant={variantP} onClick={handleCloseThis} sx={_styles.toolButton}>
        <ClearIcon sx={_styles.toolIconLg} />
      </IconButton>}
      {/*</TooltipOutlined>*/}
    </Sheet>
  );
}


================================================
FILE: src/apps/chat/components/StatusBar.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';
import { Box, IconButton, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import ExpandLessIcon from '@mui/icons-material/ExpandLess';
import MinimizeIcon from '@mui/icons-material/Minimize';

// import { isMacUser } from '~/common/util/pwaUtils';
import { ShortcutKey, ShortcutObject } from '~/common/components/shortcuts/useGlobalShortcuts';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { useGlobalShortcutsStore } from '~/common/components/shortcuts/store-global-shortcuts';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';
import { useUXLabsStore } from '~/common/stores/store-ux-labs';


// configuration
const COMPOSER_ENABLE_MINIMIZE = false;


const hideButtonTooltip = (
  <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
    Hide Shortcuts<br />
    Enable again in Settings &gt; Labs
  </Box>
);

const _styles = {

  bar: {
    borderBottom: '1px solid',
    // borderBottomColor: 'var(--joy-palette-divider)',
    borderBottomColor: 'rgba(var(--joy-palette-neutral-mainChannel) / 0.1)',
    // borderTopColor: 'rgba(var(--joy-palette-neutral-mainChannel, 99 107 116) / 0.4)',
    // backgroundColor: 'var(--joy-palette-background-surface)',
    // paddingBlock: '0.25rem',
    paddingInline: '0.5rem',
    // layout
    display: 'flex',
    flexFlow: 'row nowrap',
    columnGap: '1.5rem', // space between shortcuts
    lineHeight: '1em',
    // animation: `${animateAppear} 0.3s ease-out`,
    // transition: 'all 0.2s ease',
    // '&:hover': {
    //   backgroundColor: 'var(--joy-palette-background-level1)',
    // },
  } as const,

  hideButton: {
    '--IconButton-size': '28px',
    '--Icon-fontSize': '16px',
    '--Icon-color': 'var(--joy-palette-text-tertiary)',
    mr: -0.5,
  } as const,

  shortcut: {
    display: 'flex',
    alignItems: 'center',
    whiteSpace: 'nowrap',
    gap: '2px', // space between modifiers
    marginBlock: '0.25rem',
    // transition: 'transform 0.2s ease',
    // '&:hover': {
    //   transform: 'scale(1.05)',
    // },
    '&:hover > div': {
      backgroundColor: 'background.level1',
    } as const,
    cursor: 'pointer',
    [`&[aria-disabled="true"]`]: {
      opacity: 0.5,
      pointerEvents: 'none',
    } as const,
  } as const,

  itemKeyGroup: {
    fontSize: 'xs',
    fontWeight: 'md',
    outline: '1px solid',
    outlineColor: 'neutral.outlinedBorder',
    borderRadius: 'xs',
    // backgroundColor: 'var(--joy-palette-neutral-outlinedBorder)',
    backgroundColor: 'background.popup',
    // boxShadow: 'inset 2px 0px 4px -2px var(--joy-palette-background-backdrop)',
    boxShadow: 'xs',
    // minWidth: '1rem',
    paddingBlock: '2px',
    paddingInline: '1px',
    // pointerEvents: 'none',
    cursor: 'pointer',
    transition: 'background-color 1s ease',
    display: 'flex',
    textAlign: 'center',
    // Remove the gap and use dividers instead
    gap: 0,
    '& > span': {
      position: 'relative',
      paddingInline: '4px',
      minWidth: '1rem',
      '&:not(:last-child)': {
        borderRight: '1px solid',
        borderRightColor: 'neutral.outlinedBorder',
      },
    },
  } as const,

  itemIcon: {
    fontSize: 'md',
  } as const,

} as const;


// const animateAppear = keyframes`
//     from {
//         opacity: 0;
//         transform: translateY(10px);
//     }
//     to {
//         opacity: 1;
//         transform: translateY(0);
//     }
// `;


// Display mac-style shortcuts on windows as well
const displayMacModifiers = true;

function _platformAwareModifier(symbol: 'Ctrl' | 'Alt' | 'Shift') {
  switch (symbol) {
    case 'Ctrl':
      return displayMacModifiers ? '⌃' : 'Ctrl';
    case 'Shift':
      return displayMacModifiers ? '⇧' : '⇧';
    case 'Alt':
      return displayMacModifiers ? '⌥' /* Option */ : 'Alt';
  }
}

const ShortcutItemMemo = React.memo(ShortcutItem);

function ShortcutItem(props: { shortcut: ShortcutObject }) {

  const handleClicked = React.useCallback(() => {
    if (props.shortcut.action !== '_specialPrintShortcuts')
      props.shortcut.action();
  }, [props.shortcut]);

  return (
    <Box
      onClick={!props.shortcut.disabled ? handleClicked : undefined}
      aria-disabled={props.shortcut.disabled}
      sx={_styles.shortcut}
    >
      <Box sx={_styles.itemKeyGroup}>
        {!!props.shortcut.ctrl && <span>{_platformAwareModifier('Ctrl')}</span>}
        {!!props.shortcut.shift && <span>{_platformAwareModifier('Shift')}</span>}
        {/*{!!props.shortcut.altForNonMac && <span>{_platformAwareModifier('Alt')}</span>}*/}
        <span>{props.shortcut.key === 'Escape' ? 'Esc' : props.shortcut.key === 'Enter' ? '↵' : props.shortcut.key.toUpperCase()}</span>
      </Box>
      &nbsp;<Typography level='body-xs'>{props.shortcut.description}</Typography>
      {!!props.shortcut.endDecoratorIcon && <props.shortcut.endDecoratorIcon sx={_styles.itemIcon} />}
    </Box>
  );
}

export const StatusBarMemo = React.memo(StatusBar);

export function StatusBar(props: { toggleMinimized?: () => void, isMinimized?: boolean }) {

  // state (modifiers pressed/not)
  const { showPromisedOverlay } = useOverlayComponents();
  // const [ctrlPressed, setCtrlPressed] = React.useState(false);
  // const [shiftPressed, setShiftPressed] = React.useState(false);

  // external state
  const labsShowShortcutBar = useUXLabsStore(state => state.labsShowShortcutBar);
  const shortcuts = useGlobalShortcutsStore(useShallow(state => {
    // get visible shortcuts
    let visibleShortcuts = !labsShowShortcutBar ? [] : state.getAllShortcuts().filter(shortcut => !!shortcut.description);

    // filter by highest level if levels are present
    const maxLevel = Math.max(...visibleShortcuts.map(s => s.level ?? 0));
    if (maxLevel > 0)
      visibleShortcuts = visibleShortcuts.filter(s => s.level === maxLevel);

    visibleShortcuts.sort((a, b) => {
      // 1. First by level
      if ((a.level ?? 0) !== (b.level ?? 0))
        return (b.level ?? 0) - (a.level ?? 0);

      // 2. Then by modifiers presence (no modifiers first)
      const aModifiers = (a.ctrl ? 1 : 0) + (a.shift ? 1 : 0);
      const bModifiers = (b.ctrl ? 1 : 0) + (b.shift ? 1 : 0);
      if (aModifiers !== bModifiers)
        return aModifiers - bModifiers;

      // 3a. Special case for ShortcutKey.Esc, at the beginning
      if (a.key === ShortcutKey.Esc) return -1;
      if (b.key === ShortcutKey.Esc) return 1;

      // 3. Special case for 'Beam Edit'
      if (a.description === 'Beam Edit') return 1;
      if (b.description === 'Beam Edit') return -1;

      // 4. Finally alphabetically by key
      return a.key.localeCompare(b.key);
    });
    return visibleShortcuts;
  }));

  // handlers
  const handleHideShortcuts = React.useCallback((event: React.MouseEvent) => {
    if (event.shiftKey) {
      console.log('shortcutGroups', useGlobalShortcutsStore.getState().shortcutGroups);
      return;
    }
    showPromisedOverlay('shortcuts-confirm-close', {}, ({ onResolve, onUserReject }) =>
      <ConfirmationModal
        open onClose={onUserReject} onPositive={() => onResolve(true)}
        confirmationText='Remove productivity tips and shortcuts? You can add it back in Settings > Labs.'
        positiveActionText='Remove'
      />,
    ).then(() => useUXLabsStore.getState().setLabsShowShortcutBar(false)).catch(() => null /* ignore closure */);
  }, [showPromisedOverlay]);

  // React to modifiers
  // React.useEffect(() => {
  //   const handleKeyDown = (e: KeyboardEvent) => {
  //     if (e.key === 'Control') setCtrlPressed(true);
  //     if (e.key === 'Shift') setShiftPressed(true);
  //   };
  //   const handleKeyUp = (e: KeyboardEvent) => {
  //     if (e.key === 'Control') setCtrlPressed(false);
  //     if (e.key === 'Shift') setShiftPressed(false);
  //   };
  //   window.addEventListener('keydown', handleKeyDown);
  //   window.addEventListener('keyup', handleKeyUp);
  //   return () => {
  //     window.removeEventListener('keydown', handleKeyDown);
  //     window.removeEventListener('keyup', handleKeyUp);
  //   };
  // }, []);

  if (!labsShowShortcutBar)
    return null;

  return (
    <Box
      aria-label='Shortcuts and status bar'
      sx={_styles.bar}
    >

      {(!props.toggleMinimized || !COMPOSER_ENABLE_MINIMIZE) && !props.isMinimized ? (
        // Close Button
        <GoodTooltip variantOutlined arrow placement='top' title={hideButtonTooltip}>
          <IconButton size='sm' onClick={handleHideShortcuts} sx={_styles.hideButton}>
            <CloseRoundedIcon />
          </IconButton>
        </GoodTooltip>
      ) : (
        // Minimize / Maximize Button - note the Maximize icon would be more correct, but also less discoverable
        <IconButton size='sm' onClick={props.toggleMinimized} sx={_styles.hideButton}>
          {props.isMinimized ? <ExpandLessIcon /> : <MinimizeIcon />}
        </IconButton>
      )}

      {/* Show all shortcuts */}
      {shortcuts.map((shortcut, idx) => (
        <ShortcutItemMemo key={shortcut.key + idx} shortcut={shortcut} />
      ))}

    </Box>
  );
}



================================================
FILE: src/apps/chat/components/composer/CameraCaptureModal.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ButtonGroup, IconButton, Modal, ModalClose, Option, Select, Sheet, Tooltip, Typography } from '@mui/joy';
import AddRoundedIcon from '@mui/icons-material/AddRounded';
import CameraEnhanceIcon from '@mui/icons-material/CameraEnhance';
import CameraFrontIcon from '@mui/icons-material/CameraFront';
import CameraRearIcon from '@mui/icons-material/CameraRear';
import DownloadIcon from '@mui/icons-material/Download';
import FlipCameraAndroidOutlinedIcon from '@mui/icons-material/FlipCameraAndroidOutlined';
import InfoOutlinedIcon from '@mui/icons-material/InfoOutlined';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';

import { InlineError } from '~/common/components/InlineError';
import { Is } from '~/common/util/pwaUtils';
import { animationBackgroundCameraFlash } from '~/common/util/animUtils';
import { downloadVideoFrame, renderVideoFrameAsFile } from '~/common/util/videoUtils';
import { useCameraCapture } from '~/common/components/useCameraCapture';


// configuration
const DEBUG_NO_CAMERA_OPTION = false;
const FLASH_DURATION_MS = 600;
const ADD_COOLDOWN_MS = 300;


const captureButtonContainerSx: SxProps = {
  display: 'flex',
  gap: 1,
  justifyContent: 'space-between',
  alignItems: 'center',
};

const captureButtonGroupSx: SxProps = {
  '--ButtonGroup-separatorColor': 'none !important',
  // '--ButtonGroup-separatorSize': '2px',
  borderRadius: '3rem',
  // boxShadow: 'md',
  boxShadow: '0 8px 12px -6px rgb(var(--joy-palette-neutral-darkChannel) / 50%)',
};

const captureButtonSx: SxProps = {
  backgroundColor: 'neutral.solidHoverBg',
  pl: 3.25,
  pr: 4.5,
  py: 1.5,
  minWidth: { md: 200 },
  '&:hover': {
    backgroundColor: 'neutral.plainHoverColor',
  },
};

const addButtonSx: SxProps = {
  pl: 2.5,
  pr: 2,
};


export function CameraCaptureModal(props: {
  onCloseModal: () => void;
  onAttachImage: (file: File) => void;
  // onOCR: (ocrText: string) => void }
}) {

  // state
  const [showInfo, setShowInfo] = React.useState(false);
  const [isFlashing, setIsFlashing] = React.useState(false); // For flash effect
  const [isAddButtonDisabled, setIsAddButtonDisabled] = React.useState(false); // Cooldown state

  // external state
  const {
    videoRef,
    cameras, cameraIdx, setCameraIdx,
    zoomControl, info, error,
    resetVideo,
  } = useCameraCapture();


  // derived state
  const { onCloseModal, onAttachImage } = props;


  const stopAndClose = React.useCallback(() => {
    resetVideo();
    onCloseModal();
  }, [onCloseModal, resetVideo]);


  const handleFlashEffect = React.useCallback((cooldownMs: number) => {
    // Flash effect
    setIsFlashing(true);
    setTimeout(() => {
      setIsFlashing(false);
    }, FLASH_DURATION_MS); // Flash duration in milliseconds

    // Cooldown
    if (cooldownMs) {
      setIsAddButtonDisabled(true);
      setTimeout(() => {
        setIsAddButtonDisabled(false);
      }, cooldownMs);
    }
  }, []);

  const handleVideoSnapClicked = React.useCallback(async () => {
    if (!videoRef.current) return;
    try {
      // handleFlashEffect(0); // Trigger flash
      const file = await renderVideoFrameAsFile(videoRef.current, 'camera', 'image/jpeg', 0.95);
      onAttachImage(file);
      stopAndClose();
    } catch (error) {
      console.error('Error capturing video frame:', error);
    }
  }, [onAttachImage, stopAndClose, videoRef]);

  const handleVideoAddClicked = React.useCallback(async () => {
    if (!videoRef.current) return;
    try {
      handleFlashEffect(ADD_COOLDOWN_MS); // Trigger flash and cooldown
      const file = await renderVideoFrameAsFile(videoRef.current, 'camera', 'image/jpeg', 0.95);
      onAttachImage(file);
    } catch (error) {
      console.error('Error capturing video frame:', error);
    }
  }, [handleFlashEffect, onAttachImage, videoRef]);

  const handleVideoDownloadClicked = React.useCallback(async () => {
    if (!videoRef.current) return;
    await downloadVideoFrame(videoRef.current, 'camera', 'image/jpeg', 0.98).catch(alert);
  }, [videoRef]);


  // Reduced set of cameras

  const displayCameras = React.useMemo(() => {
    // iOS/English: "Front Camera", "Back Camera"
    if (Is.OS.iOS) {
      let reducedCameras = cameras.filter((device) => ['Front Camera', 'Back Camera'].includes(device.label));
      if (reducedCameras.length > 0)
        return reducedCameras;
    }
    return cameras;
  }, [cameras]);

  const { canSwitchCameras, isFrontCamera, isBackCamera } = React.useMemo(() => {

    // determine if the current device is a front or back camera
    let isFrontCamera = false;
    let isBackCamera = false;
    if (cameraIdx !== -1) {
      const currentDevice = displayCameras[cameraIdx];
      if (currentDevice) {
        isFrontCamera = currentDevice.label.includes('Front Camera') || currentDevice.label.toLowerCase().includes('front');
        isBackCamera = currentDevice.label.includes('Back Camera') || currentDevice.label.toLowerCase().includes('back');
      }
    }

    // quick out if we only have 1 or 0 cameras
    if (displayCameras.length <= 1)
      return { canSwitchCameras: false, isFrontCamera, isBackCamera };

    // use a reduction to find both the front and back cameras
    const foundCameras = displayCameras.reduce((acc, device) => {
      if (acc.front && acc.back) return acc;
      if (device.label.includes('Front Camera')) acc.front = true;
      else if (device.label.toLowerCase().includes('front')) acc.front = true;
      if (device.label.includes('Back Camera')) acc.back = true;
      else if (device.label.toLowerCase().includes('back')) acc.back = true;
      return acc;
    }, { front: false, back: false });

    return { canSwitchCameras: (foundCameras.front && foundCameras.back) || displayCameras.length === 2, isFrontCamera, isBackCamera };
  }, [cameraIdx, displayCameras]);

  const handleCameraSwitch = React.useCallback(() => {

    // safety checks: has multiple cameras, and current camera is valid
    if (displayCameras.length <= 1 || cameraIdx === -1) return;
    const currentCamera = displayCameras[cameraIdx] || undefined;
    if (!currentCamera) return;

    // finds the camera to switch to
    let nextIdx: number | undefined = undefined;

    // iOS
    if (currentCamera.label.includes('Front Camera'))
      nextIdx = displayCameras.findIndex((device) => device.label.includes('Back Camera'));
    else if (currentCamera.label.includes('Back Camera'))
      nextIdx = displayCameras.findIndex((device) => device.label.includes('Front Camera'));

    // Android
    if (nextIdx === undefined && currentCamera.label.includes('facing front'))
      nextIdx = displayCameras.map((device) => device.label).findLastIndex((label) => label.includes('facing back'));
    else if (nextIdx === undefined && currentCamera.label.includes('facing back'))
      nextIdx = displayCameras.map((device) => device.label).findLastIndex((label) => label.includes('facing front'));

    // Generic: if we have 2 cameras, flip to the other one
    if (nextIdx === undefined && displayCameras.length === 2)
      nextIdx = cameraIdx === 0 ? 1 : 0;

    // if we found a valid camera, switch to it
    if (nextIdx !== undefined && nextIdx !== -1)
      setCameraIdx(nextIdx);
  }, [cameraIdx, displayCameras, setCameraIdx]);


  return (
    <Modal
      open
      onClose={stopAndClose}
      sx={{
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'center',
      }}
      slotProps={{
        backdrop: {
          sx: {
            backdropFilter: 'none', // using none because this is heavy
            // backdropFilter: 'blur(4px)',
            // backgroundColor: 'rgba(11 13 14 / 0.75)',
            backgroundColor: 'rgba(var(--joy-palette-neutral-darkChannel) / 0.5)',
          },
        },
      }}
    >

      <Box sx={{
        display: 'flex', flexDirection: 'column', m: 1,
        borderRadius: 'md', overflow: 'hidden',
        boxShadow: 'lg',
      }}>

        {/* Top bar */}
        <Sheet variant='solid' invertedColors={true} sx={{
          p: 1,
          backgroundColor: 'neutral.800',
          display: 'flex',
          justifyContent: 'space-between',
        }}>
          <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
            <Select
              size='sm'
              variant={displayCameras.length > 1 ? 'soft' : 'plain'}
              color='neutral'
              value={cameraIdx} onChange={(_event: any, value: number | null) => setCameraIdx(value === null ? -1 : value)}
              indicator={<KeyboardArrowDownIcon />}
              sx={{ background: 'transparent' }}
              slotProps={{ listbox: { size: 'md' } }}
            >
              {(!displayCameras.length || DEBUG_NO_CAMERA_OPTION) && (
                <Option key='video-dev-none' value={-1}>
                  No Camera
                </Option>
              )}
              {displayCameras.map((device: MediaDeviceInfo, camIndex) => (
                <Option key={'video-dev-' + camIndex} value={camIndex}>
                  {/*{device.label?.includes('Face') ? <CameraFrontIcon />*/}
                  {/*  : device.label?.includes('tual') ? <CameraRearIcon />*/}
                  {/*    : null}*/}
                  {device.label
                    ?.replace('camera2 ', 'Camera ')
                    .replace('facing front', 'Front')
                    .replace('facing back', 'Back')}
                </Option>
              ))}
            </Select>

            {canSwitchCameras && (
              <IconButton size='sm' onClick={handleCameraSwitch}>
                {isFrontCamera ? <CameraRearIcon /> : isBackCamera ? <CameraFrontIcon /> : <FlipCameraAndroidOutlinedIcon />}
              </IconButton>
            )}
          </Box>

          <ModalClose size='lg' onClick={stopAndClose} sx={{ position: 'static' }} />
        </Sheet>

        {/* (main) Video */}
        <Box sx={{ position: 'relative', backgroundColor: 'background.level3' }}>
          <video
            ref={videoRef} autoPlay playsInline
            style={{
              display: 'block',
              width: !Is.Browser.Safari ? '100%' : undefined,
              marginLeft: 'auto', marginRight: 'auto',
              maxHeight: 'calc(100vh - 200px)',
              background: '#8888', //opacity: ocrProgress !== null ? 0.5 : 1,
            }}
          />

          {/* Flash overlay */}
          {isFlashing && (
            <Box
              sx={{
                position: 'absolute', inset: 0, zIndex: 2,
                animation: `${animationBackgroundCameraFlash} ${FLASH_DURATION_MS / 1000}s`,
              }}
            />
          )}

          {showInfo && !!info && (
            <Typography
              sx={{
                position: 'absolute', inset: 0, zIndex: 1, /* camera info on top of video */
                background: 'rgba(0,0,0,0.5)', color: 'white',
                whiteSpace: 'pre', overflowY: 'scroll',
              }}>
              {info}
            </Typography>
          )}

          {/*{ocrProgress !== null && <CircularProgress sx={{ position: 'absolute', top: 'calc(50% - 34px / 2)', left: 'calc(50% - 34px / 2)', zIndex: 2 }} />}*/}
        </Box>

        {/* Bottom controls (zoom, download) & progress */}
        <Sheet
          variant='soft'
          sx={{
            p: 1,
            display: 'flex',
            flexDirection: 'column',
            gap: 1,
          }}
        >
          {!!error && <InlineError error={error} />}

          {zoomControl}

          {/*{ocrProgress !== null && <LinearProgress color='primary' determinate value={100 * ocrProgress} sx={{ px: 2 }} />}*/}

          <Box paddingBottom={zoomControl ? 1 : undefined} sx={captureButtonContainerSx}>

            {/* Info */}
            <IconButton disabled={!info} onClick={() => setShowInfo((prev) => !prev)}>
              <InfoOutlinedIcon />
            </IconButton>

            {/*<Button disabled={ocrProgress !== null} fullWidth variant='solid' size='lg' onClick={handleVideoOCRClicked} sx={{ flex: 1, maxWidth: 260 }}>*/}
            {/*  Extract Text*/}
            {/*</Button>*/}

            {/* Capture */}
            <ButtonGroup variant='solid' sx={captureButtonGroupSx}>
              <Tooltip disableInteractive arrow placement='top' title='Add to message'>
                <IconButton size='sm' disabled={isAddButtonDisabled} onClick={handleVideoAddClicked} sx={addButtonSx}>
                  <AddRoundedIcon />
                </IconButton>
              </Tooltip>
              <Button size='lg' onClick={handleVideoSnapClicked} endDecorator={<CameraEnhanceIcon />} sx={captureButtonSx}>
                Capture
              </Button>
            </ButtonGroup>

            {/* Download */}
            <IconButton onClick={handleVideoDownloadClicked}>
              <DownloadIcon />
            </IconButton>

          </Box>
        </Sheet>

      </Box>
    </Modal>
  );
}


================================================
FILE: src/apps/chat/components/composer/Composer.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';
import type { FileWithHandle } from 'browser-fs-access';

import { Box, Button, ButtonGroup, Card, Dropdown, Grid, IconButton, Menu, MenuButton, MenuItem, Textarea, Typography } from '@mui/joy';
import { ColorPaletteProp, SxProps, VariantProp } from '@mui/joy/styles/types';
import AddCircleOutlineIcon from '@mui/icons-material/AddCircleOutline';
import ExpandLessIcon from '@mui/icons-material/ExpandLess';
import PsychologyIcon from '@mui/icons-material/Psychology';
import SendIcon from '@mui/icons-material/Send';
import StopOutlinedIcon from '@mui/icons-material/StopOutlined';
import TelegramIcon from '@mui/icons-material/Telegram';

import type { AppChatIntent } from '../../AppChat';
import { useChatAutoSuggestAttachmentPrompts, useChatMicTimeoutMsValue } from '../../store-app-chat';

import { useAgiAttachmentPrompts } from '~/modules/aifn/agiattachmentprompts/useAgiAttachmentPrompts';
import { useBrowseCapability } from '~/modules/browse/store-module-browsing';

import { DLLM, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { AudioGenerator } from '~/common/util/audio/AudioGenerator';
import { AudioPlayer } from '~/common/util/audio/AudioPlayer';
import { ButtonAttachFilesMemo, openFileForAttaching } from '~/common/components/ButtonAttachFiles';
import { ChatBeamIcon } from '~/common/components/icons/ChatBeamIcon';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { ConversationsManager } from '~/common/chat-overlay/ConversationsManager';
import { DMessageId, DMessageMetadata, DMetaReferenceItem, messageFragmentsReduceText } from '~/common/stores/chat/chat.message';
import { ShortcutKey, ShortcutObject, useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { addSnackbar } from '~/common/components/snackbar/useSnackbarsStore';
import { animationEnterBelow } from '~/common/util/animUtils';
import { browserSpeechRecognitionCapability, PLACEHOLDER_INTERIM_TRANSCRIPT, SpeechResult, useSpeechRecognition } from '~/common/components/speechrecognition/useSpeechRecognition';
import { DConversationId } from '~/common/stores/chat/chat.conversation';
import { copyToClipboard, supportsClipboardRead } from '~/common/util/clipboardUtils';
import { createTextContentFragment, DMessageAttachmentFragment, DMessageContentFragment, duplicateDMessageFragments } from '~/common/stores/chat/chat.fragments';
import { glueForMessageTokens, marshallWrapDocFragments } from '~/common/stores/chat/chat.tokens';
import { isValidConversation, useChatStore } from '~/common/stores/chat/store-chats';
import { getModelParameterValueOrThrow } from '~/common/stores/llms/llms.parameters';
import { launchAppCall, removeQueryParam, useRouterQuery } from '~/common/app.routes';
import { lineHeightTextareaMd, themeBgAppChatComposer } from '~/common/app.theme';
import { optimaOpenPreferences } from '~/common/layout/optima/useOptima';
import { platformAwareKeystrokes } from '~/common/components/KeyStroke';
import { supportsScreenCapture } from '~/common/util/screenCaptureUtils';
import { useChatComposerOverlayStore } from '~/common/chat-overlay/store-perchat_vanilla';
import { useComposerStartupText, useLogicSherpaStore } from '~/common/logic/store-logic-sherpa';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';
import { useUICounter, useUIPreferencesStore } from '~/common/stores/store-ui';
import { useUXLabsStore } from '~/common/stores/store-ux-labs';

import type { ActileItem } from './actile/ActileProvider';
import { providerAttachmentLabels } from './actile/providerAttachmentLabels';
import { providerCommands } from './actile/providerCommands';
import { providerStarredMessages, StarredMessageItem } from './actile/providerStarredMessage';
import { useActileManager } from './actile/useActileManager';

import type { AttachmentDraftId } from '~/common/attachment-drafts/attachment.types';
import { LLMAttachmentDraftsAction, LLMAttachmentsList } from './llmattachments/LLMAttachmentsList';
import { PhPaintBrush } from '~/common/components/icons/phosphor/PhPaintBrush';
import { useAttachmentDrafts } from '~/common/attachment-drafts/useAttachmentDrafts';
import { useLLMAttachmentDrafts } from './llmattachments/useLLMAttachmentDrafts';

import type { ChatExecuteMode } from '../../execute-mode/execute-mode.types';
import { chatExecuteModeCanAttach, useChatExecuteMode } from '../../execute-mode/useChatExecuteMode';

import { ButtonAttachCameraMemo, useCameraCaptureModalDialog } from './buttons/ButtonAttachCamera';
import { ButtonAttachClipboardMemo } from './buttons/ButtonAttachClipboard';
import { ButtonAttachScreenCaptureMemo } from './buttons/ButtonAttachScreenCapture';
import { ButtonAttachWebMemo } from './buttons/ButtonAttachWeb';
import { ButtonBeamMemo } from './buttons/ButtonBeam';
import { ButtonCallMemo } from './buttons/ButtonCall';
import { ButtonGroupDrawRepeat } from './buttons/ButtonGroupDrawRepeat';
import { ButtonMicContinuationMemo } from './buttons/ButtonMicContinuation';
import { ButtonMicMemo } from './buttons/ButtonMic';
import { ButtonMultiChatMemo } from './buttons/ButtonMultiChat';
import { ButtonOptionsDraw } from './buttons/ButtonOptionsDraw';
import { ComposerTextAreaActions } from './textarea/ComposerTextAreaActions';
import { ComposerTextAreaDrawActions } from './textarea/ComposerTextAreaDrawActions';
import { StatusBarMemo } from '../StatusBar';
import { TokenBadgeMemo } from './tokens/TokenBadge';
import { TokenProgressbarMemo } from './tokens/TokenProgressbar';
import { useComposerDragDrop } from './useComposerDragDrop';
import { useTextTokenCount } from './tokens/useTextTokenCounter';
import { useWebInputModal } from './WebInputModal';


// configuration
const zIndexComposerOverlayMic = 10;
const SHOW_TIPS_AFTER_RELOADS = 25;



const paddingBoxSx: SxProps = {
  p: { xs: 1, md: 2 },
};


const minimizedSx: SxProps = {
  ...paddingBoxSx,
  display: 'none',
};


/**
 * A React component for composing messages, with attachments and different modes.
 */
export function Composer(props: {
  isMobile: boolean;
  chatLLM: DLLM | null;
  composerTextAreaRef: React.RefObject<HTMLTextAreaElement | null>;
  targetConversationId: DConversationId | null;
  capabilityHasT2I: boolean;
  capabilityHasT2IEdit: boolean;
  isMulticast: boolean | null;
  isDeveloperMode: boolean;
  onAction: (conversationId: DConversationId, chatExecuteMode: ChatExecuteMode, fragments: (DMessageContentFragment | DMessageAttachmentFragment)[], metadata?: DMessageMetadata) => boolean;
  onConversationBeamEdit: (conversationId: DConversationId, editMessageId?: DMessageId) => Promise<void>;
  onConversationsImportFromFiles: (files: File[]) => Promise<void>;
  onTextImagine: (conversationId: DConversationId, text: string) => void;
  setIsMulticast: (on: boolean) => void;
  onComposerHasContent: (hasContent: boolean) => void;
  sx?: SxProps;
}) {

  // state
  const [composeText, setComposeText] = React.useState('');
  const [drawRepeat, setDrawRepeat] = React.useState(1);
  const [micContinuation, setMicContinuation] = React.useState(false);
  const [speechInterimResult, setSpeechInterimResult] = React.useState<SpeechResult | null>(null);
  const [sendStarted, setSendStarted] = React.useState(false);
  const {
    chatExecuteMode,
    chatExecuteModeSendColor, chatExecuteModeSendLabel,
    chatExecuteMenuComponent, chatExecuteMenuShown, showChatExecuteMenu,
  } = useChatExecuteMode(props.capabilityHasT2I, props.isMobile);
  const [isMinimized, setIsMinimized] = React.useState(false);
  const micCardRef = React.useRef<HTMLDivElement>(null);

  // external state
  const { showPromisedOverlay } = useOverlayComponents();
  const { newChat: appChatNewChatIntent } = useRouterQuery<Partial<AppChatIntent>>();
  const { labsAttachScreenCapture, labsCameraDesktop, labsShowCost, labsShowShortcutBar } = useUXLabsStore(useShallow(state => ({
    labsAttachScreenCapture: state.labsAttachScreenCapture,
    labsCameraDesktop: state.labsCameraDesktop,
    labsShowCost: state.labsShowCost,
    labsShowShortcutBar: state.labsShowShortcutBar,
  })));
  const timeToShowTips = useLogicSherpaStore(state => state.usageCount >= SHOW_TIPS_AFTER_RELOADS);
  const { novel: explainShiftEnter, touch: touchShiftEnter } = useUICounter('composer-shift-enter');
  const { novel: explainAltEnter, touch: touchAltEnter } = useUICounter('composer-alt-enter');
  const { novel: explainCtrlEnter, touch: touchCtrlEnter } = useUICounter('composer-ctrl-enter');
  const [startupText, setStartupText] = useComposerStartupText();
  const enterIsNewline = useUIPreferencesStore(state => state.enterIsNewline);
  const composerQuickButton = useUIPreferencesStore(state => state.composerQuickButton);
  const chatMicTimeoutMs = useChatMicTimeoutMsValue();
  const { assistantAbortible, systemPurposeId, tokenCount: _historyTokenCount, abortConversationTemp } = useChatStore(useShallow(state => {
    const conversation = state.conversations.find(_c => _c.id === props.targetConversationId);
    return {
      assistantAbortible: conversation ? !!conversation._abortController : false,
      systemPurposeId: conversation?.systemPurposeId ?? null,
      tokenCount: conversation ? conversation.tokenCount : 0,
      abortConversationTemp: state.abortConversationTemp,
    };
  }));

  // external overlay state (extra conversationId-dependent state)
  const conversationOverlayStore = props.targetConversationId
    ? ConversationsManager.getHandler(props.targetConversationId)?.conversationOverlayStore ?? null
    : null;

  // composer-overlay: for the in-reference-to state, comes from the conversation overlay
  const allowInReferenceTo = chatExecuteMode === 'generate-content';
  const inReferenceTo = useChatComposerOverlayStore(conversationOverlayStore, store => allowInReferenceTo ? store.inReferenceTo : null);

  // LLM-derived
  const noLLM = !props.chatLLM;
  const chatLLMSupportsImages = !!props.chatLLM?.interfaces?.includes(LLM_IF_OAI_Vision);

  // don't load URLs if the user is typing a command or there's no capability
  const hasComposerBrowseCapability = useBrowseCapability().inComposer;
  const enableLoadURLsInComposer = hasComposerBrowseCapability && !composeText.startsWith('/');

  // user message for attachments
  const { onConversationBeamEdit, onConversationsImportFromFiles } = props;
  const handleFilterAGIFile = React.useCallback(async (file: File): Promise<boolean> =>
    await showPromisedOverlay('composer-open-or-attach', { rejectWithValue: false }, ({ onResolve, onUserReject }) => (
      <ConfirmationModal
        open onClose={onUserReject}
        onPositive={() => {
          onConversationsImportFromFiles([file]);
          onResolve(true);
        }}
        title='Open Conversation or Attach?'
        positiveActionText='Open' negativeActionText='Attach'
        confirmationText={`Would you like to open the conversation "${file.name}" or attach it to the message?`}
      />
    )), [onConversationsImportFromFiles, showPromisedOverlay]);

  // attachments-overlay: comes from the attachments slice of the conversation overlay
  const showChatAttachments = chatExecuteModeCanAttach(chatExecuteMode, props.capabilityHasT2IEdit);
  const {
    /* items */ attachmentDrafts,
    /* append */ attachAppendClipboardItems, attachAppendDataTransfer, attachAppendEgoFragments, attachAppendFile, attachAppendUrl,
    /* take */ attachmentsRemoveAll, attachmentsTakeAllFragments, attachmentsTakeFragmentsByType,
  } = useAttachmentDrafts(conversationOverlayStore, enableLoadURLsInComposer, chatLLMSupportsImages, handleFilterAGIFile, showChatAttachments === 'only-images');

  // attachments derived state
  const llmAttachmentDraftsCollection = useLLMAttachmentDrafts(attachmentDrafts, props.chatLLM, chatLLMSupportsImages);

  // drag/drop
  const { dragContainerSx, dropComponent, handleContainerDragEnter, handleContainerDragStart } = useComposerDragDrop(!props.isMobile, attachAppendDataTransfer);

  // ai functions
  const agiAttachmentPrompts = useAgiAttachmentPrompts(useChatAutoSuggestAttachmentPrompts(), attachmentDrafts);


  // derived state

  const { composerTextAreaRef, targetConversationId, onAction, onTextImagine } = props;
  const isMobile = props.isMobile;
  const isDesktop = !props.isMobile;
  const noConversation = !targetConversationId;

  const composerTextSuffix = chatExecuteMode === 'generate-image' && isDesktop && drawRepeat > 1 ? ` x${drawRepeat}` : '';

  const micIsRunning = !!speechInterimResult;
  // more mic way below, as we use complex hooks


  // tokens derived state

  const tokensComposerTextDebounced = useTextTokenCount(composeText, props.chatLLM, 800, 1600);
  let tokensComposer = (tokensComposerTextDebounced ?? 0) + (llmAttachmentDraftsCollection.llmTokenCountApprox || 0);
  if (props.chatLLM && tokensComposer > 0)
    tokensComposer += glueForMessageTokens(props.chatLLM);
  const tokensHistory = _historyTokenCount;
  const tokensResponseMax = getModelParameterValueOrThrow('llmResponseTokens', props.chatLLM?.initialParameters, props.chatLLM?.userParameters, 0) ?? 0;
  const tokenLimit = props.chatLLM?.contextTokens || 0;
  const tokenChatPricing = props.chatLLM?.pricing?.chat;


  // Effect: load initial text if queued up (e.g. by /link/share_targetF)
  React.useEffect(() => {
    if (startupText) {
      setStartupText(null);
      setComposeText(startupText);
    }
  }, [setComposeText, setStartupText, startupText]);

  // Effect: notify the parent of presence/absence of content
  const isContentful = composeText.length > 0 || !!attachmentDrafts.length;
  const { onComposerHasContent } = props;
  React.useEffect(() => {
    onComposerHasContent?.(isContentful);
  }, [isContentful, onComposerHasContent]);


  // Overlay actions

  const handleRemoveInReferenceTo = React.useCallback((item: DMetaReferenceItem) => {
    conversationOverlayStore?.getState().removeInReferenceTo(item);
  }, [conversationOverlayStore]);

  const handleInReferenceToClear = React.useCallback(() => {
    conversationOverlayStore?.getState().clearInReferenceTo();
  }, [conversationOverlayStore]);

  React.useEffect(() => {
    if (inReferenceTo?.length)
      setTimeout(() => composerTextAreaRef.current?.focus(), 1 /* prevent focus theft */);
  }, [composerTextAreaRef, inReferenceTo]);


  // Confirmation Modals

  const confirmProceedIfAttachmentsNotSupported = React.useCallback(async (): Promise<boolean> => {
    if (llmAttachmentDraftsCollection.canAttachAllFragments) return true;
    return await showPromisedOverlay('composer-unsupported-attachments', { rejectWithValue: false }, ({ onResolve, onUserReject }) => (
      <ConfirmationModal
        open
        onClose={onUserReject}
        onPositive={() => onResolve(true)}
        confirmationText='Some attached files may not be fully compatible with the current AI model. This could affect processing. Would you like to review or proceed?'
        positiveActionText='Proceed'
        negativeActionText='Review Attachments'
        title='Attachment Compatibility Notice'
      />
    ));
  }, [llmAttachmentDraftsCollection.canAttachAllFragments, showPromisedOverlay]);


  // Primary button

  const _handleClearText = React.useCallback(() => {
    setComposeText('');
    attachmentsRemoveAll();
    handleInReferenceToClear();
  }, [attachmentsRemoveAll, handleInReferenceToClear, setComposeText]);

  const _handleSendActionUnguarded = React.useCallback(async (_chatExecuteMode: ChatExecuteMode, composerText: string): Promise<boolean> => {
    if (!isValidConversation(targetConversationId)) return false;

    // await user confirmation (or rejection) if attachments are not supported
    if (!await confirmProceedIfAttachmentsNotSupported()) return false;

    // validate some chat mode inputs
    const isDraw = _chatExecuteMode === 'generate-image';
    const isBlank = !composerText.trim();
    if (isDraw && isBlank) {
      addSnackbar({ key: 'chat-draw-empty', message: 'Please enter a description to generate an image.', type: 'info' });
      return false;
    }

    // prepare the fragments: content (if any) and attachments (if allowed, and any)
    const fragments: (DMessageContentFragment | DMessageAttachmentFragment)[] = [];
    if (composerText)
      fragments.push(createTextContentFragment(composerText + composerTextSuffix));

    const canAttach = chatExecuteModeCanAttach(_chatExecuteMode, props.capabilityHasT2IEdit);
    if (canAttach) {
      const attachmentFragments = await attachmentsTakeAllFragments('global', 'app-chat');
      fragments.push(...attachmentFragments);
    }

    if (!fragments.length) {
      // addSnackbar({ key: 'chat-composer-empty', message: 'Please enter a message or attach files.', type: 'info' });
      return false;
    }

    // prepare the metadata
    const metadata = inReferenceTo?.length ? { inReferenceTo: inReferenceTo } : undefined;

    // send the message - NOTE: if successful, the ownership of the fragments is transferred to the receiver, so we just clear them
    const enqueued = onAction(targetConversationId, _chatExecuteMode, fragments, metadata);
    if (enqueued)
      _handleClearText();
    return enqueued;
  }, [targetConversationId, confirmProceedIfAttachmentsNotSupported, composerTextSuffix, props.capabilityHasT2IEdit, inReferenceTo, onAction, _handleClearText, attachmentsTakeAllFragments]);

  const handleSendAction = React.useCallback(async (chatExecuteMode: ChatExecuteMode, composerText: string): Promise<boolean> => {
    setSendStarted(true);
    const enqueued = await _handleSendActionUnguarded(chatExecuteMode, composerText);
    setSendStarted(false);
    return enqueued;
  }, [_handleSendActionUnguarded, setSendStarted]);


  // Mic typing & continuation mode - NOTE: this is here because needs the handleSendAction, and provides recognitionState

  const onSpeechResultCallback = React.useCallback((result: SpeechResult) => {
    // not done: show interim
    if (!result.done) {
      setSpeechInterimResult({ ...result });
      return;
    }

    // done
    setSpeechInterimResult(null);
    const transcript = result.transcript.trim();
    let nextText = (composeText || '').trim();
    nextText = nextText ? nextText + ' ' + transcript : transcript;

    // auto-send (mic continuation mode) if requested
    const autoSend = (result.flagSendOnDone || micContinuation) && nextText.length >= 1 && !noConversation; //&& assistantAbortible;
    const notUserStop = result.doneReason !== 'manual';
    if (autoSend) {
      // if (notUserStop) {
      void AudioGenerator.chatAutoSend();
      // void AudioPlayer.playUrl('/sounds/mic-off-mid.mp3');
      // }
      void handleSendAction(chatExecuteMode, nextText); // fire/forget
    } else {
      // if scheduled for send but not sent, clear the send state
      if (result.flagSendOnDone)
        setSendStarted(false);

      // mic off sound
      if (!micContinuation && notUserStop)
        void AudioPlayer.playUrl('/sounds/mic-off-mid.mp3').catch(() => {
          // This happens on Is.Browser.Safari, where the audio is not allowed to play without user interaction
        });

      // update with the spoken text
      if (nextText) {
        composerTextAreaRef.current?.focus();
        setComposeText(nextText);
      }
    }
  }, [chatExecuteMode, composeText, composerTextAreaRef, handleSendAction, micContinuation, noConversation, setComposeText]);

  const { recognitionState, toggleRecognition } = useSpeechRecognition('webSpeechApi', onSpeechResultCallback, chatMicTimeoutMs || 2000);

  const micContinuationTrigger = micContinuation && !micIsRunning && !assistantAbortible && !recognitionState.errorMessage;
  const micColor: ColorPaletteProp = recognitionState.errorMessage ? 'danger' : recognitionState.isActive ? 'primary' : recognitionState.hasAudio ? 'primary' : 'neutral';
  const micVariant: VariantProp = recognitionState.hasSpeech ? 'solid' : recognitionState.hasAudio ? 'soft' : 'soft';  //(isDesktop ? 'soft' : 'plain');

  const handleToggleMic = React.useCallback(() => {
    if (micIsRunning && micContinuation)
      setMicContinuation(false);
    toggleRecognition();
  }, [micContinuation, micIsRunning, toggleRecognition]);

  const handleToggleMicContinuation = React.useCallback(() => {
    setMicContinuation(continued => !continued);
  }, []);

  React.useEffect(() => {
    // autostart the microphone if the assistant stopped typing
    if (micContinuationTrigger)
      toggleRecognition();
  }, [toggleRecognition, micContinuationTrigger]);

  React.useEffect(() => {
    // auto-scroll the mic card to the bottom
    micCardRef.current?.scrollTo({
      top: micCardRef.current.scrollHeight,
      behavior: 'smooth',
    });
  }, [speechInterimResult]);

  React.useEffect(() => {
    // auto-start the microphone if appChat was created with a particular intent
    if (appChatNewChatIntent === 'voiceInput') {
      toggleRecognition();
      void removeQueryParam('newChat');
    }
  }, [appChatNewChatIntent, toggleRecognition]);


  // Other send actins

  const handleAppendTextAndSend = React.useCallback(async (appendText: string) => {
    const newText = composeText ? `${composeText} ${appendText}` : appendText;
    setComposeText(newText);
    await handleSendAction(chatExecuteMode, newText);
  }, [chatExecuteMode, composeText, handleSendAction, setComposeText]);

  const handleFinishMicAndSend = React.useCallback(() => {
    if (!sendStarted) {
      setSendStarted(true);
      toggleRecognition(true);
    }
  }, [sendStarted, toggleRecognition]);

  const handleSendClicked = React.useCallback(async () => {
    // Auto-send as soon as the mic is done
    if (recognitionState.isActive) {
      handleFinishMicAndSend();
      return;
    }
    // Safety option
    if (micIsRunning) {
      addSnackbar({ key: 'chat-mic-running', message: 'Please wait for the microphone to finish.', type: 'info' });
      return;
    }
    await handleSendAction(chatExecuteMode, composeText); // 'chat/write/...' button
  }, [chatExecuteMode, composeText, handleFinishMicAndSend, handleSendAction, micIsRunning, recognitionState.isActive]);

  const handleSendTextBeamClicked = React.useCallback(async () => {
    if (micIsRunning) {
      addSnackbar({ key: 'chat-mic-running', message: 'Please wait for the microphone to finish.', type: 'info' });
      return;
    }
    if (composeText) {
      await handleSendAction('beam-content', composeText); // 'beam' button
    } else {
      if (targetConversationId)
        void onConversationBeamEdit(targetConversationId); // beam-edit conversation
    }
  }, [composeText, handleSendAction, micIsRunning, onConversationBeamEdit, targetConversationId]);

  const handleStopClicked = React.useCallback(() => {
    targetConversationId && abortConversationTemp(targetConversationId);
  }, [abortConversationTemp, targetConversationId]);


  // Secondary buttons

  const handleCallClicked = React.useCallback(() => {
    targetConversationId && systemPurposeId && launchAppCall(targetConversationId, systemPurposeId);
  }, [systemPurposeId, targetConversationId]);

  const handleDrawOptionsClicked = React.useCallback(() => optimaOpenPreferences('draw'), []);

  const handleTextImagineClicked = React.useCallback(() => {
    if (!composeText || !targetConversationId) return;
    onTextImagine(targetConversationId, composeText);
    setComposeText('');
  }, [composeText, onTextImagine, setComposeText, targetConversationId]);


  // Actiles

  const onActileCommandPaste = React.useCallback(({ label }: ActileItem, searchPrefix: string) => {
    if (composerTextAreaRef.current) {
      const textArea = composerTextAreaRef.current;
      const currentText = textArea.value;
      const cursorPos = textArea.selectionStart;

      // Find the position where the command starts
      const commandStart = currentText.lastIndexOf(searchPrefix, cursorPos);

      // Construct the new text with the autocompleted command
      setComposeText((prevText) => prevText.substring(0, commandStart) + label + ' ' + prevText.substring(cursorPos));

      // Schedule setting the cursor position after the state update
      const newCursorPos = commandStart + label.length + 1;
      setTimeout(() => composerTextAreaRef.current?.setSelectionRange(newCursorPos, newCursorPos), 0);
    }
  }, [composerTextAreaRef, setComposeText]);

  const onActileEmbedMessage = React.useCallback(async ({ conversationId, messageId }: StarredMessageItem) => {
    // get the message
    const cHandler = ConversationsManager.getHandler(conversationId);
    const messageToEmbed = cHandler.historyFindMessageOrThrow(messageId);
    if (messageToEmbed) {
      const fragmentsCopy = duplicateDMessageFragments(messageToEmbed.fragments, true); // [attach] deep copy a message's fragments to attach to ego
      if (fragmentsCopy.length) {
        const chatTitle = cHandler.title() ?? '';
        const messageText = messageFragmentsReduceText(fragmentsCopy);
        const label = `${chatTitle} > ${messageText.slice(0, 10)}...`;
        await attachAppendEgoFragments(fragmentsCopy, label, chatTitle, conversationId, messageId);
      }
    }
  }, [attachAppendEgoFragments]);


  const actileProviders = React.useMemo(() => [
    providerAttachmentLabels(conversationOverlayStore, onActileCommandPaste),
    providerCommands(onActileCommandPaste),
    providerStarredMessages(onActileEmbedMessage),
  ], [conversationOverlayStore, onActileCommandPaste, onActileEmbedMessage]);

  const { actileComponent, actileInterceptKeydown, actileInterceptTextChange } = useActileManager(actileProviders, composerTextAreaRef);


  // Type...

  const handleTextareaTextChange = React.useCallback((e: React.ChangeEvent<HTMLTextAreaElement>) => {
    setComposeText(e.target.value);
    isMobile && actileInterceptTextChange(e.target.value);
  }, [actileInterceptTextChange, isMobile, setComposeText]);

  const handleTextareaKeyDown = React.useCallback(async (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    // disable keyboard handling if the actile is visible
    if (actileInterceptKeydown(e))
      return;

    // Enter: primary action
    if (e.key === 'Enter') {

      // Alt (Windows) or Option (Mac) + Enter: append the message instead of sending it
      if (e.altKey && !e.metaKey && !e.ctrlKey) {
        if (await handleSendAction('append-user', composeText)) // 'alt+enter' -> write
          touchAltEnter();
        return e.preventDefault();
      }

      // Ctrl (Windows) or Command (Mac) + Enter: send for beaming
      if (e.ctrlKey && !e.metaKey && !e.altKey) {
        if (await handleSendAction('beam-content', composeText)) { // 'ctrl+enter' -> beam
          touchCtrlEnter();
          e.stopPropagation();
        }
        return e.preventDefault();
      }

      // Shift: toggles the 'enter is newline'
      if (e.shiftKey)
        touchShiftEnter();
      if (enterIsNewline ? e.shiftKey : !e.shiftKey) {
        if (!assistantAbortible)
          await handleSendAction(chatExecuteMode, composeText); // enter -> send
        return e.preventDefault();
      }
    }

  }, [actileInterceptKeydown, assistantAbortible, chatExecuteMode, composeText, enterIsNewline, handleSendAction, touchAltEnter, touchCtrlEnter, touchShiftEnter]);


  // Focus mode

  // const handleFocusModeOn = React.useCallback(() => setIsFocusedMode(true), [setIsFocusedMode]);

  // const handleFocusModeOff = React.useCallback(() => setIsFocusedMode(false), [setIsFocusedMode]);

  // useMediaSessionCallbacks({ play: toggleRecognition, pause: toggleRecognition });


  // Minimize

  const handleToggleMinimized = React.useCallback(() => setIsMinimized(hide => !hide), []);


  // Attachment Up

  const handleAttachCtrlV = React.useCallback(async (event: React.ClipboardEvent) => {
    if (await attachAppendDataTransfer(event.clipboardData, 'paste', false) === 'as_files')
      event.preventDefault();
  }, [attachAppendDataTransfer]);

  const handleAttachCameraImage = React.useCallback((file: FileWithHandle) => {
    void attachAppendFile('camera', file);
  }, [attachAppendFile]);

  const { openCamera, cameraCaptureComponent } = useCameraCaptureModalDialog(handleAttachCameraImage);

  const handleAttachScreenCapture = React.useCallback((file: File) => {
    void attachAppendFile('screencapture', file);
  }, [attachAppendFile]);

  const handleAttachFiles = React.useCallback(async (files: FileWithHandle[], errorMessage: string | null) => {
    if (errorMessage)
      addSnackbar({ key: 'attach-files-open-fail', message: `Unable to open files: ${errorMessage}`, type: 'issue' });
    for (let file of files)
      await attachAppendFile('file-open', file)
        .catch((error: any) => addSnackbar({ key: 'attach-file-open-fail', message: `Unable to attach the file "${file.name}" (${error?.message || error?.toString() || 'unknown error'})`, type: 'issue' }));
  }, [attachAppendFile]);

  const handleAttachWebLinks = React.useCallback(async (links: { url: string }[]) => {
    links.forEach(link => void attachAppendUrl('input-link', link.url));
  }, [attachAppendUrl]);

  const { openWebInputDialog, webInputDialogComponent } = useWebInputModal(handleAttachWebLinks, composeText);


  // Attachments Down

  const handleAttachmentDraftsAction = React.useCallback((attachmentDraftIdOrAll: AttachmentDraftId | null, action: LLMAttachmentDraftsAction) => {
    switch (action) {
      case 'copy-text':
        const copyFragments = attachmentsTakeFragmentsByType('doc', attachmentDraftIdOrAll, false);
        const copyString = marshallWrapDocFragments(null, copyFragments, false, '\n\n---\n\n');
        copyToClipboard(copyString, attachmentDraftIdOrAll ? 'Attachment Text' : 'Attachments Text');
        break;
      case 'inline-text':
        const inlineFragments = attachmentsTakeFragmentsByType('doc', attachmentDraftIdOrAll, true);
        setComposeText(currentText => marshallWrapDocFragments(currentText, inlineFragments, 'markdown-code', '\n\n'));
        break;
    }
  }, [attachmentsTakeFragmentsByType, setComposeText]);


  // Keyboard Shortcuts

  useGlobalShortcuts('ChatComposer.Gen', React.useMemo(() => [
    ...(assistantAbortible ? [{ key: ShortcutKey.Esc, action: handleStopClicked, description: 'Stop response', level: 2 }] : []),
  ], [assistantAbortible, handleStopClicked]));

  useGlobalShortcuts('ChatComposer', React.useMemo(() => {
    const composerShortcuts: ShortcutObject[] = [];
    if (showChatAttachments) {
      composerShortcuts.push({ key: 'f', ctrl: true, shift: true, action: () => openFileForAttaching(true, handleAttachFiles), description: 'Attach File' });
      composerShortcuts.push({ key: 'l', ctrl: true, shift: true, action: openWebInputDialog, description: 'Attach Link' });
      if (supportsClipboardRead())
        composerShortcuts.push({ key: 'v', ctrl: true, shift: true, action: attachAppendClipboardItems, description: 'Attach Clipboard' });
      // Future: keep reactive state here to support Live Screen Capture and more
      // if (labsAttachScreenCapture && supportsScreenCapture)
      //   composerShortcuts.push({ key: 's', ctrl: true, shift: true, action: openScreenCaptureDialog, description: 'Attach Screen Capture' });
    }
    if (recognitionState.isActive) {
      composerShortcuts.push({ key: 'm', ctrl: true, action: handleFinishMicAndSend, description: 'Mic · Send', disabled: !recognitionState.hasSpeech || sendStarted, endDecoratorIcon: TelegramIcon as any, level: 4 });
      composerShortcuts.push({
        key: ShortcutKey.Esc, action: () => {
          setMicContinuation(false);
          toggleRecognition(false);
        }, description: 'Mic · Stop', level: 4,
      });
    } else if (browserSpeechRecognitionCapability().mayWork)
      composerShortcuts.push({
        key: 'm', ctrl: true, action: () => {
          // steal focus from the textarea, in case it has - so that enter cannot work against us
          (document.activeElement as HTMLElement)?.blur?.();
          toggleRecognition(false);
        }, description: 'Microphone',
      });
    return composerShortcuts;
  }, [attachAppendClipboardItems, handleAttachFiles, handleFinishMicAndSend, openWebInputDialog, recognitionState.hasSpeech, recognitionState.isActive, sendStarted, showChatAttachments, toggleRecognition]));


  // ...

  const isText = chatExecuteMode === 'generate-content';
  const isTextBeam = chatExecuteMode === 'beam-content';
  const isAppend = chatExecuteMode === 'append-user';
  const isReAct = chatExecuteMode === 'react-content';
  const isDraw = chatExecuteMode === 'generate-image';

  const showChatInReferenceTo = !!inReferenceTo?.length;
  const showChatExtras = isText && !showChatInReferenceTo && !assistantAbortible && composerQuickButton !== 'off';

  const sendButtonVariant: VariantProp = (isAppend || (isMobile && isTextBeam)) ? 'outlined' : 'solid';

  const sendButtonColor: ColorPaletteProp =
    assistantAbortible ? 'warning'
      : !llmAttachmentDraftsCollection.canAttachAllFragments ? 'warning'
        : chatExecuteModeSendColor;

  const sendButtonLabel = chatExecuteModeSendLabel;

  const sendButtonIcon =
    micContinuation ? null
      : isAppend ? <SendIcon sx={{ fontSize: 18 }} />
        : isReAct ? <PsychologyIcon />
          : isTextBeam ? <ChatBeamIcon /> /* <GavelIcon /> */
            : isDraw ? <PhPaintBrush />
              : <TelegramIcon />;

  const beamButtonColor: ColorPaletteProp | undefined =
    !llmAttachmentDraftsCollection.canAttachAllFragments ? 'warning'
      : undefined;

  const showTint: ColorPaletteProp | undefined = isDraw ? 'warning' : isReAct ? 'success' : undefined;

  // stable randomization of the /verb, between '/draw', '/react'
  const placeholderAction = React.useMemo(() => {
    const actions: string[] = ['/react'];
    if (props.capabilityHasT2I) actions.push('/draw');
    return actions[Math.floor(Math.random() * actions.length)];
  }, [props.capabilityHasT2I]);

  let textPlaceholder: string =
    isDraw ? 'Describe what you would like to see...'
      : isReAct ? 'Ask a multi-step reasoning question...'
        : isTextBeam ? 'Combine insights from multiple AI models...'
          : showChatInReferenceTo ? 'Chat about this...'
            : 'Type'
            + (props.isDeveloperMode ? ' · attach code' : '')
            + (isDesktop ? ` · drop ${props.isDeveloperMode ? 'source' : 'files'}` : '')
            + ` · ${placeholderAction}`
            + (recognitionState.isAvailable ? ' · ramble' : '')
            + '...';

  if (isDesktop && timeToShowTips && !isDraw) {
    if (explainShiftEnter)
      textPlaceholder += !enterIsNewline ? '\n\n💡 Shift + Enter to add a new line' : '\n\n💡 Shift + Enter to send';
    else if (explainAltEnter)
      textPlaceholder += platformAwareKeystrokes('\n\n💡 Tip: Alt + Enter to just append the message');
    else if (explainCtrlEnter)
      textPlaceholder += platformAwareKeystrokes('\n\n💡 Tip: Ctrl + Enter to beam');
  }

  const stableGridSx: SxProps = React.useMemo(() => ({
    // basically a position:relative to enable the inner drop area
    ...dragContainerSx,
    // This used to be in the outer box, but we put it here instead
    // p: { xs: 1, md: 2 },
  }), [dragContainerSx]);

  return (
    <Box
      aria-label='New Message'
      component='section'
      bgcolor={showTint ? `var(--joy-palette-${showTint}-softBg)` : themeBgAppChatComposer}
      sx={props.sx}
    >

      {!isMobile && labsShowShortcutBar && <StatusBarMemo toggleMinimized={handleToggleMinimized} isMinimized={isMinimized} />}

      {/* This container is here just to let the potential statusbar fill the whole space, so we moved the padding here and not in the parent */}
      <Box sx={(!isMinimized || isMobile || !labsShowShortcutBar) ? paddingBoxSx : minimizedSx}>

        <Grid
          container
          onDragEnter={handleContainerDragEnter}
          onDragStart={handleContainerDragStart}
          spacing={{ xs: 1, md: 2 }}
          sx={stableGridSx}
        >

          {/* [Mobile: top, Desktop: left] */}
          <Grid xs={12} md={9}><Box sx={{ display: 'flex', gap: { xs: 1, md: 2 }, alignItems: 'stretch' }}>

            {/* [Mobile, Col1] Mic, Insert Multi-modal content, and Broadcast buttons */}
            {isMobile && (
              <Box sx={{ flexGrow: 0, display: 'grid', gap: 1, alignSelf: 'flex-start' }}>

                {/* [mobile] Mic button */}
                {recognitionState.isAvailable && <ButtonMicMemo variant={micVariant} color={micColor === 'danger' ? 'danger' : showTint || micColor} errorMessage={recognitionState.errorMessage} onClick={handleToggleMic} />}

                {/* Responsive Camera OCR button */}
                {showChatAttachments && <ButtonAttachCameraMemo color={showTint} isMobile onOpenCamera={openCamera} />}

                {/* [mobile] Attach file button (in draw with image mode)  */}
                {showChatAttachments === 'only-images' && <ButtonAttachFilesMemo color={showTint} isMobile onAttachFiles={handleAttachFiles} fullWidth multiple />}

                {/* [mobile] [+] button */}
                {showChatAttachments === true && (
                  <Dropdown>
                    <MenuButton slots={{ root: IconButton }}>
                      <AddCircleOutlineIcon />
                    </MenuButton>
                    <Menu>

                      {/* Responsive Open Files button */}
                      <MenuItem>
                        <ButtonAttachFilesMemo onAttachFiles={handleAttachFiles} fullWidth multiple />
                      </MenuItem>

                      {/* Responsive Web button */}
                      <MenuItem>
                        <ButtonAttachWebMemo disabled={!hasComposerBrowseCapability} onOpenWebInput={openWebInputDialog} />
                      </MenuItem>

                      {/* Responsive Paste button */}
                      {supportsClipboardRead() && <MenuItem>
                        <ButtonAttachClipboardMemo onAttachClipboard={attachAppendClipboardItems} />
                      </MenuItem>}

                    </Menu>
                  </Dropdown>
                )}

                {/* [Mobile] MultiChat button */}
                {props.isMulticast !== null && <ButtonMultiChatMemo isMobile multiChat={props.isMulticast} onSetMultiChat={props.setIsMulticast} />}

              </Box>
            )}

            {/* [Desktop, Col1] Insert Multi-modal content buttons */}
            {isDesktop && showChatAttachments && (
              <Box sx={{ flexGrow: 0, display: 'grid', gap: (labsAttachScreenCapture && labsCameraDesktop) ? 0.5 : 1, alignSelf: 'flex-start' }}>

                {/*<FormHelperText sx={{ mx: 'auto' }}>*/}
                {/*  Attach*/}
                {/*</FormHelperText>*/}

                {/* Responsive Open Files button */}
                <ButtonAttachFilesMemo color={showTint} onAttachFiles={handleAttachFiles} fullWidth multiple />

                {/* Responsive Web button */}
                {showChatAttachments !== 'only-images' && <ButtonAttachWebMemo color={showTint} disabled={!hasComposerBrowseCapability} onOpenWebInput={openWebInputDialog} />}

                {/* Responsive Paste button */}
                {supportsClipboardRead() && showChatAttachments !== 'only-images' && <ButtonAttachClipboardMemo color={showTint} onAttachClipboard={attachAppendClipboardItems} />}

                {/* Responsive Screen Capture button */}
                {labsAttachScreenCapture && supportsScreenCapture && <ButtonAttachScreenCaptureMemo color={showTint} onAttachScreenCapture={handleAttachScreenCapture} />}

                {/* Responsive Camera OCR button */}
                {labsCameraDesktop && <ButtonAttachCameraMemo color={showTint} onOpenCamera={openCamera} />}

              </Box>)}


            {/* Top: Textarea & Mic & Overlays, Bottom, Attachment Drafts */}
            <Box sx={{
              flexGrow: 1,
              // layout
              display: 'flex',
              flexDirection: 'column',
              gap: 1,
              minWidth: 200, // flex: enable X-scrolling (resetting any possible minWidth due to the attachment drafts)
            }}>

              {/* Text Edit + Mic buttons + MicOverlay */}
              <Box sx={{ position: 'relative' /* for Mic overlay */, height: '100%' }}>

                {/* Edit box with inner Token Progress bar */}
                <Box sx={{ position: 'relative' /* for TokenBadge & TokenProgress */, height: '100%' }}>

                  <Textarea
                    variant='outlined'
                    color={isDraw ? 'warning' : isReAct ? 'success' : undefined}
                    autoFocus
                    minRows={isMobile ? 4 : isDraw ? 4 : agiAttachmentPrompts.hasData ? 3 : showChatInReferenceTo ? 4 : 5}
                    maxRows={isMobile ? 8 : 10}
                    placeholder={textPlaceholder}
                    value={composeText}
                    onChange={handleTextareaTextChange}
                    onKeyDown={handleTextareaKeyDown}
                    onPasteCapture={handleAttachCtrlV}
                    // onFocusCapture={handleFocusModeOn}
                    // onBlurCapture={handleFocusModeOff}
                    endDecorator={isDraw
                      ? <ComposerTextAreaDrawActions
                        composerText={composeText}
                        onReplaceText={setComposeText}
                      />
                      : <ComposerTextAreaActions
                        agiAttachmentPrompts={agiAttachmentPrompts}
                        inReferenceTo={inReferenceTo}
                        onAppendAndSend={handleAppendTextAndSend}
                        onRemoveReferenceTo={handleRemoveInReferenceTo}
                      />
                    }
                    slotProps={{
                      textarea: {
                        tabIndex: !recognitionState.isActive ? undefined : -1,
                        height: '100%',
                        enterKeyHint: enterIsNewline ? 'enter' : 'send',
                        sx: {
                          ...(recognitionState.isAvailable && { pr: { md: 5 } }),
                          // mb: 0.5, // no need; the outer container already has enough p (for TokenProgressbar)
                        },
                        ref: composerTextAreaRef,
                      },
                    }}
                    sx={{
                      height: '100%',
                      backgroundColor: showTint ? undefined : 'background.level1',
                      '&:focus-within': { backgroundColor: 'background.popup', '.within-composer-focus': { backgroundColor: 'background.popup' } },
                      lineHeight: lineHeightTextareaMd,
                    }} />

                  {!showChatInReferenceTo && !isDraw && tokenLimit > 0 && (tokensComposer > 0 || (tokensHistory + tokensResponseMax) > 0) && (
                    <TokenProgressbarMemo chatPricing={tokenChatPricing} direct={tokensComposer} history={tokensHistory} responseMax={tokensResponseMax} limit={tokenLimit} />
                  )}

                  {!showChatInReferenceTo && !isDraw && tokenLimit > 0 && (
                    <TokenBadgeMemo hideBelowDollars={0.0001} chatPricing={tokenChatPricing} direct={tokensComposer} history={tokensHistory} responseMax={tokensResponseMax} limit={tokenLimit} showCost={labsShowCost} enableHover={!isMobile} showExcess absoluteBottomRight />
                  )}

                </Box>

                {/* Mic & Mic Continuation Buttons */}
                {recognitionState.isAvailable && (
                  <Box sx={{
                    position: 'absolute', top: 0, right: 0,
                    zIndex: zIndexComposerOverlayMic + 1,
                    mt: isDesktop ? 1 : 0.25,
                    mr: isDesktop ? 1 : 0.25,
                    display: 'flex', flexDirection: 'column', gap: isDesktop ? 1 : 0.25,
                  }}>
                    {isDesktop && <ButtonMicMemo variant={micVariant} color={micColor} errorMessage={recognitionState.errorMessage} onClick={handleToggleMic} noBackground={!recognitionState.isActive} />}

                    {micIsRunning && (
                      <ButtonMicContinuationMemo
                        isActive={micContinuation}
                        variant={micContinuation ? 'soft' : 'soft'} color={micContinuation ? 'primary' : 'neutral'} sx={{ background: micContinuation ? undefined : 'none' }}
                        onClick={handleToggleMicContinuation}
                      />
                    )}
                  </Box>
                )}

                {/* overlay: Mic */}
                {micIsRunning && (
                  <Card
                    ref={micCardRef}
                    color='primary' variant='soft'
                    sx={{
                      position: 'absolute', bottom: 0, left: 0, right: 0, top: 0,
                      // alignItems: 'center', justifyContent: 'center',
                      border: '1px solid',
                      borderColor: 'primary.solidBg',
                      borderRadius: 'sm',
                      boxShadow: 'inset 1px 1px 4px -3px var(--joy-palette-primary-solidHoverBg)',
                      zIndex: zIndexComposerOverlayMic,
                      pl: 1.5,
                      pr: { xs: 1.5, md: 5 },
                      py: 0.625,
                      overflow: 'auto',
                      // '[data-joy-color-scheme="light"] &': {
                      //   backgroundColor: 'primary.50',
                      // },
                    }}>
                    <Typography sx={{
                      color: 'primary.softColor',
                      lineHeight: lineHeightTextareaMd,
                      '& > .preceding': {
                        color: 'primary.softDisabledColor',
                        // color: 'rgba(var(--joy-palette-primary-mainChannel) / 0.6)',
                        overflowWrap: 'break-word',
                        textWrap: 'wrap',
                        whiteSpaceCollapse: 'preserve',
                      },
                      '& > .interim': {
                        textDecoration: 'underline',
                        textDecorationThickness: '0.25em',
                        textDecorationColor: 'rgba(var(--joy-palette-primary-mainChannel) / 0.1)',
                        textDecorationSkipInk: 'none',
                        textUnderlineOffset: '0.25em',
                      },
                      '& > .placeholder': {
                        fontStyle: 'italic',
                      },
                    }}>
                      {!!composeText && <span className='preceding'>{composeText.endsWith(' ') ? composeText : composeText + ' '}</span>}
                      {speechInterimResult.transcript}
                      <span className={speechInterimResult.interimTranscript === PLACEHOLDER_INTERIM_TRANSCRIPT ? 'placeholder' : 'interim'}>{speechInterimResult.interimTranscript}</span>
                    </Typography>
                  </Card>
                )}

              </Box>

              {/* Render any Attachments & menu items */}
              {!!conversationOverlayStore && showChatAttachments && (
                <LLMAttachmentsList
                  agiAttachmentPrompts={agiAttachmentPrompts}
                  attachmentDraftsStoreApi={conversationOverlayStore}
                  canInlineSomeFragments={llmAttachmentDraftsCollection.canInlineSomeFragments}
                  llmAttachmentDrafts={llmAttachmentDraftsCollection.llmAttachmentDrafts}
                  onAttachmentDraftsAction={handleAttachmentDraftsAction}
                />
              )}

            </Box>

          </Box></Grid>


          {/* [Mobile: bottom, Desktop: right] */}
          <Grid xs={12} md={3}>
            <Box sx={{ display: 'flex', flexDirection: 'column', gap: 1, height: '100%' } as const}>

              {/* [mobile] This row is here only for the [mobile] bottom-start corner item */}
              {/* [desktop] This column arrangement will have the [desktop] beam button right under call */}
              <Box sx={isMobile ? { display: 'flex' } : { display: 'grid', gap: 1 }}>

                {/* [mobile] bottom-corner secondary button */}
                {isMobile && (showChatExtras
                    ? (composerQuickButton === 'call'
                      ? <ButtonCallMemo isMobile disabled={noConversation || noLLM} onClick={handleCallClicked} />
                      : <ButtonBeamMemo isMobile disabled={noConversation /*|| noLLM*/} color={beamButtonColor} hasContent={!!composeText} onClick={handleSendTextBeamClicked} />)
                    : isDraw
                      ? <ButtonOptionsDraw isMobile onClick={handleDrawOptionsClicked} sx={{ mr: { xs: 1, md: 2 } }} />
                      : <IconButton disabled sx={{ mr: { xs: 1, md: 2 } }} />
                )}

                {/* Responsive Send/Stop buttons */}
                <ButtonGroup
                  variant={sendButtonVariant}
                  color={sendButtonColor}
                  sx={{
                    flexGrow: 1,
                    backgroundColor: (isMobile && sendButtonVariant === 'outlined') ? 'background.popup' : undefined,
                    boxShadow: (isMobile && sendButtonVariant !== 'outlined') ? 'none' : `0 8px 24px -4px rgb(var(--joy-palette-${sendButtonColor}-mainChannel) / 20%)`,
                  }}
                >
                  {!assistantAbortible ? (
                    <Button
                      key='composer-act'
                      fullWidth
                      disabled={noConversation /* || noLLM*/}
                      loading={sendStarted}
                      loadingPosition='end'
                      onClick={handleSendClicked}
                      endDecorator={sendButtonIcon}
                      sx={{ '--Button-gap': '1rem' }}
                    >
                      {micContinuation && 'Voice '}{sendButtonLabel}
                    </Button>
                  ) : (
                    <Button
                      key='composer-stop'
                      fullWidth
                      variant='soft'
                      disabled={noConversation}
                      onClick={handleStopClicked}
                      endDecorator={<StopOutlinedIcon sx={{ fontSize: 18 }} />}
                      sx={{ animation: `${animationEnterBelow} 0.1s ease-out` }}
                    >
                      Stop
                    </Button>
                  )}

                  {/* [Beam] Open Beam */}
                  {/*{isText && <Tooltip title='Open Beam'>*/}
                  {/*  <IconButton variant='outlined' disabled={noConversation || noLLM} onClick={handleSendTextBeamClicked}>*/}
                  {/*    <ChatBeamIcon />*/}
                  {/*  </IconButton>*/}
                  {/*</Tooltip>}*/}

                  {/* [Draw] Imagine */}
                  {/* NOTE: disabled: as we have prompt enhancement in the TextArea (Draw Mode) already */}
                  {/*{isDraw && !!composeText && <Tooltip title='Generate an image prompt'>*/}
                  {/*  <IconButton variant='outlined' disabled={noConversation || noLLM} onClick={handleTextImagineClicked}>*/}
                  {/*    <AutoAwesomeIcon />*/}
                  {/*  </IconButton>*/}
                  {/*</Tooltip>}*/}

                  {/* Mode expander */}
                  <IconButton
                    variant={chatExecuteMenuShown ? 'outlined' : assistantAbortible ? 'soft' : isDraw ? undefined : undefined}
                    disabled={noConversation /*|| chatExecuteMenuShown*/}
                    onClick={showChatExecuteMenu}
                  >
                    <ExpandLessIcon />
                  </IconButton>
                </ButtonGroup>

                {/* [desktop] secondary-top buttons */}
                {isDesktop && showChatExtras && !assistantAbortible && (
                  <ButtonBeamMemo
                    color={beamButtonColor}
                    disabled={noConversation /*|| noLLM*/}
                    hasContent={!!composeText}
                    onClick={handleSendTextBeamClicked}
                  />
                )}

              </Box>

              {/* [desktop] Draw mode N buttons */}
              {isDesktop && isDraw && <ButtonGroupDrawRepeat drawRepeat={drawRepeat} setDrawRepeat={setDrawRepeat} />}

              {/* [desktop] Multicast switch (under the Chat button) */}
              {isDesktop && props.isMulticast !== null && <ButtonMultiChatMemo multiChat={props.isMulticast} onSetMultiChat={props.setIsMulticast} />}

              {/* [desktop] secondary bottom-buttons (aligned to bottom for now, and mutually exclusive) */}
              {isDesktop && <Box sx={{ mt: 'auto', display: 'grid', gap: 1 }}>

                {/* [desktop] Call secondary button */}
                {showChatExtras && <ButtonCallMemo disabled={noConversation || noLLM || assistantAbortible} onClick={handleCallClicked} />}

                {/* [desktop] Draw Options secondary button */}
                {isDraw && <ButtonOptionsDraw onClick={handleDrawOptionsClicked} />}

              </Box>}

            </Box>
          </Grid>

          {/* overlay: Drag & Drop*/}
          {dropComponent}

        </Grid>

      </Box> {/* Padding container of the whole composer */}

      {/* Execution Mode Menu */}
      {chatExecuteMenuComponent}

      {/* Camera (when open) */}
      {cameraCaptureComponent}

      {/* Web Input Dialog (when open) */}
      {webInputDialogComponent}

      {/* Actile (when open) */}
      {actileComponent}

    </Box>
  );
}


================================================
FILE: src/apps/chat/components/composer/useComposerAutoHide.tsx
================================================
import * as React from 'react';

import { useUXLabsStore } from '~/common/stores/store-ux-labs';


// configuration
const HIDE_DELAY = 1500; // milliseconds before hiding after mouse leaves
const FORCE_SHOW_DURATION = 3000; // milliseconds to keep shown after user interaction


const compressibleStyle = {
  minHeight: 0, // makes the compressor collapse this
  overflow: 'hidden', // when collapsing cuts the content
  contain: 'paint', // improves performance by limiting the area to paint

  // Note: the following in the composer's style would make for a much better animation
  // sx={{
  //   // Add slide animation for both beam and auto-hide
  //   transition: 'transform 0.3s cubic-bezier(0.4, 0, 0.2, 1)',
  //   transform: composerAutoHide.isHidden ? 'translateY(100%)' : 'translateY(0)',
  // }}
} as const;

const _styles = {

  compressorClosed: {
    display: 'grid',
    gridTemplateRows: '0fr',
    transition: 'grid-template-rows 0.3s cubic-bezier(0.4, 0, 0.2, 1)',
  } as const,

  compressorOpen: {
    display: 'grid',
    gridTemplateRows: '1fr',
    transition: 'grid-template-rows 0.3s cubic-bezier(0.4, 0, 0.2, 1)',
  } as const,

  detector: {
    position: 'fixed',
    bottom: 0,
    left: 0,
    right: 0,
    height: '2rem',
    backgroundColor: 'rgba(var(--joy-palette-neutral-mainChannel) / 0.1)',
    // backgroundColor: { xs: 'rgba(var(--joy-palette-neutral-mainChannel) / 0.1)', md: 'transparent' },
    zIndex: 20,
  } as const,

} as const;


export function useComposerAutoHide(forceHide: boolean, isContentful: boolean) {

  // state
  const [isAutoHidden, setAutoHidden] = React.useState(false);
  const [isFocused, setIsFocused] = React.useState(false);
  const [isHovering, setIsHovering] = React.useState(false);
  const [forceShowUntil, setForceShowUntil] = React.useState<number>(0);

  // external state
  const autoHideEnabled = useUXLabsStore((state) => state.labsAutoHideComposer);

  const hideTimeoutRef = React.useRef<NodeJS.Timeout | undefined>(undefined);


  // Force show the composer for a duration (e.g., after sending a message)
  const forceShow = React.useCallback((durationMs: number = FORCE_SHOW_DURATION) => {
    setForceShowUntil(Date.now() + Math.max(1000, durationMs));
    setAutoHidden(false);
  }, []);


  const showComposer = React.useCallback(() => {
    if (hideTimeoutRef.current) {
      clearTimeout(hideTimeoutRef.current);
      hideTimeoutRef.current = undefined;
    }
    setAutoHidden(false);
  }, []);

  const hideComposerDelayed = React.useCallback(() => {
    if (hideTimeoutRef.current)
      clearTimeout(hideTimeoutRef.current);

    hideTimeoutRef.current = setTimeout(() => {
      setAutoHidden(true);
      setIsFocused(false); // reset focus state when hiding
      hideTimeoutRef.current = undefined;
    }, HIDE_DELAY);
  }, []);


  // Effect: Handle auto-hide logic based on various conditions
  const shouldStayVisible = isContentful || isHovering || isFocused || forceShowUntil > Date.now();
  const shouldAutoHide = autoHideEnabled && !shouldStayVisible;
  React.useEffect(() => {
    if (shouldAutoHide)
      hideComposerDelayed();
    else
      showComposer();
  }, [hideComposerDelayed, shouldAutoHide, showComposer]);

  // Clear force show timer when it expires
  React.useEffect(() => {
    if (forceShowUntil > 0) {
      const timeout = setTimeout(() => {
        setForceShowUntil(0);
      }, forceShowUntil - Date.now());

      return () => clearTimeout(timeout);
    }
  }, [forceShowUntil]);

  // Cleanup on unmount
  React.useEffect(() => {
    return () => {
      if (hideTimeoutRef.current)
        clearTimeout(hideTimeoutRef.current);
    };
  }, []);


  const doHide = forceHide || (autoHideEnabled && isAutoHidden);

  const compressorProps = React.useMemo(() => ({
    onMouseEnter: !autoHideEnabled ? undefined : () => setIsHovering(true),
    onMouseLeave: !autoHideEnabled ? undefined : () => setIsHovering(false),
    onFocusCapture: !autoHideEnabled ? undefined : () => setIsFocused(true),
    onBlurCapture: !autoHideEnabled ? undefined : () => setIsFocused(false),
    sx: doHide ? _styles.compressorClosed : _styles.compressorOpen,
  }), [autoHideEnabled, doHide]);

  const detectorProps = React.useMemo(() => ({
    onMouseEnter: () => {
      setIsHovering(true);
      showComposer();
    },
    onMouseLeave: () => {
      setIsHovering(false);
    },
    sx: _styles.detector,
  }), [showComposer]);

  return {
    isHidden: doHide,
    compressorProps,
    compressibleStyle,
    detectorProps,
    forceShow,
  };
}


================================================
FILE: src/apps/chat/components/composer/useComposerDragDrop.tsx
================================================
import * as React from 'react';

import { SvgIcon } from '@mui/joy';
import AttachFileRoundedIcon from '@mui/icons-material/AttachFileRounded';

import { useDragDropDataTransfer } from '~/common/components/dnd-dt/useDragDropDataTransfer';


export function useComposerDragDrop(
  enabled: boolean,
  onDataTransfer: (dataTransfer: DataTransfer, type: 'paste' | 'drop', isDropOnTextarea: boolean) => Promise<any>,
) {

  // drop implementation for the composer
  const handleComposerDrop = React.useCallback(async (dataTransfer: DataTransfer) => {

    // VSCode: detect failure of dropping from VSCode, details below:
    //         https://github.com/microsoft/vscode/issues/98629#issuecomment-634475572
    if (dataTransfer.types.includes('codeeditors')) {

      // Get the file paths
      let filePaths: string[] = [];
      if (dataTransfer.types.includes('codefiles')) {
        filePaths = JSON.parse(dataTransfer.getData('codefiles'));
      } else if (dataTransfer.types.includes('text/plain')) {
        filePaths = dataTransfer.getData('text/plain').split('\n').filter(Boolean);
      }
      const fileNames = filePaths.map(path => path.split('\\').pop() || path.split('/').pop() || 'unknown file');

      // just show an old school alert message (save callbacks)
      return alert([
        `Dropped ${fileNames.length} file${fileNames.length > 1 ? 's' : ''} from VSCode:`,
        ...fileNames.map((name, index) => `${index + 1}. ${name}`),
        '',
        'VSCode does not drag-and-drop to browsers. https://github.com/microsoft/vscode/issues/98629#issuecomment-634475572.',
        '',
        'Upload 📎, paste 📋, or drag from a folder 📁.',
      ].join('\n'));
    }

    // textarea drop
    void onDataTransfer(dataTransfer, 'drop', true); // fire/forget

  }, [onDataTransfer]);

  return useDragDropDataTransfer(enabled, 'I will hold on to this for you.', AttachFileRoundedIcon as typeof SvgIcon, 'largeIcon', false, handleComposerDrop);
}



================================================
FILE: src/apps/chat/components/composer/WebInputModal.tsx
================================================
import * as React from 'react';
import { Controller, useFieldArray, useForm } from 'react-hook-form';

import { Box, Button, Chip, FormControl, FormHelperText, IconButton, Input, Stack, Typography } from '@mui/joy';
import AddCircleOutlineRoundedIcon from '@mui/icons-material/AddCircleOutlineRounded';
import AddIcon from '@mui/icons-material/Add';
import BrowserUpdatedOutlinedIcon from '@mui/icons-material/BrowserUpdatedOutlined';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import LanguageRoundedIcon from '@mui/icons-material/LanguageRounded';
import YouTubeIcon from '@mui/icons-material/YouTube';

import { extractYoutubeVideoIDFromURL } from '~/modules/youtube/youtube.utils';

import { GoodModal } from '~/common/components/modals/GoodModal';
import { addSnackbar } from '~/common/components/snackbar/useSnackbarsStore';
import { asValidURL, extractUrlsFromText } from '~/common/util/urlUtils';


// configuration
const MAX_URLS = 5;

type WebInputData = {
  url: string,
  // attachImages?: boolean,
}

type WebInputModalInputs = {
  links: WebInputData[];
}

const _styles = {

  ytIcon: {
    color: 'red',
  } as const,

  chipLink: {
    ml: 'auto',
    pr: 1.125,
    // '--Chip-radius': '4px',
    // whiteSpace: 'break-spaces',
    // gap: 1.5,
  } as const,

} as const;


function WebInputModal(props: {
  composerText?: string,
  onClose: () => void,
  onWebLinks: (urls: WebInputData[]) => void,
}) {

  // state
  const { control: formControl, handleSubmit: formHandleSubmit, formState: { isValid: formIsValid, isDirty: formIsDirty } } = useForm<WebInputModalInputs>({
    values: { links: [{ url: '' }] },
    mode: 'onChange', // validate on change
  });
  const { fields: formFields, append: formFieldsAppend, remove: formFieldsRemove, update: formFieldsUpdate } = useFieldArray({ control: formControl, name: 'links' });
  const firstInputRef = React.useRef<HTMLInputElement>(null);

  // derived
  const urlFieldCount = formFields.length;
  const canAddMoreUrls = urlFieldCount < MAX_URLS;

  // [effect] auto-focus first input
  React.useEffect(() => {
    setTimeout(() => {
      if (firstInputRef.current)
        firstInputRef.current.focus();
    }, 0);
  }, []);


  // memos

  const extractedComposerUrls = React.useMemo(() => {
    return !props.composerText ? null : extractUrlsFromText(props.composerText);
  }, [props.composerText]);

  const extractedUrlsCount = extractedComposerUrls?.length ?? 0;

  // handlers

  const { onClose, onWebLinks } = props;

  const handleClose = React.useCallback(() => onClose(), [onClose]);

  const handleSubmit = React.useCallback(({ links }: WebInputModalInputs) => {
    // clean and prefix URLs
    const cleanUrls = links.reduce((acc, { url, ...linkRest }) => {
      const trimmed = (url || '').trim();
      if (trimmed) {
        // this form uses a 'relaxed' URL validation, meaning one can write 'big-agi.com' and we'll assume https://
        const relaxedUrl = asValidURL(trimmed, true);
        if (relaxedUrl)
          acc.push({ url: relaxedUrl, ...linkRest });
      }
      return acc;
    }, [] as WebInputData[]);
    if (!cleanUrls.length) {
      addSnackbar({ key: 'invalid-urls', message: 'Please enter at least one valid web address', type: 'issue', overrides: { autoHideDuration: 2000 } });
      return;
    }
    onWebLinks(cleanUrls);
    handleClose();
  }, [handleClose, onWebLinks]);


  // const handleAddUrl = React.useCallback((newUrl: string) => {
  //   // bail if can't add
  //   if (!canAddMoreUrls)
  //     return addSnackbar({ key: 'max-urls', message: `Maximum ${MAX_URLS} URLs allowed`, type: 'precondition-fail' });
  //
  //   // bail if already in
  //   const exists = formFields.some(({ url }) => url === newUrl);
  //   if (exists)
  //     return addSnackbar({ key: 'duplicate-url', message: 'URL already added', type: 'info' });
  //
  //   // replace the first empty field, or append
  //   const emptyFieldIndex = formFields.findIndex(field => !field.url.trim());
  //   if (emptyFieldIndex >= 0)
  //     formFieldsUpdate(emptyFieldIndex, { url: newUrl });
  //   else
  //     formFieldsAppend({ url: newUrl });
  // }, [canAddMoreUrls, formFields, formFieldsAppend, formFieldsUpdate]);


  const handleAddAllUrls = React.useCallback(() => {
    if (!extractedComposerUrls) return;

    // new URLs that are not already in the form
    const newURLs = extractedComposerUrls.filter(url => !formFields.some(field => field.url.trim() === url));
    if (!newURLs.length) return;

    // find empty fields first
    for (let i = 0; i < formFields.length; i++) {
      const field = formFields[i];
      if (!field.url.trim()) {
        formFieldsUpdate(i, { url: newURLs.shift()! });
        if (!newURLs.length) break;
      }
    }

    // append remaining
    newURLs.forEach(url => formFieldsAppend({ url }));
  }, [extractedComposerUrls, formFields, formFieldsAppend, formFieldsUpdate]);


  return (
    <GoodModal
      open
      onClose={handleClose}
      title='Add Web Content'
      titleStartDecorator={<LanguageRoundedIcon />}
      closeText={'Cancel'}
      // unfilterBackdrop
      // themedColor='neutral'
      hideBottomClose
    >
      <Box fontSize='md'>
        Enter web page addresses to import their content.
      </Box>
      <Typography level='body-sm'>
        Works on most websites and for YouTube videos (e.g., youtube.com/...) the transcript will be imported.
        {/*You can add up to {MAX_URLS} URLs.*/}
      </Typography>


      {/* Modified URLs section */}
      {!!extractedUrlsCount && (
        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
          <Typography level='title-sm' startDecorator={<BrowserUpdatedOutlinedIcon />}>
            {extractedUrlsCount} URL{extractedUrlsCount > 1 ? 's' : ''} in your message
            {/*{extractedUrlsCount} URL{extractedUrlsCount > 1 ? 's' : ''} found in your message*/}
          </Typography>
          <Chip
            variant='soft'
            onClick={handleAddAllUrls}
            startDecorator={<AddCircleOutlineRoundedIcon />}
            sx={_styles.chipLink}
          >
            Add
          </Chip>
        </Box>
      )}


      <form onSubmit={formHandleSubmit(handleSubmit)}>
        <Stack spacing={1}>
          {formFields.map((field, index) => (
            <Controller
              key={field.id}
              control={formControl}
              name={`links.${index}.url`}
              rules={{ required: 'Please enter a valid URL' }}
              render={({ field: { value, onChange }, fieldState: { error } }) => (
                <FormControl error={!!error}>
                  <Box sx={{ display: 'flex', gap: 1 }}>
                    <Input
                      required={index === 0}
                      placeholder='https://...'
                      endDecorator={extractYoutubeVideoIDFromURL(value) ? <YouTubeIcon sx={_styles.ytIcon} /> : undefined}
                      value={value}
                      onChange={onChange}
                      slotProps={index !== 0 ? undefined : {
                        input: {
                          ref: firstInputRef,
                        },
                      }}
                      sx={{ flex: 1 }}
                    />
                    {urlFieldCount > 1 && (
                      <IconButton
                        size='sm'
                        variant='plain'
                        color='neutral'
                        onClick={() => formFieldsRemove(index)}
                      >
                        <DeleteOutlineIcon />
                      </IconButton>
                    )}
                  </Box>
                  {error && <FormHelperText>{error.message}</FormHelperText>}
                </FormControl>
              )}
            />
          ))}
        </Stack>

        {/* Add a new link */}
        <Box sx={{ display: 'flex', justifyContent: 'space-between', gap: 1, mt: 2.5 }}>

          {formIsDirty && <Button
            color='neutral'
            variant='soft'
            disabled={!canAddMoreUrls}
            onClick={() => formFieldsAppend({ url: '' })}
            startDecorator={<AddIcon />}
          >
            Another
            {/*{urlFieldCount >= MAX_URLS ? 'Enough URLs' : urlFieldCount === 1 ? 'Add URL' : urlFieldCount === 2 ? 'Add another' : urlFieldCount === 3 ? 'And another one' : urlFieldCount === 4 ? 'Why stopping' : 'Just one more'}*/}
          </Button>}

          <Button
            variant='solid'
            type='submit'
            disabled={!formIsValid || !formIsDirty}
            sx={{ minWidth: 160, ml: 'auto' }}
          >
            Import {urlFieldCount > 1 ? `(${urlFieldCount})` : ''}
          </Button>

        </Box>
      </form>

    </GoodModal>
  );
}


export function useWebInputModal(onAttachWebLinks: (urls: WebInputData[]) => void, composerText?: string) {

  // state
  const [open, setOpen] = React.useState(false);
  const composerTextRef = React.useRef(composerText);

  // copy the text to a ref, constantly - we just care about a recent snapshot, but don't want to invalidate hooks
  composerTextRef.current = composerText;

  const openWebInputDialog = React.useCallback(() => setOpen(true), []);

  const webInputDialogComponent = React.useMemo(() => open && (
    <WebInputModal
      composerText={composerTextRef.current}
      onClose={() => setOpen(false)}
      onWebLinks={onAttachWebLinks}
    />
  ), [onAttachWebLinks, open]);

  return {
    openWebInputDialog,
    webInputDialogComponent,
  };
}


================================================
FILE: src/apps/chat/components/composer/actile/ActilePopup.tsx
================================================
import * as React from 'react';

import { Box, ListItem, ListItemButton, ListItemDecorator, Sheet, Typography } from '@mui/joy';

import { CloseablePopup } from '~/common/components/CloseablePopup';

import type { ActileItem, ActileProvider } from './ActileProvider';

export function ActilePopup(props: {
  anchorEl: HTMLElement | null,
  onClose: () => void,
  itemsByProvider: { provider: ActileProvider, items: ActileItem[] }[],
  activeItemIndex: number,
  activePrefixLength: number,
  onItemClick: (item: ActileItem) => void,
}) {

  // We need to keep track of the overall item index to correctly match with activeItemIndex
  const itemIndices = React.useMemo(() => {
    const indices: { providerKey: string, itemKey: string, isActive: boolean }[] = [];
    let indexCounter = 0;
    props.itemsByProvider.forEach(({ provider, items }) => {
      items.forEach((item) => {
        indices.push({
          providerKey: provider.key,
          itemKey: item.key,
          isActive: indexCounter === props.activeItemIndex,
        });
        indexCounter += 1;
      });
    });
    return indices;
  }, [props.itemsByProvider, props.activeItemIndex]);

  return (
    <CloseablePopup
      menu anchorEl={props.anchorEl} onClose={props.onClose}
      maxHeightGapPx={320}
      minWidth={320}
      noBottomPadding
      noTopPadding
    >

      {!props.itemsByProvider.length && (
        <ListItem variant='soft' color='warning'>
          <Typography level='body-md'>
            No matching command
          </Typography>
        </ListItem>
      )}

      {props.itemsByProvider.map(({ provider, items }) => (
        <React.Fragment key={provider.key}>

          {/* Provider Label */}
          <Sheet variant='soft' sx={{ p: 1, borderBottom: '1px solid', borderBottomColor: 'neutral.softActiveBg' }}>
            <Typography level='title-sm'>
              {provider.label}
            </Typography>
          </Sheet>

          {/* Items */}
          {items.map((item) => {
            const index = itemIndices.findIndex(idx => idx.providerKey === provider.key && idx.itemKey === item.key);
            const isActive = itemIndices[index]?.isActive;

            const labelBold = item.label.slice(0, props.activePrefixLength);
            const labelNormal = item.label.slice(props.activePrefixLength);

            return (
              <ListItem
                key={`${provider.key}-${item.key}`}
                variant={isActive ? 'soft' : undefined}
                color={isActive ? 'primary' : undefined}
                onClick={() => props.onItemClick(item)}
              >
                <ListItemButton color='primary'>
                  {item.Icon && (
                    <ListItemDecorator>
                      <item.Icon />
                    </ListItemDecorator>
                  )}

                  {/* Item*/}
                  <Box>

                    {/* Item main text  */}
                    <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
                      <Typography level='title-sm' color={isActive ? 'primary' : undefined}>
                        <span style={{ textDecoration: 'underline' }}><b>{labelBold}</b></span>{labelNormal}
                      </Typography>
                      {item.argument && <Typography level='body-sm'>
                        {item.argument}
                      </Typography>}
                    </Box>

                    {/* Item description */}
                    {!!item.description && <Typography level='body-xs'>
                      {item.description}
                    </Typography>}

                  </Box>

                </ListItemButton>
              </ListItem>
            );
          })}
        </React.Fragment>
      ))}

    </CloseablePopup>
  );
}



================================================
FILE: src/apps/chat/components/composer/actile/ActileProvider.tsx
================================================
import type { FunctionComponent } from 'react';

export interface ActileProvider<TItem extends ActileItem = ActileItem> {

  // Unique key for the provider
  readonly key: 'pcmd' | 'pstrmsg' | 'pattlbl';

  // Label for display
  get label(): string;

  // Interface for the provider
  fastCheckTriggerText: (trailingText: string) => boolean;
  fetchItems: () => ActileProviderItems<TItem>;
  onItemSelect: (item: ActileItem) => void;

}

export type ActileProviderItems<TItem extends ActileItem = ActileItem> = Promise<{ searchPrefix: string, items: TItem[] }>;

export interface ActileItem {
  key: string;
  providerKey: ActileProvider['key'];
  label: string;
  argument?: string;
  description?: string;
  Icon?: FunctionComponent;
}



================================================
FILE: src/apps/chat/components/composer/actile/providerAttachmentLabels.tsx
================================================
import type { ActileItem, ActileProvider, ActileProviderItems } from './ActileProvider';

import type { AttachmentDraftsStoreApi } from '~/common/attachment-drafts/store-attachment-drafts_slice';

export interface AttachmentLabelItem extends ActileItem {
  // nothing to do do here, this is really just a label
}

export const providerAttachmentLabels = (
  attachmentsStoreApi: AttachmentDraftsStoreApi | null,
  onLabelSelect: (item: ActileItem, searchPrefix: string) => void,
): ActileProvider<AttachmentLabelItem> => ({

  key: 'pattlbl',

  get label() {
    return 'Attachment Labels';
  },

  // Uses '@' as the trigger
  fastCheckTriggerText: (trailingText: string) => trailingText === '@' || trailingText.endsWith(' @'),

  fetchItems: async (): ActileProviderItems<AttachmentLabelItem> => ({
    searchPrefix: '',
    items: attachmentsStoreApi?.getState()?.attachmentDrafts.map(draft => ({
      key: draft.id,
      providerKey: 'pattlbl',
      label: draft.label,
      argument: undefined,
      description: 'name',
      Icon: undefined,
    } as AttachmentLabelItem)) ?? [],
  }),

  onItemSelect: item => onLabelSelect(item as AttachmentLabelItem, '@'),

});


================================================
FILE: src/apps/chat/components/composer/actile/providerCommands.tsx
================================================
import { findAllChatCommands } from '../../../commands/commands.registry';

import type { ActileItem, ActileProvider, ActileProviderItems } from './ActileProvider';


export const providerCommands = (
  onCommandSelect: (item: ActileItem, searchPrefix: string) => void,
): ActileProvider => ({

  key: 'pcmd',

  get label() {
    return 'Chat Commands';
  },

  fastCheckTriggerText: (trailingText: string) => {
    // only the literal '/' is a trigger
    return trailingText === '/';
  },

  fetchItems: async (): ActileProviderItems => ({
    searchPrefix: '/',
    items: findAllChatCommands().map((cmd) => ({
      key: cmd.primary,
      providerKey: 'pcmd',
      label: cmd.primary,
      argument: cmd.arguments?.join(' ') ?? undefined,
      description: cmd.description,
      Icon: cmd.Icon,
    } satisfies ActileItem)),
  }),

  onItemSelect: (item) => onCommandSelect(item as ActileItem, '/'),

});


================================================
FILE: src/apps/chat/components/composer/actile/providerStarredMessage.tsx
================================================
import { conversationTitle, DConversationId } from '~/common/stores/chat/chat.conversation';
import { MESSAGE_FLAG_STARRED, messageFragmentsReduceText, messageHasUserFlag } from '~/common/stores/chat/chat.message';
import { useChatStore } from '~/common/stores/chat/store-chats';

import type { ActileItem, ActileProvider, ActileProviderItems } from './ActileProvider';


export interface StarredMessageItem extends ActileItem {
  conversationId: DConversationId,
  messageId: string,
}

export const providerStarredMessages = (onMessageSelect: (item: StarredMessageItem) => void): ActileProvider<StarredMessageItem> => ({

  key: 'pstrmsg',

  get label() {
    return 'Starred Messages';
  },

  // only the literal '@' at start of chat, or ' @' at end of chat
  fastCheckTriggerText: (trailingText: string) => trailingText === '@' || trailingText.endsWith(' @'),

  // finds all the starred messages in all the conversations - this could be heavy
  fetchItems: async (): ActileProviderItems<StarredMessageItem> => {
    const { conversations } = useChatStore.getState();

    const starredMessages: StarredMessageItem[] = [];
    conversations.forEach((conversation) => {
      conversation.messages.forEach((message) => {
        messageHasUserFlag(message, MESSAGE_FLAG_STARRED) && starredMessages.push({
          key: message.id,
          providerKey: 'pstrmsg',
          // data
          conversationId: conversation.id,
          messageId: message.id,
          // looks
          label: conversationTitle(conversation) + ' - ' + messageFragmentsReduceText(message.fragments).slice(0, 32) + '...',
          // description: message.text.slice(32, 100),
          Icon: undefined,
        } satisfies StarredMessageItem);
      });
    });

    return {
      searchPrefix: '',
      items: starredMessages,
    };
  },

  onItemSelect: item => onMessageSelect(item as StarredMessageItem),

});


================================================
FILE: src/apps/chat/components/composer/actile/useActileManager.tsx
================================================
import * as React from 'react';

import type { ActileItem, ActileProvider } from './ActileProvider';
import { ActilePopup } from './ActilePopup';


export const useActileManager = (providers: ActileProvider[], anchorRef: React.RefObject<HTMLElement | null>) => {

  // state
  const [popupOpen, setPopupOpen] = React.useState(false);
  const [itemsByProvider, setItemsByProvider] = React.useState<{ provider: ActileProvider, items: ActileItem[] }[]>([]);
  const [activeSearchString, setActiveSearchString] = React.useState<string>('');
  const [activeItemIndex, setActiveItemIndex] = React.useState<number>(0);

  // derived state
  const activeItemsByProvider = React.useMemo(() => {
    const search = activeSearchString.trim().toLowerCase();
    return itemsByProvider.map(({ provider, items }) => ({
      provider,
      items: items.filter(item => item.label?.toLowerCase().startsWith(search)),
    })).filter(({ items }) => items.length > 0);
  }, [itemsByProvider, activeSearchString]);

  const flatActiveItems = React.useMemo(() => {
    return activeItemsByProvider.flatMap(({ items }) => items);
  }, [activeItemsByProvider]);
  const totalItems = flatActiveItems.length;
  const activeItem = totalItems > 0 && activeItemIndex >= 0 && activeItemIndex < totalItems ? flatActiveItems[activeItemIndex] : null;

  const handleClose = React.useCallback(() => {
    setPopupOpen(false);
    setItemsByProvider([]);
    setActiveSearchString('');
    setActiveItemIndex(0);
  }, []);

  const handlePopupItemClicked = React.useCallback((item: ActileItem) => {
    const provider = providers.find(p => p.key === item.providerKey);
    provider?.onItemSelect(item);
    handleClose();
  }, [providers, handleClose]);

  const handleEnterKey = React.useCallback(() => {
    if (activeItem)
      handlePopupItemClicked(activeItem);
  }, [activeItem, handlePopupItemClicked]);

  const actileInterceptTextChange = React.useCallback((trailingText: string) => {
    // Collect all providers whose trigger matches
    const matchingProviders = providers.filter(provider => provider.fastCheckTriggerText(trailingText));

    if (matchingProviders.length > 0) {
      // Fetch items from all matching providers
      Promise.all(matchingProviders.map(provider =>
        provider.fetchItems().then(({ searchPrefix, items }) => ({
          provider,
          searchPrefix,
          items: items.map(item => ({ ...item, providerKey: provider.key })),
        })),
      )).then((results) => {
        // Filter out empty results
        results = results.filter(result => result.items.length > 0);
        if (results.length) {
          setPopupOpen(true);
          setItemsByProvider(results.map(result => ({ provider: result.provider, items: result.items })));
          setActiveSearchString(results[0].searchPrefix); // Assuming all search prefixes are the same
          setActiveItemIndex(0);
        }
      }).catch(error => {
        handleClose();
        console.error('Failed to fetch popup items:', error);
      });
      return true;
    }
    return false;
  }, [handleClose, providers]);

  const actileInterceptKeydown = React.useCallback((_event: React.KeyboardEvent<HTMLTextAreaElement>): boolean => {
    const { key, currentTarget, ctrlKey, metaKey } = _event;

    if (popupOpen) {
      if (key === 'Escape' || key === 'ArrowLeft') {
        _event.preventDefault();
        handleClose();
      } else if (key === 'ArrowUp') {
        _event.preventDefault();
        setActiveItemIndex((prevIndex) => (prevIndex > 0 ? prevIndex - 1 : totalItems - 1));
      } else if (key === 'ArrowDown') {
        _event.preventDefault();
        setActiveItemIndex((prevIndex) => (prevIndex < totalItems - 1 ? prevIndex + 1 : 0));
      } else if (key === 'Enter' || key === 'ArrowRight' || key === 'Tab' || (key === ' ' && totalItems === 1)) {
        _event.preventDefault();
        handleEnterKey();
      } else if (key === 'Backspace') {
        handleClose();
      } else if (key.length === 1 && !ctrlKey && !metaKey) {
        setActiveSearchString((prev) => prev + key);
        setActiveItemIndex(0);
      }
      return true;
    }

    // Popup closed: Check for triggers
    const trailingText = (currentTarget.value || '') + key;
    return actileInterceptTextChange(trailingText);

  }, [actileInterceptTextChange, handleClose, handleEnterKey, popupOpen, totalItems]);

  const actileComponent = React.useMemo(() => {
    return !popupOpen ? null : (
      <ActilePopup
        anchorEl={anchorRef.current}
        onClose={handleClose}
        itemsByProvider={activeItemsByProvider}
        activeItemIndex={activeItemIndex}
        activePrefixLength={activeSearchString.length}
        onItemClick={handlePopupItemClicked}
      />
    );
  }, [activeItemIndex, activeItemsByProvider, activeSearchString.length, anchorRef, handleClose, handlePopupItemClicked, popupOpen]);

  return {
    actileComponent,
    actileInterceptKeydown,
    actileInterceptTextChange,
  };
};



================================================
FILE: src/apps/chat/components/composer/buttons/ButtonAttachCamera.tsx
================================================
import * as React from 'react';

import { Box, Button, ColorPaletteProp, IconButton, Tooltip } from '@mui/joy';
import AddAPhotoIcon from '@mui/icons-material/AddAPhoto';
import CameraAltOutlinedIcon from '@mui/icons-material/CameraAltOutlined';

import { buttonAttachSx } from '~/common/components/ButtonAttachFiles';

import { CameraCaptureModal } from '../CameraCaptureModal';


export const ButtonAttachCameraMemo = React.memo(ButtonAttachCamera);

function ButtonAttachCamera(props: {
  color?: ColorPaletteProp,
  isMobile?: boolean,
  disabled?: boolean,
  fullWidth?: boolean,
  noToolTip?: boolean,
  onOpenCamera: () => void,
}) {
  return props.isMobile ? (
    <IconButton color={props.color} disabled={props.disabled} onClick={props.onOpenCamera}>
      <AddAPhotoIcon />
    </IconButton>
  ) : (
    <Tooltip arrow disableInteractive placement='top-start' title={props.noToolTip ? null : (
      <Box sx={buttonAttachSx.tooltip}>
        <b>Attach photo</b><br />
        {!!props.isMobile ? 'Auto-OCR to read text' : 'See the world, on the go'}
      </Box>
    )}>
      <Button
        variant={props.color ? 'soft' : 'plain'}
        color={props.color || 'neutral'}
        disabled={props.disabled}
        fullWidth={props.fullWidth}
        startDecorator={<CameraAltOutlinedIcon />}
        onClick={props.onOpenCamera}
        sx={buttonAttachSx.desktop}
      >
        Camera
      </Button>
    </Tooltip>
  );
}

export function useCameraCaptureModalDialog(onAttachImageStable: (file: File) => void) {

  // state
  const [open, setOpen] = React.useState(false);

  const openCamera = React.useCallback(() => setOpen(true), []);

  const cameraCaptureComponent = React.useMemo(() => open && (
    <CameraCaptureModal
      onCloseModal={() => setOpen(false)}
      onAttachImage={onAttachImageStable}
    />
  ), [open, onAttachImageStable]);

  return {
    openCamera,
    cameraCaptureComponent,
  };
}


================================================
FILE: src/apps/chat/components/composer/buttons/ButtonAttachClipboard.tsx
================================================
import * as React from 'react';

import { Box, Button, ColorPaletteProp, IconButton, Tooltip } from '@mui/joy';
import ContentPasteGoIcon from '@mui/icons-material/ContentPasteGo';

import { KeyStroke } from '~/common/components/KeyStroke';
import { buttonAttachSx } from '~/common/components/ButtonAttachFiles';


export const ButtonAttachClipboardMemo = React.memo(ButtonAttachClipboard);

function ButtonAttachClipboard(props: {
  color?: ColorPaletteProp,
  isMobile?: boolean,
  disabled?: boolean,
  fullWidth?: boolean,
  noToolTip?: boolean,
  onAttachClipboard: () => void,
}) {
  return props.isMobile ? (
    <IconButton color={props.color} disabled={props.disabled} onClick={props.onAttachClipboard}>
      <ContentPasteGoIcon />
    </IconButton>
  ) : (
    <Tooltip arrow disableInteractive placement='top-start' title={props.noToolTip ? null : (
      <Box sx={buttonAttachSx.tooltip}>
        <b>Attach clipboard 📚</b><br />
        Auto-converts to the best types<br />
        <KeyStroke combo='Ctrl + Shift + V' sx={{ mt: 1, mb: 0.5 }} />
      </Box>
    )}>
      <Button
        variant={props.color ? 'soft' : 'plain'}
        color={props.color || 'neutral'}
        disabled={props.disabled}
        fullWidth={props.fullWidth}
        startDecorator={<ContentPasteGoIcon />}
        onClick={props.onAttachClipboard}
        sx={buttonAttachSx.desktop}
      >
        Paste
      </Button>
    </Tooltip>
  );
}



================================================
FILE: src/apps/chat/components/composer/buttons/ButtonAttachNewDoc.tsx
================================================
import * as React from 'react';

import { Box, Button, ColorPaletteProp, IconButton, Tooltip } from '@mui/joy';
import AddRoundedIcon from '@mui/icons-material/AddRounded';

import { buttonAttachSx } from '~/common/components/ButtonAttachFiles';


export const ButtonAttachNewMemo = React.memo(ButtonAttachNew);

function ButtonAttachNew(props: {
  color?: ColorPaletteProp,
  isMobile?: boolean,
  disabled?: boolean,
  fullWidth?: boolean,
  noToolTip?: boolean,
  onAttachNew: () => void,
}) {
  return props.isMobile ? (
    <IconButton color={props.color} disabled={props.disabled} onClick={props.onAttachNew}>
      <AddRoundedIcon />
    </IconButton>
  ) : (
    <Tooltip arrow disableInteractive placement='top-start' title={props.noToolTip ? null : (
      <Box sx={buttonAttachSx.tooltip}>
        <b>Create new document</b><br />
        Edit your own empty document
        {/*<br />*/}
        {/*<KeyStroke combo='Ctrl + Alt + N' sx={{ mt: 1, mb: 0.5 }} />*/}
      </Box>
    )}>
      <Button
        variant={props.color ? 'soft' : 'plain'}
        color={props.color || 'neutral'}
        disabled={props.disabled}
        fullWidth={props.fullWidth}
        startDecorator={<AddRoundedIcon />}
        onClick={props.onAttachNew}
        sx={buttonAttachSx.desktop}
      >
        Note
      </Button>
    </Tooltip>
  );
}



================================================
FILE: src/apps/chat/components/composer/buttons/ButtonAttachScreenCapture.tsx
================================================
import * as React from 'react';

import { Box, Button, ColorPaletteProp, IconButton, Tooltip } from '@mui/joy';
import ScreenshotMonitorIcon from '@mui/icons-material/ScreenshotMonitor';

import { Is } from '~/common/util/pwaUtils';
import { buttonAttachSx } from '~/common/components/ButtonAttachFiles';
import { takeScreenCapture } from '~/common/util/screenCaptureUtils';


export const ButtonAttachScreenCaptureMemo = React.memo(ButtonAttachScreenCapture);

function ButtonAttachScreenCapture(props: {
  color?: ColorPaletteProp,
  isMobile?: boolean,
  disabled?: boolean,
  fullWidth?: boolean,
  noToolTip?: boolean,
  onAttachScreenCapture: (file: File) => void
}) {

  // state
  const [capturing, setCapturing] = React.useState(false);
  const [error, setError] = React.useState<string | null>(null);

  // derived state
  const { onAttachScreenCapture } = props;


  const handleTakeScreenCapture = React.useCallback(async () => {
    setError(null);
    setCapturing(true);
    try {
      const file = await takeScreenCapture();
      file && onAttachScreenCapture(file);
    } catch (error: any) {
      const message = error instanceof Error ? error.message : String(error);
      setError(`Issue: ${message}`);
    }
    setCapturing(false);
  }, [onAttachScreenCapture]);


  return props.isMobile ? (
    <IconButton color={props.color} disabled={props.disabled} onClick={handleTakeScreenCapture}>
      <ScreenshotMonitorIcon />
    </IconButton>
  ) : (
    <Tooltip arrow disableInteractive placement='top-start' title={props.noToolTip ? null : (
      <Box sx={buttonAttachSx.tooltip}>
        <b>Attach screen capture</b><br />
        {error || 'Attach the image of a window, a browser tab, or a screen'}
        {!error && Is.OS.MacOS && Is.Browser.Safari && (
          <Box sx={{ mt: 1 }}><b>Safari</b>: canceling the window selection may cause a 60-second delay.</Box>
        )}
      </Box>
    )}>
      <Button
        variant={capturing ? 'solid' : props.color ? 'soft' : 'plain'}
        color={!!error ? 'danger' : props.color || 'neutral'}
        disabled={props.disabled}
        fullWidth={props.fullWidth}
        loading={capturing}
        loadingPosition={capturing ? 'start' : 'center'}
        startDecorator={<ScreenshotMonitorIcon />}
        onClick={handleTakeScreenCapture}
        sx={buttonAttachSx.desktop}
      >
        Screen
      </Button>
    </Tooltip>
  );
}



================================================
FILE: src/apps/chat/components/composer/buttons/ButtonAttachWeb.tsx
================================================
import * as React from 'react';

import { Box, Button, ColorPaletteProp, IconButton, Tooltip } from '@mui/joy';
import LanguageRoundedIcon from '@mui/icons-material/LanguageRounded';

import { buttonAttachSx } from '~/common/components/ButtonAttachFiles';
import { KeyStroke } from '~/common/components/KeyStroke';


export const ButtonAttachWebMemo = React.memo(ButtonAttachWeb);

function ButtonAttachWeb(props: {
  color?: ColorPaletteProp,
  isMobile?: boolean,
  disabled?: boolean,
  fullWidth?: boolean,
  noToolTip?: boolean,
  onOpenWebInput: () => void,
}) {

  const button = props.isMobile ? (
    <IconButton color={props.color} disabled={props.disabled} onClick={props.onOpenWebInput}>
      <LanguageRoundedIcon />
    </IconButton>
  ) : (
    <Button
      variant={props.color ? 'soft' : 'plain'}
      color={props.color || 'neutral'}
      disabled={props.disabled}
      fullWidth={props.fullWidth}
      startDecorator={<LanguageRoundedIcon />}
      onClick={props.onOpenWebInput}
      sx={buttonAttachSx.desktop}
    >
      Web
    </Button>
  );

  return (props.noToolTip || props.isMobile) ? button : (
    <Tooltip arrow disableInteractive placement='top-start' title={
      <Box sx={buttonAttachSx.tooltip}>
        <b>Add Web Content 🌐</b><br />
        Import from websites and YouTube
        <KeyStroke combo='Ctrl + Shift + L' sx={{ mt: 1, mb: 0.5 }} />
      </Box>
    }>
      {button}
    </Tooltip>
  );
}



================================================
FILE: src/apps/chat/components/composer/buttons/ButtonBeam.tsx
================================================
import * as React from 'react';

import type { ColorPaletteProp, SxProps } from '@mui/joy/styles/types';
import { Box, Button, IconButton, Tooltip } from '@mui/joy';

import { ChatBeamIcon } from '~/common/components/icons/ChatBeamIcon';
import { KeyStroke } from '~/common/components/KeyStroke';
import { animationEnterBelow } from '~/common/util/animUtils';


const desktopLegend =
  <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
    Combine the answers from multiple models<br />
    <KeyStroke combo='Ctrl + Enter' sx={{ mt: 0.5, mb: 0.25 }} />
  </Box>;

const desktopLegendNoContent =
  <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
    Enter the text to Beam, then press this
  </Box>;

const mobileSx: SxProps = {
  mr: { xs: 1, md: 2 },
};

const desktopSx: SxProps = {
  '--Button-gap': '1rem',
  backgroundColor: 'background.popup',
  // border: '1px solid',
  // borderColor: 'primary.outlinedBorder',
  boxShadow: '0 4px 16px -4px rgb(var(--joy-palette-primary-mainChannel) / 10%)',
  animation: `${animationEnterBelow} 0.1s ease-out`,
};


export const ButtonBeamMemo = React.memo(ButtonBeam);

function ButtonBeam(props: {
  isMobile?: boolean,
  color?: ColorPaletteProp,
  disabled?: boolean,
  hasContent?: boolean,
  onClick: () => void,
}) {
  return props.isMobile ? (
    <IconButton variant='soft' color={props.color ?? 'primary'} disabled={props.disabled} onClick={props.onClick} sx={mobileSx}>
      <ChatBeamIcon />
    </IconButton>
  ) : (
    <Tooltip disableInteractive variant='solid' arrow placement='right' title={props.hasContent ? desktopLegend : desktopLegendNoContent}>
      <Button variant='soft' color={props.color ?? 'primary'} disabled={props.disabled} onClick={props.onClick} endDecorator={<ChatBeamIcon />} sx={desktopSx}>
        Beam
      </Button>
    </Tooltip>
  );
}


================================================
FILE: src/apps/chat/components/composer/buttons/ButtonCall.tsx
================================================
import * as React from 'react';

import { Box, Button, IconButton, Tooltip } from '@mui/joy';
import { SxProps } from '@mui/joy/styles/types';
import CallIcon from '@mui/icons-material/Call';


const callConversationLegend =
  <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
    Quick call regarding this chat
  </Box>;

const mobileSx: SxProps = {
  mr: { xs: 1, md: 2 },
} as const;

const desktopSx: SxProps = {
  '--Button-gap': '1rem',
} as const;


export const ButtonCallMemo = React.memo(ButtonCall);

function ButtonCall(props: { isMobile?: boolean, disabled?: boolean, onClick: () => void }) {
  return props.isMobile ? (
    <IconButton variant='soft' color='primary' disabled={props.disabled} onClick={props.onClick} sx={mobileSx}>
      <CallIcon />
    </IconButton>
  ) : (
    <Tooltip disableInteractive variant='solid' arrow placement='right' title={callConversationLegend}>
      <Button variant='soft' color='primary' disabled={props.disabled} onClick={props.onClick} endDecorator={<CallIcon />} sx={desktopSx}>
        Call
      </Button>
    </Tooltip>
  );
}


================================================
FILE: src/apps/chat/components/composer/buttons/ButtonGroupDrawRepeat.tsx
================================================
import * as React from 'react';

import { Box, FormControl, IconButton } from '@mui/joy';


const _styles = {
  control: {
    gap: 1,
    mt: 1,
  } as const,

  buttonGroup: {
    display: 'flex',
    justifyContent: 'space-evenly',
    // overflowX: 'hidden',
    flexWrap: 'wrap',
    minWidth: '131px',
  } as const,

  buttonActive: {
    '--IconButton-size': { xs: '1.75rem', lg: '2rem' },
  } as const,

  button: {
    '--IconButton-size': { xs: '1.75rem', lg: '2rem' },
    border: '1px solid',
    borderColor: 'warning.outlinedBorder',
    backgroundColor: 'background.popup',
    // boxShadow: drawRepeat === n ? '0px 2px 8px 0px rgb(var(--joy-palette-warning-mainChannel) / 40%)' : 'none',
    // fontWeight: drawRepeat === n ? 'xl' : 400, /* reset, from 600 */
    transition: 'transform 0.14s, box-shadow 0.14s',
    '&:hover': {
      transform: 'translateY(-1px)',
      // backgroundColor: drawRepeat === n ? 'background.popup' : 'background.surface',
      // boxShadow: '0 0 8px 1px rgb(var(--joy-palette-warning-mainChannel) / 40%)',
    } as const,
  } as const,

  text: {
    mx: 'auto',
    fontSize: 'xs',
    opacity: '0.5',
  } as const,
} as const;


export function ButtonGroupDrawRepeat(props: {
  drawRepeat: number,
  setDrawRepeat: (n: number) => void,
}) {

  const { drawRepeat, setDrawRepeat } = props;

  return (
    <FormControl sx={_styles.control}>
      <Box sx={_styles.buttonGroup}>
        {[1, 2, 4, 5, 10].map((n) => (
          <IconButton
            key={n}
            size='sm'
            color='warning'
            variant={drawRepeat === n ? 'solid' : 'soft'}
            onClick={() => setDrawRepeat(n)}
            sx={drawRepeat === n ? _styles.buttonActive : _styles.button}
          >
            {n}
          </IconButton>
        ))}
      </Box>
      <Box sx={_styles.text}>
        {drawRepeat > 1
          ? `Create ${drawRepeat} Images`
          : 'Number of Images'}
      </Box>
    </FormControl>
  );
}


================================================
FILE: src/apps/chat/components/composer/buttons/ButtonMic.tsx
================================================
import * as React from 'react';

import { Alert, Box, IconButton } from '@mui/joy';
import { ColorPaletteProp, VariantProp } from '@mui/joy/styles/types';
import MicIcon from '@mui/icons-material/Mic';

import { ExternalDocsLink } from '~/common/components/ExternalDocsLink';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { KeyStroke } from '~/common/components/KeyStroke';
import { useDontBlurTextarea } from '~/common/components/useDontBlurTextarea';


const micLegend = (errorMessage: string | null) =>
  <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
    Voice input<br />
    <KeyStroke combo='Ctrl + M' sx={{ mt: 1, mb: 0.5 }} />
    {errorMessage && (
      <Alert variant='soft' color='danger' sx={{ mt: 2, mb: 0.5, flexDirection: 'column', alignItems: 'flex-start' }}>
        {errorMessage}
        <ExternalDocsLink color='danger' level='body-sm' docPage='help-feature-microphone'>
          How to fix...
        </ExternalDocsLink>
      </Alert>
    )}
  </Box>;


export const ButtonMicMemo = React.memo(ButtonMic);

function ButtonMic(props: {
  variant: VariantProp,
  color: ColorPaletteProp,
  errorMessage: string | null,
  noBackground?: boolean,
  onClick: () => void,
}) {

  // Mobile: don't blur the textarea when clicking the mic button
  const handleDontBlurTextArea = useDontBlurTextarea();

  return (
    <GoodTooltip placement='top' arrow enableInteractive title={micLegend(props.errorMessage)}>
      <IconButton variant={props.variant} color={props.color} onMouseDown={handleDontBlurTextArea} onClick={props.onClick} sx={props.noBackground ? { background: 'none' } : {}}>
        <MicIcon />
      </IconButton>
    </GoodTooltip>
  );
}


================================================
FILE: src/apps/chat/components/composer/buttons/ButtonMicContinuation.tsx
================================================
import * as React from 'react';

import { Box, IconButton, Tooltip } from '@mui/joy';
import { ColorPaletteProp, SxProps, VariantProp } from '@mui/joy/styles/types';
import RepeatIcon from '@mui/icons-material/Repeat';
import RepeatOnIcon from '@mui/icons-material/RepeatOn';

const micContinuationLegend =
  <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
    Voice Continuation
  </Box>;


export const ButtonMicContinuationMemo = React.memo(ButtonMicContinuation);

function ButtonMicContinuation(props: { isActive: boolean, variant: VariantProp, color: ColorPaletteProp, onClick: () => void, sx?: SxProps }) {
  return <Tooltip placement='bottom' title={micContinuationLegend}>
    <IconButton variant={props.variant} color={props.color} onClick={props.onClick} sx={props.sx}>
      {props.isActive ? <RepeatOnIcon /> : <RepeatIcon />}
    </IconButton>
  </Tooltip>;
}


================================================
FILE: src/apps/chat/components/composer/buttons/ButtonMultiChat.tsx
================================================
import * as React from 'react';

import { Box, FormControl, FormLabel, IconButton, Switch } from '@mui/joy';

import { ChatMulticastOnIcon } from '~/common/components/icons/ChatMulticastOnIcon';
import { ChatMulticastOffIcon } from '~/common/components/icons/ChatMulticastOffIcon';


export const ButtonMultiChatMemo = React.memo(ButtonMultiChat);

export function ButtonMultiChat(props: { isMobile?: boolean, multiChat: boolean, onSetMultiChat: (multiChat: boolean) => void }) {
  const { multiChat } = props;
  return props.isMobile ? (
    <IconButton
      variant={multiChat ? 'solid' : 'outlined'}
      color={multiChat ? 'warning' : undefined}
      onClick={() => props.onSetMultiChat(!multiChat)}
    >
      {multiChat ? <ChatMulticastOnIcon /> : <ChatMulticastOnIcon />}
    </IconButton>
  ) : (
    <FormControl orientation='horizontal' sx={{ minHeight: '2.25rem', justifyContent: 'space-between' }}>
      <FormLabel sx={{ gap: 1, flexFlow: 'row nowrap' }}>
        <Box sx={{ display: { xs: 'none', lg: 'inline-block' } }}>
          {multiChat ? <ChatMulticastOnIcon color='primary' /> : <ChatMulticastOffIcon />}
        </Box>
        {multiChat ? 'Multichat · On' : 'Multichat'}
      </FormLabel>
      <Switch color={multiChat ? 'primary' : undefined} checked={multiChat} onChange={(e) => props.onSetMultiChat(e.target.checked)} />
    </FormControl>
  );
}


================================================
FILE: src/apps/chat/components/composer/buttons/ButtonOptionsDraw.tsx
================================================
import * as React from 'react';

import { Button, IconButton } from '@mui/joy';
import { SxProps } from '@mui/joy/styles/types';
import FormatPaintTwoToneIcon from '@mui/icons-material/FormatPaintTwoTone';

import { PhSlidersHorizontalIcon } from '~/common/components/icons/phosphor/PhSlidersHorizontalIcon';


export function ButtonOptionsDraw(props: { isMobile?: boolean, onClick: () => void, sx?: SxProps }) {
  return props.isMobile ? (
    <IconButton variant='soft' color='warning' onClick={props.onClick} sx={props.sx}>
      <FormatPaintTwoToneIcon />
    </IconButton>
  ) : (
    <Button variant='soft' color='warning' onClick={props.onClick} sx={props.sx} endDecorator={<PhSlidersHorizontalIcon />}>
      Image Settings
    </Button>
  );
}


================================================
FILE: src/apps/chat/components/composer/llmattachments/LLMAttachmentButton.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, Button, CircularProgress, ColorPaletteProp, Sheet, Typography, VariantProp } from '@mui/joy';
import AbcIcon from '@mui/icons-material/Abc';
import CodeIcon from '@mui/icons-material/Code';
import DescriptionOutlinedIcon from '@mui/icons-material/DescriptionOutlined';
import HtmlIcon from '@mui/icons-material/Html';
import ImageOutlinedIcon from '@mui/icons-material/ImageOutlined';
import PermMediaOutlinedIcon from '@mui/icons-material/PermMediaOutlined';
import PhotoSizeSelectLargeOutlinedIcon from '@mui/icons-material/PhotoSizeSelectLargeOutlined';
import PhotoSizeSelectSmallOutlinedIcon from '@mui/icons-material/PhotoSizeSelectSmallOutlined';
import PictureAsPdfIcon from '@mui/icons-material/PictureAsPdf';
import PivotTableChartIcon from '@mui/icons-material/PivotTableChart';
import TelegramIcon from '@mui/icons-material/Telegram';
import TextFieldsIcon from '@mui/icons-material/TextFields';
import TextureIcon from '@mui/icons-material/Texture';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';
import YouTubeIcon from '@mui/icons-material/YouTube';

import { RenderImageRefDBlob } from '~/modules/blocks/image/RenderImageRefDBlob';
import { RenderImageURL } from '~/modules/blocks/image/RenderImageURL';

import type { AttachmentDraft, AttachmentDraftConverterType, AttachmentDraftId } from '~/common/attachment-drafts/attachment.types';
import { DMessageDataRef, DMessageImageRefPart, isImageRefPart } from '~/common/stores/chat/chat.fragments';
import { LiveFileIcon } from '~/common/livefile/liveFile.icons';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { ellipsizeFront, ellipsizeMiddle } from '~/common/util/textUtils';

import type { LLMAttachmentDraft } from './useLLMAttachmentDrafts';


const ATTACHMENT_MIN_STYLE = {
  height: '100%',
  minHeight: '40px',
  // commented, this is messing with the style
  // minWidth: '64px',
};

const attachmentConverterSx = { width: 18, height: 18 } as const;
const attachmentIconSx = { width: 30, maxHeight: 30, overflow: 'hidden' } as const;

const webPreviewImageSx = {
  ...attachmentIconSx,
  // transform: 'perspective(100px) rotateX(60deg)',
  // transform: 'perspective(100px) rotateY(-20deg) rotateX(30deg)',
  // transformStyle: 'preserve-3d',
} as const;


const ellipsizeLabel = (label?: string) => {
  if (!label)
    return '';
  return ellipsizeMiddle((label || '')
    .replace(/https?:\/\/(?:www\.)?/, ''), 30)
    .replace(/\/$/, '')
    .replace('…', '…\n…');
};


/**
 * Displayed while a source is loading
 */
function InputLoadingPlaceholder(props: { label: string }) {
  return <Sheet
    color='success' variant='soft'
    sx={{
      border: '1px solid',
      borderColor: 'success.solidBg',
      borderRadius: 'sm',
      display: 'flex', alignItems: 'center', justifyContent: 'center', gap: 1,
      ...ATTACHMENT_MIN_STYLE,
      boxSizing: 'border-box',
      px: 1, py: 0.5, // reduce
    }}
  >
    <CircularProgress color='success' size='sm' />
    <Typography level='title-sm' sx={{ whiteSpace: 'nowrap' }}>
      {ellipsizeLabel(props.label)}
    </Typography>
  </Sheet>;
}

/**
 * Displayed when there is an error loading the input (e.g. file does not exist)
 */
function InputErrorIndicator() {
  return <WarningRoundedIcon sx={{ color: 'danger.solidBg' }} />;
}


const converterTypeToIconMap: { [key in AttachmentDraftConverterType]: React.ComponentType<any> | null } = {
  'text': TextFieldsIcon,
  'rich-text': CodeIcon,
  'rich-text-cleaner': CodeIcon,
  'rich-text-table': PivotTableChartIcon,
  'image-original': ImageOutlinedIcon,
  'image-resized-high': PhotoSizeSelectLargeOutlinedIcon,
  'image-resized-low': PhotoSizeSelectSmallOutlinedIcon,
  'image-to-default': ImageOutlinedIcon,
  'image-ocr': AbcIcon,
  'pdf-text': PictureAsPdfIcon,
  'pdf-images': PermMediaOutlinedIcon,
  'pdf-text-and-images': PermMediaOutlinedIcon,
  'docx-to-html': DescriptionOutlinedIcon,
  'url-page-text': TextFieldsIcon, // was LanguageIcon
  'url-page-markdown': CodeIcon, // was LanguageIcon
  'url-page-html': HtmlIcon, // was LanguageIcon
  'url-page-null': TextureIcon,
  'url-page-image': ImageOutlinedIcon,
  'youtube-transcript': YouTubeIcon,
  'youtube-transcript-simple': YouTubeIcon,
  'ego-fragments-inlined': TelegramIcon,
  'unhandled': TextureIcon,
};

function attachmentIcons(attachmentDraft: AttachmentDraft, noTooltips: boolean, onViewImageRefPart: (imageRefPart: DMessageImageRefPart) => void) {
  const activeConverters = attachmentDraft.converters.filter(c => c.isActive);
  if (activeConverters.length === 0)
    return null;

  // Alternate icon for the Web Page Screenshot
  const urlImage = attachmentDraft.input?.urlImage;
  const urlImageData = urlImage?.imgDataUrl;

  // Alternate icon for Single-Image DBlob output fragments (just single for now, multiple may not look good)
  let outputSingleImageRefDBlobs: Extract<DMessageDataRef, { reftype: 'dblob' }>[] = [];
  if (!urlImageData && attachmentDraft.outputFragments.length === 1) {
    const fragment = attachmentDraft.outputFragments[0];
    if (isImageRefPart(fragment.part) && fragment.part.dataRef && fragment.part.dataRef.reftype === 'dblob')
      outputSingleImageRefDBlobs = [fragment.part.dataRef];
  }

  const handleViewFirstImage = (e: React.MouseEvent) => {
    e.preventDefault();
    e.stopPropagation();
    if (attachmentDraft.outputFragments[0] && isImageRefPart(attachmentDraft.outputFragments[0].part))
      onViewImageRefPart(attachmentDraft.outputFragments[0].part);
  };

  // Whether to render the converters
  const renderConverterIcons = !outputSingleImageRefDBlobs.length;

  // 1+ icons
  return <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>

    {/* If we have a Web preview, show it first */}
    {!!urlImageData && /*!imageDataRefs.length &&*/ (
      <TooltipOutlined key='preview' title={noTooltips ? null : <>
        {urlImage?.generator === 'youtube-thumbnail' ? 'Thumbnail' : 'Page screenshot'} {!!urlImage?.timestamp && <>as of <TimeAgo date={urlImage.timestamp} /></>}.
        <br />
        Select <b>Add {urlImage?.generator === 'youtube-thumbnail' ? 'Thumbnail' : 'Screenshot'}</b> to attach it too.
      </>} placement='top-start'>
        <div>
          <RenderImageURL
            imageURL={urlImageData}
            variant='attachment-button'
            scaledImageSx={webPreviewImageSx}
          />
        </div>
      </TooltipOutlined>
    )}

    {/* Render DBlob referred images in place of converter icons */}
    {outputSingleImageRefDBlobs.map((dataRef, _i) => dataRef && (
      <TooltipOutlined key={`image-${dataRef.dblobAssetId}`} title={noTooltips ? null : <>View converted image{/* <br/>{dataRef?.bytesSize?.toLocaleString()} bytes */}</>} placement='top-start'>
        <div>
          <RenderImageRefDBlob
            dataRefDBlobAssetId={dataRef.dblobAssetId}
            dataRefMimeType={dataRef.mimeType}
            dataRefBytesSize={dataRef.bytesSize}
            variant='attachment-button'
            scaledImageSx={attachmentIconSx}
            onClick={handleViewFirstImage}
          />
        </div>
      </TooltipOutlined>
    ))}

    {/*{activeConverters.some(c => c.id.startsWith('url-page-')) ? <LanguageIcon sx={{ opacity: 0.2, ml: -2.5 }} /> : null}*/}
    {renderConverterIcons && activeConverters.map((_converter, idx) => {
      const Icon = converterTypeToIconMap[_converter.id] ?? null;
      return !Icon ? null : (
        <TooltipOutlined key={`${_converter.id}-${idx}`} title={noTooltips ? null : `Attached as ${_converter.name}`} placement='top-start'>
          <Icon sx={attachmentConverterSx} />
        </TooltipOutlined>
      );
    })}

  </Box>;
}

function attachmentLabelText(attachmentDraft: AttachmentDraft): string {
  const converter = attachmentDraft.converters.find(c => c.isActive) ?? null;
  if (converter && attachmentDraft.label === 'Rich Text') {
    if (converter.id === 'rich-text-table')
      return 'Rich Table';
    if (converter.id === 'rich-text-cleaner')
      return 'Clean HTML';
    if (converter.id === 'rich-text')
      return 'Rich HTML';
  }
  return ellipsizeFront(attachmentDraft.label, 22);
}


export const LLMAttachmentButtonMemo = React.memo(LLMAttachmentButton);

function LLMAttachmentButton(props: {
  llmAttachment: LLMAttachmentDraft,
  menuShown: boolean,
  onToggleMenu: (attachmentDraftId: AttachmentDraftId, anchor: HTMLAnchorElement) => void,
  onViewImageRefPart: (imageRefPart: DMessageImageRefPart) => void,
}) {

  // derived state
  const { attachmentDraft: draft, llmSupportsAllFragments } = props.llmAttachment;

  const isInputLoading = draft.inputLoading;
  const isInputError = !!draft.inputError;
  const isUnconvertible = !draft.converters.length;
  const isOutputLoading = draft.outputsConverting;
  const isOutputMissing = !draft.outputFragments.length;
  const hasLiveFiles = draft.outputFragments.some(_f => _f.liveFileId);

  const showWarning = isUnconvertible || (isOutputMissing || !llmSupportsAllFragments);


  // handlers

  const { onToggleMenu } = props;

  const handleToggleMenu = React.useCallback((event: React.MouseEvent<HTMLAnchorElement>) => {
    event.preventDefault(); // added for the Right mouse click (to prevent the menu)
    onToggleMenu(draft.id, event.currentTarget);
  }, [draft.id, onToggleMenu]);

  // choose variants and color
  const color: ColorPaletteProp =
    (isInputLoading || isOutputLoading) ? 'success'
      : isInputError ? 'danger'
        : showWarning ? 'warning'
          : /*props.menuShown ? 'primary' :*/ 'neutral';

  const variant: VariantProp =
    (isInputLoading || isOutputLoading || isInputError || showWarning) ? 'soft'
      : 'outlined';

  // loading indicator before we are ready for a button
  if (isInputLoading)
    return <InputLoadingPlaceholder label={draft.label} />;

  return (
    <Button
      size='sm'
      color={color}
      variant={variant}
      onClick={handleToggleMenu}
      onContextMenu={handleToggleMenu}
      sx={{
        backgroundColor: props.menuShown ? `${color}.softActiveBg` : variant === 'outlined' ? 'background.popup' : undefined,
        border: variant === 'soft' ? '1px solid' : undefined,
        borderColor: variant === 'soft' ? `${color}.solidBg` : undefined,
        borderRadius: 'sm',
        ...ATTACHMENT_MIN_STYLE,
        px: 1, py: 0.5, // reduce
        gap: 1,
      }}
    >

      {isInputError && <InputErrorIndicator />}

      {/* Icons: Web Page Screenshot, Converter[s] */}
      {attachmentIcons(draft, props.menuShown, props.onViewImageRefPart)}

      {/* Label */}
      <Typography level='title-sm' sx={{ whiteSpace: 'nowrap' }}>
        {isOutputLoading ? 'Converting... ' : attachmentLabelText(draft)}
      </Typography>

      {/* Is Converting icon */}
      {isOutputLoading && <CircularProgress color='success' size='sm' />}

      {/* LiveFile is supported icon */}
      {hasLiveFiles && (
        <TooltipOutlined title='LiveFile is supported' placement='top-end'>
          <LiveFileIcon />
        </TooltipOutlined>
      )}

    </Button>
  );
}



================================================
FILE: src/apps/chat/components/composer/llmattachments/LLMAttachmentMenu.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Checkbox, Chip, CircularProgress, LinearProgress, ListDivider, ListItem, ListItemDecorator, MenuItem, Radio, Typography } from '@mui/joy';
import AttachmentIcon from '@mui/icons-material/Attachment';
import ClearIcon from '@mui/icons-material/Clear';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';
import ExpandLessIcon from '@mui/icons-material/ExpandLess';
import ExpandMoreIcon from '@mui/icons-material/ExpandMore';
import KeyboardArrowLeftIcon from '@mui/icons-material/KeyboardArrowLeft';
import KeyboardArrowRightIcon from '@mui/icons-material/KeyboardArrowRight';
import ReadMoreIcon from '@mui/icons-material/ReadMore';
import VerticalAlignBottomIcon from '@mui/icons-material/VerticalAlignBottom';
import VisibilityIcon from '@mui/icons-material/Visibility';

import { CloseablePopup } from '~/common/components/CloseablePopup';
import { DMessageAttachmentFragment, DMessageDocPart, DMessageImageRefPart, isDocPart, isImageRefPart } from '~/common/stores/chat/chat.fragments';
import { LiveFileIcon } from '~/common/livefile/liveFile.icons';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import type { AttachmentDraftId } from '~/common/attachment-drafts/attachment.types';
import type { AttachmentDraftsStoreApi } from '~/common/attachment-drafts/store-attachment-drafts_slice';
import type { LLMAttachmentDraft } from './useLLMAttachmentDrafts';
import type { LLMAttachmentDraftsAction } from './LLMAttachmentsList';


// configuration
const DEFAULT_DETAILS_OPEN = true;
const SHOW_INLINING_OPERATIONS = false;


const indicatorSx = {
  fontSize: '1rem',
} as const;

const indicatorGapSx: SxProps = {
  paddingLeft: '1.375rem',
};


export function LLMAttachmentMenu(props: {
  attachmentDraftsStoreApi: AttachmentDraftsStoreApi,
  llmAttachmentDraft: LLMAttachmentDraft,
  menuAnchor: HTMLAnchorElement,
  isPositionFirst: boolean,
  isPositionLast: boolean,
  onClose: () => void,
  onDraftAction?: (attachmentDraftId: AttachmentDraftId, actionId: LLMAttachmentDraftsAction) => void,
  onViewDocPart: (docPart: DMessageDocPart) => void,
  onViewImageRefPart: (imageRefPart: DMessageImageRefPart) => void
}) {

  // state
  const [showDetails, setShowDetails] = React.useState(DEFAULT_DETAILS_OPEN);

  // external state
  const uiComplexityMode = useUIPreferencesStore(state => state.complexityMode);


  // derived state

  const isUnmoveable = props.isPositionFirst && props.isPositionLast;

  const {
    attachmentDraft: draft,
    llmSupportsAllFragments,
    llmSupportsTextFragments,
    llmTokenCountApprox,
  } = props.llmAttachmentDraft;

  const {
    id: draftId,
    source: draftSource,
    input: draftInput,
    outputsConverting: isConverting,
  } = draft;

  const isInputError = !!draft.inputError;
  const isUnconvertible = !draft.converters.length;
  const isOutputMissing = !draft.outputFragments.length;
  const isOutputMultiple = draft.outputFragments.length > 1;
  const hasLiveFiles = draft.outputFragments.some(_f => _f.liveFileId);

  const showWarning = isUnconvertible || isOutputMissing || !llmSupportsAllFragments;


  // hooks

  const handleToggleShowDetails = React.useCallback(() => {
    setShowDetails(on => !on);
  }, []);


  // operations

  const { attachmentDraftsStoreApi, onClose, onDraftAction, onViewDocPart, onViewImageRefPart } = props;

  const handleMoveUp = React.useCallback(() => {
    attachmentDraftsStoreApi.getState().moveAttachmentDraft(draftId, -1);
  }, [draftId, attachmentDraftsStoreApi]);

  const handleMoveDown = React.useCallback(() => {
    attachmentDraftsStoreApi.getState().moveAttachmentDraft(draftId, 1);
  }, [draftId, attachmentDraftsStoreApi]);

  const handleRemove = React.useCallback(() => {
    onClose();
    attachmentDraftsStoreApi.getState().removeAttachmentDraft(draftId);
  }, [draftId, attachmentDraftsStoreApi, onClose]);

  const handleSetConverterIdx = React.useCallback(async (converterIdx: number | null) => {
    return attachmentDraftsStoreApi.getState().toggleAttachmentDraftConverterAndConvert(draftId, converterIdx);
  }, [draftId, attachmentDraftsStoreApi]);

  const handleDeleteOutputFragment = React.useCallback((event: React.MouseEvent, fragmentIndex: number) => {
    event.preventDefault();
    event.stopPropagation();
    attachmentDraftsStoreApi.getState().removeAttachmentDraftOutputFragment(draftId, fragmentIndex);
  }, [attachmentDraftsStoreApi, draftId]);

  const handleCopyToClipboard = React.useCallback((event: React.MouseEvent, text: string) => {
    event.preventDefault();
    event.stopPropagation();
    copyToClipboard(text, 'Attachment Text');
  }, []);

  const handleCopyLabelToClipboard = React.useCallback((event: React.MouseEvent, text: string) => {
    event.preventDefault();
    event.stopPropagation();
    copyToClipboard(text, 'Attachment Name');
  }, []);

  const handleViewImageRefPart = React.useCallback((event: React.MouseEvent, imageRefPart: DMessageImageRefPart) => {
    event.preventDefault();
    event.stopPropagation();
    onViewImageRefPart(imageRefPart);
  }, [onViewImageRefPart]);

  const handleViewDocPart = React.useCallback((event: React.MouseEvent, docPart: DMessageDocPart) => {
    event.preventDefault();
    event.stopPropagation();
    onViewDocPart(docPart);
  }, [onViewDocPart]);

  const canHaveDetails = !!draftInput && !isConverting;

  const showInputs = uiComplexityMode !== 'minimal';

  return (
    <CloseablePopup
      menu anchorEl={props.menuAnchor} onClose={props.onClose}
      dense
      maxWidth={460}
      minWidth={260}
      noTopPadding
      placement='top'
    >

      {/* Move Arrows */}
      {!isUnmoveable && <Box sx={{ display: 'flex', alignItems: 'center', borderBottom: '1px solid', borderColor: 'divider' }}>
        <MenuItem
          disabled={props.isPositionFirst}
          onClick={handleMoveUp}
          sx={{ flex: 1, display: 'flex', justifyContent: 'center' }}
        >
          <KeyboardArrowLeftIcon />
        </MenuItem>
        <MenuItem
          disabled={props.isPositionLast}
          onClick={handleMoveDown}
          sx={{ flex: 1, display: 'flex', justifyContent: 'center' }}
        >
          <KeyboardArrowRightIcon />
        </MenuItem>
      </Box>}

      {/*{(showDetails && canHaveDetails) && <ListItem variant='soft' sx={{ fontSize: 'sm', borderBottom: '1px solid', borderColor: 'divider' }}>*/}
      {/*  {draft.ref}*/}
      {/*</ListItem>}*/}

      {/* Render Converters as menu items */}
      {!isUnconvertible && (
        <ListItem sx={{ fontSize: 'sm', my: 0.75 }}>
          Attach {draftSource.media === 'url' ? 'web page'
          : draftSource.media === 'file' ? 'file'
            : draftSource.media === 'text'
              ? (draftSource.method === 'drop' ? 'drop' : draftSource.method === 'clipboard-read' ? 'clipboard' : draftSource.method === 'paste' ? 'paste' : '')
              : ''} as:
          {uiComplexityMode === 'extra' && (
            <Chip component='span' size='sm' color='neutral' variant='outlined' startDecorator={<ContentCopyIcon />} onClick={(event) => handleCopyLabelToClipboard(event, draft.label)} sx={{ ml: 'auto' }}>
              copy name
            </Chip>
          )}
        </ListItem>
      )}
      {!isUnconvertible && draft.converters.map((c, idx) =>
        <MenuItem
          disabled={c.disabled || isConverting}
          key={'c-' + c.id}
          onClick={async () => (c.isCheckbox || !c.isActive) && await handleSetConverterIdx(idx)}
        >
          <ListItemDecorator>
            {(isConverting && c.isActive)
              ? <CircularProgress size='sm' sx={{ '--CircularProgress-size': '1.25rem' }} />
              : !c.isCheckbox
                ? <Radio key={'rd-' + idx} checked={c.isActive} disabled={isConverting} />
                : <Checkbox key={'cb-' + idx} checked={c.isActive === true} disabled={isConverting} />
            }
          </ListItemDecorator>
          {c.unsupported
            ? <Box>Unsupported 🤔 <Typography level='body-xs'>{c.name}</Typography></Box>
            : c.name}
        </MenuItem>,
      )}
      {/*{!isUnconvertible && <ListDivider sx={{ mb: 0 }} />}*/}

      {/* Progress indicator (mainly for OCRs of Images, PDFs, and PDF to Images) */}
      {!!draft.outputsConversionProgress && draft.outputsConversionProgress < 1 && (
        <LinearProgress determinate value={100 * draft.outputsConversionProgress} sx={{ mx: 1 }} />
      )}

      {SHOW_INLINING_OPERATIONS && !!onDraftAction && <ListDivider />}
      {SHOW_INLINING_OPERATIONS && !!onDraftAction && (
        <MenuItem onClick={() => onDraftAction?.(draftId, 'inline-text')} disabled={!llmSupportsTextFragments || isConverting}>
          <ListItemDecorator><VerticalAlignBottomIcon /></ListItemDecorator>
          Inline text
        </MenuItem>
      )}
      {SHOW_INLINING_OPERATIONS && !!onDraftAction && (
        <MenuItem onClick={() => onDraftAction?.(draftId, 'copy-text')} disabled={!llmSupportsTextFragments || isConverting}>
          <ListItemDecorator><ContentCopyIcon /></ListItemDecorator>
          Copy text
        </MenuItem>
      )}

      {/* Warning box */}
      {(isInputError || showWarning) && (
        <Box>
          <MenuItem
            variant='soft'
            color={isInputError ? 'danger' : 'warning'}
            sx={{
              mt: !isInputError ? 0.75 : 0,
              mb: !isInputError ? 0 : 0.75,
              border: '1px solid',
              borderLeft: 'none',
              borderRight: 'none',
              borderColor: 'divider',
              fontSize: 'sm',
              py: 1,
            }}
          >
            <ListItemDecorator>
              {/*<WarningRoundedIcon />*/}
            </ListItemDecorator>
            <Box>
              <Typography color={isInputError ? 'danger' : 'warning'} level='title-sm'>
                {isInputError ? 'Loading Issue' : 'Warning'}
              </Typography>
              {isInputError ? <div>{draft.inputError}</div>
                : isUnconvertible ? <div>Attachments of type {draft.input?.mimeType} are not supported yet. You can request this on GitHub.</div>
                  : isOutputMissing ? <div>File not supported. Please try another format.</div>
                    : !llmSupportsAllFragments ? <div>May not be compatible with the current model. Please try another format.</div>
                      : <>Unknown warning</>}
            </Box>
          </MenuItem>
        </Box>
      )}

      {/* Details Expandable Menu */}
      {!isInputError && <MenuItem
        variant='soft'
        color={isOutputMissing ? 'warning' : 'success'}
        disabled={!canHaveDetails}
        onClick={handleToggleShowDetails}
        sx={{
          mt: (isInputError || showWarning) ? 0 : 0.75,
          mb: 0.75,
          border: '1px solid',
          borderLeft: 'none',
          borderRight: 'none',
          borderColor: 'divider',
        }}
      >
        <ListItemDecorator>
          {(showDetails && canHaveDetails) ? <ExpandLessIcon /> : <ExpandMoreIcon />}
        </ListItemDecorator>
        {!(showDetails && canHaveDetails) ? (
          <Typography sx={{ fontSize: 'sm' }}>
            Details
          </Typography>
        ) : (
          <Box sx={{ my: 0.5 }}>

            {/* <- inputs */}
            {showInputs && !!draftInput && (
              <Typography level='body-sm' textColor='text.primary' startDecorator={<AttachmentIcon sx={indicatorSx} />}>
                {draftInput.mimeType}{typeof draftInput.dataSize === 'number' ? ` · ${draftInput.dataSize.toLocaleString()} bytes` : ''}
              </Typography>
            )}
            {showInputs && !!draftInput?.altMimeType && (
              <Typography level='body-sm' sx={indicatorGapSx}>
                {draftInput.altMimeType} · {draftInput.altData?.length.toLocaleString()}
              </Typography>
            )}
            {showInputs && !!draftInput?.urlImage && (
              <Typography level='body-sm' sx={indicatorGapSx}>
                {draftInput.urlImage.mimeType} · {draftInput.urlImage.width} x {draftInput.urlImage.height} · {draftInput.urlImage.imgDataUrl?.length.toLocaleString()}
                {' · '}
                <Chip component='span' size='sm' color='primary' variant='outlined' startDecorator={<VisibilityIcon />} onClick={(event) => {
                  if (draftInput?.urlImage?.imgDataUrl) {
                    // Invoke the viewer but with a virtual 'temp' part description to see this preview image
                    handleViewImageRefPart(event, {
                      pt: 'image_ref',
                      dataRef: {
                        reftype: 'url',
                        url: draftInput.urlImage.imgDataUrl,
                      },
                      altText: draft.label || 'URL Image Preview',
                      width: draftInput.urlImage.width || undefined,
                      height: draftInput.urlImage.height || undefined,
                    });
                  }
                }}>
                  view
                </Chip>
              </Typography>
            )}

            {/*<Typography level='body-sm'>*/}
            {/*  Converters: {draft.converters.map(((converter, idx) => ` ${converter.id}${converter.isActive ? '*' : ''}`)).join(', ')}*/}
            {/*</Typography>*/}

            {/* -> Outputs */}
            <Box sx={{ mt: 1 }}>
              {isOutputMissing ? (
                <Typography level='body-sm' startDecorator={<ReadMoreIcon sx={indicatorSx} />}>...</Typography>
              ) : (
                draft.outputFragments.map(({ part }, index) => {
                  if (isDocPart(part)) {
                    return (
                      <Typography key={index} level='body-sm' sx={{ color: 'text.primary' }} startDecorator={<ReadMoreIcon sx={indicatorSx} />}>
                        <span>{part.data.mimeType /* part.type: big-agi type, not source mime */} · {part.data.text.length.toLocaleString()} bytes ·&nbsp;</span>
                        <Chip component='span' size='sm' color='primary' variant='outlined' startDecorator={<VisibilityIcon />} onClick={(event) => handleViewDocPart(event, part)}>
                          view
                        </Chip>
                        <Chip component='span' size='sm' color='success' variant='outlined' startDecorator={<ContentCopyIcon />} onClick={(event) => handleCopyToClipboard(event, part.data.text)}>
                          copy
                        </Chip>
                      </Typography>
                    );
                  } else if (isImageRefPart(part)) {
                    const resolution = part.width && part.height ? `${part.width} x ${part.height}` : 'no resolution';
                    const mime = part.dataRef.reftype === 'dblob' ? part.dataRef.mimeType : 'unknown image';
                    return (
                      <Typography key={index} level='body-sm' sx={{ color: 'text.primary' }} startDecorator={<ReadMoreIcon sx={indicatorSx} />}>
                        <span>{mime /*.replace('image/', 'img: ')*/} · {resolution} · {part.dataRef.reftype === 'dblob' ? (part.dataRef.bytesSize?.toLocaleString() || 'no size') : '(remote)'} ·&nbsp;</span>
                        <Chip component='span' size={isOutputMultiple ? 'sm' : 'md'} color='primary' variant='outlined' startDecorator={<VisibilityIcon />} onClick={(event) => handleViewImageRefPart(event, part)}>
                          view
                        </Chip>
                        {isOutputMultiple && <Chip component='span' size={isOutputMultiple ? 'sm' : 'md'} color='danger' variant='outlined' startDecorator={<DeleteForeverIcon />} onClick={(event) => handleDeleteOutputFragment(event, index)}>
                          del
                        </Chip>}
                      </Typography>
                    );
                  } else {
                    return (
                      <Typography key={index} level='body-sm' sx={{ color: 'text.primary' }} startDecorator={<ReadMoreIcon sx={indicatorSx} />}>
                        {(part as DMessageAttachmentFragment['part']).pt}: (other)
                      </Typography>
                    );
                  }
                })
              )}
              {!!llmTokenCountApprox && (
                <Typography level='body-xs' mt={0.5} sx={indicatorGapSx}>
                  ~{llmTokenCountApprox.toLocaleString()} tokens
                </Typography>
              )}
            </Box>

            {/* LiveFile notice */}
            {hasLiveFiles && !!draftInput && (
              <Typography level='body-xs' color='success' mt={1} startDecorator={<LiveFileIcon sx={{ width: 16, height: 16 }} />}>
                LiveFile is supported
              </Typography>
            )}

          </Box>
        )}
      </MenuItem>}

      {/* Remove */}
      <MenuItem onClick={handleRemove}>
        <ListItemDecorator><ClearIcon /></ListItemDecorator>
        Remove
      </MenuItem>

    </CloseablePopup>
  );
}



================================================
FILE: src/apps/chat/components/composer/llmattachments/LLMAttachmentsList.tsx
================================================
import * as React from 'react';

import { Box, CircularProgress, IconButton, ListDivider, ListItemDecorator, MenuItem } from '@mui/joy';
import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';
import ClearIcon from '@mui/icons-material/Clear';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import ExpandLessIcon from '@mui/icons-material/ExpandLess';
import VerticalAlignBottomIcon from '@mui/icons-material/VerticalAlignBottom';

import type { AgiAttachmentPromptsData } from '~/modules/aifn/agiattachmentprompts/useAgiAttachmentPrompts';

import { CloseablePopup } from '~/common/components/CloseablePopup';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';

import type { AttachmentDraftId } from '~/common/attachment-drafts/attachment.types';
import type { AttachmentDraftsStoreApi } from '~/common/attachment-drafts/store-attachment-drafts_slice';
import type { DMessageDocPart, DMessageImageRefPart } from '~/common/stores/chat/chat.fragments';

import { ViewImageRefPartModal } from '../../message/fragments-content/ViewImageRefPartModal';

import type { LLMAttachmentDraft } from './useLLMAttachmentDrafts';
import { LLMAttachmentButtonMemo } from './LLMAttachmentButton';
import { LLMAttachmentMenu } from './LLMAttachmentMenu';
import { LLMAttachmentsPromptsButtonMemo } from './LLMAttachmentsPromptsButton';
import { ViewDocPartModal } from '../../message/fragments-content/ViewDocPartModal';


export type LLMAttachmentDraftsAction = 'inline-text' | 'copy-text';


const _style = {

  bar: {
    position: 'relative',
  } as const,

  barScrollX: {
    height: '100%',
    pr: 5,
    overflowX: 'auto',
    display: 'flex',
    alignItems: 'center',
    gap: 1,
  } as const,

  barWraps: {
    display: 'flex',
    flexWrap: 'wrap',
    alignItems: 'center',
    gap: 1,
  } as const,

  barMenuButton: {
    // borderRadius: 'sm',
    borderRadius: 0,
    position: 'absolute', right: 0, top: 0,
    backgroundColor: 'neutral.softDisabledBg',
  } as const,

} as const;


/**
 * Renderer of attachment drafts, with menus, etc.
 */
export function LLMAttachmentsList(props: {
  agiAttachmentPrompts?: AgiAttachmentPromptsData,
  attachmentDraftsStoreApi: AttachmentDraftsStoreApi,
  canInlineSomeFragments: boolean,
  llmAttachmentDrafts: LLMAttachmentDraft[],
  onAttachmentDraftsAction?: (attachmentDraftId: AttachmentDraftId | null, actionId: LLMAttachmentDraftsAction) => void,
  buttonsCanWrap?: boolean,
}) {

  // state
  const { showPromisedOverlay } = useOverlayComponents();
  const [draftMenu, setDraftMenu] = React.useState<{ anchor: HTMLAnchorElement, attachmentDraftId: AttachmentDraftId } | null>(null);
  const [overallMenuAnchor, setOverallMenuAnchor] = React.useState<HTMLAnchorElement | null>(null);
  const [viewerDocPart, setViewerDocPart] = React.useState<DMessageDocPart | null>(null);
  const [viewerImageRefPart, setViewerImageRefPart] = React.useState<DMessageImageRefPart | null>(null);

  // derived state

  const { agiAttachmentPrompts, canInlineSomeFragments, llmAttachmentDrafts } = props;
  const hasAttachments = llmAttachmentDrafts.length >= 1;

  // derived item menu state

  const itemMenuAnchor = draftMenu?.anchor;
  const itemMenuAttachmentDraftId = draftMenu?.attachmentDraftId;
  const itemMenuAttachmentDraft = itemMenuAttachmentDraftId ? llmAttachmentDrafts.find(la => la.attachmentDraft.id === draftMenu.attachmentDraftId) : undefined;
  const itemMenuIndex = itemMenuAttachmentDraft ? llmAttachmentDrafts.indexOf(itemMenuAttachmentDraft) : -1;


  // overall menu

  const { onAttachmentDraftsAction } = props;

  const handleOverallMenuHide = React.useCallback(() => setOverallMenuAnchor(null), []);

  const handleOverallMenuToggle = React.useCallback((event: React.MouseEvent<HTMLAnchorElement>) => {
    event.shiftKey && console.log('llmAttachmentDrafts', llmAttachmentDrafts);
    event.preventDefault(); // added for the Right mouse click (to prevent the menu)
    setOverallMenuAnchor(anchor => anchor ? null : event.currentTarget);
  }, [llmAttachmentDrafts]);

  const handleOverallCopyText = React.useCallback(() => {
    handleOverallMenuHide();
    onAttachmentDraftsAction?.(null, 'copy-text');
  }, [handleOverallMenuHide, onAttachmentDraftsAction]);

  const handleOverallInlineText = React.useCallback(() => {
    handleOverallMenuHide();
    onAttachmentDraftsAction?.(null, 'inline-text');
  }, [handleOverallMenuHide, onAttachmentDraftsAction]);

  const handleOverallClear = React.useCallback(async () => {
    if (await showPromisedOverlay('chat-attachments-clear', { rejectWithValue: false }, ({ onResolve, onUserReject }) =>
      <ConfirmationModal
        open onClose={onUserReject} onPositive={() => onResolve(true)}
        title='Confirm Removal'
        positiveActionText='Remove All'
        confirmationText={`This action will remove all (${llmAttachmentDrafts.length}) attachments. Do you want to proceed?`}
      />,
    )) {
      handleOverallMenuHide();
      props.attachmentDraftsStoreApi.getState().removeAllAttachmentDrafts();
    }
  }, [handleOverallMenuHide, llmAttachmentDrafts.length, props.attachmentDraftsStoreApi, showPromisedOverlay]);


  // item menu

  const handleDraftMenuHide = React.useCallback(() => setDraftMenu(null), []);

  const handleDraftMenuToggle = React.useCallback((attachmentDraftId: AttachmentDraftId, anchor: HTMLAnchorElement) => {
    handleOverallMenuHide();
    setDraftMenu(prev => prev?.attachmentDraftId === attachmentDraftId ? null : { anchor, attachmentDraftId });
  }, [handleOverallMenuHide]);

  const handleDraftAction = React.useCallback((attachmentDraftId: AttachmentDraftId, actionId: LLMAttachmentDraftsAction) => {
    // pass-through, but close the menu as well, as the action is destructive for the caller
    handleDraftMenuHide();
    onAttachmentDraftsAction?.(attachmentDraftId, actionId);
  }, [handleDraftMenuHide, onAttachmentDraftsAction]);

  const handleViewImageRefPart = React.useCallback((imageRefPart: DMessageImageRefPart) => {
    setViewerImageRefPart(imageRefPart);
  }, []);

  const handleCloseImageViewer = React.useCallback(() => {
    setViewerImageRefPart(null);
  }, []);

  const handleViewDocPart = React.useCallback((docPart: DMessageDocPart) => {
    setViewerDocPart(docPart);
  }, []);

  const handleCloseDocPartViewer = React.useCallback(() => {
    setViewerDocPart(null);
  }, []);


  // no components without attachments
  if (!hasAttachments)
    return null;

  return <>

    {/* Attachment Drafts bar */}
    <Box sx={_style.bar}>

      {/* Horizontally scrollable */}
      <Box sx={!props.buttonsCanWrap ? _style.barScrollX : _style.barWraps}>

        {/* AI Suggestion Button */}
        {(!!agiAttachmentPrompts && (agiAttachmentPrompts.isVisible || agiAttachmentPrompts.hasData)) && (
          <LLMAttachmentsPromptsButtonMemo data={agiAttachmentPrompts} />
        )}

        {/* Attachment Buttons */}
        {llmAttachmentDrafts.map((llmAttachment) =>
          <LLMAttachmentButtonMemo
            key={llmAttachment.attachmentDraft.id}
            llmAttachment={llmAttachment}
            menuShown={llmAttachment.attachmentDraft.id === itemMenuAttachmentDraftId}
            onToggleMenu={handleDraftMenuToggle}
            onViewImageRefPart={handleViewImageRefPart}
          />,
        )}

      </Box>

      {/* Overall Menu button */}
      {!props.buttonsCanWrap && (
        <IconButton
          onClick={handleOverallMenuToggle}
          onContextMenu={handleOverallMenuToggle}
          sx={_style.barMenuButton}
        >
          <ExpandLessIcon />
        </IconButton>
      )}

    </Box>


    {/* Image Viewer Modal - when opening attachment images */}
    {!!viewerImageRefPart && (
      <ViewImageRefPartModal imageRefPart={viewerImageRefPart} onClose={handleCloseImageViewer} />
    )}

    {/* Text Viewer Modal */}
    {!!viewerDocPart && (
      <ViewDocPartModal docPart={viewerDocPart} onClose={handleCloseDocPartViewer} />
    )}


    {/* Single LLM Attachment Draft Menu */}
    {!!itemMenuAnchor && !!itemMenuAttachmentDraft && !!props.attachmentDraftsStoreApi && (
      <LLMAttachmentMenu
        attachmentDraftsStoreApi={props.attachmentDraftsStoreApi}
        llmAttachmentDraft={itemMenuAttachmentDraft}
        menuAnchor={itemMenuAnchor}
        isPositionFirst={itemMenuIndex === 0}
        isPositionLast={itemMenuIndex === llmAttachmentDrafts.length - 1}
        onClose={handleDraftMenuHide}
        onDraftAction={!onAttachmentDraftsAction ? undefined : handleDraftAction}
        onViewDocPart={handleViewDocPart}
        onViewImageRefPart={handleViewImageRefPart}
      />
    )}


    {/* All Drafts Menu */}
    {!!overallMenuAnchor && (
      <CloseablePopup
        menu anchorEl={overallMenuAnchor} onClose={handleOverallMenuHide}
        dense
        minWidth={200}
        placement='top-start'
      >
        {/* uses the agiAttachmentPrompts to imagine what the user will ask aboud those */}
        {!!agiAttachmentPrompts && (
          <MenuItem color='primary' variant='soft' onClick={agiAttachmentPrompts.refetch} disabled={!hasAttachments || agiAttachmentPrompts.isFetching}>
            <ListItemDecorator>{agiAttachmentPrompts.isFetching ? <CircularProgress size='sm' /> : <AutoFixHighIcon />}</ListItemDecorator>
            What can I do?
          </MenuItem>
        )}
        {!!agiAttachmentPrompts && <ListDivider />}

        {!!onAttachmentDraftsAction && <MenuItem onClick={handleOverallInlineText} disabled={!canInlineSomeFragments}>
          <ListItemDecorator><VerticalAlignBottomIcon /></ListItemDecorator>
          Inline all text
        </MenuItem>}
        {!!onAttachmentDraftsAction && <MenuItem onClick={handleOverallCopyText} disabled={!canInlineSomeFragments}>
          <ListItemDecorator><ContentCopyIcon /></ListItemDecorator>
          Copy all text
        </MenuItem>}
        {!!onAttachmentDraftsAction && <ListDivider />}

        <MenuItem onClick={handleOverallClear}>
          <ListItemDecorator><ClearIcon /></ListItemDecorator>
          Remove All{llmAttachmentDrafts.length > 5 ? <span style={{ opacity: 0.5 }}> {llmAttachmentDrafts.length} attachments</span> : null}
        </MenuItem>
      </CloseablePopup>
    )}

  </>;
}


================================================
FILE: src/apps/chat/components/composer/llmattachments/LLMAttachmentsPromptsButton.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, CircularProgress, IconButton } from '@mui/joy';
import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';

import type { AgiAttachmentPromptsData } from '~/modules/aifn/agiattachmentprompts/useAgiAttachmentPrompts';

import { BigAgiSquircleIcon } from '~/common/components/icons/big-agi/BigAgiSquircleIcon';
import { GoodTooltip } from '~/common/components/GoodTooltip';

import { AGI_SUGGESTIONS_COLOR } from '../textarea/ComposerTextAreaActions';


export const LLMAttachmentsPromptsButtonMemo = React.memo(LLMAttachmentsPromptsButton);


const promptGenIconButtonSx: SxProps = {
  // minWidth: 40,
  backgroundColor: 'background.level1',
  boxShadow: `inset 0 4px 6px -4px rgb(var(--joy-palette-${AGI_SUGGESTIONS_COLOR}-darkChannel) / 40%)`,
  borderRadius: '2rem',
  borderBottomLeftRadius: 0,
  // borderColor: `${AGI_SUGGESTIONS_COLOR}.outlinedBorder`,
  // '&:hover': {
  //   backgroundColor: 'background.level1',
  // },
  '&:hover': {
    backgroundColor: `${AGI_SUGGESTIONS_COLOR}.solidBg`,
    borderColor: `${AGI_SUGGESTIONS_COLOR}.solidBg`,
    color: `${AGI_SUGGESTIONS_COLOR}.solidColor`,
  },
};

const brightenSx: SxProps = {
  ...promptGenIconButtonSx,
  backgroundColor: 'background.popup',
  boxShadow: 'xs',
};

function LLMAttachmentsPromptsButton({ data }: { data: AgiAttachmentPromptsData }) {

  const tooltipTitle =
    data.error ? (data.error.message || 'Error guessing actions')
      : data.isFetching ? null
        : data.isPending ? <Box sx={{ display: 'flex', gap: 1 }}><BigAgiSquircleIcon inverted sx={{ color: 'white', borderRadius: '1rem' }} /> What can I do?</Box>
          : 'Give me more ideas';

  const button = (
    <IconButton
      variant={data.error ? 'soft' : data.hasData ? 'outlined' : 'soft'}
      color={data.error ? 'danger' : data.hasData ? AGI_SUGGESTIONS_COLOR : AGI_SUGGESTIONS_COLOR}
      size='sm'
      disabled={data.isFetching}
      onClick={data.refetch}
      // onClick={data.hasData ? data.clear : data.refetch}
      sx={(data.hasData && !data.isFetching) ? brightenSx : promptGenIconButtonSx}
    >
      {data.isFetching ? (
        <CircularProgress size='sm' color='neutral' />
      ) : (
        <AutoFixHighIcon fontSize='small' />
      )}
    </IconButton>
  );

  return !tooltipTitle ? button : (
    <GoodTooltip variantOutlined arrow title={tooltipTitle}>
      {button}
    </GoodTooltip>
  );
}


================================================
FILE: src/apps/chat/components/composer/llmattachments/useLLMAttachmentDrafts.ts
================================================
import * as React from 'react';

import type { AttachmentDraft } from '~/common/attachment-drafts/attachment.types';
import type { DLLM } from '~/common/stores/llms/llms.types';
import type { DMessageAttachmentFragment } from '~/common/stores/chat/chat.fragments';
import { estimateTokensForFragments } from '~/common/stores/chat/chat.tokens';


export interface LLMAttachmentDraftsCollection {
  llmAttachmentDrafts: LLMAttachmentDraft[];
  canAttachAllFragments: boolean;
  canInlineSomeFragments: boolean;
  llmTokenCountApprox: number | null;
}


export interface LLMAttachmentDraft {
  attachmentDraft: AttachmentDraft;
  llmSupportsAllFragments: boolean;
  llmSupportsTextFragments: boolean;
  llmTokenCountApprox: number | null;
}


export function useLLMAttachmentDrafts(attachmentDrafts: AttachmentDraft[], chatLLM: DLLM | null, chatLLMSupportsImages: boolean): LLMAttachmentDraftsCollection {

  /* [Optimization] Use a Ref to store the previous state of llmAttachmentDrafts and chatLLM
   *
   * Note that this works on 2 levels:
   * - 1. avoids recomputation, but more importantly,
   * - 2. avoids re-rendering by keeping those llmAttachmentDrafts objects stable.
   *
   * Important to notice that the attachmentDraft objects[] are stable to start with, so we can
   * safely use reference equality to check if internal properties (or order) have changed.
   */
  const prevStateRef = React.useRef<{
    chatLLM: DLLM | null;
    llmAttachmentDrafts: LLMAttachmentDraft[];
  }>({ llmAttachmentDrafts: [], chatLLM: null });

  return React.useMemo(() => {

    // [Optimization]
    const equalChatLLM = chatLLM === prevStateRef.current.chatLLM;

    // LLM-dependent multi-modal enablement
    // TODO: consider also Audio inputs, maybe PDF binary inputs
    const supportedTypes: DMessageAttachmentFragment['part']['pt'][] = chatLLMSupportsImages ? ['image_ref', 'doc'] : ['doc'];
    const supportedTextTypes: DMessageAttachmentFragment['part']['pt'][] = supportedTypes.filter(pt => pt === 'doc');

    // Add LLM-specific properties to each attachment draft
    const llmAttachmentDrafts = attachmentDrafts.map((a, index) => {

      // [Optimization] If not change in LLM and the attachmentDraft is the same object reference, reuse the previous LLMAttachmentDraft
      let prevDraft: LLMAttachmentDraft | undefined = prevStateRef.current.llmAttachmentDrafts[index];
      // if not found, search by id
      if (!prevDraft)
        prevDraft = prevStateRef.current.llmAttachmentDrafts.find(_pd => _pd.attachmentDraft.id === a.id);
      if (equalChatLLM && prevDraft && prevDraft.attachmentDraft === a)
        return prevDraft;

      // Otherwise, create a new LLMAttachmentDraft
      return {
        attachmentDraft: a,
        llmSupportsAllFragments: !a.outputFragments ? false : a.outputFragments.every(op => supportedTypes.includes(op.part.pt)),
        llmSupportsTextFragments: !a.outputFragments ? false : a.outputFragments.some(op => supportedTextTypes.includes(op.part.pt)),
        llmTokenCountApprox: chatLLM
          ? estimateTokensForFragments(chatLLM, 'user', a.outputFragments, true, 'useLLMAttachmentDrafts')
          : null,
      };
    });

    // Calculate the overall properties
    const canAttachAllFragments = llmAttachmentDrafts.every(a => a.llmSupportsAllFragments);
    const canInlineSomeFragments = llmAttachmentDrafts.some(a => a.llmSupportsTextFragments);
    const llmTokenCountApprox = chatLLM
      ? llmAttachmentDrafts.reduce((acc, a) => acc + (a.llmTokenCountApprox || 0), 0)
      : null;

    // [Optimization] Update the ref with the new state
    prevStateRef.current = { llmAttachmentDrafts, chatLLM };

    return {
      llmAttachmentDrafts,
      canAttachAllFragments,
      canInlineSomeFragments,
      llmTokenCountApprox,
    };

  }, [attachmentDrafts, chatLLM, chatLLMSupportsImages]); // Dependencies for the outer useMemo
}



================================================
FILE: src/apps/chat/components/composer/textarea/AttachmentsPromptsButton.tsx
================================================
// import * as React from 'react';
//
// import type { SxProps } from '@mui/joy/styles/types';
// import { Alert, Box, Button, CircularProgress } from '@mui/joy';
// import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';
//
// import type { AgiAttachmentPromptsData } from '~/modules/aifn/attachmentprompts/useAgiAttachmentPrompts';
//
//
// const promptsButtonSx: SxProps = { display: 'flex', gap: 1, mb: 0.5 };
//
// export function AttachmentsPromptsButton({ data }: { data: AgiAttachmentPromptsData }) {
//   return (
//     <Box sx={promptsButtonSx}>
//
//       <Button
//         variant='outlined'
//         color='primary'
//         disabled={data.isFetching}
//         endDecorator={
//           data.isFetching ? <CircularProgress color='neutral' sx={{ '--CircularProgress-size': '16px' }} />
//             : <AutoFixHighIcon sx={{ fontSize: '20px' }} />
//         }
//         onClick={data.refetch}
//         sx={{
//           px: 3,
//           backgroundColor: 'background.surface',
//           boxShadow: '0 4px 6px -4px rgb(var(--joy-palette-primary-darkChannel) / 40%)',
//           borderRadius: 'sm',
//         }}
//       >
//         {data.isFetching ? 'Guessing what to do...' : data.isPending ? 'Guess what to do' : 'What else could we do'}
//       </Button>
//
//       {!!data.error && (
//         <Alert variant='soft' color='danger'>
//           {data.error.message || 'Error guessing actions'}
//         </Alert>
//       )}
//
//     </Box>
//   );
// }


================================================
FILE: src/apps/chat/components/composer/textarea/ComposerTextAreaActions.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ColorPaletteProp } from '@mui/joy';

import type { AgiAttachmentPromptsData } from '~/modules/aifn/agiattachmentprompts/useAgiAttachmentPrompts';

import type { DMetaReferenceItem } from '~/common/stores/chat/chat.message';

import { InReferenceToBubble } from '../../message/in-reference-to/InReferenceToBubble';


// configuration
export const AGI_SUGGESTIONS_COLOR: ColorPaletteProp = 'success';

// Styles

export const composerTextAreaSx: SxProps = {
  flex: 1,

  // layout
  display: 'grid',
  justifyItems: 'start',
  gap: 0.5,
  mb: 0.625,

  // Buttons
  [`& button`]: {
    '--Button-gap': '1.2rem',
    transition: 'background-color 0.2s, color 0.2s',
    // minWidth: 160,
  } as const,
} as const;


const promptButtonSx: SxProps = {
  minHeight: '2rem',
  placeSelf: 'start',

  color: `${AGI_SUGGESTIONS_COLOR}.softActiveColor`,
  backgroundColor: 'background.surface',
  border: '1px solid',
  borderColor: `${AGI_SUGGESTIONS_COLOR}.outlinedBorder`,
  borderRadius: '1rem',
  borderBottomLeftRadius: 0,
  boxShadow: 'xs',
  pl: 1.5,
  pr: 2,
  py: 0.5,
  fontSize: 'sm',
  fontWeight: 'normal',
  cursor: 'pointer',
  transition: 'none',
  textAlign: 'start',
  // whiteSpace: 'balance',
  '&:hover': {
    backgroundColor: `${AGI_SUGGESTIONS_COLOR}.solidBg`,
    borderColor: `${AGI_SUGGESTIONS_COLOR}.solidBg`,
    color: `${AGI_SUGGESTIONS_COLOR}.solidColor`,
    transition: 'none',
  },
};


export function ComposerTextAreaActions(props: {
  agiAttachmentPrompts: AgiAttachmentPromptsData,
  inReferenceTo?: DMetaReferenceItem[] | null
  onAppendAndSend: (appendText: string) => Promise<void>,
  onRemoveReferenceTo: (item: DMetaReferenceItem) => void,
}) {

  // skip the component if there's nothing to show
  const { agiAttachmentPrompts } = props;
  if (!props.inReferenceTo?.length && !agiAttachmentPrompts.prompts?.length /*&& !props.agiAttachmentPrompts.isVisible*/)
    return null;

  return (
    <Box sx={composerTextAreaSx}>

      {/* In-Reference-To bubbles */}
      {props.inReferenceTo?.map((item, index) => (
        <InReferenceToBubble
          key={index}
          item={item}
          onRemove={props.onRemoveReferenceTo}
          className='within-composer-focus'
        />
      ))}

      {/* Auto-Prompts from attachments */}
      {agiAttachmentPrompts.prompts.map((candidate, index) =>
        <Button
          key={index}
          color={AGI_SUGGESTIONS_COLOR}
          variant='plain'
          onClick={() => props.onAppendAndSend(candidate)}
          // disabled as otherwise it gets white when hovering and the composer has focus
          // className='within-composer-focus'
          sx={promptButtonSx}
        >
          {candidate}
        </Button>,
      )}

      {/* Guess Action Button */}
      {/*{(agiAttachmentPrompts.isVisible || agiAttachmentPrompts.hasData) && (*/}
      {/*  <AttachmentsPromptsButton data={props.agiAttachmentPrompts} />*/}
      {/*)}*/}

    </Box>
  );
}



================================================
FILE: src/apps/chat/components/composer/textarea/ComposerTextAreaDrawActions.tsx
================================================
import * as React from 'react';

import { Box, Button } from '@mui/joy';
import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';

import { composerTextAreaSx } from './ComposerTextAreaActions';
import { imaginePromptFromTextOrThrow } from '~/modules/aifn/imagine/imaginePromptFromText';


const _style = {
  enhance: {
    minWidth: 170,
    mx: 0.625,
    pr: 2,
    border: '1px solid',
    borderColor: 'warning.outlinedBorder',
    boxShadow: '0px 4px 4px -4px rgb(var(--joy-palette-warning-darkChannel) / 20%)',
    transition: 'background-color 0.14s',
    justifyContent: 'space-between',
  } as const,
  gone: {
    visibility: 'hidden',
  } as const,
} as const;

export function ComposerTextAreaDrawActions(props: {
  composerText: string,
  onReplaceText: (text: string) => void,
}) {

  // state
  const [isSimpleEnhancing, setIsSimpleEnhancing] = React.useState(false);


  // derived
  const trimmedPrompt = props.composerText.trim();
  const userHasText = trimmedPrompt.length >= 3;


  const { onReplaceText } = props;

  const handleSimpleEnhance = React.useCallback(async () => {
    if (!trimmedPrompt || isSimpleEnhancing) return;
    setIsSimpleEnhancing(true);
    const improvedPrompt = await imaginePromptFromTextOrThrow(trimmedPrompt, 'DEV')
      .catch(console.error);
    if (improvedPrompt)
      onReplaceText(improvedPrompt);
    setIsSimpleEnhancing(false);
  }, [isSimpleEnhancing, onReplaceText, trimmedPrompt]);


  return (
    <Box sx={composerTextAreaSx}>

      {/* Enhance button */}
      <Box sx={{ ml: 'auto' }}>
        <Button
          size='sm'
          variant={isSimpleEnhancing ? 'soft' : 'soft'}
          color='warning'
          disabled={!userHasText}
          loading={isSimpleEnhancing}
          loadingPosition='end'
          // className={promptButtonClass}
          endDecorator={<AutoFixHighIcon sx={{ fontSize: '20px' }} />}
          onClick={handleSimpleEnhance}
          sx={!userHasText ? _style.gone : _style.enhance}
        >
          {isSimpleEnhancing ? 'Enhancing...' : 'Enhance Prompt'}
        </Button>
      </Box>

    </Box>
  );
}



================================================
FILE: src/apps/chat/components/composer/tokens/TokenBadge.tsx
================================================
import * as React from 'react';

import { Badge } from '@mui/joy';

import type { DPricingChatGenerate } from '~/common/stores/llms/llms.pricing';
import { formatModelsCost } from '~/common/util/costUtils';

import { tokenCountsMathAndMessage, TokenTooltip } from './TokenTooltip';


/**
 * Simple little component to show the token count (and a tooltip on hover)
 */
export const TokenBadgeMemo = React.memo(TokenBadge);

function TokenBadge(props: {
  chatPricing?: DPricingChatGenerate,

  direct: number,
  history?: number,
  responseMax?: number,
  limit: number,

  enableHover?: boolean,
  hideBelowDollars?: number,
  showCost?: boolean
  showExcess?: boolean,
  absoluteBottomRight?: boolean,
  inline?: boolean,
}) {

  // state
  const [isHovering, setIsHovering] = React.useState(false);

  const { message, color, remainingTokens, costMax, costMin } =
    tokenCountsMathAndMessage(props.limit, props.direct, props.history, props.responseMax, props.chatPricing);


  // handlers
  const handleHoverEnter = React.useCallback(() => setIsHovering(true), []);

  const handleHoverLeave = React.useCallback(() => setIsHovering(false), []);


  let badgeValue: string;

  const showAltCosts = !!props.showCost && !!costMax && costMin !== undefined;
  if (showAltCosts) {
    // Note: switched to 'min cost (>= ...)' on mobile as well, to restore the former behavior, just uncomment the !props.enableHover (a proxy for isMobile)
    badgeValue = (/*!props.enableHover ||*/ isHovering)
      ? '< ' + formatModelsCost(costMax)
      : '> ' + formatModelsCost(costMin);
  } else {

    // show the direct tokens, unless we exceed the limit and 'showExcess' is enabled
    const value = (props.showExcess && (props.limit && remainingTokens <= 0))
      ? Math.abs(remainingTokens)
      : props.direct;

    badgeValue = value.toLocaleString();
  }

  const shallHide = !props.direct && remainingTokens >= 0 && !showAltCosts;
  if (shallHide) return null;

  // invisible will be revealed on mouse hover, it's a "weaker" hidden state
  const shallInvisible = showAltCosts && !!props.hideBelowDollars && typeof costMin === 'number' && costMin < props.hideBelowDollars;

  return (
    <TokenTooltip color={color} message={message} placement='top-end'>
      <Badge
        variant='soft' color={color} max={1000000}
        // invisible={shallHide}
        onMouseEnter={props.enableHover ? handleHoverEnter : undefined}
        onMouseLeave={props.enableHover ? handleHoverLeave : undefined}
        badgeContent={badgeValue}
        slotProps={{
          root: {
            sx: {
              ...((props.absoluteBottomRight) && { position: 'absolute', bottom: 8, right: 8 }),
              cursor: 'help',
              ...(shallInvisible && {
                opacity: 0,
                '&:hover': { opacity: 1 },
              }),
            },
          },
          badge: {
            sx: {
              // the badge (not the tooltip)
              // boxShadow: 'sm',
              fontFamily: 'code',
              fontSize: 'xs',
              ...((props.absoluteBottomRight || props.inline) && { position: 'static', transform: 'none' }),
            },
          },
        }}
      />
    </TokenTooltip>
  );
}


================================================
FILE: src/apps/chat/components/composer/tokens/TokenProgressbar.tsx
================================================
import * as React from 'react';

import { Box, useTheme } from '@mui/joy';

import type { DPricingChatGenerate } from '~/common/stores/llms/llms.pricing';

import { tokenCountsMathAndMessage, TokenTooltip } from './TokenTooltip';


/**
 * Progress bar, with curves to match the rounded-corners Textarea
 *
 * The Textarea contains it within the Composer (at least).
 */
export const TokenProgressbarMemo = React.memo(TokenProgressbar);

function TokenProgressbar(props: {
  chatPricing?: DPricingChatGenerate,

  direct: number,
  history: number,
  responseMax: number,
  limit: number,
}) {

  // external state
  const theme = useTheme();

  if (!(props.limit > 0) || (!props.direct && !props.history && !props.responseMax)) return null;

  // compute percentages
  let historyPct = 100 * props.history / props.limit;
  let responsePct = 100 * props.responseMax / props.limit;
  let directPct = 100 * props.direct / props.limit;
  const totalPct = historyPct + responsePct + directPct;
  const isOverflow = totalPct >= 100;

  if (isOverflow) {
    let scale = 100 / totalPct;
    scale *= scale; // make proportional space for the 'danger' (overflow) representation
    historyPct *= scale;
    responsePct *= scale;
    directPct *= scale;
  }

  // bar colors
  const historyColor = theme.palette.primary.softActiveBg;
  const directColor = theme.palette.primary.solidBg;
  const responseColor = theme.palette.neutral.softActiveBg;
  const overflowColor = theme.palette.danger.softColor;

  // tooltip message/color
  const { message, color } = tokenCountsMathAndMessage(props.limit, props.direct, props.history, props.responseMax, props.chatPricing);

  // sizes
  const containerHeight = 8;
  const height = isOverflow ? 8 : 4;

  return (

    <TokenTooltip color={color} message={props.direct ? null : message}>

      <Box sx={{
        position: 'absolute', left: 1, right: 1, bottom: 1, height: containerHeight,
        overflow: 'hidden', borderBottomLeftRadius: 5, borderBottomRightRadius: 5,
      }}>

        {/* History */}
        {historyPct > 0 && <Box sx={{
          background: historyColor,
          position: 'absolute', left: 0, bottom: 0, width: historyPct + '%', height,
        }} />}

        {/* Direct */}
        {directPct > 0 && <Box sx={{
          background: directColor,
          position: 'absolute', left: historyPct + '%', bottom: 0, width: directPct + '%', height,
        }} />}

        {/* Response */}
        {responsePct > 0 && <Box sx={{
          background: responseColor,
          position: 'absolute', left: (totalPct > 100 ? (historyPct + directPct) : (100 - responsePct)) + '%', bottom: 0, width: responsePct + '%', height,
        }} />}

        {/* Overflow */}
        {isOverflow && <Box sx={{
          background: overflowColor,
          position: 'absolute', left: (historyPct + directPct + responsePct) + '%', right: 0, bottom: 0, height,
        }} />}

      </Box>

    </TokenTooltip>
  );
}


================================================
FILE: src/apps/chat/components/composer/tokens/TokenTooltip.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, ColorPaletteProp, Tooltip } from '@mui/joy';

import { DPricingChatGenerate, getLlmCostForTokens } from '~/common/stores/llms/llms.pricing';
import { adjustContentScaling, themeScalingMap } from '~/common/app.theme';
import { formatModelsCost } from '~/common/util/costUtils';
import { useUIContentScaling } from '~/common/stores/store-ui';


export function tokenCountsMathAndMessage(tokenLimit: number | 0, directTokens: number, historyTokens?: number, responseMaxTokens?: number, chatPricing?: DPricingChatGenerate): {
  color: ColorPaletteProp,
  message: string,
  remainingTokens: number,
  costMax?: number,
  costMin?: number,
} {
  const usedInputTokens = directTokens + (historyTokens || 0);
  const usedMaxTokens = usedInputTokens + (responseMaxTokens || 0);
  const remainingTokens = tokenLimit - usedMaxTokens;
  const gteLimit = (remainingTokens <= 0 && tokenLimit > 0);

  // message
  let message: string = gteLimit ? '⚠️ ' : '';

  // costs
  let costMax: number | undefined = undefined;
  let costMin: number | undefined = undefined;

  // no limit: show used tokens only
  if (!tokenLimit) {
    message += `Requested: ${usedMaxTokens.toLocaleString()} tokens`;
  }
  // has full information (d + i < l)
  else if (historyTokens || responseMaxTokens) {
    message +=
      `▶ ${Math.abs(remainingTokens).toLocaleString()} ${remainingTokens >= 0 ? 'available' : 'excess'} message tokens\n\n` +
      ` = Model max tokens: ${_alignRight(tokenLimit)}\n` +
      `     - This message: ${_alignRight(directTokens)}\n` +
      `          - History: ${_alignRight(historyTokens || 0)}\n` +
      `     - Max response: ${_alignRight(responseMaxTokens || 0)}`;

    // add the price, if available
    if (chatPricing) {
      const inputPrice = getLlmCostForTokens(usedInputTokens, usedInputTokens, chatPricing.input);
      const outputPrice = getLlmCostForTokens(usedInputTokens, responseMaxTokens || 0, chatPricing.output);

      costMin = inputPrice;
      const costOutMax = outputPrice;

      if (costMin !== undefined || costOutMax !== undefined) {
        message += `\n\n\n▶ Chat Turn Cost (max, approximate)\n`;

        if (costMin !== undefined) {
          const inputPricePerM = costMin * 1e6 / usedInputTokens;
          message += '\n' +
            `       Input tokens: ${_alignRight(usedInputTokens)}\n` +
            `    Input Price $/M: ${inputPricePerM.toFixed(2).padStart(8)}\n` +
            `         Input cost: ${('$' + costMin.toFixed(4)).padStart(8)}\n`;
        }

        if (costOutMax !== undefined) {
          const outputPricePerM = costOutMax * 1e6 / (responseMaxTokens || 1);
          message += '\n' +
            `  Max output tokens: ${_alignRight(responseMaxTokens!)}\n` +
            `   Output Price $/M: ${outputPricePerM.toFixed(2).padStart(8)}\n` +
            `    Max output cost: ${('$' + costOutMax.toFixed(4)).padStart(8)}\n`;
        }

        if (costMin !== undefined) {
          message += '\n' +
            ` > Min message cost: <span class="highlight-cost yellow">${formatModelsCost(costMin).padStart(8)}</span>`;
        }

        costMax = (costMin !== undefined && costOutMax !== undefined) ? costMin + costOutMax : undefined;
        if (costMax !== undefined) {
          message += '\n' +
            ` < Max message cost: <span>${formatModelsCost(costMax).padStart(8)}</span>\n` +
            '   (depends on assistant response)';
        }

        // if (hack_lastMessageCosts)
        //   message += '\n\n  ' +
        //     `Last message cost: ${hack_lastMessageCosts}\n`;
      }
    }
  }
  // Cleaner mode: d + ? < R (total is the remaining in this case)
  else {
    message +=
      `${(tokenLimit + usedMaxTokens).toLocaleString()} available tokens after deleting this\n\n` +
      ` = Currently free: ${_alignRight(tokenLimit)}\n` +
      `   + This message: ${_alignRight(usedMaxTokens)}`;
  }

  const color: ColorPaletteProp =
    (tokenLimit && remainingTokens < 0)
      ? 'danger'
      : remainingTokens < tokenLimit / 4
        ? 'warning'
        : 'primary';

  return { color, message, remainingTokens, costMax, costMin };
}

function _alignRight(value: number, columnSize: number = 8) {
  const str = value.toLocaleString();
  return str.padStart(columnSize);
}

const tooltipMessageSx: SxProps = {
  p: 2,
  whiteSpace: 'pre',
  '& .highlight-cost': {
    position: 'relative',
    color: 'black',
    '&::before': {
      content: '""',
      position: 'absolute',
      left: '-2px',
      right: '-2px',
      top: '0.1em',
      bottom: '-0.1em',
      transform: 'skew(-5deg) rotate(-1deg)',
      zIndex: -1,
    },
    '&.yellow::before': {
      background: 'linear-gradient(104deg, rgba(255,255,132,0) 0.9%, rgba(255,255,132,1) 2.4%, rgba(255,252,132,1) 50%, rgba(255,255,132,1) 97.6%, rgba(255,255,132,0) 99.1%)',
    },
    '&.orange::before': {
      background: 'linear-gradient(104deg, rgba(255,204,132,0) 0.9%, rgba(255,204,132,1) 2.4%, rgba(255,187,132,1) 50%, rgba(255,204,132,1) 97.6%, rgba(255,204,132,0) 99.1%)',
    },
  },
};

export function TokenTooltip(props: { message: string | null, color: ColorPaletteProp, placement?: 'top' | 'top-end', children: React.ReactElement }) {

  // external state
  const contentScaling = useUIContentScaling();

  const fontSize = themeScalingMap[adjustContentScaling(contentScaling, -1)]?.blockFontSize ?? undefined;

  return (
    <Tooltip
      placement={props.placement}
      variant={props.color !== 'primary' ? 'solid' : 'soft'}
      color={props.color}
      title={!props.message ? null :
        <Box dangerouslySetInnerHTML={{ __html: props.message }} sx={tooltipMessageSx} />
      }
      sx={{
        fontFamily: 'code',
        fontSize: fontSize,
        // fontSize: '0.8125rem',
        border: '1px solid',
        borderColor: `${props.color}.outlinedColor`,
        boxShadow: 'md',
      }}
    >
      {props.children}
    </Tooltip>
  );
}



================================================
FILE: src/apps/chat/components/composer/tokens/useTextTokenCounter.tsx
================================================
import * as React from 'react';

import type { DLLM } from '~/common/stores/llms/llms.types';
import { estimateTextTokens } from '~/common/stores/chat/chat.tokens';


/**
 * Efficient hook that calculates token count for text with debouncing and deadline,
 * and only updates when the token count changes.
 *
 * @param text The text to count tokens for.
 * @param llm The LLM (includes the config) we perform the token count FOR.
 * @param debounceMs The minimum time between updates (keeps rolling at every change)
 * @param deadlineMs The maximum time between updates (fires even if the text is still changing)
 */
export function useTextTokenCount(
  text: string,
  llm: DLLM | null,
  debounceMs: number = 300,
  deadlineMs: number = 1200,
): number | undefined {

  // state: text ref to just read point value
  const lastTextRef = React.useRef<string>(undefined);

  // state
  const [tokenCount, setTokenCount] = React.useState<number | undefined>(undefined);
  const lastTokenCountRef = React.useRef<number | undefined>(undefined);

  const resetTokenCount = React.useCallback((value: number | undefined = 0) => {
    if (lastTokenCountRef.current === value) return;
    lastTokenCountRef.current = value;
    setTokenCount(value);
  }, []);


  // Timers: Debounced/Deadlined

  const debounceTimerRef = React.useRef<ReturnType<typeof setTimeout>>(undefined);
  const deadlineTimerRef = React.useRef<ReturnType<typeof setTimeout>>(undefined);

  const clearTimers = React.useCallback((clearDebounce: boolean = true, clearDeadline: boolean = true) => {
    if (clearDebounce && debounceTimerRef.current) {
      clearTimeout(debounceTimerRef.current);
      debounceTimerRef.current = undefined;
    }
    if (clearDeadline && deadlineTimerRef.current) {
      clearTimeout(deadlineTimerRef.current);
      deadlineTimerRef.current = undefined;
    }
  }, []);


  // tokens calculation, given the input text and LLM (which includes the LLM configuration)
  // NOTE: we shall extend this for fragments? (images, etc.)

  const calculateAndUpdateTextTokens = React.useCallback(() => {

    // no llm: can't count
    const currentText = lastTextRef.current;
    if (!llm || currentText === undefined) {
      resetTokenCount(undefined);
      return;
    }

    // [HEAVY] compute tokens
    const newTextTokens = !currentText ? 0
      : estimateTextTokens(currentText, llm, 'useTextTokenCount');

    // only update state if changed
    if (newTextTokens !== lastTokenCountRef.current) {
      lastTokenCountRef.current = newTextTokens;
      setTokenCount(newTextTokens);
    }

    // clear both timers since we're current now
    clearTimers(true, true);

  }, [clearTimers, llm, resetTokenCount]);


  // debounce mechanics

  React.useEffect(() => {

    // if there's no LLM, we can't do anything
    if (!llm || text === undefined) {
      resetTokenCount(undefined);
      return;
    }

    // update text reference for the calculation function
    lastTextRef.current = text;

    // restart the debounce timer
    clearTimers(true, false);
    debounceTimerRef.current = setTimeout(calculateAndUpdateTextTokens, debounceMs);

    // set a deadline timer if one isn't already running
    if (!deadlineTimerRef.current && deadlineMs > debounceMs)
      deadlineTimerRef.current = setTimeout(calculateAndUpdateTextTokens, deadlineMs);

  }, [calculateAndUpdateTextTokens, clearTimers, deadlineMs, debounceMs, llm, resetTokenCount, text]);

  // cleanup at unmount
  React.useEffect(() => () => clearTimers(true, true), [clearTimers]);

  return tokenCount;
}



================================================
FILE: src/apps/chat/components/layout-bar/ChatBarAltTitle.tsx
================================================
import * as React from 'react';

import { Box, Typography } from '@mui/joy';
import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';

import { autoConversationTitle } from '~/modules/aifn/autotitle/autoTitle';

import { DConversationId } from '~/common/stores/chat/chat.conversation';
import { capitalizeFirstLetter } from '~/common/util/textUtils';

import { CHAT_NOVEL_TITLE } from '../../AppChat';

import { FadeInButton } from '../layout-drawer/ChatDrawerItem';


export function ChatBarAltTitle(props: {
  conversationId: DConversationId | null,
  conversationTitle: string,
}) {

  // state
  const [isEditingTitle, setIsEditingTitle] = React.useState<boolean>(false);

  // derived state
  const { conversationId, conversationTitle } = props;
  const hasConversation = !!conversationId;


  const handleTitleEditAuto = React.useCallback(async () => {
    if (!conversationId) return;
    setIsEditingTitle(true);
    await autoConversationTitle(conversationId, true);
    setIsEditingTitle(false);
  }, [conversationId]);


  return (
    <Box sx={{ display: 'flex', gap: { xs: 1, md: 3 }, alignItems: 'center' }}>

      <Typography>
        {capitalizeFirstLetter(conversationTitle?.trim() || CHAT_NOVEL_TITLE)}
      </Typography>

      {hasConversation && (
        <FadeInButton size='sm' disabled={isEditingTitle} onClick={handleTitleEditAuto}>
          <AutoFixHighIcon />
        </FadeInButton>
      )}

    </Box>
  );
}



================================================
FILE: src/apps/chat/components/layout-bar/ChatBarBeam.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Box, IconButton, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';

import { BeamStoreApi, useBeamStore } from '~/modules/beam/store-beam.hooks';

import { AppBreadcrumbs } from '~/common/components/AppBreadcrumbs';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { KeyStroke } from '~/common/components/KeyStroke';
import { Release } from '~/common/app.release';
import { ShortcutKey, useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { animationBackgroundBeamGather, animationColorBeamScatterINV, animationEnterBelow } from '~/common/util/animUtils';


const _styles = {

  bar: {
    // layout
    display: 'flex',
    alignItems: 'center',
    gap: { xs: 1, md: 2 } as const,

    minWidth: 0, // ensures the breadcrumbs don't overflow
    // Customize breadcrumbs to enable collapse of the first one (chat title)
    '& nav': {
      overflow: 'hidden',
    },
    '& nav > ol': {
      flexWrap: 'nowrap',
    } as const,
    '& nav > ol > li:first-of-type': {
      overflow: 'hidden',
      maxWidth: { xs: '110px', md: '140px' },
    } as const,

  } as const,

  barScatter: {
    animation: `${animationColorBeamScatterINV} 5s infinite, ${animationEnterBelow} 0.6s`,
  } as const,

  barGather: {
    animation: `${animationBackgroundBeamGather} 3s infinite, ${animationEnterBelow} 0.6s`,
    px: 1.5, py: 0.5,
  } as const,

} as const;


export function ChatBarBeam(props: {
  beamStore: BeamStoreApi,
  conversationTitle: string,
  isMobile: boolean,
}) {

  // state
  const [showCloseConfirmation, setShowCloseConfirmation] = React.useState(false);


  // external beam state
  const { isEditMode, isScattering, isGatheringAny, requiresConfirmation, setIsMaximized, terminateBeam } = useBeamStore(props.beamStore, useShallow((store) => ({
    // state
    isEditMode: store.isEditMode,
    isScattering: store.isScattering,
    isGatheringAny: store.isGatheringAny,
    requiresConfirmation: store.isScattering || store.isGatheringAny || store.raysReady > 0,
    // actions
    setIsMaximized: store.setIsMaximized,
    terminateBeam: store.terminateKeepingSettings,
  })));


  // closure handlers

  const handleCloseBeam = React.useCallback(() => {
    if (requiresConfirmation)
      setShowCloseConfirmation(true);
    else
      terminateBeam();
  }, [requiresConfirmation, terminateBeam]);

  const handleCloseConfirmation = React.useCallback(() => {
    terminateBeam();
    setShowCloseConfirmation(false);
  }, [terminateBeam]);

  const handleCloseDenial = React.useCallback(() => {
    setShowCloseConfirmation(false);
  }, []);

  const handleMaximizeBeam = React.useCallback(() => {
    setIsMaximized(true);
  }, [setIsMaximized]);


  // intercept esc this beam is focused
  useGlobalShortcuts('ChatBarAltBeam', React.useMemo(() => [
    { key: ShortcutKey.Esc, action: handleCloseBeam, level: 10 /* because Modal-ish */ },
  ], [handleCloseBeam]));


  return (
    <Box sx={_styles.bar}>

      {/* [desktop] maximize button, or a disabled spacer  */}
      {!props.isMobile && (
        <GoodTooltip variantOutlined title={<Box sx={{ p: 1 }}>Maximize Beam</Box>}>
          <IconButton size='sm' onClick={handleMaximizeBeam}>
            {/*<OpenInFullIcon sx={{ fontSize: 'md' }} />*/}
          </IconButton>
        </GoodTooltip>
      )}

      <AppBreadcrumbs rootTitle={
        props.conversationTitle?.length > 3
          ? <Box className='agi-ellipsize'>{props.conversationTitle || 'Chat'}</Box>
          : undefined
      }>

        {/* Title & Status */}
        <Typography level='title-md' noWrap>
          <Box
            component='span'
            sx={Release.Features.LIGHTER_ANIMATIONS ? undefined
              : isGatheringAny ? _styles.barGather
                : isScattering ? _styles.barScatter
                  : undefined}
          >
            {isGatheringAny ? 'Merging...' : isScattering ? 'Beaming...' : isEditMode ? 'Beam Edit' : 'Beam'}
          </Box>
          {(!isGatheringAny && !isScattering && !isEditMode) && ' Mode'}
        </Typography>

      </AppBreadcrumbs>

      {/* Right Close Icon */}
      <GoodTooltip variantOutlined title={<Box sx={{ p: 1, display: 'flex', flexDirection: 'column', gap: 1 }}>Back to Chat <KeyStroke variant='outlined' combo='Esc' /></Box>}>
        <IconButton aria-label='Close' size='sm' onClick={handleCloseBeam}>
          <CloseRoundedIcon />
        </IconButton>
      </GoodTooltip>


      {/* Confirmation Modal */}
      {showCloseConfirmation && (
        <ConfirmationModal
          open
          onClose={handleCloseDenial}
          onPositive={handleCloseConfirmation}
          lowStakes
          noTitleBar
          confirmationText='Are you sure you want to close Beam Mode? Unsaved text will be lost.'
          positiveActionText='Yes, close'
        />
      )}
    </Box>
  );
}



================================================
FILE: src/apps/chat/components/layout-bar/ChatBarChat.tsx
================================================
import * as React from 'react';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import type { OptimaBarControlMethods } from '~/common/layout/optima/bar/OptimaBarDropdown';

import { useChatLLMDropdown } from './useLLMDropdown';
import { usePersonaIdDropdown } from './usePersonaDropdown';
import { useFolderDropdown } from './useFolderDropdown';


export function ChatBarChat(props: {
  conversationId: DConversationId | null;
  llmDropdownRef: React.Ref<OptimaBarControlMethods>;
  personaDropdownRef: React.Ref<OptimaBarControlMethods>;
}) {

  // state
  const { chatLLMDropdown } = useChatLLMDropdown(props.llmDropdownRef);
  const { personaDropdown } = usePersonaIdDropdown(props.conversationId, props.personaDropdownRef);
  const { folderDropdown } = useFolderDropdown(props.conversationId);

  return <>

    {/* Persona selector */}
    {personaDropdown}

    {/* Model selector */}
    {chatLLMDropdown}

    {/* Folder selector */}
    {folderDropdown}

  </>;
}



================================================
FILE: src/apps/chat/components/layout-bar/useFolderDropdown.tsx
================================================
import * as React from 'react';

import ClearIcon from '@mui/icons-material/Clear';
import FolderIcon from '@mui/icons-material/Folder';

import { DConversationId } from '~/common/stores/chat/chat.conversation';
import { OptimaBarDropdownMemo, OptimaDropdownItems } from '~/common/layout/optima/bar/OptimaBarDropdown';
import { useFolderStore } from '~/common/stores/folders/store-chat-folders';


export const ClearFolderText = 'No Folder';
const SPECIAL_ID_CLEAR_FOLDER = '_REMOVE_';


export function useFolderDropdown(conversationId: DConversationId | null) {

  // external state
  const { folders, enableFolders } = useFolderStore();


  // Prepare items for the dropdown
  const folderItems: OptimaDropdownItems | null = React.useMemo(() => {
    if (!folders.length)
      return null;

    // add one item per folder
    const items = folders.reduce((items, folder) => {
      items[folder.id] = {
        title: folder.title,
        icon: <FolderIcon sx={{ color: folder.color }} />,
      };
      return items;
    }, {} as OptimaDropdownItems);

    // add one item representing no folder
    items[SPECIAL_ID_CLEAR_FOLDER] = {
      title: ClearFolderText,
      icon: <ClearIcon />,
    };

    return items;
  }, [folders]);


  // Handle dropdown folder change
  const handleFolderChange = React.useCallback((folderId: string | null) => {
    if (conversationId && folderId) {
      // Remove conversation from all folders
      folders.forEach(folder => {
        if (folder.conversationIds.includes(conversationId)) {
          useFolderStore.getState().removeConversationFromFolder(folder.id, conversationId);
        }
      });
      // Add conversation to the selected folder
      if (folderId !== SPECIAL_ID_CLEAR_FOLDER)
        useFolderStore.getState().addConversationToFolder(folderId, conversationId);
    }
  }, [conversationId, folders]);

  // find the folder ID for the active Conversation
  const currentFolderId = folders.find(folder => folder.conversationIds.includes(conversationId || ''))?.id || null;

  // Create the dropdown component
  const folderDropdown = React.useMemo(() => {

    // don't show the dropdown if folders are not enabled
    if (!enableFolders || !folderItems)
      return null;

    return (
      <OptimaBarDropdownMemo
        items={folderItems}
        value={currentFolderId}
        onChange={handleFolderChange}
        placeholder='Assign to folder'
        showSymbols
      />
    );
  }, [currentFolderId, enableFolders, folderItems, handleFolderChange]);

  return { folderDropdown };
}


================================================
FILE: src/apps/chat/components/layout-bar/useLLMDropdown.tsx
================================================
import * as React from 'react';

import { Box, IconButton, ListItemButton, ListItemDecorator } from '@mui/joy';
import ArrowForwardRoundedIcon from '@mui/icons-material/ArrowForwardRounded';
import BuildCircleIcon from '@mui/icons-material/BuildCircle';
import SettingsIcon from '@mui/icons-material/Settings';

import { findModelVendor } from '~/modules/llms/vendors/vendors.registry';

import type { DLLM, DLLMId } from '~/common/stores/llms/llms.types';
import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { DebouncedInputMemo } from '~/common/components/DebouncedInput';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { KeyStroke } from '~/common/components/KeyStroke';
import { OptimaBarControlMethods, OptimaBarDropdownMemo, OptimaDropdownItems } from '~/common/layout/optima/bar/OptimaBarDropdown';
import { findModelsServiceOrNull } from '~/common/stores/llms/store-llms';
import { isDeepEqual } from '~/common/util/hooks/useDeep';
import { optimaActions, optimaOpenModels } from '~/common/layout/optima/useOptima';
import { useAllLLMs } from '~/common/stores/llms/hooks/useAllLLMs';
import { useModelDomain } from '~/common/stores/llms/hooks/useModelDomain';
import { useUIComplexityMode } from '~/common/stores/store-ui';


function LLMDropdown(props: {
  dropdownRef: React.Ref<OptimaBarControlMethods>,
  llms: ReadonlyArray<DLLM>,
  chatLlmId: undefined | DLLMId | null,
  setChatLlmId: (llmId: DLLMId | null) => void,
  placeholder?: string,
}) {

  // state
  const [filterString, setfilterString] = React.useState<string | null>(null);

  // external state
  const uiComplexityMode = useUIComplexityMode();
  const showSymbols = uiComplexityMode !== 'minimal';

  // derived state
  const { chatLlmId, llms, setChatLlmId } = props;

  const llmsCount = llms.filter(llm => !llm.hidden).length;
  const showFilter = llmsCount >= 50;

  const handleChatLLMChange = React.useCallback((value: DLLMId | null) => {
    value && setChatLlmId(value);
  }, [setChatLlmId]);

  const handleOpenLLMOptions = React.useCallback(() => {
    return chatLlmId && optimaActions().openModelOptions(chatLlmId);
  }, [chatLlmId]);


  // dropdown items - chached
  const stabilizeLlmOptions = React.useRef<OptimaDropdownItems>(undefined);

  const llmDropdownItems: OptimaDropdownItems = React.useMemo(() => {
    const llmItems: OptimaDropdownItems = {};
    let prevServiceId: DModelsServiceId | null = null;
    let sepCount = 0;

    const lcFilterString = filterString?.toLowerCase();
    const filteredLLMs = llms.filter(llm => {
      if (chatLlmId && llm.id === chatLlmId)
        return true;

      // filter-out models that don't contain the search string
      if (lcFilterString && !llm.label.toLowerCase().includes(lcFilterString))
        return false;

      // filter-out hidden models from the dropdown
      return lcFilterString ? true : !llm.hidden;
    });

    for (const llm of filteredLLMs) {
      // add separators when changing services
      if (!prevServiceId || llm.sId !== prevServiceId) {
        const vendor = findModelVendor(llm.vId);
        const serviceLabel = findModelsServiceOrNull(llm.sId)?.label || vendor?.name || llm.sId;
        llmItems[`sep-${llm.sId}`] = {
          type: 'separator',
          title: serviceLabel,
          // NOTE: commenting because not useful, and creates a recursive issue in isDeepEqual - not needed, so kthxbye
          // icon: vendor?.Icon ? <vendor.Icon /> : undefined,
        };
        prevServiceId = llm.sId;
        sepCount++;
      }

      // add the model item
      llmItems[llm.id] = {
        title: llm.label,
        ...(llm.userStarred ? { symbol: '⭐' } : {}),
        // icon: llm.id.startsWith('some vendor') ? <VendorIcon /> : undefined,
      };
    }

    // if there's a single separator (i.e. only one source), remove it
    if (sepCount === 1) {
      for (const key in llmItems) {
        if (key.startsWith('sep-')) {
          delete llmItems[key];
          break;
        }
      }
    }

    // stabilize the items: reuse the full array if nothing changed
    const prev = stabilizeLlmOptions.current;
    if (prev && isDeepEqual(prev, llmItems)) return prev;

    // otherwise update the cache and return the new items
    return stabilizeLlmOptions.current = llmItems;
  }, [chatLlmId, llms, filterString]);


  // "Model Options" button (only on the active item)
  const llmDropdownButton = React.useMemo(() => (
    <GoodTooltip title={
      <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
        Model Options
        <KeyStroke variant='outlined' combo='Ctrl + Shift + O' sx={{ my: 0.5 }} />
      </Box>
    }>
      <IconButton
        variant='outlined' color='neutral'
        onClick={handleOpenLLMOptions}
        sx={{
          ml: 'auto',
          // mr: -0.5,
          my: '-0.25rem' /* absorb the menuItem padding */,
          backgroundColor: 'background.surface',
          boxShadow: 'xs',
        }}
      >
        <SettingsIcon sx={{ fontSize: 'xl' }} />
      </IconButton>
    </GoodTooltip>
  ), [handleOpenLLMOptions]);


  // "Models Filter" box
  const llmDropdownPrependOptions = React.useMemo(() =>
    !showFilter ? undefined : (
      <Box sx={{ p: 1 }}>
        <DebouncedInputMemo
          aggressiveRefocus
          debounceTimeout={300}
          onDebounce={setfilterString}
          placeholder={`Search ${llmsCount} models...`}
        />
      </Box>
    ), [showFilter, llmsCount]);

  // [effect] clear filter when the active model changes
  // Note: this doesn't work because the debounced component holds the filter string
  // React.useEffect(() => {
  //   if (chatLlmId) {
  //     setsearchQuery(null);
  //     console.log('cleared');
  //   }
  // }, [chatLlmId]);


  // Zero State - no models available
  const hasDropdownOptions = Object.keys(llmDropdownItems || {}).length > 0;

  // "Models Setup" button
  const llmDropdownAppendOptions = React.useMemo(() => <>

    {/*{chatLlmId && (*/}
    {/*  <ListItemButton key='menu-opt' onClick={handleOpenLLMOptions}>*/}
    {/*    <ListItemDecorator><SettingsIcon color='success' /></ListItemDecorator>*/}
    {/*    <Box sx={{ flexGrow: 1, display: 'flex', justifyContent: 'space-between', gap: 1 }}>*/}
    {/*      Options*/}
    {/*      <KeyStroke combo='Ctrl + Shift + O' />*/}
    {/*    </Box>*/}
    {/*  </ListItemButton>*/}
    {/*)}*/}

    <ListItemButton key='menu-llms' onClick={optimaOpenModels} sx={{ backgroundColor: 'background.surface', py: 'calc(2 * var(--ListDivider-gap))' }}>
      <ListItemDecorator>{!hasDropdownOptions ? '⚠️' : <BuildCircleIcon color='success' />}</ListItemDecorator>
      <Box sx={{ flexGrow: 1, display: 'flex', justifyContent: 'space-between', gap: 1, alignItems: 'center' }}>
        {!hasDropdownOptions ? 'Add Models' : 'Models'}
        {/*<Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>*/}
        {/*  <KeyStroke variant='outlined' size='sm' combo='Ctrl + Shift + M' sx={{ ml: 2, bgcolor: 'background.popup' }} />*/}
        <ArrowForwardRoundedIcon sx={{ ml: 'auto', fontSize: 'xl' }} />
        {/*</Box>*/}
      </Box>
    </ListItemButton>

  </>, [hasDropdownOptions]);


  return (
    <OptimaBarDropdownMemo
      ref={props.dropdownRef}
      items={llmDropdownItems}
      value={chatLlmId}
      onChange={handleChatLLMChange}
      placeholder={props.placeholder || '⚠️ Models …'}
      prependOption={llmDropdownPrependOptions}
      appendOption={llmDropdownAppendOptions}
      activeEndDecorator={llmDropdownButton}
      showSymbols={showSymbols ? 'compact' : false}
    />
  );
}


export function useChatLLMDropdown(dropdownRef: React.Ref<OptimaBarControlMethods>) {

  // external state
  const llms = useAllLLMs();
  const { domainModelId: chatLLMId, assignDomainModelId: setChatLLMId } = useModelDomain('primaryChat');

  const chatLLMDropdown = React.useMemo(() => {
    return <LLMDropdown dropdownRef={dropdownRef} llms={llms} chatLlmId={chatLLMId} setChatLlmId={setChatLLMId} />;
  }, [chatLLMId, dropdownRef, llms, setChatLLMId]);

  return { chatLLMId, chatLLMDropdown };
}

/*export function useTempLLMDropdown(props: { initialLlmId: DLLMId | null }) {
  // local state
  const [llmId, setLlmId] = React.useState<DLLMId | null>(props.initialLlmId);

  // external state
  const llms = useModelsStore(state => state.llms);

  const chatLLMDropdown = React.useMemo(
    () => <LLMDropdown llms={llms} llmId={llmId} setLlmId={setLlmId} />,
    [llms, llmId, setLlmId],
  );

  return { llmId, chatLLMDropdown };
}*/


================================================
FILE: src/apps/chat/components/layout-bar/usePersonaDropdown.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { SystemPurposeId, SystemPurposes } from '../../../../data';

import { DConversationId } from '~/common/stores/chat/chat.conversation';
import { OptimaBarControlMethods, OptimaBarDropdownMemo } from '~/common/layout/optima/bar/OptimaBarDropdown';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useUIComplexityIsMinimal } from '~/common/stores/store-ui';

import { usePurposeStore } from '../persona-selector/store-purposes';


function PersonaDropdown(props: {
  dropdownRef: React.Ref<OptimaBarControlMethods>,
  systemPurposeId: SystemPurposeId | null,
  setSystemPurposeId: (systemPurposeId: SystemPurposeId | null) => void,
}) {

  // external state
  const hiddenPurposeIDs = usePurposeStore(state => state.hiddenPurposeIDs);
  const zenMode = useUIComplexityIsMinimal();


  // filter by key in the object - must be missing the system purpose ids hidden by the user, or be the currently active one
  const visibleSystemPurposes = React.useMemo(() => {
    return Object.keys(SystemPurposes)
      .filter(key => !hiddenPurposeIDs.includes(key as SystemPurposeId) || key === props.systemPurposeId)
      .reduce((obj, key) => {
        obj[key as SystemPurposeId] = SystemPurposes[key as SystemPurposeId];
        return obj;
      }, {} as typeof SystemPurposes);
  }, [hiddenPurposeIDs, props.systemPurposeId]);


  const { setSystemPurposeId } = props;

  const handleSystemPurposeChange = React.useCallback((value: string | null) => {
    setSystemPurposeId(value as (SystemPurposeId | null));
  }, [setSystemPurposeId]);


  return (
    <OptimaBarDropdownMemo
      ref={props.dropdownRef}
      items={visibleSystemPurposes}
      value={props.systemPurposeId}
      onChange={handleSystemPurposeChange}
      showSymbols={!zenMode}
    />
  );

}

export function usePersonaIdDropdown(conversationId: DConversationId | null, dropdownRef: React.Ref<OptimaBarControlMethods>) {

  // external state
  const { systemPurposeId } = useChatStore(useShallow(state => {
    const conversation = state.conversations.find(conversation => conversation.id === conversationId);
    return {
      systemPurposeId: conversation?.systemPurposeId ?? null,
    };
  }));


  const handleSetSystemPurposeId = React.useCallback((systemPurposeId: SystemPurposeId | null) => {
    if (conversationId && systemPurposeId)
      useChatStore.getState().setSystemPurposeId(conversationId, systemPurposeId);
  }, [conversationId]);

  const personaDropdown = React.useMemo(() => {
      // Note: commented the following as chats with 'null' personas are allowed, and this prevents the control from showing
      // if (!systemPurposeId) return null;
      return (
        <PersonaDropdown
          dropdownRef={dropdownRef}
          systemPurposeId={systemPurposeId}
          setSystemPurposeId={handleSetSystemPurposeId}
        />
      );
    },
    [dropdownRef, handleSetSystemPurposeId, systemPurposeId],
  );

  return { personaDropdown };
}


================================================
FILE: src/apps/chat/components/layout-drawer/ChatDrawer.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Box, Button, Dropdown, IconButton, ListDivider, ListItem, ListItemButton, ListItemDecorator, Menu, MenuButton, MenuItem, Tooltip, Typography } from '@mui/joy';
import AddIcon from '@mui/icons-material/Add';
import AttachFileRoundedIcon from '@mui/icons-material/AttachFileRounded';
import CheckRoundedIcon from '@mui/icons-material/CheckRounded';
import ClearIcon from '@mui/icons-material/Clear';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import FileDownloadOutlinedIcon from '@mui/icons-material/FileDownloadOutlined';
import FileUploadOutlinedIcon from '@mui/icons-material/FileUploadOutlined';
import FolderIcon from '@mui/icons-material/Folder';
import FormatPaintOutlinedIcon from '@mui/icons-material/FormatPaintOutlined';
import MoreVertIcon from '@mui/icons-material/MoreVert';
import StarOutlineRoundedIcon from '@mui/icons-material/StarOutlineRounded';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { CloseablePopup } from '~/common/components/CloseablePopup';
import { DFolder, useFolderStore } from '~/common/stores/folders/store-chat-folders';
import { DebouncedInputMemo } from '~/common/components/DebouncedInput';
import { FoldersToggleOff } from '~/common/components/icons/FoldersToggleOff';
import { FoldersToggleOn } from '~/common/components/icons/FoldersToggleOn';
import { OPTIMA_DRAWER_BACKGROUND } from '~/common/layout/optima/optima.config';
import { OptimaDrawerHeader } from '~/common/layout/optima/drawer/OptimaDrawerHeader';
import { OptimaDrawerList } from '~/common/layout/optima/drawer/OptimaDrawerList';
import { capitalizeFirstLetter } from '~/common/util/textUtils';
import { getIsMobile } from '~/common/components/useMatchMedia';
import { optimaCloseDrawer } from '~/common/layout/optima/useOptima';
import { themeScalingMap, themeZIndexOverMobileDrawer } from '~/common/app.theme';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { ChatDrawerItemMemo, FolderChangeRequest } from './ChatDrawerItem';
import { ChatFolderList } from './folders/ChatFolderList';
import { ChatNavGrouping, ChatSearchDepth, ChatSearchSorting, isDrawerSearching, useChatDrawerRenderItems } from './useChatDrawerRenderItems';
import { ClearFolderText } from '../layout-bar/useFolderDropdown';
import { useChatDrawerFilters } from '../../store-app-chat';


// this is here to make shallow comparisons work on the next hook
const noFolders: DFolder[] = [];

/*
 * Lists folders and returns the active folder
 */
export const useFolders = (activeFolderId: string | null) => useFolderStore(useShallow(({ enableFolders, folders, toggleEnableFolders }) => {

  // finds the active folder if any
  const activeFolder = (enableFolders && activeFolderId)
    ? folders.find(folder => folder.id === activeFolderId) ?? null
    : null;

  return {
    activeFolder,
    allFolders: enableFolders ? folders : noFolders,
    enableFolders,
    toggleEnableFolders,
  };
}));


export const ChatDrawerMemo = React.memo(ChatDrawer);

function ChatDrawer(props: {
  activeConversationId: DConversationId | null,
  activeFolderId: string | null,
  chatPanesConversationIds: DConversationId[],
  disableNewButton: boolean,
  onConversationActivate: (conversationId: DConversationId) => void,
  onConversationBranch: (conversationId: DConversationId, messageId: string | null, addSplitPane: boolean) => void,
  onConversationNew: (forceNoRecycle: boolean, isIncognito: boolean) => void,
  onConversationsDelete: (conversationIds: DConversationId[], bypassConfirmation: boolean) => void,
  onConversationsExportDialog: (conversationId: DConversationId | null, exportAll: boolean) => void,
  onConversationsImportDialog: () => void,
  setActiveFolderId: (folderId: string | null) => void,
}) {

  const { onConversationActivate, onConversationBranch, onConversationNew, onConversationsDelete, onConversationsExportDialog } = props;

  // local state
  const [navGrouping, setNavGrouping] = React.useState<ChatNavGrouping>('date');
  const [searchSorting, setSearchSorting] = React.useState<ChatSearchSorting>('date');
  const [searchDepth, setSearchDepth] = React.useState<ChatSearchDepth>('attachments'); // default: full search
  const [debouncedSearchQuery, setDebouncedSearchQuery] = React.useState('');
  const [folderChangeRequest, setFolderChangeRequest] = React.useState<FolderChangeRequest | null>(null);

  // external state
  const {
    clearFilters,
    filterHasDocFragments, toggleFilterHasDocFragments,
    filterHasImageAssets, toggleFilterHasImageAssets,
    filterHasStars, toggleFilterHasStars,
    filterIsArchived, toggleFilterIsArchived,
    showPersonaIcons, toggleShowPersonaIcons,
    showRelativeSize, toggleShowRelativeSize,
  } = useChatDrawerFilters();
  const { activeFolder, allFolders, enableFolders, toggleEnableFolders } = useFolders(props.activeFolderId);
  const { filteredChatsCount, filteredChatIDs, filteredChatsAreEmpty, filteredChatsBarBasis, filteredChatsIncludeActive, renderNavItems } = useChatDrawerRenderItems(
    props.activeConversationId, props.chatPanesConversationIds, debouncedSearchQuery, activeFolder, allFolders, filterHasStars, filterHasImageAssets, filterHasDocFragments, filterIsArchived, navGrouping, searchSorting, showRelativeSize, searchDepth,
  );
  const [uiComplexityMode, contentScaling] = useUIPreferencesStore(useShallow((state) => [state.complexityMode, state.contentScaling]));
  const zenMode = uiComplexityMode === 'minimal';
  const gifMode = uiComplexityMode === 'extra';


  // New/Activate/Delete Conversation

  const isMultiPane = props.chatPanesConversationIds.length >= 2;
  const disableNewButton = props.disableNewButton && filteredChatsIncludeActive;
  const newButtonDontRecycle = isMultiPane || !filteredChatsIncludeActive;

  const handleButtonNew = React.useCallback((event: React.MouseEvent) => {
    // FIXME: undocumented: shift+click to force incognito mode
    onConversationNew(newButtonDontRecycle, event.shiftKey);
    if (getIsMobile())
      optimaCloseDrawer();
  }, [newButtonDontRecycle, onConversationNew]);

  const handleConversationActivate = React.useCallback((conversationId: DConversationId, closeMenu: boolean) => {
    onConversationActivate(conversationId);
    if (closeMenu && getIsMobile())
      optimaCloseDrawer();
  }, [onConversationActivate]);

  const handleConversationsDeleteFiltered = React.useCallback(() => {
    !!filteredChatIDs?.length && onConversationsDelete(filteredChatIDs, false);
  }, [filteredChatIDs, onConversationsDelete]);

  const handleConversationDeleteNoConfirmation = React.useCallback((conversationId: DConversationId) => {
    conversationId && onConversationsDelete([conversationId], true);
  }, [onConversationsDelete]);

  const handleConversationsExport = React.useCallback(() => {
    props.activeConversationId && onConversationsExportDialog(props.activeConversationId, true);
  }, [onConversationsExportDialog, props.activeConversationId]);


  // Folder change request

  const handleConversationFolderChange = React.useCallback((folderChangeRequest: FolderChangeRequest) => setFolderChangeRequest(folderChangeRequest), []);

  const handleConversationFolderCancel = React.useCallback(() => setFolderChangeRequest(null), []);

  const handleConversationFolderSet = React.useCallback((conversationId: DConversationId, nextFolderId: string | null) => {
    // Remove conversation from existing folders
    const { addConversationToFolder, folders, removeConversationFromFolder } = useFolderStore.getState();
    folders.forEach(folder => folder.conversationIds.includes(conversationId) && removeConversationFromFolder(folder.id, conversationId));

    // Add conversation to the selected folder
    nextFolderId && addConversationToFolder(nextFolderId, conversationId);

    // Close the menu
    setFolderChangeRequest(null);
  }, []);


  // memoize the group dropdown
  const { isSearching } = isDrawerSearching(debouncedSearchQuery);
  const groupingComponent = React.useMemo(() => (
    <Dropdown>
      <MenuButton
        aria-label='View options'
        slots={{ root: IconButton }}
        slotProps={{ root: { size: 'sm' } }}
      >
        <MoreVertIcon />
      </MenuButton>

      {!isSearching ? (
        // Search/Filter default menu: Grouping, Filtering, ...
        <Menu placement='bottom-start' sx={{ minWidth: 200, zIndex: themeZIndexOverMobileDrawer /* need to be on top of the Modal on Mobile */ }}>
          <ListItem>
            <Typography level='body-sm'>Group By</Typography>
          </ListItem>
          {(['date', 'persona', 'dimension'] as Exclude<ChatNavGrouping, false>[]).map(_gName => (
            <MenuItem
              key={'group-' + _gName}
              aria-label={`Group by ${_gName}`}
              selected={navGrouping === _gName}
              onClick={() => setNavGrouping(grouping => grouping === _gName ? false : _gName)}
            >
              <ListItemDecorator>{navGrouping === _gName && <CheckRoundedIcon />}</ListItemDecorator>
              {capitalizeFirstLetter(_gName)}
            </MenuItem>
          ))}

          <ListDivider />
          <ListItem>
            <Typography level='body-sm'>Filter</Typography>
          </ListItem>
          <MenuItem onClick={toggleFilterIsArchived}>
            <ListItemDecorator>{filterIsArchived && <CheckRoundedIcon />}</ListItemDecorator>
            Archived
          </MenuItem>
          <MenuItem onClick={toggleFilterHasStars}>
            <ListItemDecorator>{filterHasStars && <CheckRoundedIcon />}</ListItemDecorator>
            Starred <StarOutlineRoundedIcon />
          </MenuItem>
          <MenuItem onClick={toggleFilterHasImageAssets}>
            <ListItemDecorator>{filterHasImageAssets && <CheckRoundedIcon />}</ListItemDecorator>
            Has Images <FormatPaintOutlinedIcon />
          </MenuItem>
          <MenuItem onClick={toggleFilterHasDocFragments}>
            <ListItemDecorator>{filterHasDocFragments && <CheckRoundedIcon />}</ListItemDecorator>
            Has Attachments <AttachFileRoundedIcon />
          </MenuItem>

          <ListDivider />
          <ListItem>
            <Typography level='body-sm'>Show</Typography>
          </ListItem>
          <MenuItem onClick={toggleShowPersonaIcons}>
            <ListItemDecorator>{showPersonaIcons && <CheckRoundedIcon />}</ListItemDecorator>
            Icons
          </MenuItem>
          <MenuItem onClick={toggleShowRelativeSize}>
            <ListItemDecorator>{showRelativeSize && <CheckRoundedIcon />}</ListItemDecorator>
            Relative Size
          </MenuItem>
        </Menu>
      ) : (
        // While searching, show the sorting and depth options
        <Menu placement='bottom-start' sx={{ minWidth: 180, zIndex: themeZIndexOverMobileDrawer /* need to be on top of the Modal on Mobile */ }}>
          <ListItem>
            <Typography level='body-sm'>Sort By</Typography>
          </ListItem>
          <MenuItem selected={searchSorting === 'frequency'} onClick={() => setSearchSorting('frequency')}>
            <ListItemDecorator>{searchSorting === 'frequency' && <CheckRoundedIcon />}</ListItemDecorator>
            Matches
          </MenuItem>
          <MenuItem selected={searchSorting === 'date'} onClick={() => setSearchSorting('date')}>
            <ListItemDecorator>{searchSorting === 'date' && <CheckRoundedIcon />}</ListItemDecorator>
            Date
          </MenuItem>
          <ListDivider />
          <ListItem>
            <Typography level='body-sm'>Search In</Typography>
          </ListItem>
          <MenuItem selected={searchDepth === 'titles'} onClick={() => setSearchDepth('titles')}>
            <ListItemDecorator>{searchDepth === 'titles' && <CheckRoundedIcon />}</ListItemDecorator>
            Titles
          </MenuItem>
          <MenuItem selected={searchDepth === 'content'} onClick={() => setSearchDepth('content')}>
            <ListItemDecorator>{searchDepth === 'content' && <CheckRoundedIcon />}</ListItemDecorator>
            Titles + Content
          </MenuItem>
          <MenuItem selected={searchDepth === 'attachments'} onClick={() => setSearchDepth('attachments')}>
            <ListItemDecorator>{searchDepth === 'attachments' && <CheckRoundedIcon />}</ListItemDecorator>
            Full
          </MenuItem>
        </Menu>
      )}
    </Dropdown>
  ), [
    filterHasDocFragments, filterHasImageAssets, filterHasStars, isSearching, navGrouping, searchSorting, searchDepth, filterIsArchived, showPersonaIcons, showRelativeSize,
    toggleFilterHasDocFragments, toggleFilterHasImageAssets, toggleFilterHasStars, toggleFilterIsArchived, toggleShowPersonaIcons, toggleShowRelativeSize,
  ]);


  return <>

    {/* Drawer Header */}
    <OptimaDrawerHeader title='Chats' onClose={optimaCloseDrawer}>
      <Tooltip title={enableFolders ? 'Hide Folders' : 'Use Folders'}>
        <IconButton size='sm' onClick={toggleEnableFolders}>
          {enableFolders ? <FoldersToggleOn /> : <FoldersToggleOff />}
        </IconButton>
      </Tooltip>
    </OptimaDrawerHeader>

    {/* Folders List (shrink at twice the rate as the Titles) */}
    {/*<Box sx={{*/}
    {/*  display: 'grid',*/}
    {/*  gridTemplateRows: !enableFolders ? '0fr' : '1fr',*/}
    {/*  transition: 'grid-template-rows 0.42s cubic-bezier(.17,.84,.44,1)',*/}
    {/*  '& > div': {*/}
    {/*    padding: enableFolders ? 2 : 0,*/}
    {/*    transition: 'padding 0.42s cubic-bezier(.17,.84,.44,1)',*/}
    {/*    overflow: 'hidden',*/}
    {/*  },*/}
    {/*}}>*/}
    {enableFolders && (
      <ChatFolderList
        folders={allFolders}
        contentScaling={contentScaling}
        activeFolderId={props.activeFolderId}
        onFolderSelect={props.setActiveFolderId}
        sx={{
          // shrink this at twice the rate as the Titles list
          flexGrow: 0, flexShrink: 2, overflow: 'hidden',
          minHeight: '7.5rem',
          p: 2,
          backgroundColor: 'background.level1',
        }}
      />
    )}
    {/*</Box>*/}

    {/* Chats List */}
    <OptimaDrawerList variant='plain' noTopPadding noBottomPadding tallRows>

      {enableFolders && <ListDivider sx={{ mb: 0 }} />}

      {/* Search / New Chat */}
      <Box sx={{ display: 'flex', flexDirection: 'column', m: 2, gap: 2 }}>

        {/* Search Input Field */}
        <DebouncedInputMemo
          minChars={2}
          onDebounce={setDebouncedSearchQuery}
          debounceTimeout={300}
          placeholder='Search...'
          aria-label='Search'
          endDecorator={groupingComponent}
        />

        {/* New Chat Button */}
        <Button
          // variant='outlined'
          variant={disableNewButton ? undefined : 'soft'}
          disabled={disableNewButton}
          onClick={handleButtonNew}
          sx={{
            // ...PageDrawerTallItemSx,
            justifyContent: 'flex-start',
            padding: '0px 0.75rem',

            // style
            border: '1px solid',
            borderColor: 'neutral.outlinedBorder',
            borderRadius: 'sm',
            '--ListItemDecorator-size': 'calc(2.5rem - 1px)', // compensate for the border
            // backgroundColor: 'background.popup',
            // boxShadow: (disableNewButton || props.isMobile) ? 'none' : 'xs',
            // transition: 'box-shadow 0.2s',
          }}
        >
          <ListItemDecorator><AddIcon sx={{ fontSize: '' }} /></ListItemDecorator>
          New chat
        </Button>

      </Box>

      {/* Chat Titles List (shrink as half the rate as the Folders List) */}
      <Box sx={{ flexGrow: 1, flexShrink: 1, flexBasis: '20rem', overflowY: 'auto', ...themeScalingMap[contentScaling].chatDrawerItemSx }}>
        {renderNavItems.map((item, idx) => item.type === 'nav-item-chat-data' ? (
            <ChatDrawerItemMemo
              key={'nav-chat-' + item.conversationId}
              item={item}
              showSymbols={!showPersonaIcons ? false : zenMode ? false : gifMode ? 'gif' : true}
              bottomBarBasis={filteredChatsBarBasis}
              onConversationActivate={handleConversationActivate}
              onConversationBranch={onConversationBranch}
              onConversationDeleteNoConfirmation={handleConversationDeleteNoConfirmation}
              onConversationExport={onConversationsExportDialog}
              onConversationFolderChange={handleConversationFolderChange}
            />
          ) : item.type === 'nav-item-group' ? (
            <Typography key={'nav-divider-' + idx} level='body-xs' sx={{
              textAlign: 'center',
              my: 1,
              // my: 'calc(var(--ListItem-minHeight) / 4)',
              // keeps the group header sticky to the top
              position: 'sticky',
              top: 0,
              backgroundColor: OPTIMA_DRAWER_BACKGROUND,
              zIndex: 1,
            }}>
              {item.title}
            </Typography>
          ) : item.type === 'nav-item-info-message' ? (
            <Box key={'nav-info-' + idx} sx={{ display: 'flex', alignItems: 'center', justifyContent: 'center', gap: 1, ml: 2 }}>
              <Typography level='body-xs' sx={{ color: 'primary.softColor', my: 'calc(var(--ListItem-minHeight) / 4)' }}>
                {filterHasStars && <StarOutlineRoundedIcon sx={{ color: 'primary.softColor', fontSize: 'xl', mb: -0.5, mr: 1 }} />}
                {item.message}
              </Typography>
              {(filterHasStars || filterHasImageAssets || filterHasDocFragments || filterIsArchived) && (
                <Tooltip title='Clear Filters'>
                  <IconButton size='sm' color='primary' onClick={clearFilters}>
                    <ClearIcon />
                  </IconButton>
                </Tooltip>
              )}
            </Box>
          ) : null,
        )}
      </Box>

      <ListDivider sx={{ my: 0 }} />

      {/* Bottom commands */}
      <Box sx={{ flexShrink: 0, display: 'flex', alignItems: 'center' }}>
        <ListItemButton onClick={props.onConversationsImportDialog} sx={{ flex: 1 }}>
          <ListItemDecorator>
            <FileDownloadOutlinedIcon />
          </ListItemDecorator>
          Import
          {/*<OpenAIIcon sx={{  ml: 'auto' }} />*/}
        </ListItemButton>

        <ListItemButton disabled={filteredChatsAreEmpty} onClick={handleConversationsExport} sx={{ flex: 1 }}>
          <ListItemDecorator>
            <FileUploadOutlinedIcon />
          </ListItemDecorator>
          Export
        </ListItemButton>
      </Box>

      <ListItemButton disabled={filteredChatsAreEmpty} onClick={handleConversationsDeleteFiltered}>
        <ListItemDecorator>
          <DeleteOutlineIcon />
        </ListItemDecorator>
        Delete {filteredChatsCount >= 2 ? `all ${filteredChatsCount} chats` : 'chat'}
      </ListItemButton>

    </OptimaDrawerList>


    {/* [Menu] Chat Item Folder Change */}
    {!!folderChangeRequest?.anchorEl && (
      <CloseablePopup
        menu anchorEl={folderChangeRequest.anchorEl} onClose={handleConversationFolderCancel}
        bigIcons
        minWidth={200}
        placement='bottom-start'
        zIndex={themeZIndexOverMobileDrawer /* need to be on top of the Modal on Mobile */}
      >

        {/* Folder Assignment Buttons */}
        {allFolders.map(folder => {
          const isRequestFolder = folder === folderChangeRequest.currentFolder;
          return (
            <ListItem
              key={folder.id}
              variant={isRequestFolder ? 'soft' : 'plain'}
              onClick={() => handleConversationFolderSet(folderChangeRequest.conversationId, folder.id)}
            >
              <ListItemButton>
                <ListItemDecorator>
                  <FolderIcon sx={{ color: folder.color }} />
                </ListItemDecorator>
                {folder.title}
              </ListItemButton>
            </ListItem>
          );
        })}

        {/* Remove Folder Assignment */}
        {!!folderChangeRequest.currentFolder && (
          <ListItem onClick={() => handleConversationFolderSet(folderChangeRequest.conversationId, null)}>
            <ListItemButton>
              <ListItemDecorator>
                <ClearIcon />
              </ListItemDecorator>
              {ClearFolderText}
            </ListItemButton>
          </ListItem>
        )}

      </CloseablePopup>
    )}

  </>;
}


================================================
FILE: src/apps/chat/components/layout-drawer/ChatDrawerItem.tsx
================================================
import * as React from 'react';

import { Avatar, Box, IconButton, ListItem, ListItemButton, ListItemDecorator, Sheet, styled, Tooltip, Typography } from '@mui/joy';
import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import CopyAllIcon from '@mui/icons-material/CopyAll';
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import FileUploadOutlinedIcon from '@mui/icons-material/FileUploadOutlined';
import FolderIcon from '@mui/icons-material/Folder';
import FolderOutlinedIcon from '@mui/icons-material/FolderOutlined';
import TelegramIcon from '@mui/icons-material/Telegram';
import VisibilityOffIcon from '@mui/icons-material/VisibilityOff';

import { SystemPurposeId, SystemPurposes } from '../../../../data';

import { autoConversationTitle } from '~/modules/aifn/autotitle/autoTitle';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import type { DFolder } from '~/common/stores/folders/store-chat-folders';
import { ANIM_BUSY_TYPING } from '~/common/util/dMessageUtils';
import { ChatBeamIcon } from '~/common/components/icons/ChatBeamIcon';
import { InlineTextarea } from '~/common/components/InlineTextarea';
import { isDeepEqual } from '~/common/util/hooks/useDeep';
import { useChatStore } from '~/common/stores/chat/store-chats';

import { CHAT_NOVEL_TITLE } from '../../AppChat';


// set to true to display the conversation IDs
// const DEBUG_CONVERSATION_IDS = false;


export const FadeInButton = styled(IconButton)({
  opacity: 0.5,
  transition: 'opacity 0.16s',
  '&:hover': { opacity: 1 },
});


export const ChatDrawerItemMemo = React.memo(ChatDrawerItem, (prev, next) =>
  // usign a custom function because `ChatNavigationItemData` is a complex object and memo won't work
  isDeepEqual(prev.item, next.item) &&
  prev.showSymbols === next.showSymbols &&
  prev.bottomBarBasis === next.bottomBarBasis &&
  prev.onConversationActivate === next.onConversationActivate &&
  prev.onConversationBranch === next.onConversationBranch &&
  prev.onConversationDeleteNoConfirmation === next.onConversationDeleteNoConfirmation &&
  prev.onConversationExport === next.onConversationExport &&
  prev.onConversationFolderChange === next.onConversationFolderChange,
);

export interface ChatNavigationItemData {
  type: 'nav-item-chat-data',
  conversationId: DConversationId;
  isActive: boolean;
  isAlsoOpen: string | false;
  isEmpty: boolean;
  isIncognito: boolean;
  title: string;
  isArchived: boolean;
  userSymbol: string | undefined;
  userFlagsSummary: string | undefined;
  containsDocAttachments: boolean;
  containsImageAssets: boolean;
  folder: DFolder | null | undefined; // null: 'All', undefined: do not show folder select
  updatedAt: number;
  hasBeamOpen: boolean;
  messageCount: number;
  beingGenerated: boolean;
  systemPurposeId: SystemPurposeId;
  searchFrequency: number;
}

export interface FolderChangeRequest {
  conversationId: DConversationId;
  anchorEl: HTMLButtonElement;
  currentFolder: DFolder | null;
}

function ChatDrawerItem(props: {
  // NOTE: always update the Memo comparison if you add or remove props
  item: ChatNavigationItemData,
  showSymbols: boolean | 'gif',
  bottomBarBasis: number,
  onConversationActivate: (conversationId: DConversationId, closeMenu: boolean) => void,
  onConversationBranch: (conversationId: DConversationId, messageId: string | null, addSplitPane: boolean) => void,
  onConversationDeleteNoConfirmation: (conversationId: DConversationId) => void,
  onConversationExport: (conversationId: DConversationId, exportAll: boolean) => void,
  onConversationFolderChange: (folderChangeRequest: FolderChangeRequest) => void,
}) {

  // state
  const [isEditingTitle, setIsEditingTitle] = React.useState(false);
  const [isAutoEditingTitle, setIsAutoEditingTitle] = React.useState(false);
  const [deleteArmed, setDeleteArmed] = React.useState(false);

  // derived state
  const { onConversationBranch, onConversationExport, onConversationFolderChange } = props;
  const {
    conversationId,
    isActive,
    isAlsoOpen,
    isIncognito,
    title,
    userSymbol,
    userFlagsSummary,
    containsDocAttachments,
    containsImageAssets,
    folder,
    hasBeamOpen,
    messageCount,
    beingGenerated,
    systemPurposeId,
    searchFrequency,
  } = props.item;
  const isNew = messageCount === 0;


  // [effect] auto-disarm when inactive
  const shallClose = deleteArmed && !isActive;
  React.useEffect(() => {
    if (shallClose)
      setDeleteArmed(false);
  }, [shallClose]);


  // Activate

  const handleConversationActivate = () => props.onConversationActivate(conversationId, true);


  // branch

  const handleConversationBranch = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    conversationId && onConversationBranch(conversationId, null, false /* no pane from Drawer duplicate */);
  }, [conversationId, onConversationBranch]);


  // export

  const handleConversationExport = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    conversationId && onConversationExport(conversationId, false);
  }, [conversationId, onConversationExport]);


  // Folder change

  const handleFolderChangeBegin = React.useCallback((event: React.MouseEvent<HTMLButtonElement>) => {
    event.stopPropagation();
    onConversationFolderChange({
      conversationId,
      anchorEl: event.currentTarget,
      currentFolder: folder ?? null,
    });
  }, [conversationId, folder, onConversationFolderChange]);


  // Title Edit

  const handleTitleEditBegin = React.useCallback(() => setIsEditingTitle(true), []);

  const handleTitleEditCancel = React.useCallback(() => {
    setIsEditingTitle(false);
  }, []);

  const handleTitleEditChange = React.useCallback((text: string) => {
    setIsEditingTitle(false);
    useChatStore.getState().setUserTitle(conversationId, text.trim());
  }, [conversationId]);

  const handleTitleEditAuto = React.useCallback(async () => {
    setIsAutoEditingTitle(true);
    await autoConversationTitle(conversationId, true);
    setIsAutoEditingTitle(false);
  }, [conversationId]);


  // Delete

  const { onConversationDeleteNoConfirmation } = props;
  const handleDeleteButtonShow = React.useCallback((event: React.MouseEvent) => {
    // special case: if 'Shift' is pressed, delete immediately
    if (event.shiftKey) { // immediately delete:conversation
      event.stopPropagation();
      onConversationDeleteNoConfirmation(conversationId);
      return;
    }
    setDeleteArmed(true);
  }, [conversationId, onConversationDeleteNoConfirmation]);

  const handleDeleteButtonHide = React.useCallback(() => setDeleteArmed(false), []);

  const handleConversationDelete = React.useCallback((event: React.MouseEvent) => {
    if (deleteArmed) {
      setDeleteArmed(false);
      event.stopPropagation();
      onConversationDeleteNoConfirmation(conversationId);
    }
  }, [conversationId, deleteArmed, onConversationDeleteNoConfirmation]);


  const personaSymbol = userSymbol || SystemPurposes[systemPurposeId]?.symbol || '❓';
  const personaImageURI = SystemPurposes[systemPurposeId]?.imageUri ?? undefined;


  const progress = props.bottomBarBasis ? 100 * (searchFrequency || messageCount) / props.bottomBarBasis : 0;

  const titleRowComponent = React.useMemo(() => <>

    {/* Symbol, if globally enabled */}
    {(props.showSymbols || isIncognito) && (
      <ListItemDecorator>
        {hasBeamOpen ? (
          <ChatBeamIcon sx={{ fontSize: 'xl' }} />
        ) : isIncognito ? (
          <VisibilityOffIcon sx={{ fontSize: 'xl' }} />
        ) : (beingGenerated && props.showSymbols === 'gif') ? (
          <Avatar
            alt='chat activity'
            variant='plain'
            src={ANIM_BUSY_TYPING}
            sx={{
              width: '1.5rem',
              height: '1.5rem',
              borderRadius: 'var(--joy-radius-sm)',
            }}
          />
        ) : beingGenerated ? (
          <TelegramIcon sx={{ fontSize: 'xl' }} />
        ) : (personaImageURI && props.showSymbols === 'gif') ? (
          <Avatar
            alt={personaSymbol}
            src={personaImageURI}
            sx={{
              width: '1.5rem',
              height: '1.5rem',
              borderRadius: 'var(--joy-radius-sm)',
            }}
          />
        ) : (
          <Typography sx={isNew ? { opacity: 0.4, filter: 'grayscale(0.75)' } : undefined}>
            {personaSymbol}
          </Typography>
        )}
      </ListItemDecorator>
    )}

    {/* Title */}
    {!isEditingTitle ? (
      // using Box to not reset the parent font scaling
      <Box
        onDoubleClick={handleTitleEditBegin}
        sx={{
          color: isActive ? 'text.primary' : 'text.secondary',
          overflowWrap: 'anywhere',
          flex: 1,
        }}
      >
        {/*{DEBUG_CONVERSATION_IDS && `${conversationId} - `}*/}
        {title.trim() ? title : CHAT_NOVEL_TITLE}{beingGenerated && ' ...'}
      </Box>
    ) : (
      <InlineTextarea
        invertedColors
        initialText={title}
        onEdit={handleTitleEditChange}
        onCancel={handleTitleEditCancel}
        sx={{
          flexGrow: 1,
          ml: -1.5, mr: -0.5,
        }}
      />
    )}

    {/* Right text */}
    {searchFrequency > 0 ? (
      // Display search frequency if it exists and is greater than 0
      <Typography level='body-sm'>
        {searchFrequency}
      </Typography>
    ) : (props.showSymbols && (userFlagsSummary || containsDocAttachments || containsImageAssets)) ? (
      <Box sx={{
        fontSize: 'xs',
        whiteSpace: 'nowrap',
        pointerEvents: 'none',
      }}>
        {userFlagsSummary}{containsDocAttachments && '📄'}{containsImageAssets && '🖍️'}
      </Box>
    ) : null}

  </>, [beingGenerated, containsDocAttachments, containsImageAssets, handleTitleEditBegin, handleTitleEditCancel, handleTitleEditChange, hasBeamOpen, isActive, isEditingTitle, isIncognito, isNew, personaImageURI, personaSymbol, props.showSymbols, searchFrequency, title, userFlagsSummary]);

  const progressBarFixedComponent = React.useMemo(() =>
    progress > 0 && (
      <Box sx={{
        backgroundColor: 'neutral.softHoverBg',
        position: 'absolute', left: 0, bottom: 0, width: progress + '%', height: 4,
      }} />
    ), [progress]);

  return (isActive || isAlsoOpen) ? (

    // Active or Also Open
    <Sheet
      variant={isActive ? 'solid' : 'outlined'}
      invertedColors={isActive}
      onClick={!isActive ? handleConversationActivate : undefined}
      sx={{
        // common
        // position: 'relative', // for the progress bar (now disabled)
        '--ListItem-minHeight': '2.75rem',

        // differences between primary and secondary variants
        ...(isActive ? {
          border: 'none', // there's a default border of 1px and invisible.. hmm
        } : {
          // '--variant-borderWidth': '0.125rem',
          cursor: 'pointer',
        }),

        // style
        fontSize: 'inherit',
        backgroundColor: isActive ? 'neutral.solidActiveBg' : 'neutral.softBg',
        borderRadius: 'md',
        mx: '0.25rem',
        '&:hover > button': {
          opacity: 1, // fade in buttons when hovering, but by default wash them out a bit
        },
        ...(isIncognito && {
          backgroundColor: 'background.level2',
          backgroundImage: 'repeating-linear-gradient(45deg, rgba(0,0,0,0.03), rgba(0,0,0,0.03) 10px, transparent 10px, transparent 20px)',
          // border: 'none',
          // border: '1px dashed',
          borderColor: 'background.level3',
          // purple icon to further indicate incognito mode
          '& .MuiListItemDecorator-root': {
            color: '#9C27B0',
          },
          // filter: 'brightness(0.5) contrast(0.5)',
        }),
      }}
    >

      <ListItem sx={{ border: 'none', display: 'grid', gap: 0, px: 'calc(var(--ListItem-paddingX) - 0.25rem)' }}>

        {/* Title row */}
        <Box sx={{ display: 'flex', gap: 'var(--ListItem-gap)', minHeight: '2.25rem', alignItems: 'center' }}>
          {titleRowComponent}
        </Box>

        {/* buttons row */}
        {isActive && (
          <Box sx={{ display: 'flex', gap: 0.5, minHeight: '2.25rem', alignItems: 'center' }}>
            {props.showSymbols && <ListItemDecorator />}

            {/* Current Folder color, and change initiator */}
            {!deleteArmed && <>
              {(folder !== undefined) && <>
                <Tooltip arrow disableInteractive title={folder ? `Change Folder (${folder.title})` : 'Add to Folder'}>
                  {folder ? (
                    <IconButton size='sm' onClick={handleFolderChangeBegin}>
                      <FolderIcon style={{ color: folder.color || 'inherit' }} />
                    </IconButton>
                  ) : (
                    <FadeInButton size='sm' onClick={handleFolderChangeBegin}>
                      <FolderOutlinedIcon />
                    </FadeInButton>
                  )}
                </Tooltip>

                {/*<Divider orientation='vertical' sx={{ my: 1, opacity: 0.5 }} />*/}
              </>}

              <Tooltip arrow disableInteractive title='Rename'>
                <FadeInButton size='sm' disabled={isEditingTitle || isAutoEditingTitle} onClick={handleTitleEditBegin}>
                  <EditRoundedIcon />
                </FadeInButton>
              </Tooltip>

              {!isNew && <>
                <Tooltip arrow disableInteractive color='success' title='Auto-Title'>
                  <FadeInButton size='sm' disabled={isEditingTitle || isAutoEditingTitle} onClick={handleTitleEditAuto}>
                    <AutoFixHighIcon />
                  </FadeInButton>
                </Tooltip>

                <Tooltip arrow disableInteractive title='Duplicate'>
                  <FadeInButton size='sm' onClick={handleConversationBranch}>
                    <CopyAllIcon />
                  </FadeInButton>
                </Tooltip>

                <Tooltip arrow disableInteractive title='Export Chat'>
                  <FadeInButton size='sm' onClick={handleConversationExport}>
                    <FileUploadOutlinedIcon />
                  </FadeInButton>
                </Tooltip>
              </>}

            </>}

            {/* --> */}
            <Box sx={{ flex: 1 }} />

            {/* Delete [armed, arming] buttons */}
            {/*{!searchFrequency && <>*/}
            {deleteArmed && (
              <Tooltip color='danger' arrow disableInteractive title='Confirm Deletion'>
                <FadeInButton key='btn-del' variant='solid' color='success' size='sm' onClick={handleConversationDelete} sx={{ opacity: 1, mr: 0.5 }}>
                  <DeleteForeverIcon sx={{ color: 'danger.solidBg' }} />
                </FadeInButton>
              </Tooltip>
            )}

            <Tooltip arrow disableInteractive title={deleteArmed ? 'Cancel Delete' : 'Delete'}>
              <FadeInButton key='btn-arm' size='sm' onClick={deleteArmed ? handleDeleteButtonHide : handleDeleteButtonShow} sx={deleteArmed ? { opacity: 1 } : {}}>
                {deleteArmed ? <CloseRoundedIcon /> : <DeleteOutlineIcon />}
              </FadeInButton>
            </Tooltip>
            {/*</>}*/}
          </Box>
        )}

        {/* View places row */}
        {isAlsoOpen && (
          <Typography level='body-xs' sx={{ mx: 'auto' }}>
            <em>In view {isAlsoOpen}</em>
          </Typography>
        )}

      </ListItem>

      {/* Optional progress bar, underlay */}
      {/* NOTE: disabled on 20240204: quite distracting on the active chat sheet */}
      {/*{progressBarFixedComponent}*/}

    </Sheet>

  ) : (

    // Inactive Conversation - click to activate
    <ListItem
      // sx={{ '--ListItem-minHeight': '2.75rem' }}
    >

      <ListItemButton
        onClick={handleConversationActivate}
        sx={{
          border: 'none', // there's a default border of 1px and invisible.. hmm
          position: 'relative', // for the progress bar
          borderRadius: 'sm', // OPTIMA_NAV_RADIUS, // sync with the optima radius, because they need to match
          ...isIncognito && {
            filter: 'contrast(0)',
          },
        }}
      >

        {titleRowComponent}

        {/* Optional progress bar, underlay */}
        {progressBarFixedComponent}

      </ListItemButton>

    </ListItem>
  );
}


================================================
FILE: src/apps/chat/components/layout-drawer/useChatDrawerRenderItems.tsx
================================================
import * as React from 'react';

import { useModuleBeamStore } from '~/modules/beam/store-module-beam';

import type { DFolder } from '~/common/stores/folders/store-chat-folders';
import { DMessage, DMessageUserFlag, MESSAGE_FLAG_STARRED, messageFragmentsReduceText, messageHasUserFlag, messageUserFlagToEmoji } from '~/common/stores/chat/chat.message';
import { conversationTitle, DConversationId } from '~/common/stores/chat/chat.conversation';
import { getLocalMidnightInUTCTimestamp, getTimeBucketEn } from '~/common/util/timeUtils';
import { isAttachmentFragment, isContentOrAttachmentFragment, isDocPart, isImageRefPart } from '~/common/stores/chat/chat.fragments';
import { shallowEquals } from '~/common/util/hooks/useShallowObject';
import { useChatStore } from '~/common/stores/chat/store-chats';

import type { ChatNavigationItemData } from './ChatDrawerItem';


// configuration
const SEARCH_MIN_CHARS = 3;


interface ChatDrawerRenderItems {
  renderNavItems: (ChatNavigationItemData | ChatNavigationGroupData | ChatNavigationInfoMessage)[];
  filteredChatIDs: DConversationId[];
  filteredChatsCount: number;
  filteredChatsAreEmpty: boolean;
  filteredChatsBarBasis: number;
  filteredChatsIncludeActive: boolean;
}

interface ChatNavigationGroupData {
  type: 'nav-item-group',
  title: string,
}

interface ChatNavigationInfoMessage {
  type: 'nav-item-info-message',
  message: string,
}

export type ChatNavGrouping = false | 'date' | 'persona' | 'dimension';

export type ChatSearchSorting = 'frequency' | 'date';

export type ChatSearchDepth = 'titles' | 'content' | 'attachments';


function messageHasDocAttachmentFragments(message: DMessage): boolean {
  return message.fragments.some(fragment => isAttachmentFragment(fragment) && isDocPart(fragment.part));
}

function messageHasImageFragments(message: DMessage): boolean {
  return message.fragments.some(fragment => isContentOrAttachmentFragment(fragment) && isImageRefPart(fragment.part) /*&& fragment.part.dataRef.reftype === 'dblob'*/);
}

function messageHasStarredFragments(message: DMessage): boolean {
  return messageHasUserFlag(message, MESSAGE_FLAG_STARRED);
}

// Returns a string with the pane indices where the conversation is also open, or false if it's not
function findOpenInViewIndices(chatPanesConversationIds: DConversationId[], ourId: DConversationId): string | false {
  if (chatPanesConversationIds.length <= 1) return false;
  return chatPanesConversationIds.reduce((acc: string[], id, idx) => {
    if (id === ourId)
      acc.push((idx + 1).toString());
    return acc;
  }, []).join(', ') || false;
}

export function isDrawerSearching(filterByQuery: string): { isSearching: boolean, lcTextQuery: string } {
  const lcTextQuery = filterByQuery.trim().toLowerCase();
  return {
    isSearching: lcTextQuery.length >= SEARCH_MIN_CHARS,
    lcTextQuery,
  };
}


/*
 * Optimization: return a reduced version of the DConversation object for 'Drawer Items' purposes,
 * to avoid unnecessary re-renders on each new character typed by the assistant
 */
export function useChatDrawerRenderItems(
  activeConversationId: DConversationId | null,
  chatPanesConversationIds: DConversationId[],
  filterByQuery: string,
  activeFolder: DFolder | null,
  allFolders: DFolder[],
  filterHasStars: boolean,
  filterHasImageAssets: boolean,
  filterHasDocFragments: boolean,
  filterIsArchived: boolean,
  grouping: ChatNavGrouping,
  searchSorting: ChatSearchSorting,
  showRelativeSize: boolean,
  searchDepth: ChatSearchDepth,
): ChatDrawerRenderItems {

  // state
  const [_, setJustAMinuteCounter] = React.useState(0);

  // external state
  const openBeamConversationIds = useModuleBeamStore(state => state.openBeamConversationIds);


  // [effect] Refresh every minute because the `getTimeBucketEn` function uses the current time
  React.useEffect(() => {
    const interval = setInterval(() => setJustAMinuteCounter(c => c + 1), 60 * 1000);
    return () => clearInterval(interval);
  }, []);


  const stabilizeRenderItems = React.useRef<ChatDrawerRenderItems>(undefined);

  return useChatStore(({ conversations: convPreFilter }) => {

      // filter 0: archival status
      const conversations = filterIsArchived ? convPreFilter.filter(c => !!c.isArchived)
        : convPreFilter.filter(c => !c.isArchived);

      // filter 1: select all conversations or just the ones in the active folder
      const conversationsInFolder = !activeFolder ? conversations
        : conversations.filter(_c => activeFolder.conversationIds.includes(_c.id));

      // filter 2: preparation: lowercase the query
      const { isSearching, lcTextQuery } = isDrawerSearching(filterByQuery);

      // transform (the conversations into ChatNavigationItemData) + filter2 (if searching)
      const chatNavItems = conversationsInFolder
        .map((_c): ChatNavigationItemData | null => {

          // optimized reduction to find stars/images/docs/and lowercased text for search
          const messageCount = _c.messages.length;
          const messageFlags = new Set<DMessageUserFlag>();
          let lcMessageSearchText = '';
          let hasStars = false, hasImages = false, hasDocs = false;
          for (const _m of _c.messages) {
            _m.userFlags?.forEach(flag => messageFlags.add(flag));
            if (isSearching && searchDepth !== 'titles') {
              const messageText = messageFragmentsReduceText(_m.fragments, '\n', searchDepth !== 'attachments');
              if (messageText) lcMessageSearchText += messageText.toLowerCase() + '\n';
            }
            if (!hasStars && messageHasStarredFragments(_m)) hasStars = true;
            if (!hasImages && messageHasImageFragments(_m)) hasImages = true;
            if (!hasDocs && messageHasDocAttachmentFragments(_m)) hasDocs = true;
          }

          // filter for required attributes
          if ((filterHasStars && !hasStars) || (filterHasImageAssets && !hasImages) || (filterHasDocFragments && !hasDocs))
            return null;

          // rich properties
          const title = conversationTitle(_c);
          const isAlsoOpen = findOpenInViewIndices(chatPanesConversationIds, _c.id);

          // set the frequency counters if filtering is enabled
          let searchFrequency: number = 0;
          if (isSearching) {
            const titleFrequency = title.toLowerCase().split(lcTextQuery).length - 1;
            const messageFrequency = lcMessageSearchText.split(lcTextQuery).length - 1;
            searchFrequency = titleFrequency + messageFrequency;
            if (searchFrequency === 0) return null;
          }

          // union of message flags -> emoji string
          const userFlagsUnique = !messageFlags.size ? undefined
            : Array.from(messageFlags).map(messageUserFlagToEmoji).join('');

          // create the ChatNavigationData
          return {
            type: 'nav-item-chat-data',
            conversationId: _c.id,
            isActive: _c.id === activeConversationId,
            isAlsoOpen,
            isIncognito: !!_c._isIncognito,
            isEmpty: !messageCount && !_c.userTitle,
            title,
            isArchived: !!_c.isArchived,
            userSymbol: _c.userSymbol || undefined,
            userFlagsSummary: userFlagsUnique,
            containsDocAttachments: hasDocs && filterHasDocFragments, // special case: only show this icon when filtering - too many icons otherwise
            containsImageAssets: hasImages,
            folder: !allFolders.length
              ? undefined                             // don't show folder select if folders are disabled
              : _c.id === activeConversationId        // only show the folder for active conversation(s)
                ? allFolders.find(folder => folder.conversationIds.includes(_c.id)) ?? null
                : null,
            updatedAt: _c.updated || _c.created || 0,
            hasBeamOpen: !!openBeamConversationIds?.[_c.id],
            messageCount,
            beingGenerated: !!_c._abortController, // FIXME: when the AbortController is moved at the message level, derive the state in the conv
            systemPurposeId: _c.systemPurposeId,
            searchFrequency,
          };
        })
        .filter(item => !!item) as ChatNavigationItemData[];

      // check if the active conversation has an item in the list
      const filteredChatsIncludeActive = chatNavItems.some(_c => _c.conversationId === activeConversationId);


      // [sort by frequency, don't group] if there's a search query
      if (isSearching && searchSorting === 'frequency')
        chatNavItems.sort((a, b) => b.searchFrequency - a.searchFrequency);

      // Render List
      let renderNavItems: ChatDrawerRenderItems['renderNavItems'];

      // [search] add a header if searching
      if (isSearching) {

        // start growing the render array from the nav array
        renderNavItems = [...chatNavItems];

        // only prepend a 'Results' group if there are results
        if (chatNavItems.length)
          renderNavItems.unshift({
            type: 'nav-item-group',
            title: chatNavItems.length >= 10 ? `Search results (${chatNavItems.length})` : chatNavItems.length > 1 ? 'Search Results' : 'Search Result',
          });

      }
      // [grouping] group by date or persona
      else if (grouping) {

        switch (grouping) {
          // [grouping/date or persona]: sort by last updated
          case 'date':
          case 'persona':
            chatNavItems.sort((a, b) => b.updatedAt - a.updatedAt);
            break;
          // [grouping/dimension]: sort by message count
          case 'dimension':
            chatNavItems.sort((a, b) => b.messageCount - a.messageCount);
            break;
        }

        const midnightTime = getLocalMidnightInUTCTimestamp();
        const grouped = chatNavItems.reduce((acc, item) => {

          // derive the bucket name
          let bucket: string;
          switch (grouping) {
            case 'date':
              bucket = getTimeBucketEn(item.updatedAt || midnightTime, midnightTime);
              break;
            case 'persona':
              bucket = item.systemPurposeId;
              break;
            case 'dimension':
              if (item.messageCount > 20)
                bucket = 'Large chats';
              else if (item.messageCount > 10)
                bucket = 'Medium chats';
              else if (item.messageCount > 5)
                bucket = 'Small chats';
              else if (item.messageCount > 1)
                bucket = 'Tiny chats';
              else if (item.messageCount === 1)
                bucket = 'Single message';
              else
                bucket = 'Empty chats';
              break;
          }

          if (!acc[bucket])
            acc[bucket] = [];
          acc[bucket].push(item);
          return acc;
        }, {} as { [groupName: string]: ChatNavigationItemData[] });

        // prepend group names as special items
        renderNavItems = Object.entries(grouped).flatMap(([groupName, items]) => [
          { type: 'nav-item-group', title: groupName },
          ...items,
        ]);
      } else {

        // [no grouping & no searching] just render the chatNavItems
        // Note: we don't want to modify the original array, as we're including spurious objects for subsequent reduction functions
        renderNavItems = [...chatNavItems];

      }

      // [zero state] searching & filtering
      if (!renderNavItems.length) {
        renderNavItems.push({
          type: 'nav-item-info-message',
          message: (filterHasStars && (filterHasImageAssets || filterHasDocFragments)) ? 'No results'
            : filterHasDocFragments ? 'No attachment results'
              : filterHasImageAssets ? 'No image results'
                : filterHasStars ? 'No starred results'
                  : filterIsArchived ? 'No archived conversations'
                    : isSearching ? 'Text not found'
                      : 'No conversations in folder',
        });
      } else {
        // filtering reminder (will be rendered with a clear button too)
        if (filterHasStars || filterHasImageAssets || filterHasDocFragments || filterIsArchived) {
          renderNavItems.unshift({
            type: 'nav-item-info-message',
            message: `${filterIsArchived ? 'Showing' : 'Filtering by'} ${[
              filterHasStars && 'stars',
              filterHasImageAssets && 'images',
              filterHasDocFragments && 'attachments',
              filterIsArchived && 'archived',
            ].filter(Boolean).join(', ')}`,
          });
        }
      }

      // other derived state
      const filteredChatIDs = chatNavItems.map(_c => _c.conversationId);
      const filteredChatsCount = chatNavItems.length;
      const filteredChatsAreEmpty = !filteredChatsCount || (filteredChatsCount === 1 && chatNavItems[0].isEmpty);
      const filteredChatsBarBasis = !isSearching && (!showRelativeSize || filteredChatsCount < 2) ? 0
        : chatNavItems.reduce((longest, _c) => Math.max(longest, isSearching ? _c.searchFrequency : _c.messageCount), 1);

      // stabilize individual renderNavItems (only if in the same place)
      const prev = stabilizeRenderItems.current;
      // Update: we don't need this as <ChatDrawerItem> is already memoed
      // if (prev && renderNavItems.length === prev.renderNavItems.length)
      //   renderNavItems = renderNavItems.map((item, index) => {
      //     if (index < prev.renderNavItems.length && shallowEquals(item, prev.renderNavItems[index]))
      //       return prev.renderNavItems[index];
      //     return item;
      //   });

      // next state
      const next: ChatDrawerRenderItems = {
        renderNavItems,
        filteredChatIDs,
        filteredChatsCount,
        filteredChatsAreEmpty,
        filteredChatsBarBasis,
        filteredChatsIncludeActive,
      };

      // stabilize the render items
      if (prev
        && prev.renderNavItems.length === next.renderNavItems.length
        && prev.renderNavItems.every((_a, i) => shallowEquals(_a, next.renderNavItems[i]))
        && shallowEquals(prev.filteredChatIDs, next.filteredChatIDs)
        && prev.filteredChatsCount === next.filteredChatsCount
        && prev.filteredChatsAreEmpty === next.filteredChatsAreEmpty
        && prev.filteredChatsBarBasis === next.filteredChatsBarBasis
        && prev.filteredChatsIncludeActive === next.filteredChatsIncludeActive
      ) return prev;
      return stabilizeRenderItems.current = next;
    },
  );
}


================================================
FILE: src/apps/chat/components/layout-drawer/folders/AddFolderButton.tsx
================================================
import * as React from 'react';

import { ListItem, ListItemButton, ListItemDecorator } from '@mui/joy';
import AddIcon from '@mui/icons-material/Add';
import FolderIcon from '@mui/icons-material/Folder';

import { InlineTextarea } from '~/common/components/InlineTextarea';
import { getRotatingFolderColor, useFolderStore } from '~/common/stores/folders/store-chat-folders';


export function AddFolderButton() {

  // state
  const [isAddingFolder, setIsAddingFolder] = React.useState(false);
  const [newFolderColor, setNewFolderColor] = React.useState<string | null>(null);


  const handleAddFolder = () => {
    setNewFolderColor(getRotatingFolderColor());
    setIsAddingFolder(true);
  };

  const handleCreateFolder = (name: string) => {
    if (name.trim())
      useFolderStore.getState().createFolder(name.trim(), newFolderColor || undefined);
    setIsAddingFolder(false);
  };

  const handleCancelAddFolder = () => {
    setIsAddingFolder(false);
  };

  return isAddingFolder ? (
    <ListItem>
      <ListItemDecorator>
        <FolderIcon style={{ color: newFolderColor || 'inherit' }} />
      </ListItemDecorator>
      <InlineTextarea
        initialText=''
        placeholder='Folder Name'
        onEdit={handleCreateFolder}
        onCancel={handleCancelAddFolder}
        sx={{ ml: -1.5, mr: -0.5, flexGrow: 1, minWidth: 100 }}
      />
      {/*<IconButton color='danger' onClick={handleCancelAddFolder}>*/}
      {/*  <CloseRoundedIcon />*/}
      {/*</IconButton>*/}
    </ListItem>
  ) : (
    <ListItem>
      <ListItemButton
        onClick={handleAddFolder}
        sx={{
          // equal to the 'new chat' button
          fontSize: 'sm',
          fontWeight: 'lg',
          color: 'neutral.outlinedColor',
          border: 0,
        }}
      >
        <ListItemDecorator>
          <AddIcon sx={{ fontSize: 'xl', pl: '0.25rem' }} />
        </ListItemDecorator>
        New folder
      </ListItemButton>
    </ListItem>
  );
}



================================================
FILE: src/apps/chat/components/layout-drawer/folders/ChatFolderList.tsx
================================================
import * as React from 'react';
import { SortableContext, sortableKeyboardCoordinates, verticalListSortingStrategy } from '@dnd-kit/sortable';
import { closestCenter, DndContext, DragEndEvent, KeyboardSensor, PointerSensor, useSensor, useSensors } from '@dnd-kit/core';
import { restrictToParentElement, restrictToVerticalAxis } from '@dnd-kit/modifiers';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, List, ListItem, ListItemButton, ListItemDecorator } from '@mui/joy';
import FolderOpenOutlinedIcon from '@mui/icons-material/FolderOpenOutlined';
import FolderOutlinedIcon from '@mui/icons-material/FolderOutlined';

import { ContentScaling, themeScalingMap } from '~/common/app.theme';
import { DFolder, useFolderStore } from '~/common/stores/folders/store-chat-folders';

import { AddFolderButton } from './AddFolderButton';
import { FolderListItem } from './FolderListItem';


const _styles = {
  listBase: {

    // show scrollbars when shrunk
    height: '100%',
    overflowY: 'auto',

    // style
    // borderRadius: 'sm',
    backgroundColor: 'background.popup',
    boxShadow: 'sm',

    // original list properties
    '--List-gap': 0,
    '--List-radius': '0.5rem',
    '--ListDivider-gap': 0,

    // copied from the former PageDrawerList as this was contained
    '--Icon-fontSize': 'var(--joy-fontSize-xl2)',

    // override global variant tokens
    // '--joy-palette-neutral-plainHoverBg': 'rgba(0 0 0 / 0.08)',
    // '--joy-palette-neutral-plainActiveBg': 'rgba(0 0 0 / 0.12)',
    // [theme.getColorSchemeSelector('dark')]: {
    //   '--joy-palette-neutral-plainHoverBg': 'rgba(255 255 255 / 0.1)',
    //   '--joy-palette-neutral-plainActiveBg': 'rgba(255 255 255 / 0.16)',
    // },
  } as const,

  allItem: {
    border: 0,
  } as const,
} as const;

const _dndModifiers = [restrictToVerticalAxis, restrictToParentElement];


export function ChatFolderList(props: {
  folders: DFolder[];
  contentScaling: ContentScaling;
  activeFolderId: string | null;
  onFolderSelect: (folderId: string | null) => void;
  sx?: SxProps;
}) {

  // derived props
  const { folders, onFolderSelect, activeFolderId } = props;


  // DnD Kit
  const sensors = useSensors(
    useSensor(PointerSensor, {
      activationConstraint: { distance: 8 },
    }),
    useSensor(KeyboardSensor, {
      coordinateGetter: sortableKeyboardCoordinates,
    }),
  );


  // memos

  const folderIds = React.useMemo(() => {
    return folders.map(f => f.id);
  }, [folders]);

  const listSx = React.useMemo(() => ({
    ..._styles.listBase,
    ...themeScalingMap[props.contentScaling].chatDrawerItemFolderSx,
  }), [props.contentScaling]);


  // handlers

  const handleDragEnd = React.useCallback((event: DragEndEvent) => {
    const { active, over } = event;
    if (!over || active.id === over.id) return;
    const oldIndex = folderIds.findIndex(fId => fId === active.id);
    const newIndex = folderIds.findIndex(fId => fId === over.id);
    if (oldIndex !== -1 && newIndex !== -1)
      useFolderStore.getState().moveFolder(oldIndex, newIndex);
  }, [folderIds]);


  return (
    <Box sx={props.sx}>

      <List
        variant='plain'
        sx={listSx}
      >

        {/* 'All' Button */}
        <ListItem>
          <ListItemButton
            selected={!activeFolderId}
            onClick={(event) => {
              event.stopPropagation(); // Prevent the ListItemButton's onClick from firing
              onFolderSelect(null);
            }}
            sx={_styles.allItem}
          >
            <ListItemDecorator>{!activeFolderId ? <FolderOpenOutlinedIcon /> : <FolderOutlinedIcon />}</ListItemDecorator>
            All
          </ListItemButton>
        </ListItem>

        {/* Sortable folders */}
        <DndContext
          sensors={sensors}
          collisionDetection={closestCenter}
          onDragEnd={handleDragEnd}
          modifiers={_dndModifiers}
        >
          <SortableContext
            items={folderIds}
            strategy={verticalListSortingStrategy}
          >

            {/* Folder Items */}
            {folders.map((folder) => (
              <FolderListItem
                key={folder.id}
                folder={folder}
                isActive={folder.id === activeFolderId}
                onFolderSelect={onFolderSelect}
              />
            ))}

          </SortableContext>
        </DndContext>

        {/* 'Add Folder' Button */}
        <AddFolderButton />

      </List>
    </Box>
  );
}



================================================
FILE: src/apps/chat/components/layout-drawer/folders/FolderListItem.tsx
================================================
import * as React from 'react';
import { CSS } from '@dnd-kit/utilities';
import { useSortable } from '@dnd-kit/sortable';

import { FormLabel, IconButton, ListItem, ListItemButton, ListItemContent, ListItemDecorator, MenuItem, Radio, RadioGroup, Sheet } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import Done from '@mui/icons-material/Done';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import FolderIcon from '@mui/icons-material/Folder';
import MoreVertIcon from '@mui/icons-material/MoreVert';

import { CloseablePopup } from '~/common/components/CloseablePopup';
import { DFolder, FOLDERS_COLOR_PALETTE, useFolderStore } from '~/common/stores/folders/store-chat-folders';
import { InlineTextarea } from '~/common/components/InlineTextarea';
import { themeZIndexOverMobileDrawer } from '~/common/app.theme';


const _styles = {

  menuButton: {
    visibility: 'hidden',
  } as const,

  itemButton: {
    border: 0,
  } as const,

  itemTextArea: {
    ml: -1.5,
    mr: -0.5,
    flexGrow: 1,
  } as const,

} as const;


export function FolderListItem(props: {
  folder: DFolder;
  isActive: boolean;
  onFolderSelect: (folderId: string | null) => void;
}) {

  // props
  const { isActive, onFolderSelect } = props;
  const { id: folderId, color: folderColor, title: folderTitle } = props.folder;

  // state
  const [deleteArmed, setDeleteArmed] = React.useState(false);
  const [isEditing, setIsEditing] = React.useState(false);
  const [menuAnchorEl, setMenuAnchorEl] = React.useState<null | HTMLAnchorElement>(null);

  // DnD Kit sortable
  const {
    attributes,
    listeners,
    setNodeRef,
    transform,
    transition,
    isDragging,
  } = useSortable({ id: folderId });


  // handlers

  const handleFolderActivate = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    onFolderSelect(folderId);
  }, [folderId, onFolderSelect]);


  // menu handlers

  const handleMenuToggle = React.useCallback((event: React.MouseEvent<HTMLAnchorElement>) => {
    event.preventDefault(); // added for the Right mouse click (to prevent the menu)
    event.stopPropagation(); // keep the focus on the menu that's opening
    setDeleteArmed(false); // Reset delete armed state
    setMenuAnchorEl(anchor => anchor ? null : event.currentTarget);
  }, []);

  const handleMenuClose = React.useCallback(() => setMenuAnchorEl(null), []);


  // Edit Title

  const handleEditTitle = React.useCallback((event: React.MouseEvent<HTMLElement, MouseEvent>) => {
    event.stopPropagation(); // Prevent the ListItemButton's onClick from firing
    setIsEditing(true);
  }, []);

  const handleCancelEditTitle = React.useCallback(() => setIsEditing(false), []);

  const handleSetTitle = React.useCallback((newTitle: string, folderId: string) => {
    if (newTitle.trim())
      useFolderStore.getState().setFolderName(folderId, newTitle.trim());
    setIsEditing(false); // Exit edit mode
    // Blur the input element if it's currently focused
    if (document.activeElement instanceof HTMLElement) {
      document.activeElement.blur();
    }
  }, []);


  // Deletion

  const handleDeleteButtonShow = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    setDeleteArmed(true);
  }, []);

  const handleDeleteConfirmed = React.useCallback((event: React.MouseEvent) => {
    if (!deleteArmed) return;
    setDeleteArmed(false);
    event.stopPropagation();
    useFolderStore.getState().deleteFolder(folderId);
    handleMenuClose();
  }, [deleteArmed, folderId, handleMenuClose]);

  const handleDeleteCanceled = React.useCallback((event: React.MouseEvent) => {
    if (!deleteArmed) return;
    setDeleteArmed(false);
    event.stopPropagation();
  }, [deleteArmed]);


  // Color

  const handleColorChange = React.useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    useFolderStore.getState().setFolderColor(folderId, event.target.value);
    handleMenuClose();
  }, [folderId, handleMenuClose]);


  return (
    <ListItem
      ref={setNodeRef}
      sx={{
        transform: CSS.Transform.toString(transform),
        transition,
        userSelect: 'none',
        zIndex: isDragging ? 1 : undefined,

        // shows the menu icon on hover
        '&:hover .menu-icon': {
          visibility: 'visible',
        },
      }}
      endAction={!isEditing &&
        <IconButton
          size='sm'
          // variant='plain'
          onClick={handleMenuToggle}
          onContextMenu={handleMenuToggle}
          sx={!isActive ? _styles.menuButton : undefined}
          className='menu-icon'
        >
          <MoreVertIcon />
        </IconButton>
      }
    >
      <ListItemButton
        {...attributes}
        {...listeners}
        selected={isActive}
        onClick={handleFolderActivate}
        sx={_styles.itemButton}
      >
        <ListItemDecorator>
          <FolderIcon style={{ color: folderColor || 'inherit' }} />
        </ListItemDecorator>

        {isEditing ? (
          <InlineTextarea
            initialText={folderTitle}
            onEdit={newTitle => handleSetTitle(newTitle, folderId)}
            onCancel={handleCancelEditTitle}
            sx={_styles.itemTextArea}
          />
        ) : (
          <ListItemContent onDoubleClick={handleEditTitle}>
            {folderTitle}
          </ListItemContent>
        )}

        {/* Folder Options Menu */}
        {!!menuAnchorEl && (
          <CloseablePopup
            menu anchorEl={menuAnchorEl} onClose={handleMenuClose}
            dense
            placement='top'
            zIndex={themeZIndexOverMobileDrawer /* need to be on top of the Modal on Mobile */}
          >

            <MenuItem
              onClick={(event) => {
                handleEditTitle(event);
                handleMenuClose();
              }}
            >
              <ListItemDecorator>
                <EditRoundedIcon />
              </ListItemDecorator>
              Edit
            </MenuItem>

            {!deleteArmed ? (
              <MenuItem onClick={handleDeleteButtonShow}>
                <ListItemDecorator>
                  <DeleteOutlineIcon />
                </ListItemDecorator>
                Delete
              </MenuItem>
            ) : (
              <>
                <MenuItem onClick={handleDeleteCanceled}>
                  <ListItemDecorator>
                    <CloseRoundedIcon />
                  </ListItemDecorator>
                  Cancel
                </MenuItem>
                <MenuItem onClick={handleDeleteConfirmed} color='danger' sx={{ color: 'danger' }}>
                  <ListItemDecorator>
                    <DeleteOutlineIcon />
                  </ListItemDecorator>
                  Confirm Deletion
                </MenuItem>
              </>
            )}

            <MenuItem
              sx={{
                display: 'flex',
                flexDirection: 'column',
                alignItems: 'flex-start',
                p: 2,
                minWidth: 200,
              }}
            >
              <FormLabel
                id='folder-color'
                sx={{
                  mb: 1.5,
                  fontSize: 'xs',
                  fontWeight: 'xl', /* 700: this COLOR labels stands out positively */
                  letterSpacing: '0.1em',
                  textTransform: 'uppercase',
                }}
              >
                Color
              </FormLabel>
              <RadioGroup
                aria-labelledby='product-color-attribute'
                defaultValue={folderColor || 'warning'}
                onChange={handleColorChange}
                sx={{ gap: 2, flexWrap: 'wrap', flexDirection: 'row', maxWidth: 240 }}
              >
                {FOLDERS_COLOR_PALETTE.map((color, index) => (
                  <Sheet
                    key={index}
                    sx={{
                      position: 'relative',
                      width: 20,
                      height: 20,
                      flexShrink: 0,
                      bgcolor: `${color}`,
                      borderRadius: '50%',
                      display: 'flex',
                      alignItems: 'center',
                      justifyContent: 'center',
                    }}
                  >
                    <Radio
                      overlay
                      variant='solid'
                      checkedIcon={<Done />}
                      value={color}
                      color='neutral'
                      slotProps={{
                        input: { 'aria-label': color },
                        radio: {
                          sx: {
                            display: 'contents',
                            // '--variant-borderWidth': '2px',
                          },
                        },
                      }}
                      // sx={{
                      //   '--joy-focus-outlineOffset': '4px',
                      //   '--joy-palette-focusVisible': color,
                      //   [`& .${radioClasses.action}.${radioClasses.focusVisible}`]: {
                      //     outlineWidth: '2px',
                      //   },
                      // }}
                    />
                  </Sheet>
                ))}
              </RadioGroup>
            </MenuItem>

          </CloseablePopup>
        )}

      </ListItemButton>
    </ListItem>
  );
}



================================================
FILE: src/apps/chat/components/layout-pane/ChatPane.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Box, Checkbox, IconButton, ListItem, ListItemButton, ListItemDecorator, MenuItem, Switch, Tooltip, Typography } from '@mui/joy';
import AddIcon from '@mui/icons-material/Add';
import ArchiveOutlinedIcon from '@mui/icons-material/ArchiveOutlined';
import CleaningServicesOutlinedIcon from '@mui/icons-material/CleaningServicesOutlined';
import CompressIcon from '@mui/icons-material/Compress';
import EngineeringIcon from '@mui/icons-material/Engineering';
import ForkRightIcon from '@mui/icons-material/ForkRight';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';
import RestartAltIcon from '@mui/icons-material/RestartAlt';
import SettingsSuggestOutlinedIcon from '@mui/icons-material/SettingsSuggestOutlined';
import UnarchiveOutlinedIcon from '@mui/icons-material/UnarchiveOutlined';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { CodiconSplitHorizontal } from '~/common/components/icons/CodiconSplitHorizontal';
import { CodiconSplitHorizontalRemove } from '~/common/components/icons/CodiconSplitHorizontalRemove';
import { CodiconSplitVertical } from '~/common/components/icons/CodiconSplitVertical';
import { CodiconSplitVerticalRemove } from '~/common/components/icons/CodiconSplitVerticalRemove';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { OptimaPanelGroupedList, OptimaPanelGroupGutter } from '~/common/layout/optima/panel/OptimaPanelGroupedList';
import { optimaActions } from '~/common/layout/optima/useOptima';
import { useChatStore } from '~/common/stores/chat/store-chats'; // may be replaced with a dedicated hook for the chat pane
import { useLabsDevMode } from '~/common/stores/store-ux-labs';

import { useChatShowSystemMessages } from '../../store-app-chat';
import { panesManagerActions, usePaneDuplicateOrClose } from '../panes/store-panes-manager';


function VariformPaneFrame() {
  return (
    <OptimaPanelGroupGutter>
      <Typography level='body-sm'>
        To add variables within messages, please use the <Box component='span' sx={{ fontWeight: 600 }}>{'{{'}variable_name{'}}'}</Box> syntax.
      </Typography>
    </OptimaPanelGroupGutter>
  );
}


export function ChatPane(props: {
  conversationId: DConversationId | null,
  disableItems: boolean,
  hasConversations: boolean,
  isMessageSelectionMode: boolean,
  isVerticalSplit: boolean,
  onConversationBranch: (conversationId: DConversationId, messageId: string | null, addSplitPane: boolean) => void,
  onConversationClear: (conversationId: DConversationId) => void,
  onConversationFlatten: (conversationId: DConversationId) => void,
  // onConversationNew: (forceNoRecycle: boolean) => void,
  setIsMessageSelectionMode: (isMessageSelectionMode: boolean) => void,
}): React.ReactNode {

  // external state
  const { canAddPane, isMultiPane } = usePaneDuplicateOrClose();
  const [showSystemMessages, setShowSystemMessages] = useChatShowSystemMessages();
  const labsDevMode = useLabsDevMode();

  const { isArchived, setArchived } = useChatStore(useShallow((state) => {
    const conversation = state.conversations.find(_c => _c.id === props.conversationId);
    return {
      isArchived: !conversation ? undefined : !!conversation.isArchived,
      setArchived: state.setArchived,
    };
  }));


  // Window

  const handleIncreaseMultiPane = React.useCallback((event?: React.MouseEvent) => {
    event?.stopPropagation();

    // create a new pane with the current conversation
    // duplicateFocusedPane();

    // create a new empty pane
    panesManagerActions().insertEmptyAfterFocusedPane(true);

    // load a brand new conversation inside
    // FIXME: still testing this
    // props.onConversationNew(true);
  }, []);

  const handleToggleMultiPane = React.useCallback((_event: React.MouseEvent) => {
    if (isMultiPane)
      panesManagerActions().removeNonFocusedPanes();
    else
      handleIncreaseMultiPane(undefined);
  }, [handleIncreaseMultiPane, isMultiPane]);


  // Actions

  const handleConversationRestart = (event: React.MouseEvent<HTMLDivElement>) => {
    props.conversationId && props.onConversationClear(props.conversationId);
  };

  const handleConversationBranch = (event: React.MouseEvent<HTMLDivElement>) => {
    props.conversationId && props.onConversationBranch(props.conversationId, null, true);
  };

  const handleConversationFlatten = (event: React.MouseEvent<HTMLElement>) => {
    props.conversationId && props.onConversationFlatten(props.conversationId);
  };

  const handleToggleMessageSelectionMode = (event: React.MouseEvent) => {
    props.setIsMessageSelectionMode(!props.isMessageSelectionMode);
  };

  const handleToggleArchive = React.useCallback(() => {
    if (!props.conversationId || !setArchived) return;
    setArchived(props.conversationId, !isArchived);
  }, [isArchived, props.conversationId, setArchived]);

  const handleToggleSystemMessages = () => setShowSystemMessages(!showSystemMessages);


  return <>

    {/* Window group */}
    <OptimaPanelGroupedList title='Window'>

      <ListItem
        endAction={!isMultiPane ? undefined : (
          <Tooltip title='Add Another Split'>
            <IconButton
              size='sm'
              variant='outlined'
              disabled={!canAddPane}
              onClick={handleIncreaseMultiPane}
              sx={{ ml: 'auto', /*mr: '2px',*/ my: '-0.25rem' /* absorb the menuItem padding */ }}
            >
              <AddIcon />
            </IconButton>
          </Tooltip>
        )}
      >
        <ListItemButton onClick={handleToggleMultiPane}>
          <ListItemDecorator>{props.isVerticalSplit
            ? (isMultiPane ? <CodiconSplitVerticalRemove /> : <CodiconSplitVertical />)
            : (isMultiPane ? <CodiconSplitHorizontalRemove /> : <CodiconSplitHorizontal />)
          }</ListItemDecorator>
          {props.isVerticalSplit
            ? (isMultiPane ? 'Unsplit' : 'Split Down')
            : (isMultiPane ? 'Unsplit' : 'Split Right')}
        </ListItemButton>
      </ListItem>

    </OptimaPanelGroupedList>

    {/* Chat Actions group */}
    <OptimaPanelGroupedList title='Actions'>
      {/* Use 2 columns */}
      <Box sx={{ display: 'grid', gridTemplateColumns: '1fr 1fr' }}>

        {/* Left column */}
        <Box sx={{ display: 'flex', flexDirection: 'column' }}>

          <MenuItem disabled={props.disableItems} onClick={handleToggleArchive}>
            <ListItemDecorator>{isArchived ? <UnarchiveOutlinedIcon /> : <ArchiveOutlinedIcon />}</ListItemDecorator>
            {isArchived ? <b>Unarchive</b> : 'Archive'}
          </MenuItem>

          <MenuItem disabled={props.disableItems} onClick={handleConversationBranch}>
            <ListItemDecorator><ForkRightIcon /></ListItemDecorator>
            Branch
          </MenuItem>

        </Box>

        {/* Right column */}
        <Box sx={{ display: 'flex', flexDirection: 'column' }}>

          <MenuItem disabled={props.disableItems} onClick={handleConversationFlatten}>
            <ListItemDecorator><CompressIcon /></ListItemDecorator>
            Compact
          </MenuItem>

          <MenuItem disabled={props.disableItems} onClick={handleConversationRestart}>
            <ListItemDecorator><RestartAltIcon /></ListItemDecorator>
            <Box sx={{ flexGrow: 1, display: 'flex', justifyContent: 'space-between', gap: 1 }}>
              Restart
              {/*{!props.disableItems && <KeyStroke combo='Ctrl + Shift + X' />}*/}
            </Box>
          </MenuItem>

        </Box>
      </Box>

      {/* Spans both columns */}
      <MenuItem
        disabled={props.disableItems}
        color={props.isMessageSelectionMode ? 'warning' : 'neutral'}
        variant={props.isMessageSelectionMode ? 'solid' : 'plain'}
        onClick={handleToggleMessageSelectionMode}
        sx={props.isMessageSelectionMode ? { fontWeight: 'lg' } : {}}
      >
        <ListItemDecorator>{!props.isMessageSelectionMode ? <CleaningServicesOutlinedIcon /> : <Checkbox size='md' color='warning' variant='plain' checked />}</ListItemDecorator>
        Cleanup
      </MenuItem>

    </OptimaPanelGroupedList>

    {/* ... how do we name this? ... */}
    <OptimaPanelGroupedList title='Persona'>
      <ListItemButton disabled={props.disableItems} onClick={handleToggleSystemMessages}>
        <ListItemDecorator><SettingsSuggestOutlinedIcon /></ListItemDecorator>
        Show Instruction
        {/*<FormLabelStart title='View System Instruction' />*/}
        <Switch size='sm' checked={showSystemMessages} disabled={props.disableItems} onChange={handleToggleSystemMessages} sx={{ ml: 'auto' }} />
        {/*<Checkbox size='md' checked={showSystemMessages} disabled={props.disableItems} sx={{ ml: 'auto' }} />*/}
      </ListItemButton>
    </OptimaPanelGroupedList>

    {/* [DEV] Development */}
    {labsDevMode && (
      <OptimaPanelGroupedList title='[Developers]'>
        <MenuItem onClick={optimaActions().openAIXDebugger}>
          <ListItemDecorator><EngineeringIcon /></ListItemDecorator>
          AIX: Show Last Request...
        </MenuItem>
      </OptimaPanelGroupedList>
    )}

  </>;
}


================================================
FILE: src/apps/chat/components/message/BlockOpContinue.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Chip, ColorPaletteProp } from '@mui/joy';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';


// configuration
const ACTIVE_COLOR: ColorPaletteProp = 'warning';


const containerSx: SxProps = {
  marginInlineStart: 1.5,
  backgroundColor: `${ACTIVE_COLOR}.softBg`,
  borderRadius: 'lg',
  // boxShadow: 'xs',
  // p: 0.25,

  // layout
  display: 'flex',
  alignItems: 'center',
  gap: 1,
};

const chipSx: SxProps = {
  px: 2,
};


export function BlockOpContinue(props: {
  contentScaling: ContentScaling,
  messageRole: DMessageRole,
  onContinue: (continueText: null | string) => void,
}) {

  return (
    <Box sx={containerSx}>

      <ScaledTextBlockRenderer
        text='🧱 Token limit hit.'
        contentScaling={props.contentScaling}
        textRenderVariant='text'
        // showAsItalic
      />

      <Chip
        color={ACTIVE_COLOR}
        variant='outlined'
        size={props.contentScaling === 'md' ? 'lg' : 'md'}
        onClick={() => props.onContinue(null)}
        sx={chipSx}
      >
        Continue...
      </Chip>

    </Box>
  );
}


================================================
FILE: src/apps/chat/components/message/BlockOpOptions.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ColorPaletteProp } from '@mui/joy';

import type { ContentScaling } from '~/common/app.theme';
import { DMessageContentFragment, DMessageTextPart, isTextContentFragment } from '~/common/stores/chat/chat.fragments';


// configuration
const OPTION_ACTIVE_COLOR: ColorPaletteProp = 'neutral';
const OPTION_DEBUG_PARSER = false;
const OPTION_MAX_LENGTH = 100;
const OPTION_MAX_OPTIONS = 8;
const OPTION_MIN_OPTIONS = 2;

/*
const containerSx: SxProps = {
  marginInlineStart: 1.5,
  // backgroundColor: `${OPTION_ACTIVE_COLOR}.softBg`,
  // borderRadius: 'lg',
  // p: 1,

  // layout
  // display: 'flex',
  // flexDirection: 'column',
  // gap: 1,
};
*/
const optionGroupSx: SxProps = {
  marginInlineStart: 1.5,

  // flex: 1,
  display: 'flex',
  flexDirection: 'column',
  alignItems: 'flex-start',
  gap: 0,
};

const optionSx: SxProps = {
  // style
  fontWeight: 'normal',
  // px: 1.5,
  py: 0.5,
  minHeight: '1rem',
  color: 'text.primary',
  // borderRadius: 'sm',
  borderRadius: '1rem',
  // width: '100%',
  textAlign: 'inherit',

  // layout
  justifyContent: 'flex-start',
};


export function optionsExtractFromFragments_dangerModifyFragment(enabled: boolean, fragments: DMessageContentFragment[]): { fragments: DMessageContentFragment[], options: string[], } {
  if (enabled && fragments.length) {
    const fragment = fragments[fragments.length - 1];
    if (isTextContentFragment(fragment)) {
      const parsed = _parseOptionsFromText(fragment.part.text);
      if (parsed) {
        return {
          fragments: [...fragments.slice(0, fragments.length - 1), {
            ...fragment,
            part: {
              ...fragment.part,
              text: parsed.beforeText,
            } satisfies DMessageTextPart,
          }],
          options: parsed.options,
        };
      }
    }
  }
  return { fragments: fragments, options: [] };
}


const debugParser = (...args: any[]) => console.log('[DEV] parseOptions:', ...args);

/**
 * Hand rolled parser to extract options from a text string.
 * We check if the string is followed by '- ...' or '1. ...' list items.
 * We also check if the former string ends with ':' or '?', which indicates the start of an option list.
 * If any condition is not met, we abort parsing.
 */
function _parseOptionsFromText(text: string): { beforeText: string; options: string[] } | null {

  const options: string[] = [];
  let remainingText = text.trimEnd();
  let inOL = false;
  let inUL = false;
  let nlCount = 0;

  while (true) {

    // get the last line of text (-1 is okay, as it's the last line)
    const prevNewlineIdx = remainingText.lastIndexOf('\n');
    const chunk = remainingText.slice(prevNewlineIdx + 1);

    // check if it's a list item
    if (chunk.startsWith('- ') || chunk.startsWith('* ') || chunk.startsWith('+ ') || chunk.startsWith('• ')) {
      if (inOL) {
        if (OPTION_DEBUG_PARSER) debugParser('switched from OL to UL (end)');
        return null;
      }
      inUL = true;
      nlCount = 0;
      if (chunk.length > OPTION_MAX_LENGTH) {
        if (OPTION_DEBUG_PARSER) debugParser('UL option too long (end)');
        return null;
      }
      // only for UL we want to remove the list marker
      options.unshift(chunk.slice(2));
    } else if (/^\d+\.\s/.test(chunk)) {
      if (inUL) {
        if (OPTION_DEBUG_PARSER) debugParser('switched from UL to OL (end)');
        return null;
      }
      inOL = true;
      nlCount = 0;
      if (chunk.length > OPTION_MAX_LENGTH) {
        if (OPTION_DEBUG_PARSER) debugParser('OL option too long (end)');
        return null;
      }
      options.unshift(chunk);
    } else if (chunk.trim() === '') {
      nlCount++;
      if (nlCount > 1) {
        if (OPTION_DEBUG_PARSER) debugParser('two newlines (end)');
        return null;
      }
    } else if (remainingText.endsWith(':') || remainingText.endsWith('?') /*|| remainingText.endsWith('.')*/) {
      if (options.length >= OPTION_MIN_OPTIONS) {
        if (OPTION_DEBUG_PARSER) debugParser('found options (end)', remainingText);
        return { beforeText: remainingText, options };
      }
      if (OPTION_DEBUG_PARSER) debugParser('not enough options (end)');
      return null;
    } else {
      if (OPTION_DEBUG_PARSER) debugParser('not a list item (end)');
      return null;
    }

    // end when too many options
    if (options.length > OPTION_MAX_OPTIONS) {
      if (OPTION_DEBUG_PARSER) debugParser('too many options (end)');
      return null;
    }

    if (prevNewlineIdx === -1) {
      if (OPTION_DEBUG_PARSER) debugParser('no more newlines (end)');
      return null;
    }
    remainingText = remainingText.slice(0, prevNewlineIdx);
    if (OPTION_DEBUG_PARSER) debugParser({ prevNewlineIdx, chunk, remainingText });
  }
}

export function BlockOpOptions(props: {
  contentScaling: ContentScaling,
  options: string[],
  onContinue: (continueText: null | string) => void,
}) {
  const buttonSx = React.useMemo(() => ({ ...optionSx, fontSize: props.contentScaling }), [props.contentScaling]);
  return (
    <Box sx={optionGroupSx}>
      {props.options.map((option, index) => (
        <Button
          key={index}
          color={OPTION_ACTIVE_COLOR}
          variant='soft'
          size={props.contentScaling === 'md' ? 'md' : 'sm'}
          onClick={() => props.onContinue(option.endsWith('?') ? option.slice(0, -1) : option)}
          sx={buttonSx}
        >
          {option}
        </Button>
      ))}
    </Box>
  );
}


// PARSER TESTING
/*
const createFragment = (text: string): DMessageFragment => createTextContentFragment(text);

const runTest = (input: string, expectedBeforeText: string | null, expectedOptions: string[]) => {
  const fragments = [createFragment(input)];
  const { renderContentOrVoidFragments, renderOptions } = optionsExtractFromFragments_dangerModifyFragment(true, fragments);

  if (!expectedBeforeText) {
    // expect no parsing/modification
    assert.deepStrictEqual(renderContentOrVoidFragments, fragments);
    assert.deepStrictEqual(renderOptions, []);
    return;
  }

  // expect successful parsing
  assert.strictEqual(((renderContentOrVoidFragments[0] as DMessageContentFragment).part as any).text, expectedBeforeText);
  assert.deepStrictEqual(renderOptions, expectedOptions);
};

describe('Options Parser', () => {

  describe('Basic Functionality', () => {
    it('should not parse when disabled', () => {
      const fragments = [createFragment('Choose:\n1. Option A\n2. Option B')];
      const result = optionsExtractFromFragments_dangerModifyFragment(false, fragments);
      assert.deepStrictEqual(result.renderContentOrVoidFragments, fragments);
      assert.deepStrictEqual(result.renderOptions, []);
    });

    it('should handle empty fragments', () => {
      const result = optionsExtractFromFragments_dangerModifyFragment(true, []);
      assert.deepStrictEqual(result.renderContentOrVoidFragments, []);
      assert.deepStrictEqual(result.renderOptions, []);
    });
  });

  describe('Unordered Lists', () => {
    it('should parse simple unordered list', () => {
      runTest(
        'Choose one:\n- Option A\n- Option B\n- Option C',
        'Choose one:',
        ['Option A', 'Option B', 'Option C'],
      );
    });

    it('should parse with asterisks', () => {
      runTest(
        'Pick one:\n* First\n* Second',
        'Pick one:',
        ['First', 'Second'],
      );
    });

    it('should parse with plus signs', () => {
      runTest(
        'Select:\n+ One\n+ Two',
        'Select:',
        ['One', 'Two'],
      );
    });

    it('should fail on mixed list markers', () => {
      runTest(
        'Choose:\n- First\n1. Second',
        null,
        [],
      );
    });
  });

  describe('Ordered Lists', () => {
    it('should parse simple ordered list', () => {
      runTest(
        'Select one:\n1. First option\n2. Second option',
        'Select one:',
        ['1. First option', '2. Second option'],
      );
    });

    it('should handle non-sequential numbers', () => {
      runTest(
        'Pick:\n1. First\n3. Third',
        'Pick:',
        ['1. First', '3. Third'],
      );
    });
  });

  describe('List Requirements', () => {
    it('should require minimum options', () => {
      runTest(
        'Choose:\n- Just one option',
        null,
        [],
      );
    });

    it('should limit maximum options', () => {
      runTest(
        'Many:\n- One\n- Two\n- Three\n- Four\n- Five\n- Six',
        null,
        [],
      );
    });

    it('should require prompt ending with : or ?', () => {
      runTest(
        'Options\n- One\n- Two',
        null,
        [],
      );
    });

    it('should accept question mark ending', () => {
      runTest(
        'Which one?\n- Option A\n- Option B',
        'Which one?',
        ['Option A', 'Option B'],
      );
    });
  });

  describe('Formatting Rules', () => {
    it('should handle extra whitespace', () => {
      runTest(
        'Choose:\n\n- Option A\n\n- Option B',
        'Choose:',
        ['Option A', 'Option B'],
      );
    });

    it('should reject options exceeding length limit', () => {
      runTest(
        'Pick:\n- ' + 'A'.repeat(101),
        null,
        [],
      );
    });

    it('should maintain original text when no list found', () => {
      const text = 'Just a regular message without options';
      runTest(text, null, []);
    });
  });

  describe('Mixed Content', () => {
    it('should handle text before options', () => {
      runTest(
        'This is a long explanation.\nHere are your choices:\n- Option A\n- Option B',
        'This is a long explanation.\nHere are your choices:',
        ['Option A', 'Option B'],
      );
    });

    it('should reject mixed list types', () => {
      runTest(
        'Choose:\n1. First\n- Second',
        null,
        [],
      );
    });
  });

  describe('Edge Cases', () => {
    it('should handle empty input', () => runTest('', null, []));
    it('should handle empty input', () => runTest('\n', null, []));
    it('should handle empty input', () => runTest('\n\n', null, []));
    it('should handle empty input', () => runTest('\na\n', null, []));
    it('should handle empty input', () => runTest('a\n\n', null, []));
    it('should handle empty input', () => runTest('\n\na', null, []));
    it('should handle empty input', () => runTest('\na', null, []));
    it('should handle empty input', () => runTest('a', null, []));
    it('should handle empty input', () => runTest('test:\n- aa', null, []));

    it('should handle empty options', () => {
      runTest(
        'Choose:\n- \n- ',
        null,
        [],
      );
    });

    it('should handle single character options', () => {
      runTest(
        'Pick:\n- A\n- B',
        'Pick:',
        ['A', 'B'],
      );
    });

    it('should handle options with special characters', () => {
      runTest(
        'Select:\n- Option #1!\n- Option @2?',
        'Select:',
        ['Option #1!', 'Option @2?'],
      );
    });
  });

});
*/


================================================
FILE: src/apps/chat/components/message/ChatMessage.styles.ts
================================================
import type { SxProps } from '@mui/joy/styles/types';

import { animationColorRainbow } from '~/common/util/animUtils';


export const messageAsideColumnSx: SxProps = {
  // make this stick to the top of the screen
  position: 'sticky',
  top: '0.25rem',

  // style
  // filter: 'url(#agi-holographic)',

  // flexBasis: 0, // this won't let the item grow
  minWidth: { xs: 50, md: 64 },
  maxWidth: 80,
  textAlign: 'center',
  // layout
  display: 'flex',
  flexDirection: 'column',
  alignItems: 'center',
  gap: 0.25, // 2024-08-24: added, space the avatar icon from the label

  // when with the 'edit-button' class
  '&.msg-edit-button': {
    gap: 0.25,
  },
};

export const messageZenAsideColumnSx: SxProps = {
  ...messageAsideColumnSx,
  minWidth: undefined,
  maxWidth: undefined,
  mx: -1,
};

export const messageAvatarLabelSx: SxProps = {
  overflowWrap: 'anywhere',
};

export const messageAvatarLabelAnimatedSx: SxProps = {
  animation: `${animationColorRainbow} 5s linear infinite`,
  // Extra hinting... but looks weird
  // fontStyle: 'italic',
};



================================================
FILE: src/apps/chat/components/message/ChatMessage.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';
import TimeAgo from 'react-timeago';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, ButtonGroup, CircularProgress, Divider, IconButton, ListDivider, ListItem, ListItemDecorator, MenuItem, Switch, Tooltip, Typography } from '@mui/joy';
import { ClickAwayListener, Popper } from '@mui/base';
import AccountTreeOutlinedIcon from '@mui/icons-material/AccountTreeOutlined';
import AlternateEmailIcon from '@mui/icons-material/AlternateEmail';
import CheckRoundedIcon from '@mui/icons-material/CheckRounded';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import ContentCutIcon from '@mui/icons-material/ContentCut';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import DifferenceIcon from '@mui/icons-material/Difference';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import ForkRightIcon from '@mui/icons-material/ForkRight';
import FormatBoldIcon from '@mui/icons-material/FormatBold';
import FormatPaintOutlinedIcon from '@mui/icons-material/FormatPaintOutlined';
import InsertLinkIcon from '@mui/icons-material/InsertLink';
import MoreVertIcon from '@mui/icons-material/MoreVert';
import NotificationsActiveIcon from '@mui/icons-material/NotificationsActive';
import NotificationsOutlinedIcon from '@mui/icons-material/NotificationsOutlined';
import RecordVoiceOverOutlinedIcon from '@mui/icons-material/RecordVoiceOverOutlined';
import ReplayIcon from '@mui/icons-material/Replay';
import ReplyAllRoundedIcon from '@mui/icons-material/ReplyAllRounded';
import ReplyRoundedIcon from '@mui/icons-material/ReplyRounded';
import StrikethroughSIcon from '@mui/icons-material/StrikethroughS';
import TelegramIcon from '@mui/icons-material/Telegram';
import TextureIcon from '@mui/icons-material/Texture';
import VerticalAlignBottomIcon from '@mui/icons-material/VerticalAlignBottom';
import VisibilityIcon from '@mui/icons-material/Visibility';
import VisibilityOffIcon from '@mui/icons-material/VisibilityOff';

import { ModelVendorAnthropic } from '~/modules/llms/vendors/anthropic/anthropic.vendor';

import { AnthropicIcon } from '~/common/components/icons/vendors/AnthropicIcon';
import { ChatBeamIcon } from '~/common/components/icons/ChatBeamIcon';
import { CloseablePopup } from '~/common/components/CloseablePopup';
import { DMessage, DMessageId, DMessageUserFlag, DMetaReferenceItem, MESSAGE_FLAG_AIX_SKIP, MESSAGE_FLAG_NOTIFY_COMPLETE, MESSAGE_FLAG_STARRED, MESSAGE_FLAG_VND_ANT_CACHE_AUTO, MESSAGE_FLAG_VND_ANT_CACHE_USER, messageFragmentsReduceText, messageHasUserFlag } from '~/common/stores/chat/chat.message';
import { KeyStroke } from '~/common/components/KeyStroke';
import { MarkHighlightIcon } from '~/common/components/icons/MarkHighlightIcon';
import { Release } from '~/common/app.release';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { adjustContentScaling, themeScalingMap, themeZIndexChatBubble } from '~/common/app.theme';
import { avatarIconSx, makeMessageAvatarIcon, messageBackground, useMessageAvatarLabel } from '~/common/util/dMessageUtils';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { createTextContentFragment, DMessageFragment, DMessageFragmentId, updateFragmentWithEditedText } from '~/common/stores/chat/chat.fragments';
import { useFragmentBuckets } from '~/common/stores/chat/hooks/useFragmentBuckets';
import { useUIPreferencesStore } from '~/common/stores/store-ui';
import { useUXLabsStore } from '~/common/stores/store-ux-labs';

import { BlockOpContinue } from './BlockOpContinue';
import { BlockOpOptions, optionsExtractFromFragments_dangerModifyFragment } from './BlockOpOptions';
import { ContentFragments } from './fragments-content/ContentFragments';
import { DocumentAttachmentFragments } from './fragments-attachment-doc/DocumentAttachmentFragments';
import { ImageAttachmentFragments } from './fragments-attachment-image/ImageAttachmentFragments';
import { InReferenceToList } from './in-reference-to/InReferenceToList';
import { VoidFragments } from './fragments-void/VoidFragments';
import { messageAsideColumnSx, messageAvatarLabelAnimatedSx, messageAvatarLabelSx, messageZenAsideColumnSx } from './ChatMessage.styles';
import { setIsNotificationEnabledForModel, useChatShowTextDiff } from '../../store-app-chat';
import { useSelHighlighterMemo } from './useSelHighlighterMemo';


// Enable the menu on text selection
const ENABLE_CONTEXT_MENU = false;
const ENABLE_BUBBLE = true;
export const BUBBLE_MIN_TEXT_LENGTH = 3;

// Enable the hover button to copy the whole message. The Copy button is also available in Blocks, or in the Avatar Menu.
const ENABLE_COPY_MESSAGE_OVERLAY: boolean = false;


const messageBodySx: SxProps = {
  display: 'flex',
  alignItems: 'flex-start', // avatars at the top, and honor 'static' position
  gap: { xs: 0, md: 1 },
};

const messageBodyReverseSx: SxProps = {
  ...messageBodySx,
  flexDirection: 'row-reverse',
};

export const messageSkippedSx = {
  // show a nice ghostly border (dashed?)
  border: '1px dashed',
  borderColor: 'neutral.solidBg',
  // make it look good
  filter: 'grayscale(1)',
} as const;

const personaAvatarOrMenuSx: SxProps = {
  display: 'flex',
};

const editButtonWrapSx: SxProps = {
  overflowWrap: 'anywhere',
  mb: -0.5, // this is so that the 'edit/cancel' labels won't push down the edit box when single lined
};

const fragmentsListSx: SxProps = {
  // style
  flexGrow: 1,  // capture all the space, for edit modes
  minWidth: 0,  // VERY important, otherwise very wide messages will overflow the container, causing scroll on the whole page
  my: 'auto',   // v-center content if there's any gap (e.g. single line of text)

  // layout
  display: 'flex',
  flexDirection: 'column',
  gap: 1.5,     // we give a bit more space between the 'classes' of fragments (in-reply-to, images, content, attachments, etc.)
};

const antCachePromptOffSx: SxProps = {
  transition: 'color 0.16s, transform 0.16s',
};

const antCachePromptOnSx: SxProps = {
  ...antCachePromptOffSx,
  color: ModelVendorAnthropic.brandColor,
  transform: 'rotate(90deg)',
};


export interface ChatMessageFunctionsHandle {
  beginEditTextContent: () => void;
}

export type ChatMessageTextPartEditState = { [fragmentId: DMessageFragmentId]: string };

export const ChatMessageMemo = React.memo(ChatMessage);

/**
 * The Message component is a customizable chat message UI component that supports
 * different roles (user, assistant, and system), text editing, syntax highlighting,
 * and code execution using Sandpack for TypeScript, JavaScript, and HTML code blocks.
 * The component also provides options for copying code to clipboard and expanding
 * or collapsing long user messages.
 *
 */
export function ChatMessage(props: {
  actionsRef?: React.Ref<ChatMessageFunctionsHandle>,
  message: DMessage,
  diffPreviousText?: string,
  fitScreen: boolean,
  hasInReferenceTo?: boolean;
  isMobile: boolean,
  isBottom?: boolean,
  isImagining?: boolean,
  isSpeaking?: boolean,
  hideAvatar?: boolean,
  showAntPromptCaching?: boolean,
  showBlocksDate?: boolean,
  showUnsafeHtmlCode?: boolean,
  adjustContentScaling?: number,
  topDecorator?: React.ReactNode,
  onAddInReferenceTo?: (item: DMetaReferenceItem) => void,
  onMessageAssistantFrom?: (messageId: string, offset: number) => Promise<void>,
  onMessageBeam?: (messageId: string) => Promise<void>,
  onMessageBranch?: (messageId: string) => void,
  onMessageContinue?: (messageId: string, continueText: null | string) => void,
  onMessageDelete?: (messageId: string) => void,
  onMessageFragmentAppend?: (messageId: DMessageId, fragment: DMessageFragment) => void
  onMessageFragmentDelete?: (messageId: DMessageId, fragmentId: DMessageFragmentId) => void,
  onMessageFragmentReplace?: (messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment) => void,
  onMessageToggleUserFlag?: (messageId: string, flag: DMessageUserFlag, maxPerConversation?: number) => void,
  onMessageTruncate?: (messageId: string) => void,
  onTextDiagram?: (messageId: string, text: string) => Promise<void>,
  onTextImagine?: (text: string) => Promise<void>,
  onTextSpeak?: (text: string) => Promise<void>,
  sx?: SxProps,
}) {

  // state
  const blocksRendererRef = React.useRef<HTMLDivElement>(null);
  const [isHovering, setIsHovering] = React.useState(false);
  const [selText, setSelText] = React.useState<string | null>(null);
  const [bubbleAnchor, setBubbleAnchor] = React.useState<HTMLElement | null>(null);
  const [contextMenuAnchor, setContextMenuAnchor] = React.useState<HTMLElement | null>(null);
  const [opsMenuAnchor, setOpsMenuAnchor] = React.useState<HTMLElement | null>(null);
  const [textContentEditState, setTextContentEditState] = React.useState<ChatMessageTextPartEditState | null>(null);

  // external state
  const { adjContentScaling, disableMarkdown, doubleClickToEdit, uiComplexityMode } = useUIPreferencesStore(useShallow(state => ({
    adjContentScaling: adjustContentScaling(state.contentScaling, props.adjustContentScaling),
    disableMarkdown: state.disableMarkdown,
    doubleClickToEdit: state.doubleClickToEdit,
    uiComplexityMode: state.complexityMode,
  })));
  const labsEnhanceCodeBlocks = useUXLabsStore(state => state.labsEnhanceCodeBlocks);
  const [showDiff, setShowDiff] = useChatShowTextDiff();


  // derived state
  const {
    id: messageId,
    role: messageRole,
    fragments: messageFragments,
    pendingIncomplete: messagePendingIncomplete,
    purposeId: messagePurposeId,
    generator: messageGenerator,
    metadata: messageMetadata,
    created: messageCreated,
    updated: messageUpdated,
  } = props.message;

  const fromAssistant = messageRole === 'assistant';
  const fromSystem = messageRole === 'system';
  const fromUser = messageRole === 'user';
  const messageHasBeenEdited = !!messageUpdated;

  const isUserMessageSkipped = messageHasUserFlag(props.message, MESSAGE_FLAG_AIX_SKIP);
  const isUserStarred = messageHasUserFlag(props.message, MESSAGE_FLAG_STARRED);
  const isUserNotifyComplete = messageHasUserFlag(props.message, MESSAGE_FLAG_NOTIFY_COMPLETE);
  const isVndAndCacheAuto = !!props.showAntPromptCaching && messageHasUserFlag(props.message, MESSAGE_FLAG_VND_ANT_CACHE_AUTO);
  const isVndAndCacheUser = !!props.showAntPromptCaching && messageHasUserFlag(props.message, MESSAGE_FLAG_VND_ANT_CACHE_USER);

  const {
    imageAttachments,       // Stamp-sized Images
    voidFragments,          // Model-Aux, Placeholders
    contentFragments,       // Text (Markdown + Code + ... blocks), Errors, (large) Images
    nonImageAttachments,    // Document Attachments, likely the User dropped them in
  } = useFragmentBuckets(messageFragments);

  const fragmentFlattenedText = React.useMemo(() => messageFragmentsReduceText(messageFragments), [messageFragments]);
  const handleHighlightSelText = useSelHighlighterMemo(messageId, selText, contentFragments, fromAssistant, props.onMessageFragmentReplace);

  const textSubject = selText ? selText : fragmentFlattenedText;
  const isSpecialT2I = textSubject.startsWith('/draw ') || textSubject.startsWith('/imagine ') || textSubject.startsWith('/img ');
  const couldDiagram = textSubject.length >= 100 && !isSpecialT2I;
  const couldImagine = textSubject.length >= 3 && !isSpecialT2I;
  const couldSpeak = couldImagine;

  const userCommandApprox = !fromUser ? false
    : fragmentFlattenedText.startsWith('/draw ') ? 'draw'
      : fragmentFlattenedText.startsWith('/react ') ? 'react'
        : false;


  // TODO: fix the diffing
  // const wordsDiff = useWordsDifference(textSubject, props.diffPreviousText, showDiff);


  const { onMessageAssistantFrom, onMessageDelete, onMessageFragmentAppend, onMessageFragmentDelete, onMessageFragmentReplace, onMessageContinue } = props;

  const handleFragmentNew = React.useCallback(() => {
    onMessageFragmentAppend?.(messageId, createTextContentFragment(''));
  }, [messageId, onMessageFragmentAppend]);

  const handleFragmentDelete = React.useCallback((fragmentId: DMessageFragmentId) => {
    onMessageFragmentDelete?.(messageId, fragmentId);
  }, [messageId, onMessageFragmentDelete]);

  const handleFragmentReplace = React.useCallback((fragmentId: DMessageFragmentId, newFragment: DMessageFragment) => {
    onMessageFragmentReplace?.(messageId, fragmentId, newFragment);
  }, [messageId, onMessageFragmentReplace]);

  const handleMessageContinue = React.useCallback((continueText: null | string) => {
    onMessageContinue?.(messageId, continueText);
  }, [messageId, onMessageContinue]);


  // Text Editing

  const isEditingText = !!textContentEditState;

  const handleApplyEdit = React.useCallback((fragmentId: DMessageFragmentId, editedText: string) => {
    // perform deletion of the fragment if the text is empty
    if (!editedText.length)
      return handleFragmentDelete(fragmentId);

    // find the fragment to be replaced
    const oldFragment = messageFragments.find(f => f.fId === fragmentId);
    if (!oldFragment) return;
    const newFragment = updateFragmentWithEditedText(oldFragment, editedText);
    if (newFragment)
      handleFragmentReplace(fragmentId, newFragment);
  }, [handleFragmentDelete, handleFragmentReplace, messageFragments]);

  const handleApplyAllEdits = React.useCallback(async (withControl: boolean) => {
    const state = textContentEditState || {};
    setTextContentEditState(null);
    for (const [fragmentId, editedText] of Object.entries(state))
      handleApplyEdit(fragmentId, editedText);
    // if the user pressed Ctrl, we begin a regeneration from here
    if (withControl && onMessageAssistantFrom)
      await onMessageAssistantFrom(messageId, 0);
  }, [handleApplyEdit, messageId, onMessageAssistantFrom, textContentEditState]);

  const handleEditsApplyClicked = React.useCallback(() => handleApplyAllEdits(false), [handleApplyAllEdits]);

  const handleEditsBegin = React.useCallback(() => setTextContentEditState({}), []);

  const handleEditsCancel = React.useCallback(() => setTextContentEditState(null), []);

  const handleEditSetText = React.useCallback((fragmentId: DMessageFragmentId, editedText: string, applyNow: boolean) => {
    if (applyNow)
      handleApplyEdit(fragmentId, editedText);
    else
      setTextContentEditState((prev): ChatMessageTextPartEditState => ({ ...prev, [fragmentId]: editedText || '' }));
  }, [handleApplyEdit]);


  // Message Operations Menu

  const { onAddInReferenceTo, onMessageToggleUserFlag } = props;

  const handleOpsMenuToggle = React.useCallback((event: React.MouseEvent<HTMLElement>) => {
    event.preventDefault(); // added for the Right mouse click (to prevent the menu)
    !!event.currentTarget && setOpsMenuAnchor(event.currentTarget);
  }, []);

  const handleCloseOpsMenu = React.useCallback(() => setOpsMenuAnchor(null), []);

  const handleOpsCopy = (e: React.MouseEvent) => {
    copyToClipboard(textSubject, 'Text');
    e.preventDefault();
    handleCloseOpsMenu();
    closeContextMenu();
    closeBubble();
  };

  const handleOpsEditToggle = React.useCallback((e: React.MouseEvent) => {
    if (messagePendingIncomplete && !isEditingText) return; // don't allow editing while incomplete
    if (isEditingText) handleEditsCancel();
    else handleEditsBegin();
    e.preventDefault();
    handleCloseOpsMenu();
  }, [handleCloseOpsMenu, handleEditsBegin, handleEditsCancel, isEditingText, messagePendingIncomplete]);

  const handleOpsToggleAntCacheUser = React.useCallback(() => {
    onMessageToggleUserFlag?.(messageId, MESSAGE_FLAG_VND_ANT_CACHE_USER, 2);
  }, [messageId, onMessageToggleUserFlag]);

  const handleOpsToggleSkipMessage = React.useCallback(() => {
    onMessageToggleUserFlag?.(messageId, MESSAGE_FLAG_AIX_SKIP);
  }, [messageId, onMessageToggleUserFlag]);

  const handleOpsToggleStarred = React.useCallback(() => {
    onMessageToggleUserFlag?.(messageId, MESSAGE_FLAG_STARRED);
  }, [messageId, onMessageToggleUserFlag]);

  const handleOpsToggleNotifyComplete = React.useCallback(() => {
    // also remember the preference, for auto-setting flags by the persona
    setIsNotificationEnabledForModel(messageId, !isUserNotifyComplete);
    onMessageToggleUserFlag?.(messageId, MESSAGE_FLAG_NOTIFY_COMPLETE);
  }, [isUserNotifyComplete, messageId, onMessageToggleUserFlag]);

  const handleOpsAssistantFrom = async (e: React.MouseEvent) => {
    e.preventDefault();
    handleCloseOpsMenu();
    await props.onMessageAssistantFrom?.(messageId, fromAssistant ? -1 : 0);
  };

  const handleOpsBeamFrom = async (e: React.MouseEvent) => {
    e.stopPropagation();
    handleCloseOpsMenu();
    await props.onMessageBeam?.(messageId);
  };

  const handleOpsBranch = (e: React.MouseEvent) => {
    e.preventDefault();
    e.stopPropagation(); // to try to not steal the focus from the branched conversation
    props.onMessageBranch?.(messageId);
    handleCloseOpsMenu();
  };

  const handleOpsToggleShowDiff = () => setShowDiff(!showDiff);

  const handleOpsDiagram = async (e: React.MouseEvent) => {
    e.preventDefault();
    if (props.onTextDiagram) {
      await props.onTextDiagram(messageId, textSubject.trim());
      handleCloseOpsMenu();
      closeContextMenu();
      closeBubble();
    }
  };

  const handleOpsImagine = async (e: React.MouseEvent) => {
    e.preventDefault();
    if (props.onTextImagine) {
      await props.onTextImagine(textSubject.trim());
      handleCloseOpsMenu();
      closeContextMenu();
      closeBubble();
    }
  };

  const handleOpsAddInReferenceTo = (e: React.MouseEvent) => {
    e.preventDefault();
    if (onAddInReferenceTo && textSubject.trim().length >= BUBBLE_MIN_TEXT_LENGTH) {
      onAddInReferenceTo({ mrt: 'dmsg', mText: textSubject.trim(), mRole: messageRole /*, messageId*/ });
      handleCloseOpsMenu();
      closeContextMenu();
      closeBubble();
    }
  };

  const handleOpsSpeak = async (e: React.MouseEvent) => {
    e.preventDefault();
    if (props.onTextSpeak) {
      await props.onTextSpeak(textSubject.trim());
      handleCloseOpsMenu();
      closeContextMenu();
      closeBubble();
    }
  };

  const handleOpsTruncate = (_e: React.MouseEvent) => {
    props.onMessageTruncate?.(messageId);
    handleCloseOpsMenu();
  };

  const handleOpsDelete = React.useCallback(() => {
    onMessageDelete?.(messageId);
  }, [messageId, onMessageDelete]);


  // Context Menu

  const removeContextAnchor = React.useCallback(() => {
    if (contextMenuAnchor) {
      try {
        document.body.removeChild(contextMenuAnchor);
      } catch (e) {
        // ignore...
      }
    }
  }, [contextMenuAnchor]);

  const openContextMenu = React.useCallback((event: MouseEvent, selectedText: string) => {
    event.stopPropagation();
    event.preventDefault();

    // remove any stray anchor
    removeContextAnchor();

    // create a temporary fixed anchor element to position the menu
    const anchorEl = document.createElement('div');
    anchorEl.style.position = 'fixed';
    anchorEl.style.left = `${event.clientX}px`;
    anchorEl.style.top = `${event.clientY}px`;
    document.body.appendChild(anchorEl);

    setContextMenuAnchor(anchorEl);
    setSelText(selectedText);
  }, [removeContextAnchor]);

  const closeContextMenu = React.useCallback(() => {
    // window.getSelection()?.removeAllRanges?.();
    removeContextAnchor();
    setContextMenuAnchor(null);
    setSelText(null);
  }, [removeContextAnchor]);

  const handleContextMenu = React.useCallback((event: MouseEvent) => {
    const selection = window.getSelection();
    if (selection && selection.rangeCount > 0) {
      const range = selection.getRangeAt(0);
      const selectedText = range.toString().trim();
      if (selectedText.length > 0)
        openContextMenu(event, selectedText);
    }
  }, [openContextMenu]);


  // Bubble

  const closeBubble = React.useCallback((anchorEl?: HTMLElement, options?: { clearSelection?: boolean }) => {
    // NOTE - we used to have this always on, which would remove the highlighted text, but it's fired too much and in particular
    // it was corrupting the extension of text selection (http://github.com/enricoros/big-AGI/issues/788)
    //
    // However the likely expected user behavior here is to keep the selection, hence by default we don't clear it
    if (options?.clearSelection)
      window.getSelection()?.removeAllRanges?.();
    try {
      const anchor = anchorEl || bubbleAnchor;
      anchor && document.body.removeChild(anchor);
    } catch (e) {
      // ignore...
    }
    setBubbleAnchor(null);
    setSelText(null);
  }, [bubbleAnchor]);

  // restore blocksRendererRef
  const handleOpenBubble = React.useCallback((event?: MouseEvent | null) => {
    // check for selection
    const selection = window.getSelection();
    if (!selection || selection.rangeCount <= 0) return;

    // check for enough selection
    const selectionText = selection.toString();
    if (selectionText.trim().length < BUBBLE_MIN_TEXT_LENGTH) return;

    // check for the selection being inside the blocks renderer (core of the message)
    const selectionRange = selection.getRangeAt(0);
    const blocksElement = blocksRendererRef.current;
    if (!blocksElement || !blocksElement.contains(selectionRange.commonAncestorContainer)) return;

    const rangeRects = selectionRange.getClientRects();
    if (rangeRects.length <= 0) return;

    const firstRect = rangeRects[0];
    const anchorEl = document.createElement('div');
    anchorEl.style.position = 'fixed';
    anchorEl.style.left = `${firstRect.left + window.scrollX}px`;
    anchorEl.style.top = !props.isMobile ? `${firstRect.top + window.scrollY}px` : `${firstRect.top + window.scrollY - 45}px`;
    if (props.isMobile)
      anchorEl.style.zIndex = '99999';  // Higher z-index to compete with native UI

    document.body.appendChild(anchorEl);
    anchorEl.setAttribute('role', 'dialog');

    // auto-close logic on unselect
    const closeOnUnselect = () => {
      const selection = window.getSelection();
      if (!selection || selection.toString().trim() === '') {
        closeBubble(anchorEl, { clearSelection: false });
        document.removeEventListener('selectionchange', closeOnUnselect);
      }
    };
    document.addEventListener('selectionchange', closeOnUnselect);

    setBubbleAnchor(anchorEl);
    setSelText(selectionText); /* TODO: operate on the underlying content, not the rendered text */
  }, [closeBubble, props.isMobile]);

  const handleBubbleClickAway = React.useCallback((event: MouseEvent | TouchEvent /* DOM, not React */) => {
    if (!event.shiftKey)
      closeBubble();
  }, [closeBubble]);


  // Expose actions handle for parent components
  React.useImperativeHandle(props.actionsRef, () => ({
    beginEditTextContent: () => {
      if (!isEditingText && props.onMessageFragmentReplace && !messagePendingIncomplete)
        handleEditsBegin();
    },
  }), [handleEditsBegin, isEditingText, messagePendingIncomplete, props.onMessageFragmentReplace]);


  // Blocks renderer

  const handleBlocksContextMenu = React.useCallback((event: React.MouseEvent) => {
    handleContextMenu(event.nativeEvent);
  }, [handleContextMenu]);

  const handleBlocksDoubleClick = React.useCallback((event: React.MouseEvent) => {
    if ((doubleClickToEdit || event.shiftKey) && props.onMessageFragmentReplace)
      handleOpsEditToggle(event);
  }, [doubleClickToEdit, handleOpsEditToggle, props.onMessageFragmentReplace]);

  const handleBlocksMouseUp = React.useCallback((event: React.MouseEvent) => {
    // https://github.com/enricoros/big-AGI/issues/788
    // If shift is pressed, it's a selection extension attempt. Let the browser handle it.
    if (event.shiftKey)
      return;
    handleOpenBubble(event.nativeEvent);
  }, [handleOpenBubble]);

  const handleBlocksTouchEnd = React.useCallback((event: React.TouchEvent) => {
    if (event.shiftKey) return; // just to match the flow

    // on mobile, allow for text-selection events to process, then open
    setTimeout(() => {
      const selection = window.getSelection();
      if (selection && selection.toString().trim().length >= BUBBLE_MIN_TEXT_LENGTH)
        handleOpenBubble(null);
    }, 300);
  }, [handleOpenBubble]);


  // Options interceptor

  const lookForOptions = props.onMessageContinue !== undefined && props.isBottom === true && messageGenerator?.tokenStopReason !== 'out-of-tokens' && fromAssistant && !messagePendingIncomplete && !isEditingText && uiComplexityMode !== 'minimal' && false;

  const { fragments: renderContentFragments, options: continuationOptions } = React.useMemo(() => {
    return optionsExtractFromFragments_dangerModifyFragment(lookForOptions, contentFragments);
  }, [contentFragments, lookForOptions]);


  // style
  const backgroundColor = messageBackground(messageRole, userCommandApprox, messageHasBeenEdited, false /*isAssistantError && !errorMessage*/);

  const listItemSx: SxProps = React.useMemo(() => ({
    // vars
    '--AGI-overlay-start-opacity': uiComplexityMode === 'extra' ? 0.1 : 0,

    // style
    backgroundColor: backgroundColor,
    px: { xs: 1, md: themeScalingMap[adjContentScaling]?.chatMessagePadding ?? 2 },
    py: themeScalingMap[adjContentScaling]?.chatMessagePadding ?? 2,
    // filter: 'url(#agi-futuristic-glow)',

    // style: omit border if set externally
    ...(!('borderBottom' in (props.sx || {})) && !props.isBottom && {
      borderBottom: '1px solid',
      borderBottomColor: 'divider',
    }),

    // style: when starred
    ...(isUserStarred && {
      outline: '3px solid',
      outlineColor: 'primary.solidBg',
      boxShadow: 'lg',
      borderRadius: 'lg',
      zIndex: 1,
    }),

    // style: when has a user/automatic breakpoint
    ...(isVndAndCacheUser && {
      borderInlineStart: `0.125rem solid ${ModelVendorAnthropic.brandColor}`,
      // borderTopLeftRadius: '0.375rem',
      // borderBottomLeftRadius: '0.375rem',
    }),
    ...(uiComplexityMode === 'extra' && isVndAndCacheAuto && !isVndAndCacheUser && {
      position: 'relative',
      '&::before': {
        content: '""',
        position: 'absolute',
        left: 0,
        top: 0,
        bottom: 0,
        width: '0.125rem',
        background: `repeating-linear-gradient( -45deg, transparent, transparent 2px, ${ModelVendorAnthropic.brandColor} 2px, ${ModelVendorAnthropic.brandColor} 12px ) repeat`,
      },
    }),
    // style: when the user skips the message
    ...(isUserMessageSkipped && messageSkippedSx),

    // style: when the message is being edited
    ...(isEditingText && {
      zIndex: 1, // this is to make the whole message appear on top of Beam Scatter > RayControlsMemo
    }),

    // for: ENABLE_COPY_MESSAGE_OVERLAY
    // '&:hover > button': { opacity: 1 },

    // layout
    display: 'block', // this is Needed, otherwise there will be a horizontal overflow

    ...props.sx,
  }), [adjContentScaling, backgroundColor, isEditingText, isUserMessageSkipped, isUserStarred, isVndAndCacheAuto, isVndAndCacheUser, props.isBottom, props.sx, uiComplexityMode]);


  // avatar icon & label & tooltip

  const zenMode = uiComplexityMode === 'minimal';

  const showAvatarIcon = !props.hideAvatar && !zenMode;
  const messageGeneratorName = messageGenerator?.name;
  const messageAvatarIcon = React.useMemo(
    () => !showAvatarIcon ? null : makeMessageAvatarIcon(uiComplexityMode, messageRole, messageGeneratorName, messagePurposeId, !!messagePendingIncomplete, isUserMessageSkipped, isUserNotifyComplete, true),
    [isUserMessageSkipped, isUserNotifyComplete, messageGeneratorName, messagePendingIncomplete, messagePurposeId, messageRole, showAvatarIcon, uiComplexityMode],
  );

  const { label: messageAvatarLabel, tooltip: messageAvatarTooltip } = useMessageAvatarLabel(props.message, uiComplexityMode);


  return (
    <Box
      component='li'
      role='chat-message'
      tabIndex={-1 /* for shortcuts navigation */}
      onMouseUp={(ENABLE_BUBBLE && !fromSystem /*&& !isAssistantError*/) ? handleBlocksMouseUp : undefined}
      onTouchEnd={(ENABLE_BUBBLE && !fromSystem /*&& !isAssistantError*/) ? handleBlocksTouchEnd : undefined}
      sx={listItemSx}
      // className={messagePendingIncomplete ? 'agi-border-4' /* CSS Effect while in progress */ : undefined}
    >

      {/* (Optional) top decorator */}
      {props.topDecorator}


      {/* Message Row: Aside, Fragment[][], Aside2 */}
      <Box
        role={undefined /* aside | message | ops */}
        sx={(fromAssistant && !isEditingText) ? messageBodySx : messageBodyReverseSx}
      >

        {/* [start-Avatar] Avatar (Persona) */}
        {!props.hideAvatar && !isEditingText && (
          <Box sx={zenMode ? messageZenAsideColumnSx : messageAsideColumnSx}>

            {/* Persona Avatar or Menu Button */}
            <Box
              onClick={(event) => {
                // [DEBUG][PROD] shift+click to dump the DMessage
                event.shiftKey && console.log('message', props.message);
                handleOpsMenuToggle(event);
              }}
              onContextMenu={handleOpsMenuToggle}
              onMouseEnter={props.isMobile ? undefined : () => setIsHovering(true)}
              onMouseLeave={props.isMobile ? undefined : () => setIsHovering(false)}
              sx={personaAvatarOrMenuSx}
            >
              {showAvatarIcon && !isHovering && !opsMenuAnchor ? (
                messageAvatarIcon
              ) : (
                <IconButton
                  size='sm'
                  variant={opsMenuAnchor ? 'solid' : zenMode ? 'plain' : 'soft'}
                  color={(fromAssistant || fromSystem || zenMode) ? 'neutral' : userCommandApprox === 'draw' ? 'warning' : userCommandApprox === 'react' ? 'success' : 'primary'}
                  sx={avatarIconSx}
                >
                  <MoreVertIcon />
                </IconButton>
              )}
            </Box>

            {/* Assistant (llm/function) name */}
            {fromAssistant && !zenMode && (
              <TooltipOutlined asLargePane enableInteractive title={messageAvatarTooltip} placement='bottom-start'>
                <Typography level='body-xs' sx={(messagePendingIncomplete && !Release.Features.LIGHTER_ANIMATIONS) ? messageAvatarLabelAnimatedSx : messageAvatarLabelSx}>
                  {messageAvatarLabel}
                </Typography>
              </TooltipOutlined>
            )}

          </Box>
        )}

        {/* [start-Edit] Fragments Edit: Apply */}
        {isEditingText && (
          <Box sx={messageAsideColumnSx} className='msg-edit-button'>
            <Tooltip arrow disableInteractive title='Apply Edits'>
              <IconButton size='sm' variant='solid' color='warning' onClick={handleEditsApplyClicked}>
                <CheckRoundedIcon />
              </IconButton>
            </Tooltip>
            <Typography level='body-xs' sx={editButtonWrapSx}>
              Done
            </Typography>
          </Box>
        )}


        {/* V-Fragments: Image Attachments | Content | Doc Attachments */}
        <Box ref={blocksRendererRef /* restricts the BUBBLE menu to the children of this */} sx={fragmentsListSx}>

          {/* (optional) Message date */}
          {(props.showBlocksDate === true && !!(messageUpdated || messageCreated)) && (
            <Typography level='body-sm' sx={{ mx: 1.5, textAlign: fromAssistant ? 'left' : 'right' }}>
              <TimeAgo date={messageUpdated || messageCreated} />
            </Typography>
          )}

          {/* (special case) System modified warning */}
          {fromSystem && messageHasBeenEdited && (
            <Typography level='body-sm' color='warning' sx={{ mt: 1, mx: 1.5, textAlign: 'end' }}>
              modified by user - auto-update disabled
            </Typography>
          )}

          {/* In-Reference-To Bubble */}
          {!!messageMetadata?.inReferenceTo?.length && (
            <InReferenceToList items={messageMetadata.inReferenceTo} />
          )}

          {/* Image Attachment Fragments - just for a prettier display on top of the message */}
          {imageAttachments.length >= 1 && (
            <ImageAttachmentFragments
              imageAttachments={imageAttachments}
              contentScaling={adjContentScaling}
              messageRole={messageRole}
              disabled={isEditingText}
              onFragmentDelete={!props.onMessageFragmentDelete ? undefined : handleFragmentDelete}
            />
          )}

          {/* Void Fragments */}
          {voidFragments.length >= 1 && (
            <VoidFragments
              voidFragments={voidFragments}
              nonVoidFragmentsCount={renderContentFragments.length}
              contentScaling={adjContentScaling}
              uiComplexityMode={uiComplexityMode}
              messageRole={messageRole}
            />
          )}

          {/* Content Fragments */}
          <ContentFragments
            contentFragments={renderContentFragments}
            showEmptyNotice={!messageFragments.length && !messagePendingIncomplete}

            contentScaling={adjContentScaling}
            uiComplexityMode={uiComplexityMode}
            fitScreen={props.fitScreen}
            isMobile={props.isMobile}
            messageRole={messageRole}
            optiAllowSubBlocksMemo={!!messagePendingIncomplete}
            disableMarkdownText={disableMarkdown || fromUser /* User messages are edited as text. Try to have them in plain text. NOTE: This may bite. */}
            showUnsafeHtmlCode={props.showUnsafeHtmlCode}
            enhanceCodeBlocks={labsEnhanceCodeBlocks}

            textEditsState={textContentEditState}
            setEditedText={(!props.onMessageFragmentReplace || messagePendingIncomplete) ? undefined : handleEditSetText}
            onEditsApply={handleApplyAllEdits}
            onEditsCancel={handleEditsCancel}

            onFragmentAddBlank={!props.onMessageFragmentAppend ? undefined : handleFragmentNew}
            onFragmentDelete={!props.onMessageFragmentDelete ? undefined : handleFragmentDelete}
            onFragmentReplace={!props.onMessageFragmentReplace ? undefined : handleFragmentReplace}
            onMessageDelete={!props.onMessageDelete ? undefined : handleOpsDelete}

            onContextMenu={(props.onMessageFragmentReplace && ENABLE_CONTEXT_MENU) ? handleBlocksContextMenu : undefined}
            onDoubleClick={(props.onMessageFragmentReplace /*&& doubleClickToEdit disabled, as we may have shift too */) ? handleBlocksDoubleClick : undefined}
          />

          {/* Document Fragments */}
          {nonImageAttachments.length >= 1 && (
            <DocumentAttachmentFragments
              attachmentFragments={nonImageAttachments}
              messageRole={messageRole}
              contentScaling={adjContentScaling}
              isMobile={props.isMobile}
              zenMode={zenMode}
              allowSelection={!isEditingText}
              disableMarkdownText={disableMarkdown}
              onFragmentDelete={!props.onMessageFragmentDelete ? undefined : handleFragmentDelete}
              onFragmentReplace={!props.onMessageFragmentReplace ? undefined : handleFragmentReplace}
            />
          )}

          {/* Continue... */}
          {props.isBottom && messageGenerator?.tokenStopReason === 'out-of-tokens' && !!props.onMessageContinue && (
            <BlockOpContinue
              contentScaling={adjContentScaling}
              messageRole={messageRole}
              onContinue={handleMessageContinue}
            />
          )}

          {/* Continue Options... */}
          {continuationOptions.length >= 1 && !!props.onMessageContinue && (
            <BlockOpOptions
              contentScaling={adjContentScaling}
              options={continuationOptions}
              onContinue={handleMessageContinue}
            />
          )}

        </Box>


        {/* [end-Edit] Fragments Edit: Cancel */}
        {isEditingText && (
          <Box sx={messageAsideColumnSx} className='msg-edit-button'>
            <Tooltip arrow disableInteractive title='Discard Edits'>
              <IconButton size='sm' variant='solid' onClick={handleEditsCancel}>
                <CloseRoundedIcon />
              </IconButton>
            </Tooltip>
            <Typography level='body-xs' sx={editButtonWrapSx}>
              Cancel
            </Typography>
          </Box>
        )}

      </Box>


      {/* Overlay copy icon */}
      {ENABLE_COPY_MESSAGE_OVERLAY && !fromSystem && !isEditingText && (
        <Tooltip title={messagePendingIncomplete ? null : (fromAssistant ? 'Copy message' : 'Copy input')} variant='solid'>
          <IconButton
            variant='outlined' onClick={handleOpsCopy}
            sx={{
              position: 'absolute', ...(fromAssistant ? { right: { xs: 12, md: 28 } } : { left: { xs: 12, md: 28 } }), zIndex: 10,
              opacity: 0, transition: 'opacity 0.16s cubic-bezier(.17,.84,.44,1)',
            }}>
            <ContentCopyIcon />
          </IconButton>
        </Tooltip>
      )}


      {/* Message Operations Menu (3 dots) */}
      {!!opsMenuAnchor && (
        <CloseablePopup
          menu anchorEl={opsMenuAnchor} onClose={handleCloseOpsMenu}
          dense
          minWidth={280}
          placement={fromAssistant ? 'auto-start' : 'auto-end'}
        >

          {fromSystem && (
            <ListItem>
              <Typography level='body-sm'>
                System message
              </Typography>
            </ListItem>
          )}

          {/* Edit / Copy */}
          <Box sx={{ display: 'flex', alignItems: 'center' }}>
            {/* Edit */}
            {!!props.onMessageFragmentReplace && (
              <MenuItem variant='plain' disabled={!!messagePendingIncomplete} onClick={handleOpsEditToggle} sx={{ flex: 1 }}>
                <ListItemDecorator>{isEditingText ? <CloseRoundedIcon /> : <EditRoundedIcon />}</ListItemDecorator>
                {isEditingText ? 'Discard' : 'Edit'}
              </MenuItem>
            )}
            {/* Copy */}
            <MenuItem onClick={handleOpsCopy} sx={{ flex: 1 }}>
              <ListItemDecorator><ContentCopyIcon /></ListItemDecorator>
              Copy
            </MenuItem>
            {/* Starred */}
            {!!onMessageToggleUserFlag && (
              <MenuItem onClick={handleOpsToggleStarred} sx={{ flexGrow: 0, px: 1 }}>
                <Tooltip disableInteractive title={!isUserStarred ? 'Link message - use @ to refer to it from another chat' : 'Remove link'}>
                  {isUserStarred
                    ? <AlternateEmailIcon color='primary' sx={{ fontSize: 'xl' }} />
                    : <InsertLinkIcon sx={{ rotate: '45deg' }} />
                  }
                  {/*{isUserStarred*/}
                  {/*  ? <StarRoundedIcon color='primary' sx={{ fontSize: 'xl2' }} />*/}
                  {/*  : <StarOutlineRoundedIcon sx={{ fontSize: 'xl2' }} />*/}
                  {/*}*/}
                </Tooltip>
              </MenuItem>
            )}
          </Box>

          {/* Notify Complete */}
          {messagePendingIncomplete && !!onMessageToggleUserFlag && <ListDivider />}
          {messagePendingIncomplete && !!onMessageToggleUserFlag && (
            <MenuItem onClick={handleOpsToggleNotifyComplete}>
              <ListItemDecorator>{isUserNotifyComplete ? <NotificationsActiveIcon /> : <NotificationsOutlinedIcon />}</ListItemDecorator>
              Notify on reply
            </MenuItem>
          )}

          {/* Anthropic Breakpoint Toggle */}
          {!messagePendingIncomplete && <ListDivider />}
          {!messagePendingIncomplete && !isUserMessageSkipped && !!props.showAntPromptCaching && (
            <MenuItem onClick={handleOpsToggleAntCacheUser}>
              <ListItemDecorator><AnthropicIcon sx={isVndAndCacheUser ? antCachePromptOnSx : antCachePromptOffSx} /></ListItemDecorator>
              {isVndAndCacheUser ? 'Do not cache' : <>Cache <span style={{ opacity: 0.5 }}>up to here</span></>}
            </MenuItem>
          )}
          {!messagePendingIncomplete && !isUserMessageSkipped && !!props.showAntPromptCaching && isVndAndCacheAuto && !isVndAndCacheUser && (
            <MenuItem disabled>
              <ListItemDecorator><TextureIcon sx={{ color: ModelVendorAnthropic.brandColor }} /></ListItemDecorator>
              Auto-Cached <span style={{ opacity: 0.5 }}>for 5 min</span>
            </MenuItem>
          )}
          {/* Aix Skip Message */}
          {!messagePendingIncomplete && !!props.onMessageToggleUserFlag && (
            <MenuItem onClick={handleOpsToggleSkipMessage}>
              <ListItemDecorator>{isUserMessageSkipped ? <VisibilityOffIcon sx={{ color: 'danger.plainColor' }} /> : <VisibilityIcon />}</ListItemDecorator>
              {isUserMessageSkipped ? 'Unskip' : 'Skip AI processing'}
            </MenuItem>
          )}

          {/* Delete / Branch / Truncate */}
          {!!props.onMessageBranch && <ListDivider />}
          {!!props.onMessageBranch && (
            <MenuItem onClick={handleOpsBranch} disabled={fromSystem}>
              <ListItemDecorator>
                <ForkRightIcon />
              </ListItemDecorator>
              Branch
              {!props.isBottom && <span style={{ opacity: 0.5 }}>from here</span>}
            </MenuItem>
          )}
          {!!props.onMessageDelete && (
            <MenuItem onClick={handleOpsDelete} disabled={false /*fromSystem*/}>
              <ListItemDecorator><DeleteOutlineIcon /></ListItemDecorator>
              Delete
              <span style={{ opacity: 0.5 }}>message</span>
            </MenuItem>
          )}
          {!!props.onMessageTruncate && (
            <MenuItem onClick={handleOpsTruncate} disabled={props.isBottom}>
              <ListItemDecorator><VerticalAlignBottomIcon /></ListItemDecorator>
              Truncate
              <span style={{ opacity: 0.5 }}>after this</span>
            </MenuItem>
          )}
          {/* Diagram / Draw / Speak */}
          {!!props.onTextDiagram && <ListDivider />}
          {!!props.onTextDiagram && (
            <MenuItem onClick={handleOpsDiagram} disabled={!couldDiagram}>
              <ListItemDecorator><AccountTreeOutlinedIcon /></ListItemDecorator>
              Auto-Diagram ...
            </MenuItem>
          )}
          {!!props.onTextImagine && (
            <MenuItem onClick={handleOpsImagine} disabled={!couldImagine || props.isImagining}>
              <ListItemDecorator>{props.isImagining ? <CircularProgress size='sm' /> : <FormatPaintOutlinedIcon />}</ListItemDecorator>
              Auto-Draw
            </MenuItem>
          )}
          {!!props.onTextSpeak && (
            <MenuItem onClick={handleOpsSpeak} disabled={!couldSpeak || props.isSpeaking}>
              <ListItemDecorator>{props.isSpeaking ? <CircularProgress size='sm' /> : <RecordVoiceOverOutlinedIcon />}</ListItemDecorator>
              Speak
            </MenuItem>
          )}
          {/* Diff Viewer */}
          {!!props.diffPreviousText && <ListDivider />}
          {!!props.diffPreviousText && (
            <MenuItem onClick={handleOpsToggleShowDiff}>
              <ListItemDecorator><DifferenceIcon /></ListItemDecorator>
              Show difference
              <Switch checked={showDiff} onChange={handleOpsToggleShowDiff} sx={{ ml: 'auto' }} />
            </MenuItem>
          )}
          {/* Beam/Restart */}
          {(!!props.onMessageAssistantFrom || !!props.onMessageBeam) && <ListDivider />}
          {!!props.onMessageAssistantFrom && (
            <MenuItem disabled={fromSystem} onClick={handleOpsAssistantFrom}>
              <ListItemDecorator>{fromAssistant ? <ReplayIcon color='primary' /> : <TelegramIcon color='primary' />}</ListItemDecorator>
              {!fromAssistant
                ? <>Restart <span style={{ opacity: 0.5 }}>from here</span></>
                : !props.isBottom
                  ? <>Retry <span style={{ opacity: 0.5 }}>from here</span></>
                  : <Box sx={{ flexGrow: 1, display: 'flex', justifyContent: 'space-between', gap: 1 }}>Retry<KeyStroke variant='outlined' combo='Ctrl + Shift + Z' /></Box>}
            </MenuItem>
          )}
          {!!props.onMessageBeam && (
            <MenuItem disabled={fromSystem} onClick={handleOpsBeamFrom}>
              <ListItemDecorator>
                <ChatBeamIcon color={fromSystem ? undefined : 'primary'} />
              </ListItemDecorator>
              {!fromAssistant
                ? <>Beam <span style={{ opacity: 0.5 }}>from here</span></>
                : !props.isBottom
                  ? <>Beam Edit</>
                  : <Box sx={{ flexGrow: 1, display: 'flex', justifyContent: 'space-between', gap: 1 }}>Beam Edit<KeyStroke variant='outlined' combo='Ctrl + Shift + B' /></Box>}
            </MenuItem>
          )}
        </CloseablePopup>
      )}


      {/* Bubble Over Toolbar */}
      {ENABLE_BUBBLE && !!bubbleAnchor && (
        <Popper placement='top-start' open={true} anchorEl={bubbleAnchor} slotProps={{
          root: { style: { zIndex: themeZIndexChatBubble } },
        }}>
          <ClickAwayListener onClickAway={handleBubbleClickAway}>
            <ButtonGroup
              variant='plain'
              sx={{
                '--ButtonGroup-separatorColor': 'none !important',
                '--ButtonGroup-separatorSize': 0,
                borderRadius: '0',
                backgroundColor: 'background.popup',
                border: '1px solid',
                borderColor: 'primary.outlinedBorder',
                boxShadow: '0px 4px 24px -8px rgb(var(--joy-palette-neutral-darkChannel) / 50%)',
                mb: 1.5,
                ml: -1.5,
                alignItems: 'center',
                '& > button': {
                  '--Icon-fontSize': 'var(--joy-fontSize-lg, 1.125rem)',
                  minHeight: '2.5rem',
                  minWidth: '2.75rem',
                },
              }}
            >
              {/* Bubble Add Reference */}
              {!!onAddInReferenceTo && <Tooltip disableInteractive arrow placement='top' title={props.hasInReferenceTo ? 'Reply to this too' : fromAssistant ? 'Reply' : 'Refer To'}>
                <IconButton color='primary' onClick={handleOpsAddInReferenceTo}>
                  {props.hasInReferenceTo ? <ReplyAllRoundedIcon sx={{ fontSize: 'xl' }} /> : <ReplyRoundedIcon sx={{ fontSize: 'xl' }} />}
                </IconButton>
              </Tooltip>}
              {/*{!!props.onMessageBeam && fromAssistant && <Tooltip disableInteractive arrow placement='top' title='Beam'>*/}
              {/*  <IconButton color='primary'>*/}
              {/*    <ChatBeamIcon sx={{ fontSize: 'xl' }} />*/}
              {/*  </IconButton>*/}
              {/*</Tooltip>}*/}
              {!!onAddInReferenceTo && <Divider />}

              {/* Text Tools (edits fragment, only for assistant messages) */}
              {fromAssistant && <Tooltip disableInteractive arrow placement='top' title='Highlight Text'>
                <IconButton disabled={!handleHighlightSelText} onClick={!handleHighlightSelText ? undefined : () => {
                  handleHighlightSelText('highlight');
                  closeBubble();
                }}>
                  <MarkHighlightIcon hcolor={handleHighlightSelText ? 'yellow' : undefined} />
                </IconButton>
              </Tooltip>}
              {fromAssistant && <Tooltip disableInteractive arrow placement='top' title='Strike Through'>
                <IconButton disabled={!handleHighlightSelText} onClick={!handleHighlightSelText ? undefined : () => {
                  handleHighlightSelText('strike');
                  closeBubble();
                }}>
                  <StrikethroughSIcon />
                </IconButton>
              </Tooltip>}
              {fromAssistant && <Tooltip disableInteractive arrow placement='top' title='Toggle Bold'>
                <IconButton disabled={!handleHighlightSelText} onClick={!handleHighlightSelText ? undefined : () => {
                  handleHighlightSelText('strong');
                  closeBubble();
                }}>
                  <FormatBoldIcon />
                </IconButton>
              </Tooltip>}
              {fromAssistant && <Tooltip disableInteractive arrow placement='top' title='Cut Text'>
                <IconButton disabled={!handleHighlightSelText} onClick={!handleHighlightSelText ? undefined : () => {
                  handleHighlightSelText('cut');
                  closeBubble();
                }}>
                  <ContentCutIcon />
                </IconButton>
              </Tooltip>}
              {fromAssistant && <Divider />}

              {/* Intelligent functions */}
              {!!props.onTextDiagram && <Tooltip disableInteractive arrow placement='top' title={couldDiagram ? 'Auto-Diagram...' : 'Too short to Auto-Diagram'}>
                <IconButton color='success' onClick={couldDiagram ? handleOpsDiagram : undefined}>
                  <AccountTreeOutlinedIcon sx={{ color: couldDiagram ? 'primary' : 'neutral.plainDisabledColor' }} />
                </IconButton>
              </Tooltip>}
              {!!props.onTextImagine && <Tooltip disableInteractive arrow placement='top' title='Auto-Draw'>
                <IconButton color='success' onClick={handleOpsImagine} disabled={!couldImagine || props.isImagining}>
                  {!props.isImagining ? <FormatPaintOutlinedIcon /> : <CircularProgress sx={{ '--CircularProgress-size': '16px' }} />}
                </IconButton>
              </Tooltip>}
              {!!props.onTextSpeak && <Tooltip disableInteractive arrow placement='top' title='Speak'>
                <IconButton color='success' onClick={handleOpsSpeak} disabled={!couldSpeak || props.isSpeaking}>
                  {!props.isSpeaking ? <RecordVoiceOverOutlinedIcon /> : <CircularProgress sx={{ '--CircularProgress-size': '16px' }} />}
                </IconButton>
              </Tooltip>}
              {(!!props.onTextDiagram || !!props.onTextImagine || !!props.onTextSpeak) && <Divider />}

              {/* Bubble Copy */}
              <Tooltip disableInteractive arrow placement='top' title='Copy Selection'>
                <IconButton onClick={handleOpsCopy}>
                  <ContentCopyIcon />
                </IconButton>
              </Tooltip>

            </ButtonGroup>
          </ClickAwayListener>
        </Popper>
      )}


      {/* Context (Right-click) Menu */}
      {!!contextMenuAnchor && (
        <CloseablePopup
          menu anchorEl={contextMenuAnchor} onClose={closeContextMenu}
          dense
          minWidth={220}
          placement='bottom-start'
        >
          <MenuItem onClick={handleOpsCopy} sx={{ flex: 1, alignItems: 'center' }}>
            <ListItemDecorator><ContentCopyIcon /></ListItemDecorator>
            Copy
          </MenuItem>
          {!!props.onTextDiagram && <ListDivider />}
          {!!props.onTextDiagram && <MenuItem onClick={handleOpsDiagram} disabled={!couldDiagram || props.isImagining}>
            <ListItemDecorator><AccountTreeOutlinedIcon /></ListItemDecorator>
            Auto-Diagram ...
          </MenuItem>}
          {!!props.onTextImagine && <MenuItem onClick={handleOpsImagine} disabled={!couldImagine || props.isImagining}>
            <ListItemDecorator>{props.isImagining ? <CircularProgress size='sm' /> : <FormatPaintOutlinedIcon />}</ListItemDecorator>
            Auto-Draw
          </MenuItem>}
          {!!props.onTextSpeak && <MenuItem onClick={handleOpsSpeak} disabled={!couldSpeak || props.isSpeaking}>
            <ListItemDecorator>{props.isSpeaking ? <CircularProgress size='sm' /> : <RecordVoiceOverOutlinedIcon />}</ListItemDecorator>
            Speak
          </MenuItem>}
        </CloseablePopup>
      )}

    </Box>
  );
}



================================================
FILE: src/apps/chat/components/message/CleanerMessage.tsx
================================================
import * as React from 'react';

import { Box, Button, Checkbox, Chip, IconButton, ListItem, Sheet } from '@mui/joy';
import AttachFileRoundedIcon from '@mui/icons-material/AttachFileRounded';
import ClearIcon from '@mui/icons-material/Clear';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import ErrorIcon from '@mui/icons-material/ErrorRounded';
import ImageIcon from '@mui/icons-material/ImageRounded';
import TextFieldsIcon from '@mui/icons-material/TextFieldsRounded';
import VisibilityIcon from '@mui/icons-material/Visibility';
import VisibilityOffIcon from '@mui/icons-material/VisibilityOff';

import { DMessage, MESSAGE_FLAG_AIX_SKIP, messageFragmentsReduceText, messageHasUserFlag } from '~/common/stores/chat/chat.message';
import { DMessageAttachmentFragment, DMessageFragment, isAttachmentFragment, isContentFragment, isImageRefPart } from '~/common/stores/chat/chat.fragments';
import { makeMessageAvatarIcon, messageBackground } from '~/common/util/dMessageUtils';

import { TokenBadgeMemo } from '../composer/tokens/TokenBadge';
import { isErrorChatMessage } from './explainServiceErrors';
import { messageSkippedSx } from './ChatMessage';


// configuration
/**
 * This is being introduced because despite the automated ellipses, the text will still be fully layouted
 * by the Browser layout engine and as such very slow.
 */
const CLEANER_MESSAGE_MAX_LENGTH = 280;


interface FragmentAnalysis {
  textCount: number;
  errorCount: number;
  toolCount: number;
  imageCount: number;
  attachmentCount: number;
  attachments: DMessageAttachmentFragment[];
}

/**
 * Analyzes message fragments and returns counts and attachments in a single pass
 */
function analyzeMessageFragments(messageFragments: ReadonlyArray<DMessageFragment>): FragmentAnalysis {
  const result: FragmentAnalysis = {
    textCount: 0,
    errorCount: 0,
    toolCount: 0,
    imageCount: 0,
    attachmentCount: 0,
    attachments: [],
  };

  messageFragments.forEach(fragment => {
    if (isContentFragment(fragment)) {
      switch (fragment.part.pt) {
        case 'text':
          if (fragment.part.text.trim()) result.textCount++;
          break;
        case 'error':
          result.errorCount++;
          break;
        case 'image_ref':
          if (isImageRefPart(fragment.part)) {
            result.imageCount++;
          } else {
            console.warn('[DEV] Unexpected image_ref part:', { fragment });
          }
          break;
        case 'tool_invocation':
        case 'tool_response':
          result.toolCount++;
          break;
      }
    } else if (isAttachmentFragment(fragment)) {
      if (isImageRefPart(fragment.part)) {
        result.imageCount++;
      } else {
        result.attachmentCount++;
        result.attachments.push(fragment);
      }
    }
  });

  return result;
}


const styles = {
  listItem: {
    borderBottom: '1px solid',
    borderBottomColor: 'divider',
    typography: 'body-sm',
  } as const,

  tokenBadge: {
    display: 'flex',
    minWidth: { xs: 45, sm: 50 },
    justifyContent: 'flex-end',
  } as const,

  avatar: {
    display: { xs: 'none', sm: 'flex' } as const,
    minWidth: 40 as const,
    justifyContent: 'center',
  } as const,

  role: {
    minWidth: 52,
  } as const,

  message: {
    flexGrow: 1,
    textOverflow: 'ellipsis', overflow: 'hidden',
    // whiteSpace: 'nowrap',
    display: '-webkit-box',
    WebkitLineClamp: 2,
    WebkitBoxOrient: 'vertical',
    maxHeight: '2.9em',
  } as const,

} as const;


/**
 * Header bar for controlling the operations during the Selection mode
 */
export const MessagesSelectionHeader = (props: {
  hasSelected: boolean,
  sumTokens: number,
  onClose: () => void,
  onSelectAll: (selected: boolean) => void,
  onDeleteMessages: () => void,
  onToggleVisibility: () => void,
  areAllMessagesHidden: boolean,
}) =>
  <Sheet color='warning' variant='solid' invertedColors sx={{
    position: 'sticky', top: 0, left: 0, right: 0, zIndex: 5 /* Cleanup Selection Header on top of messages */,
    boxShadow: 'md',
    display: 'flex',
    flexDirection: 'row',
    alignItems: 'center',
    gap: { xs: 1, sm: 2 }, px: { xs: 1, md: 2 }, py: 1,
  }}>
    <Checkbox size='md' onChange={event => props.onSelectAll(event.target.checked)} sx={{ minWidth: 24, justifyContent: 'center' }} />

    <Box sx={{ fontSize: 'sm' }}>Select all ({props.sumTokens?.toLocaleString()})</Box>

    <Box sx={{ mx: 'auto', display: 'flex', gap: 1 }}>
      <Button
        size='sm'
        disabled={!props.hasSelected}
        onClick={props.onToggleVisibility}
        sx={{ minWidth: { md: 120 } }}
        endDecorator={props.areAllMessagesHidden ? <VisibilityIcon /> : <VisibilityOffIcon />}
      >
        {props.areAllMessagesHidden ? 'Show' : 'Hide'}
      </Button>
      <Button size='sm' disabled={!props.hasSelected} onClick={props.onDeleteMessages} sx={{ minWidth: { md: 120 } }} endDecorator={<DeleteOutlineIcon />}>
        Delete
      </Button>
    </Box>

    <IconButton size='sm' onClick={props.onClose}>
      <ClearIcon />
    </IconButton>
  </Sheet>;


/**
 * Small representation of a ChatMessage, used when in selection mode
 *
 * Shall look similarly to the main ChatMessage, for consistency, but just allow a simple checkbox selection
 */
export function CleanerMessage(props: { message: DMessage, selected: boolean, remainingTokens?: number, onToggleSelected?: (messageId: string, selected: boolean) => void }) {

  // derived state
  const {
    id: messageId,
    fragments: messageFragments,
    pendingIncomplete: messagePendingIncomplete,
    role: messageRole,
    purposeId: messagePurposeId,
    generator: messageGenerator,
    tokenCount: messageTokenCount,
    updated: messageUpdated,
  } = props.message;

  const analysis = React.useMemo(() => analyzeMessageFragments(messageFragments), [messageFragments]);

  let messageText = messageFragmentsReduceText(messageFragments, '\n\n', true);
  if (messageText.length > CLEANER_MESSAGE_MAX_LENGTH)
    messageText = messageText.substring(0, CLEANER_MESSAGE_MAX_LENGTH - 2) + '...';

  const fromAssistant = messageRole === 'assistant';

  const messageGeneratorName = messageGenerator?.name;

  const isUserMessageSkipped = messageHasUserFlag(props.message, MESSAGE_FLAG_AIX_SKIP);

  const isAssistantError = fromAssistant && isErrorChatMessage(messageText);

  const userCommandApprox = messageRole !== 'user' ? false
    : messageText.startsWith('/draw ') ? 'draw'
      : messageText.startsWith('/react ') ? 'react'
        : false;

  const backgroundColor = messageBackground(messageRole, userCommandApprox, !!messageUpdated, isAssistantError);

  const avatarIconEl: React.JSX.Element | null = React.useMemo(() => {
    return makeMessageAvatarIcon('pro', messageRole, messageGeneratorName, messagePurposeId, !!messagePendingIncomplete, isUserMessageSkipped, false, false);
  }, [isUserMessageSkipped, messageGeneratorName, messagePendingIncomplete, messagePurposeId, messageRole]);

  const handleCheckedChange = (event: React.ChangeEvent<HTMLInputElement>) =>
    props.onToggleSelected && props.onToggleSelected(messageId, event.target.checked);

  const hasChips = analysis.textCount > 1 || analysis.errorCount > 0 || analysis.toolCount > 0 || analysis.imageCount > 0 || analysis.attachmentCount > 0;

  return (
    <ListItem
      onClick={() => props.onToggleSelected?.(messageId, !props.selected)}
      sx={{
        backgroundColor,
        display: 'flex', flexDirection: !fromAssistant ? 'row' : 'row', alignItems: 'center',
        gap: { xs: 1, sm: 2 }, px: { xs: 1, md: 2 }, py: 2,
        ...styles.listItem,
        ...(isUserMessageSkipped && messageSkippedSx),
        // position: 'relative',
        '&:hover > button': { opacity: 1 },
      }}
    >

      {!!props.onToggleSelected && <Box sx={{ display: 'flex', minWidth: 24, justifyContent: 'center' }}>
        <Checkbox size='md' checked={props.selected} onChange={handleCheckedChange} sx={{ zIndex: 2 }} />
      </Box>}

      {props.remainingTokens !== undefined && <Box sx={styles.tokenBadge}>
        <TokenBadgeMemo direct={messageTokenCount} limit={props.remainingTokens} inline />
      </Box>}

      <Box sx={styles.avatar}>
        {avatarIconEl}
      </Box>

      <Box sx={styles.role}>
        {messageRole.replace('assistant', 'AI').replace('user', 'User').replace('system', 'Sys')}
      </Box>

      <Box sx={{ flexGrow: 1, display: 'flex', flexDirection: 'column', gap: 1 }}>

        <Box sx={styles.message}>
          {messageText || <span style={{ fontStyle: 'italic', color: 'text.tertiary' }}>No content</span>}
        </Box>

        {/* Fragment statistics chips row */}
        {hasChips && (
          <Box sx={{ display: 'flex', alignItems: 'center', gap: { xs: 1, sm: 2 }, mt: 1 }}>
            {analysis.textCount > 1 && (
              <Chip size='sm' variant='solid' color='neutral' startDecorator={<TextFieldsIcon />} sx={{ px: 1 }}>
                {analysis.textCount} sections
              </Chip>
            )}
            {analysis.errorCount > 0 && (
              <Chip size='sm' variant='solid' color='danger' startDecorator={<ErrorIcon />} sx={{ px: 1 }}>
                {analysis.errorCount} error{analysis.errorCount > 1 ? 's' : ''}
              </Chip>
            )}
            {analysis.toolCount > 0 && (
              <Chip size='sm' variant='solid' color='primary' sx={{ px: 1 }}>
                {analysis.toolCount} tool{analysis.toolCount > 1 ? 's' : ''}
              </Chip>
            )}
            {analysis.imageCount > 0 && (
              <Chip size='sm' variant='solid' color='success' startDecorator={<ImageIcon />} sx={{ px: 1 }}>
                {analysis.imageCount} image{analysis.imageCount > 1 ? 's' : ''}
              </Chip>
            )}
            {/*{analysis.attachmentCount > 0 && (*/}
            {/*  <Chip size='sm' variant='solid' color='primary' startDecorator={<AttachFileRoundedIcon />} sx={{ px: 1 }}>*/}
            {/*    {analysis.attachmentCount} file{analysis.attachmentCount > 1 ? 's' : ''}*/}
            {/*  </Chip>*/}
            {/*)}*/}

            {/* Individual attachment chips with names */}
            {analysis.attachments.map((attachment, idx) => {
              const name = attachment.title || 'Unnamed';
              const displayName = name.length > 20 ? name.slice(0, 17) + '...' : name;
              return (
                <Chip key={`att-${idx}`} size='sm' variant='outlined' color='primary' sx={{ px: 1 }} startDecorator={<AttachFileRoundedIcon />}>
                  {displayName}
                </Chip>
              );
            })}
          </Box>
        )}

      </Box>
    </ListItem>
  );
}


================================================
FILE: src/apps/chat/components/message/explainServiceErrors.tsx
================================================
import * as React from 'react';

import { Link } from '~/common/components/Link';


export function isErrorChatMessage(text: string) {
  if (!text) return false;
  return ['**[Service Issue] ', '[Issue] ', '[OpenAI Issue] '].some(prefix => text.startsWith(prefix));
}

export function explainServiceErrors(text: string, isAssistant: boolean) {
  const isAssistantError = isAssistant && isErrorChatMessage(text);
  if (!isAssistantError)
    return null;

  switch (true) {
    case text.includes('"insufficient_quota"'):
      return <>
        {/*The model appears to be occupied at the moment. Kindly try another model, try again after some time,*/}
        {/*or give it another go by selecting <b>Run again</b> from the message menu.*/}
        The OpenAI API key appears to have <b>insufficient quota</b>. Please
        check <Link noLinkStyle href='https://platform.openai.com/usage' target='_blank'>your usage</Link> and
        make sure the usage is under <Link noLinkStyle href='https://platform.openai.com/account/billing/limits' target='_blank'>the limits</Link>.
      </>;

    case text.includes('"invalid_api_key"'):
      return <>
        The OpenAI API key appears to be incorrect or to have expired.
        Please <Link noLinkStyle href='https://platform.openai.com/api-keys' target='_blank'>check your
        API key</Link> and update it in <b>Models</b>.
      </>;

    // [OpenAI] "Service Temporarily Unavailable (503)", {"code":503,"message":"Service Unavailable.","param":null,"type":"cf_service_unavailable"}
    case text.includes('"cf_service_unavailable"'):
      return <>
        The OpenAI servers appear to be having trouble at the moment. Kindly follow
        the <Link noLinkStyle href='https://status.openai.com/' target='_blank'>OpenAI Status</Link> page
        for up to date information, and at your option try again.
      </>;

    case text.includes('"context_length_exceeded"'):
      const pattern = /maximum context length is (\d+) tokens.+resulted in (\d+) tokens/;
      const match = pattern.exec(text);
      const usedText = match ? <b>{parseInt(match[2] || '0').toLocaleString()} tokens &gt; {parseInt(match[1] || '0').toLocaleString()}</b> : '';
      return <>
        This thread <b>surpasses the maximum size</b> allowed for this model. {usedText}.
        Please consider removing some earlier messages from the conversation, start a new conversation,
        choose a model with larger context, or submit a shorter new message.
        {!usedText && ` -- ${text}`}
      </>;
  }

  return null;
}


================================================
FILE: src/apps/chat/components/message/useSelHighlighterMemo.ts
================================================
import * as React from 'react';

import type { DMessageId } from '~/common/stores/chat/chat.message';
import { createTextContentFragment, DMessageContentFragment, DMessageFragment, DMessageFragmentId, isTextContentFragment } from '~/common/stores/chat/chat.fragments';
import { wrapWithMarkdownSyntax } from '~/modules/blocks/markdown/markdown.wrapper';

import { BUBBLE_MIN_TEXT_LENGTH } from './ChatMessage';


/* Note: future evolution of Marking:
 * 'data-purpose'?: 'review' | 'important' | 'note'; // Purpose of the highlight
 * 'data-user-id'?: string; // Unique user identifier
 * 'data-context'?: string; // Context or description of the highlight
 * 'data-version'?: string; // Version of the document/content
 * 'data-platform'?: 'web' | 'mobile' | 'extension'; // Platform or tool that created the highlight
 * 'data-category'?: string; // Category for organization
 *
 * Example:
 * <mark id="highlight-123" data-purpose="important" data-user-id="user123" data-context="Key point in the document" data-version="1.0" data-platform="web" data-category="summary">
 *   This is an important highlight.
 * </mark>
 */
const APPLY_HTML_HIGHLIGHT = (text: string) => `<mark>${text}</mark>`;
const APPLY_HTML_STRIKE = (text: string) => `<del>${text}</del>`;
const APPLY_MD_STRONG = (text: string) => wrapWithMarkdownSyntax(text, '**');
const APPLY_CUT = (_text: string) => ''; // Cut removes the text entirely

type HighlightTool = 'highlight' | 'strike' | 'strong' | 'cut';

export function useSelHighlighterMemo(
  messageId: DMessageId,
  selText: string | null,
  fragments: DMessageContentFragment[],
  fromAssistant: boolean,
  onMessageFragmentReplace?: (messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment) => void,
): ((tool: HighlightTool) => void) | null {
  return React.useMemo(() => {

    // Existence check
    if (!selText || selText.length < BUBBLE_MIN_TEXT_LENGTH || !fromAssistant || !onMessageFragmentReplace)
      return null;

    // Create the highlighter function, if there's 1 and only 1 occurrence of the selection
    const highlightFunction = fragments.reduce((acc: false /* not found */ | ((tool: HighlightTool) => void) | true /* more than one */, fragment) => {
      if (!acc && isTextContentFragment(fragment)) {
        const fragmentText = fragment.part.text;
        let index = fragmentText.indexOf(selText);

        while (index !== -1) {

          // If we've found more than one occurrence, we can stop
          if (acc) return true;

          index = fragmentText.indexOf(selText, index + 1);

          // Tool application function
          acc = (tool: HighlightTool) => {

            // Apply the tool
            const highlighted =
              tool === 'highlight' ? APPLY_HTML_HIGHLIGHT(selText)
                : tool === 'strike' ? APPLY_HTML_STRIKE(selText)
                  : tool === 'strong' ? APPLY_MD_STRONG(selText)
                    : tool === 'cut' ? APPLY_CUT(selText)
                      : selText;

            // Toggle, if the tooled text is already present (except for cut which always removes)
            const newFragmentText =
              tool === 'cut' ? fragmentText.replace(selText, highlighted) // Cut always removes text
                : fragmentText.includes(highlighted) ? fragmentText.replace(highlighted, selText) // toggles selection
                  : fragmentText.replace(selText, highlighted);

            // Replace the whole fragment within the message
            onMessageFragmentReplace(messageId, fragment.fId, createTextContentFragment(newFragmentText));

          };
        }
      }
      return acc;
    }, false);

    return typeof highlightFunction === 'function' ? highlightFunction : null;
  }, [fragments, fromAssistant, messageId, onMessageFragmentReplace, selText]);
}



================================================
FILE: src/apps/chat/components/message/fragments-attachment-doc/DocAttachmentFragment.tsx
================================================
import * as React from 'react';

import { Box, Button, Switch, Tooltip, Typography } from '@mui/joy';
import CheckRoundedIcon from '@mui/icons-material/CheckRounded';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import EditRoundedIcon from '@mui/icons-material/EditRounded';

import { AutoBlocksRenderer } from '~/modules/blocks/AutoBlocksRenderer';
import { enhancedCodePanelTitleTooltipSx, RenderCodePanelFrame } from '~/modules/blocks/code/RenderCodePanelFrame';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';
import type { LiveFileId } from '~/common/livefile/liveFile.types';
import { DMessageAttachmentFragment, DMessageDocPart, DMessageFragmentId, DVMimeType, isDocPart, updateFragmentWithEditedText } from '~/common/stores/chat/chat.fragments';
import { InlineTextarea } from '~/common/components/InlineTextarea';
import { useContextWorkspaceId } from '~/common/stores/workspace/WorkspaceIdProvider';
import { useScrollToBottom } from '~/common/scroll-to-bottom/useScrollToBottom';

import { BlockEdit_TextFragment } from '../fragments-content/BlockEdit_TextFragment';
import { buttonIconForFragment, DocSelColor } from './DocAttachmentFragmentButton';
import { useLiveFileSync } from './livefile-sync/useLiveFileSync';


// configuration
const FALLBACK_NO_TITLE = 'Untitled Attachment';


const _styles = {
  button: {
    minWidth: 100,
  } as const,
  titleDisabled: {
    opacity: 0.5,
  } as const,
  titleEditable: {
    cursor: 'pointer',
    '&:hover': { textDecoration: 'underline' } as const,
  } as const,
  titleTextArea: {
    minWidth: 200,
    flexGrow: 1,
  } as const,
} as const;


function _inferInitialViewAsCode(attachmentFragment: DMessageAttachmentFragment) {
  if (!isDocPart(attachmentFragment.part))
    return false;
  // just use the mime of the doc part
  return attachmentFragment.part.vdt === DVMimeType.VndAgiCode;
}


export function DocAttachmentFragment(props: {
  fragment: DMessageAttachmentFragment,
  controlledEditor: boolean,
  editedText?: string,
  setEditedText: (fragmentId: DMessageFragmentId, value: string) => void,
  messageRole: DMessageRole,
  contentScaling: ContentScaling,
  isMobile: boolean,
  zenMode: boolean,
  disableMarkdownText: boolean,
  onFragmentDelete?: (fragmentId: DMessageFragmentId) => void,
  onFragmentReplace?: (fragmentId: DMessageFragmentId, newContent: DMessageAttachmentFragment) => void,
}) {

  // state
  const [isDeleteArmed, setIsDeleteArmed] = React.useState(false);
  const [isEditing, setIsEditing] = React.useState(false);
  const [isEditingTitle, setIsEditingTitle] = React.useState(false);
  const [viewAsCode, setViewAsCode] = React.useState(() => _inferInitialViewAsCode(props.fragment));

  // external state
  const workspaceId = useContextWorkspaceId();
  const { skipNextAutoScroll } = useScrollToBottom();

  // derived state
  const { editedText, fragment, onFragmentDelete, onFragmentReplace } = props;


  const fragmentId = fragment.fId;
  const fragmentDocPart = fragment.part;

  if (!isDocPart(fragmentDocPart))
    throw new Error('Unexpected part type: ' + fragmentDocPart.pt);

  const fragmentTitle = fragmentDocPart.l1Title || fragment.caption; // what's this for?
  const reverseToolbar = props.messageRole === 'assistant';

  const displayTitle = fragmentDocPart.meta?.srcFileName || fragmentDocPart.l1Title || fragmentDocPart.ref || FALLBACK_NO_TITLE;

  const showDeleteInstead = typeof editedText === 'string' && editedText.length === 0 && !!onFragmentDelete;


  // hooks

  const handleReplaceDocFragmentText = React.useCallback((newText: string) => {
    if (!onFragmentReplace) return;

    // replacement fragment (same fId), and stop if not replaced
    const newFragment = updateFragmentWithEditedText(fragment, newText);
    if (!newFragment) return;

    // Note: this reuses the same fragment ID, which makes the screen not flash (otherwise the whole editor would disappear as the ID does not exist anymore)
    onFragmentReplace?.(fragmentId, newFragment as DMessageAttachmentFragment);
  }, [fragment, fragmentId, onFragmentReplace]);

  const handleReplaceFragmentLiveFileId = React.useCallback((liveFileId: LiveFileId) => {
    onFragmentReplace?.(fragmentId, { ...fragment, liveFileId: liveFileId });
  }, [fragment, fragmentId, onFragmentReplace]);


  const handleTitleEditBegin = React.useCallback(() => {
    if (!onFragmentReplace) return;
    setIsEditing(false);
    setIsEditingTitle(true);
  }, [onFragmentReplace]);

  const handleTitleEditCancel = React.useCallback(() => {
    setIsEditingTitle(false);
  }, []);

  const handleTitleEditSave = React.useCallback((newTitle: string) => {
    setIsEditingTitle(false);
    if (!newTitle.trim() || newTitle === displayTitle || !onFragmentReplace) return;

    // retitle the fragment, without changing Id
    const newDocPart: DMessageDocPart = { ...fragmentDocPart, l1Title: newTitle, version: (fragmentDocPart?.version ?? 1) + 1 };
    const newFragment: DMessageAttachmentFragment = { ...fragment, title: newTitle, part: newDocPart };

    onFragmentReplace(fragment.fId, newFragment);
  }, [displayTitle, fragment, fragmentDocPart, onFragmentReplace]);


  // LiveFile sync

  const disableLiveFile = !onFragmentReplace
    || !workspaceId; // NOTE: this is a trick for when used outside of a WorkspaceId context provider

  const { liveFileControlButton, liveFileActions } = useLiveFileSync(
    fragment.liveFileId ?? null,
    workspaceId,
    props.isMobile,
    fragmentDocPart.data.text,
    disableLiveFile ? undefined : handleReplaceFragmentLiveFileId,
    disableLiveFile ? undefined : handleReplaceDocFragmentText,
  );


  // delete

  const handleFragmentDelete = React.useCallback(() => {
    onFragmentDelete?.(fragmentId);
  }, [fragmentId, onFragmentDelete]);

  const handleToggleDeleteArmed = React.useCallback((event: React.MouseEvent) => {
    // reset other states when entering Delete
    if (!isDeleteArmed) {
      // setIsLiveFileArmed(false);
      // setIsEditing(false);
    }
    if (!isDeleteArmed && event.shiftKey) // immadiately delete:fragment
      handleFragmentDelete();
    else
      setIsDeleteArmed(on => !on);
  }, [handleFragmentDelete, isDeleteArmed]);


  // edit

  const handleEditApply = React.useCallback(() => {
    setIsDeleteArmed(false);

    if (props.controlledEditor) {
      setIsEditing(false);
      setIsEditingTitle(false); // just in case
      return; // controlled editor, already applied, delete is only allowed via the button
    }

    if (editedText === undefined)
      return;

    if (editedText.length > 0 || !onFragmentDelete) {
      handleReplaceDocFragmentText(editedText);
      setIsEditing(false);
      setIsEditingTitle(false); // just in case
    } else {
      // if the user deleted all text, let's remove the part
      handleFragmentDelete();
    }
  }, [editedText, handleFragmentDelete, handleReplaceDocFragmentText, onFragmentDelete, props.controlledEditor]);

  const handleToggleEdit = React.useCallback(() => {
    // reset other states when entering Edit
    if (!isEditing) {
      setIsEditingTitle(false); // cancel title edit
      setIsDeleteArmed(false);
      // setIsLiveFileArmed(false);
      // resetLiveFileState();
      skipNextAutoScroll();
    }
    setIsEditing(on => !on);
  }, [isEditing, skipNextAutoScroll]);


  // view as code

  const handleToggleViewAsCode = React.useCallback(() => {
    setViewAsCode(on => !on);
  }, []);


  // memoed components

  const viewAsLabel =
    !viewAsCode ? (fragmentDocPart.vdt ? 'text' : '(unknown)')
      : (fragmentDocPart.data.mimeType && fragmentDocPart.data.mimeType !== fragmentDocPart.vdt) ? fragmentDocPart.data.mimeType || ''
        : '';

  const headerTooltipContents = React.useMemo(() => (
    <Box sx={enhancedCodePanelTitleTooltipSx}>
      <div>Attachment Title</div>
      <div>{fragment.title}</div>
      <div>Identifier</div>
      <div>{fragmentDocPart.ref}</div>
      <div>Doc Title</div>
      <div>{fragmentDocPart.l1Title}</div>
      <div>Doc Version</div>
      <div>{fragmentDocPart.version || '(none)'}</div>
      <div>Text Mime type</div>
      <div>{fragmentDocPart.data?.mimeType || '(unknown)'}</div>
      <div>Render type</div>
      <div>{fragmentDocPart.vdt}</div>
      <div>Text Buffer Id</div>
      <div>{fragmentId}</div>
      {!!fragment.caption && <div>Att. Caption</div>}
      {!!fragment.caption && <div>{fragment.caption}</div>}
      <div>view as code</div>
      <Switch
        size='sm'
        variant='solid'
        color='neutral'
        checked={viewAsCode}
        onChange={handleToggleViewAsCode}
        endDecorator={viewAsLabel}
      />
    </Box>
  ), [fragment.caption, fragment.title, fragmentDocPart, fragmentId, handleToggleViewAsCode, viewAsCode, viewAsLabel]);


  const headerRow = React.useMemo(() => {
    const TitleIcon = buttonIconForFragment(fragmentDocPart);

    return <>
      <Box sx={{ flex: 1, display: 'flex', alignItems: 'center', gap: 1, overflow: 'hidden' }}>

        <Tooltip arrow variant='outlined' color='neutral' placement='top-start' title={headerTooltipContents}>
          {TitleIcon && <TitleIcon />}
        </Tooltip>

        {(!isEditingTitle || isEditing) ? (
          <Typography
            level='title-sm'
            onClick={isEditing ? undefined : onFragmentReplace ? handleTitleEditBegin : undefined}
            sx={isEditing ? _styles.titleDisabled : onFragmentReplace ? _styles.titleEditable : undefined}
            className='agi-ellipsize'
          >
            {displayTitle}
          </Typography>
        ) : (
          <InlineTextarea
            initialText={displayTitle}
            placeholder='Document title'
            onEdit={handleTitleEditSave}
            onCancel={handleTitleEditCancel}
            sx={_styles.titleTextArea}
          />
        )}

      </Box>

      {/* Live File Control button */}
      {!isEditing && liveFileControlButton}

    </>;
  }, [displayTitle, fragmentDocPart, handleTitleEditBegin, handleTitleEditCancel, handleTitleEditSave, headerTooltipContents, isEditing, isEditingTitle, liveFileControlButton, onFragmentReplace]);


  const toolbarRow = React.useMemo(() => (!onFragmentDelete && !onFragmentReplace) ? null : (
    <Box sx={{
      display: 'flex',
      flexDirection: !reverseToolbar ? 'row' : 'row-reverse',
      flexWrap: 'wrap',
      justifyContent: 'space-between',
      gap: 1,
    }}>

      {/* Delete / Confirm */}
      {!!onFragmentDelete && (
        <Box sx={{ display: 'flex', flexDirection: !reverseToolbar ? 'row' : 'row-reverse', gap: 1 }}>
          {!isEditing && <Button
            variant='soft'
            color={DocSelColor}
            size='sm'
            onClick={handleToggleDeleteArmed}
            startDecorator={isDeleteArmed ? <CloseRoundedIcon /> : <DeleteOutlineIcon />}
            sx={_styles.button}
          >
            {isDeleteArmed ? 'Cancel' : 'Delete'}
          </Button>}
          {isDeleteArmed && (
            <Button
              variant='solid'
              color='danger'
              size='sm'
              onClick={handleFragmentDelete}
              startDecorator={<DeleteForeverIcon />}
            >
              Delete
            </Button>
          )}
        </Box>
      )}

      {/* Edit / Save */}
      {!!onFragmentReplace && (
        <Box sx={{ display: 'flex', flexDirection: !reverseToolbar ? 'row' : 'row-reverse', gap: 1 }}>
          {(!props.controlledEditor || !isEditing) && <Button
            variant='soft'
            color={DocSelColor}
            size='sm'
            onClick={handleToggleEdit}
            startDecorator={isEditing ? <CloseRoundedIcon /> : <EditRoundedIcon />}
            sx={_styles.button}
          >
            {isEditing ? 'Cancel' : 'Edit'}
          </Button>}
          {isEditing && (
            <Button
              variant={props.controlledEditor ? 'soft' : 'solid'}
              color={showDeleteInstead ? 'danger' : props.controlledEditor ? undefined : 'success'}
              onClick={handleEditApply}
              size='sm'
              startDecorator={showDeleteInstead ? <DeleteForeverIcon /> : props.controlledEditor ? undefined : <CheckRoundedIcon />}
              sx={_styles.button}
            >
              {!showDeleteInstead ? 'Save' : 'Delete'}
            </Button>
          )}
        </Box>
      )}
    </Box>
  ), [handleEditApply, handleFragmentDelete, handleToggleDeleteArmed, handleToggleEdit, isDeleteArmed, isEditing, onFragmentDelete, onFragmentReplace, props.controlledEditor, reverseToolbar, showDeleteInstead]);


  return (
    <RenderCodePanelFrame
      color={DocSelColor}
      contentScaling={props.contentScaling}
      headerRow={headerRow}
      subHeaderInline={!isEditing && liveFileActions}
      toolbarRow={toolbarRow}
      selectedOutline
    >

      {/* Show / Edit the Document Attachment Part */}
      {isEditing ? (
        // Document Editor
        <BlockEdit_TextFragment
          initialText={fragmentDocPart.data.text}
          fragmentId={fragmentId}
          contentScaling={props.contentScaling}
          controlled={props.controlledEditor}
          editedText={editedText}
          setEditedText={props.setEditedText}
          squareTopBorder
          onSubmit={handleEditApply}
          onEscapePressed={handleToggleEdit}
          // endDecorator={editedText ? 'Shift+Enter to save · Escape to cancel.' : 'No changes · Escape to cancel.'}
        />
      ) : (
        // Document viewer, including the collapse/expand state inside
        <Box py={1}>
          <AutoBlocksRenderer
            // text={marshallWrapText(fragmentDocPart.data.text, /*part.meta?.srcFileName || part.ref*/ undefined, 'markdown-code')}
            text={fragmentDocPart.data.text}
            renderAsCodeWithTitle={viewAsCode ? (fragmentDocPart.data?.mimeType || fragmentDocPart.ref || fragmentTitle) : undefined}
            fromRole={props.messageRole}
            contentScaling={props.contentScaling}
            fitScreen={props.isMobile}
            isMobile={props.isMobile}
            codeRenderVariant='plain'
            textRenderVariant={props.disableMarkdownText ? 'text' : 'markdown'}
          />
        </Box>
      )}

    </RenderCodePanelFrame>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-attachment-doc/DocAttachmentFragmentButton.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ColorPaletteProp } from '@mui/joy';
import AbcIcon from '@mui/icons-material/Abc';
import CodeIcon from '@mui/icons-material/Code';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import ImageOutlinedIcon from '@mui/icons-material/ImageOutlined';
import PictureAsPdfIcon from '@mui/icons-material/PictureAsPdf';
import TextFieldsIcon from '@mui/icons-material/TextFields';
import TextureIcon from '@mui/icons-material/Texture';

import { ContentScaling, themeScalingMap } from '~/common/app.theme';
import { DMessageAttachmentFragment, DMessageFragmentId, DVMimeType, isDocPart } from '~/common/stores/chat/chat.fragments';
import { LiveFileIcon } from '~/common/livefile/liveFile.icons';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { ellipsizeMiddle } from '~/common/util/textUtils';
import { useLiveFileMetadata } from '~/common/livefile/useLiveFileMetadata';


// configuration
export const DocSelColor: ColorPaletteProp = 'primary';
const DocUnselColor: ColorPaletteProp = 'primary';


export function buttonIconForFragment(part: DMessageAttachmentFragment['part']): React.ComponentType<any> {
  switch (part.pt) {
    case 'doc':
      switch (part.vdt) {
        case DVMimeType.TextPlain:
          return TextFieldsIcon;
        case DVMimeType.VndAgiCode:
          return CodeIcon;
        case DVMimeType.VndAgiOcr:
          return part.meta?.srcOcrFrom === 'image' ? AbcIcon : PictureAsPdfIcon;
        // NOTE: the objective is to grow this set, but wisely
        // - no rush to fill the space, as we need data at rest & in flight (for auto type conversion) support,
        //   including the reintepretation of the deta in the Aix.Adapters
        // case INT_MIME_VND_AGI_EGO_FRAGMENTS:
        //   return TelegramIcon;
        // case INT_MIME_AGI_TEXT_HTML:
        //   return CodeIcon;
        // case 'text/markdown':
        //   return CodeIcon;
        default:
          return TextureIcon;
      }
    case 'image_ref':
      return ImageOutlinedIcon;
    case '_pt_sentinel':
      return TextureIcon;
  }
}


export function DocAttachmentFragmentButton(props: {
  fragment: DMessageAttachmentFragment,
  contentScaling: ContentScaling,
  isSelected: boolean,
  isSelectable: boolean,
  toggleSelected: (fragmentId: DMessageFragmentId) => void,
}) {

  // external state
  const liveFileMetadata = useLiveFileMetadata(props.fragment.liveFileId);

  // derived state
  const { fragment, isSelected, toggleSelected } = props;
  const hasLiveFile = !!liveFileMetadata;
  const isLiveFilePaired = liveFileMetadata ? liveFileMetadata.isPairingValid || false : false;

  // handlers
  const handleSelectFragment = React.useCallback(() => {
    toggleSelected(fragment.fId);
  }, [fragment.fId, toggleSelected]);

  // memos
  const buttonSx = React.useMemo((): SxProps => ({
    // from ATTACHMENT_MIN_STYLE
    // height: '100%',
    minHeight: props.contentScaling === 'md' ? 40 : props.contentScaling === 'sm' ? 38 : 36,
    minWidth: '64px',
    maxWidth: '340px',
    padding: 0,

    // style
    fontSize: themeScalingMap[props.contentScaling]?.fragmentButtonFontSize ?? undefined,
    border: '1px solid',
    borderRadius: 'sm',
    boxShadow: isSelected ? undefined : `0px 3px 4px -2px rgb(var(--joy-palette-${isSelected ? DocSelColor : DocUnselColor}-darkChannel) / ${isSelected ? 50 : 20}%)`,
    ...isSelected ? {
      borderColor: `${DocSelColor}.solidBg`,
    } : {
      borderColor: `${DocUnselColor}.outlinedBorder`,
      backgroundColor: 'background.popup',
    },

    // from LLMAttachmentButton
    display: 'flex', flexDirection: 'row',
  }), [isSelected, props.contentScaling]);

  // only operate on doc fragments
  if (!isDocPart(fragment.part))
    return 'Unexpected: ' + fragment.part.pt;

  const buttonText = ellipsizeMiddle(fragment.part.l1Title || fragment.title || 'Document', 28 /* totally arbitrary length */);

  const Icon = isSelected ? EditRoundedIcon : buttonIconForFragment(fragment.part);

  return (
    <Button
      size={props.contentScaling === 'md' ? 'md' : 'sm'}
      variant={isSelected ? 'solid' : 'soft'}
      color={isSelected ? DocSelColor : DocUnselColor}
      disabled={!props.isSelectable}
      onClick={handleSelectFragment}
      sx={buttonSx}
    >
      {!!Icon && (
        <Box sx={{
          height: '80%', // was 100%, but it's neat-o to have the line a bit engraved
          paddingX: '0.5rem',
          borderRight: '1px solid',
          borderRightColor: isSelected ? `${DocSelColor}.solidBg` : `${DocUnselColor}.outlinedDisabledBorder`, // this was outlinedBorder
          display: 'flex', alignItems: 'center',
        }}>
          <Icon />
        </Box>
      )}
      <Box sx={{ display: 'flex', flexDirection: 'column', alignItems: 'flex-start', paddingX: '0.5rem' }}>
        <Box sx={{ whiteSpace: 'nowrap', fontWeight: 'md', minWidth: 48 }}>
          {buttonText}
        </Box>
        {/*<Box sx={{ fontSize: 'xs', fontWeight: 'sm' }}>*/}
        {/*  {fragment.caption}*/}
        {/*</Box>*/}
      </Box>
      {hasLiveFile && (
        <TooltipOutlined
          title={!isLiveFilePaired ? 'LiveFile needs re-pairing.' : 'LiveFile is supported'}
          color={!isLiveFilePaired ? 'danger' : 'success'}
          placement='top-end'
        >
          <LiveFileIcon
            color={!isSelected ? 'success' : undefined}
            sx={{ mr: '0.5rem', color: (!isLiveFilePaired && !isSelected) ? 'darkred' : undefined }}
          />
        </TooltipOutlined>
      )}
    </Button>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-attachment-doc/DocumentAttachmentFragments.tsx
================================================
import * as React from 'react';
import { Box } from '@mui/joy';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';
import { DMessageAttachmentFragment, DMessageFragmentId, isDocPart, updateFragmentWithEditedText } from '~/common/stores/chat/chat.fragments';

import type { ChatMessageTextPartEditState } from '../ChatMessage';
import { DocAttachmentFragmentButton } from './DocAttachmentFragmentButton';
import { DocAttachmentFragment } from './DocAttachmentFragment';


/**
 * Displays a list of 'cards' which are buttons with a mutually exclusive active state.
 * When one is active, there is a content part just right under (with the collapse mechanism in case it's a user role).
 * If one is clicked the content part (use ContentPartText) is displayed.
 */
export function DocumentAttachmentFragments(props: {
  attachmentFragments: DMessageAttachmentFragment[],
  messageRole: DMessageRole,
  contentScaling: ContentScaling,
  isMobile: boolean,
  zenMode: boolean,
  allowSelection: boolean,
  disableMarkdownText: boolean,
  onFragmentDelete?: (fragmentId: DMessageFragmentId) => void,
  onFragmentReplace?: (fragmentId: DMessageFragmentId, newFragment: DMessageAttachmentFragment) => void,
}) {

  // state
  const [_activeFragmentId, setActiveFragmentId] = React.useState<DMessageFragmentId | null>(null);
  const [editState, setEditState] = React.useState<ChatMessageTextPartEditState | null>(null);


  // derived state
  const isSelectable = props.allowSelection;
  const activeFragmentId = !isSelectable ? null : _activeFragmentId;


  // selection

  const handleToggleSelectedId = React.useCallback((fragmentId: DMessageFragmentId) => {
    if (isSelectable)
      setActiveFragmentId(prevId => prevId === fragmentId ? null : fragmentId);
  }, [isSelectable]);

  const selectedFragment = props.attachmentFragments.find(fragment => fragment.fId === activeFragmentId);


  // editing

  const controlledEditor = false;
  const { onFragmentReplace } = props;

  const handleEditSetText = React.useCallback((fragmentId: DMessageFragmentId, value: string) => {
    if (!onFragmentReplace || !selectedFragment) return;

    // uncontrolled: store edits as overlay state
    if (!controlledEditor) {
      setEditState(prevState => ({ ...prevState, [fragmentId]: value }));
      return;
    }

    // edited text fragment
    const updatedFragment = updateFragmentWithEditedText(selectedFragment, value);
    if (!updatedFragment) return;

    // alter parent state
    onFragmentReplace(fragmentId, updatedFragment);
  }, [controlledEditor, onFragmentReplace, selectedFragment]);

  const handleFragmentReplace = React.useCallback((fragmentId: DMessageFragmentId, newFragment: DMessageAttachmentFragment) => {
    if (!onFragmentReplace) return;

    // reset the edit overlay state
    if (!controlledEditor) {
      setEditState(prevState => {
        const newState = { ...prevState };
        delete newState[fragmentId];
        return newState;
      });
    }

    // alter parent state
    onFragmentReplace(fragmentId, newFragment);
  }, [controlledEditor, onFragmentReplace]);


  // [effect] clear edits on onmount
  React.useEffect(() => {
    return () => setEditState(null);
  }, []);


  // memos
  const buttonsSx = React.useMemo(() => ({
    // layout
    display: 'flex',
    flexWrap: 'wrap',
    gap: 1,
    justifyContent: props.messageRole === 'assistant' ? 'flex-start' : 'flex-end',
    ...selectedFragment && { mb: 1 },
  }), [props.messageRole, selectedFragment]);


  return (
    <Box aria-label={`${props.attachmentFragments.length} attachments`} sx={{
      // layout
      display: 'flex',
      flexDirection: 'column',
    }}>

      {/* Document buttons */}
      <Box sx={buttonsSx}>
        {props.attachmentFragments.map((attachmentFragment) =>
          <DocAttachmentFragmentButton
            key={attachmentFragment.fId}
            fragment={attachmentFragment}
            contentScaling={props.contentScaling}
            isSelected={activeFragmentId === attachmentFragment.fId}
            isSelectable={props.allowSelection}
            toggleSelected={handleToggleSelectedId}
          />,
        )}
      </Box>

      {/* Document Viewer & Editor */}
      {!!selectedFragment && isDocPart(selectedFragment.part) && (
        <DocAttachmentFragment
          key={selectedFragment.fId /* this is here for the useLiveFile hook which otherwise would migrate state across fragments */}
          fragment={selectedFragment}
          controlledEditor={controlledEditor}
          messageRole={props.messageRole}
          editedText={controlledEditor ? undefined : editState?.[selectedFragment.fId]}
          setEditedText={handleEditSetText}
          contentScaling={props.contentScaling}
          isMobile={props.isMobile}
          zenMode={props.zenMode}
          disableMarkdownText={props.disableMarkdownText}
          onFragmentDelete={props.onFragmentDelete}
          onFragmentReplace={!props.onFragmentReplace ? undefined : handleFragmentReplace}
        />
      )}

    </Box>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-attachment-doc/livefile-sync/LiveFileControlButton.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ColorPaletteProp, SvgIcon } from '@mui/joy';
import UploadFileRoundedIcon from '@mui/icons-material/UploadFileRounded';

import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { getFirstFileSystemFileHandle } from '~/common/util/fileSystemUtils';
import { useDragDropDataTransfer } from '~/common/components/dnd-dt/useDragDropDataTransfer';

import { LiveFileChooseIcon, LiveFileIcon } from '~/common/livefile/liveFile.icons';


// configuration
const BUTTON_COLOR: ColorPaletteProp = 'neutral';


// const controlButtonSx: SxProps = {
//   minHeight: 36,
// };

const refreshButtonSx: SxProps = {
  // border: '1px solid',
  // borderColor: `${BUTTON_COLOR}.outlinedBorder`,
  boxShadow: `inset 0 4px 6px -6px rgb(var(--joy-palette-${BUTTON_COLOR}-darkChannel) / 40%)`,
};


export function LiveFileControlButton(props: {
  disabled: boolean;
  hasContent: boolean;
  hideWhenHasContent: boolean;
  isPaired: boolean;
  onPairWithFSFHandle: (fsHandle: FileSystemFileHandle) => Promise<any>;
  onPairWithPicker: () => Promise<any>;
  onUpdateFileContent: () => Promise<any>;
}) {

  const { onPairWithFSFHandle, onPairWithPicker, onUpdateFileContent } = props;

  // state

  const handleDataTransfer = React.useCallback(async (dataTransfer: DataTransfer) => {
    const fsfHandle = await getFirstFileSystemFileHandle(dataTransfer);
    if (fsfHandle)
      await onPairWithFSFHandle(fsfHandle);
  }, [onPairWithFSFHandle]);

  const { dragContainerSx, dropComponent, handleContainerDragEnter, handleContainerDragStart } =
    useDragDropDataTransfer(true, 'Pair', UploadFileRoundedIcon as typeof SvgIcon, 'startDecorator', true, handleDataTransfer);

  // hooks

  const handleOnClick = React.useCallback(async () => {
    if (props.isPaired)
      await onUpdateFileContent();
    else
      await onPairWithPicker();
  }, [onPairWithPicker, onUpdateFileContent, props.isPaired]);

  if (props.hideWhenHasContent && props.hasContent)
    return null;

  return (
    <Box
      onDragEnter={handleContainerDragEnter}
      onDragStart={handleContainerDragStart}
      sx={dragContainerSx}
    >
      <TooltipOutlined
        title={
          props.hasContent ? 'Reload and compare file contents'
            : props.isPaired ? 'Sync and monitor file changes'
              : 'Set up live file pairing (you can also drag and drop a file here)'
        }
        color='success'
        placement='top-end'
      >
        <Button
          variant={props.hasContent ? 'outlined' : 'plain'}
          color={BUTTON_COLOR}
          size='sm'
          disabled={props.disabled}
          onClick={handleOnClick}
          endDecorator={
            props.hasContent ? <LiveFileIcon color='success' />
              : props.isPaired ? <LiveFileIcon color='success' />
                : <LiveFileChooseIcon color='success' />
          }
          sx={props.hasContent ? refreshButtonSx : undefined /*controlButtonSx*/}
        >
          {props.hasContent ? 'Refresh'
            : props.isPaired ? 'Enable Sync'
              : 'Pair File'}
        </Button>
      </TooltipOutlined>

      {dropComponent}
    </Box>
  );
}


================================================
FILE: src/apps/chat/components/message/fragments-attachment-doc/livefile-sync/useLiveFileSync.tsx
================================================
import * as React from 'react';
import { diffLines } from 'diff';
import { fileOpen } from 'browser-fs-access';

import { Box, Button, ColorPaletteProp, Dropdown, IconButton, ListDivider, ListItemDecorator, Menu, MenuButton, MenuItem, Sheet } from '@mui/joy';
import MoreVertIcon from '@mui/icons-material/MoreVert';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import type { DWorkspaceId } from '~/common/stores/workspace/workspace.types';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { WindowFocusObserver } from '~/common/util/windowUtils';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';
import { workspaceActions } from '~/common/stores/workspace/store-client-workspace';

import type { LiveFileId } from '~/common/livefile/liveFile.types';
import { LiveFileChooseIcon, LiveFileCloseIcon, LiveFileIcon, LiveFileReloadIcon, LiveFileSaveIcon } from '~/common/livefile/liveFile.icons';
import { isLiveFileSupported, liveFileCreateOrThrow } from '~/common/livefile/store-live-file';
import { liveFileSheetSx } from '~/common/livefile/livefile.theme';
import { useLiveFileContent } from '~/common/livefile/useLiveFileContent';

import { LiveFileControlButton } from './LiveFileControlButton';


interface LinesDiffSummary {
  insertions: number;
  deletions: number;
}

function _computeLineDiffStats(fromText: string, toText: string): LinesDiffSummary {
  // compute the insertions and deletions diff - NOTE: lines are the most common
  return (diffLines(fromText, toText) || []).reduce((acc, part) => {
    if (part.added) acc.insertions += part.count ?? 1;
    if (part.removed) acc.deletions += part.count ?? 1;
    return acc;
  }, { insertions: 0, deletions: 0 });
}


interface FileOperationStatus {
  message: React.ReactNode;
  mtype: 'info' | 'changes' | 'success' | 'error';
}


export function useLiveFileSync(
  _liveFileId: LiveFileId | null,
  workspaceId: DWorkspaceId | null,
  isMobile: boolean,
  bufferText: string,
  onReplaceLiveFileId?: (liveFileId: LiveFileId) => void,
  onSetBufferText?: (text: string) => void,
) {

  // state
  const { showPromisedOverlay } = useOverlayComponents();
  const [diffSummary, setDiffSummary] = React.useState<LinesDiffSummary | null>(null);
  const [status, setStatus] = React.useState<FileOperationStatus | null>(null);

  // external state
  const {
    fileData,
    isPairingValid,
    liveFileContentClose,
    liveFileContentReloadFromDisk,
    liveFileContentWriteAndReload,
  } = useLiveFileContent(_liveFileId);

  // derived state
  const fileContent = fileData?.content ?? undefined;
  const fileErrorText = fileData?.error ?? undefined;
  const isLoadingFile = fileData?.isLoading ?? false;
  const isSavingFile = fileData?.isSaving ?? false;

  const fileHasContent = fileContent !== undefined;
  const fileIsDifferent = !!diffSummary?.deletions || !!diffSummary?.insertions;

  const shallUpdateOnRefocus = isPairingValid && fileHasContent;


  // [effect] Auto-compute the diffs when the underlying text changes
  React.useEffect(() => {
    if (fileContent === undefined || bufferText === undefined) {
      setDiffSummary(null);
      return;
    }

    // Same content: no diff
    if (fileContent === bufferText) {
      setDiffSummary({ insertions: 0, deletions: 0 });
      setStatus({ message: isMobile ? 'Identical to File.' : 'No changes.' /* 'The File is identical to this Document.'*/, mtype: 'info' });
      return;
    }

    // Compute the diff
    const lineDiffs = _computeLineDiffStats(bufferText, fileContent);
    setDiffSummary(lineDiffs);
    if (lineDiffs.insertions && lineDiffs.deletions)
      setStatus({
        message: <>File has {lineDiffs.insertions?.toLocaleString()} <Box component='span' sx={{ color: 'success.solidBg' }}>added</Box> and {lineDiffs.deletions?.toLocaleString()} <Box component='span' sx={{ color: 'danger.softColor' }}>removed</Box> lines.</>,
        mtype: 'changes',
      });
    else if (lineDiffs.insertions)
      setStatus({ message: <>File has {lineDiffs.insertions?.toLocaleString()} <Box component='span' sx={{ color: 'success.solidBg' }}>added lines</Box>.</>, mtype: 'changes' });
    else if (lineDiffs.deletions)
      setStatus({ message: <>File has {lineDiffs.deletions?.toLocaleString()} <Box component='span' sx={{ color: 'danger.softColor' }}>removed lines</Box>.</>, mtype: 'changes' });
    else
      setStatus({ message: 'No changes.', mtype: 'info' });
  }, [bufferText, fileContent, isMobile]);

  // [effect] On error, replace the status message with the error message
  React.useEffect(() => {
    if (fileErrorText)
      setStatus({ message: fileErrorText, mtype: 'error' });
  }, [fileErrorText]);


  // callbacks

  const handleStopLiveFile = React.useCallback(async () => {
    await liveFileContentClose();
    setDiffSummary(null);
    setStatus(null);
  }, [liveFileContentClose]);

  const _handleReloadFileContent = React.useCallback(async (liveFileId?: LiveFileId) => {
    if (isLoadingFile)
      setStatus({ message: 'Already Loading file...', mtype: 'info' });
    if (!fileHasContent)
      setStatus({ message: 'Reading file...', mtype: 'info' });
    await liveFileContentReloadFromDisk(liveFileId);
    // content and errors will be reactive here (see effects)
  }, [fileHasContent, isLoadingFile, liveFileContentReloadFromDisk]);

  const handlePairNewFSFHandle = React.useCallback(async (fsfHandle: FileSystemFileHandle) => {
    // Pair the file: create a LiveFile, replace it in the Fragment, and load the preview
    try {
      const liveFileId = await liveFileCreateOrThrow(fsfHandle);
      if (!workspaceId)
        console.warn('[DEV] No workspaceId to pair the file with.');
      else
        workspaceActions().liveFileAssign(workspaceId, liveFileId);
      onReplaceLiveFileId?.(liveFileId);
      // Immediately load the preview on this ID
      await _handleReloadFileContent(liveFileId);
    } catch (error: any) {
      setStatus({ message: `Error pairing the file: ${error?.message || typeof error === 'string' ? error : 'Unknown error'}`, mtype: 'error' });
    }
  }, [_handleReloadFileContent, onReplaceLiveFileId, workspaceId]);

  const handlePairNewFileWithPicker = React.useCallback(async () => {
    // pick a file
    const fileWithHandle = await fileOpen({ description: 'Select a File to pair to this document' }).catch(() => null /* The User closed the files picker */);
    if (!fileWithHandle)
      return;
    if (fileWithHandle.handle)
      await handlePairNewFSFHandle(fileWithHandle.handle);
    else
      setStatus({ message: `Browser does not support LiveFile operations. ${isLiveFileSupported() ? 'No filesystem handles.' : ''}`, mtype: 'error' });
  }, [handlePairNewFSFHandle]);


  // Save and Load from Disk

  const handleLoadFromDisk = React.useCallback(() => {
    if (fileContent === undefined)
      setStatus({ message: 'No file content loaded. Please preview changes first.', mtype: 'info' });
    else
      onSetBufferText?.(fileContent);
  }, [fileContent, onSetBufferText]);

  const handleSaveToDisk = React.useCallback(async (event: React.MouseEvent) => {
    if (!isPairingValid) {
      setStatus({ message: 'No file paired. Please choose a file first.', mtype: 'info' });
      return;
    }

    // ask the user for confirmation before saving to file
    if (!event.shiftKey && !await showPromisedOverlay('livefile-overwrite', { rejectWithValue: false }, ({ onResolve, onUserReject }) =>
      <ConfirmationModal
        open onClose={onUserReject} onPositive={() => onResolve(true)}
        title='Overwrite File'
        positiveActionText='Overwrite'
        confirmationText='Are you sure you want to overwrite the file with the current contents?'
      />,
    )) return;

    setStatus({ message: 'Saving to file...', mtype: 'info' });
    const saved = await liveFileContentWriteAndReload(bufferText);
    if (!saved) {
      // if not saved, the error will be shown in the effect
    } else
      setStatus({ message: 'Content saved to file.', mtype: 'success' });
  }, [bufferText, isPairingValid, liveFileContentWriteAndReload, showPromisedOverlay]);


  // Memoed components code

  const liveFileControlButton = React.useMemo(() => (!isLiveFileSupported() || !onReplaceLiveFileId) ? null : (
    <LiveFileControlButton
      disabled={isSavingFile}
      hasContent={fileHasContent}
      hideWhenHasContent
      isPaired={isPairingValid}
      onPairWithFSFHandle={handlePairNewFSFHandle}
      onPairWithPicker={handlePairNewFileWithPicker}
      onUpdateFileContent={_handleReloadFileContent}
    />
  ), [_handleReloadFileContent, fileHasContent, handlePairNewFSFHandle, handlePairNewFileWithPicker, isPairingValid, isSavingFile, onReplaceLiveFileId]);

  const liveFileActions = React.useMemo(() => {
    if (!isLiveFileSupported() || (!status && !fileHasContent))
      return null;

    const isError = status?.mtype === 'error';

    const statusColor: ColorPaletteProp =
      isError ? 'warning'
        : status?.mtype === 'success' ? 'success'
          : status?.mtype === 'changes' ? 'neutral'
            : 'neutral';

    return (
      <Sheet color={statusColor} sx={liveFileSheetSx}>

        <Box sx={{ display: 'flex', alignItems: 'center' }}>

          {/* Refresh Content Button */}
          {isPairingValid && (
            <TooltipOutlined title='Reload and compare File' placement='top-start' color='success'>
              <IconButton size='sm' variant='outlined' onClick={() => _handleReloadFileContent()} sx={{ mr: 1 }}>
                <LiveFileIcon color='success' />
              </IconButton>
            </TooltipOutlined>
          )}

          {/* Alert Decorator (startDecorator will have it messy) */}
          {status?.mtype === 'error' && <WarningRoundedIcon sx={{ mr: 1 }} />}

          {' '}<span>{status?.message}</span>

        </Box>


        <Box sx={{ ml: 'auto', display: 'flex', gap: 1 }}>
          {/* Load from file */}
          {fileIsDifferent && !isError && !!onSetBufferText && (
            <Button
              variant='outlined'
              color='neutral'
              size='sm'
              // disabled={isLoadingFile /* commented to not make this flash */}
              onClick={handleLoadFromDisk}
              startDecorator={<LiveFileReloadIcon />}
              aria-label='Load content from disk'
            >
              {isMobile ? 'Update' : 'Replace with file'}
            </Button>
          )}

          {/* Save to File */}
          {fileIsDifferent && !isError && (
            <Button
              variant='outlined'
              color='danger'
              size='sm'
              disabled={isSavingFile}
              onClick={handleSaveToDisk}
              startDecorator={<LiveFileSaveIcon />}
              aria-label='Save content to disk'
            >
              {isMobile ? 'Save' : 'Save to file'}
            </Button>
          )}

          {/* More Controls */}
          <Dropdown>

            <MenuButton
              aria-label='LiveFile Controls'
              slots={{ root: IconButton }}
              slotProps={{ root: { size: 'sm' } }}
            >
              <MoreVertIcon />
            </MenuButton>

            <Menu size='md' sx={{ minWidth: 220 }}>

              {/* Reassign File button */}
              {!!onReplaceLiveFileId && (
                <MenuItem onClick={handlePairNewFileWithPicker}>
                  <ListItemDecorator>
                    <LiveFileChooseIcon />
                  </ListItemDecorator>
                  Pair a different file
                </MenuItem>
              )}

              <ListDivider />

              {/* Close button */}
              <MenuItem onClick={handleStopLiveFile}>
                <ListItemDecorator>
                  <LiveFileCloseIcon />
                </ListItemDecorator>
                Stop sync
              </MenuItem>

            </Menu>
          </Dropdown>

        </Box>
      </Sheet>
    );
  }, [_handleReloadFileContent, fileHasContent, fileIsDifferent, handleLoadFromDisk, handlePairNewFileWithPicker, handleSaveToDisk, handleStopLiveFile, isMobile, isPairingValid, isSavingFile, onReplaceLiveFileId, onSetBufferText, status]);


  // Auto-click on 'refresh' on window focus

  React.useEffect(() => {
    return WindowFocusObserver.getInstance().subscribe(async (focused) => {
      if (focused && shallUpdateOnRefocus)
        await _handleReloadFileContent();
    });
  }, [_handleReloadFileContent, shallUpdateOnRefocus]);


  return {
    liveFileActions,
    liveFileControlButton,
  };
}



================================================
FILE: src/apps/chat/components/message/fragments-attachment-image/ImageAttachmentFragments.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { RenderImageRefDBlob } from '~/modules/blocks/image/RenderImageRefDBlob';

import type { DMessageRole } from '~/common/stores/chat/chat.message';
import { ContentScaling, themeScalingMap } from '~/common/app.theme';
import { DMessageAttachmentFragment, DMessageFragmentId, DMessageImageRefPart, isImageRefPart } from '~/common/stores/chat/chat.fragments';

import { ViewImageRefPartModal } from '../fragments-content/ViewImageRefPartModal';


// configuration
const CARD_MIN_SQR = 84;
const CARD_MAX_WIDTH = CARD_MIN_SQR * 3;      // 3:1      max wide ratio (252px)
const CARD_MAX_HEIGHT = CARD_MIN_SQR * 2.25;  // 1:2.25   max tall ratio (189px)


const layoutSx: SxProps = {
  // style
  my: 'auto',
  flex: 0,

  // layout
  display: 'flex',
  flexWrap: 'wrap',
  // alignItems: 'center',        // commented to keep them to the top
  // justifyContent: 'flex-end',  // commented as we do it dynamically
  gap: { xs: 0.5, md: 1 },
};

const imageSheetPatchSx: SxProps = {
  // undo the RenderImageURL default style
  m: 0,
  minWidth: CARD_MIN_SQR,
  minHeight: CARD_MIN_SQR,
  boxShadow: 'xs',
  // border: 'none',

  // style
  // backgroundColor: 'background.popup',
  borderRadius: 'sm',
  overflow: 'hidden',

  // style the <img> tag
  '& picture > img': {
    // override the style in RenderImageURL
    maxWidth: CARD_MAX_WIDTH, // very important to keep the aspect ratio
    maxHeight: CARD_MAX_HEIGHT, // very important to keep the aspect ratio
    // width: '100%',
    // height: '100%',
    // objectFit: 'cover',
  },
};


/**
 * Shows image attachments in a flexbox that wraps the images (overflowing by rows)
 * Also see `TextAttachmentFragments` for the text version, and 'ContentFragments'.
 */
export function ImageAttachmentFragments(props: {
  imageAttachments: DMessageAttachmentFragment[],
  contentScaling: ContentScaling,
  messageRole: DMessageRole,
  disabled?: boolean,
  onFragmentDelete?: (fragmentId: DMessageFragmentId) => void,
}) {

  // state
  const [viewingImageRefPart, setViewingImageRefPart] = React.useState<DMessageImageRefPart | null>(null);


  const layoutSxMemo = React.useMemo((): SxProps => ({
    ...layoutSx,
    justifyContent: props.messageRole === 'assistant' ? 'flex-start' : 'flex-end',
  }), [props.messageRole]);

  const cardStyleSxMemo = React.useMemo((): SxProps => ({
    fontSize: themeScalingMap[props.contentScaling]?.blockFontSize ?? undefined,
    lineHeight: themeScalingMap[props.contentScaling]?.blockLineHeight ?? 1.75,
    ...imageSheetPatchSx,
  }), [props.contentScaling]);


  return (
    <Box aria-label={`${props.imageAttachments.length} images`} sx={layoutSxMemo}>

      {/* render each image attachment */}
      {props.imageAttachments.map(attachmentFragment => {
        // only operate on image_ref
        if (!isImageRefPart(attachmentFragment.part))
          throw new Error('Unexpected part type: ' + attachmentFragment.part.pt);

        const { title, part: imageRefPart } = attachmentFragment;
        const { dataRef /*, altText */ } = imageRefPart;

        // only support rendering DBLob images as cards for now
        if (dataRef.reftype === 'dblob') {
          return (
            <RenderImageRefDBlob
              key={'att-img-' + attachmentFragment.fId}
              dataRefDBlobAssetId={dataRef.dblobAssetId}
              dataRefMimeType={dataRef.mimeType}
              dataRefBytesSize={dataRef.bytesSize}
              imageAltText={imageRefPart.altText || title}
              imageWidth={imageRefPart.width}
              imageHeight={imageRefPart.height}
              disabled={props.disabled}
              onDeleteFragment={!props.onFragmentDelete ? undefined : () => props.onFragmentDelete?.(attachmentFragment.fId)}
              onViewImage={() => setViewingImageRefPart(imageRefPart)}
              scaledImageSx={cardStyleSxMemo}
              variant='attachment-card'
            />
          );
        }

        throw new Error('Unexpected dataRef type: ' + dataRef.reftype);
      })}

      {/* Image viewer modal */}
      {viewingImageRefPart && (
        <ViewImageRefPartModal
          imageRefPart={viewingImageRefPart}
          onClose={() => setViewingImageRefPart(null)}
        />
      )}

    </Box>
  );
}


================================================
FILE: src/apps/chat/components/message/fragments-content/BlockEdit_TextFragment.tsx
================================================
import * as React from 'react';

import { BlocksTextarea } from '~/modules/blocks/BlocksContainers';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import { Is } from '~/common/util/pwaUtils';
import { ShortcutKey, useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { useUIPreferencesStore } from '~/common/stores/store-ui';


// configuration

/**
 * Note: this will disable the global 'shift+enter' shortcut (and the status message) for this component as well.
 * - #760. Edit Mode not respecting Enter to Send
 * - #770. inconsistent return / shift + return
 * - #771. PR which was not merged (overly complex regex)
 * set to 'undefined' to follow the user preference
 * set to 'true' to force 'enter' to be a newline, which is best for mobile devices where 'shift+enter' is not possible
 */
const FORCE_ENTER_IS_NEWLINE = !Is.Desktop ? true : undefined;


const _textAreaSlotPropsEnter = {
  textarea: {
    enterKeyHint: 'enter' as const,
  },
  endDecorator: {
    sx: {
      fontSize: 'xs',
      pl: 0.5,
      mt: 1.5,
    },
  },
};

const _textAreaSlotPropsDone = {
  ..._textAreaSlotPropsEnter,
  textarea: {
    enterKeyHint: 'done' as const,
  },
};

const _styles = {
  squareTop: {
    borderTopLeftRadius: 0,
    borderTopRightRadius: 0,
  } as const,
} as const;


/**
 * Very similar to <InlineTextArea /> but with externally controlled state rather than internal.
 * Made it for as the editing alternative for <ContentPartText />.
 */
export function BlockEdit_TextFragment(props: {
  // current value
  initialText: string,
  inputLabel?: string,
  fragmentId: DMessageFragmentId,
  enableRestart?: boolean,

  // visual
  contentScaling: ContentScaling,
  // endDecorator?: React.ReactNode
  squareTopBorder?: boolean,

  // edited value
  controlled?: boolean, // if true, the editor will assume enter is new line, and not emit onSubmit
  editedText?: string,
  setEditedText: (fragmentId: DMessageFragmentId, value: string, applyNow: boolean) => void,
  onSubmit: (withControl: boolean) => void,
  onEscapePressed: () => void,
}) {

  // state
  const [isFocused, setIsFocused] = React.useState(false);

  // external
  // NOTE: we disabled `useUIPreferencesStore(state => state.enterIsNewline)` on 2024-06-19, as it's
  //       not a good pattern for this kind of editing and we have buttons to take care of Save/Cancel
  //
  // NOTE2: as per #https://github.com/enricoros/big-AGI/issues/760, this is a UX break of behavior.
  //        adding a configuration option to quickly
  const isControlled = !!props.controlled;
  const enterIsNewline = useUIPreferencesStore(state => isControlled ? true : FORCE_ENTER_IS_NEWLINE !== undefined ? FORCE_ENTER_IS_NEWLINE : state.enterIsNewline);

  // derived state
  const { fragmentId, setEditedText, onSubmit, onEscapePressed } = props;

  // handlers
  const handleEditTextChanged = React.useCallback((e: React.ChangeEvent<HTMLTextAreaElement>) => {
    (e.target.value !== undefined) && setEditedText(fragmentId, e.target.value, false);
  }, [fragmentId, setEditedText]);

  const handleEditKeyDown = React.useCallback((e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter') {
      const withControl = e.ctrlKey;
      if (enterIsNewline ? e.shiftKey : !e.shiftKey) {
        e.preventDefault();
        if (!isControlled && (!withControl || props.enableRestart))
          onSubmit(withControl);
      } // [Beam] eat up pure Ctrl+Enter, to not restart beams
      else if (e.ctrlKey) {
        e.stopPropagation(); // prevents the global shortcut
      }
    } else if (e.key === 'Escape') {
      e.preventDefault();
      onEscapePressed();
    }
  }, [enterIsNewline, isControlled, onEscapePressed, onSubmit, props.enableRestart]);

  // shortcuts
  const isEdited = props.editedText !== undefined;
  useGlobalShortcuts('TextFragmentEditor', React.useMemo(() => (isControlled || !isFocused) ? [] : [
    ...(!FORCE_ENTER_IS_NEWLINE ? [] : [{ key: ShortcutKey.Enter, shift: true, description: 'Save', disabled: !isEdited && props.enableRestart !== true, level: 3, action: () => null }]),
    ...props.enableRestart ? [{ key: ShortcutKey.Enter, ctrl: true, shift: true, description: 'Save & Retry', disabled: !isEdited, level: 3, action: () => onSubmit(true) }] : [],
    { key: ShortcutKey.Esc, description: 'Cancel', level: 3, action: onEscapePressed },
  ], [isControlled, isEdited, isFocused, onEscapePressed, onSubmit, props.enableRestart]));

  return (
    <BlocksTextarea
      variant={/*props.invertedColors ? 'plain' :*/ 'soft'}
      color={/*props.uncolor ? undefined : props.invertedColors ? 'primary' :*/ 'warning'}
      autoFocus
      size={props.contentScaling !== 'md' ? 'sm' : undefined}
      value={(!isControlled && props.editedText !== undefined) /* if Controlled, ignore any edited text overlay */
        ? props.editedText /* self-text */
        : props.initialText /* DMessageTextPart text */
      }
      startDecorator={props.inputLabel ? <small>{props.inputLabel}</small> : undefined}
      placeholder={'Edit the message...'}
      minRows={1.5} // unintuitive
      onFocus={isControlled ? undefined : () => setIsFocused(true)}
      onBlur={isControlled ? undefined : () => setIsFocused(false)}
      // onBlur={props.disableAutoSaveOnBlur ? undefined : handleEditBlur}
      onChange={handleEditTextChanged}
      onKeyDown={handleEditKeyDown}
      slotProps={enterIsNewline ? _textAreaSlotPropsEnter : _textAreaSlotPropsDone}
      // endDecorator={props.endDecorator}
      sx={!props.squareTopBorder ? undefined : _styles.squareTop}
    />
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-content/BlockOpEmpty.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Chip } from '@mui/joy';
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { ContentScaling } from '~/common/app.theme';


const containerSx: SxProps = {
  marginInlineStart: 1.5,
  backgroundColor: 'neutral.softBg',
  borderRadius: 'lg',

  // layout
  display: 'flex',
  alignItems: 'center',
  gap: 1,
};

const chipSx: SxProps = {
  px: 2,
};


export function BlockOpEmpty(props: {
  text: string,
  contentScaling: ContentScaling,
  onDelete?: () => void,
}) {

  // state
  // const { showPromisedOverlay } = useOverlayComponents();

  // derived state
  // const { onDelete } = props;

  // const handleConfirmDelete = React.useCallback(async () => {
  //   if (onDelete && await showPromisedOverlay('chat-message-delete-confirmation', { rejectWithValue: false }, ({ onResolve, onUserReject }) =>
  //     <ConfirmationModal
  //       open onClose={onUserReject} onPositive={() => onResolve(true)}
  //       confirmationText='Are you sure you want to delete this message?'
  //       positiveActionText='Delete'
  //       title='Delete Message'
  //     />,
  //   )) onDelete();
  // }, [onDelete, showPromisedOverlay]);

  return (
    <Box sx={containerSx}>

      <ScaledTextBlockRenderer
        text={props.text}
        contentScaling={props.contentScaling}
        textRenderVariant='text'
        showAsItalic
      />

      {!!props.onDelete && (
        <Chip
          color='neutral'
          variant='outlined'
          size={props.contentScaling === 'md' ? 'lg' : 'md'}
          onClick={props.onDelete}
          sx={chipSx}
          startDecorator={<DeleteForeverIcon />}
        >
          Delete
        </Chip>
      )}

    </Box>
  );
}


================================================
FILE: src/apps/chat/components/message/fragments-content/BlockPartError.tsx
================================================
import * as React from 'react';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';


export function BlockPartError(props: {
  errorText: string,
  messageRole: DMessageRole,
  contentScaling: ContentScaling,
}) {

  // Check if the errorText starts with '**' and has a closing '**' following Markdown rules
  let textToRender = props.errorText;
  let renderAsMarkdown = false;

  // render as markdown (better looking) if there is no 'structure' that requres plaintext ("{" basically)
  const containsBold = textToRender.indexOf('**') !== -1;
  const containsStructure = textToRender.indexOf('{') !== -1 && props.errorText.indexOf('}') !== -1;
  if (containsBold && !containsStructure)
    renderAsMarkdown = true;

  // if there's structure, still (potentially) remove the starting and ending '**' from the first occurrence
  if (!renderAsMarkdown && containsBold && textToRender.startsWith('**')) {
    const closingBoldIndex = textToRender.indexOf('**', 2);
    if (closingBoldIndex > 2) {
      // Remove the starting and ending '**' from the first occurrence
      textToRender =
        textToRender.substring(2, closingBoldIndex) +
        textToRender.substring(closingBoldIndex + 2);
    }
  }

  return (
    <ScaledTextBlockRenderer
      text={textToRender}
      contentScaling={props.contentScaling}
      textRenderVariant={renderAsMarkdown ? 'markdown' : 'text'}
      showAsDanger
    />
  );
}


================================================
FILE: src/apps/chat/components/message/fragments-content/BlockPartImageRef.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { BlocksContainer } from '~/modules/blocks/BlocksContainers';
import { RenderImageRefDBlob } from '~/modules/blocks/image/RenderImageRefDBlob';
import { RenderImageURL } from '~/modules/blocks/image/RenderImageURL';

import type { DMessageContentFragment, DMessageFragmentId, DMessageImageRefPart } from '~/common/stores/chat/chat.fragments';
import { ContentScaling, themeScalingMap } from '~/common/app.theme';

import { ViewImageRefPartModal } from './ViewImageRefPartModal';


export function BlockPartImageRef(props: {
  imageRefPart: DMessageImageRefPart,
  fragmentId?: DMessageFragmentId,
  disableViewer?: boolean,
  contentScaling: ContentScaling,
  onFragmentDelete?: (fragmentId: DMessageFragmentId) => void,
  onFragmentReplace?: (fragmentId: DMessageFragmentId, newFragment: DMessageContentFragment) => void,
}) {

  // state
  const [viewingImageRefPart, setViewingImageRefPart] = React.useState<DMessageImageRefPart | null>(null);

  // derived state
  const { fragmentId, imageRefPart, onFragmentDelete, onFragmentReplace } = props;
  const { dataRef } = imageRefPart;

  // event handlers
  const handleDeleteFragment = React.useCallback(() => {
    if (fragmentId && onFragmentDelete)
      onFragmentDelete(fragmentId);
  }, [fragmentId, onFragmentDelete]);

  const handleReplaceFragment = React.useCallback((newImageFragment: DMessageContentFragment) => {
    if (fragmentId && onFragmentReplace)
      onFragmentReplace(fragmentId, newImageFragment);
  }, [fragmentId, onFragmentReplace]);

  const handleViewImage = React.useCallback(() => {
    setViewingImageRefPart(imageRefPart);
  }, [imageRefPart]);


  // memo the scaled image style
  const scaledImageSx = React.useMemo((): SxProps => ({
    // overflowX: 'auto', // <- this would make the right side margin scrollable
    fontSize: themeScalingMap[props.contentScaling]?.blockFontSize ?? undefined,
    lineHeight: themeScalingMap[props.contentScaling]?.blockLineHeight ?? 1.75,
    marginBottom: themeScalingMap[props.contentScaling]?.blockImageGap ?? 1.5,
  }), [props.contentScaling]);

  return (
    <BlocksContainer>

      {/* Render DBlob / URL / Error -> downloads -> Calls RenderImageURL */}
      {dataRef.reftype === 'dblob' ? (
        <RenderImageRefDBlob
          dataRefDBlobAssetId={dataRef.dblobAssetId}
          dataRefMimeType={dataRef.mimeType}
          dataRefBytesSize={dataRef.bytesSize}
          imageAltText={imageRefPart.altText}
          imageWidth={imageRefPart.width}
          imageHeight={imageRefPart.height}
          onDeleteFragment={onFragmentDelete ? handleDeleteFragment : undefined}
          onReplaceFragment={onFragmentReplace ? handleReplaceFragment : undefined}
          onViewImage={props.disableViewer ? undefined : handleViewImage}
          scaledImageSx={scaledImageSx}
          variant='content-part'
        />
      ) : dataRef.reftype === 'url' ? (
        <RenderImageURL
          imageURL={dataRef.url}
          expandableText={imageRefPart.altText}
          scaledImageSx={scaledImageSx}
          variant='content-part'
        />
      ) : (
        <Box>
          ContentPartImageRef: unknown reftype
        </Box>
      )}

      {/* Image viewer modal */}
      {!props.disableViewer && viewingImageRefPart && (
        <ViewImageRefPartModal
          imageRefPart={viewingImageRefPart}
          onClose={() => setViewingImageRefPart(null)}
        />
      )}

    </BlocksContainer>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-content/BlockPartText_AutoBlocks.tsx
================================================
import * as React from 'react';

import type { WordsDiff } from '~/modules/blocks/wordsdiff/RenderWordsDiff';
import { AutoBlocksRenderer } from '~/modules/blocks/AutoBlocksRenderer';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import type { DMessageRole } from '~/common/stores/chat/chat.message';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { InlineError } from '~/common/components/InlineError';

import { explainServiceErrors } from '../explainServiceErrors';

/**
 * The OG part, comprised of text, which can be markdown, have code blocks, etc.
 * Uses BlocksRenderer to render the markdown/code/html/text, etc.
 */
export function BlockPartText_AutoBlocks(props: {
  // current value
  textPartText: string,
  setEditedText?: (fragmentId: DMessageFragmentId, value: string, applyNow: boolean) => void,

  fragmentId: DMessageFragmentId,
  messageRole: DMessageRole,

  contentScaling: ContentScaling,
  isMobile: boolean,
  fitScreen: boolean,
  disableMarkdownText: boolean,
  enhanceCodeBlocks: boolean,
  renderAsWordsDiff?: WordsDiff,

  showUnsafeHtmlCode?: boolean,
  optiAllowSubBlocksMemo: boolean,

  onContextMenu?: (event: React.MouseEvent) => void;
  onDoubleClick?: (event: React.MouseEvent) => void;

}) {

  // derived state
  const messageText = props.textPartText;
  const fromAssistant = props.messageRole === 'assistant';


  // handlers

  const { fragmentId, setEditedText } = props;

  const handleSetText = React.useCallback((newText: string) => {
    setEditedText?.(fragmentId, newText, true);
  }, [fragmentId, setEditedText]);


  const errorExplainer = React.useMemo(
    () => !messageText ? null : explainServiceErrors(messageText, fromAssistant),
    [fromAssistant, messageText],
  );

  // if errored, render an Auto-Error message
  if (errorExplainer) {
    return (
      <GoodTooltip placement='top' arrow title={messageText}>
        <div><InlineError error={<>{errorExplainer} Hover this message for more details.</>} /></div>
      </GoodTooltip>
    );
  }

  return (
    <AutoBlocksRenderer
      text={messageText || ''}
      fromRole={props.messageRole}
      contentScaling={props.contentScaling}
      fitScreen={props.fitScreen}
      isMobile={props.isMobile}
      showUnsafeHtmlCode={props.showUnsafeHtmlCode}
      renderAsWordsDiff={props.renderAsWordsDiff}
      codeRenderVariant={props.enhanceCodeBlocks ? 'enhanced' : 'outlined'}
      textRenderVariant={props.disableMarkdownText ? 'text' : 'markdown'}
      optiAllowSubBlocksMemo={props.optiAllowSubBlocksMemo}
      onContextMenu={props.onContextMenu}
      onDoubleClick={props.onDoubleClick}
      setText={!props.setEditedText ? undefined : handleSetText}
    />
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-content/BlockPartToolInvocation.tsx
================================================
import * as React from 'react';

import type { ColorPaletteProp, SxProps, VariantProp } from '@mui/joy/styles/types';
import { Sheet } from '@mui/joy';

import { BlocksContainer } from '~/modules/blocks/BlocksContainers';
import { useScaledTypographySx } from '~/modules/blocks/blocks.styles';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageToolInvocationPart } from '~/common/stores/chat/chat.fragments';


const keyValueGridSx = {
  border: '1px solid',
  borderRadius: 'sm',
  boxShadow: 'inset 2px 0 4px -2px rgba(0, 0, 0, 0.2)',
  p: 1.5,

  // Grid layout with 2 columns
  display: 'grid',
  gridTemplateColumns: 'auto 1fr',
  // alignItems: 'baseline',
  columnGap: 2,
  rowGap: 0.5,

  // fade the text of the first column
  // '& > :nth-of-type(odd)': {
  //   opacity: 0.67,
  //   // fontSize: '90%',
  // },
} as const;


export type KeyValueData = { label: string, value: React.ReactNode, asCode?: boolean }[];

export function KeyValueGrid(props: {
  data: KeyValueData,
  contentScaling: ContentScaling,
  color?: ColorPaletteProp,
  variant?: VariantProp,
  stableSx?: SxProps,
}) {

  const { fontSize, lineHeight } = useScaledTypographySx(props.contentScaling, false, false);

  const gridSx = React.useMemo(() => ({
    ...keyValueGridSx,
    // fontWeight,
    fontSize,
    lineHeight,
    ...props.stableSx,
  }), [fontSize, lineHeight, props.stableSx]);

  return (
    <Sheet color={props.color} variant={props.variant || 'soft'} sx={gridSx}>
      {props.data.map(({ label, value }, index) => (
        <React.Fragment key={index}>
          <div>{label}</div>
          <div>{value}</div>
        </React.Fragment>
      ))}
    </Sheet>
  );
}


export function BlockPartToolInvocation(props: {
  toolInvocationPart: DMessageToolInvocationPart,
  contentScaling: ContentScaling,
  onDoubleClick?: (event: React.MouseEvent) => void;
}) {

  const part = props.toolInvocationPart;

  const kvData: KeyValueData = React.useMemo(() => {
    switch (part.invocation.type) {
      case 'function_call':
        return [
          { label: 'Name', value: <strong>{part.invocation.name}</strong> },
          { label: 'Args', value: part.invocation.args || 'None', asCode: true },
          { label: 'Id', value: part.id },
        ];
      case 'code_execution':
        return [
          { label: 'Language', value: part.invocation.language },
          { label: 'Author', value: part.invocation.author },
          {
            label: 'Code',
            value: <div style={{ whiteSpace: 'pre-wrap' }}>{part.invocation.code.trim()}</div>,
          },
          { label: 'Id', value: part.id },
        ];
    }
  }, [part]);

  return (
    <BlocksContainer onDoubleClick={props.onDoubleClick}>
      <KeyValueGrid
        data={kvData}
        contentScaling={props.contentScaling}
      />
    </BlocksContainer>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-content/BlockPartToolResponse.tsx
================================================
import * as React from 'react';

import { BlocksContainer } from '~/modules/blocks/BlocksContainers';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageToolResponsePart } from '~/common/stores/chat/chat.fragments';

import { KeyValueData, KeyValueGrid } from './BlockPartToolInvocation';


export function BlockPartToolResponse(props: {
  toolResponsePart: DMessageToolResponsePart,
  contentScaling: ContentScaling,
  onDoubleClick?: (event: React.MouseEvent) => void;
}) {

  const part = props.toolResponsePart;

  const kvData: KeyValueData = React.useMemo(() => {
    switch (part.response.type) {
      case 'function_call':
        return [
          { label: 'Id', value: part.id },
          { label: 'Name', value: <strong>{part.response.name}</strong> },
          { label: 'Response', value: part.response.result, asCode: true },
          ...(!part.error ? [] : [{ label: 'Error', value: part.error }]),
          { label: 'Environment', value: part.environment },
        ];
      case 'code_execution':
        return [
          { label: 'Id', value: part.id },
          { label: 'Response', value: part.response.result, asCode: true },
          ...(!part.error ? [] : [{ label: 'Error', value: part.error }]),
          { label: 'Executor', value: part.response.executor },
          { label: 'Environment', value: part.environment },
        ];
    }
  }, [part]);

  return (
    <BlocksContainer onDoubleClick={props.onDoubleClick}>
      <KeyValueGrid
        data={kvData}
        contentScaling={props.contentScaling}
        color={part.error ? 'danger' : 'primary'}
      />
    </BlocksContainer>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-content/ContentFragments.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button } from '@mui/joy';
import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { ContentScaling, UIComplexityMode } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';
import { DMessageContentFragment, DMessageFragmentId, isTextPart } from '~/common/stores/chat/chat.fragments';

import type { ChatMessageTextPartEditState } from '../ChatMessage';
import { BlockEdit_TextFragment } from './BlockEdit_TextFragment';
import { BlockOpEmpty } from './BlockOpEmpty';
import { BlockPartError } from './BlockPartError';
import { BlockPartImageRef } from './BlockPartImageRef';
import { BlockPartText_AutoBlocks } from './BlockPartText_AutoBlocks';
import { BlockPartToolInvocation } from './BlockPartToolInvocation';
import { BlockPartToolResponse } from './BlockPartToolResponse';


const _editLayoutSx: SxProps = {
  display: 'grid',
  gap: 1.5,     // see why we give more space on ChatMessage

  // horizontal separator between messages (second part+ and before)
  // '& > *:not(:first-of-type)': {
  //   borderTop: '1px solid',
  //   borderTopColor: 'background.level3',
  // },
};

const _startLayoutSx: SxProps = {
  ..._editLayoutSx,
  justifyContent: 'flex-start',
} as const;

const _endLayoutSx: SxProps = {
  ..._editLayoutSx,
  justifyContent: 'flex-end',
} as const;


export function ContentFragments(props: {

  contentFragments: DMessageContentFragment[]
  showEmptyNotice: boolean,

  contentScaling: ContentScaling,
  uiComplexityMode: UIComplexityMode,
  fitScreen: boolean,
  isMobile: boolean,
  messageRole: DMessageRole,
  optiAllowSubBlocksMemo?: boolean,
  disableMarkdownText: boolean,
  enhanceCodeBlocks: boolean,
  showUnsafeHtmlCode?: boolean,

  textEditsState: ChatMessageTextPartEditState | null,
  setEditedText?: (fragmentId: DMessageFragmentId, value: string, applyNow: boolean) => void,
  onEditsApply: (withControl: boolean) => void,
  onEditsCancel: () => void,

  onFragmentAddBlank?: () => void,
  onFragmentDelete?: (fragmentId: DMessageFragmentId) => void,
  onFragmentReplace?: (fragmentId: DMessageFragmentId, newFragment: DMessageContentFragment) => void,
  onMessageDelete?: () => void,

  onContextMenu?: (event: React.MouseEvent) => void;
  onDoubleClick?: (event: React.MouseEvent) => void;

}) {

  const isEmpty = !props.contentFragments.length;
  const fromAssistant = props.messageRole === 'assistant';
  const fromUser = props.messageRole === 'user';
  const isEditingText = !!props.textEditsState;
  const enableRestartFromEdit = !fromAssistant && props.messageRole !== 'system';

  // Content Fragments Edit Zero-State: button to create a new TextContentFragment
  if (isEditingText && isEmpty)
    return !props.onFragmentAddBlank ? null : (
      <Button aria-label='message body empty' variant='plain' color='neutral' onClick={props.onFragmentAddBlank} sx={{ justifyContent: 'flex-start' }}>
        add text ...
      </Button>
    );

  // when editing text, don't show the empty notice
  if (props.showEmptyNotice && isEditingText)
    return null;

  // if no fragments, don't box them
  if (!props.showEmptyNotice && isEmpty)
    return null;

  return <Box aria-label='message body' sx={isEditingText ? _editLayoutSx : fromAssistant ? _startLayoutSx : _endLayoutSx}>

    {/* Empty Message Block - if empty */}
    {props.showEmptyNotice && (
      <BlockOpEmpty
        text={`empty ${fromAssistant ? 'model ' : fromUser ? 'user ' : ''}message`}
        contentScaling={props.contentScaling}
        onDelete={props.onMessageDelete}
      />
    )}

    {props.contentFragments.map((fragment) => {

      // simplify
      const { fId, part } = fragment;

      // Determine the text to edit based on the part type
      let editText = '';
      let editLabel;
      if (isTextPart(part))
        editText = part.text;
      else if (part.pt === 'error')
        editText = part.error;
      else if (part.pt === 'tool_invocation') {
        if (part.invocation.type === 'function_call') {
          editText = part.invocation.args /* string | null */ || '';
          editLabel = `[Invocation] Function Call: \`${part.invocation.name}\``;
        } else {
          editText = part.invocation.code;
          editLabel = `[Invocation] Code Execution: \`${part.invocation.language}\``;
        }
      } else if (part.pt === 'tool_response') {
        if (!part.error) {
          editText = part.response.result;
          editLabel = `[Response]: ${part.response.type === 'function_call' ? 'Function Call' : 'Code Execution'}: \`${part.id}\``;
        }
      }

      // editing for text parts, tool invocations, or tool responses
      if (props.textEditsState && !!props.setEditedText && (isTextPart(part) || part.pt === 'error' || part.pt === 'tool_invocation' || part.pt === 'tool_response')) {
        return (
          <BlockEdit_TextFragment
            key={'edit-' + fId}
            initialText={editText}
            inputLabel={editLabel}
            fragmentId={fId}
            contentScaling={props.contentScaling}
            enableRestart={enableRestartFromEdit}
            editedText={props.textEditsState[fId]}
            setEditedText={props.setEditedText}
            onSubmit={props.onEditsApply}
            onEscapePressed={props.onEditsCancel}
            // endDecorator='Shift+Enter to save · Ctrl+Shift+Enter to restart · Escape to cancel'
          />
        );
      }

      switch (part.pt) {
        case 'error':
          return (
            <BlockPartError
              key={fId}
              errorText={part.error}
              messageRole={props.messageRole}
              contentScaling={props.contentScaling}
            />
          );


        case 'image_ref':
          return (
            <BlockPartImageRef
              key={fId}
              imageRefPart={part}
              fragmentId={fId}
              contentScaling={props.contentScaling}
              onFragmentDelete={props.onFragmentDelete}
              onFragmentReplace={props.onFragmentReplace}
            />
          );

        // This is the most frequent part by far, and can be broken down into sub-blocks
        case 'text':
          return (
            <BlockPartText_AutoBlocks
              key={fId}
              // ref={blocksRendererRef}
              textPartText={part.text}
              setEditedText={props.setEditedText}
              fragmentId={fId}
              messageRole={props.messageRole}
              contentScaling={props.contentScaling}
              fitScreen={props.fitScreen}
              isMobile={props.isMobile}
              disableMarkdownText={props.disableMarkdownText}
              enhanceCodeBlocks={props.enhanceCodeBlocks}
              // renderWordsDiff={wordsDiff || undefined}
              showUnsafeHtmlCode={props.showUnsafeHtmlCode}
              optiAllowSubBlocksMemo={!!props.optiAllowSubBlocksMemo}
              onContextMenu={props.onContextMenu}
              onDoubleClick={props.onDoubleClick}
            />
          );

        case 'tool_invocation':
          return (
            <BlockPartToolInvocation
              key={fId}
              toolInvocationPart={part}
              contentScaling={props.contentScaling}
              onDoubleClick={props.onDoubleClick}
            />
          );

        case 'tool_response':
          return (
            <BlockPartToolResponse
              key={fId}
              toolResponsePart={part}
              contentScaling={props.contentScaling}
              onDoubleClick={props.onDoubleClick}
            />
          );

        case '_pt_sentinel':
          return null;

        default:
          // noinspection JSUnusedLocalSymbols
          const _exhaustiveContentFragmentCheck: never = part;
          return (
            <ScaledTextBlockRenderer
              key={fId}
              text={`Unknown Content Fragment: ${(part as any)?.pt}`}
              contentScaling={props.contentScaling}
              textRenderVariant='text'
              showAsDanger
            />
          );
      }
    }).filter(Boolean)}
  </Box>;
}



================================================
FILE: src/apps/chat/components/message/fragments-content/ViewDocPartModal.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { DMessageDocPart } from '~/common/stores/chat/chat.fragments';
import { GoodModal } from '~/common/components/modals/GoodModal';


const containerSx: SxProps = {
  maxHeight: '80vh',
  overflow: 'auto',
  display: 'grid',
  gap: 2,
};

const propGridSx: SxProps = {
  display: 'grid',
  gridTemplateColumns: 'auto 1fr auto 1fr',
  alignItems: 'center',
  columnGap: 2,
  rowGap: 1,
  '& > :nth-of-type(odd)': {
    color: 'text.secondary',
    fontSize: 'xs',
  },
};

const textPageSx: SxProps = {
  // style it up, as there's nothing
  backgroundColor: 'background.surface',
  boxShadow: 'xs',
  borderRadius: 'sm',

  // pad better the ScaledTextBlockRenderer (add 1.5 vertical as 1.5 hor is built in)
  '& > div': {
    py: 1.5,
  },
};


export function ViewDocPartModal(props: {
  docPart: DMessageDocPart,
  onClose: () => void,
}) {

  // state
  // const [forceCodeRender, setForceCodeRender] = React.useState(false);

  const { docPart } = props;

  const mimeType = docPart.data?.mimeType || '(unknown)';

  const renderAsMarkdown = mimeType === 'text/markdown';
  // const renderAsCode = docPart.vdt === 'application/vnd.agi.code';

  return (
    <GoodModal
      open={true}
      onClose={props.onClose}
      title='Text Attachment'
      noTitleBar={false}
      sx={{ maxWidth: '90vw', backgroundColor: 'background.level2' }}
    >

      <Box sx={containerSx}>

        <Box color='primary' sx={{ px: 1.5, fontSize: 'sm' }}>
          <Box sx={propGridSx}>
            <div>Doc Title</div>
            <div>{docPart.l1Title}</div>
            <div>Identifier</div>
            <div>{docPart.ref}</div>
            <div>Mime Type</div>
            <div>{docPart.data?.mimeType || '(unknown)'}</div>
            <div>Render Type</div>
            <div>{docPart.vdt}</div>
            <div>Rendering As</div>
            <div>{renderAsMarkdown ? 'Markdown' : /*renderAsCode ? 'Code' :*/ 'Text'} (auto)</div>
            <div>Doc Version</div>
            <div>{docPart.version || '(none)'}</div>
          </Box>
        </Box>

        <Box sx={textPageSx}>
          <ScaledTextBlockRenderer
            text={docPart.data.text}
            contentScaling='sm'
            textRenderVariant={renderAsMarkdown ? 'markdown' : 'text'}
          />
        </Box>

      </Box>
    </GoodModal>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-content/ViewImageRefPartModal.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button } from '@mui/joy';
import FileDownloadOutlinedIcon from '@mui/icons-material/FileDownloadOutlined';

import { getImageAsset } from '~/common/stores/blob/dblobs-portability';

import type { DMessageImageRefPart } from '~/common/stores/chat/chat.fragments';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { convert_Base64WithMimeType_To_Blob } from '~/common/util/blobUtils';
import { downloadBlob } from '~/common/util/downloadUtils';

import { BlockPartImageRef } from './BlockPartImageRef';
import { AppBreadcrumbs } from '~/common/components/AppBreadcrumbs';


const imageViewerModalSx: SxProps = {
  maxWidth: '90vw',
  backgroundColor: 'background.level2',
};

const imageViewerContainerSx: SxProps = {
  // display: 'flex',
  // alignItems: 'center',
  // justifyContent: 'center',
  maxHeight: '80vh',
  overflow: 'auto',

  // pre-compensate the Block > Render Items 1.5 margin
  m: -1.5,
  '& > div': {
    pt: 1.5,
  },
};


export function ViewImageRefPartModal(props: {
  imageRefPart: DMessageImageRefPart,
  onClose: () => void,
}) {

  // state
  const [downloading, setDownloading] = React.useState(false);
  // const [copying, setCopying] = React.useState(false);

  // derived state
  const { dataRef, altText } = props.imageRefPart;
  const isDBlob = dataRef.reftype === 'dblob';

  // handlers

  // const handleCopy = React.useCallback(async () => {
  //   if (dataRef.reftype !== 'dblob') return;
  //
  //   setCopying(true);
  //   try {
  //     const imageAsset = await getImageAsset(dataRef.dblobAssetId);
  //     if (!imageAsset) return;
  //
  //     const blob = convert_Base64WithMimeType_To_Blob(imageAsset.data.base64, imageAsset.data.mimeType, 'ViewImageRefPartModal');
  //
  //     copyBlobPromiseToClipboard(imageAsset.data.mimeType, blob, 'Image');
  //   } catch (error) {
  //     console.error('Failed to copy image:', error);
  //   } finally {
  //     setCopying(false);
  //   }
  // }, [dataRef]);

  const handleDownload = React.useCallback(async () => {
    if (dataRef.reftype !== 'dblob') return;

    setDownloading(true);
    try {
      const imageAsset = await getImageAsset(dataRef.dblobAssetId);
      if (!imageAsset) return;

      const blob = await convert_Base64WithMimeType_To_Blob(imageAsset.data.base64, imageAsset.data.mimeType, 'ViewImageRefPartModal');

      const extension = imageAsset.data.mimeType.split('/')[1] || 'png';
      const filename = `${altText || 'image'}.${extension}`.replace(/[^a-z0-9.\-_]/gi, '_');

      downloadBlob(blob, filename);
    } catch (error) {
      console.error('Failed to download image:', error);
    } finally {
      setDownloading(false);
    }
  }, [dataRef, altText]);

  const title = props.imageRefPart.altText || 'Attachment Image';
  return (
    <GoodModal
      open={true}
      onClose={props.onClose}
      title={
        <AppBreadcrumbs size='md' rootTitle='View'>
          <AppBreadcrumbs.Leaf><b>{title}</b></AppBreadcrumbs.Leaf>
        </AppBreadcrumbs>
      }
      // themedColor='neutral'
      unfilterBackdrop
      startButton={isDBlob ? (
        <Box sx={{ display: 'flex', gap: 1 }}>
          {/*<Button*/}
          {/*  variant='soft'*/}
          {/*  color='neutral'*/}
          {/*  loading={copying}*/}
          {/*  loadingPosition='start'*/}
          {/*  startDecorator={<ContentCopyIcon sx={{ fontSize: 'lg' }} />}*/}
          {/*  onClick={handleCopy}*/}
          {/*>*/}
          {/*  Copy*/}
          {/*</Button>*/}
          <Button
            variant='soft'
            color='neutral'
            loading={downloading}
            loadingPosition='start'
            startDecorator={<FileDownloadOutlinedIcon />}
            onClick={handleDownload}
          >
            Download
          </Button>
        </Box>
      ) : undefined}
      sx={imageViewerModalSx}
    >
      <Box sx={imageViewerContainerSx}>
        <BlockPartImageRef
          disableViewer={true /* we're in the Modal, we won't pop this up anymore */}
          imageRefPart={props.imageRefPart}
          contentScaling='sm'
        />
      </Box>
    </GoodModal>
  );
}


================================================
FILE: src/apps/chat/components/message/fragments-void/BlockPartModelAnnotations.tsx
================================================
import * as React from 'react';

import { Box, Button, List, ListItem, ListItemButton } from '@mui/joy';
import ExpandMoreIcon from '@mui/icons-material/ExpandMore';

import { useScaledTypographySx } from '~/modules/blocks/blocks.styles';

import type { ContentScaling } from '~/common/app.theme';
import type { DVoidWebCitation } from '~/common/stores/chat/chat.fragments';
import type { Immutable } from '~/common/types/immutable.types';
import { AvatarDomainFavicon } from '~/common/components/AvatarDomainFavicon';
import { ExpanderControlledBox } from '~/common/components/ExpanderControlledBox';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { urlExtractDomain, urlPrettyHref } from '~/common/util/urlUtils';


// configuration
const MAX_ICONS = 6;
const COLOR = 'neutral';


const styles = {

  iconRowButton: {
    minHeight: '2.25rem',
    gap: 0.5,
    px: 1.5,
    border: 'none',
    transition: 'transform 0.14s ease',
    // '&:hover': { transform: 'translateY(-1px)' } as const,
  } as const,

  citationsList: {
    mt: 1,
    p: 0, // remove the list default padding
    boxShadow: `inset 1px 1px 3px -3px var(--joy-palette-${COLOR}-solidBg)`,
    borderRadius: 'sm',
    border: '1px solid',
    borderColor: `${COLOR}.outlinedBorder`,
    backgroundColor: `rgb(var(--joy-palette-${COLOR}-lightChannel) / 10%)`,
  } as const,

  citationItem: {
    // py: 0.75,
    gap: 1.5,
    borderRadius: 0,
    borderBottom: '1px solid',
    borderBottomColor: 'divider',
  } as const,

  citationItemLast: {
    // py: 0.75,
    gap: 1.5,
    border: 'none',
  } as const,

  citationNumber: {
    minWidth: 22,
    textAlign: 'end',
    // color: 'text.tertiary',
    // fontWeight: 'lg',
  } as const,

  line: {
    flex: 1,
    display: 'flex',
    alignItems: 'center',
    gap: 1,
  } as const,

  lineContent: {
    display: 'grid',
    overflow: 'hidden',
  } as const,

  lineLink: {
    fontStyle: 'italic',
    fontSize: 'xs',
    opacity: 0.5,
  } as const,

} as const;


export function BlockPartModelAnnotations(props: {
  itemsName?: string;
  annotations: Immutable<DVoidWebCitation[]>;
  contentScaling: ContentScaling;
}) {

  // state
  const [expanded, setExpanded] = React.useState(false);

  // external state
  const scaledTypographySx = useScaledTypographySx(props.contentScaling, false, false);

  // derived
  const annotationsCount = props.annotations.length;
  const moreIcons = annotationsCount - MAX_ICONS;

  const handleToggleExpanded = React.useCallback(() => setExpanded(on => !on), []);

  if (!annotationsCount)
    return null;

  return (
    <Box>

      {/* Row of favicons */}
      <Button
        size='sm'
        variant={expanded ? 'plain' : 'plain'}
        color={COLOR}
        fullWidth
        aria-expanded={expanded}
        onClick={handleToggleExpanded}
        sx={styles.iconRowButton}
      >
        <span>{annotationsCount} {props.itemsName || 'citation'}{annotationsCount > 1 ? 's' : ''}</span>

        {/* Icons */}
        {!expanded && props.annotations.slice(0, MAX_ICONS).map((citation, index) => (
          <TooltipOutlined key={index} title={citation.title || urlExtractDomain(citation.url)}>
            <div>
              <AvatarDomainFavicon key={index} url={citation.url} size={24} iconRes={48} noHover noShadow />
            </div>
          </TooltipOutlined>
        ))}

        {/* +X symbol */}
        {(moreIcons >= 1 && !expanded) && '+' + moreIcons}

        {/* Expand/Collapse button */}
        <ExpandMoreIcon
          sx={{
            ml: 'auto',
            transition: 'transform 0.14s ease',
            transform: expanded ? 'rotate(180deg)' : 'none',
          }}
        />
      </Button>

      {/* Expanded citations list */}
      <ExpanderControlledBox expanded={expanded}>

        <List sx={{ ...styles.citationsList, ...scaledTypographySx }}>
          {props.annotations.map((citation, index) => {
            const domain = urlExtractDomain(citation.url);

            return (
              <ListItem key={index}>
                <ListItemButton
                  component='a'
                  href={citation.url}
                  target='_blank'
                  rel='noopener noreferrer'
                  sx={index < annotationsCount - 1 ? styles.citationItem : styles.citationItemLast}
                >
                  <Box sx={styles.citationNumber}>
                    {citation.refNumber ? `[${citation.refNumber}]` : index + 1}
                  </Box>

                  <Box sx={styles.line}>
                    <AvatarDomainFavicon url={!expanded ? '' : citation.url} size={32} iconRes={64} />
                    <Box sx={styles.lineContent}>
                      <Box className='agi-ellipsize'>
                        {citation.title || domain}
                      </Box>
                      <Box sx={styles.lineLink} className='agi-ellipsize'>
                        {urlPrettyHref(citation.url, true, true)}
                        {citation.pubTs && (
                          <span style={{ marginLeft: '0.5em' }}>
                            · {new Date(citation.pubTs).toLocaleDateString()}
                          </span>
                        )}
                      </Box>
                    </Box>
                  </Box>

                </ListItemButton>
              </ListItem>

            );
          })}
        </List>
      </ExpanderControlledBox>

    </Box>
  );
}



================================================
FILE: src/apps/chat/components/message/fragments-void/BlockPartModelAux.tsx
================================================
import * as React from 'react';

import type { ColorPaletteProp } from '@mui/joy/styles/types';
import { Box, Chip, Typography } from '@mui/joy';
import AllInclusiveIcon from '@mui/icons-material/AllInclusive';
import TextFieldsIcon from '@mui/icons-material/TextFields';

import { useScaledTypographySx } from '~/modules/blocks/blocks.styles';

import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { ExpanderControlledBox } from '~/common/components/ExpanderControlledBox';
import { adjustContentScaling, ContentScaling } from '~/common/app.theme';
import { createTextContentFragment, DMessageContentFragment, DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';


// configuration
// const REASONING_COLOR = '#ca74b8'; // '#f22a85' (folder-aligned), '#ca74b8' (emoji-aligned)
const REASONING_COLOR: ColorPaletteProp = 'success';
const ANTHROPIC_REDACTED_EXPLAINER = //  https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#example-streaming-with-redacted-thinking
  'Some of Claude\'s internal reasoning has been automatically encrypted for safety reasons. This doesn\'t affect the quality of responses.';


const _styles = {

  block: {
    mx: 1.5,
  } as const,

  chip: {
    px: 1.5,
    py: 0.375,
    my: '1px', // to not crop the outline on mobile
    outline: '1px solid',
    outlineColor: `${REASONING_COLOR}.solidBg`, // .outlinedBorder
    boxShadow: `1px 2px 4px -3px var(--joy-palette-${REASONING_COLOR}-solidBg)`,
  } as const,

  chipIcon: {
    fontSize: '1rem',
    mr: 0.5,
  } as const,

  chipExpanded: {
    mt: '1px', // need to copy the `chip` mt
    px: 1.5,
    py: 0.375,
    // borderRadius: 'sm',
    // transition: 'border-radius 0.2s ease-in-out',
  } as const,

  text: {
    borderRadius: '12px',
    border: '1px solid',
    borderColor: `${REASONING_COLOR}.outlinedColor`,
    backgroundColor: `rgb(var(--joy-palette-${REASONING_COLOR}-lightChannel) / 15%)`, // similar to success.50
    boxShadow: 'inset 1px 1px 3px -3px var(--joy-palette-neutral-solidBg)',
    mt: 1,
    p: 1,

    // plain text style
    overflowWrap: 'anywhere',
    whiteSpace: 'break-spaces',

    // layout
    display: 'flex',
    flexDirection: 'column',
  } as const,

  buttonInline: {
    outline: 'none',
    // borderRadius: 'sm',
    // fontSize: 'xs',
  } as const,

} as const;

export function BlockPartModelAux(props: {
  fragmentId: DMessageFragmentId,
  auxType: 'reasoning' | string,
  auxText: string,
  auxHasSignature: boolean,
  auxRedactedDataCount: number,
  zenMode: boolean,
  contentScaling: ContentScaling,
  onFragmentReplace?: (fragmentId: DMessageFragmentId, newFragment: DMessageContentFragment) => void,
}) {

  // state
  const [neverExpanded, setNeverExpanded] = React.useState(true);
  const [expanded, setExpanded] = React.useState(false);

  // external state
  const { showPromisedOverlay } = useOverlayComponents();

  // memo
  const scaledTypographySx = useScaledTypographySx(adjustContentScaling(props.contentScaling, -1), false, false);
  const textSx = React.useMemo(() => ({ ..._styles.text, ...scaledTypographySx }), [scaledTypographySx]);

  let typeText = props.auxType === 'reasoning' ? 'Reasoning' : 'Auxiliary';


  // handlers

  const { onFragmentReplace } = props;
  const showInline = !!onFragmentReplace;

  const handleToggleExpanded = React.useCallback(() => {
    setNeverExpanded(false);
    setExpanded(on => !on);
  }, []);

  const handleInline = React.useCallback(() => {
    if (!onFragmentReplace) return;
    showPromisedOverlay('chat-message-inline-aux', {}, ({ onResolve, onUserReject }) =>
      <ConfirmationModal
        open onClose={onUserReject} onPositive={() => onResolve(true)}
        confirmationText={<>
          Convert this {typeText.toLowerCase()} into regular message text?
          <br />
          It will become part of the message and can&apos;t be collapsed again.
        </>}
        positiveActionText='Convert'
      />,
    ).then(() => {
      onFragmentReplace(props.fragmentId, createTextContentFragment(props.auxText));
    }).catch(() => null /* ignore closure */);
  }, [onFragmentReplace, props.auxText, props.fragmentId, showPromisedOverlay, typeText]);


  // create up to 3 dots '.' based on the length of the auxText (1 dot per 100 characters)
  // const dots = '.'.repeat(Math.floor(props.auxText.length / 100) % 5);

  return <Box sx={_styles.block}>

    {/* Chip to expand/collapse */}
    <Box sx={{ display: 'flex', flexWrap: 'wrap', gap: 1, alignItems: 'center', justifyContent: 'space-between' }}>
      <Chip
        color={REASONING_COLOR}
        variant={expanded ? 'solid' : 'soft'}
        size='sm'
        onClick={handleToggleExpanded}
        sx={expanded ? _styles.chipExpanded : _styles.chip}
        startDecorator={<AllInclusiveIcon sx={_styles.chipIcon}  /* sx={{ color: expanded ? undefined : REASONING_COLOR }} */ />}
        // startDecorator='🧠'
      >
        Show {typeText}
      </Chip>

      {expanded && showInline && !!props.auxText && (
        <Chip
          color={REASONING_COLOR}
          variant='soft'
          size='sm'
          disabled={!onFragmentReplace}
          onClick={!onFragmentReplace ? undefined : handleInline}
          endDecorator={<TextFieldsIcon />}
          sx={_styles.chip}
        >
          Make Regular Text
        </Chip>
      )}
    </Box>

    {/* Controlled Box */}
    <ExpanderControlledBox expanded={expanded}>

      {!neverExpanded && (
        <Typography sx={textSx}>
          <span>
            {props.auxText}
            {!!props.auxRedactedDataCount && <Box component='span' sx={{ color: 'text.disabled' }}> {ANTHROPIC_REDACTED_EXPLAINER}{'.'.repeat(props.auxRedactedDataCount % 5)}</Box>}
          </span>
        </Typography>
      )}

    </ExpanderControlledBox>

  </Box>;
}


================================================
FILE: src/apps/chat/components/message/fragments-void/BlockPartPlaceholder.tsx
================================================
import * as React from 'react';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';
import { DataStreamViz } from '~/common/components/DataStreamViz';


// configuration
const DATASTREAM_VISUALIZATION_DELAY = Math.round(2 * Math.PI * 1000);


export function BlockPartPlaceholder(props: {
  placeholderText: string,
  messageRole: DMessageRole,
  contentScaling: ContentScaling,
  showAsItalic?: boolean,
  showAsDataStreamViz?: boolean,
}) {

  // state
  const [showVisualization, setShowVisualization] = React.useState(false);


  React.useEffect(() => {
    let timerId: ReturnType<typeof setTimeout> | undefined;

    if (props.showAsDataStreamViz)
      timerId = setTimeout(() => setShowVisualization(true), DATASTREAM_VISUALIZATION_DELAY);
    else
      setShowVisualization(false);

    return () => timerId && clearTimeout(timerId);
  }, [props.showAsDataStreamViz]);


  // Alternative placeholder visualization
  if (props.showAsDataStreamViz && showVisualization)
    return <DataStreamViz height={1 + 8 * 4} />;

  return (
    <ScaledTextBlockRenderer
      text={props.placeholderText}
      contentScaling={props.contentScaling}
      textRenderVariant='text'
      showAsItalic={props.showAsItalic}
    />
  );
}


================================================
FILE: src/apps/chat/components/message/fragments-void/VoidFragments.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { ContentScaling, UIComplexityMode } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';
import { DMessageContentFragment, DMessageFragmentId, DMessageVoidFragment, isPlaceholderPart } from '~/common/stores/chat/chat.fragments';
import { Release } from '~/common/app.release';

import { BlockPartModelAux } from './BlockPartModelAux';
import { BlockPartPlaceholder } from './BlockPartPlaceholder';
import { BlockPartModelAnnotations } from './BlockPartModelAnnotations';


const editLayoutSx: SxProps = {
  display: 'grid',
  gap: 1.5,     // see why we give more space on ChatMessage

  // horizontal separator between messages (second part+ and before)
  // '& > *:not(:first-of-type)': {
  //   borderTop: '1px solid',
  //   borderTopColor: 'background.level3',
  // },
};

const startLayoutSx: SxProps = {
  ...editLayoutSx,

  // NOTE: we used to have 'flex-start' here, but it was causing the Annotation fragment to not be able to
  // stretch to the full with of this 'void fragments' container.
  // So now we don't have 'flex-start' anymore, and we may expect issues with other Fragment kinds?
  // justifyContent: 'flex-start',
};

const endLayoutSx: SxProps = {
  ...editLayoutSx,
  justifyContent: 'flex-end',
};


/**
 * Note: one of the reasons to have a separate Void Fragments list (below images, above content)
 * is to display the void fragments without the 'star' separator (or edit state) that content fragments have.
 *
 * In the future we can revisit this decision in case Content fragments and *Void Fragments** are
 * interleaved - but for now, Void fragments will be grouped together at the top.
 */
export function VoidFragments(props: {

  voidFragments: DMessageVoidFragment[],
  nonVoidFragmentsCount: number,

  contentScaling: ContentScaling,
  uiComplexityMode: UIComplexityMode,
  messageRole: DMessageRole,

  onFragmentReplace?: (fragmentId: DMessageFragmentId, newFragment: DMessageContentFragment) => void,

}) {

  const showDataStreamViz =
    !Release.Features.LIGHTER_ANIMATIONS
    && props.uiComplexityMode !== 'minimal'
    && props.voidFragments.length === 1 && props.nonVoidFragmentsCount === 0
    && isPlaceholderPart(props.voidFragments[0].part);

  const fromAssistant = props.messageRole === 'assistant';


  return <Box aria-label='message void' sx={showDataStreamViz ? editLayoutSx : fromAssistant ? startLayoutSx : endLayoutSx}>

    {props.voidFragments.map(({ fId, part }) => {
      switch (part.pt) {

        case 'annotations':
          return (
            <BlockPartModelAnnotations
              key={fId}
              annotations={part.annotations}
              contentScaling={props.contentScaling}
            />
          );

        case 'ma':
          return (
            <BlockPartModelAux
              key={fId}
              fragmentId={fId}
              auxType={part.aType}
              auxText={part.aText}
              auxHasSignature={part.textSignature !== undefined}
              auxRedactedDataCount={part.redactedData?.length ?? 0}
              zenMode={props.uiComplexityMode === 'minimal'}
              contentScaling={props.contentScaling}
              onFragmentReplace={props.onFragmentReplace}
            />
          );

        case 'ph':
          return (
            <BlockPartPlaceholder
              key={fId}
              placeholderText={part.pText}
              messageRole={props.messageRole}
              contentScaling={props.contentScaling}
              showAsItalic
              showAsDataStreamViz={showDataStreamViz}
            />
          );

        case '_pt_sentinel':
          return null;

        default:
          // noinspection JSUnusedLocalSymbols
          const _exhaustiveVoidFragmentCheck: never = part;
          return (
            <ScaledTextBlockRenderer
              key={fId}
              text={`Unknown Void Fragment: ${(part as any)?.pt}`}
              contentScaling={props.contentScaling}
              textRenderVariant='text'
              showAsDanger
            />
          );
      }

    })}

  </Box>;
}



================================================
FILE: src/apps/chat/components/message/in-reference-to/InReferenceToBubble.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, IconButton, Tooltip, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import ReplyRoundedIcon from '@mui/icons-material/ReplyRounded';

import type { DMetaReferenceItem } from '~/common/stores/chat/chat.message';


// configuration
const INLINE_COLOR = 'primary';


const bubbleComposerSx: SxProps = {
  // contained
  width: '100%',
  zIndex: 2, // stays on top of the 'tokens' bubble in the composer

  // style
  backgroundColor: 'background.surface',
  border: '1px solid',
  borderColor: 'neutral.outlinedBorder',
  borderRadius: 'sm',
  boxShadow: 'xs',
  padding: '0.5rem 0.25rem 0.5rem 0.5rem',

  // layout
  display: 'flex',
  alignItems: 'start',
};

export const inlineMessageBubbleSx: SxProps = {
  ...bubbleComposerSx,

  // redefine
  // border: 'none',
  // mt: 1,
  borderColor: `${INLINE_COLOR}.outlinedColor`, // outlinedBorder:lighter, outlinedColor:darker
  borderRadius: 'sm',
  boxShadow: 'xs',
  // boxShadow: 'inset 2px 0px 5px -4px var(--joy-palette-primary-outlinedColor)',
  width: undefined,
  padding: '0.375rem 0.25rem 0.375rem 0.5rem',

  // FORMERLY: self-layout (parent: 'block', as 'grid' was not working and the user would scroll the app on the x-axis on mobile)
  // float: 'inline-end',
  // mr: { xs: 7.75, md: 10.5 }, // personaSx.minWidth + gap (md: 1) + 1.5 (text margin)

  // now: the parent is a 'grid' to v-layout fragment types
  // mx: '0.75rem', // 1.5, like margin of text blocks
  ml: 'auto', // right-align the bubble in the parent

};


export function InReferenceToBubble(props: {
  item: DMetaReferenceItem,
  onRemove?: (item: DMetaReferenceItem) => void,
  className?: string,
  bubbleVariant?: 'message',
}) {

  // derived state

  const variantMessage = props.bubbleVariant === 'message';

  // handlers

  const { onRemove } = props;

  const handleRemoveClicked = React.useCallback(() => {
    onRemove?.(props.item);
  }, [onRemove, props.item]);

  return (
    <Box className={props.className} sx={!variantMessage ? bubbleComposerSx : inlineMessageBubbleSx}>

      <Tooltip disableInteractive arrow title='Referring to this assistant text' placement='top'>
        <ReplyRoundedIcon sx={{
          color: variantMessage ? `${INLINE_COLOR}.outlinedColor` : 'primary.solidBg',
          fontSize: 'xl',
          mt: 0.125,
          transform: props.item.mRole === 'assistant' ? undefined : 'rotate(105deg)',
        }} />
      </Tooltip>

      <Typography level='body-sm' sx={{
        flex: 1,
        ml: 1,
        mr: variantMessage ? 1 : 0.5,
        overflow: 'auto',
        maxHeight: variantMessage ? '8rem' : '5.75rem',
        lineHeight: 'xl',
        color: variantMessage ? 'primary.softActiveColor' : 'text.secondary',
        whiteSpace: 'break-spaces', // 'balance'
      }}>
        {props.item.mText}
      </Typography>

      {!!props.onRemove && (
        <IconButton size='sm' onClick={handleRemoveClicked} sx={{ my: -0.5, background: 'none' }}>
          <CloseRoundedIcon />
        </IconButton>
      )}

    </Box>
  );
}


================================================
FILE: src/apps/chat/components/message/in-reference-to/InReferenceToList.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import type { DMetaReferenceItem } from '~/common/stores/chat/chat.message';

import { InReferenceToBubble } from './InReferenceToBubble';


const inReferenceToGroupSx: SxProps = {
  display: 'flex',
  flexDirection: 'column',
  gap: 1,
};


export function InReferenceToList(props: { items: DMetaReferenceItem[] }) {
  return (
    <Box sx={inReferenceToGroupSx}>
      {props.items.map((item, index) => (
        <InReferenceToBubble
          key={'irt-' + index}
          item={item}
          bubbleVariant='message'
        />
      ))}
    </Box>
  );
}


================================================
FILE: src/apps/chat/components/messages-list/CMLZeroConversation.tsx
================================================
import * as React from 'react';

import { Box, Button, Sheet, Typography } from '@mui/joy';
import AddIcon from '@mui/icons-material/Add';


const _styles = {
  center: {
    mx: 'auto',
    mt: 6.5, // roughly matches the 'AI Persona' buttons
    // my: 'auto',
  } as const,

  sheet: {
    maxWidth: 220,
    p: 2,
    // backgroundColor: 'background.popup',
    borderRadius: 'xl',

    display: 'flex',
    flexDirection: 'column',
    gap: 1.5,
  } as const,

  button: {
    // width: '100%',
    border: '1px solid',
    borderColor: 'neutral.outlinedBorder',
    borderRadius: 'sm',
    justifyContent: 'start',
  } as const,
} as const;


export function CMLZeroConversation(props: {
  onConversationNew: (forceNoRecycle: boolean, isIncognito: boolean) => void,
}) {
  return (
    <Box sx={_styles.center}>
      <Sheet
        variant='outlined'
        sx={_styles.sheet}
      >
        <Typography level='body-xs'>
          Please <>select a conversation</> from
          the left pane, <>branch</> a chat,
          or create a new one.
        </Typography>
        <Button
          variant='soft'
          onClick={() => props.onConversationNew(true, false)}
          startDecorator={<AddIcon />}
          sx={_styles.button}
        >
          New chat
        </Button>
      </Sheet>
    </Box>
  );
}


================================================
FILE: src/apps/chat/components/panes/store-panes-manager.ts
================================================
import * as React from 'react';
import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import { useShallow } from 'zustand/react/shallow';

import { DConversationId } from '~/common/stores/chat/chat.conversation';
import { agiUuid } from '~/common/util/idUtils';
import { useChatStore } from '~/common/stores/chat/store-chats';


// change this to increase/decrease the number history steps per pane
const MAX_HISTORY_LENGTH = 10;

// change this to allow for more/less panes
const MAX_CONCURRENT_PANES = 4;

// change to true to enable verbose console logging
const DEBUG_PANES_MANAGER = false;


// Future: support different types of panes: chat, docs, diff, settings, (beam?) etc.
// type Pane = ChatPane;

interface ChatPane {

  paneId: string;

  conversationId: DConversationId | null;

  // other per-pane storage? or would this be cluttering the panes(view)-only abstaction?
  // ... we are currently creating companion ConversationHandler obects for this

  history: DConversationId[]; // History of the conversationIds for this pane
  historyIndex: number; // Current position in the history for this pane

}

interface AppChatPanesState {

  chatPanes: ChatPane[];
  chatPaneFocusIndex: number | null;

}

interface AppChatPanesActions {

  // actions
  openConversationInFocusedPane: (conversationId: DConversationId) => void;
  openConversationInSplitPane: (conversationId: DConversationId) => void;
  navigateHistoryInFocusedPane: (direction: 'back' | 'forward') => boolean;
  duplicateFocusedPane: (/*paneIndex: number*/) => void;
  insertEmptyAfterFocusedPane: (reuseEmpty: boolean) => void;
  removeNonFocusedPanes: () => void;
  removePane: (paneIndex: number) => void;
  removeOtherPanes: (keepPaneIndex: number) => void;
  setFocusedPaneIndex: (paneIndex: number) => void;
  _onConversationsChanged: (conversationIds: DConversationId[]) => void;

}


const useAppChatPanesStore = create<AppChatPanesState & AppChatPanesActions>()(persist(
  (_set, _get) => ({

    // Initial state: no panes
    chatPanes: [] as ChatPane[],
    chatPaneFocusIndex: null as number | null,

    openConversationInFocusedPane: (conversationId: DConversationId) => {
      _set((state) => {
        const { chatPanes, chatPaneFocusIndex } = state;

        // If there's no pane or no focused pane, create and focus a new one.
        if (!chatPanes.length || chatPaneFocusIndex === null) {
          const newPane = _createChatPane(conversationId);
          return {
            chatPanes: [newPane],
            chatPaneFocusIndex: 0, // Focus the new pane
          };
        }

        // sanity check: Get the focused pane
        const focusedPane = chatPanes[chatPaneFocusIndex];
        if (!focusedPane) {
          console.warn('openConversationInFocusedPane: focusedPane is null', chatPaneFocusIndex, chatPanes);
          return state;
        }

        // Check if the conversation is already open in the focused pane.
        if (focusedPane.conversationId === conversationId) {
          if (DEBUG_PANES_MANAGER)
            console.log(`open-focuses: ${conversationId} is open in focused pane`, chatPaneFocusIndex, chatPanes);
          return state;
        }

        // Truncate the future history before adding the new conversation.
        const truncatedHistory = focusedPane.history.slice(0, focusedPane.historyIndex + 1);
        const newHistory = [...truncatedHistory, conversationId].slice(-MAX_HISTORY_LENGTH);

        // Update the focused pane with the new conversation and history.
        const newPanes = [...chatPanes];
        newPanes[chatPaneFocusIndex] = {
          ...focusedPane,
          conversationId,
          history: newHistory,
          historyIndex: newHistory.length - 1,
        };

        if (DEBUG_PANES_MANAGER)
          console.log(`open-focuses: set ${conversationId} in focused pane`, chatPaneFocusIndex, chatPanes);

        // Return the updated state.
        return {
          chatPanes: newPanes,
        };
      });
    },

    openConversationInSplitPane: (conversationId: DConversationId) => {
      // Open a conversation in a new pane, reusing an existing pane if possible.
      const { chatPanes, chatPaneFocusIndex, openConversationInFocusedPane } = _get();

      // Copy from the focused pane, if there's one
      const focusedPane = chatPaneFocusIndex !== null ? chatPanes[chatPaneFocusIndex] ?? null : null;

      // if fewer than the maximum panes, create a new pane and focus it
      if (chatPanes.length < MAX_CONCURRENT_PANES) {
        const insertIndex = chatPaneFocusIndex !== null ? chatPaneFocusIndex + 1 : chatPanes.length;
        _set((state) => ({
          chatPanes: [
            ...state.chatPanes.slice(0, insertIndex),
            focusedPane ? _duplicateChatPane(focusedPane) : _createChatPane(null),
            ...state.chatPanes.slice(insertIndex),
          ],
          chatPaneFocusIndex: insertIndex,
        }));
      }
      // max reached, replace the next pane (with wraparound) - note the outside logic won't get us here
      else {
        const replaceIndex = (chatPaneFocusIndex !== null ? chatPaneFocusIndex + 1 : 0) % MAX_CONCURRENT_PANES;
        _set({
          chatPaneFocusIndex: replaceIndex,
        });
      }

      // Open the conversation in the newly created or updated pane
      openConversationInFocusedPane(conversationId);

      if (DEBUG_PANES_MANAGER)
        console.log(`open-split-pane: after:`, _get().chatPanes);
    },

    navigateHistoryInFocusedPane: (direction: 'back' | 'forward'): boolean => {
      const { chatPanes, chatPaneFocusIndex } = _get();
      if (chatPaneFocusIndex === null)
        return false;

      const focusedPane = chatPanes[chatPaneFocusIndex];
      let newHistoryIndex = focusedPane.historyIndex;

      if (direction === 'back' && newHistoryIndex > 0)
        newHistoryIndex--;
      else if (direction === 'forward' && newHistoryIndex < focusedPane.history.length - 1)
        newHistoryIndex++;
      else {
        if (DEBUG_PANES_MANAGER)
          console.log(`navigateHistoryInFocusedPane: no history ${direction} for`, focusedPane);
        return false;
      }

      const newPanes = [...chatPanes];
      newPanes[chatPaneFocusIndex] = {
        ...focusedPane,
        conversationId: focusedPane.history[newHistoryIndex],
        historyIndex: newHistoryIndex,
      };

      if (DEBUG_PANES_MANAGER)
        console.log(`navigateHistoryInFocusedPane: ${direction} to`, focusedPane, newPanes);

      _set({
        chatPanes: newPanes,
      });

      return true;
    },

    duplicateFocusedPane: (/*paneIndex: number*/) =>
      _set(state => {
        const { chatPanes, chatPaneFocusIndex: _srcIndex } = state;

        // Validate index
        if (_srcIndex === null || _srcIndex < 0 || _srcIndex >= chatPanes.length) {
          console.warn('Attempted to duplicate a pane with an out-of-range index:', _srcIndex);
          return state; // Return the existing state without changes
        }

        // Clone the pane at the specified index, including a deep copy of the history array
        const paneToDuplicate = chatPanes[_srcIndex];
        const dstIndex = _srcIndex + 1;

        // Insert the duplicated pane into the array, right after the original pane
        const newPanes = [
          ...chatPanes.slice(0, dstIndex),
          _duplicateChatPane(paneToDuplicate),
          ...chatPanes.slice(dstIndex),
        ];

        return {
          chatPanes: newPanes,
          chatPaneFocusIndex: dstIndex,
        };
      }),

    insertEmptyAfterFocusedPane: (reuseEmpty: boolean) =>
      _set(state => {
        const { chatPanes, chatPaneFocusIndex: _srcIndex } = state;

        // if reusing, move focus to the first empty pane, if any
        if (reuseEmpty) {
          const emptyPaneIndex = chatPanes.findIndex(pane => pane.conversationId === null);
          if (emptyPaneIndex >= 0) {
            if (DEBUG_PANES_MANAGER)
              console.log('insertEmptyAfterFocusedPane: reusing empty pane at:', emptyPaneIndex);
            return {
              chatPaneFocusIndex: emptyPaneIndex,
            };
          }
        }

        // check precondition
        if (chatPanes.length >= MAX_CONCURRENT_PANES) {
          console.warn('Cannot add more panes: maximum reached');
          return state;
        }

        // insert an empty pane after the focused pane, or at the end if no focus
        const dstIndex = (_srcIndex !== null && _srcIndex >= 0) ? _srcIndex + 1 : chatPanes.length;
        const newPanes = [
          ...chatPanes.slice(0, dstIndex),
          _createChatPane(null),
          ...chatPanes.slice(dstIndex),
        ];

        if (DEBUG_PANES_MANAGER)
          console.log('insertEmptyAfterFocusedPane: created new empty pane at:', dstIndex);

        return {
          chatPanes: newPanes,
          chatPaneFocusIndex: dstIndex, // focus the new empty pane
        };
      }),

    removeNonFocusedPanes: () =>
      _set(state => {
        const { chatPanes, chatPaneFocusIndex } = state;
        if (chatPanes.length < 2)
          return state;

        const newPanes = [chatPanes[chatPaneFocusIndex ?? 0]];
        return {
          chatPanes: newPanes,
          chatPaneFocusIndex: 0,
        };
      }),

    removePane: (paneIndex: number) =>
      _set(state => {
        const { chatPanes } = state;
        if (paneIndex < 0 || paneIndex >= chatPanes.length)
          return state;

        const newPanes = chatPanes.toSpliced(paneIndex, 1);

        // when a pane is removed, focus the pane 0, or null if no panes remain
        return {
          chatPanes: newPanes,
          chatPaneFocusIndex: newPanes.length ? 0 : null,
        };
      }),

    removeOtherPanes: (keepPaneIdx: number) =>
      _set(state => {
        const { chatPanes } = state;
        if (keepPaneIdx < 0 || keepPaneIdx >= chatPanes.length || chatPanes.length <= 1 /* if only one pane, no need to do anything */)
          return state;

        const newPanes = [chatPanes[keepPaneIdx]];

        // focus the only remaining pane
        return {
          chatPanes: newPanes,
          chatPaneFocusIndex: 0,
        };
      }),

    setFocusedPaneIndex: (paneIndex: number) =>
      _set(state => {
        if (state.chatPaneFocusIndex === paneIndex)
          return state;

        const newFocusIndex =
          (paneIndex >= 0 && paneIndex < state.chatPanes.length) ? paneIndex // Valid index, set focus to it
            /**
             * If trying to set an invalid index but we have panes - default to first pane (0)
             * This fixed the bug where maxing out a pane would cause the focus to 'null' out
             */
            : (paneIndex >= 0 && state.chatPanes.length > 0) ? 0
              : null; // Unfocus

        return {
          chatPaneFocusIndex: newFocusIndex,
        };
      }),


    /**
     * This function is vital, as is invoked when the conversationId[] changes in the global chats store.
     * It takes care of `creating the first pane` as well as `removing invalid history items, reassiging
     * conversationIds, and re-focusing the pane`.
     */
    _onConversationsChanged: (conversationIds: DConversationId[]) =>
      _set(state => {
        const { chatPanes, chatPaneFocusIndex } = state;

        // handle panes
        let untouched = true;
        const newPanes: ChatPane[] = chatPanes.map(chatPane => {
          const { conversationId, history, historyIndex } = chatPane;

          // adjust history if any is deleted
          let newHistoryIndex = historyIndex;
          const newHistory = history.filter((_hId, index) => {
            const historyStillPresent = conversationIds.includes(_hId);
            if (!historyStillPresent && index <= historyIndex)
              newHistoryIndex--;
            return historyStillPresent;
          });
          if (newHistoryIndex < 0 && newHistory.length > 0)
            newHistoryIndex = 0;

          // check if pointing to a valid conversationId
          const needsNewConversationId = !conversationId || !conversationIds.includes(conversationId);
          if (!needsNewConversationId && newHistory.length === history.length)
            return chatPane;

          const nextConversationId = newHistoryIndex >= 0 && newHistoryIndex < newHistory.length
            ? newHistory[newHistoryIndex]
            : newHistory.length > 0
              ? newHistory[newHistory.length - 1]
              : conversationIds[0] ?? null;

          untouched = false;
          return {
            ...chatPane,
            conversationId: nextConversationId,
            history: newHistory,
            historyIndex: newHistoryIndex,
          };
        }).filter(pane => !!pane.conversationId);

        // if untouched, return state as-is
        if (untouched && newPanes.length >= 1)
          return state;

        // play it safe, and make sure a pane exists, and is focused
        return {
          chatPanes: newPanes.length ? newPanes : [_createChatPane(conversationIds[0] ?? null)],
          chatPaneFocusIndex: (newPanes.length && chatPaneFocusIndex !== null && chatPaneFocusIndex < newPanes.length) ? chatPaneFocusIndex : 0,
        };
      }),

  }), {
    // note: added the '-2' suffix on 20240308 to invalidate the persisted state, as we are adding a paneId
    name: 'app-app-chat-panes-2',
  },
));


function _createChatPane(conversationId: DConversationId | null = null): ChatPane {
  return {
    paneId: agiUuid('chat-pane'),
    conversationId,
    history: conversationId ? [conversationId] : [],
    historyIndex: conversationId ? 0 : -1,
  };
}

function _duplicateChatPane(pane: ChatPane): ChatPane {
  return {
    paneId: agiUuid('chat-pane'),
    conversationId: pane.conversationId,
    history: [...pane.history],
    historyIndex: pane.historyIndex,
  };
}


// Instant getters

export function panesManagerActions(): AppChatPanesActions {
  return useAppChatPanesStore.getState();
}

export function getInstantAppChatPanesCount() {
  return useAppChatPanesStore.getState().chatPanes.length;
}


// Reactive hooks

export function usePanesManager() {
  // use Panes - Note: before we had { _onConversationsChanged, ...panesFunctions } = ... but we don't need the internal function anymore
  const panesData = useAppChatPanesStore(useShallow(state => ({
    // state
    chatPanes: state.chatPanes as Readonly<ChatPane[]>,
    focusedPaneIndex: state.chatPaneFocusIndex,
    focusedPaneConversationId: state.chatPaneFocusIndex !== null ? state.chatPanes[state.chatPaneFocusIndex]?.conversationId ?? null : null,
    // methods
    openConversationInFocusedPane: state.openConversationInFocusedPane,
    openConversationInSplitPane: state.openConversationInSplitPane,
    navigateHistoryInFocusedPane: state.navigateHistoryInFocusedPane,
    removePane: state.removePane,
    setFocusedPaneIndex: state.setFocusedPaneIndex,
  })));

  // use changes in Conversation IDs[] to trigger the existence check
  const conversationIDs: DConversationId[] = useChatStore(useShallow(state =>
    state.conversations.map(_c => _c.id),
  ));

  // [Effect] Ensure all Panes have a valid Conversation ID
  React.useEffect(() => {
    panesManagerActions()._onConversationsChanged(conversationIDs);
  }, [conversationIDs]);

  return panesData;
}

export function usePaneDuplicateOrClose() {
  return useAppChatPanesStore(useShallow(state => ({
    // state
    canAddPane: state.chatPanes.length < MAX_CONCURRENT_PANES
      // if the current pane has an empty conversation, don't add another one!
      && (state.chatPaneFocusIndex === null || state.chatPanes[state.chatPaneFocusIndex].conversationId !== null),
    isMultiPane: state.chatPanes.length > 1,
    // actions
    duplicateFocusedPane: state.duplicateFocusedPane,
    removeOtherPanes: state.removeOtherPanes,
  })));
}


================================================
FILE: src/apps/chat/components/persona-selector/PersonaSelector.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { SxProps } from '@mui/joy/styles/types';
import { Alert, Avatar, Box, Button, Card, CardContent, Checkbox, IconButton, Input, List, ListItem, ListItemButton, Textarea, Tooltip, Typography } from '@mui/joy';
import ClearIcon from '@mui/icons-material/Clear';
import DoneIcon from '@mui/icons-material/Done';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import EditNoteIcon from '@mui/icons-material/EditNote';
import SearchIcon from '@mui/icons-material/Search';
import TelegramIcon from '@mui/icons-material/Telegram';

import { SystemPurposeData, SystemPurposeExample, SystemPurposeId, SystemPurposes } from '../../../../data';

import { YouTubeURLInput } from '~/modules/youtube/YouTubeURLInput';
import { bareBonesPromptMixer } from '~/modules/persona/pmix/pmix';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { ExpanderControlledBox } from '~/common/components/ExpanderControlledBox';
import { createDMessageTextContent } from '~/common/stores/chat/chat.message';
import { lineHeightTextareaMd } from '~/common/app.theme';
import { navigateToPersonas } from '~/common/app.routes';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useChipBoolean } from '~/common/components/useChipBoolean';
import { useModelDomain } from '~/common/stores/llms/hooks/useModelDomain';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { usePurposeStore } from './store-purposes';


// 'special' purpose IDs, for tile hiding purposes
const PURPOSE_ID_PERSONA_CREATOR = '__persona-creator__';
const TILE_ACTIVE_COLOR = 'primary' as const;

// defined looks
const tileSize = 7; // rem
const tileGap = 0.5; // rem


function Tile(props: {
  text?: string,
  imageUrl?: string,
  symbol?: string,
  isActive: boolean,
  isEditMode: boolean,
  isHidden?: boolean,
  isHighlighted?: boolean,
  onClick: () => void,
  sx?: SxProps,
}) {
  return (
    <Button
      variant={(!props.isEditMode && props.isActive) ? 'solid' : props.isHighlighted ? 'soft' : 'soft'}
      color={(!props.isEditMode && props.isActive) ? 'primary' : props.isHighlighted ? 'primary' : TILE_ACTIVE_COLOR}
      onClick={props.onClick}
      sx={{
        aspectRatio: 1,
        height: `${tileSize}rem`,
        fontWeight: 'md',
        lineHeight: 'xs',
        paddingInline: 0.5,
        ...((props.isEditMode || !props.isActive) ? {
          boxShadow: `0 2px 8px -3px rgb(var(--joy-palette-${TILE_ACTIVE_COLOR}-darkChannel) / 30%)`,
          // boxShadow: props.isHighlighted
          //   ? '0 2px 8px -2px rgb(var(--joy-palette-primary-darkChannel) / 30%)'
          //   : 'sm',
          backgroundColor: props.isHighlighted ? undefined : 'background.popup',
          // ...(props.imageUrl && {
          //   backgroundImage: `linear-gradient(rgba(255 255 255 /0.85), rgba(255 255 255 /1)), url(${props.imageUrl})`,
          //   backgroundPosition: 'center',
          //   backgroundSize: 'cover',
          //   '&:hover': {
          //     backgroundImage: 'none',
          //   },
          // }),
        } : {}),
        flexDirection: 'column', gap: props.symbol === '🎭' ? 0.5 : 1.25, pt: 1.25,
        ...props.sx,
      }}
    >
      {/* [Edit mode checkbox] */}
      {props.isEditMode && (
        <Checkbox
          variant='soft' color={TILE_ACTIVE_COLOR}
          checked={!props.isHidden}
          // label={<Typography level='body-xs'>show</Typography>}
          sx={{ position: 'absolute', left: `${tileGap}rem`, top: `${tileGap}rem` }}
        />
      )}

      {/* Icon and Text */}
      {/*<Box sx={{ fontSize: '2rem' }}>*/}
      {/*  {props.symbol}*/}
      {/*</Box>*/}
      <Avatar
        variant='plain'
        src={props.imageUrl}
        sx={{
          '--Avatar-size': '3rem',
          fontSize: '2rem',
          borderRadius: props.imageUrl ? 'sm' : 0,
          boxShadow: (props.imageUrl && !props.isActive) ? 'sm' : undefined,
        }}
      >
        {props.symbol}
      </Avatar>
      <div>
        {props.text}
      </div>
    </Button>
  );
}


/**
 * Purpose selector for the current chat. Clicking on any item activates it for the current chat.
 */
export function PersonaSelector(props: {
  conversationId: DConversationId,
  isMobile: boolean,
  runExample: (example: SystemPurposeExample) => void,
}) {

  // state
  const [searchQuery, setSearchQuery] = React.useState('');
  const [filteredIDs, setFilteredIDs] = React.useState<SystemPurposeId[] | null>(null);
  const [editMode, setEditMode] = React.useState(false);


  // external state
  const { complexityMode, showPersonaFinder } = useUIPreferencesStore(useShallow(state => ({
    complexityMode: state.complexityMode,
    showPersonaFinder: state.showPersonaFinder,
  })));
  const [showExamples, showExamplescomponent] = useChipBoolean('Examples', complexityMode === 'extra' && !props.isMobile);
  const [showPrompt, showPromptComponent] = useChipBoolean('Prompt', false);
  const { systemPurposeId, setSystemPurposeId } = useChatStore(useShallow(state => {
    const conversation = state.conversations.find(conversation => conversation.id === props.conversationId);
    return {
      systemPurposeId: conversation ? conversation.systemPurposeId : null,
      setSystemPurposeId: conversation ? state.setSystemPurposeId : null,
    };
  }));
  const { hiddenPurposeIDs, toggleHiddenPurposeId } = usePurposeStore(useShallow(state => ({
    hiddenPurposeIDs: state.hiddenPurposeIDs,
    toggleHiddenPurposeId: state.toggleHiddenPurposeId,
  })));
  const { domainModelId: chatLLMId } = useModelDomain('primaryChat');
  const chatLLM = { id: chatLLMId ?? undefined }; // adapter for porting


  // derived state

  const isCustomPurpose = systemPurposeId === 'Custom';
  const isYouTubeTranscriber = systemPurposeId === 'YouTubeTranscriber';

  const { selectedPurpose, fourExamples } = React.useMemo(() => {
    const selectedPurpose: SystemPurposeData | null = systemPurposeId ? (SystemPurposes[systemPurposeId] ?? null) : null;
    // const selectedExample = selectedPurpose?.examples?.length
    //   ? selectedPurpose.examples[Math.floor(Math.random() * selectedPurpose.examples.length)]
    //   : null;
    const fourExamples = selectedPurpose?.examples?.slice(0, 4) ?? null;
    return { selectedPurpose, fourExamples };
  }, [systemPurposeId]);


  const unfilteredPurposeIDs = (filteredIDs && showPersonaFinder) ? filteredIDs : Object.keys(SystemPurposes) as SystemPurposeId[];
  const visiblePurposeIDs = editMode ? unfilteredPurposeIDs : unfilteredPurposeIDs.filter(id => !hiddenPurposeIDs.includes(id));
  const hidePersonaCreator = hiddenPurposeIDs.includes(PURPOSE_ID_PERSONA_CREATOR);


  // Handlers

  const handlePurposeChanged = React.useCallback((purposeId: SystemPurposeId | null) => {
    if (purposeId && setSystemPurposeId)
      setSystemPurposeId(props.conversationId, purposeId);
  }, [props.conversationId, setSystemPurposeId]);

  const handleAppendTranscriptAsMessage = React.useCallback((messageText: string) => {
    // Create a new message object
    const newMessage = createDMessageTextContent('assistant', messageText); // [chat] append assistant:YouTube transcript

    // Append the new message to the conversation
    useChatStore.getState().appendMessage(props.conversationId, newMessage);
  }, [props.conversationId]);


  const handleCustomSystemMessageChange = React.useCallback((v: React.ChangeEvent<HTMLTextAreaElement>): void => {
    // TODO: persist this change? Right now it's reset every time.
    //       maybe we shall have a "save" button just save on a state to persist between sessions
    SystemPurposes['Custom'].systemMessage = v.target.value;
  }, []);

  const handleSwitchToCustom = React.useCallback((customText: string) => {
    if (setSystemPurposeId) {
      SystemPurposes['Custom'].systemMessage = customText;
      setSystemPurposeId(props.conversationId, 'Custom');
    }
  }, [props.conversationId, setSystemPurposeId]);

  const toggleEditMode = React.useCallback(() => setEditMode(on => !on), []);


  // Search (filtering)

  const handleSearchClear = React.useCallback(() => {
    setSearchQuery('');
    setFilteredIDs(null);
  }, []);

  const handleSearchOnChange = React.useCallback((e: React.ChangeEvent<HTMLInputElement>) => {
    const query = e.target.value;
    if (!query)
      return handleSearchClear();

    // Filter results based on search term (title and description)
    const lcQuery = query.toLowerCase();
    const ids = (Object.keys(SystemPurposes) as SystemPurposeId[])
      .filter(key => SystemPurposes.hasOwnProperty(key))
      .filter(key => {
        const purpose = SystemPurposes[key as SystemPurposeId];
        return purpose.title.toLowerCase().includes(lcQuery)
          || (typeof purpose.description === 'string' && purpose.description.toLowerCase().includes(lcQuery));
      });

    setSearchQuery(query);
    setFilteredIDs(ids);

    // If there's a search term, activate the first item
    // if (ids.length && systemPurposeId && !ids.includes(systemPurposeId))
    //   handlePurposeChanged(ids[0] as SystemPurposeId);
  }, [handleSearchClear]);

  const handleSearchOnKeyDown = React.useCallback((e: React.KeyboardEvent<HTMLInputElement>): void => {
    if (e.key == 'Escape')
      handleSearchClear();
  }, [handleSearchClear]);


  // safety check - shouldn't happen - this is set to null when the conversation is not found
  if (!setSystemPurposeId)
    return null;


  return (
    <Box sx={{
      maxWidth: 'md',
      minWidth: `${2 + 1 + tileSize * 2}rem`, // accomodate at least 2 columns (scroll-x in case)
      mx: 'auto',
      minHeight: '90%', // was 60svh - looked too big on desktop stacked
      display: 'grid',
      px: { xs: 0.5, sm: 1, md: 2 },
      py: 2,
    }}>

      {showPersonaFinder && <Box>
        <Input
          fullWidth
          variant='outlined' color='neutral'
          value={searchQuery} onChange={handleSearchOnChange}
          onKeyDown={handleSearchOnKeyDown}
          placeholder='Search for purpose…'
          startDecorator={<SearchIcon />}
          endDecorator={searchQuery && (
            <IconButton onClick={handleSearchClear}>
              <ClearIcon />
            </IconButton>
          )}
          sx={{
            boxShadow: 'sm',
          }}
        />
      </Box>}


      <Box sx={{
        my: 'auto',
        // layout
        display: 'grid',
        gridTemplateColumns: `repeat(auto-fit, minmax(${tileSize}rem, ${tileSize}rem))`,
        justifyContent: 'center', gap: `${tileGap}rem`,
      }}>

        {/* [row 0] ...  Edit mode [ ] */}
        <Box sx={{
          gridColumn: '1 / -1',
          display: 'flex', alignItems: 'center', justifyContent: 'space-between',
        }}>
          <Typography level='title-sm'>
            AI Persona
          </Typography>
          <Tooltip disableInteractive title={editMode ? 'Done Editing' : 'Edit Tiles'}>
            <IconButton size='sm' onClick={toggleEditMode} sx={{ my: '-0.25rem' /* absorb the button padding */ }}>
              {editMode ? <DoneIcon /> : <EditRoundedIcon />}
            </IconButton>
          </Tooltip>
        </Box>

        {/* Personas Tiles */}
        {visiblePurposeIDs.map((spId: SystemPurposeId) => {
          const isActive = systemPurposeId === spId;
          const systemPurpose = SystemPurposes[spId];
          return (
            <Tile
              key={'tile-' + spId}
              text={systemPurpose?.title}
              imageUrl={systemPurpose?.imageUri}
              symbol={systemPurpose?.symbol}
              isActive={isActive}
              isEditMode={editMode}
              isHidden={hiddenPurposeIDs.includes(spId)}
              isHighlighted={systemPurpose?.highlighted}
              onClick={() => editMode ? toggleHiddenPurposeId(spId) : handlePurposeChanged(spId)}
            />
          );
        })}

        {/* Persona Creator Tile */}
        {(editMode || !hidePersonaCreator) && (
          <Tile
            text='Persona Creator'
            symbol='🎭'
            isActive={false}
            isEditMode={editMode}
            isHidden={hidePersonaCreator}
            onClick={() => editMode ? toggleHiddenPurposeId(PURPOSE_ID_PERSONA_CREATOR) : void navigateToPersonas()}
            sx={{
              fontSize: 'xs',
              boxShadow: 'xs',
              backgroundColor: 'neutral.softDisabledBg',
            }}
          />
        )}


        {/* [row -3] Description */}
        <Box sx={{ gridColumn: '1 / -1', mt: 3, display: 'flex', alignItems: 'center', flexWrap: 'wrap', gap: 1 }}>

          {/* Description*/}
          <Typography level='body-sm' sx={{ color: 'text.primary' }}>
            {!selectedPurpose
              ? 'Cannot find the former persona' + (systemPurposeId ? ` "${systemPurposeId}"` : '')
              : selectedPurpose?.description || 'No description available'}
          </Typography>

          {/* Examples/Prompt Toggles */}
          <Box sx={{ display: 'flex', gap: 1 }}>
            {fourExamples && showExamplescomponent}
            {!isCustomPurpose && showPromptComponent}
          </Box>

        </Box>

        {/* [row -3] Example incipits */}
        {systemPurposeId !== 'Custom' && (
          <ExpanderControlledBox expanded={showExamples || (!isCustomPurpose && showPrompt)} sx={{ gridColumn: '1 / -1', pt: 1 }}>
            {showExamples && (
              <List
                aria-label='Persona Conversation Starters'
                sx={{
                  // example items 2-col layout
                  display: 'grid',
                  gridTemplateColumns: `repeat(auto-fit, minmax(${tileSize * 3 + 1}rem, 1fr))`,
                  gap: 1,
                }}
              >
                {fourExamples?.map((example, idx) => (
                  <ListItem
                    key={idx}
                    variant='outlined'
                    sx={{
                      // padding: '0.25rem 0.5rem',
                      backgroundColor: 'background.popup',
                      borderRadius: 'md',
                      boxShadow: 'xs',
                      '& svg': { opacity: 0.1, transition: 'opacity 0.2s' },
                      '&:hover svg': { opacity: 1 },
                    }}
                  >
                    <ListItemButton onClick={() => props.runExample(example)} sx={{ justifyContent: 'space-between', borderRadius: 'md' }}>
                      <Typography level='body-sm'>
                        {/* Icon 📁 when the .action is 'require-data-attachment' */}
                        {(typeof example === 'object' && example.action === 'require-data-attachment') ? '📁 ' : ''}
                        {(typeof example === 'string') ? example : example.prompt}
                      </Typography>
                      <TelegramIcon color='primary' sx={{}} />
                    </ListItemButton>
                  </ListItem>
                ))}
              </List>
            )}
            {(!isCustomPurpose && showPrompt) && (
              <Card>
                <CardContent>
                  <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, mb: 1 }}>
                    <Typography level='title-sm'>
                      System Prompt
                    </Typography>
                    <Button
                      variant='plain' color='neutral' size='sm'
                      endDecorator={<EditNoteIcon />}
                      onClick={() => handleSwitchToCustom(bareBonesPromptMixer(selectedPurpose?.systemMessage || 'No system message available', chatLLM?.id))}
                      sx={{ ml: 'auto', my: '-0.25rem' /* absorb the button padding */ }}
                    >
                      Custom
                    </Button>
                  </Box>
                  <Typography level='body-sm' sx={{ whiteSpace: 'break-spaces' }}>
                    {bareBonesPromptMixer(selectedPurpose?.systemMessage || 'No system message available', chatLLM?.id)}
                  </Typography>
                  {!!selectedPurpose?.systemMessageNotes && (
                    <Alert sx={{ m: -1, mt: 1, p: 1 }}>
                      <Typography level='body-xs'>
                        Prompt notes: {selectedPurpose.systemMessageNotes}
                      </Typography>
                    </Alert>
                  )}
                </CardContent>
              </Card>
            )}
          </ExpanderControlledBox>
        )}

        {/* [row -1] Custom Prompt box */}
        {systemPurposeId === 'Custom' && (
          <Textarea
            autoFocus
            variant='outlined'
            placeholder='Craft your custom system message here…'
            minRows={3}
            defaultValue={SystemPurposes['Custom']?.systemMessage}
            onChange={handleCustomSystemMessageChange}
            endDecorator={
              <Alert sx={{ flex: 1, p: 1 }}>
                <Typography level='body-xs'>
                  Just start chatting when done.
                </Typography>
              </Alert>
            }
            sx={{
              gridColumn: '1 / -1',
              backgroundColor: 'background.surface',
              '&:focus-within': {
                backgroundColor: 'background.popup',
              },
              lineHeight: lineHeightTextareaMd,
            }}
          />
        )}

        {/* [row -1] YouTube URL */}
        {isYouTubeTranscriber && (
          <YouTubeURLInput
            onSubmit={handleAppendTranscriptAsMessage}
            sx={{
              gridColumn: '1 / -1',
            }}
          />
        )}

      </Box>

    </Box>
  );
}


================================================
FILE: src/apps/chat/components/persona-selector/store-purposes.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';


interface PurposeStore {

  // state
  hiddenPurposeIDs: string[];

  // actions
  toggleHiddenPurposeId: (purposeId: string) => void;

}


export const usePurposeStore = create<PurposeStore>()(
  persist(
    (set) => ({

      // default state
      hiddenPurposeIDs: ['Developer', 'Designer', 'YouTubeTranscriber'],

      toggleHiddenPurposeId: (purposeId: string) => {
        set(state => {
          const hiddenPurposeIDs = state.hiddenPurposeIDs.includes(purposeId)
            ? state.hiddenPurposeIDs.filter((id) => id !== purposeId)
            : [...state.hiddenPurposeIDs, purposeId];
          return {
            hiddenPurposeIDs,
          };
        });
      },

    }),
    {
      name: 'app-purpose',

      /* versioning:
       * 1: hide 'Developer' as 'DeveloperPreview' is best
       * 2: add a hidden 'YouTubeTranscriber' purpose
       */
      version: 2,

      migrate: (state: any, fromVersion: number): PurposeStore => {
        // 0 -> 1: rename 'enterToSend' to 'enterIsNewline' (flip the meaning)
        if (state && fromVersion === 0)
          if (!state.hiddenPurposeIDs.includes('Developer'))
            state.hiddenPurposeIDs.push('Developer');
        // 1 -> 2: add a hidden 'YouTubeTranscriber' purpose
        if (state && fromVersion === 1)
          if (!state.hiddenPurposeIDs.includes('YouTubeTranscriber'))
            state.hiddenPurposeIDs.push('YouTubeTranscriber');
        return state;
      },
    }),
);


================================================
FILE: src/apps/chat/editors/_handleExecute.ts
================================================
import { getChatLLMId } from '~/common/stores/llms/store-llms';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import type { DMessage } from '~/common/stores/chat/chat.message';
import { ConversationHandler } from '~/common/chat-overlay/ConversationHandler';
import { ConversationsManager } from '~/common/chat-overlay/ConversationsManager';
import { createTextContentFragment, isContentOrAttachmentFragment, isImageRefPart, isTextContentFragment } from '~/common/stores/chat/chat.fragments';
import { getConversationSystemPurposeId } from '~/common/stores/chat/store-chats';

import type { ChatExecuteMode } from '../execute-mode/execute-mode.types';
import { textToDrawCommand } from '../commands/CommandsDraw';

import { _handleExecuteCommand, RET_NO_CMD } from './_handleExecuteCommand';
import { runImageGenerationUpdatingState } from './image-generate';
import { runPersonaOnConversationHead } from './chat-persona';
import { runReActUpdatingState } from './react-tangent';


export async function _handleExecute(chatExecuteMode: ChatExecuteMode, conversationId: DConversationId, executeCallerNameDebug: string) {

  // Handle missing conversation
  if (!conversationId)
    return 'err-no-conversation';

  const chatLLMId = getChatLLMId();
  const cHandler = ConversationsManager.getHandler(conversationId);
  const initialHistory = cHandler.historyViewHeadOrThrow('handle-execute-' + executeCallerNameDebug) as Readonly<DMessage[]>;

  // Update the system message from the active persona to the history
  // NOTE: this does NOT call setMessages anymore (optimization). make sure to:
  //       1. all the callers need to pass a new array
  //       2. all the exit points need to call setMessages
  const _inplaceEditableHistory = [...initialHistory];
  ConversationHandler.inlineUpdatePurposeInHistory(conversationId, _inplaceEditableHistory, chatLLMId || undefined);

  // Support for Prompt Caching - it's here rather than upstream to apply to user-initiated workflows
  ConversationHandler.inlineUpdateAutoPromptCaching(_inplaceEditableHistory);

  // Set the history - note that 'history' objects become invalid after this, and you'd have to
  // re-read it from the store, such as with `cHandler.historyView()`
  cHandler.historyReplace(_inplaceEditableHistory);


  // Handle unconfigured
  if (!chatLLMId || !chatExecuteMode)
    return !chatLLMId ? 'err-no-chatllm' : 'err-no-chatmode';

  // handle missing last user message (or fragment)
  // note that we use the initial history, as the user message could have been displaced on the edited versions
  const lastMessage = initialHistory.length >= 1 ? initialHistory.slice(-1)[0] : null;
  const firstFragment = lastMessage?.fragments[0];
  if (!lastMessage || !firstFragment)
    return 'err-no-last-message';


  // execute a command, if the last message has one
  if (lastMessage.role === 'user') {
    const cmdRC = await _handleExecuteCommand(lastMessage.id, firstFragment, lastMessage, cHandler, chatLLMId);
    if (cmdRC !== RET_NO_CMD) return cmdRC;
  }

  // get the system purpose (note: we don't react to it, or it would invalidate half UI components..)
  // TODO: change this massively
  if (!getConversationSystemPurposeId(conversationId)) {
    cHandler.messageAppendAssistantText('Issue: no Persona selected.', 'issue');
    return 'err-no-persona';
  }

  // synchronous long-duration tasks, which update the state as they go
  switch (chatExecuteMode) {
    case 'generate-content':
      return await runPersonaOnConversationHead(chatLLMId, conversationId);

    case 'beam-content':
      const updatedInputHistory = cHandler.historyViewHeadOrThrow('chat-beam-execute');
      cHandler.beamInvoke(updatedInputHistory, [], null);
      return true;

    case 'append-user':
      return true;

    case 'generate-image':
      // verify we were called with a single DMessageTextContent
      if (!isTextContentFragment(firstFragment))
        return false;
      const imagePrompt = firstFragment.part.text;
      cHandler.messageFragmentReplace(lastMessage.id, firstFragment.fId, createTextContentFragment(textToDrawCommand(imagePrompt)), true);

      // use additional image fragments as image inputs
      const imageInputFragments = lastMessage.fragments.slice(1)
        .filter(fragment => isContentOrAttachmentFragment(fragment) && isImageRefPart(fragment.part));

      return await runImageGenerationUpdatingState(cHandler, imagePrompt, imageInputFragments);

    case 'react-content':
      // verify we were called with a single DMessageTextContent
      if (!isTextContentFragment(firstFragment))
        return false;
      const reactPrompt = firstFragment.part.text;
      cHandler.messageFragmentReplace(lastMessage.id, firstFragment.fId, createTextContentFragment(`/react ${reactPrompt}`), true);
      return await runReActUpdatingState(cHandler, reactPrompt, chatLLMId, lastMessage.id);

    default:
      console.log('Chat execute: issue running', chatExecuteMode, conversationId, lastMessage);
      return false;
  }
}



================================================
FILE: src/apps/chat/editors/_handleExecuteCommand.ts
================================================
import type { DLLMId } from '~/common/stores/llms/llms.types';
import type { DMessage, DMessageId } from '~/common/stores/chat/chat.message';
import { ConversationHandler } from '~/common/chat-overlay/ConversationHandler';
import { createTextContentFragment, DMessageFragment, isContentOrAttachmentFragment, isImageRefPart, isTextContentFragment } from '~/common/stores/chat/chat.fragments';

import { extractChatCommand, helpPrettyChatCommands } from '../commands/commands.registry';
import { runImageGenerationUpdatingState } from './image-generate';
import { runReActUpdatingState } from './react-tangent';


export const RET_NO_CMD = 'no-cmd';


export async function _handleExecuteCommand(lastMessageId: DMessageId, lastMessageFirstFragment: DMessageFragment, lastMessage: Readonly<DMessage>, cHandler: ConversationHandler, chatLLMId: DLLMId) {

  // commands must have a first Content DMessageTextPart
  if (!isTextContentFragment(lastMessageFirstFragment))
    return RET_NO_CMD;

  // check if we have a command
  const _chatCommand = extractChatCommand(lastMessageFirstFragment.part.text)[0];
  if (_chatCommand?.type !== 'cmd')
    return RET_NO_CMD;

  // extract the information from the command
  const { providerId, command: userCommand, params: userText, isErrorNoArgs } = _chatCommand;

  // create a copy of the lastMessage without the 'command' part in the first fragment
  // TODO: future: move command to be decorators (meta parts) on the message
  const lastMessageNoCommand = { ...lastMessage };


  // Valid /commands are intercepted here, and override chat modes, generally for mechanics or sidebars
  switch (providerId) {

    case 'cmd-ass-t2i':

      // use additional image fragments as image inputs
      const imageInputFragments = lastMessage.fragments.slice(1)
        .filter(fragment => isContentOrAttachmentFragment(fragment) && isImageRefPart(fragment.part));

      return await runImageGenerationUpdatingState(cHandler, userText!, imageInputFragments);

    case 'cmd-chat-alter':
      // clear command
      if (userCommand === '/clear') {
        if (userText === 'all')
          cHandler.historyClear();
        else
          cHandler.messageAppendAssistantText('Issue: this command requires the \'all\' parameter to confirm the operation.', 'issue');
        return true;
      }
      // assistant/system command: change role and remove the /command
      cHandler.messageEdit(lastMessageId, { role: userCommand.startsWith('/s') ? 'system' : userCommand.startsWith('/a') ? 'assistant' : 'user' }, false, false);
      cHandler.messageFragmentReplace(lastMessageId, lastMessageFirstFragment.fId, createTextContentFragment(userText || ''), true);
      return true;

    case 'cmd-help':
      cHandler.messageAppendAssistantText(`Available Chat Commands:\n${helpPrettyChatCommands()}`, 'help');
      return true;

    // NOTE 12/9/2024: removed this as /beam should not be a command, but it's already a chat mode, e.g. can't be headless executed.
    //                 the following code is here for reference/historical reasons
    // case 'cmd-mode-beam':
    //   if (isErrorNoArgs || !userText)
    //     return false;
    //   // remove '/beam ', as we want to be a user chat message
    //   cHandler.messageFragmentReplace(lastMessageId, lastMessageFirstFragment.fId, createTextContentFragment(userText), true);
    //   cHandler.beamInvoke(cHandler.historyViewHead('cmd-mode-beam'), [], null);
    //   return true;

    case 'cmd-mode-react':
      // create a temporary copy of the message,

      return await runReActUpdatingState(cHandler, userText, chatLLMId, lastMessageId);

    default:
      cHandler.messageAppendAssistantText('This command is not supported', 'help');
      return false;
  }
}



================================================
FILE: src/apps/chat/editors/browse-load.ts
================================================
/*
// NOTE: this is not used anymore and here just as a reference code and to demonstrate alternative conversation modes / editors

import { callBrowseFetchPageOrThrow } from '~/modules/browse/browse.client';

import type { ConversationHandler } from '~/common/chat-overlay/ConversationHandler';
import { createErrorContentFragment, createTextContentFragment } from '~/common/stores/chat/chat.fragments';


export const runBrowseGetPageUpdatingState = async (cHandler: ConversationHandler, url?: string) => {
  if (!url) {
    cHandler.messageAppendAssistantText('Issue: no URL provided.', 'issue');
    return false;
  }

  // noinspection HttpUrlsUsage
  const shortUrl = url.replace('https://www.', '').replace('https://', '').replace('http://', '').replace('www.', '');
  const { assistantMessageId, placeholderFragmentId } = cHandler.messageAppendAssistantPlaceholder(
    `Loading page at ${shortUrl}...`,
    { generator: { mgt: 'named', name: 'web' } },
  );

  try {
    const page = await callBrowseFetchPageOrThrow(url);
    if (!page.content) {
      cHandler.messageFragmentReplace(assistantMessageId, placeholderFragmentId, createErrorContentFragment('Issue: Browsing pointed to a file but we do not support files at the moment.'), true);
      return false;
    }

    const pageContent = page.content.markdown || page.content.text || page.content.html || 'Issue: Browsing did not produce a page content.';
    cHandler.messageFragmentReplace(assistantMessageId, placeholderFragmentId, createTextContentFragment(pageContent), true);

    return true;
  } catch (error: any) {
    console.error(error);

    const pageError = 'Issue: Browsing did not produce a page.\n(error: ' + (error?.message || error?.toString() || 'unknown') + ').';
    cHandler.messageFragmentReplace(assistantMessageId, placeholderFragmentId, createErrorContentFragment(pageError), true);

    return false;
  }
};
 */


================================================
FILE: src/apps/chat/editors/chat-persona.ts
================================================
import { AixChatGenerateContent_DMessage, aixChatGenerateContent_DMessage_FromConversation } from '~/modules/aix/client/aix.client';
import { autoChatFollowUps } from '~/modules/aifn/auto-chat-follow-ups/autoChatFollowUps';
import { autoConversationTitle } from '~/modules/aifn/autotitle/autoTitle';

import { DConversationId, splitSystemMessageFromHistory } from '~/common/stores/chat/chat.conversation';
import type { DLLMId } from '~/common/stores/llms/llms.types';
import { AudioGenerator } from '~/common/util/audio/AudioGenerator';
import { ConversationsManager } from '~/common/chat-overlay/ConversationsManager';
import { DMessage, MESSAGE_FLAG_NOTIFY_COMPLETE, messageWasInterruptedAtStart } from '~/common/stores/chat/chat.message';
import { getUXLabsHighPerformance } from '~/common/stores/store-ux-labs';

import { PersonaChatMessageSpeak } from './persona/PersonaChatMessageSpeak';
import { getChatAutoAI, getIsNotificationEnabledForModel } from '../store-app-chat';
import { getInstantAppChatPanesCount } from '../components/panes/store-panes-manager';


// configuration
export const CHATGENERATE_RESPONSE_PLACEHOLDER = '...'; // 💫 ..., 🖊️ ...


export interface PersonaProcessorInterface {
  handleMessage(accumulatedMessage: AixChatGenerateContent_DMessage, messageComplete: boolean): void;
}


/**
 * The main "chat" function.
 * @returns `true` if the operation was successful, `false` otherwise.
 */
export async function runPersonaOnConversationHead(
  assistantLlmId: DLLMId,
  conversationId: DConversationId,
): Promise<boolean> {

  const cHandler = ConversationsManager.getHandler(conversationId);

  const _history = cHandler.historyViewHeadOrThrow('runPersonaOnConversationHead') as Readonly<DMessage[]>;
  if (_history.length === 0)
    return false;

  // split pre dynamic-personas
  let { chatSystemInstruction, chatHistory } = splitSystemMessageFromHistory(_history);

  // assistant response placeholder
  const isNotifyEnabled = getIsNotificationEnabledForModel(assistantLlmId);
  const { assistantMessageId } = cHandler.messageAppendAssistantPlaceholder(
    CHATGENERATE_RESPONSE_PLACEHOLDER,
    {
      purposeId: chatSystemInstruction?.purposeId,
      generator: { mgt: 'named', name: assistantLlmId },
      ...(isNotifyEnabled ? { userFlags: [MESSAGE_FLAG_NOTIFY_COMPLETE] } : {}),
    },
  );

  const parallelViewCount = getUXLabsHighPerformance() ? 0 : getInstantAppChatPanesCount();

  // ai follow-up operations (fire/forget)
  const { autoSpeak, autoSuggestDiagrams, autoSuggestHTMLUI, autoSuggestQuestions, autoTitleChat, chatKeepLastThinkingOnly } = getChatAutoAI();

  // AutoSpeak
  const autoSpeaker: PersonaProcessorInterface | null = autoSpeak !== 'off' ? new PersonaChatMessageSpeak(autoSpeak) : null;

  // when an abort controller is set, the UI switches to the "stop" mode
  const abortController = new AbortController();
  cHandler.setAbortController(abortController, 'chat-persona');

  // stream the assistant's messages directly to the state store
  const messageStatus = await aixChatGenerateContent_DMessage_FromConversation(
    assistantLlmId,
    chatSystemInstruction,
    chatHistory,
    'conversation',
    conversationId,
    { abortSignal: abortController.signal, throttleParallelThreads: parallelViewCount },
    (messageOverwrite: AixChatGenerateContent_DMessage, messageComplete: boolean) => {

      // Note: there was an abort check here, but it removed the last packet, which contained the cause and final text.
      // if (abortController.signal.aborted)
      //   console.warn('runPersonaOnConversationHead: Aborted', { conversationId, assistantLlmId, messageOverwrite });

      // deep copy the object to avoid partial updates
      let deepCopy = structuredClone(messageOverwrite);

      // [Cosmetic Logic] if the content hasn't come yet, don't replace the fragments to still show the placeholder
      if (!messageComplete && deepCopy.pendingIncomplete && deepCopy.fragments?.length === 0)
        delete (deepCopy as any).fragments;

      // update the message
      cHandler.messageEdit(assistantMessageId, deepCopy, messageComplete, false);

      // if requested, speak the message
      autoSpeaker?.handleMessage(messageOverwrite, messageComplete);

      // if (messageComplete)
      //   AudioGenerator.basicAstralChimes({ volume: 0.4 }, 0, 2, 250);
    },
  );

  // final message update (needed only in case of error)
  const lastDeepCopy = structuredClone(messageStatus.lastDMessage);
  if (messageStatus.outcome === 'errored')
    cHandler.messageEdit(assistantMessageId, lastDeepCopy, true, false);

  // special case: if the last message was aborted and had no content, delete it
  if (messageWasInterruptedAtStart(lastDeepCopy)) {
    cHandler.messagesDelete([assistantMessageId]);
    // NOTE: ok to exit here, as the abort was already done
    return false;
  }

  // notify when complete, if set
  if (cHandler.messageHasUserFlag(assistantMessageId, MESSAGE_FLAG_NOTIFY_COMPLETE)) {
    cHandler.messageSetUserFlag(assistantMessageId, MESSAGE_FLAG_NOTIFY_COMPLETE, false, false);
    AudioGenerator.chatNotifyResponse();
  }

  // check if aborted
  const hasBeenAborted = abortController.signal.aborted;

  // clear to send, again
  // FIXME: race condition? (for sure!)
  cHandler.clearAbortController('chat-persona');

  if (autoTitleChat) {
    // fire/forget, this will only set the title if it's not already set
    void autoConversationTitle(conversationId, false);
  }

  if (!hasBeenAborted && (autoSuggestDiagrams || autoSuggestHTMLUI || autoSuggestQuestions))
    void autoChatFollowUps(conversationId, assistantMessageId, autoSuggestDiagrams, autoSuggestHTMLUI, autoSuggestQuestions);

  if (chatKeepLastThinkingOnly)
    cHandler.historyKeepLastThinkingOnly();

  // return true if this succeeded
  return messageStatus.outcome === 'success';
}



================================================
FILE: src/apps/chat/editors/image-generate.ts
================================================
import { getActiveTextToImageProviderOrThrow, t2iGenerateImageContentFragments } from '~/modules/t2i/t2i.client';

import type { AixParts_InlineImagePart } from '~/modules/aix/server/api/aix.wiretypes';
import { aixConvertImageRefToInlineImageOrThrow } from '~/modules/aix/client/aix.client.chatGenerateRequest';

import type { ConversationHandler } from '~/common/chat-overlay/ConversationHandler';
import type { Immutable } from '~/common/types/immutable.types';
import type { TextToImageProvider } from '~/common/components/useCapabilities';
import { createErrorContentFragment, DMessageFragment, isContentOrAttachmentFragment, isImageRefPart } from '~/common/stores/chat/chat.fragments';


// NOTE: also see src/common/stores/chat/chat.gc.ts, which has cleanup code for images create here


/**
 * Text to image, appended as an 'assistant' message
 */
export async function runImageGenerationUpdatingState(cHandler: ConversationHandler, imageText: string, imageFragments?: Immutable<DMessageFragment[]>) {
  if (!imageText) {
    cHandler.messageAppendAssistantText('Issue: no image description provided.', 'issue');
    return false;
  }

  // Acquire the active TextToImageProvider
  let t2iProvider: TextToImageProvider | undefined = undefined;
  try {
    t2iProvider = getActiveTextToImageProviderOrThrow();
  } catch (error: any) {
    cHandler.messageAppendAssistantText(`[Issue] Sorry, I can't generate images right now. ${error?.message || error?.toString() || 'Unknown error'}.`, 'issue');
    return 'err-t2i-unconfigured';
  }

  // if the imageText ends with " xN" or " [N]" (where N is a number), then we'll generate N images
  const match = imageText.match(/\sx(\d+)$|\s\[(\d+)]$/);
  const repeat = match ? parseInt(match[1] || match[2], 10) : 1;
  if (repeat > 1)
    imageText = imageText.replace(/x(\d+)$|\[(\d+)]$/, '').trim(); // Remove the "xN" or "[N]" part from the imageText

  const { assistantMessageId, placeholderFragmentId } = cHandler.messageAppendAssistantPlaceholder(
    `Give me ${t2iProvider.vendor === 'openai' ? 'a minute' : 'a few seconds'} while I draw ${imageText?.length > 20 ? 'that' : '"' + imageText + '"'} with ${t2iProvider.painter}...`,
    { generator: { mgt: 'named', name: t2iProvider.painter } },
  );

  // edit-generation: ready the images payload
  const aixInlineImageParts: AixParts_InlineImagePart[] = [];
  if (imageFragments?.length) {
    for (const fragment of imageFragments) {
      if (!isContentOrAttachmentFragment(fragment) || !isImageRefPart(fragment.part)) {
        console.log('[DEV] Invalid image fragment', { fragment });
        continue;
      }

      // dereference and ready for transmission - do not resize any input
      try {
        const aixImageInlinePart = await aixConvertImageRefToInlineImageOrThrow(fragment.part, false);
        if (!aixImageInlinePart) {
          console.log('[DEV] Invalid image fragment', { fragment });
          continue;
        }
        aixInlineImageParts.push(aixImageInlinePart);
      } catch (error: any) {
        console.log('[DEV] Error converting image fragment', { fragment, error });
      }
    }
  }

  try {
    const imageContentFragments = await t2iGenerateImageContentFragments(t2iProvider, imageText, aixInlineImageParts, repeat, 'app-chat');

    // add the image content fragments to the message
    for (const imageContentFragment of imageContentFragments)
      cHandler.messageFragmentAppend(assistantMessageId, imageContentFragment, false, false);

    cHandler.messageFragmentDelete(assistantMessageId, placeholderFragmentId, true, true);

    return true;
  } catch (error: any) {

    const drawError = `Issue encountered while creating your image.\n${error?.message || error?.toString() || 'Unknown error'}.`;
    cHandler.messageFragmentReplace(assistantMessageId, placeholderFragmentId, createErrorContentFragment(drawError), true);

    return false;
  }
}




================================================
FILE: src/apps/chat/editors/react-tangent.ts
================================================
import { Agent } from '~/modules/aifn/react/react';
import { useBrowseStore } from '~/modules/browse/store-module-browsing';

import type { ConversationHandler } from '~/common/chat-overlay/ConversationHandler';
import type { DLLMId } from '~/common/stores/llms/llms.types';
import { createErrorContentFragment, createTextContentFragment } from '~/common/stores/chat/chat.fragments';

// configuration
const EPHEMERAL_DELETION_DELAY = 5 * 1000;


/**
 * Synchronous ReAct chat function - TODO: event loop, auto-ui, cleanups, etc.
 */
export async function runReActUpdatingState(cHandler: ConversationHandler, question: string | undefined, assistantLlmId: DLLMId, contextRef: string) {
  if (!question) {
    cHandler.messageAppendAssistantText('Issue: no question provided.', 'issue');
    return false;
  }

  // create an assistant placeholder message - to be filled when we're done
  const assistantModelLabel = 'react-' + assistantLlmId; //.slice(4, 7); // HACK: this is used to change the Avatar animation
  const { assistantMessageId, placeholderFragmentId } = cHandler.messageAppendAssistantPlaceholder(
    '...',
    { generator: { mgt: 'named', name: assistantModelLabel } },
  );
  const { enableReactTool: enableBrowse } = useBrowseStore.getState();

  // Abort controller for the ReAct loop
  const abortController = new AbortController();
  cHandler.setAbortController(abortController, 'react-tangent');

  // Ephemeral: the space of Status and Logs, auto-plugged to the UI
  const hEphemeral = cHandler.createEphemeralHandler(`Reason+Act`, 'Initializing ReAct..');
  let ephemeralText = '';
  const logToEphemeral = (text: string) => {
    console.log(text);
    ephemeralText += (text.length > 300 ? text.slice(0, 300) + '...' : text) + '\n';
    hEphemeral.updateText(ephemeralText);
  };
  const showStateInEphemeral = (state: object) => hEphemeral.updateState(state);

  try {

    // react loop
    const agent = new Agent(contextRef, abortController.signal);
    const reactResult = await agent.reAct(question, assistantLlmId, 5, enableBrowse, logToEphemeral, showStateInEphemeral);

    cHandler.messageFragmentReplace(assistantMessageId, placeholderFragmentId, createTextContentFragment(reactResult), true);

    hEphemeral.markAsDone();

    return true;
  } catch (error: any) {
    console.error('ReAct error', error);

    logToEphemeral(ephemeralText + `\n${error || 'unknown'}`);

    const reactError = `Issue: ReAct couldn't answer your question. ${error?.message || error?.toString() || 'Unknown error'}`;
    cHandler.messageFragmentReplace(assistantMessageId, placeholderFragmentId, createErrorContentFragment(reactError), true);

    return false;
  } finally {
    // FIXME: Massive race condition here
    cHandler.clearAbortController('react-tangent');
  }
}


================================================
FILE: src/apps/chat/editors/persona/PersonaChatMessageSpeak.ts
================================================
import { elevenLabsSpeakText } from '~/modules/elevenlabs/elevenlabs.client';

import { isTextContentFragment } from '~/common/stores/chat/chat.fragments';

import type { AixChatGenerateContent_DMessage } from '~/modules/aix/client/aix.client';

import type { PersonaProcessorInterface } from '../chat-persona';


export type AutoSpeakType = 'off' | 'firstLine' | 'all';


export class PersonaChatMessageSpeak implements PersonaProcessorInterface {
  private spokenLine: boolean = false;

  constructor(private autoSpeakType: AutoSpeakType) {
  }

  handleMessage(accumulatedMessage: Partial<AixChatGenerateContent_DMessage>, messageComplete: boolean) {
    if (this.autoSpeakType === 'off' || this.spokenLine) return;

    // Require a Content.Text first fragment
    if (!accumulatedMessage.fragments?.length || !isTextContentFragment(accumulatedMessage.fragments[0]))
      return;
    const text = accumulatedMessage.fragments[0].part.text;

    if (!messageComplete)
      this.#handleTextSoFar(text);
    else
      this.#finalizeText(text);
  }


  #handleTextSoFar(textSoFar: string): void {
    // 📢 TTS: first-line
    if (this.autoSpeakType === 'firstLine') {
      const cutPoint = this.#findLastCutPoint(textSoFar);
      if (cutPoint > 100 && cutPoint < 400) {
        const firstParagraph = textSoFar.substring(0, cutPoint);
        this.#speak(firstParagraph);
      }
    }
  }

  #finalizeText(fullText: string): void {
    if (fullText.length > 0) {
      this.#speak(fullText);
    }
  }

  #findLastCutPoint(text: string): number {
    let cutPoint = text.lastIndexOf('\n');
    if (cutPoint < 0)
      cutPoint = text.lastIndexOf('. ');
    return cutPoint;
  }

  #speak(text: string) {
    console.log('📢 TTS:', text);
    this.spokenLine = true;
    // fire/forget: we don't want to stall this loop
    void elevenLabsSpeakText(text, undefined, false, true);
  }
}



================================================
FILE: src/apps/chat/execute-mode/execute-mode.items.ts
================================================
import * as React from 'react';

import type { ColorPaletteProp } from '@mui/joy/styles/types';

import type { ChatExecuteMode } from './execute-mode.types';


interface ModeDescription {
  // menu data
  label: string;
  description: string | React.JSX.Element;
  canAttach?: true | 'requires-tti-edit';
  highlight?: boolean;
  shortcut?: string;
  hideOnDesktop?: boolean;
  requiresTTI?: boolean;
  // button data
  sendColor: ColorPaletteProp;
  sendText: string;
}


export const ExecuteModeItems: { [key in ChatExecuteMode]: ModeDescription } = {
  'generate-content': {
    label: 'Chat',
    description: 'Persona replies',
    canAttach: true,
    sendColor: 'primary',
    sendText: 'Chat',
  },
  'beam-content': {
    label: 'Beam', // Best of, Auto-Prime, Top Pick, Select Best
    description: 'Combine multiple models', // Smarter: combine...
    shortcut: 'Ctrl + Enter',
    canAttach: true,
    hideOnDesktop: true,
    sendColor: 'primary',
    sendText: 'Beam',
  },
  'append-user': {
    label: 'Add',
    description: 'Insert content',
    shortcut: 'Alt + Enter',
    canAttach: true,
    sendColor: 'primary',
    sendText: 'Add',
  },
  'generate-image': {
    label: 'Draw',
    description: 'AI Image Generation',
    canAttach: 'requires-tti-edit',
    requiresTTI: true,
    sendColor: 'warning',
    sendText: 'Draw',
  },
  'react-content': {
    label: 'Reason + Act', //  · α
    description: 'Answer questions in multiple steps',
    sendColor: 'success',
    sendText: 'ReAct',
  },
};



================================================
FILE: src/apps/chat/execute-mode/execute-mode.types.ts
================================================
/**
 * Mode: how to treat the input from the Composer
 * Was: ChatModeId
 */
export type ChatExecuteMode =
  | 'append-user'
  | 'beam-content'
  | 'generate-content'
  | 'generate-image'
  | 'react-content'
  ;



================================================
FILE: src/apps/chat/execute-mode/ExecuteModeMenu.tsx
================================================
import * as React from 'react';

import { Box, MenuItem, Radio, Typography } from '@mui/joy';

import { CloseablePopup } from '~/common/components/CloseablePopup';
import { KeyStroke, platformAwareKeystrokes } from '~/common/components/KeyStroke';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import type { ChatExecuteMode } from './execute-mode.types';
import { ExecuteModeItems } from './execute-mode.items';


export function ExecuteModeMenu(props: {
  isMobile: boolean,
  hasCapabilityT2I: boolean,
  anchorEl: HTMLAnchorElement | null,
  onClose: () => void,
  chatExecuteMode: ChatExecuteMode,
  onSetChatExecuteMode: (chatExecuteMode: ChatExecuteMode) => void,
}) {

  // external state
  const enterIsNewline = useUIPreferencesStore(state => state.enterIsNewline);

  return (
    <CloseablePopup
      menu anchorEl={props.anchorEl} onClose={props.onClose}
      minWidth={320}
      placement='top-end'
    >

      {/*<MenuItem color='neutral' selected>*/}
      {/*  Conversation Mode*/}
      {/*</MenuItem>*/}
      {/**/}
      {/*<ListDivider />*/}

      {/* Items */}
      {Object.entries(ExecuteModeItems)
        .filter(([_key, data]) => !data.hideOnDesktop || props.isMobile)
        .map(([key, data]) =>
          <MenuItem key={'chat-mode-' + key} onClick={() => props.onSetChatExecuteMode(key as ChatExecuteMode)}>
            <Box sx={{ flexGrow: 1, display: 'flex', flexDirection: 'row', alignItems: 'center', gap: 2 }}>
              <Radio color={data.highlight ? 'success' : undefined} checked={key === props.chatExecuteMode} />
              <Box sx={{ flexGrow: 1 }}>
                <Typography>{data.label}</Typography>
                <Typography level='body-xs'>{data.description}{(data.requiresTTI && !props.hasCapabilityT2I) ? 'Unconfigured' : ''}</Typography>
              </Box>
              {(key === props.chatExecuteMode || !!data.shortcut) && (
                <KeyStroke variant='outlined' combo={platformAwareKeystrokes(
                  newLineShortcut(
                    (key === props.chatExecuteMode) ? 'ENTER'
                      : data.shortcut ? data.shortcut
                        : 'ENTER',
                    enterIsNewline,
                  ),
                )} />
              )}
            </Box>
          </MenuItem>,
        )}

    </CloseablePopup>
  );
}

function newLineShortcut(shortcut: string, enterIsNewLine: boolean) {
  if (shortcut === 'ENTER')
    return enterIsNewLine ? 'Shift + Enter' : 'Enter';
  return shortcut;
}



================================================
FILE: src/apps/chat/execute-mode/useChatExecuteMode.tsx
================================================
import * as React from 'react';

import type { ChatExecuteMode } from './execute-mode.types';
import { ExecuteModeMenu } from './ExecuteModeMenu';
import { ExecuteModeItems } from './execute-mode.items';


export function chatExecuteModeCanAttach(chatExecuteMode: ChatExecuteMode, capabilityHasT2IEdit: boolean): boolean | 'only-images' {
  const executeMode = ExecuteModeItems[chatExecuteMode];
  if (!executeMode) return false;
  if (executeMode.canAttach === 'requires-tti-edit' && capabilityHasT2IEdit)
    return 'only-images';
  return executeMode.canAttach === true;
}


export function useChatExecuteMode(capabilityHasT2I: boolean, isMobile: boolean) {

  // state
  const [chatExecuteMode, setChatExecuteMode] = React.useState<ChatExecuteMode>('generate-content');
  const [chatExecuteModeMenuAnchor, setChatExecuteModeMenuAnchor] = React.useState<HTMLAnchorElement | null>(null);


  const handleMenuHide = React.useCallback(() => setChatExecuteModeMenuAnchor(null), []);

  const handleMenuShow = React.useCallback((event: React.MouseEvent<HTMLAnchorElement>) => {
    setChatExecuteModeMenuAnchor(anchor => anchor ? null : event.currentTarget);
  }, []);

  const handleChangeMode = React.useCallback((mode: ChatExecuteMode) => {
    handleMenuHide();
    setChatExecuteMode(mode);
  }, [handleMenuHide]);


  const chatExecuteMenuComponent = React.useMemo(() => !!chatExecuteModeMenuAnchor && (
    <ExecuteModeMenu
      isMobile={isMobile}
      hasCapabilityT2I={capabilityHasT2I}
      anchorEl={chatExecuteModeMenuAnchor}
      onClose={handleMenuHide}
      chatExecuteMode={chatExecuteMode}
      onSetChatExecuteMode={handleChangeMode}
    />
  ), [capabilityHasT2I, chatExecuteMode, chatExecuteModeMenuAnchor, handleMenuHide, handleChangeMode, isMobile]);


  return {
    chatExecuteMode,
    chatExecuteMenuComponent,
    chatExecuteModeSendColor: ExecuteModeItems[chatExecuteMode]?.sendColor || 'primary',
    chatExecuteModeSendLabel: ExecuteModeItems[chatExecuteMode]?.sendText || 'Send',
    chatExecuteMenuShown: !!chatExecuteModeMenuAnchor,
    showChatExecuteMenu: handleMenuShow,
  };
}



================================================
FILE: src/apps/diff/AppDiff.tsx
================================================
import * as React from 'react';
import type { FileWithHandle } from 'browser-fs-access';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Card, Divider, FormControl, IconButton, Textarea, Tooltip, Typography } from '@mui/joy';
import SwapHorizIcon from '@mui/icons-material/SwapHoriz';

import { RenderWordsDiff, useWordsDifference } from '~/modules/blocks/wordsdiff/RenderWordsDiff';

import { ButtonAttachFilesMemo } from '~/common/components/ButtonAttachFiles';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { countWords } from '~/common/util/textUtils';
import { themeScalingMap } from '~/common/app.theme';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUIContentScaling } from '~/common/stores/store-ui';

import { AppSmallContainer } from '../AppSmallContainer';


export function AppDiff() {

  // state
  const [text1, setText1] = React.useState('This is the Original text...');
  const [text2, setText2] = React.useState('This is the Modified text...');
  const [isSwapping, setIsSwapping] = React.useState(false);


  // external state
  const isMobile = useIsMobile();
  const contentScaling = useUIContentScaling();
  const diffs = useWordsDifference(text2 || '', text1 || '', true);

  // memos
  const handleSwap = React.useCallback(() => {
    setIsSwapping(true);
    setTimeout(() => {
      const temp = text1;
      setText1(text2);
      setText2(temp);
      setIsSwapping(false);
    }, 200); // sync this with the transition duration
  }, [text1, text2]);

  const scaledTypographySx: SxProps = React.useMemo(() => ({
    fontSize: themeScalingMap[contentScaling]?.blockFontSize ?? undefined,
    lineHeight: themeScalingMap[contentScaling]?.blockLineHeight ?? 1.75,
  }), [contentScaling]);


  const c1 = text1?.length || 0;
  const c2 = text2?.length || 0;
  const w1 = countWords(text1);
  const w2 = countWords(text2);


  return (
    <AppSmallContainer
      title={isMobile ? 'Text Diff' : 'Text Comparison'}
      description='Compare two versions of text to highlight changes and differences.'
    >

      <Box sx={{ display: 'flex', flexDirection: 'column', gap: 2 }}>

        {/* Grid with the 2 input boxes */}
        <Box sx={{
          display: 'grid',
          gridTemplateColumns: { xs: '1fr', md: '1fr auto 1fr' },
          gap: 2,
          alignItems: 'center',
          justifyContent: 'center',
        }}>

          <FormControl sx={{ alignSelf: 'flex-start' }}>
            <Box sx={{ display: 'flex', flexWrap: 'wrap', justifyContent: 'space-between', alignItems: 'center', gap: 1, mb: 1 }}>
              <FormLabelStart title='Original' />
              <ButtonAttachFilesMemo noToolTip onAttachFiles={(files: FileWithHandle[]) => files[0]?.text().then((text) => setText1(text))} />
            </Box>
            <Textarea
              variant='outlined'
              color={text1 ? undefined : 'warning'}
              minRows={5}
              maxRows={isMobile ? 8 : 10}
              placeholder='Paste or type your original text here...'
              autoFocus
              value={text1}
              onChange={(e) => setText1(e.target.value)}
              endDecorator={
                <Box sx={{
                  backgroundColor: 'background.surface', px: 0.5, py: 0.25, borderRadius: 'xs',
                  width: '100%', lineHeight: 'lg', fontSize: 'xs',
                  display: 'flex', flexFlow: 'row wrap', gap: 1, justifyContent: 'space-between',
                }}>
                  {!w1 ? <div>No words</div> : <div>Word count: <b>{w1}</b></div>}
                  {!c1 ? <div>No characters</div> : <div>Character Count: <b>{c1}</b></div>}
                </Box>
              }
              sx={{
                transition: 'transform 0.2s ease-in-out',
                transform: isSwapping ? 'scale(0.97) translateX(5%)' : 'scale(1)',
                '&:focus-within': { backgroundColor: 'background.popup' },
                ...scaledTypographySx,
              }}
            />
          </FormControl>

          <Tooltip title='Swap texts' disableInteractive>
            <IconButton
              variant='soft'
              onClick={handleSwap}
              sx={{
                my: { xs: 1, md: 0 },
                transition: isSwapping ? 'transform 0.2s ease-in-out' : undefined,
                transform: isSwapping ? 'rotate(180deg)' : 'rotate(0)',
              }}
            >
              <SwapHorizIcon />
            </IconButton>
          </Tooltip>

          <FormControl sx={{ alignSelf: 'flex-start' }}>
            <Box sx={{ display: 'flex', flexWrap: 'wrap', justifyContent: 'space-between', alignItems: 'center', gap: 1, mb: 1 }}>
              <FormLabelStart title='Modified' />
              <ButtonAttachFilesMemo noToolTip onAttachFiles={(files: FileWithHandle[]) => files[0]?.text().then((text) => setText2(text))} />
            </Box>
            <Textarea
              variant='outlined'
              color={text2 ? undefined : 'warning'}
              minRows={5}
              maxRows={isMobile ? 8 : 10}
              placeholder='Paste or type your modified text here...'
              value={text2}
              onChange={(e) => setText2(e.target.value)}
              endDecorator={
                <Box sx={{
                  backgroundColor: 'background.surface', px: 0.5, py: 0.25, borderRadius: 'xs',
                  width: '100%', lineHeight: 'lg', fontSize: 'xs',
                  display: 'flex', flexFlow: 'row wrap', gap: 1, justifyContent: 'space-between',
                }}>
                  {!w2 ? <div>No words</div> : <div>Word count: <b>{w2}</b></div>}
                  {!c2 ? <div>No characters</div> : <div>Character Count: <b>{c2}</b></div>}
                </Box>
              }
              sx={{
                transition: 'transform 0.2s ease-in-out',
                transform: isSwapping ? 'scale(0.97) translateX(-5%)' : 'scale(1)',
                '&:focus-within': { backgroundColor: 'background.popup' },
                ...scaledTypographySx,
              }}
            />
          </FormControl>

        </Box>

        {diffs?.length ? (
          <Box sx={{ display: 'flex', flexDirection: 'column', gap: 2 }}>

            <Divider sx={{ my: 2 }}>
              <Typography level='title-sm'>
                Differences
              </Typography>
            </Divider>

            <Card sx={{
              borderRadius: 'sm',
              backgroundColor: 'background.popup',
              p: 1,
            }}>
              <RenderWordsDiff
                wordsDiff={diffs}
                sx={scaledTypographySx}
              />
            </Card>

            <Typography level='body-sm'>
              <Typography color='danger'>Red</Typography>: Deleted, <Typography color='success'>Green</Typography>: Added.
            </Typography>

          </Box>
        ) : (
          <Typography level='body-sm' sx={{ my: 2 }}>
            Enter or paste your texts and the differences will be highlighted here.
          </Typography>
        )}

      </Box>
    </AppSmallContainer>
  );
}


================================================
FILE: src/apps/draw/AppDraw.tsx
================================================
import * as React from 'react';

import { useCapabilityTextToImage } from '~/modules/t2i/t2i.client';

import { OptimaToolbarIn } from '~/common/layout/optima/portals/OptimaPortalsIn';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useProcessingQueue } from '~/common/logic/ProcessingQueue';

import { DrawCreate } from './DrawCreate';
import { DrawGallery } from './DrawGallery';
import { drawCreateQueue } from './queue-draw-create';
import { useDrawSectionDropdown } from './useDrawSectionDropdown';


// export interface AppDrawIntent {
//   backTo: 'app-chat';
// }


export function AppDraw() {

  // state
  const [showHeader, setShowHeader] = React.useState(true);
  // const [_drawIntent, setDrawIntent] = React.useState<AppDrawIntent | null>(null);

  // external state
  const isMobile = useIsMobile();
  const { queueState, queueAddItem, queueCancelAll } = useProcessingQueue(drawCreateQueue);
  const { activeProviderId, mayWork, providers, setActiveProviderId } = useCapabilityTextToImage();

  // const query = useRouterQuery<Partial<AppDrawIntent>>();

  // [effect] set intent from the query parameters
  // React.useEffect(() => {
  //   if (query.backTo) {
  //     setDrawIntent({
  //       backTo: query.backTo || 'app-chat',
  //     });
  //   }
  // }, [query]);
  // const hasIntent = !!drawIntent && !!drawIntent.backTo;

  // pluggable layout
  const { drawSection, drawSectionDropdown } = useDrawSectionDropdown(queueState.items.length, queueCancelAll);

  return <>

    {/* -> Toolbar */}
    <OptimaToolbarIn>{drawSectionDropdown}</OptimaToolbarIn>

    {drawSection === 'create' ? (
      <DrawCreate
        queue={drawCreateQueue}
        isMobile={isMobile}
        showHeader={showHeader}
        onHideHeader={() => setShowHeader(false)}
        mayWork={mayWork}
        providers={providers}
        activeProviderId={activeProviderId}
        setActiveProviderId={setActiveProviderId}
      />
    ) : drawSection === 'browse' ? (
      <DrawGallery domain='draw' />
    ) : drawSection === 'media' ? (
      <DrawGallery domain='app' />
    ) : null}

  </>;
}


================================================
FILE: src/apps/draw/DrawCreate.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import type { TextToImageProvider } from '~/common/components/useCapabilities';
import { ScrollToBottom } from '~/common/scroll-to-bottom/ScrollToBottom';
import { ScrollToBottomButton } from '~/common/scroll-to-bottom/ScrollToBottomButton';

import { DesignerPrompt, PromptComposer } from './create/PromptComposer';
import { DrawCreateQueue } from './queue-draw-create';
import { DrawSectionHeading } from './create/DrawSectionHeading';
import { DrawProviderConfigure } from './create/DrawProviderConfigure';
import { ZeroDrawConfig } from './create/ZeroDrawConfig';
import { ZeroGenerations } from './create/ZeroGenerations';
import { useProcessingQueue } from '~/common/logic/ProcessingQueue';


const imagineWorkspaceSx: SxProps = {
  flexGrow: 1,
  overflowY: 'auto',

  // style
  backgroundColor: 'background.level3',
  boxShadow: 'inset 0 0 4px 0px rgba(0, 0, 0, 0.2)',

  // layout
  display: 'flex',
  flexDirection: 'column',
};

const imagineScrollContainerSx: SxProps = {
  flex: 1,
  overflowY: 'auto',
  position: 'relative',
  minHeight: 128,
};


/*async function queryActiveGenerateImageVector(singlePrompt: string, vectorSize: number = 1) {
  const imageContentFragments = await t2iGenerateImageContentFragments(null, singlePrompt, vectorSize, 'global', 'app-draw');

  for (const imageContentFragment of imageContentFragments) {
    console.log('TODO: notImplemented: imagePartDataRef: CRUD and View of blobs as ImageBlocks', imageContentFragment.part);
  }
  // TODO continue...

  return [];
}*/

/*
function TempPromptImageGen(props: { prompt: DesignerPrompt, sx?: SxProps }) {

  // NOTE: we shall consider a multidimensional shape-based design

  // derived state
  const { prompt: dp } = props;

  // external state
  const { data: imageBlocks, error, isPending } = useQuery<ImageBlock[], Error>({
    enabled: !!dp.prompt,
    queryKey: ['draw-dpid', dp.uuid],
    queryFn: () => queryActiveGenerateImageVector(dp.prompt, dp._repeatCount),
    refetchOnReconnect: false,
    refetchOnMount: false,
    staleTime: Infinity,
  });

  return <>

    {error && <InlineError error={error} />}

    {Array.from({ length: dp._repeatCount }).map((_, index) => {
      const imgUid = `gen-img-${index}`;
      const imageBlock = imageBlocks?.[index] || null;
      return imageBlock
        // ? <RenderImage key={imgUid} imageBlock={imageBlock} noTooltip />
        ? <Box sx={{


          display: 'flex', flexDirection: 'column', justifyContent: 'center', alignItems: 'center', position: 'relative',
          mx: 'auto', my: 'auto', // mt: (index > 0 || !props.isFirst) ? 1.5 : 0,
          boxShadow: 'lg',
          backgroundColor: 'neutral.solidBg',

          '& picture': { display: 'flex' },
          '& img': { maxWidth: '100%', maxHeight: '100%' },

        }}>
          <picture><img src={imageBlock.url} alt={imageBlock.alt} /></picture>
        </Box>
        : <Card key={imgUid} sx={{ mb: 'auto' }}>
          <Skeleton animation='wave' variant='rectangular' sx={{ minWidth: 128, width: '100%', aspectRatio: 1 }} />
        </Card>;
    })}

  </>;
}
*/

export function DrawCreate(props: {
  queue: DrawCreateQueue,
  isMobile: boolean,
  showHeader: boolean,
  onHideHeader: () => void,
  mayWork: boolean,
  providers: TextToImageProvider[],
  activeProviderId: string | null,
  setActiveProviderId: (providerId: (string | null)) => void,
}) {

  // state
  const [prompts, setPrompts] = React.useState<DesignerPrompt[]>([]);


  // external state
  const { queueState } = useProcessingQueue(props.queue);
  console.log('DrawCreate', { queueState });

  // handlers
  const handleStopDrawing = React.useCallback(() => {
    setPrompts([]);
  }, []);

  const { queue } = props;

  const handlePromptEnqueue = React.useCallback((designerPrompts: DesignerPrompt[]) => {
    for (const designerPrompt of designerPrompts) {
      void queue.enqueueItem(designerPrompt); // fire/forget
    }
  }, [queue]);


  return <>

    {/* The container is a '100dvh flex column' with App background (see `pageCoreSx`) */}

    {/* Embossed Imagine Workspace */}
    <Box sx={imagineWorkspaceSx}>

      {/* This box is here to let ScrollToBottomButton anchor to this (relative) insted of the scroll-dependent ScrollToBottom */}
      <Box sx={imagineScrollContainerSx}>

        {/* [overlay] Welcoming header - Closeable */}
        {props.showHeader && (
          <DrawSectionHeading
            isBeta
            title='Imagine'
            subTitle={props.mayWork ? 'Model, Prompts, Go!' : 'No AI providers configured :('}
            chipText='Multi-model, AI Text-to-Image'
            highlight={props.mayWork}
            onRemoveHeading={props.onHideHeader}
            sx={{
              position: 'absolute',
              left: 0, top: 0, right: 0,
              zIndex: 1,
              m: { xs: 1, md: 2 },
              boxShadow: 'md',
            }}
          />
        )}

        <ScrollToBottom
          bootToBottom
          stickToBottomInitial
          sx={{
            flex: 1,
            display: 'flex',
            flexDirection: 'column',
            p: { xs: 1, md: 2 },
          }}
        >

          {/* Gallery/Placeholders Grid */}
          <Box sx={{
            // my: 'auto',
            mt: 'auto',
            mx: 'auto',
            border: '1px solid purple',
            minHeight: '300px',

            // layout
            display: 'grid',
            gridTemplateColumns: props.isMobile
              ? 'repeat(auto-fit, minmax(320px, 1fr))'
              : 'repeat(auto-fit, minmax(max(min(100%, 400px), 100%/5), 1fr))',
            gap: { xs: 2, md: 2 },
          }}>

            {/*  {prompts.map((prompt, _index) => {*/}
            {/*    return (*/}
            {/*      <TempPromptImageGen*/}
            {/*        key={prompt.dpId}*/}
            {/*        prompt={prompt}*/}
            {/*        sx={{*/}
            {/*          border: DEBUG_LAYOUT ? '1px solid green' : undefined,*/}
            {/*        }}*/}
            {/*      />*/}
            {/*    );*/}


          </Box>

          <Box sx={{background:'red'}}>THIS APPLICATION IS IN DEV - NOT PROD - DO NOT USE</Box>

          {/* Fallback */}
          <ZeroGenerations />

          {/* End with this Unconfigured message */}
          {!props.mayWork && <ZeroDrawConfig />}


          {/* Visibility and actions are handled via Context */}
          <ScrollToBottomButton />

        </ScrollToBottom>

      </Box>


      {/* Prompt Composer - inside the workspace for root-scrollability */}
      <PromptComposer
        isMobile={props.isMobile}
        queueLength={prompts.length}
        onDrawingStop={handleStopDrawing}
        onPromptEnqueue={handlePromptEnqueue}
        sx={{
          flex: 0,
          backgroundColor: 'background.level2',
          borderTop: `1px solid`,
          borderTopColor: 'divider',
          p: { xs: 1, md: 2 },
        }}
      />

    </Box>

    {/* AI Service Provider Options */}
    <DrawProviderConfigure
      providers={props.providers}
      activeProviderId={props.activeProviderId}
      setActiveProviderId={props.setActiveProviderId}
      sx={{
        backgroundColor: 'background.level1',
        borderTop: `1px solid`,
        borderTopColor: 'divider',
        p: { xs: 1, md: 2 },
      }}
    />

  </>;
}



================================================
FILE: src/apps/draw/DrawGallery.tsx
================================================
import * as React from 'react';
import { Box, Table } from '@mui/joy';

import { DBlobAssetType, DBlobImageAsset, useDBAssetsByScopeAndType } from '~/common/stores/blob/dblobs-portability';

import { ZeroGallery } from './gallery/ZeroGallery';


export function DrawGallery(props: { domain: 'draw' | 'app' }) {
  const [items] = useDBAssetsByScopeAndType<DBlobImageAsset>(
    DBlobAssetType.IMAGE,
    'global',
    props.domain === 'draw' ? 'app-draw' : 'app-chat',
  );


  const boxStyles = {
    flexGrow: 1,
    overflowY: 'auto',
    p: { xs: 2, md: 6 },
  };

  const cellStyles = {
    overflowWrap: 'anywhere',
    whiteSpace: 'break-spaces',
  };

  return (
    <Box sx={boxStyles}>
      <Table borderAxis='both' size='sm' stripe='odd' variant='plain'>
        <thead>
        <tr>
          <th>Image</th>
          <th>Origin</th>
          <th>Metadata</th>
        </tr>
        </thead>
        <tbody>
        {(items || []).map(({ id, label, cache, data, origin, metadata, createdAt, updatedAt }) => (
          <tr key={id}>
            <td>
              <Box sx={cellStyles}>
                <picture style={{ display: 'flex', maxWidth: 256, maxHeight: 256 }}>
                  <img
                    src={cache.thumb256?.base64 ? `data:${cache.thumb256?.mimeType};base64,${cache.thumb256?.base64}` : `data:${data.mimeType};base64,${data.base64}`}
                    alt={label}
                    style={{
                      boxShadow: '0 0 4px 1px rgba(0, 0, 0, 0.1)',
                      maxWidth: '100%',
                      maxHeight: '100%',
                      opacity: cache.thumb256?.base64 ? 1 : 0.5,
                    }}
                  />
                </picture>
                {label}
              </Box>
            </td>
            <td>
              <Box sx={cellStyles}>{JSON.stringify(origin, null, 2)}</Box>
            </td>
            <td>
              <Box sx={cellStyles}>
                {JSON.stringify(metadata, null, 2)}
                <br />
                {createdAt ? new Date(createdAt).toLocaleString() : 'no creation'}
                <br />
                {updatedAt && updatedAt !== createdAt ? new Date(updatedAt).toLocaleString() : null}
              </Box>
            </td>
          </tr>
        ))}
        </tbody>
      </Table>
      {(!items || items.length === 0) && <ZeroGallery domain={props.domain} />}
    </Box>
  );
}


================================================
FILE: src/apps/draw/queue-draw-create.tsx
================================================
import { ItemAsyncWorker, ProcessingQueue } from '~/common/logic/ProcessingQueue';

import type { DesignerPrompt } from './create/PromptComposer';
import { t2iGenerateImageContentFragments } from '~/modules/t2i/t2i.client';

/**
 * This function needs to create a new image (saved as an DBlob asset) based on the inputs.
 */
const drawCreateWorker: ItemAsyncWorker<DesignerPrompt> = async (item, _update, signal) => {
  await t2iGenerateImageContentFragments(null, item.prompt, [], item._repeatCount, 'app-draw').catch(console.error);
  return item;
};

export class DrawCreateQueue extends ProcessingQueue<DesignerPrompt> {
  constructor() {
    super(4, 10, drawCreateWorker);
  }
}

/**
 * The single drawing queue for the draw app: keeps running background jobs until done or canceled
 */
export const drawCreateQueue = new DrawCreateQueue();



================================================
FILE: src/apps/draw/useDrawSectionDropdown.tsx
================================================
import * as React from 'react';

import { Box, Button } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';

import { BigAgiSquircleIcon } from '~/common/components/icons/big-agi/BigAgiSquircleIcon';
import { OptimaBarDropdownMemo, OptimaDropdownItems } from '~/common/layout/optima/bar/OptimaBarDropdown';
import { Link } from '~/common/components/Link';
import { ROUTE_INDEX } from '~/common/app.routes';


export type DrawSection = 'create' | 'browse' | 'media';

const drawDropdownItems: OptimaDropdownItems = {
  create: {
    title: 'Create Images',
  },
  browse: {
    title: 'View Gallery',
  },
  media: {
    title: 'App Media',
  },
};


function DrawSectionDropdown(props: {
  drawSection: DrawSection | null,
  setDrawSection: (drawSection: DrawSection | null) => void,
}) {

  const { setDrawSection } = props;

  const handleSystemPurposeChange = React.useCallback((value: string | null) => {
    setDrawSection(value as (DrawSection | null));
  }, [setDrawSection]);

  return (
    <OptimaBarDropdownMemo
      items={drawDropdownItems}
      value={props.drawSection}
      onChange={handleSystemPurposeChange}
    />
  );

}

export function useDrawSectionDropdown(remainingJobs: number, cancelAllJobs: () => void) {
  // state
  const [drawSection, setDrawSection] = React.useState<DrawSection | null>('create');

  const drawSectionDropdown = React.useMemo(() => (
    <Box sx={{
      display: 'flex',
      alignItems: 'center',
      gap: 1,
    }}>
      <Link href={ROUTE_INDEX}>
        <BigAgiSquircleIcon inverted sx={{ width: 32, height: 32, color: 'white' }} />
      </Link>

      <DrawSectionDropdown
        drawSection={drawSection}
        setDrawSection={setDrawSection}
      />

      {/* Button to cancel pending Jobs from the UI (running and queued) */}
      {!!remainingJobs && (
        <Box sx={{ display: 'flex', gap: 1, alignItems: 'center' }}>
          <Button size='sm' color='danger' variant='soft' onClick={cancelAllJobs} sx={{ my: 0 }}>
            {remainingJobs} · <CloseRoundedIcon />
          </Button>
        </Box>
      )}

    </Box>
  ), [cancelAllJobs, drawSection, remainingJobs]);

  return { drawSection, drawSectionDropdown };
}



================================================
FILE: src/apps/draw/create/ButtonPromptFromIdea.tsx
================================================
import * as React from 'react';

import { Button, ButtonGroup, IconButton, Tooltip } from '@mui/joy';
import ArrowForwardRoundedIcon from '@mui/icons-material/ArrowForwardRounded';
import LightbulbOutlinedIcon from '@mui/icons-material/LightbulbOutlined';

// const desktopButtonLegend =
//   <Box sx={{ px: 1, py: 0.75, lineHeight: '1.5rem' }}>
//     <b>From Idea</b><br />
//     From Idea
//   </Box>;


export function ButtonPromptFromIdea(props: {
  isMobile?: boolean,
  disabled: boolean,
  onIdeaNext: () => void,
  onIdeaUse: () => void,
}) {

  const { onIdeaNext, onIdeaUse } = props;

  const handleIdeaNext = React.useCallback((event: React.MouseEvent) => {
    event.preventDefault();
    event.stopPropagation();
    onIdeaNext();
  }, [onIdeaNext]);

  return props.isMobile ? null : (
    <ButtonGroup
      variant='outlined' color='neutral'
      disabled={props.disabled}
      sx={{
        // '--ButtonGroup-separatorSize': 0,
        minWidth: 160,
      }}
    >
      <Tooltip disableInteractive title='New Idea'>
        <Button
          fullWidth onClick={handleIdeaNext}
          startDecorator={<LightbulbOutlinedIcon />}
          sx={{
            // '--Button-gap': 'auto',
            // minWidth: 100,
            justifyContent: 'flex-start',
            transition: 'background-color 0.2s, color 0.2s',
          }}>
          Idea
        </Button>
      </Tooltip>
      <Tooltip disableInteractive title='Use Idea'>
        <IconButton size='sm' onClick={onIdeaUse}>
          <ArrowForwardRoundedIcon />
        </IconButton>
      </Tooltip>
    </ButtonGroup>
  );
}


================================================
FILE: src/apps/draw/create/ButtonPromptFromX.tsx
================================================
import * as React from 'react';

import { Button } from '@mui/joy';
import InsertPhotoOutlinedIcon from '@mui/icons-material/InsertPhotoOutlined';
import ChatOutlinedIcon from '@mui/icons-material/ChatOutlined';

export function ButtonPromptFromX(props: { isMobile?: boolean, name: string, disabled?: boolean }) {
  return props.isMobile ? null : (
    <Button
      disabled={props.disabled}
      fullWidth variant='soft' color='neutral'
      startDecorator={props.name === 'Chats' ? <ChatOutlinedIcon /> : <InsertPhotoOutlinedIcon />}
      sx={{
        justifyContent: 'flex-start',
        transition: 'background-color 0.2s, color 0.2s',
        minWidth: 160,
      }}>
      {props.name}
    </Button>
  );
}


================================================
FILE: src/apps/draw/create/DrawProviderConfigure.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, Card, CardContent } from '@mui/joy';
import ConstructionIcon from '@mui/icons-material/Construction';

import { DallESettings } from '~/modules/t2i/dalle/DallESettings';

import type { TextToImageProvider } from '~/common/components/useCapabilities';
import { ExpanderControlledBox } from '~/common/components/ExpanderControlledBox';

import { DrawProviderSelector } from './DrawProviderSelector';


export function DrawProviderConfigure(props: {
  providers: TextToImageProvider[],
  activeProviderId: string | null,
  setActiveProviderId: (providerId: (string | null)) => void,
  sx?: SxProps,
}) {

  // state
  const [_open, setOpen] = React.useState(false);


  // derived state

  const { activeProviderId, providers } = props;

  const { ProviderConfig } = React.useMemo(() => {
    const provider = providers.find(provider => provider.providerId === activeProviderId);
    const ProviderConfig: React.FC | null = provider?.vendor === 'openai' ? DallESettings : null;
    return {
      ProviderConfig,
    };
  }, [activeProviderId, providers]);

  const open = _open && !!ProviderConfig;


  const handleToggleOpen = React.useCallback(() => {
    setOpen(on => !on);
  }, []);


  return (

    <Box
      sx={{
        flex: 0,
        display: 'grid',
        ...props.sx,
      }}
    >

      {/* Service-Specific Configuration */}
      <ExpanderControlledBox expanded={open}>
        {!!ProviderConfig && (
          <Card variant='outlined' sx={{ mb: 1, borderTopColor: 'primary.softActiveBg' }}>
            <CardContent sx={{ gap: 1.5 /* keep in sync with SettingsModal > AccordionDetails > Box */ }}>
              <ProviderConfig />
            </CardContent>
          </Card>
        )}
      </ExpanderControlledBox>

      {/* Service / Options Button */}
      <Box sx={{ display: 'flex', flexFlow: 'row wrap', gap: 1 }}>

        <DrawProviderSelector
          title='AI Service:'
          variant='outlined'
          providers={props.providers}
          activeProviderId={props.activeProviderId}
          setActiveProviderId={props.setActiveProviderId}
        />

        <Button
          variant={open ? 'solid' : 'outlined'}
          color={open ? 'neutral' : 'neutral'}
          endDecorator={<ConstructionIcon />}
          onClick={handleToggleOpen}
          sx={{ backgroundColor: open ? undefined : 'background.surface' }}
        >
          Options
        </Button>
      </Box>

    </Box>

  );
}


================================================
FILE: src/apps/draw/create/DrawProviderSelector.tsx
================================================
import * as React from 'react';

import type { VariantProp } from '@mui/joy/styles/types';
import { FormControl, FormLabel, ListItemDecorator, Option, Select } from '@mui/joy';
import FormatPaintTwoToneIcon from '@mui/icons-material/FormatPaintTwoTone';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';

import type { TextToImageProvider } from '~/common/components/useCapabilities';
import { OpenAIIcon } from '~/common/components/icons/vendors/OpenAIIcon';
import { hideOnMobile } from '~/common/app.theme';
import { optimaSelectSlotProps } from '~/common/layout/optima/bar/OptimaBarDropdown';


export function DrawProviderSelector(props: {
  title?: string,
  variant: VariantProp,
  providers: TextToImageProvider[],
  activeProviderId: string | null,
  setActiveProviderId: (providerId: (string | null)) => void
}) {

  // create the options
  const providerOptions = React.useMemo(() => {
    const options: { label: string, value: string, configured: boolean, Icon?: React.FC }[] = [];
    props.providers.forEach(provider => {
      options.push({
        label: provider.label + (provider.painter !== provider.label ? ` ${provider.painter}` : ''),
        value: provider.providerId,
        configured: provider.configured,
        Icon: provider.vendor === 'openai' ? OpenAIIcon : FormatPaintTwoToneIcon,
      });
    });
    return options;
  }, [props.providers]);


  return (
    <FormControl orientation='horizontal' sx={{ justifyContent: 'start', alignItems: 'center' }}>

      {!!props.title && (
        <FormLabel sx={hideOnMobile}>
          {props.title}
        </FormLabel>
      )}

      <Select
        variant={props.variant}
        value={props.activeProviderId}
        onChange={(_event, value) => value && props.setActiveProviderId(value)}
        placeholder='Select a service'
        indicator={<KeyboardArrowDownIcon />}
        slotProps={{
          ...optimaSelectSlotProps,
          button: {
            sx: {
              // overwrite all properties of the button (we don't need 'agi-ellipsize', max-width, etc.)
              minWidth: '7.5rem',
            },
          },
        }}
        // startDecorator={<FormatPaintTwoToneIcon sx={{ display: { xs: 'none', sm: 'inherit' } }} />}
        // sx={{ minWidth: '12rem' /* doesn't work anymore with SlotProps */ }}
      >
        {providerOptions.map(option => (
          <Option key={option.value} value={option.value} disabled={!option.configured}>
            <ListItemDecorator>
              {!!option.Icon && <option.Icon />}
            </ListItemDecorator>
            {option.label}
            {!option.configured && ' (not configured)'}
          </Option>
        ))}
      </Select>

    </FormControl>
  );
}


================================================
FILE: src/apps/draw/create/DrawSectionHeading.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { AspectRatio, Box, Card, CardOverflow, Chip, IconButton, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import FormatPaintTwoToneIcon from '@mui/icons-material/FormatPaintTwoTone';

import { animationShadowRingLimey } from '~/common/util/animUtils';


export function DrawSectionHeading(props: {
  title: React.ReactNode;
  isBeta?: boolean,
  subTitle: React.ReactNode;
  chipText: string | string[];
  highlight?: boolean,
  onRemoveHeading?: () => void,
  sx?: SxProps,
}) {

  return (

    <Card
      size='lg'
      variant='plain'
      orientation='horizontal'
      sx={{
        '--icon-size': { xs: '80px', md: '96px' },
        display: 'flex',
        flexFlow: 'row wrap',
        alignItems: 'center',
        gap: { xs: 3, md: 3 },
        ...props.sx,
      }}
    >

      {/* Left Draw Symbol */}
      <CardOverflow variant='solid' color='primary'>
        <AspectRatio
          ratio='1'
          variant='plain'
          color='primary'
          sx={{
            width: 'var(--icon-size)',
            m: 'auto',
            bgcolor: 'background.popup',
            borderRadius: '50%',
            boxShadow: 'sm',
            pointerEvents: 'none',
            transform: 'translateX(50%)',
            animation: props.highlight ? `${animationShadowRingLimey} 5s infinite` : undefined,
          }}
        >
          <div>
            <FormatPaintTwoToneIcon sx={{ fontSize: '3rem' }} />
          </div>
        </AspectRatio>
      </CardOverflow>

      {/* Messaging */}
      <Box sx={{
        flex: 1,
        pt: 0.5,
        ml: 'calc(var(--icon-size) / 2)',
        position: 'relative',
      }}>
        <Box sx={{ display: 'flex', alignItems: 'start' }}>
          <Typography level='title-lg'>
            {props.title}
          </Typography>
          {props.isBeta && (
            <Chip variant='solid' size='sm' sx={{ ml: 1, fontSize: '' }}>
              beta
            </Chip>
          )}
        </Box>
        <Typography level='title-sm' sx={{ mt: 1 }}>
          {props.subTitle}
        </Typography>
        <Box>
          {Array.isArray(props.chipText) ? props.chipText.map((text, i) => (
            <Chip key={i} variant='outlined' size='sm' sx={{ px: 1, py: 0.5, mt: 0.5, ml: !i ? -1 : -0.5, textWrap: 'wrap' }}>
              {text}
            </Chip>
          )) : (!!props.chipText?.trim()) && (
            <Chip variant='outlined' size='sm' sx={{ px: 1, py: 0.5, mt: 0.5, ml: -1, textWrap: 'wrap' }}>
              {props.chipText}
            </Chip>
          )}
        </Box>

        {/* Close button */}
        {!!props.onRemoveHeading && (
          <IconButton
            variant='plain'
            color='neutral'
            onClick={props.onRemoveHeading}
            sx={{
              position: 'absolute',
              top: -2,
              right: -4,
              zIndex: 1,
            }}>
            <CloseRoundedIcon />
          </IconButton>
        )}
      </Box>

      {/* Section Selector*/}
      {/*{props.showSections && (*/}
      {/*  <Divider sx={{ flex: 1 }}>*/}

      {/*    <ButtonGroup*/}
      {/*      // color='primary'*/}
      {/*      size='sm'*/}
      {/*      orientation='horizontal'*/}
      {/*      sx={{*/}
      {/*        mx: 'auto',*/}
      {/*        backgroundColor: 'background.surface',*/}
      {/*        boxShadow: 'sm',*/}
      {/*        '& > button': {*/}
      {/*          minWidth: 104,*/}
      {/*        },*/}
      {/*      }}*/}
      {/*    >*/}
      {/*      <Button*/}
      {/*        variant={props.section === 0 ? 'solid' : 'plain'}*/}
      {/*        onClick={() => props.setSection(0)}*/}
      {/*      >*/}
      {/*        Generate*/}
      {/*      </Button>*/}
      {/*      <Button*/}
      {/*        disabled*/}
      {/*        variant={props.section === 1 ? 'solid' : 'plain'}*/}
      {/*        onClick={() => props.setSection(1)}*/}
      {/*      >*/}
      {/*        Refine*/}
      {/*      </Button>*/}
      {/*      /!*<Button*!/*/}
      {/*      /!*  disabled*!/*/}
      {/*      /!*  variant={props.section === 2 ? 'solid' : 'plain'}*!/*/}
      {/*      /!*  onClick={() => props.setSection(1)}*!/*/}
      {/*      /!*>*!/*/}
      {/*      /!*  Gallery*!/*/}
      {/*      /!*</Button>*!/*/}
      {/*    </ButtonGroup>*/}

      {/*  </Divider>*/}
      {/*)}*/}

    </Card>
  );
}


================================================
FILE: src/apps/draw/create/PromptComposer.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ButtonGroup, Dropdown, FormControl, Grid, IconButton, Menu, MenuButton, MenuItem, Textarea, Typography } from '@mui/joy';
import AddRoundedIcon from '@mui/icons-material/AddRounded';
import AutoFixHighIcon from '@mui/icons-material/AutoFixHigh';
import FormatPaintTwoToneIcon from '@mui/icons-material/FormatPaintTwoTone';
import KeyboardArrowLeftIcon from '@mui/icons-material/KeyboardArrowLeft';
import KeyboardArrowRightIcon from '@mui/icons-material/KeyboardArrowRight';
import MoreTimeIcon from '@mui/icons-material/MoreTime';
import NumbersRoundedIcon from '@mui/icons-material/NumbersRounded';
import RemoveIcon from '@mui/icons-material/Remove';
import StopOutlinedIcon from '@mui/icons-material/StopOutlined';

import { imaginePromptFromTextOrThrow } from '~/modules/aifn/imagine/imaginePromptFromText';

import { agiUuid } from '~/common/util/idUtils';
import { animationEnterBelow } from '~/common/util/animUtils';
import { lineHeightTextareaMd } from '~/common/app.theme';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { ButtonPromptFromIdea } from './ButtonPromptFromIdea';
import { useDrawIdeas } from './useDrawIdeas';


const promptButtonClass = 'PromptDesigner-button';


export interface DesignerPrompt {
  dpId: string,
  prompt: string,
  _repeatCount: number,
  // tags: string[],
  // effects: string[],
  // style: string[],
  // detail: string[],
  // restyle: string[],
  // [key: string]: string[],
}


export function PromptComposer(props: {
  isMobile: boolean,
  queueLength: number,
  onDrawingStop: () => void,
  onPromptEnqueue: (prompt: DesignerPrompt[]) => void,
  sx?: SxProps,
}) {

  // state
  const [nextPrompt, setNextPrompt] = React.useState<string>('');
  const [tempCount, setTempCount] = React.useState<number>(1);
  const [tempRepeat, setTempRepeat] = React.useState<number>(1);
  const [isSimpleEnhancing, setIsSimpleEnhancing] = React.useState<boolean>(false);
  const [showMobileRepeat, setShowMobileRepeat] = React.useState<boolean>(false);

  // external state
  const { currentIdea, nextRandomIdea, clearCurrentIdea } = useDrawIdeas();
  const enterIsNewline = useUIPreferencesStore(state => state.enterIsNewline);


  // derived state
  const isRepeatShown = showMobileRepeat || !props.isMobile;
  const userHasText = !!nextPrompt;
  const currentIdeaPrompt = currentIdea?.prompt || '';
  const nonEmptyPrompt = nextPrompt || currentIdeaPrompt;
  const queueLength = props.queueLength;
  const qBusy = queueLength > 0;


  // Drawing

  const { onDrawingStop, onPromptEnqueue } = props;

  const handleDrawStop = React.useCallback(() => {
    onDrawingStop();
  }, [onDrawingStop]);

  const handlePromptEnqueue = React.useCallback(() => {
    setNextPrompt('');
    clearCurrentIdea();
    if (nonEmptyPrompt?.trim()) {
      onPromptEnqueue([{
        dpId: agiUuid('draw-prompt'),
        prompt: nonEmptyPrompt,
        _repeatCount: isRepeatShown ? tempRepeat : 1,
      }]);
    }
  }, [clearCurrentIdea, isRepeatShown, nonEmptyPrompt, onPromptEnqueue, tempRepeat]);


  // Type...

  const handleTextareaTextChange = React.useCallback((e: React.ChangeEvent<HTMLTextAreaElement>) => {
    setNextPrompt(e.target.value);
    // setUserHasChanged(true);
  }, []);

  const handleTextareaKeyDown = React.useCallback((e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    // Check for the primary Draw key
    if (e.key !== 'Enter')
      return;

    // Shift: toggles the 'enter is newline'
    if (enterIsNewline ? e.shiftKey : !e.shiftKey) {
      if (userHasText)
        handlePromptEnqueue();
      return e.preventDefault();
    }
  }, [enterIsNewline, handlePromptEnqueue, userHasText]);


  // Ideas
  const handleIdeaUse = React.useCallback(() => {
    currentIdeaPrompt && setNextPrompt(currentIdeaPrompt);
  }, [currentIdeaPrompt]);

  // PromptFx
  const handleSimpleEnhance = React.useCallback(async () => {
    if (nonEmptyPrompt?.trim()) {
      setIsSimpleEnhancing(true);
      const improvedPrompt = await imaginePromptFromTextOrThrow(nonEmptyPrompt, 'DEV')
        .catch(console.error);
      if (improvedPrompt)
        setNextPrompt(improvedPrompt);
      setIsSimpleEnhancing(false);
    }
  }, [nonEmptyPrompt]);

  const textEnrichComponents = React.useMemo(() => (
    <Box sx={{
      flex: 1,
      margin: 1,
      marginTop: 0,

      // layout
      display: 'flex', flexFlow: 'row wrap', alignItems: 'center', gap: 1,

      // Buttons (tagged by class)
      [`& .${promptButtonClass}`]: {
        '--Button-gap': '1.2rem',
        transition: 'background-color 0.2s, color 0.2s',
        minWidth: 100,
      },
    }}>

      {/* Change / Use idea */}
      {/*{props.isMobile && (*/}
      {/*  <ButtonGroup variant='soft' color='neutral' sx={{ borderRadius: 'sm' }}>*/}
      {/*    <Button className={promptButtonClass} disabled={userHasText} onClick={handleIdeaNext}>*/}
      {/*      Idea*/}
      {/*    </Button>*/}
      {/*    <Tooltip disableInteractive title='Use Idea'>*/}
      {/*      <IconButton onClick={handleIdeaUse}>*/}
      {/*        <ArrowDownwardIcon />*/}
      {/*      </IconButton>*/}
      {/*    </Tooltip>*/}
      {/*  </ButtonGroup>*/}
      {/*)}*/}

      {/* PromptFx */}
      <Button
        variant={isSimpleEnhancing ? 'solid' : 'soft'}
        color='primary'
        disabled={!userHasText}
        loading={isSimpleEnhancing}
        className={promptButtonClass}
        endDecorator={<AutoFixHighIcon sx={{ fontSize: '20px' }} />}
        onClick={handleSimpleEnhance}
        sx={{
          boxShadow: (!userHasText || isSimpleEnhancing) ? undefined : '0 6px 6px -6px rgb(var(--joy-palette-primary-darkChannel) / 40%)',
          borderRadius: 'xs',
          // boxShadow: 'xs'
        }}
      >
        Enhance
      </Button>

      {/*<Button*/}
      {/*  variant='soft' color='success'*/}
      {/*  disabled={!userHasText}*/}
      {/*  className={promptButtonClass}*/}
      {/*  endDecorator={<AutoFixHighIcon sx={{ fontSize: '20px' }} />}*/}
      {/*  onClick={handleClickMissing}*/}
      {/*  sx={{ borderRadius: 'sm' }}*/}
      {/*>*/}
      {/*  Restyle*/}
      {/*</Button>*/}

      <ButtonGroup sx={{ ml: 'auto' }}>
        {tempCount > 1 && <IconButton onClick={() => setTempCount(count => count - 1)}>
          <RemoveIcon />
        </IconButton>}
        {tempCount > 1 && <>
          <IconButton>
            <KeyboardArrowLeftIcon />
          </IconButton>
          <Button
            sx={{
              px: 0,
              minWidth: '3rem',
              pointerEvents: 'none',
            }}>
            <Typography level='body-xs' color='danger' sx={{ fontWeight: 'lg' }}>
              {tempCount > 1 ? `1 / ${tempCount}` : '1'}
            </Typography>
          </Button>
          <IconButton>
            <KeyboardArrowRightIcon />
          </IconButton>
        </>}
        <IconButton onClick={() => setTempCount(count => count + 1)}>
          <AddRoundedIcon />
        </IconButton>
      </ButtonGroup>

      {/* Char counter */}
      {/*<Typography level='body-sm' sx={{ ml: 'auto', mr: 1 }}>*/}
      {/*  {!!nonEmptyPrompt?.length && nonEmptyPrompt.length.toLocaleString()}*/}
      {/*</Typography>*/}
    </Box>
  ), [handleSimpleEnhance, isSimpleEnhancing, tempCount, userHasText]);

  return (
    <Box aria-label='Drawing Prompt' component='section' sx={props.sx}>

      <Grid container spacing={{ xs: 1, md: 2 }}>

        {/* Prompt (Text) Box */}
        <Grid xs={12} md={9}>
          <Box sx={{
            height: '100%',
            display: 'flex',
            gap: { xs: 1, md: 2 },
          }}>

            {props.isMobile ? (
              <Box sx={{ display: 'flex', flexDirection: 'column', gap: 1 }}>

                <Dropdown>
                  <MenuButton disabled={userHasText} slots={{ root: IconButton }}>
                    <AddRoundedIcon />
                  </MenuButton>
                  <Menu placement='top'>
                    {/* Add From History? */}
                    {/*<MenuItem>*/}
                    {/*  <ButtonPromptFromPlaceholder name='History' disabled />*/}
                    {/*</MenuItem>*/}
                    <MenuItem>
                      <ButtonPromptFromIdea disabled={userHasText} onIdeaNext={nextRandomIdea} onIdeaUse={handleIdeaUse} />
                    </MenuItem>
                    {/*<MenuItem>*/}
                    {/*  <ButtonPromptFromX name='Image' disabled />*/}
                    {/*</MenuItem>*/}
                    {/*<MenuItem>*/}
                    {/*  <ButtonPromptFromPlaceholder name='Chat' disabled />*/}
                    {/*</MenuItem>*/}
                  </Menu>
                </Dropdown>

              </Box>
            ) : (
              <Box sx={{ display: 'flex', flexDirection: 'column', gap: 1 }}>

                <ButtonPromptFromIdea disabled={userHasText} onIdeaNext={nextRandomIdea} onIdeaUse={handleIdeaUse} />

                {/*<ButtonPromptFromX name='Image' disabled />*/}

                {/*<ButtonPromptFromPlaceholder name='Chats' disabled />*/}

              </Box>

            )}

            <Textarea
              variant='outlined'
              // size='sm'
              autoFocus
              minRows={props.isMobile ? 4 : 3}
              maxRows={props.isMobile ? 6 : 8}
              placeholder={currentIdeaPrompt || 'Enter your prompt here and hit "Draw".'}
              value={nextPrompt}
              onChange={handleTextareaTextChange}
              onKeyDown={handleTextareaKeyDown}
              endDecorator={textEnrichComponents}
              slotProps={{
                textarea: {
                  enterKeyHint: enterIsNewline ? 'enter' : 'send',
                  // ref: props.designerTextAreaRef,
                },
              }}
              sx={{
                flexGrow: 1,
                boxShadow: 'md',
                '&:focus-within': { backgroundColor: 'background.popup' },
                lineHeight: lineHeightTextareaMd,
              }}
            />

          </Box>
        </Grid>

        {/* [Desktop: Right, Mobile: Bottom] Buttons */}
        <Grid xs={12} md={3} sx={{
          mb: 'auto',
          display: 'flex',
          alignItems: 'flex-end', // to align the mobile number picker to the bottom
          gap: { xs: 1, md: 2 },
        }}>

          {/* Toggle the Numbers Picker */}
          {props.isMobile && (
            <IconButton
              variant='soft'
              onClick={() => setShowMobileRepeat(show => !show)}
              sx={isRepeatShown ? {
                backgroundColor: 'background.surface',
                boxShadow: '0 0 8px 0 rgb(var(--joy-palette-primary-mainChannel) / 40%)',
              } : undefined}
            >
              <NumbersRoundedIcon />
            </IconButton>
          )}

          {/* vertical: Draw Button | Number selector  */}
          <Box sx={{
            flex: 1,
            display: 'grid',
            gap: 1,
          }}>

            {/* Draw / Stop */}
            {!qBusy ? (
              <Button
                key='draw-queue'
                variant='solid' color='primary'
                endDecorator={<FormatPaintTwoToneIcon />}
                onClick={handlePromptEnqueue}
                sx={{
                  animation: `${animationEnterBelow} 0.1s ease-out`,
                  boxShadow: !props.isMobile ? `0 8px 24px -4px rgb(var(--joy-palette-primary-mainChannel) / 20%)` : 'none',
                  justifyContent: 'space-between',
                }}
              >
                Draw {tempCount > 1 ? `(${tempCount})` : ''}
              </Button>
            ) : <>
              <Button
                key='draw-terminate'
                variant='soft' color='warning'
                endDecorator={<StopOutlinedIcon sx={{ fontSize: 18 }} />}
                onClick={handleDrawStop}
                sx={{
                  // animation: `${animationEnterBelow} 0.1s ease-out`,
                  boxShadow: !props.isMobile ? `0 8px 24px -4px rgb(var(--joy-palette-warning-mainChannel) / 20%)` : 'none',
                  justifyContent: 'space-between',
                }}
              >
                Stop / CLEAR (wip)
              </Button>
              <Button
                key='draw-queuemore'
                variant='soft'
                color='primary'
                endDecorator={<MoreTimeIcon sx={{ fontSize: 18 }} />}
                onClick={handlePromptEnqueue}
                sx={{
                  animation: `${animationEnterBelow} 0.1s ease-out`,
                  boxShadow: !props.isMobile ? `0 8px 24px -4px rgb(var(--joy-palette-primary-mainChannel) / 20%)` : 'none',
                  justifyContent: 'space-between',
                }}
              >
                Enqueue
              </Button>
            </>}

            {/* Number selector */}
            {isRepeatShown && (
              <FormControl sx={{ gap: 1 }}>
                {!props.isMobile && <Typography level='body-xs'>&nbsp;Number of Images:</Typography>}
                <Box sx={{ display: 'flex', justifyContent: 'space-evenly' }}>
                  {[1, 2, 3, 4, 5].map((n) => (
                    <IconButton
                      key={n}
                      color={tempRepeat === n ? 'primary' : 'neutral'}
                      variant={tempRepeat === n ? 'soft' : 'plain'}
                      onClick={() => setTempRepeat(n)}
                      sx={{
                        backgroundColor: tempRepeat === n ? 'background.surface' : undefined,
                        borderRadius: '50%',
                        boxShadow: tempRepeat === n ? '0 0 8px 1px rgb(var(--joy-palette-primary-mainChannel) / 40%)' : 'none',
                        fontWeight: tempRepeat === n ? 'xl' : 400, /* reset, from 600 */
                        '&:hover': {
                          backgroundColor: tempRepeat === n ? 'background.popup' : 'background.surface',
                          boxShadow: '0 0 8px 1px rgb(var(--joy-palette-primary-mainChannel) / 40%)',
                        },
                      }}
                    >
                      {n}
                    </IconButton>
                  ))}
                </Box>
              </FormControl>
            )}

          </Box>

        </Grid>

      </Grid>

      {/* Modals...  */}
      {/* ... */}

    </Box>
  );
}


================================================
FILE: src/apps/draw/create/useDrawIdeas.tsx
================================================
import * as React from 'react';


interface DrawIdea {
  author: string,
  prompt: string,
  short: string,
  score: number,
}

/**
 * The following are drawing ideas, offered to people.
 * Generated with: https://github.com/enricoros/big-AGI/issues/311#issuecomment-1909473441
 */
const allIdeas: DrawIdea[] = [
  { author: 'Beatriz', prompt: 'An intricate book nook with miniature worlds nestled between classic tomes, casting a magical glow over a cozy reading corner.', short: 'Magical book nook miniature', score: 46 },
  { author: 'Charlie', prompt: 'A powerful black-and-white portrait of diverse hands united, each marked with a word of hope, capturing the essence of solidarity.', short: 'United hands with words of hope', score: 45 },
  { author: 'Disha', prompt: 'A serene garden oasis with a violin resting against an ancient tree, as if the music itself could make flowers bloom.', short: 'Garden oasis with violin', score: 43 },
  { author: 'Fatima', prompt: 'A night sky canvas with constellations drawn by the city lights below, a blend of urban design and celestial wonder.', short: 'Night sky and city light constellations', score: 46 },
  { author: 'Hana', prompt: 'A vibrant mural of the Earth, with real plants growing out of the painting, blurring the lines between art and environmental activism.', short: 'Earth mural with real plants', score: 47 },
  { author: 'Julia', prompt: 'A child\'s hand gently holding a bird, with the shadow cast forming a heart, capturing a moment of pure connection with nature.', short: 'Heart shadow with bird in hand', score: 49 },
  { author: 'Julia', prompt: 'A whimsical photo of a deck of cards mid-shuffle, with birds seemingly flying out of the fanned cards into a sunset sky.', short: 'Cards with birds in sunset', score: 48 },
  { author: 'Lina', prompt: 'A stop-motion of a pottery wheel spinning, each frame capturing a different historical era\'s pottery style coming to life.', short: 'Pottery wheel through historical eras', score: 45 },
  { author: 'Mason', prompt: 'A heartwarming snapshot of a loyal golden retriever patiently waiting at a train station, its reflection mirroring in the glossy floor, encapsulating the themes of loyalty and anticipation.', short: 'Loyal dog awaiting its owner', score: 47 },
  { author: 'Nia', prompt: 'A fairytale book with plants growing from the pages, creating a living story that captures the imagination of both young and old.', short: 'Fairytale book with living plants', score: 50 },
  { author: 'Omar', prompt: 'A building being \'drawn\' in the sky by a crane, as if architecture is being sketched in real-time.', short: 'Building \'drawn\' in the sky', score: 43 },
  { author: 'Priya', prompt: 'A photo capturing the fluid motion of a traditional dance, with colorful fabric swirling around the dancer like a living painting.', short: 'Traditional dance with colorful fabric', score: 43 },
  { author: 'Quin', prompt: 'A breathtaking summit view with a single flag planted, the colors of which morph into a vibrant time-lapse of the sky changing.', short: 'Summit view with time-lapse sky', score: 45 },
  { author: 'Quin', prompt: 'A cliffside yoga pose with the sun setting into the ocean below, embodying the perfect balance between adventure and tranquility.', short: 'Cliffside yoga at sunset', score: 48 },
  { author: 'Rosa', prompt: 'An experiment in color: vibrant chemical reactions captured in crystal-clear glassware, showcasing the beauty of science.', short: 'Colorful science reactions', score: 48 },
  { author: 'Samir', prompt: 'A stunning photo of ancient script carved into a mountain, juxtaposed with the modern skyline in the distance.', short: 'Ancient script and modern skyline', score: 48 },
  { author: 'Sofia', prompt: 'A whimsical and vibrant image of a capybara sculpted entirely from pink cotton candy, set against a minimalist backdrop with splashes of bright, contrasting colors.', short: 'Cotton candy capybara in color splashes', score: 49 },
  { author: 'Tanya', prompt: 'A mural blending street art with digital pixels, where the physical wall seems to dissolve into a virtual game world.', short: 'Street art to digital game world mural', score: 45 },
  { author: 'Tanya', prompt: 'A paintbrush touching a canvas, where each stroke animates into a scene from an indie game, illustrating the art behind the code.', short: 'Animated indie game art', score: 50 },
].sort(() => Math.random() - 0.5); // shuffle the ideas, once

function _randomDrawIdea() {
  return allIdeas[Math.floor(Math.random() * allIdeas.length)];
}


export function useDrawIdeas() {
  // state
  const [currentIdea, setCurrentIdea] = React.useState<DrawIdea | null>(null);

  const nextRandomIdea = React.useCallback(() => {
    setCurrentIdea(prevIdea => {
      let nextIdea = _randomDrawIdea();
      while (nextIdea === prevIdea)
        nextIdea = _randomDrawIdea();
      return nextIdea;
    });
  }, []);

  const clearCurrentIdea = React.useCallback(() => {
    setCurrentIdea(null);
  }, []);

  return { allIdeas, currentIdea, nextRandomIdea, clearCurrentIdea };
}


================================================
FILE: src/apps/draw/create/ZeroDrawConfig.tsx
================================================
import * as React from 'react';

import { Button, Card, CardActions, CardContent, Typography } from '@mui/joy';

import { optimaOpenPreferences } from '~/common/layout/optima/useOptima';


export function ZeroDrawConfig() {

  const handleConfigureDrawing = React.useCallback(() => {
    optimaOpenPreferences('draw');
  }, []);

  return (
    <Card variant='outlined' color='neutral' sx={{
      m: 'auto',
      boxShadow: 'sm',
      maxWidth: 'max(60%, 320px)',
    }}>
      <CardContent>
        <Typography>
          <strong>AI Text-to-Image</strong> does not seem available.<br />
          Please configure one service, such as an OpenAI LLM service.
        </Typography>
      </CardContent>
      <CardActions buttonFlex='0'>
        <Button color='danger' onClick={handleConfigureDrawing} sx={{ minWidth: '160px' }}>
          Configure
        </Button>
      </CardActions>
    </Card>
  );
}


================================================
FILE: src/apps/draw/create/ZeroGenerations.tsx
================================================
import * as React from 'react';

import { Card, Typography } from '@mui/joy';


export function ZeroGenerations() {
  return (
    <Card variant='soft' sx={{
      maxWidth: 'max(50%, 320px)',
      mx: 'auto',
      mt: 'auto',
      mb: '6rem',
      backgroundColor: 'background.surface',
      borderRadius: 'lg',
      boxShadow: 'lg',
      display: 'flex',
      flexDirection: 'column',
      gap: 1,
    }}>
      {/*<Typography level='h4'>*/}
      {/*  {Brand.Title.Base} Draw*/}
      {/*</Typography>*/}
      <Typography level='title-sm' sx={{ whiteSpace: 'balance' }}>
        Generate stunning images from text.
        Simply type in an image, drawing, or photo description, and the AI will bring your vision to life.
        {/*To get started enter your prompt and hit &quot;<b>Draw</b>&quot;.*/}
      </Typography>
    </Card>
  );
}


================================================
FILE: src/apps/draw/gallery/ZeroGallery.tsx
================================================
import * as React from 'react';

import { Card } from '@mui/joy';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUIContentScaling } from '~/common/stores/store-ui';


const zeroGalleryMd = `
### {{title}}

You haven't created any images yet. To get started:

- Use **/draw your idea** in the **Chat** application.
- Open the **Draw** application to create images from text prompts.

You can switch between **Gallery** and **App Media** in the top bar at any time.

Your past creations will appear here once you start drawing. 
`.trim();


export function ZeroGallery(props: { domain: 'draw' | 'app' }) {

  // external state
  const isMobile = useIsMobile();
  const contentScaling = useUIContentScaling();

  const text = zeroGalleryMd.replace('{{title}}', props.domain === 'draw'
    ? 'Empty Gallery'
    : 'No App Media',
  );

  return (
    <Card variant='soft' sx={{
      maxWidth: 'max(50%, 340px)',
      mx: 'auto',
      my: '2rem',
      backgroundColor: 'background.surface',
      borderRadius: 'lg',
      boxShadow: 'lg',
      display: 'flex',
      flexDirection: 'column',
      gap: 1,
    }}>
      {/*<Typography level='h4'>*/}
      {/*  {Brand.Title.Base} No Images */}
      {/*</Typography>*/}
      {/*<Typography level='title-sm' sx={{ whiteSpace: 'balance' }}>*/}
      <ScaledTextBlockRenderer text={text} contentScaling={contentScaling} textRenderVariant='markdown' />
      {/*</Typography>*/}
    </Card>
  );
}


================================================
FILE: src/apps/draw/promptfx/PromptFX.tsx
================================================
/*

THIS FILE IS A PLACEHOLDER for the DRAW App

import { DConversationId, DMessage } from '~/common/state/store-chats';
import { Sheet } from '@mui/joy';


export type PromptFXInput = {
  origin: {
    type: 'app-draw',
    singleGenRequestId: SingleGenRequest['id'],
  } | {
    type: 'chat',
    conversationId: DConversationId,
    messageId: DMessage['id'],
  },
  prompt: string,
}

interface SingleGenRequest {
  id: string,

}

interface MultiGenRequest {
  requests: SingleGenRequest[],
  requestIdx: number | null,
}


export type PromptFXOutput = {
  input: PromptFXInput,
  output: {
    promptMatrix: MultiGenRequest,
  }
}

interface IPromptFX {

  onCancel: () => void,
  onDone: (output: PromptFXOutput) => void,

}

function PromptFX(props: {}) {

  return <>

    <Sheet>
      a
    </Sheet>

  </>;
}


const usePromptFX = (input: PromptFXInput) => {



  return {
    test: 3,
    PromptFX,
  };
};
*/


================================================
FILE: src/apps/link-chat/AppLinkChat.tsx
================================================
import * as React from 'react';
import Head from 'next/head';
import { useQuery } from '@tanstack/react-query';

import { Box, Button, Card, CardContent, Divider, Input, Typography } from '@mui/joy';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { forgetChatLinkItem, useSharedChatLinkItems } from '~/modules/trade/link/store-share-link';

import { Brand } from '~/common/app.config';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { DataAtRestV1 } from '~/common/stores/chat/chats.converters';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { InlineError } from '~/common/components/InlineError';
import { LogoProgress } from '~/common/components/LogoProgress';
import { OptimaDrawerIn, OptimaPanelIn } from '~/common/layout/optima/portals/OptimaPortalsIn';
import { addSnackbar } from '~/common/components/snackbar/useSnackbarsStore';
import { apiAsyncNode } from '~/common/util/trpc.client';
import { capitalizeFirstLetter } from '~/common/util/textUtils';
import { conversationTitle } from '~/common/stores/chat/chat.conversation';
import { navigateToChatLinkList } from '~/common/app.routes';
import { themeBgAppDarker } from '~/common/app.theme';

import { LinkChatAppMenuItems } from './LinkChatAppMenuItems';
import { LinkChatDrawer } from './LinkChatDrawer';
import { LinkChatViewer } from './LinkChatViewer';


const SPECIAL_LIST_PAGE_ID = 'list';


const Centerer = (props: { backgroundColor: string, children?: React.ReactNode }) =>
  <Box sx={{
    backgroundColor: props.backgroundColor,
    display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center',
    flexGrow: 1,
  }}>
    {props.children}
  </Box>;

const ListPlaceholder = (props: { hasLinks: boolean }) =>
  <Box sx={{ p: { xs: 3, md: 6 } }}>
    <Card>
      <CardContent>
        <Typography level='title-md'>
          Shared Conversations
        </Typography>
        <Typography level='body-sm'>
          {props.hasLinks
            ? 'Here you can see formely exported shared conversations. Please select a conversation from the drawer.'
            : 'No shared conversations found. Please export a conversation from this browser first.'}
        </Typography>
      </CardContent>
    </Card>
  </Box>;


const ShowLoading = () =>
  <Centerer backgroundColor={themeBgAppDarker}>
    <LogoProgress showProgress={true} />
    <Typography level='title-sm' sx={{ mt: 2 }}>
      Loading Chat...
    </Typography>
  </Centerer>;

const ShowError = (props: { error: any }) =>
  <Centerer backgroundColor={themeBgAppDarker}>
    <InlineError error={props.error} severity='warning' />
  </Centerer>;


/**
 * Fetches the object using tRPC
 * Note: we don't have react-query for the Node functions, so we use the immediate API here,
 *       and wrap it in a react-query hook
 */
async function fetchStoredChatV1(objectId: string | null) {
  if (!objectId)
    throw new Error('No Stored Chat');

  // fetch
  const result = await apiAsyncNode.trade.storageGet.query({ objectId });
  if (result.type === 'error')
    throw result.error;

  // validate a CHAT_V1
  const { dataType, dataObject, storedAt, expiresAt } = result;
  if (dataType !== 'CHAT_V1')
    throw new Error('Unsupported data type: ' + dataType);

  // convert to DConversation
  const restored = DataAtRestV1.recreateConversation(dataObject as any);
  if (!restored)
    throw new Error('Could not restore conversation');

  return { conversation: restored, storedAt, expiresAt };
}


export function AppLinkChat(props: { chatLinkId: string | null }) {

  // state
  const [deleteConfirmId, setDeleteConfirmId] = React.useState<string | null>(null);
  const [deleteConfirmKey, setDeleteConfirmKey] = React.useState<string | null>(null);

  // derived state 1
  const isListPage = props.chatLinkId === SPECIAL_LIST_PAGE_ID;
  const linkId = isListPage ? null : props.chatLinkId;

  // external state
  const sharedChatLinkItems = useSharedChatLinkItems();
  const { data, isError, error, isPending } = useQuery({
    enabled: !!linkId,
    queryKey: ['chat-link', linkId],
    queryFn: () => fetchStoredChatV1(linkId),
    staleTime: 1000 * 60 * 60 * 24, // 24 hours
  });

  // derived state 2
  const hasLinks = sharedChatLinkItems.length > 0;
  const pageTitle = (data?.conversation && conversationTitle(data.conversation)) || 'Shared Chat'; // also the (nav) App title


  const handleDelete = React.useCallback(async (objectId: string, deletionKey: string) => {
    setDeleteConfirmId(null);
    setDeleteConfirmKey(null);

    // delete from storage
    let err: string | null = null;
    try {
      const response = await apiAsyncNode.trade.storageDelete.mutate({ objectId, deletionKey });
      if (response.type === 'error')
        err = response.error || 'unknown error';
    } catch (error: any) {
      err = error?.message ?? error?.toString() ?? 'unknown error';
    }

    // delete from local store
    if (!err)
      forgetChatLinkItem(objectId);

    // UI feedback
    addSnackbar({
      key: err ? 'chatlink-deletion-issue' : 'chatlink-deletion-success',
      type: err ? 'issue' : 'success',
      message: err ? 'Could not delete link: ' + err : 'Link deleted successfully',
    });

    // move to the list page
    if (!err)
      void navigateToChatLinkList();
  }, []);


  // Delete: ID confirmation

  const handleConfirmDeletion = React.useCallback((linkId: string) => linkId && setDeleteConfirmId(linkId), []);

  const handleCancelDeletion = React.useCallback(() => setDeleteConfirmId(null), []);

  // Delete: Key confirmation

  const handleConfirmDeletionKey = React.useCallback(() => {
    if (!deleteConfirmId) return;

    // if we already have the key, we can delete right away
    const item = sharedChatLinkItems.find(i => i.objectId === deleteConfirmId);
    let deletionKey = (item && item.deletionKey) ? item.deletionKey : null;
    if (deletionKey)
      return handleDelete(deleteConfirmId, deletionKey);

    // otherwise ask for the key
    setDeleteConfirmKey('');
  }, [deleteConfirmId, handleDelete, sharedChatLinkItems]);

  const handleCancelDeletionKey = React.useCallback(() => {
    setDeleteConfirmId(null);
    setDeleteConfirmKey(null);
  }, []);

  const handleDeletionKeyConfirmed = React.useCallback(() => {
    deleteConfirmId && deleteConfirmKey && handleDelete(deleteConfirmId, deleteConfirmKey);
  }, [deleteConfirmId, deleteConfirmKey, handleDelete]);


  return <>

    <Head>
      <title>{capitalizeFirstLetter(pageTitle)} · {Brand.Title.Base} 🚀</title>
    </Head>

    {/* -> Drawer */}
    <OptimaDrawerIn>
      <LinkChatDrawer
        activeLinkId={linkId}
        sharedChatLinkItems={sharedChatLinkItems}
        onDeleteLink={handleConfirmDeletion}
      />
    </OptimaDrawerIn>

    {/* -> Panel */}
    <OptimaPanelIn>
      <LinkChatAppMenuItems
        activeLinkId={linkId}
        onDeleteLink={handleConfirmDeletion}
      />
    </OptimaPanelIn>


    {isListPage
      ? <ListPlaceholder hasLinks={hasLinks} />
      : isPending
        ? <ShowLoading />
        : isError
          ? <ShowError error={error} />
          : !!data?.conversation
            ? <LinkChatViewer conversation={data.conversation} storedAt={data.storedAt} expiresAt={data.expiresAt} />
            : <Centerer backgroundColor={themeBgAppDarker} />}


    {/* Delete confirmation */}
    {!!deleteConfirmId && (deleteConfirmKey === null) && (
      <ConfirmationModal
        onClose={handleCancelDeletion} onPositive={handleConfirmDeletionKey}
        confirmationText='Are you sure you want to delete this link?'
        positiveActionText={'Yes, Delete'}
      />
    )}

    {/* Deletion Key Input */}
    {!!deleteConfirmId && (deleteConfirmKey !== null) && (
      <GoodModal
        open title='Enter Deletion Key'
        titleStartDecorator={<WarningRoundedIcon sx={{ color: 'danger.solidBg' }} />}
        onClose={handleCancelDeletionKey}
        hideBottomClose
      >
        <Divider />
        <Typography level='body-md'>
          You need to enter the original deletion key to delete this conversation.
        </Typography>
        <Input
          value={deleteConfirmKey}
          onChange={event => setDeleteConfirmKey(event.target.value)}
          sx={{ flexGrow: 1 }}
        />
        <Box sx={{ display: 'flex', gap: 1, justifyContent: 'flex-end', mt: 2 }}>
          <Button autoFocus variant='plain' color='neutral' onClick={handleCancelDeletionKey}>
            Cancel
          </Button>
          <Button
            variant='solid' color='danger'
            disabled={!deleteConfirmKey.trim()}
            onClick={handleDeletionKeyConfirmed}
            sx={{ lineHeight: '1.5em' }}
          >
            Delete
          </Button>
        </Box>
      </GoodModal>
    )}

  </>;
}


================================================
FILE: src/apps/link-chat/LinkChatAppMenuItems.tsx
================================================
import * as React from 'react';

import { ListDivider, ListItemDecorator, MenuItem, Switch, Typography } from '@mui/joy';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';

import { OptimaPanelGroupedList } from '~/common/layout/optima/panel/OptimaPanelGroupedList';

import { SettingUIComplexity } from '../settings-modal/settings-ui/SettingUIComplexity';
import { SettingUIContentScaling } from '../settings-modal/settings-ui/SettingUIContentScaling';

import { useChatShowSystemMessages } from '../chat/store-app-chat';


/**
 * Menu Items are the settings for the chat.
 */
export function LinkChatAppMenuItems(props: {
  activeLinkId: string | null,
  onDeleteLink: (linkId: string) => void,
}) {

  // external state
  const [showSystemMessages, setShowSystemMessages] = useChatShowSystemMessages();

  const handleRenderSystemMessageChange = (event: React.ChangeEvent<HTMLInputElement>) => setShowSystemMessages(event.target.checked);

  const { activeLinkId, onDeleteLink } = props;

  const handleDeleteLink = React.useCallback(() => {
    activeLinkId && onDeleteLink(activeLinkId);
  }, [activeLinkId, onDeleteLink]);


  return <OptimaPanelGroupedList title='Conversation'>

    <MenuItem onClick={() => setShowSystemMessages(!showSystemMessages)} sx={{ justifyContent: 'space-between' }}>
      <Typography>
        System message
      </Typography>
      <Switch
        checked={showSystemMessages} onChange={handleRenderSystemMessageChange}
        // endDecorator={showSystemMessages ? 'On' : 'Off'}
        slotProps={{ endDecorator: { sx: { minWidth: 26 } } }}
      />
    </MenuItem>

    <SettingUIComplexity noLabel />

    <SettingUIContentScaling noLabel />

    <ListDivider />

    <MenuItem onClick={handleDeleteLink} sx={{ justifyContent: 'space-between' }}>
      Delete
      <ListItemDecorator>
        <DeleteOutlineIcon />
      </ListItemDecorator>
    </MenuItem>

  </OptimaPanelGroupedList>;
}


================================================
FILE: src/apps/link-chat/LinkChatDrawer.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, ListDivider, ListItem, ListItemButton, ListItemDecorator, Switch, Typography } from '@mui/joy';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';

import type { SharedChatLinkItem } from '~/modules/trade/link/store-share-link';

import { Link } from '~/common/components/Link';
import { OptimaDrawerHeader } from '~/common/layout/optima/drawer/OptimaDrawerHeader';
import { OptimaDrawerList } from '~/common/layout/optima/drawer/OptimaDrawerList';
import { getChatLinkRelativePath } from '~/common/app.routes';
import { optimaCloseDrawer } from '~/common/layout/optima/useOptima';


/**
 * Drawer Items are all the links already shared, for quick access.
 * This is stores in the Trade Store (local storage).
 */
export function LinkChatDrawer(props: {
  activeLinkId: string | null,
  sharedChatLinkItems: SharedChatLinkItem[]
  onDeleteLink: (linkId: string) => void,
}) {

  // state
  const [showDeletionKeys, setShowDeletionKeys] = React.useState<boolean>(false);

  // derived state
  const { activeLinkId, onDeleteLink } = props;
  const chatLinkItems = props.sharedChatLinkItems.toSorted((a, b) => b.createdAt.localeCompare(a.createdAt));
  const hasLinks = chatLinkItems.length > 0;


  const handleDeleteLink = React.useCallback(() => {
    activeLinkId && onDeleteLink(activeLinkId);
  }, [activeLinkId, onDeleteLink]);

  const handleToggleDeletionKeys = React.useCallback(() => {
    setShowDeletionKeys(on => !on);
  }, []);


  return <>

    <OptimaDrawerHeader
      title='Your Shared Links'
      onClose={optimaCloseDrawer}
    />

    <OptimaDrawerList variant='plain' noTopPadding noBottomPadding tallRows>

      <ListItem>
        <Typography level='body-sm'>
          {hasLinks ? 'Links shared by you' : 'No prior shared links'}
        </Typography>
      </ListItem>

      <Box sx={{ flex: 1, overflowY: 'auto' }}>

        {hasLinks && <Box sx={{ overflowY: 'auto' }}>
          {chatLinkItems.map(item => (
            <ListItemButton
              key={'chat-link-' + item.objectId}
              variant={activeLinkId === item.objectId ? 'soft' : undefined}
              component={Link} href={getChatLinkRelativePath(item.objectId)} noLinkStyle
              sx={{
                display: 'flex', flexDirection: 'column',
                alignItems: 'flex-start',
              }}
            >
              <Box>
                <Typography level='title-sm'>
                  {item.chatTitle || 'Untitled Chat'}
                </Typography>
                {showDeletionKeys && <Typography level='body-xs'>
                  Deletion Key: {item.deletionKey}
                </Typography>}
                <Typography level='body-xs'>
                  <TimeAgo date={item.createdAt} />
                </Typography>
              </Box>
            </ListItemButton>
          ))}
        </Box>}

      </Box>

      <ListDivider sx={{ my: 0 }} />

      <ListItemButton disabled={!hasLinks || !activeLinkId} onClick={handleDeleteLink}>
        <ListItemDecorator>
          <DeleteOutlineIcon />
        </ListItemDecorator>
        Delete
      </ListItemButton>

      <ListItemButton onClick={handleToggleDeletionKeys}>
        <ListItemDecorator />
        Show Deletion Keys
        <Switch checked={showDeletionKeys} sx={{ ml: 'auto' }} />
      </ListItemButton>

    </OptimaDrawerList>

  </>;

}


================================================
FILE: src/apps/link-chat/LinkChatViewer.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, Button, Card, CardContent, List, ListItem, Tooltip, Typography } from '@mui/joy';
import TelegramIcon from '@mui/icons-material/Telegram';

import { ChatMessageMemo } from '../chat/components/message/ChatMessage';
import { useChatShowSystemMessages } from '../chat/store-app-chat';

import type { DMessageFragment, DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import type { DMessageId } from '~/common/stores/chat/chat.message';
import { Brand } from '~/common/app.config';
import { ScrollToBottom } from '~/common/scroll-to-bottom/ScrollToBottom';
import { WorkspaceIdProvider } from '~/common/stores/workspace/WorkspaceIdProvider';
import { capitalizeFirstLetter } from '~/common/util/textUtils';
import { conversationTitle, DConversation, excludeSystemMessages } from '~/common/stores/chat/chat.conversation';
import { launchAppChat } from '~/common/app.routes';
import { themeBgAppDarker } from '~/common/app.theme';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useIsMobile } from '~/common/components/useMatchMedia';


/**
 * Renders a chat link view with conversation details and messages.
 */
export function LinkChatViewer(props: { conversation: DConversation, storedAt: Date, expiresAt: Date | null }) {

  // state
  const [cloning, setCloning] = React.useState<boolean>(false);
  const listBottomRef = React.useRef<HTMLDivElement>(null);

  // external state
  const isMobile = useIsMobile();
  const [showSystemMessages] = useChatShowSystemMessages();
  const hasExistingChat = useChatStore(state => state.conversations.some(c => c.id === props.conversation.id));

  // derived state
  const messages = props.conversation.messages;
  const filteredMessages = excludeSystemMessages(messages, showSystemMessages);
  const hasMessages = filteredMessages.length > 0;

  // Effect: Scroll to bottom of list when messages change

  /*React.useEffect(() => {
    setTimeout(() => {
      if (listBottomRef.current)
        listBottomRef.current.scrollIntoView({ behavior: 'smooth' });
    }, 1000);
  }, [messages]);*/


  const handleClone = async (canOverwrite: boolean) => {
    setCloning(true);
    const importedId = useChatStore.getState().importConversation({ ...props.conversation }, !canOverwrite);
    void launchAppChat(importedId);
    setCloning(false);
  };


  return (

    <Box sx={{
      flexGrow: 1,
      backgroundColor: themeBgAppDarker,
      display: 'flex', flexFlow: 'column nowrap', minHeight: 96, alignItems: 'center',
      gap: { xs: 3, md: 5, xl: 6 },
      px: { xs: 2 },
      py: { xs: 3, md: 5, xl: 6 },
    }}>

      {/* Title Card */}
      <Card sx={{
        display: 'flex', flexDirection: 'column',
        // backgroundColor: 'background.level1',
        // borderRadius: 'xl',
        // boxShadow: 'xs',
        px: 2.5,
        maxWidth: '100%',
        // animation: `${cssMagicSwapKeyframes} 0.4s cubic-bezier(0.22, 1, 0.36, 1)`,
      }}>
        <CardContent sx={{ gap: 1 }}>
          <Typography level='h4' startDecorator={<TelegramIcon sx={{ fontSize: 'xl2' }} />}>
            {capitalizeFirstLetter(conversationTitle(props.conversation, 'Chat'))}
          </Typography>
          <Typography level='body-xs'>
            Uploaded <TimeAgo date={props.storedAt} />
            {!!props.expiresAt && <>, expires <TimeAgo date={props.expiresAt} /></>}.
          </Typography>
        </CardContent>
      </Card>

      {/* Messages */}
      <Card sx={{
        borderRadius: 'xl', boxShadow: 'md',
        maxWidth: '100%', // fixes the card growing out of bounds
        overflowY: 'hidden',
        p: 0,
      }}>

        <WorkspaceIdProvider conversationId={null}>

          <ScrollToBottom bootToBottom bootSmoothly>

            <List sx={{
              minHeight: '100%',
              p: 0,
              display: 'flex', flexDirection: 'column',
              flexGrow: 1,
            }}>

              <ListItem sx={{
                // backgroundColor: 'background.surface',
                borderBottom: '1px solid',
                borderBottomColor: 'divider',
                borderBottomStyle: 'dashed',
                // justifyContent: 'center',
                px: { xs: 2.5, md: 3.5 }, py: 2,
              }}>
                <Typography level='body-md'>
                  Welcome to the chat! 👋
                </Typography>
              </ListItem>

              {filteredMessages.map((message, idx) =>
                <ChatMessageMemo
                  key={'msg-' + message.id}
                  message={message}
                  fitScreen={isMobile}
                  isMobile={isMobile}
                  showBlocksDate={idx === 0 || idx === filteredMessages.length - 1 /* first and last message */}
                  onMessageFragmentReplace={(_messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment) => {
                    message.fragments = message.fragments.map(f => (f.fId === fragmentId) ? newFragment : f);
                  }}
                />,
              )}

              <ListItem sx={{
                px: { xs: 2.5, md: 3.5 }, py: 2,
              }}>
                <Typography level='body-sm' ref={listBottomRef}>
                  Like the chat? Import it and keep the talk going! 🚀
                </Typography>
              </ListItem>

            </List>

          </ScrollToBottom>

        </WorkspaceIdProvider>

      </Card>

      {/* Buttons */}
      <Box sx={{ display: 'flex', flexFlow: 'row wrap', alignItems: 'center', justifyContent: 'center', gap: 2 }}>
        <Button
          variant='solid' color='neutral' size='lg'
          disabled={!hasMessages || cloning} loading={cloning}
          endDecorator={<TelegramIcon />}
          onClick={() => handleClone(false)}
          sx={{
            boxShadow: 'md',
          }}
        >
          {hasExistingChat
            ? `Import as New`
            : `Import on ${Brand.Title.Base}`}
        </Button>

        {hasExistingChat && (
          <Tooltip title='This conversation is already present, enabling Overwrite'>
            <Button
              variant='soft' color='warning'
              disabled={!hasMessages || cloning} loading={cloning}
              endDecorator={<TelegramIcon />}
              onClick={() => handleClone(true)}
            >
              Import Over
            </Button>
          </Tooltip>
        )}
      </Box>

    </Box>

  );
}



================================================
FILE: src/apps/news/AppNews.tsx
================================================
import * as React from 'react';
import NextImage from 'next/image';
import TimeAgo from 'react-timeago';
import { AspectRatio, Box, Button, Card, CardContent, CardOverflow, Container, Grid, Sheet, Typography } from '@mui/joy';
import ExpandMoreIcon from '@mui/icons-material/ExpandMore';
import LaunchIcon from '@mui/icons-material/Launch';

import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';

import { Brand } from '~/common/app.config';
import { Link } from '~/common/components/Link';
import { ROUTE_INDEX } from '~/common/app.routes';
import { Release } from '~/common/app.release';
import { animationColorBlues, animationColorRainbow } from '~/common/util/animUtils';
import { capitalizeFirstLetter } from '~/common/util/textUtils';
import { useIsMobile } from '~/common/components/useMatchMedia';

import { NewsItems } from './news.data';
import { beamNewsCallout } from './beam.data';


// number of news items to show by default, before the expander
const NEWS_INITIAL_COUNT = 3;
const NEWS_LOAD_STEP = 2;


const _frontendBuild = Release.buildInfo('frontend');

export const newsRoadmapCallout =
  <Card variant='solid' invertedColors>
    <CardContent sx={{ gap: 2 }}>
      <Typography level='title-lg'>
        Open Roadmap
      </Typography>
      <Typography level='body-sm'>
        Take a peek at our roadmap to see what&apos;s in the pipeline.
        Discover upcoming features and let us know what excites you the most!
      </Typography>
      <Grid container spacing={1}>
        <Grid xs={12} sm={7}>
          <Button
            fullWidth variant='soft' color='primary' endDecorator={<LaunchIcon />}
            component={Link} href={Brand.URIs.OpenProject} noLinkStyle target='_blank'
          >
            Explore
          </Button>
        </Grid>
        <Grid xs={12} sm={5} sx={{ display: 'flex', flexAlign: 'center', justifyContent: 'center' }}>
          <Button
            fullWidth variant='plain' color='primary' endDecorator={<LaunchIcon />}
            component={Link} href={Brand.URIs.OpenRepo + '/issues/new?template=roadmap-request.md&title=%5BSuggestion%5D'} noLinkStyle target='_blank'
          >
            Suggest a Feature
          </Button>
        </Grid>
      </Grid>
    </CardContent>
  </Card>;

export function BuildInfoCard(props: { noMargin?: boolean }) {
  return (
    <Card variant='solid' color='neutral' invertedColors sx={props.noMargin ? undefined : { mb: 3 }}>
      <Typography level='title-md' sx={{ my: -1 }}>
        Development Build Information
      </Typography>
      <BuildInfoSheet />
    </Card>
  );
}

function BuildInfoSheet() {
  const backendBuild = React.useMemo(() => getBackendCapabilities().build, []);
  const frontendBuild = React.useMemo(() => Release.buildInfo('frontend'), []);
  return (
    <Sheet variant='soft' invertedColors sx={{
      fontSize: 'xs',
      // fontFamily: 'code',
      color: 'text.secondary',
      backgroundColor: 'background.popup',
      // border: '1px solid',
      // borderColor: 'divider',
      borderRadius: 'sm',
      // boxShadow: 'inset 1px 1px 4px -2px rgba(0,0,0,0.1)',
      p: 1,
      mb: -1,
      mx: -1,
    }}>
      PL: <strong>{Release.TenantSlug}</strong> · package {backendBuild?.pkgVersion} ({Release.Monotonics.NewsVersion}).<br />
      Frontend: {frontendBuild.gitSha} - deployed {frontendBuild.timestamp ? <strong><TimeAgo date={frontendBuild.timestamp} /></strong> : 'unknown'}, and
      backend {backendBuild?.gitSha}{backendBuild?.timestamp === frontendBuild.timestamp ? '.' : backendBuild?.timestamp ? <TimeAgo date={backendBuild?.timestamp!} /> : 'unknown.'}<br />
      Ships with -modal/-model: {Object.entries(Release.TechLevels).map(([name, version], idx, arr) => <React.Fragment key={name}><strong>{name}</strong> v{version}{idx < arr.length - 1 ? ', ' : ''}</React.Fragment>)}.<br />
      Ships with intelligent functions: {Release.AiFunctions.map((name, idx, arr) => <React.Fragment key={name}><i>{name}</i>{idx < arr.length - 1 ? ', ' : ''}</React.Fragment>)}.
    </Sheet>
  );
}

export function AppNews() {
  // state
  const [lastNewsIdx, setLastNewsIdx] = React.useState<number>(NEWS_INITIAL_COUNT - 1);

  // external state
  const isMobile = useIsMobile();

  // news selection
  const news = NewsItems.filter((_, idx) => idx <= lastNewsIdx);
  const firstNews = news[0] ?? null;

  // show expander
  const canExpand = news.length < NewsItems.length;

  return (

    <Box sx={{
      flexGrow: 1,
      overflowY: 'auto',
      display: 'flex', justifyContent: 'center',
      p: { xs: 3, md: 6 },
    }}>

      <Box sx={{
        my: 'auto',
        display: 'flex', flexDirection: 'column', alignItems: 'center',
      }}>

        <Typography level='h1' sx={{ fontSize: '2.9rem', mb: 4 }}>
          Welcome to {Brand.Title.Base} <Box component='span' sx={{ animation: `${animationColorBlues} 10s infinite`, zIndex: 1 /* perf-opt */ }}>{firstNews?.versionCode}</Box>!
        </Typography>

        <Typography sx={{ mb: 2 }} level='title-sm'>
          {capitalizeFirstLetter(Brand.Title.Base)} has been updated to version {firstNews?.versionCode}
        </Typography>

        <Box sx={{ mb: 5 }}>
          <Button
            variant='solid' color='primary' size='lg'
            component={Link} href={ROUTE_INDEX} noLinkStyle
            // endDecorator='✨'
            sx={{
              boxShadow: '0 8px 24px -4px rgb(var(--joy-palette-primary-mainChannel) / 20%)',
              minWidth: 180,
            }}
          >
            Continue
          </Button>
        </Box>

        {/*<Typography level='title-sm' sx={{ mb: 1, placeSelf: 'start', ml: 1 }}>*/}
        {/*  Here is what's new:*/}
        {/*</Typography>*/}

        <Container disableGutters maxWidth='sm'>
          {news?.map((ni, idx) => {
            // const firstCard = idx === 0;
            const addPadding = false; //!firstCard; // || showExpander;
            return <React.Fragment key={idx}>

              {/* Inject the Big-AGI 2.0 item here*/}
              {/*{idx === 1 && (*/}
              {/*  <Box sx={{ mb: 3 }}>*/}
              {/*    {bigAgi2NewsCallout}*/}
              {/*  </Box>*/}
              {/*)}*/}

              {/* Inject the Beam item here*/}
              {idx === 2 && (
                <Box sx={{ mb: 3 }}>
                  {beamNewsCallout}
                </Box>
              )}

              {/* News Item */}
              <Card key={'news-' + idx} sx={{ mb: 3, minHeight: 32, gap: 1 }}>
                <CardContent sx={{ position: 'relative', pr: addPadding ? 4 : 0 }}>
                  <Box sx={{ display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
                    <Typography level='title-sm' component='div'>
                      {ni.text ? ni.text : ni.versionName ? <><b>{ni.versionCode}</b> · </> : `Version ${ni.versionCode}:`}
                      <Box
                        component='span'
                        sx={idx ? {} : {
                          animation: `${animationColorRainbow} 5s infinite`,
                          fontWeight: 'lg',
                          zIndex: 1, /* perf-opt */
                        }}
                      >
                        {ni.versionName}
                      </Box>
                    </Typography>
                    <Typography level='body-sm' sx={{ ml: 'auto' }}>
                      {idx === 0 && _frontendBuild.timestamp
                        ? <TimeAgo date={_frontendBuild.timestamp} />
                        : !!ni.versionDate && <TimeAgo date={ni.versionDate} />}
                    </Typography>
                  </Box>

                  {!!ni.items && (ni.items.length > 0) && (
                    <ul style={{ marginTop: 8, marginBottom: 8, paddingInlineStart: '1.5rem', listStyleType: '"-  "' }}>
                      {ni.items.filter(item => item.dev !== true).map((item, idx) => (
                        <li key={idx} style={{ listStyle: (item.icon || item.noBullet) ? '" "' : '"-  "', marginLeft: item.icon ? '-1.125rem' : undefined }}>
                          <Typography component='div' sx={{ fontSize: 'sm' }}>
                            {item.icon && <item.icon sx={{ fontSize: 'xs', mr: 0.75 }} />}
                            {item.text}
                          </Typography>
                        </li>
                      ))}
                    </ul>
                  )}

                  {/*{idx === 0 && <BuildInfoSheet />}*/}

                </CardContent>

                {!!ni.versionCoverImage && (
                  <CardOverflow sx={{
                    m: '0 calc(var(--CardOverflow-offset) - 1px) calc(var(--CardOverflow-offset) - 1px)',
                  }}>
                    <AspectRatio ratio='2'>
                      <NextImage
                        src={ni.versionCoverImage}
                        alt={`Cover image for ${ni.versionCode}`}
                        // commented: we scale the images to 600px wide (>300 px tall)
                        // sizes='(max-width: 1200px) 100vw, 50vw'
                        priority={idx === 0}
                        quality={90}
                      />
                    </AspectRatio>
                  </CardOverflow>
                )}

              </Card>

              {/* Inject the roadmap item here*/}
              {idx === 3 && (
                <Box sx={{ mb: 3 }}>
                  {newsRoadmapCallout}
                </Box>
              )}

            </React.Fragment>;
          })}

          {/* Inject the Build Info Sheet */}
          {!isMobile && <BuildInfoCard />}

          {canExpand && (
            <Button
              fullWidth
              variant='soft'
              color='neutral'
              onClick={() => setLastNewsIdx(index => index + NEWS_LOAD_STEP)}
              endDecorator={<ExpandMoreIcon />}
            >
              Previous News
            </Button>
          )}

        </Container>

        {/*<Typography sx={{ textAlign: 'center' }}>*/}
        {/*  Enjoy!*/}
        {/*  <br /><br />*/}
        {/*  -- The {Brand.Title.Base} Team*/}
        {/*</Typography>*/}

      </Box>

    </Box>
  );
}


================================================
FILE: src/apps/news/beam.data.tsx
================================================
import * as React from 'react';

import { Button, Card, CardContent, Grid, Typography } from '@mui/joy';
import LaunchIcon from '@mui/icons-material/Launch';

import { Link } from '~/common/components/Link';


// export const beamReleaseDate = '2024-04-01T22:00:00Z';
export const beamBlogUrl = 'https://big-agi.com/blog/beam-multi-model-ai-reasoning/';

export const beamNewsCallout =
  <Card variant='solid' invertedColors>
    <CardContent sx={{ gap: 2 }}>
      <Typography level='title-lg'>
        Beam - launched in 1.15
      </Typography>
      <Typography level='body-sm'>
        Beam is a world-first, multi-model AI chat modality that accelerates the discovery of superior solutions by leveraging the collective strengths of diverse LLMs.
        {/*Beam is a world-first, multi-model AI chat modality. By combining the strenghts of diverse LLMs, Beam allows you to find better answers, faster.*/}
      </Typography>
      <Grid container spacing={1}>
        <Grid xs={12} sm={7}>
          <Button
            fullWidth variant='soft' color='primary' endDecorator={<LaunchIcon />}
            component={Link} href={beamBlogUrl} noLinkStyle target='_blank'
          >
            Blog
          </Button>
        </Grid>
        <Grid xs={12} sm={5} sx={{ display: 'flex', flexAlign: 'center', justifyContent: 'center' }}>
          {/*<Button*/}
          {/*  fullWidth variant='outlined' color='primary' startDecorator={<ThumbUpRoundedIcon />}*/}
          {/*  // endDecorator={<LaunchIcon />}*/}
          {/*  component={Link} href={beamHNUrl} noLinkStyle target='_blank'*/}
          {/*>*/}
          {/*  on Hackernews 🙏*/}
          {/*</Button>*/}
        </Grid>
      </Grid>
    </CardContent>
  </Card>;


================================================
FILE: src/apps/news/bigAgi2.data.tsx
================================================
import * as React from 'react';

import { Button, Card, CardContent, Grid, Typography } from '@mui/joy';
import AccessTimeIcon from '@mui/icons-material/AccessTime';
import LaunchIcon from '@mui/icons-material/Launch';

import { Link } from '~/common/components/Link';


const bigAgi2SurveyUrl = 'https://y2rjg0zillz.typeform.com/to/ZSADpr5u?utm_source=gh-2&utm_medium=news&utm_campaign=ea2';

export const bigAgi2NewsCallout =
  <Card variant='solid' invertedColors>
    <CardContent sx={{ gap: 2 }}>
      <Typography level='title-lg'>
        Big-AGI 2.0 - In Development
      </Typography>
      <Typography level='body-sm'>
        We&apos;re building the next version of Big-AGI with your needs in mind. New features, better performance, enhanced AI interactions. Help us shape it.
      </Typography>
      <Grid container spacing={1}>
        <Grid xs={12} sm={7}>
          <Button
            fullWidth variant='soft' color='primary' endDecorator={<LaunchIcon />}
            component={Link} href={bigAgi2SurveyUrl} noLinkStyle target='_blank'
          >
            Apply for Early Access
          </Button>
        </Grid>
        <Grid xs={12} sm={5} sx={{ display: 'flex', flexAlign: 'center', justifyContent: 'center' }}>
          <Button
            fullWidth variant='outlined' color='primary' startDecorator={<AccessTimeIcon />}
            disabled
          >
            Coming Fall 2024
          </Button>
        </Grid>
      </Grid>
    </CardContent>
  </Card>;


================================================
FILE: src/apps/news/news.data.tsx
================================================
import * as React from 'react';
import { StaticImageData } from 'next/image';

import { Box, Chip, SvgIconProps, Typography } from '@mui/joy';
import GoogleIcon from '@mui/icons-material/Google';

import { AnthropicIcon } from '~/common/components/icons/vendors/AnthropicIcon';
import { ChatBeamIcon } from '~/common/components/icons/ChatBeamIcon';
import { ExternalLink } from '~/common/components/ExternalLink';
import { GroqIcon } from '~/common/components/icons/vendors/GroqIcon';
import { LocalAIIcon } from '~/common/components/icons/vendors/LocalAIIcon';
import { MistralIcon } from '~/common/components/icons/vendors/MistralIcon';
import { PerplexityIcon } from '~/common/components/icons/vendors/PerplexityIcon';

import { Brand } from '~/common/app.config';
import { Link } from '~/common/components/Link';
import { Release } from '~/common/app.release';
import { clientUtmSource } from '~/common/util/pwaUtils';
import { platformAwareKeystrokes } from '~/common/components/KeyStroke';

import { beamBlogUrl } from './beam.data';


// Cover Images
// A landscape image of a capybara made entirely of clear, translucent crystal, wearing oversized black sunglasses, sitting at a sleek, minimalist desk. The desk is bathed in a soft, ethereal light emanating from within the capybara, symbolizing clarity and transparency. The capybara is typing on a futuristic, holographic keyboard, with floating code snippets and diagrams surrounding it, illustrating an improved developer experience and Auto-Diagrams feature. The background is a clean, white space with subtle, geometric patterns. Close-up photography style with a bokeh effect.
import coverV116 from '../../../public/images/covers/release-cover-v1.16.0.png';
// (not exactly) Imagine a futuristic, holographically bounded space. Inside this space, four capybaras stand. Three of them are in various stages of materialization, their forms made up of thousands of tiny, vibrant particles of electric blues, purples, and greens. These particles represent the merging of different intelligent inputs, symbolizing the concept of 'Beaming'. Positioned slightly towards the center and ahead of the others, the fourth capybara is fully materialized and composed of shimmering golden cotton candy, representing the optimal solution the 'Beam' feature seeks to achieve. The golden capybara gazes forward confidently, embodying a target achieved. Illuminated grid lines softly glow on the floor and walls of the setting, amplifying the futuristic aspect. In front of the golden capybara, floating, holographic interfaces depict complex networks of points and lines symbolizing the solution space 'Beaming' explores. The capybara interacts with these interfaces, implying the user's ability to control and navigate towards the best outcomes.
import coverV115 from '../../../public/images/covers/release-cover-v1.15.0.png';
// An image of a capybara sculpted entirely from iridescent blue cotton candy, gazing into a holographic galaxy of floating AI model icons (representing various AI models like Perplexity, Groq, etc.). The capybara is wearing a lightweight, futuristic headset, and its paws are gesturing as if orchestrating the movement of the models in the galaxy. The backdrop is minimalist, with occasional bursts of neon light beams, creating a sense of depth and wonder. Close-up photography, bokeh effect, with a dark but vibrant background to make the colors pop.
import coverV114 from '../../../public/images/covers/release-cover-v1.14.0.png';
// An image of a capybara sculpted entirely from black cotton candy, set against a minimalist backdrop with splashes of bright, contrasting sparkles. The capybara is using a computer with split screen made of origami, split keyboard and is wearing origami sunglasses with very different split reflections. Split halves are very contrasting. Close up photography, bokeh, white background.
import coverV113 from '../../../public/images/covers/release-cover-v1.13.0.png';
// An image of a capybara sculpted entirely from black cotton candy, set against a minimalist backdrop with splashes of bright, contrasting sparkles. The capybara is calling on a 3D origami old-school pink telephone and the camera is zooming on the telephone. Close up photography, bokeh, white background.
import coverV112 from '../../../public/images/covers/release-cover-v1.12.0.png';


interface NewsItem {
  versionCode: string;
  versionName?: string;
  versionMoji?: string;
  versionDate?: Date;
  versionCoverImage?: StaticImageData;
  text?: string | React.JSX.Element;
  items?: {
    text: React.ReactNode;
    dev?: boolean;
    issue?: number;
    icon?: React.FC<SvgIconProps>;
    noBullet?: boolean;
  }[];
}

// news and feature surfaces
export const NewsItems: NewsItem[] = [
  /* {
    versionCode: Release.App.versionCode,
    versionName: Release.App.versionName,
    versionDate: new Date('2024-10-15T01:00:00Z'),
    items: [
      { text: <>You&apos;re running an <B>unsupported Early Access</B> build of Big-AGI V2. This version is used by developers to implement long-term breaking features.</> },
      { text: <>This branch previews experimental features that are subject to change and may break without notice.</> },
      { text: <>Please report screenshots of breakages and console error messages.</> },
      { text: <>Please note that this is not the official release.</> },
      { text: <>For stable releases: <ExternalLink href='https://big-agi.com'>big-agi.com</ExternalLink>.</> },
    ],
  }, */
  {
    versionCode: Release.App.versionCode,
    versionName: Release.App.versionName,
    versionDate: new Date('2024-10-15T01:00:00Z'),
    items: [
      { text: <>You&apos;re running an unsupported <B>develpers build</B> of Big-AGI 2. This branch carries breaking features that are subject to change and may break.</> },
      { text: <><B>dev-branch:</B> LFS, Apply, MM-reAct, fu-Chart, fu-UI, fu-Diagram, C-fixes</> },
      { text: <><B>big-agi-2:</B> partial list of changes <ExternalLink href='https://github.com/enricoros/big-AGI/issues/567'>here</ExternalLink></> },
      { text: <>Please report screenshots of breakages and console error messages.</> },
      { text: <>2,000+ changes, 60,000+ lines of code changed vs. 1.16</> },
      { text: <>Do not use, no cloud backups, <ExternalLink href='https://big-agi.com'>stable version here</ExternalLink>.</> },
    ],
  },
  {
    versionCode: '1.16.9',
    versionName: 'Crystal Clear',
    versionDate: new Date('2024-06-07T05:00:00Z'),
    // versionDate: new Date('2024-05-13T19:00:00Z'),
    // versionDate: new Date('2024-05-09T00:00:00Z'),
    versionCoverImage: coverV116,
    items: [
      { text: <><B href={beamBlogUrl} wow>Beam</B> core and UX improvements based on user feedback</>, issue: 470, icon: ChatBeamIcon },
      { text: <>Chat <B>Cost estimation</B> with supported models* 💰</> },
      { text: <>Major <B>Auto-Diagrams</B> enhancements</> },
      { text: <>Save/load chat files with Ctrl+S / O</>, issue: 466 },
      { text: <><B issue={500}>YouTube Transcriber</B> persona: chat with videos</>, issue: 500 },
      { text: <>Improved <B issue={508}>formula render</B>, dark-mode diagrams</>, issue: 508 },
      { text: <>More: <B issue={517}>code soft-wrap</B>, selection toolbar, <B issue={507}>3x faster</B> on Apple silicon</>, issue: 507 },
      { text: <>Updated <B>Anthropic</B>*, <B>Groq</B>, <B>Ollama</B>, <B>OpenAI</B>*, <B>OpenRouter</B>*, and <B>Perplexity</B></> },
      { text: <>Developers: update LLMs data structures</>, dev: true },
      { text: <>1.16.1: Support for <B>OpenAI</B> <B href='https://openai.com/index/hello-gpt-4o/'>GPT-4o</B></> },
      { text: <>1.16.2: Proper <B>Gemini</B> support, <B>HTML/Markdown</B> downloads, and latest <B>Mistral</B></> },
      { text: <>1.16.3: Support for <B href='https://www.anthropic.com/news/claude-3-5-sonnet'>Claude 3.5 Sonnet</B> (refresh your <B>Anthropic</B> models)</> },
      { text: <>1.16.4: <B>8192 tokens</B> support for Claude 3.5 Sonnet</> },
      { text: <>1.16.5: OpenAI <B>GPT-4o Mini</B> support</> },
      { text: <>1.16.6: Groq <B>Llama 3.1</B> support</> },
      { text: <>1.16.7: Gpt-4o <B>2024-08-06</B></> },
      { text: <>1.16.8: <B>ChatGPT-4o</B> latest</> },
      { text: <>1.16.9: <B>Gemini</B> fixes</> },
      { text: <>OpenAI <B>o1</B>, DeepSeek R1, and newer models require Big-AGI 2. <B href='https://y2rjg0zillz.typeform.com/to/ZSADpr5u?utm_source=gh-2&utm_medium=news&utm_campaign=ea2'>Sign up here</B></> },
    ],
  },
  {
    versionCode: '1.15',
    versionName: 'Beam',
    versionDate: new Date('2024-04-10T08:00:00Z'),
    versionCoverImage: coverV115,
    items: [
      { text: <><B href={beamBlogUrl} wow>Beam</B>: Find better answers with multi-model AI reasoning</>, issue: 443, icon: ChatBeamIcon },
      // { text: <><B>Explore diverse perspectives</B> and <B>synthesize optimal responses</B></>, noBullet: true },
      { text: <><B issue={436}>Auto-configure</B> models for managed deployments</>, issue: 436 },
      { text: <>Message <B issue={476}>starring ⭐</B>, filtering and attachment</>, issue: 476 },
      { text: <>Default persona improvements</> },
      { text: <>Fixes to Gemini models and SVGs, improvements to UI and icons, and more</> },
      { text: <>Developers: imperative LLM models discovery</>, dev: true },
      { text: <>1.15.1: Support for <B>Gemini Pro 1.5</B> and <B>OpenAI 2024-04-09</B> models</> },
    ],
  },
  {
    versionCode: '1.14',
    versionName: 'Modelmorphic',
    versionCoverImage: coverV114,
    versionDate: new Date('2024-03-07T08:00:00Z'),
    items: [
      { text: <>Anthropic <B href='https://www.anthropic.com/news/claude-3-family'>Claude-3</B> support for smarter chats</>, issue: 443, icon: AnthropicIcon },
      { text: <><B issue={407}>Perplexity</B> support, including Online models</>, issue: 407, icon: PerplexityIcon },
      { text: <><B issue={427}>Groq</B> support, with speeds up to 500 tok/s</>, issue: 427, icon: GroqIcon },
      { text: <>Support for new Mistral-Large models</>, icon: MistralIcon },
      { text: <>Support for Google Gemini 1.5 models and various improvements</>, icon: GoogleIcon as any },
      { text: <>Deeper LocalAI integration including support for <B issue={411}>model galleries</B></>, icon: LocalAIIcon },
      { text: <>Major <B href='https://twitter.com/enricoros/status/1756553038293303434'>performance optimizations</B>: runs faster, saves power, saves memory</> },
      { text: <>Improvements: auto-size charts, search and folder experience</> },
      { text: <>Perfect chat scaling, with rapid keyboard shortcuts</> },
      { text: <>Also: diagrams auto-resize, open code with StackBlitz and JSFiddle, quick model visibility toggle, open links externally, docs on the web</> },
      { text: <>Fixes: standalone LaTeX blocks, close views by dragging, knowledge cutoff dates, crashes on Google translate (thanks dad)</> },
    ],
  },
  {
    versionCode: '1.13',
    versionName: 'Multi + Mind',
    versionMoji: '🧠🔀',
    versionDate: new Date('2024-02-08T07:47:00Z'),
    versionCoverImage: coverV113,
    items: [
      { text: <>Side-by-Side <B issue={208}>split windows</B>: multitask with parallel conversations</>, issue: 208 },
      { text: <><B issue={388} wow>Multi-Chat</B> mode: message all, all at once</>, issue: 388 },
      { text: <>Adjustable <B>text size</B>: denser chats</>, issue: 399 },
      { text: <>Export <B issue={392}>tables as CSV</B> files</>, issue: 392 },
      { text: <><B>Dev2</B> persona technology preview</> },
      { text: <>Better looking chats, spacing, fonts, menus</> },
      { text: <>More: video player, LM Studio tutorial, speedups, MongoDB (docs)</> },
    ],
  },
  {
    versionCode: '1.12',
    versionName: 'AGI Hotline',
    // versionMoji: '✨🗣️',
    versionDate: new Date('2024-01-26T12:30:00Z'),
    versionCoverImage: coverV112,
    items: [
      { text: <><B issue={354} wow>Voice Call Personas</B>: save time, recap conversations</>, issue: 354 },
      { text: <>Updated <B issue={364}>OpenAI Models</B> to the 0125 release</>, issue: 364 },
      { text: <>Chats: Auto-<B issue={222} wow>Rename</B> and <B issue={360}>assign folders</B></>, issue: 222 },
      { text: <><B issue={356}>Link Sharing</B> makeover and control</>, issue: 356 },
      { text: <><B issue={358}>Accessibility</B> for screen readers</>, issue: 358 },
      { text: <>Export chats to <B>Markdown</B></>, issue: 337 },
      { text: <>Paste <B>tables from Excel</B></>, issue: 286 },
      { text: <>Large optimizations</> },
      { text: <>Ollama updates</>, issue: 309 },
      { text: <>Over <B>150 commits</B> and <B>7,000+ lines changed</B> for development enhancements</>, dev: true },
    ],
  },
  {
    versionCode: '1.11',
    versionName: 'Singularity',
    versionMoji: '🌌🌠',
    versionDate: new Date('2024-01-16T06:30:00Z'),
    items: [
      { text: <><B issue={329} wow>Search chats</B> (@joriskalz)</>, issue: 329 },
      { text: <>Quick <B issue={327}>commands pane</B> (open with &apos;/&apos;)</>, issue: 327 },
      { text: <><B>Together AI</B> Inference platform support</>, issue: 346 },
      { text: <>Persona creation: <B issue={301}>history</B></>, issue: 301 },
      { text: <>Persona creation: fix <B issue={328}>API timeouts</B></>, issue: 328 },
      { text: <>Support up to five <B issue={323}>OpenAI-compatible</B> endpoints</>, issue: 323 },
    ],
  },
  {
    versionCode: '1.10',
    versionName: 'The Year of AGI',
    // versionMoji: '🎊✨',
    versionDate: new Date('2024-01-06T08:00:00Z'),
    items: [
      { text: <><B issue={201} wow>New UI</B> for desktop and mobile, enabling future expansions</>, issue: 201 },
      { text: <><B issue={321} wow>Folder categorization</B> for conversation management</>, issue: 321 },
      { text: <><B>LM Studio</B> support and refined token management</> },
      { text: <>Draggable panes in split screen mode</>, issue: 308 },
      { text: <>Bug fixes and UI polish</> },
      { text: <>Developers: document proxy settings on docker</>, issue: 318, dev: true },
    ],
  },
  {
    versionCode: '1.9',
    versionName: 'Creative Horizons',
    // versionMoji: '🎨🌌',
    versionDate: new Date('2023-12-28T22:30:00Z'),
    items: [
      { text: <><B issue={212} wow>DALL·E 3</B> support (/draw), with advanced control</>, issue: 212 },
      { text: <><B issue={304} wow>Perfect scrolling</B> UX, on all devices</>, issue: 304 },
      { text: <>Create personas <B issue={287}>from text</B></>, issue: 287 },
      { text: <>Openrouter: auto-detect models, support free-tiers and rates</>, issue: 291 },
      { text: <>Image drawing: unified UX, including auto-prompting</> },
      { text: <>Fix layout on Firefox</>, issue: 255 },
      { text: <>Developers: new Text2Image subsystem, Optima layout subsystem, ScrollToBottom library, using new Panes library, improved Llms subsystem</>, dev: true },
    ],
  },
  {
    versionCode: '1.8',
    versionName: 'To The Moon And Back',
    // versionMoji: '🚀🌕🔙❤️',
    versionDate: new Date('2023-12-20T09:30:00Z'),
    items: [
      { text: <><B issue={275} wow>Google Gemini</B> models support</> },
      { text: <><B issue={273}>Mistral Platform</B> support</> },
      { text: <><B issue={270}>Ollama chats</B> perfection</> },
      { text: <>Custom <B issue={280}>diagrams instructions</B> (@joriskalz)</> },
      { text: <><B>Single-Tab</B> mode, enhances data integrity and prevents DB corruption</> },
      { text: <>Updated Ollama (v0.1.17) and OpenRouter models</> },
      { text: <>More: fixed ⌘ shortcuts on Mac</> },
      { text: <><Link href='https://big-agi.com'>Website</Link>: official downloads</> },
      { text: <>Easier Vercel deployment, documented <Link href='https://github.com/enricoros/big-AGI/issues/276#issuecomment-1858591483'>network troubleshooting</Link></>, dev: true },
    ],
  },
  {
    versionCode: '1.7',
    versionName: 'Attachment Theory',
    // versionDate: new Date('2023-12-11T06:00:00Z'), // 1.7.3
    versionDate: new Date('2023-12-10T12:00:00Z'), // 1.7.0
    items: [
      { text: <>New <B issue={251} wow>attachments system</B>: drag, paste, link, snap, images, text, pdfs</> },
      { text: <>Desktop <B issue={253}>webcam access</B> for direct image capture (Labs option)</> },
      { text: <>Independent browsing with <B code='/docs/config-feature-browse.md'>Browserless</B> support</> },
      { text: <><B issue={256}>Overheat</B> LLMs with higher temperature limits</> },
      { text: <>Enhanced security via <B code='/docs/deploy-authentication.md'>password protection</B></> },
      { text: <>{platformAwareKeystrokes('Ctrl+Shift+O')}: quick access to model options</> },
      { text: <>Optimized voice input and performance</> },
      { text: <>Latest Ollama models</> },
    ],
  },
  {
    versionCode: '1.6',
    versionName: 'Surf\'s Up',
    versionDate: new Date('2023-11-28T21:00:00Z'),
    items: [
      { text: <><B issue={237} wow>Web Browsing</B> support, see the <B code='/docs/config-feature-browse.md'>browsing user guide</B></> },
      { text: <><B issue={235}>Branching Discussions</B> at any message</> },
      { text: <><B issue={207}>Keyboard Navigation</B>: use {platformAwareKeystrokes('Ctrl+Shift+Left/Right')} to navigate chats</> },
      { text: <><B issue={236}>UI fixes</B> (thanks to the first sponsor)</> },
      { text: <>Added support for Anthropic Claude 2.1</> },
      { text: <>Large rendering performance optimization</> },
      { text: <>More: <Chip>/help</Chip>, import ChatGPT from source, new Flattener</> },
      { text: <>Devs: improved code quality, snackbar framework</>, dev: true },
    ],
  },
  {
    versionCode: '1.5',
    versionName: 'Loaded!',
    versionDate: new Date('2023-11-19T21:00:00Z'),
    items: [
      { text: <><B issue={190} wow>Continued Voice</B> for hands-free interaction</> },
      { text: <><B issue={192}>Visualization</B> Tool for data representations</> },
      { text: <><B code='/docs/config-local-ollama.md'>Ollama (guide)</B> local models support</> },
      { text: <><B issue={194}>Text Tools</B> including highlight differences</> },
      { text: <><B href='https://mermaid.js.org/'>Mermaid</B> Diagramming Rendering</> },
      { text: <><B>OpenAI 1106</B> Chat Models</> },
      { text: <>Cloudflare OpenAI API Gateway</> },
      { text: <>Helicone for Anthropic</> },
    ],
  },
  {
    versionCode: '1.4',
    items: [
      { text: <><B>Share and clone</B> conversations, with public links</> },
      { text: <><B code='/docs/config-azure-openai.md'>Azure</B> models, incl. gpt-4-32k</> },
      { text: <><B>OpenRouter</B> models full support, incl. gpt-4-32k</> },
      { text: <>Latex Rendering</> },
      { text: <>Augmented Chat modes (Labs)</> },
    ],
  },
  {
    versionCode: '1.3.5',
    items: [
      { text: <>AI in the real world with <B>Camera OCR</B> - MOBILE-ONLY</> },
      { text: <><B>Anthropic</B> models full support</> },
      { text: <>Removed the 20 chats hard limit</> },
      { text: <>Backup chats (export all)</> },
      { text: <>Import ChatGPT shared chats</> },
      { text: <>Cleaner, better, newer UI, including relative chats size</> },
    ],
  },
  {
    versionCode: '1.3.1',
    items: [
      { text: <><B>Flattener</B> - 4-mode conversations summarizer</> },
      { text: <><B>Forking</B> - branch your conversations</> },
      { text: <><B>/s</B> and <B>/a</B> to append a <i>system</i> or <i>assistant</i> message</> },
      { text: 'NextJS STOP bug.. squashed, with Vercel!' },
    ],
  },
  {
    versionCode: '1.2.1',
    // text: '',
    items: [
      { text: <>New home page: <b><Link href={Brand.URIs.Home + clientUtmSource()} target='_blank'>{Brand.URIs.Home.replace('https://', '')}</Link></b></> },
      { text: 'Support 𝑓unction models' }, // (n)
      { text: <Box sx={{ display: 'flex', alignItems: 'center' }}>Labs: experiments</Box> }, // ⚗️🧬🔬🥼 🥽🧪 <ScienceIcon sx={{ fontSize: 24, opacity: 0.5 }} />
    ],
  },
];


function B(props: {
  // one-of
  href?: string,
  issue?: number,
  code?: string,

  wow?: boolean,
  children: React.ReactNode
}) {
  const href =
    props.issue ? `${Brand.URIs.OpenRepo}/issues/${props.issue}`
      : props.code ? `${Brand.URIs.OpenRepo}/blob/main/${props.code}`
        : props.href;
  const boldText = (
    <Typography component='span' color={!!href ? 'primary' : 'neutral'} sx={{ fontWeight: 'lg' }}>
      {props.children}
    </Typography>
  );
  if (!href)
    return boldText;
  // append UTM details if missing
  const hrefWithUtm = href.includes('utm_source=') ? href : href + clientUtmSource();
  return (
    <ExternalLink href={hrefWithUtm} highlight={props.wow} icon={props.issue ? 'issue' : undefined}>
      {boldText}
    </ExternalLink>
  );
}


================================================
FILE: src/apps/personas/AppPersonas.tsx
================================================
import * as React from 'react';

import { Box, Container, ListDivider, Typography } from '@mui/joy';

import { OptimaDrawerIn } from '~/common/layout/optima/portals/OptimaPortalsIn';

import { Creator } from './creator/Creator';
import { CreatorDrawer } from './creator/CreatorDrawer';
import { Viewer } from './creator/Viewer';


export function AppPersonas() {

  // state
  const [selectedSimplePersonaId, setSelectedSimplePersonaId] = React.useState<string | null>(null);

  return <>

    {/* -> Drawer */}
    <OptimaDrawerIn>
      <CreatorDrawer
        selectedSimplePersonaId={selectedSimplePersonaId}
        setSelectedSimplePersonaId={setSelectedSimplePersonaId}
      />
    </OptimaDrawerIn>

    <Box sx={{
      flexGrow: 1,
      overflowY: 'auto',
      p: { xs: 3, md: 6 },
    }}>

      <Container disableGutters maxWidth='md' sx={{ display: 'flex', flexDirection: 'column', gap: 1 }}>

        <Typography level='title-lg' sx={{ textAlign: 'center' }}>
          AI Personas Creator
        </Typography>

        <ListDivider sx={{ my: 2 }} />

        {!!selectedSimplePersonaId && <Viewer selectedSimplePersonaId={selectedSimplePersonaId} />}

        <Creator display={!selectedSimplePersonaId} />

      </Container>

    </Box>
  </>;
}


================================================
FILE: src/apps/personas/store-app-personas.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import { agiUuid } from '~/common/util/idUtils';
import { useShallow } from 'zustand/react/shallow';


// constraint the max number of saved prompts, to stay below localStorage quota
const MAX_SAVED_PROMPTS = 100;


/**
 * Very simple personas store for the "Persona Creator" - note that we shall
 * switch to a more complex personas store in the future, as for now we mainly
 * save system prompts so that we don't lose what was created.
 */
export interface SimplePersona {
  id: string;
  name?: string;
  systemPrompt: string; // The system prompt is very important and required
  creationDate: string; // ISO string format
  pictureUrl?: string; // Optional picture URL
  // source material
  inputProvenance?: SimplePersonaProvenance;
  inputText: string;
  // llm used
  llmLabel?: string;
}

export type SimplePersonaProvenance = {
  type: 'youtube';
  url: string;
  title?: string;
  thumbnailUrl?: string;
} | {
  type: 'text';
};


interface AppPersonasStore {

  // state
  simplePersonas: SimplePersona[];

  // actions
  prependSimplePersona: (systemPrompt: string, inputText: string, inputProvenance?: SimplePersonaProvenance, llmLabel?: string) => void;
  deleteSimplePersona: (id: string) => void;
  deleteSimplePersonas: (ids: Set<string>) => void;

}

/**
 * DO NOT USE outside of this application - this is a very simple store for Personas so that
 * they're not immediately lost.
 */
const useAppPersonasStore = create<AppPersonasStore>()(persist(
  (_set, _get) => ({

    simplePersonas: [],

    prependSimplePersona: (systemPrompt: string, inputText: string, inputProvenance?: SimplePersonaProvenance, llmLabel?: string) =>
      _set(state => {
        const newPersona: SimplePersona = {
          id: agiUuid('persona-simple'),
          systemPrompt,
          creationDate: new Date().toISOString(),
          inputProvenance,
          // to save bytes, do not save input text when from YouTube
          inputText: inputProvenance?.type === 'youtube' ? '' : inputText,
          llmLabel,
        };
        return {
          simplePersonas: [
            newPersona,
            ...state.simplePersonas.slice(0, MAX_SAVED_PROMPTS - 1),
          ],
        };
      }),

    deleteSimplePersona: (simplePersonaId: string) =>
      _set(state => ({
        simplePersonas: state.simplePersonas.filter(persona => persona.id !== simplePersonaId),
      })),

    deleteSimplePersonas: (simplePersonaIds: Set<string>) =>
      _set(state => ({
        simplePersonas: state.simplePersonas.filter(persona => !simplePersonaIds.has(persona.id)),
      })),

  }),
  {
    name: 'app-app-personas',
    version: 1,
  },
));

export function useSimplePersonas() {
  const simplePersonas = useAppPersonasStore(useShallow(state => state.simplePersonas));
  return { simplePersonas };
}

export function useSimplePersona(simplePersonaId: string) {
  const simplePersona = useAppPersonasStore(useShallow(state => {
    return state.simplePersonas.find(persona => persona.id === simplePersonaId) ?? null;
  }));
  return { simplePersona };
}

export function prependSimplePersona(systemPrompt: string, inputText: string, inputProvenance?: SimplePersonaProvenance, llmLabel?: string) {
  useAppPersonasStore.getState().prependSimplePersona(systemPrompt, inputText, inputProvenance, llmLabel);
}

export function deleteSimplePersona(simplePersonaId: string) {
  useAppPersonasStore.getState().deleteSimplePersona(simplePersonaId);
}

export function deleteSimplePersonas(simplePersonaIds: Set<string>) {
  useAppPersonasStore.getState().deleteSimplePersonas(simplePersonaIds);
}


================================================
FILE: src/apps/personas/creator/Creator.tsx
================================================
import * as React from 'react';

import { Alert, Box, Button, Card, CardContent, CircularProgress, Divider, FormLabel, Grid, IconButton, LinearProgress, Tab, tabClasses, TabList, TabPanel, Tabs, Typography } from '@mui/joy';
import AddIcon from '@mui/icons-material/Add';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import SettingsAccessibilityIcon from '@mui/icons-material/SettingsAccessibility';

import { LLMChainStep, useLLMChain } from '~/modules/aifn/useLLMChain';
import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import type { ContentScaling } from '~/common/app.theme';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { agiUuid } from '~/common/util/idUtils';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { useFormEditTextArray } from '~/common/components/forms/useFormEditTextArray';
import { useLLMSelect, useLLMSelectLocalState } from '~/common/components/forms/useLLMSelect';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';
import { useUIContentScaling } from '~/common/stores/store-ui';

import { FromText } from './FromText';
import { FromYouTube } from './FromYouTube';
import { prependSimplePersona, SimplePersonaProvenance } from '../store-app-personas';


// delay to start a new chain after the previous one finishes
const CONTINUE_DELAY: number | false = false;


const Prompts: string[] = [
  'You are skilled in analyzing and embodying diverse characters. You meticulously study transcripts to capture key attributes, draft comprehensive character sheets, and refine them for authenticity. Feel free to make assumptions without hedging, be concise and be creative.',
  'Conduct comprehensive research on the provided transcript. Identify key characteristics of the speaker, including age, professional field, distinct personality traits, style of communication, narrative context, and self-awareness. Additionally, consider any unique aspects such as their use of humor, their cultural background, core values, passions, fears, personal history, and social interactions. Your output for this stage is an in-depth written analysis that exhibits an understanding of both the superficial and more profound aspects of the speaker\'s persona.',
  'Craft your documented analysis into a draft of the \'You are a...\' character sheet. It should encapsulate all crucial personality dimensions, along with the motivations and aspirations of the persona. Keep in mind to balance succinctness and depth of detail for each dimension. The deliverable here is a comprehensive draft of the character sheet that captures the speaker\'s unique essence.',
  'Compare the draft character sheet with the original transcript, validating its content and ensuring it captures both the speaker’s overt characteristics and the subtler undertones. Omit unknown information, fine-tune any areas that require clarity, have been overlooked, or require more authenticity. Use clear and illustrative examples from the transcript to refine your sheet and offer meaningful, tangible reference points. Your output is a coherent, comprehensive, and nuanced instruction that begins with \'You are a...\' and  serves as a go-to guide for an actor recreating the persona.',
];

const getTitlesForTab = (selectedTab: number): string[] => {
  const analyzeSubject: string = selectedTab ? 'text' : 'transcript';
  return [
    'Common: Creator System Prompt',
    `Analyze the ${analyzeSubject}`,
    'Define the character',
    'Cross the t\'s',
  ];
};

// chain to convert a text input string (e.g. youtube transcript) into a persona prompt
function createChain(instructions: string[], titles: string[]): LLMChainStep[] {
  return [
    {
      name: titles[1],
      setSystem: instructions[0],
      addUserChainInput: true,
      addUserText: instructions[1],
    },
    {
      name: titles[2],
      addModelPrevOutput: true,
      addUserText: instructions[2],
    },
    {
      name: titles[3],
      addModelPrevOutput: true,
      addUserText: instructions[3],
    },
  ];
}


export const PersonaPromptCard = (props: {
  content: string,
  contentScaling: ContentScaling,
}) =>
  <Card sx={{ boxShadow: 'md', mt: 3 }}>

    <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
      <Typography level='title-lg' color='success' startDecorator={<SettingsAccessibilityIcon color='success' />}>
        Persona Prompt
      </Typography>
      <GoodTooltip title='Copy system prompt'>
        <Button color='success' onClick={() => copyToClipboard(props.content, 'Persona prompt')} endDecorator={<ContentCopyIcon />} sx={{ minWidth: 120 }}>
          Copy
        </Button>
      </GoodTooltip>
    </Box>

    <CardContent>
      <Alert variant='soft' color='success' sx={{ mb: 1 }}>
        You may now copy the text below and use it as Custom prompt!
      </Alert>
      <ScaledTextBlockRenderer
        text={props.content}
        contentScaling={props.contentScaling}
        textRenderVariant='markdown'
      />
    </CardContent>
  </Card>;


export function Creator(props: { display: boolean }) {

  // state
  const advanced = useToggleableBoolean();
  const [selectedTab, setSelectedTab] = React.useState(0);
  const [chainInputText, setChainInputText] = React.useState<string | null>(null);
  const [inputProvenance, setInputProvenance] = React.useState<SimplePersonaProvenance | null>(null);
  const [showIntermediates, setShowIntermediates] = React.useState(false);

  // external state
  const contentScaling = useUIContentScaling();
  const [personaLlmId, setPersonaLlmId] = useLLMSelectLocalState(true);
  const [personaLlm, llmComponent] = useLLMSelect(personaLlmId, setPersonaLlmId, { label: 'Persona Creation Model', larger: true });


  // editable prompts
  const promptTitles = React.useMemo(() => getTitlesForTab(selectedTab), [selectedTab]);

  const {
    strings: editedInstructions, stringEditors: instructionEditors,
  } = useFormEditTextArray(Prompts, promptTitles);

  const { steps: creationChainSteps, id: chainId } = React.useMemo(() => {
    return {
      steps: createChain(editedInstructions, promptTitles),
      id: agiUuid('persona-creator-chain'),
    };
  }, [editedInstructions, promptTitles]);

  const llmLabel = personaLlm?.label || undefined;
  const savePersona = React.useCallback((personaPrompt: string, inputText: string) => {
    prependSimplePersona(personaPrompt, inputText, inputProvenance ?? undefined, llmLabel);
  }, [inputProvenance, llmLabel]);

  const {
    // isFinished,
    isTransforming,
    chainProgress,
    chainIntermediates,
    chainStepName,
    chainStepInterimChars,
    chainOutputText,
    chainErrorMessage,
    userCancelChain,
    restartChain,
  } = useLLMChain(
    creationChainSteps,
    personaLlm?.id,
    chainInputText ?? undefined,
    'persona-extract',
    chainId,
    savePersona,
  );


  // Reset the relevant state when the selected tab changes
  React.useEffect(() => {
    setChainInputText(null);
  }, [selectedTab]);


  // [debug] Restart the chain when complete after a delay
  const debugRestart = !!CONTINUE_DELAY && !isTransforming && (chainProgress === 1 || !!chainErrorMessage);
  React.useEffect(() => {
    if (debugRestart) {
      const timeout = setTimeout(restartChain, CONTINUE_DELAY);
      return () => clearTimeout(timeout);
    }
  }, [debugRestart, restartChain]);


  const handleCreate = React.useCallback((text: string, provenance: SimplePersonaProvenance) => {
    setChainInputText(text);
    setInputProvenance(provenance);
  }, []);

  const handleCancel = React.useCallback(() => {
    setChainInputText(null);
    setInputProvenance(null);
    userCancelChain();
  }, [userCancelChain]);


  // Hide the GFX, but not the logic (hooks)
  if (!props.display)
    return null;

  return <>

    <Typography level='title-sm' mb={3}>
      Create the <em>System Prompt</em> of an AI Persona from YouTube or Text.
    </Typography>


    {/* Inputs */}
    <Tabs
      variant='outlined'
      defaultValue={0}
      value={selectedTab}
      onChange={(_event, newValue) => setSelectedTab(newValue as number)}
      sx={{
        // boxShadow: 'sm',
        borderRadius: 'md',
        // overflow: 'hidden',
        display: isTransforming ? 'none' : undefined,
      }}
    >
      <TabList
        sx={{
          minHeight: '3rem',
          [`& .${tabClasses.root}[aria-selected="true"]`]: {
            // color: 'primary.softColor',
            bgcolor: 'background.popup',
            boxShadow: 'sm',
            fontWeight: 'lg',
          },
          // first element
          '& > *:first-of-type': { borderTopLeftRadius: '0.5rem' },
        }}
      >
        <Tab>From YouTube</Tab>
        <Tab>From Text</Tab>
      </TabList>
      <TabPanel keepMounted value={0} sx={{ p: 3 }}>
        <FromYouTube isTransforming={isTransforming} onCreate={handleCreate} />
      </TabPanel>
      <TabPanel keepMounted value={1} sx={{ p: 3 }}>
        <FromText isCreating={isTransforming} onCreate={handleCreate} />
      </TabPanel>

      <Divider orientation='horizontal' />

      <Box sx={{ p: 3, display: 'flex', flexDirection: 'column', gap: 2 }}>
        {llmComponent}

        {advanced.on && (
          <Box sx={{ my: 1, display: 'flex', flexDirection: 'column', gap: 2 }}>
            {instructionEditors}
          </Box>
        )}

        <FormLabel onClick={advanced.toggle} sx={{ textDecoration: 'underline', cursor: 'pointer' }}>
          {advanced.on ? 'Hide Advanced' : 'Advanced: Prompts'}
        </FormLabel>
      </Box>
    </Tabs>


    {/* Embodiment Progress */}
    {/* <GoodModal open> */}
    {isTransforming && <Card><CardContent sx={{ display: 'flex', flexDirection: 'column', gap: 3 }}>
      <Box sx={{ display: 'flex', flexDirection: 'column', alignItems: 'center', my: 2 }}>
        <CircularProgress color='primary' value={Math.max(10, 100 * chainProgress)} />
      </Box>
      <Box>
        <Typography color='success' level='title-lg'>
          Embodying Persona ...
        </Typography>
        <Typography level='title-sm' sx={{ mt: 1 }}>
          Using: {personaLlm?.label}
        </Typography>
      </Box>
      <Box>
        <Typography color='success' level='title-sm' sx={{ fontWeight: 'lg' }}>
          {chainStepName}
        </Typography>
        <LinearProgress color='success' determinate value={Math.max(10, 100 * chainProgress)} sx={{ mt: 1.5 }} />
        <Typography level='body-sm' sx={{ mt: 1 }}>
          {chainStepInterimChars === null ? 'Loading ...' : `Generating (${chainStepInterimChars.toLocaleString()} bytes) ...`}
        </Typography>
      </Box>
      <Typography level='title-sm'>
        This may take 1-2 minutes.
        While larger models will produce higher quality prompts,
        if you experience any errors (e.g. LLM timeouts, or context overflows for larger videos)
        please try again with faster/smaller models.
      </Typography>
      <Button variant='soft' color='neutral' onClick={handleCancel} sx={{ ml: 'auto', minWidth: 100, mt: 3 }}>
        Cancel
      </Button>
    </CardContent></Card>}


    {/* Errors */}
    {!!chainErrorMessage && (
      <Alert color='warning' sx={{ mt: 1 }}>
        <Typography component='div'>{chainErrorMessage}</Typography>
      </Alert>
    )}

    {/* The Persona (Output) */}
    {chainOutputText && <>
      <PersonaPromptCard
        content={chainOutputText}
        contentScaling={contentScaling}
      />
    </>}


    {/* Input + Intermediate outputs (with expander) */}
    {(isTransforming || chainIntermediates?.length > 0) && <>
      <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'flex-end', mt: 3, mb: 0.5, mx: 1 }}>
        <Typography level='title-lg'>
          {isTransforming ? 'Working ...' : 'Intermediate Work'}
        </Typography>
        <IconButton size='sm' variant={showIntermediates ? 'solid' : 'outlined'} onClick={() => setShowIntermediates(s => !s)}>
          <AddIcon />
        </IconButton>
      </Box>
      <Grid container spacing={2}>
        <Grid xs={12} md={showIntermediates ? 12 : 6}>
          <Card sx={{ height: '100%', overflow: 'hidden' }}>
            <CardContent>
              <Typography color='success' level='title-sm' sx={{ mb: 1 }}>
                Input Text
              </Typography>
              <Typography level='body-sm'>
                {showIntermediates ? chainInputText : (chainInputText?.slice(0, 280) + '...')}
              </Typography>
            </CardContent>
          </Card>
        </Grid>
        {chainIntermediates.map((intermediate, i) =>
          <Grid xs={12} md={showIntermediates ? 12 : 6} key={i}>
            <Card sx={{ height: '100%', overflow: 'hidden' }}>
              <CardContent>
                <Typography color='success' level='title-sm' sx={{ mb: 1 }}>
                  {i + 1}. {intermediate.name}
                </Typography>
                <Typography level='body-sm'>
                  {showIntermediates ? intermediate.output : (intermediate.output?.slice(0, 280) + '...')}
                </Typography>
              </CardContent>
            </Card>
          </Grid>,
        )}
      </Grid>
    </>}

  </>;
}


================================================
FILE: src/apps/personas/creator/CreatorDrawer.tsx
================================================
import * as React from 'react';

import { Box, Button, IconButton, ListItemDecorator, Sheet, Tooltip } from '@mui/joy';
import CheckBoxIcon from '@mui/icons-material/CheckBox';
import CheckBoxOutlineBlankIcon from '@mui/icons-material/CheckBoxOutlineBlank';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import Diversity2Icon from '@mui/icons-material/Diversity2';
import DoneIcon from '@mui/icons-material/Done';

import { OptimaDrawerHeader } from '~/common/layout/optima/drawer/OptimaDrawerHeader';
import { OptimaDrawerList } from '~/common/layout/optima/drawer/OptimaDrawerList';
import { optimaCloseDrawer } from '~/common/layout/optima/useOptima';

import { CreatorDrawerItem } from './CreatorDrawerItem';
import { deleteSimplePersona, deleteSimplePersonas, useSimplePersonas } from '../store-app-personas';


export function CreatorDrawer(props: {
  selectedSimplePersonaId: string | null,
  setSelectedSimplePersonaId: (simplePersonaId: string | null) => void,
}) {

  // selection mode
  const [selectMode, setSelectMode] = React.useState(false);
  const [selectedIds, setSelectedIds] = React.useState<Set<string>>(new Set());

  // external state
  const { simplePersonas } = useSimplePersonas();


  // derived state
  const hasPersonas = simplePersonas.length > 0;


  // Simple Persona Operations

  const { setSelectedSimplePersonaId } = props;

  const handleSimplePersonaUnselect = React.useCallback(() => {
    setSelectedSimplePersonaId(null);
  }, [setSelectedSimplePersonaId]);

  const handleSimplePersonaDelete = React.useCallback((simplePersonaId: string) => {
    deleteSimplePersona(simplePersonaId);
    handleSimplePersonaUnselect();
  }, [handleSimplePersonaUnselect]);


  // Selection

  const handleSelectionClose = React.useCallback(() => {
    setSelectMode(false);
    setSelectedIds(new Set());
  }, []);

  const handleSelectionToggleId = React.useCallback((simplePersonaId: string) => {
    setSelectedIds(prevSelectedIds => {
      const newSelectedItems = new Set(prevSelectedIds);
      if (newSelectedItems.has(simplePersonaId))
        newSelectedItems.delete(simplePersonaId);
      else
        newSelectedItems.add(simplePersonaId);
      return newSelectedItems;
    });
  }, []);

  const handleSelectionInvert = React.useCallback(() => {
    setSelectedIds(prevSelectedIds => {
      const newSelectedIds = new Set(prevSelectedIds);
      simplePersonas.forEach(persona => {
        if (newSelectedIds.has(persona.id))
          newSelectedIds.delete(persona.id);
        else
          newSelectedIds.add(persona.id);
      });
      return newSelectedIds;
    });
  }, [simplePersonas]);

  const handleSelectionDelete = React.useCallback(() => {
    deleteSimplePersonas(selectedIds);
    setSelectedIds(new Set());
  }, [selectedIds]);


  return <>

    {/* Drawer Header */}
    <OptimaDrawerHeader
      title={selectMode ? 'Selection Mode' : 'Recent'}
      onClose={selectMode ? handleSelectionClose : optimaCloseDrawer}
    >
      {hasPersonas && !selectMode && (
        <Tooltip title={selectMode ? 'Done' : 'Select'}>
          <IconButton onClick={selectMode ? handleSelectionClose : () => setSelectMode(true)}>
            {selectMode ? <DoneIcon /> : <CheckBoxOutlineBlankIcon />}
          </IconButton>
        </Tooltip>
      )}
    </OptimaDrawerHeader>

    <OptimaDrawerList
      variant='plain'
      noTopPadding noBottomPadding tallRows
      onClick={handleSimplePersonaUnselect}
    >

      {selectMode ? (
        // Selection Header
        <Sheet variant='soft' color='warning' invertedColors>
          <Box sx={{ display: 'flex', alignItems: 'center', px: 1, minHeight: '3rem' }}>
            <Button
              variant='plain'
              color='warning'
              startDecorator={selectedIds.size === simplePersonas.length ? <CheckBoxOutlineBlankIcon /> : <CheckBoxIcon />}
              onClick={handleSelectionInvert}
            >
              {selectedIds.size === simplePersonas.length
                ? 'Select None'
                : selectedIds.size === 0
                  ? `Select ${simplePersonas.length.toLocaleString() || 'All'}`
                  : 'Invert'}
            </Button>
            <Button
              variant='solid'
              color='warning'
              startDecorator={<DeleteOutlineIcon />}
              onClick={handleSelectionDelete}
              disabled={selectedIds.size === 0}
              sx={{ ml: 'auto' }}
            >
              Delete
            </Button>
          </Box>
        </Sheet>
      ) : (
        // Create Button
        <Button
          variant={props.selectedSimplePersonaId ? 'plain' : 'soft'}
          onClick={handleSimplePersonaUnselect}
          sx={{
            m: 2,

            // ...PageDrawerTallItemSx,
            justifyContent: 'flex-start',
            padding: '0px 0.75rem',

            // style
            border: '1px solid',
            borderColor: 'neutral.outlinedBorder',
            borderRadius: 'sm',
            '--ListItemDecorator-size': 'calc(2.5rem - 1px)', // compensate for the border
          }}
        >
          <ListItemDecorator><Diversity2Icon /></ListItemDecorator>
          {/*<Typography level='title-sm' sx={!props.selectedSimplePersonaId ? { fontWeight: 'lg' } : undefined}>*/}
          Create
          {/*</Typography>*/}
        </Button>
      )}

      {/* Personas [] */}
      <Box sx={{ flex: 1, overflowY: 'auto' }}>
        {simplePersonas.map(item =>
          <CreatorDrawerItem
            key={item.id}
            item={item}
            isActive={item.id === props.selectedSimplePersonaId}
            isSelected={selectedIds.has(item.id)}
            isSelection={selectMode}
            onClick={(event) => {
              event.stopPropagation();
              if (selectMode)
                handleSelectionToggleId(item.id);
              else
                props.setSelectedSimplePersonaId(item.id);
            }}
            onDelete={handleSimplePersonaDelete}
          />,
        )}
      </Box>

    </OptimaDrawerList>

  </>;
}


================================================
FILE: src/apps/personas/creator/CreatorDrawerItem.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, Checkbox, IconButton, ListItemButton, ListItemDecorator, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import TextFieldsIcon from '@mui/icons-material/TextFields';
import YouTubeIcon from '@mui/icons-material/YouTube';

import type { SimplePersona } from '../store-app-personas';


export function CreatorDrawerItem(props: {
  item: SimplePersona,
  isActive: boolean,
  isSelected: boolean,
  isSelection: boolean,
  onClick: (event: React.MouseEvent) => void,
  onDelete: (simplePersonaId: string) => void,
}) {

  // state
  const [deleteArmed, setDeleteArmed] = React.useState(false);


  // derived

  const { item, isActive } = props;

  const thumbnailUrl = item.pictureUrl || ((item.inputProvenance?.type === 'youtube' && item.inputProvenance.thumbnailUrl) ? item.inputProvenance.thumbnailUrl : undefined);

  const icon = thumbnailUrl
    ? <picture style={{ lineHeight: 0 }}><img src={thumbnailUrl} alt='Simple Persona Thumbnail' width={20} height={20} /></picture>
    : item.inputProvenance?.type === 'text'
      ? <TextFieldsIcon />
      : item.inputProvenance?.type === 'youtube'
        ? <YouTubeIcon />
        : undefined;


  return (
    <ListItemButton
      variant={isActive ? 'soft' : undefined}
      onClick={props.onClick}
      sx={{
        '&:hover > button': { opacity: 1 },
      }}
    >
      {/* Symbol or Thumbnail picture */}
      <ListItemDecorator>
        {props.isSelection ? (
          <Checkbox checked={props.isSelected} />
        ) : icon}
      </ListItemDecorator>

      <Box sx={{ overflow: 'hidden' }}>

        {/* Title or System prompt (ellipsized) */}
        <Typography level='title-sm' className='agi-ellipsize'>
          {item.name || (item.systemPrompt?.slice(0, 40) + '...')}
        </Typography>

        {/* creation Model */}
        {/*{!!item.llmLabel && <Typography level='body-xs' sx={{ overflow: 'hidden', whiteSpace: 'nowrap', textOverflow: 'ellipsis' }}>*/}
        {/*  {item.llmLabel}*/}
        {/*</Typography>}*/}

        {/* creation Date */}
        <Typography level='body-xs'>
          {!!item.creationDate && <TimeAgo date={item.creationDate} />}
        </Typography>

      </Box>


      {/* Delete Arming */}
      {!props.isSelection && !deleteArmed && (
        <IconButton
          variant={isActive ? 'solid' : 'outlined'}
          size='sm'
          sx={{ opacity: { xs: 1, sm: 0 }, transition: 'opacity 0.2s' }}
          onClick={() => setDeleteArmed(on => !on)}
        >
          <DeleteOutlineIcon />
        </IconButton>
      )}

      {/* Delete / Cancel buttons */}
      {!props.isSelection && deleteArmed && <>
        <IconButton size='sm' variant='solid' color='danger' onClick={() => props.onDelete(item.id)}>
          <DeleteOutlineIcon />
        </IconButton>
        <IconButton size='sm' variant='solid' color='neutral' onClick={() => setDeleteArmed(false)}>
          <CloseRoundedIcon />
        </IconButton>
      </>}

    </ListItemButton>
  );
}


================================================
FILE: src/apps/personas/creator/FromText.tsx
================================================
import * as React from 'react';

import { Box, Button, Textarea, Typography } from '@mui/joy';
import TextFieldsIcon from '@mui/icons-material/TextFields';

import { lineHeightTextareaMd } from '~/common/app.theme';

import type { SimplePersonaProvenance } from '../store-app-personas';


// minimum number of characters required to create from text
const MIN_CHARS = 100;


export function FromText(props: {
  isCreating: boolean;
  onCreate: (text: string, provenance: SimplePersonaProvenance) => void;
}) {

  // state
  const [text, setText] = React.useState('');

  const handleCreateFromText = (e: React.FormEvent<HTMLFormElement>) => {
    e.preventDefault(); // stop the form submit
    props.onCreate(text, { type: 'text' });
  };

  return <>

    <Typography level='title-md' startDecorator={<TextFieldsIcon />} sx={{ mb: 3 }}>
      <b>Text</b> -&gt; Persona
    </Typography>

    <form onSubmit={handleCreateFromText}>
      <Textarea
        required
        variant='outlined'
        minRows={4} maxRows={8}
        placeholder='Paste your text (e.g. tweets, social media, etc.) here...'
        value={text}
        onChange={event => setText(event.target.value)}
        sx={{
          backgroundColor: 'background.level1',
          '&:focus-within': {
            backgroundColor: 'background.popup',
          },
          lineHeight: lineHeightTextareaMd,
          mb: 1.5,
        }}
      />

      <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
        <Button
          type='submit' variant='solid'
          disabled={props.isCreating || text?.length < MIN_CHARS}
          sx={{ minWidth: 140 }}
        >
          Create
        </Button>

        <Typography level='body-sm'>
          {text.length < MIN_CHARS ? `(${MIN_CHARS - text.length})` : text.length.toLocaleString()}
        </Typography>
      </Box>
    </form>

  </>;
}


================================================
FILE: src/apps/personas/creator/FromYouTube.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, Card, IconButton, Input, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import YouTubeIcon from '@mui/icons-material/YouTube';

import { extractYoutubeVideoIDFromURL } from '~/modules/youtube/youtube.utils';
import { useYouTubeTranscript, YTVideoTranscript } from '~/modules/youtube/useYouTubeTranscript';

import { GoodTooltip } from '~/common/components/GoodTooltip';
import { InlineError } from '~/common/components/InlineError';

import type { SimplePersonaProvenance } from '../store-app-personas';


function YouTubeVideoTranscriptCard(props: { transcript: YTVideoTranscript, onClose: () => void, sx?: SxProps }) {
  const { transcript } = props;
  return (
    <Card
      variant='soft'
      sx={{
        border: '1px dashed',
        borderColor: 'neutral.solidBg',
        p: 1,
        ...props.sx,
      }}
    >
      <Box sx={{ position: 'relative' }}>
        {!!transcript.thumbnailUrl && (
          <picture style={{ lineHeight: 0 }}>
            <img
              src={transcript.thumbnailUrl}
              alt='YouTube Video Thumbnail'
              height={80}
              style={{ float: 'left', marginRight: 8 }}
            />
          </picture>
        )}

        {/*<Box sx={{ display: 'flex', flexDirection: 'column', gap: 0.5 }}>*/}
        <Typography level='title-sm'>
          {transcript?.title}
        </Typography>
        <Typography level='body-xs' sx={{ mt: 0.75 }}>
          {transcript?.transcript.slice(0, 280)}...
        </Typography>
        {/*</Box>*/}

        <IconButton
          size='sm'
          onClick={props.onClose}
          sx={{
            position: 'absolute', top: -8, right: -8,
            borderRadius: 'md',
          }}>
          <CloseRoundedIcon />
        </IconButton>
      </Box>
    </Card>
  );
}


export function FromYouTube(props: {
  isTransforming: boolean;
  onCreate: (text: string, provenance: SimplePersonaProvenance) => void;
}) {

  // state
  const [videoURL, setVideoURL] = React.useState('');
  const [videoID, setVideoID] = React.useState<string | null>(null);

  // external state

  const { onCreate } = props;
  const onNewTranscript = React.useCallback((transcript: YTVideoTranscript) => {
    // setVideoID(null); // reset the video ID, to cycle the refetch
    onCreate(
      transcript.transcript,
      {
        type: 'youtube',
        url: videoURL,
        title: transcript.title,
        thumbnailUrl: transcript.thumbnailUrl,
      },
    );
  }, [onCreate, videoURL]);

  const {
    transcript,
    isFetching, isError, error,
  } = useYouTubeTranscript(videoID, onNewTranscript);


  const handleVideoURLChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    setVideoID(null);
    setVideoURL(e.target.value);
  };

  const handleCreateFromTranscript = (e: React.FormEvent<HTMLFormElement>) => {
    e.preventDefault(); // stop the form submit

    const videoId = extractYoutubeVideoIDFromURL(videoURL) || null;
    if (!videoId)
      setVideoURL('Invalid');

    // kick-start the transcript fetch
    setVideoID(videoId);
  };


  return <>

    <Typography level='title-md' startDecorator={<YouTubeIcon sx={{ color: '#f00' }} />} sx={{ mb: 3 }}>
      YouTube -&gt; Persona
    </Typography>

    <form onSubmit={handleCreateFromTranscript}>
      <Input
        required
        type='url'
        fullWidth
        disabled={isFetching || props.isTransforming}
        variant='outlined'
        placeholder='YouTube Video URL'
        value={videoURL}
        onChange={handleVideoURLChange}
        sx={{ mb: 1.5, backgroundColor: 'background.popup' }}
      />

      <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
        <Button
          type='submit' variant='solid'
          disabled={isFetching || props.isTransforming || !videoURL}
          loading={isFetching}
          sx={{ minWidth: 140 }}
        >
          Create
        </Button>

        <GoodTooltip title='This example comes from the popular Fireship YouTube channel, which presents technical topics with irreverent humor.'>
          <Button variant='outlined' color='neutral' onClick={() => setVideoURL('https://www.youtube.com/watch?v=M_wZpSEvOkc')}>
            Example
          </Button>
        </GoodTooltip>
      </Box>
    </form>

    {isError && (
      <InlineError error={error} sx={{ mt: 3 }} />
    )}

    {!!transcript && !!videoID && (
      <YouTubeVideoTranscriptCard transcript={transcript} onClose={() => setVideoID(null)} sx={{ mt: 3 }} />
    )}

  </>;
}


================================================
FILE: src/apps/personas/creator/Viewer.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Typography } from '@mui/joy';

import { Link } from '~/common/components/Link';
import { useUIContentScaling } from '~/common/stores/store-ui';

import { PersonaPromptCard } from './Creator';
import { useSimplePersona } from '../store-app-personas';


export function Viewer(props: { selectedSimplePersonaId: string }) {

  // external state
  const contentScaling = useUIContentScaling();
  const { simplePersona } = useSimplePersona(props.selectedSimplePersonaId);

  if (!simplePersona)
    return <Typography level='body-sm'>Loading Persona...</Typography>;

  return <>

    <Typography level='title-sm'>
      This <em>System Prompt</em> was created <TimeAgo date={simplePersona.creationDate} />
      using the <strong>{simplePersona.llmLabel}</strong> model.
    </Typography>

    <PersonaPromptCard
      content={simplePersona.systemPrompt || ''}
      contentScaling={contentScaling}
    />

    {/* tell about the Provenances */}
    <Typography level='body-sm' sx={{ mt: 3 }}>
      {simplePersona.inputProvenance?.type === 'youtube' && <>The source was this YouTube video: <Link href={simplePersona.inputProvenance.url} target='_blank'>{simplePersona.inputProvenance.title}</Link>.</>}
      {simplePersona.inputProvenance?.type === 'text' && <>The source was a text snippet of {simplePersona.inputText?.length.toLocaleString()} characters.</>}
    </Typography>

  </>;
}


================================================
FILE: src/apps/settings-modal/AppChatSettingsAI.tsx
================================================
import * as React from 'react';

import { FormControl, ListDivider, Switch } from '@mui/joy';
import CodeIcon from '@mui/icons-material/Code';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import EngineeringIcon from '@mui/icons-material/Engineering';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import type { DModelDomainId } from '~/common/stores/llms/model.domains.types';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormSelectControl, FormSelectOption } from '~/common/components/forms/FormSelectControl';
import { useLLMSelect } from '~/common/components/forms/useLLMSelect';
import { useLabsDevMode } from '~/common/stores/store-ux-labs';
import { useModelDomain } from '~/common/stores/llms/hooks/useModelDomain';

import { useChatAutoAI } from '../chat/store-app-chat';


const _keepThinkingBlocksOptions: FormSelectOption<'all' | 'last-only'>[] = [
  {
    value: 'last-only',
    label: 'Most Recent',
    description: 'Default',
  },
  {
    value: 'all',
    label: 'Preserve All',
    description: 'Keep all traces',
  },
] as const;


function FormControlDomainModel(props: {
  domainId: DModelDomainId,
  title: React.ReactNode,
  description?: React.ReactNode,
  tooltip?: React.ReactNode,
}) {

  // external state
  const { domainModelId: fastModelId, assignDomainModelId: setFastModelId } = useModelDomain(props.domainId);
  const [_llm, llmComponent] = useLLMSelect(fastModelId, setFastModelId, { label: '', autoRefreshDomain: props.domainId });

  return (
    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart
        title={props.title}
        description={props.description}
        tooltip={props.tooltip}
      />
      {llmComponent}
    </FormControl>
  );
}


export function AppChatSettingsAI() {

  const {
    autoSuggestAttachmentPrompts, setAutoSuggestAttachmentPrompts,
    autoSuggestDiagrams, setAutoSuggestDiagrams,
    autoSuggestHTMLUI, setAutoSuggestHTMLUI,
    // autoSuggestQuestions, setAutoSuggestQuestions,
    autoTitleChat, setAutoTitleChat,
    chatKeepLastThinkingOnly, setChatKeepLastThinkingOnly,
  } = useChatAutoAI();

  const labsDevMode = useLabsDevMode();

  const showModelIcons = false; // useUIComplexityMode() === 'extra';

  // callbacks

  const handleAutoSetChatTitleChange = (event: React.ChangeEvent<HTMLInputElement>) => setAutoTitleChat(event.target.checked);

  const handleAutoSuggestAttachmentPromptsChange = (event: React.ChangeEvent<HTMLInputElement>) => setAutoSuggestAttachmentPrompts(event.target.checked);

  const handleAutoSuggestDiagramsChange = (event: React.ChangeEvent<HTMLInputElement>) => setAutoSuggestDiagrams(event.target.checked);

  const handleAutoSuggestHTMLUIChange = (event: React.ChangeEvent<HTMLInputElement>) => setAutoSuggestHTMLUI(event.target.checked);

  // const handleAutoSuggestQuestionsChange = (event: React.ChangeEvent<HTMLInputElement>) => setAutoSuggestQuestions(event.target.checked);

  return <>

    <FormControlDomainModel
      domainId='codeApply'
      title={!showModelIcons ? 'Coding model' : <><CodeIcon color='primary' sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Coding model</>}
      description='Code tasks'
      tooltip={<>
        Smart <b>code editing</b> model (must support Tool Calls) with great coding skills and not too slow. Used for:
        <ul>
          <li>Diagrams generation</li>
          <li>HTML UI generation</li>
          <li>Forward compatibility</li>
        </ul>
        Ideally select a Sonnet 3.5-class model.
      </>}
    />

    <FormControlDomainModel
      domainId='fastUtil'
      title={!showModelIcons ? 'Utility model' : <><EditRoundedIcon color='primary' sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Utility model</>}
      description='Titles, misc tasks'
      tooltip={<>
        Lightweight model (must support Tool Calls) used for &quot;fast&quot;, low-cost operations, such as:
        <ul>
          <li>Chat title generation</li>
          <li>Attachment prompts</li>
          <li>Drawing prompts</li>
          <li>And more</li>
        </ul>
        For chat messages and similar high-quality content, the chat model is used instead.
      </>}
    />

    {labsDevMode && (
      <FormControlDomainModel
        domainId='primaryChat'
        title={<><EngineeringIcon color='warning' sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Last used model</>}
        description='Chat fallback model'
        tooltip='The last used chat model, used as default for new conversations. This is a develoment setting used to test out auto-detection of the most fitting initial chat model.'
      />
    )}

    <FormSelectControl
      title='Reasoning traces'
      tooltip='Controls how AI thinking/reasoning blocks are kept in your chat history. Keeping only in the last message (default) reduces clutter.'
      options={_keepThinkingBlocksOptions}
      value={chatKeepLastThinkingOnly ? 'last-only' : 'all'}
      onChange={(value) => setChatKeepLastThinkingOnly(value === 'last-only')}
      selectSx={{ minWidth: 140 }}
    />

    <ListDivider inset='gutter'>Automatic AI Functions</ListDivider>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title='Chat Auto-Title'
                      description={autoTitleChat ? 'Auto' : 'Manual only'}
                      tooltip='[Utility model]  Automatically generates relevant titles for new chat conversations.'
                      tooltipWarning={!autoTitleChat} />
      <Switch checked={autoTitleChat} onChange={handleAutoSetChatTitleChange}
              endDecorator={autoTitleChat ? 'On' : 'Off'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title='Attachment Prompts'
                      description={autoSuggestAttachmentPrompts ? 'Guess Actions' : 'Off'}
                      tooltip={!autoSuggestAttachmentPrompts ? undefined : '[Utility model]  Suggests actions/prompts when attachments are added to the conversation.'} />
      <Switch checked={autoSuggestAttachmentPrompts} onChange={handleAutoSuggestAttachmentPromptsChange}
              endDecorator={autoSuggestAttachmentPrompts ? 'On' : 'Off'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>


    <ListDivider inset='gutter'>Auto-augment Messages</ListDivider>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title='Generative Diagrams'
                      description={autoSuggestDiagrams ? 'Add Diagrams' : 'Off'}
                      tooltip={!autoSuggestDiagrams ? undefined : '[Coding model]  Automatically creates visual diagrams and flowcharts when the AI detects that a response would be clearer with a visual representation.'} />
      <Switch checked={autoSuggestDiagrams} onChange={handleAutoSuggestDiagramsChange}
              endDecorator={autoSuggestDiagrams ? 'On' : 'Off'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart
        title='Generative UIs'
        description={autoSuggestHTMLUI ? 'Add HTML' : 'Off'}
        tooltipWarning={autoSuggestHTMLUI}
        tooltip={<>
          [Coding model] Creates interactive UI components within chat responses when appropriate.
          <hr />
          SECURITY WARNING: THIS TURNS ON JS/HTML CODE EXECUTION WITHIN CHAT MESSAGES
          <hr />
          ALPHA QUALITY FOR TESTING ONLY. Use at your own risk.
        </>}
      />
      <Switch checked={autoSuggestHTMLUI} onChange={handleAutoSuggestHTMLUIChange}
              endDecorator={autoSuggestHTMLUI ? <div>On{' '}<WarningRoundedIcon sx={{ cursor: 'pointer', color: 'red' }} /></div> : 'Off'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>

    {/*<FormControl disabled orientation='horizontal' sx={{ justifyContent: 'space-between' }}>*/}
    {/*  <FormLabelStart title='Auto Questions'*/}
    {/*                  description={autoSuggestQuestions ? 'LLM Questions' : 'No'}*/}
    {/*                  tooltip={<>Vote <Link href='https://github.com/enricoros/big-agi/issues/228' target='_blank'>#228</Link></>} />*/}
    {/*  <Switch checked={autoSuggestQuestions} onChange={handleAutoSuggestQuestionsChange}*/}
    {/*          endDecorator={autoSuggestQuestions ? 'On' : 'Off'}*/}
    {/*          slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />*/}
    {/*</FormControl>*/}

  </>;
}



================================================
FILE: src/apps/settings-modal/SettingsModal.tsx
================================================
import * as React from 'react';
import { Accordion, AccordionDetails, accordionDetailsClasses, AccordionGroup, AccordionSummary, accordionSummaryClasses, Avatar, Box, Button, ListItemContent, styled, Tab, TabList, TabPanel, Tabs } from '@mui/joy';
import AddIcon from '@mui/icons-material/Add';
import AutoAwesomeIcon from '@mui/icons-material/AutoAwesome';
import KeyboardCommandKeyOutlinedIcon from '@mui/icons-material/KeyboardCommandKeyOutlined';
import LanguageRoundedIcon from '@mui/icons-material/LanguageRounded';
import MicIcon from '@mui/icons-material/Mic';
import RecordVoiceOverIcon from '@mui/icons-material/RecordVoiceOver';
import ScienceIcon from '@mui/icons-material/Science';
import SearchIcon from '@mui/icons-material/Search';
import TerminalOutlinedIcon from '@mui/icons-material/TerminalOutlined';

import { BrowseSettings } from '~/modules/browse/BrowseSettings';
import { DallESettings } from '~/modules/t2i/dalle/DallESettings';
import { ElevenlabsSettings } from '~/modules/elevenlabs/ElevenlabsSettings';
import { GoogleSearchSettings } from '~/modules/google/GoogleSearchSettings';
import { T2ISettings } from '~/modules/t2i/T2ISettings';

import type { PreferencesTabId } from '~/common/layout/optima/store-layout-optima';
import { AppBreadcrumbs } from '~/common/components/AppBreadcrumbs';
import { DarkModeToggleButton, darkModeToggleButtonSx } from '~/common/components/DarkModeToggleButton';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { Is } from '~/common/util/pwaUtils';
import { optimaActions } from '~/common/layout/optima/useOptima';
import { useIsMobile } from '~/common/components/useMatchMedia';

import { AppChatSettingsAI } from './AppChatSettingsAI';
import { AppChatSettingsUI } from './settings-ui/AppChatSettingsUI';
import { UxLabsSettings } from './UxLabsSettings';
import { VoiceSettings } from './VoiceSettings';


// configuration
const TAB_RADIUS = 'md';
const COLOR_TAB_LIST = 'primary';
const COLOR_TOPIC_ICON = 'primary';


// styled <AccordionGroup variant='plain'> into a Topics component
const Topics = styled(AccordionGroup)({
  // round and clip corners
  borderRadius: `calc(var(--joy-radius-${TAB_RADIUS}) - 1px)`, // compensates for a half-pixel weirdness
  overflow: 'hidden',

  // larger summary, with a spinning icon
  [`& .${accordionSummaryClasses.button}`]: {
    minHeight: 64,
  },
  [`& .${accordionSummaryClasses.indicator}`]: {
    transition: '0.2s',
  },
  [`& [aria-expanded="true"] .${accordionSummaryClasses.indicator}`]: {
    transform: 'rotate(45deg)',
  },

  // larger padded block
  [`& .${accordionDetailsClasses.content}.${accordionDetailsClasses.expanded}`]: {
    paddingBlock: '1rem',
  },
});

function Topic(props: { title?: React.ReactNode, icon?: string | React.ReactNode, startCollapsed?: boolean, children?: React.ReactNode }) {

  // state
  const [expanded, setExpanded] = React.useState(props.startCollapsed !== true);

  // derived state
  const hideTitleBar = !props.title && !props.icon;

  return (
    <Accordion
      expanded={expanded || hideTitleBar}
      onChange={(_event, expanded) => setExpanded(expanded)}
      sx={{
        '&:not(:last-child)': {
          borderBottomColor: 'primary.softActiveBg',
        },
        '&:last-child': {
          borderBottom: 'none',
        },
      }}
    >

      {!hideTitleBar && (
        <AccordionSummary
          color='primary'
          variant={expanded ? 'plain' : 'soft'}
          indicator={<AddIcon />}
          slotProps={!expanded ? undefined : {
            button: { sx: { backgroundColor: 'rgba(var(--joy-palette-primary-lightChannel) / 0.2)' } },
          }}
        >
          {!!props.icon && (
            <Avatar
              color={COLOR_TOPIC_ICON}
              variant={expanded ? 'plain' /* was: soft */ : 'plain'}
              // size='sm'
            >
              {props.icon}
            </Avatar>
          )}
          <ListItemContent sx={{ color: `${COLOR_TOPIC_ICON}.softColor` }}>
            {props.title}
          </ListItemContent>
        </AccordionSummary>
      )}

      <AccordionDetails
        slotProps={{
          content: {
            sx: {
              px: { xs: 1.5, md: 2 },
            },
          },
        }}
      >
        <Box sx={{
          display: 'grid',
          gap: 2, // keep in sync with ProviderConfigure > ExpanderControlledBox > Card > CardContent (Draw App)
        }}>
          {props.children}
        </Box>
      </AccordionDetails>

    </Accordion>
  );
}


const _styles = {

  // modal: undefined,
  modal: {
    backgroundColor: 'background.level1',
  } as const,

  tabs: {
    backgroundColor: 'transparent',
  } as const,

  tabsList: {
    backgroundColor: `${COLOR_TAB_LIST}.softHoverBg`,
    mb: 2,
    p: 0.5,
    // borderRadius: '2rem',
    borderRadius: TAB_RADIUS,
    fontSize: 'md',
    fontWeight: 'md',
    boxShadow: `inset 1px 1px 4px -3px var(--joy-palette-${COLOR_TAB_LIST}-solidHoverBg)`,
    gap: 0.5,
  } as const,

  tabsListTab: {
    // borderRadius: '2rem',
    borderRadius: 'sm',
    flex: 1,
    p: 0,
    '&[aria-selected="true"]': {
      // color: 'primary.plainColor',
      bgcolor: 'background.popup',
      // color: `${COLOR_TAB_LIST}.solidColor`,
      // bgcolor: `${COLOR_TAB_LIST}.solidBg`,
      boxShadow: 'xs',
      fontWeight: 'lg',
      zIndex: 1,
    } as const,
    // '&:hover': {
    //   backgroundColor: 'background.level1',
    // } as const,
  } as const,

  tabPanel: {
    boxShadow: 'xs',
    backgroundColor: 'background.surface',
    borderRadius: TAB_RADIUS,
    p: 0,
    // p: 'var(--Tabs-gap)',
  } as const,

} as const;


/**
 * Component that allows the User to modify the application settings,
 * persisted on the client via localStorage.
 */
export function SettingsModal(props: {
  open: boolean,
  tab: PreferencesTabId,
  setTab: (index: PreferencesTabId) => void,
  onClose: () => void,
  onOpenShortcuts: () => void,
}) {

  // external state
  const isMobile = useIsMobile();

  // handlers

  const { setTab } = props;
  const isToolsTab = props.tab === 'tools';
  const enableAixDebugger = Is.Deployment.Localhost;

  const handleSetTab = React.useCallback((_event: any, value: string | number | null) => {
    setTab((value ?? undefined) as PreferencesTabId);
  }, [setTab]);

  return (
    <GoodModal
      // title='Preferences' strongerTitle
      title={
        <AppBreadcrumbs size='md' rootTitle='App'>
          <AppBreadcrumbs.Leaf><b>Preferences</b></AppBreadcrumbs.Leaf>
        </AppBreadcrumbs>
      }
      open={props.open} onClose={props.onClose}
      startButton={
        <Box sx={{ display: 'flex', gap: 1, alignItems: 'center' }}>
          {!isToolsTab && <DarkModeToggleButton hasText />}
          {!isMobile && !isToolsTab && <Button variant='soft' color='neutral' onClick={props.onOpenShortcuts} startDecorator={<KeyboardCommandKeyOutlinedIcon color='primary' />} sx={darkModeToggleButtonSx}>
            Shortcuts
          </Button>}
          {isToolsTab && <Button variant='soft' color='neutral' onClick={optimaActions().openLogger} startDecorator={<TerminalOutlinedIcon color='primary' />} sx={darkModeToggleButtonSx}>
            Logs Viewer
          </Button>}
          {isToolsTab && <Button variant='soft' color='neutral' disabled={!enableAixDebugger} onClick={optimaActions().openAIXDebugger} startDecorator={<TerminalOutlinedIcon color={enableAixDebugger ? 'primary' : undefined} />} sx={darkModeToggleButtonSx}>
            AIX Debugger
          </Button>}
        </Box>
      }
      sx={_styles.modal}
    >

      {/*<Divider />*/}

      <Tabs
        aria-label='Settings tabbed menu'
        value={props.tab || 'chat'}
        onChange={handleSetTab}
        sx={_styles.tabs}
      >
        <TabList
          size='sm'
          disableUnderline
          sx={_styles.tabsList}
        >
          <Tab value='chat' disableIndicator sx={_styles.tabsListTab}>Chat</Tab>
          <Tab value='voice' disableIndicator sx={_styles.tabsListTab}>Voice</Tab>
          <Tab value='draw' disableIndicator sx={_styles.tabsListTab}>Draw</Tab>
          <Tab value='tools' disableIndicator sx={_styles.tabsListTab}>Tools</Tab>
        </TabList>

        <TabPanel value='chat' variant='outlined' sx={_styles.tabPanel}>
          <Topics>
            <Topic>
              <AppChatSettingsUI />
            </Topic>
            <Topic icon={<AutoAwesomeIcon />} title={
              'Chat AI'
              // <>Chat AI <WarningRoundedIcon sx={{ ml: 1, color: 'orangered' }} /></>
            } startCollapsed>
              <AppChatSettingsAI />
            </Topic>
            <Topic icon={<ScienceIcon />} title='Labs' startCollapsed>
              <UxLabsSettings />
            </Topic>
          </Topics>
        </TabPanel>

        <TabPanel value='voice' variant='outlined' sx={_styles.tabPanel}>
          <Topics>
            <Topic icon={/*'🎙️'*/ <MicIcon />} title='Microphone'>
              <VoiceSettings />
            </Topic>
            <Topic icon={/*'📢'*/ <RecordVoiceOverIcon />} title='ElevenLabs API'>
              <ElevenlabsSettings />
            </Topic>
          </Topics>
        </TabPanel>

        <TabPanel value='draw' variant='outlined' sx={_styles.tabPanel}>
          <Topics>
            <Topic>
              <T2ISettings />
            </Topic>
            <Topic icon='🖍️️' title='OpenAI'>
              <DallESettings />
            </Topic>
          </Topics>
        </TabPanel>

        <TabPanel value='tools' variant='outlined' sx={_styles.tabPanel}>
          <Topics>
            <Topic icon={<LanguageRoundedIcon />} title='Browse Web Pages'>
              <BrowseSettings />
            </Topic>
            <Topic icon={<SearchIcon />} title='Web Search · Google API' startCollapsed>
              <GoogleSearchSettings />
            </Topic>
            {/*<Topic icon='🛠' title='Other tools...' />*/}
          </Topics>
        </TabPanel>
      </Tabs>

      {/*<Divider />*/}

    </GoodModal>
  );
}



================================================
FILE: src/apps/settings-modal/ShortcutsModal.tsx
================================================
import * as React from 'react';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import { GoodModal } from '~/common/components/modals/GoodModal';
import { platformAwareKeystrokes } from '~/common/components/KeyStroke';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUIContentScaling } from '~/common/stores/store-ui';


const shortcutsMd = platformAwareKeystrokes(`

| Shortcut         | Description                             |
|------------------|-----------------------------------------|
| **Edit**         |                                         |
| Shift + Enter    | Newline                                 |
| Alt + Enter      | Append (no response)                    |
| Ctrl + Enter     | Beam (and start all Beams)              |
| Ctrl + Shift + Z | **Regenerate** last message             |
| Ctrl + Shift + B | **Beam** last message                   |
| Ctrl + Shift + F | Attach file                             |
| Ctrl + Shift + V | Attach clipboard (better than Ctrl + V) |
| Ctrl + M         | Microphone (voice typing)               |
| Ctrl + L         | Change Model                            |
| Ctrl + P         | Change Persona                          |
| **Chats**        |                                         |
| Ctrl + O         | Open Chat ...                           |
| Ctrl + S         | Save Chat ...                           |
| Ctrl + Shift + N | **New** chat                            |
| Ctrl + Shift + X | **Reset** chat                          |
| Ctrl + Shift + D | **Delete** chat                         |
| Ctrl + Up        | Previous message/Beam (shift for top)   |
| Ctrl + Down      | Next message/Beam (shift to bottom)     |
| Ctrl + [         | **Previous** chat (in history)          |
| Ctrl + ]         | **Next** chat (in history)              |
| **Settings**     |                                         |
| Ctrl + ,         | ⚙️ Preferences                          |
| Ctrl + Shift + M | 🧠 Models                               |
| Ctrl + Shift + O | 💬 Options (current Chat Model)         |
| Ctrl + Shift + + | Increase Text Size                      |
| Ctrl + Shift + - | Decrease Text Size                      |
| Ctrl + Shift + / | Shortcuts                               |

`).trim();


export function ShortcutsModal(props: { onClose: () => void }) {

  // external state
  const isMobile = useIsMobile();
  const contentScaling = useUIContentScaling();

  return (
    <GoodModal open title='Desktop Shortcuts' onClose={props.onClose}>
      <ScaledTextBlockRenderer
        text={shortcutsMd}
        contentScaling={contentScaling}
        textRenderVariant='markdown'
      />
    </GoodModal>
  );
}



================================================
FILE: src/apps/settings-modal/UxLabsSettings.tsx
================================================
import * as React from 'react';

import { FormControl, Switch, Typography } from '@mui/joy';
import AddAPhotoIcon from '@mui/icons-material/AddAPhoto';
import CodeIcon from '@mui/icons-material/Code';
import EditNoteIcon from '@mui/icons-material/EditNote';
import EngineeringIcon from '@mui/icons-material/Engineering';
import LocalAtmOutlinedIcon from '@mui/icons-material/LocalAtmOutlined';
import ScreenshotMonitorIcon from '@mui/icons-material/ScreenshotMonitor';
import ShortcutIcon from '@mui/icons-material/Shortcut';
import SpeedIcon from '@mui/icons-material/Speed';
import TitleIcon from '@mui/icons-material/Title';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormSwitchControl } from '~/common/components/forms/FormSwitchControl';
import { Is } from '~/common/util/pwaUtils';
import { Link } from '~/common/components/Link';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUXLabsStore } from '~/common/stores/store-ux-labs';


// uncomment for more settings
export const DEV_MODE_SETTINGS = false;


export function UxLabsSettings() {

  // external state
  const isMobile = useIsMobile();
  const {
    labsAttachScreenCapture, setLabsAttachScreenCapture,
    labsCameraDesktop, setLabsCameraDesktop,
    labsChatBarAlt, setLabsChatBarAlt,
    labsEnhanceCodeBlocks, setLabsEnhanceCodeBlocks,
    labsHighPerformance, setLabsHighPerformance,
    labsShowCost, setLabsShowCost,
    labsAutoHideComposer, setLabsAutoHideComposer,
    labsShowShortcutBar, setLabsShowShortcutBar,
    labsDevMode, setLabsDevMode,
    labsDevNoStreaming, setLabsDevNoStreaming,
  } = useUXLabsStore();

  return <>

    {/* [DEV MODE] Settings */}

    {(Is.Deployment.Localhost || labsDevMode) && (
      <FormSwitchControl
        title={<><EngineeringIcon color='warning' sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Developer Mode</>} description={labsDevMode ? 'Enabled' : 'Disabled'}
        checked={labsDevMode} onChange={setLabsDevMode}
      />
    )}

    {labsDevMode && (
      <FormSwitchControl
        title={<><EngineeringIcon color='warning' sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Disable Streaming</>} description={labsDevNoStreaming ? 'Enabled' : 'Disabled'}
        checked={labsDevNoStreaming} onChange={setLabsDevNoStreaming}
      />
    )}

    {/* Non-Graduated Settings */}

    <FormSwitchControl
      title={<><CodeIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Enhance Legacy Code</>} description={labsEnhanceCodeBlocks ? 'Auto-Enhance' : 'Disabled'}
      checked={labsEnhanceCodeBlocks} onChange={setLabsEnhanceCodeBlocks}
    />

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart
        title={<><SpeedIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Unlock Refresh</>}
        description={labsHighPerformance ? 'Unlocked' : 'Default'}
        tooltipWarning={labsHighPerformance}
        tooltip={<>
          Unlocks the maximum UI refresh rate for Chats and Beams, and will draw every single token as they come in.
          <hr />
          THIS MAY CAUSE HIGH CPU USAGE, BATTERY DRAIN, AND STUTTERING WITH FAST MODELS.
          <hr />
          Default: OFF
        </>}
      />
      <Switch checked={labsHighPerformance} onChange={event => setLabsHighPerformance(event.target.checked)}
              endDecorator={labsHighPerformance ? 'On' : 'Off'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>

    {DEV_MODE_SETTINGS && <FormSwitchControl
      title={<><TitleIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Chat Title</>} description={labsChatBarAlt === 'title' ? 'Show Title' : 'Show Models'}
      checked={labsChatBarAlt === 'title'} onChange={(on) => setLabsChatBarAlt(on ? 'title' : false)}
    />}

    {!isMobile && <FormSwitchControl
      title={<><ScreenshotMonitorIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} /> Screen Capture</>} description={labsAttachScreenCapture ? 'Enabled' : 'Disabled'}
      checked={labsAttachScreenCapture} onChange={setLabsAttachScreenCapture}
    />}

    {!isMobile && <FormSwitchControl
      title={<><AddAPhotoIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} /> Webcam Capture</>} description={/*'v1.8 · ' +*/ (labsCameraDesktop ? 'Enabled' : 'Disabled')}
      checked={labsCameraDesktop} onChange={setLabsCameraDesktop}
    />}

    <FormSwitchControl
      title={<><LocalAtmOutlinedIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Cost of messages</>} description={labsShowCost ? 'Show when available' : 'Disabled'}
      checked={labsShowCost} onChange={setLabsShowCost}
    />

    {!isMobile && <FormSwitchControl
      title={<><ShortcutIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Shortcuts Bar</>} description={labsShowShortcutBar ? 'Status Bar' : 'Disabled'}
      checked={labsShowShortcutBar} onChange={setLabsShowShortcutBar}
    />}

    <FormSwitchControl
      title={<><EditNoteIcon sx={{ fontSize: 'lg', mr: 0.5, mb: 0.25 }} />Auto-hide input</>} description={labsAutoHideComposer ? 'Hover to show' : 'Always visible'}
      checked={labsAutoHideComposer} onChange={setLabsAutoHideComposer}
    />

    {/*
      Other Graduated (removed or backlog):
        - <Link href='https://github.com/enricoros/big-AGI/issues/359' target='_blank'>Draw App</Link>
        - Text Tools: dinamically shown where applicable (e.g. Diff)
        - Chat Mode: follow-ups; moved to Chat Advanced UI
    */}

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Graduated' description='Ex-labs' />
      <Typography level='body-xs'>
        <Link href='https://big-agi.com/blog/beam-multi-model-ai-reasoning' target='_blank'>Beam</Link>
        {' · '}<Link href='https://github.com/enricoros/big-AGI/issues/208' target='_blank'>Split Chats</Link>
        {' · '}<Link href='https://github.com/enricoros/big-AGI/issues/354' target='_blank'>Call AGI</Link>
        {' · '}<Link href='https://github.com/enricoros/big-AGI/issues/282' target='_blank'>Persona Creator</Link>
        {' · '}<Link href='https://github.com/enricoros/big-agi/issues/192' target='_blank'>Auto Diagrams</Link>
        {' · '}Imagine · Chat Search · Text Tools · LLM Overheat
      </Typography>
    </FormControl>

  </>;
}


================================================
FILE: src/apps/settings-modal/VoiceSettings.tsx
================================================
import * as React from 'react';

import { FormControl } from '@mui/joy';

import { useChatMicTimeoutMs } from '../chat/store-app-chat';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormRadioControl } from '~/common/components/forms/FormRadioControl';
import { LanguageSelect } from '~/common/components/LanguageSelect';
import { useIsMobile } from '~/common/components/useMatchMedia';


export function VoiceSettings() {

  // external state
  const isMobile = useIsMobile();
  const [chatTimeoutMs, setChatTimeoutMs] = useChatMicTimeoutMs();


  // this converts from string keys to numbers and vice versa
  const chatTimeoutValue: string = '' + chatTimeoutMs;
  const setChatTimeoutValue = (value: string) => value && setChatTimeoutMs(parseInt(value));

  return <>

    {/* LanguageSelect: moved from the UI settings (where it logically belongs), just to group things better from an UX perspective */}
    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Language'
                      description='ASR and TTS'
                      tooltip='Currently for Microphone input and Voice output. Microphone support varies by browser (iPhone/Safari lacks speech input). We will use the ElevenLabs MultiLanguage model if a language other than English is selected.' />
      <LanguageSelect />
    </FormControl>

    {!isMobile && <FormRadioControl
      title='Mic Timeout'
      description={chatTimeoutMs < 1000 ? 'Best for quick calls' : chatTimeoutMs > 5000 ? 'Best for thinking' : 'Standard'}
      options={[
        { value: '600', label: '.6s' },
        { value: '2000', label: '2s' },
        { value: '5000', label: '5s' },
        { value: '15000', label: '15s' },
      ]}
      value={chatTimeoutValue} onChange={setChatTimeoutValue}
    />}

  </>;
}


================================================
FILE: src/apps/settings-modal/settings-ui/AppChatSettingsUI.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Button, FormControl, Switch } from '@mui/joy';
import BuildCircleIcon from '@mui/icons-material/BuildCircle';
import WidthNormalIcon from '@mui/icons-material/WidthNormal';
import WidthWideIcon from '@mui/icons-material/WidthWide';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormRadioControl } from '~/common/components/forms/FormRadioControl';
import { useUIPreferencesStore } from '~/common/stores/store-ui';
import { isPwa } from '~/common/util/pwaUtils';
import { optimaOpenModels } from '~/common/layout/optima/useOptima';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useModelsZeroState } from '~/common/stores/llms/hooks/useModelsZeroState';

import { SettingUIComplexity } from './SettingUIComplexity';
import { SettingUIComposerQuickButton } from './SettingUIComposerQuickButton';
import { SettingUIContentScaling } from './SettingUIContentScaling';


// configuration
const SHOW_MARKDOWN_DISABLE_SETTING = false;
const SHOW_PURPOSE_FINDER = false;


const OptionsPageSize = [
  { value: 'narrow', label: <WidthNormalIcon sx={{ width: 25, height: 24, mt: -0.25 }} /> },
  { value: 'wide', label: <WidthWideIcon sx={{ width: 25, height: 24, mt: -0.25 }} /> },
  { value: 'full', label: 'Full' },
] as const;


function ModelsSetupButton(props: { isMissingModels?: boolean }) {
  return <Button
    // variant='soft' color='success'
    color={props.isMissingModels ? 'danger' : undefined}
    onClick={optimaOpenModels}
    startDecorator={<BuildCircleIcon />}
    sx={{
      '--Icon-fontSize': 'var(--joy-fontSize-xl2)',
      minWidth: 150,
      boxShadow: props.isMissingModels ? 'lg' : undefined,
    }}
  >
    {/*Admin Models*/}
    AI Models
  </Button>;
}


export function AppChatSettingsUI() {

  // external state
  const isMobile = useIsMobile();
  const isMissingModels = useModelsZeroState();
  const {
    centerMode, setCenterMode,
    disableMarkdown, setDisableMarkdown,
    doubleClickToEdit, setDoubleClickToEdit,
    enterIsNewline, setEnterIsNewline,
    showPersonaFinder, setShowPersonaFinder,
  } = useUIPreferencesStore(useShallow(state => ({
    centerMode: state.centerMode, setCenterMode: state.setCenterMode,
    disableMarkdown: state.disableMarkdown, setDisableMarkdown: state.setDisableMarkdown,
    doubleClickToEdit: state.doubleClickToEdit, setDoubleClickToEdit: state.setDoubleClickToEdit,
    enterIsNewline: state.enterIsNewline, setEnterIsNewline: state.setEnterIsNewline,
    showPersonaFinder: state.showPersonaFinder, setShowPersonaFinder: state.setShowPersonaFinder,
  })));

  const handleEnterIsNewlineChange = (event: React.ChangeEvent<HTMLInputElement>) => setEnterIsNewline(!event.target.checked);

  const handleDoubleClickToEditChange = (event: React.ChangeEvent<HTMLInputElement>) => setDoubleClickToEdit(event.target.checked);

  const handleDisableMarkdown = (event: React.ChangeEvent<HTMLInputElement>) => setDisableMarkdown(event.target.checked);

  const handleShowSearchBarChange = (event: React.ChangeEvent<HTMLInputElement>) => setShowPersonaFinder(event.target.checked);

  return <>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='AI Models'
                      description='Configure' />
      <ModelsSetupButton isMissingModels={isMissingModels} />
    </FormControl>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title='Enter sends ⏎'
                      description={enterIsNewline ? 'New line' : 'Sends message'} />
      <Switch checked={!enterIsNewline} onChange={handleEnterIsNewlineChange}
              endDecorator={enterIsNewline ? 'Off' : 'On'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>

    {SHOW_MARKDOWN_DISABLE_SETTING && (
      <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
        <FormLabelStart title='Disable Markdown'
                        description={disableMarkdown ? 'As text' : 'Render markdown'} />
        <Switch checked={disableMarkdown} onChange={handleDisableMarkdown}
                endDecorator={disableMarkdown ? 'On' : 'Off'}
                slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
      </FormControl>
    )}

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title={isMobile ? 'Edit Mode' : 'Easy Edit'}
                      description={doubleClickToEdit ? (isMobile ? 'Double tap' : 'Double click') : (isMobile ? 'Menu' : 'Shift + double-click')} />
      <Switch checked={doubleClickToEdit} onChange={handleDoubleClickToEditChange}
              endDecorator={doubleClickToEdit ? 'On' : 'Off'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>

    {SHOW_PURPOSE_FINDER && <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title='Purpose finder'
                      description={showPersonaFinder ? 'Show search bar' : 'Hide search bar'} />
      <Switch checked={showPersonaFinder} onChange={handleShowSearchBarChange}
              endDecorator={showPersonaFinder ? 'On' : 'Off'}
              slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
    </FormControl>}

    <SettingUIContentScaling />

    {!isPwa() && !isMobile && (
      <FormRadioControl
        title='Page Size'
        description={centerMode === 'full' ? 'Full screen chat' : centerMode === 'narrow' ? 'Narrow chat' : 'Wide'}
        options={OptionsPageSize}
        value={centerMode} onChange={setCenterMode}
      />
    )}

    <SettingUIComplexity />

    {isMobile && <SettingUIComposerQuickButton />}

  </>;
}



================================================
FILE: src/apps/settings-modal/settings-ui/SettingUIComplexity.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { UIComplexityMode } from '~/common/app.theme';
import { FormSelectControl, FormSelectOption } from '~/common/components/forms/FormSelectControl';
import { useUIPreferencesStore } from '~/common/stores/store-ui';


const AppearanceOptions: FormSelectOption<UIComplexityMode>[] = [
  { value: 'minimal', label: 'Minimal', description: 'Clean' },
  { value: 'pro', label: 'Pro (default)', description: 'Perfect' },
  { value: 'extra', label: 'Extra', description: 'GIFs & more.' },
];

export function SettingUIComplexity(props: { noLabel?: boolean }) {

  // external state
  const [complexityMode, setComplexityMode] = useUIPreferencesStore(useShallow(state => [state.complexityMode, state.setComplexityMode]));

  return (
    <FormSelectControl
      title={props.noLabel ? undefined : 'Appearance'}
      options={AppearanceOptions}
      value={complexityMode}
      onChange={setComplexityMode}
      selectSx={{ minWidth: 150 }}
    />
  );
}



================================================
FILE: src/apps/settings-modal/settings-ui/SettingUIComposerQuickButton.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { FormSelectControl, FormSelectOption } from '~/common/components/forms/FormSelectControl';
import { useUIPreferencesStore } from '~/common/stores/store-ui';


const QuickOptions: FormSelectOption<'off' | 'call' | 'beam'>[] = [
  { value: 'beam', label: 'Beam', description: 'Beam it' },
  { value: 'call', label: 'Call', description: 'Call Persona' },
  { value: 'off', label: 'Off', description: 'Hide' },
];

export function SettingUIComposerQuickButton(props: { noLabel?: boolean }) {

  // external state
  const [composerQuickButton, setComposerQuickButton] = useUIPreferencesStore(useShallow(state => [state.composerQuickButton, state.setComposerQuickButton]));

  return (
    <FormSelectControl
      title={props.noLabel ? undefined : 'Quick Button'}
      options={QuickOptions}
      value={composerQuickButton}
      onChange={setComposerQuickButton}
      selectSx={{ minWidth: 150 }}
    />
  );
}



================================================
FILE: src/apps/settings-modal/settings-ui/SettingUIContentScaling.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { FormControl, IconButton, Step, Stepper } from '@mui/joy';

import type { ContentScaling } from '~/common/app.theme';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { useUIPreferencesStore } from '~/common/stores/store-ui';


export function SettingUIContentScaling(props: { noLabel?: boolean }) {

  // external state
  const [contentScaling, setContentScaling] = useUIPreferencesStore(useShallow(state => [state.contentScaling, state.setContentScaling]));

  return (
    <FormControl orientation='horizontal' sx={{ justifyContent: props.noLabel ? 'center' : 'space-between' }}>
      {!props.noLabel && (
        <FormLabelStart
          title='Text Size'
          description={contentScaling === 'xs' ? 'Dense' : contentScaling === 'sm' ? 'Default' : 'Larger'}
        />
      )}
      <Stepper sx={{
        maxWidth: 160,
        width: '100%',
        '--Step-connectorThickness': '2px',
        '--StepIndicator-size': '2rem',
      }}>
        {(['xs', 'sm', 'md'] as ContentScaling[]).map(sizeKey => {
          const isActive = sizeKey === contentScaling;
          return (
            <Step
              key={sizeKey}
              onClick={() => setContentScaling(sizeKey)}
              indicator={
                <IconButton
                  size='sm'
                  variant={isActive ? 'outlined' : 'soft'}
                  // color={isActive ? 'primary' : 'neutral'}
                  sx={{
                    // style
                    fontSize: sizeKey,
                    // 400 would be more representative because it's the default, but being in a button we're 500 (md) instead of 400.
                    //     However it's good to have that extra confidence when choosing a lower font size, as then while reading text
                    //     the 400 makes lots of sense.
                    // fontWeight: ...400?,
                    // borderRadius: !isActive ? '50%' : undefined,
                    borderRadius: '50%',
                    width: '1rem',
                    height: '1rem',
                    // style when active
                    '--variant-borderWidth': '2px',
                    borderColor: 'primary.solidBg',
                  }}
                >
                  {'Aa' /* Nothing says 'font' more than this */}
                </IconButton>
              }
            />
          );
        })}
      </Stepper>
    </FormControl>
  );
}


================================================
FILE: src/apps/tokens/AppTokens.tsx
================================================
import * as React from 'react';

import { Box, FormControl, Textarea, Typography } from '@mui/joy';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { lineHeightTextareaMd } from '~/common/app.theme';
import { preloadTiktokenLibrary, textTokensForEncodingId } from '~/common/tokens/tokens.text';
import { useTokenizerSelect } from '~/common/tokens/useTokenizerSelect';

import { AppSmallContainer } from '../AppSmallContainer';


function generateColor(index: number) {
  const hue = ((index + 1) * 137.508) % 360; // use golden angle approximation for color distribution
  return `hsl(${hue}, 80%, 80%)`;
}


export function AppTokens() {

  // Local state
  const [text, setText] = React.useState('');
  const [tokenizerId, _, tokenizerSelectComponent] = useTokenizerSelect('o200k_base');
  const [tokenDetails, setTokenDetails] = React.useState<{ token: number, chunk: string, bytes: string }[]>([]);


  // Ensure the Tiktoken library is preloaded
  React.useEffect(() => {
    preloadTiktokenLibrary().catch(console.error).then(() => setText('Welcome! Type or paste any text here to see the tokens.'));
  }, []);


  // If no text is set within 10 seconds, set a default text
  // React.useEffect(() => {
  //   if (text)
  //     return;
  //   const timer = setTimeout(() => {
  //     if (!text) {
  //       setText('Big-AGI\n\nIntelligence is a stream of tokens.');
  //     }
  //   }, 10000);
  //   return () => clearTimeout(timer);
  // }, [text]);


  const handleTextChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    setText(e.target.value);
  };

  const updateTokenDetails = (text: string, encodingId: string | null) => {
    if (encodingId) {
      const details = textTokensForEncodingId(text, encodingId, 'AppTokens');
      setTokenDetails(details || []);
    }
  };

  // when the text or tokenizer changes, update the token details
  React.useEffect(() => {
    tokenizerId && updateTokenDetails(text, tokenizerId);
  }, [text, tokenizerId]);


  return (
    <AppSmallContainer
      title='Tokens'
      description='Developer tool to see how AI reads your prompts, word by word.'
    >

      <Box sx={{ display: 'flex' }}>
        {tokenizerSelectComponent}
      </Box>

      <FormControl>
        <FormLabelStart title='Text' />
        <Textarea
          placeholder='Paste or type here...'
          value={text}
          onChange={handleTextChange}
          minRows={5}
          maxRows={10}
          endDecorator={
            <Box sx={{
              backgroundColor: 'background.surface', px: 0.5, py: 0.25, borderRadius: 'xs',
              width: '100%', lineHeight: 'lg', fontSize: 'xs',
              display: 'flex', flexFlow: 'row wrap', gap: 1, justifyContent: 'space-between',
            }}>
              <div>Token Count: {tokenDetails?.length || 0}</div>
              <div>Character Count: {text.length}</div>
            </Box>
          }
          sx={{
            '&:focus-within': { backgroundColor: 'background.popup' },
            lineHeight: lineHeightTextareaMd,
            // boxShadow: 'none',
            mb: 1.5,
          }}
        />

      </FormControl>

      {tokenDetails.length > 0 && (
        <Box sx={{ display: 'flex', flexDirection: 'column', gap: 1, mb: 4 }}>
          <Box sx={{
            // looks
            fontFamily: 'code',
            // fontWeight: 400,
            whiteSpace: 'pre-wrap',
            // backgroundColor: 'background.surface',
            // py: 2,

            // layout
            display: 'flex',
            flexWrap: 'wrap',
            alignItems: 'flex-start',
            gap: 0.25,
          }}>
            {tokenDetails.map((detail, index) => (
              <Box key={index} sx={{
                backgroundColor: generateColor(index),
                borderRadius: '0.2rem',
                padding: '0.1rem',
                boxShadow: 'xs',
              }}>
                {detail.chunk}
              </Box>
            ))}
          </Box>
        </Box>
      )}

      {tokenDetails.length > 0 && (
        <Box>
          <Typography level='title-lg' sx={{ mb: 1 }}>Token Details</Typography>
          <Box sx={{
            fontSize: 'sm',
            lineHeight: 'lg',

            display: 'grid',
            gridTemplateColumns: 'auto 1fr auto',
            columnGap: 2,
            rowGap: 0.25,
          }}>
            <div><b>Number</b></div>
            <div><b>Bytes</b></div>
            <div><b>Chunks</b></div>
            {tokenDetails.map((detail, index) => (
              <React.Fragment key={'t-' + detail.token + '-i-' + index}>
                <div style={{ textAlign: 'right' }}>{detail.token}</div>
                <div>{detail.bytes}</div>
                <div>
                  <span style={{
                    whiteSpace: 'pre-wrap',
                    background: generateColor(index),
                    display: 'inline-block',
                    padding: '1px 4px',
                    borderRadius: '2px',
                  }}>{detail.chunk}</span>
                </div>
              </React.Fragment>
            ))}
          </Box>
        </Box>
      )}

      <Typography level='body-sm'>
        Understanding tokenization helps create more effective AI prompts.
      </Typography>

    </AppSmallContainer>
  );
}


================================================
FILE: src/common/app.config.ts
================================================
/**
 * Application Identity (Brand)
 *
 * Also note that the 'Brand' is used in the following places:
 *  - README.md               all over
 *  - package.json            app-slug and version
 *  - [public/manifest.json]  name, short_name, description, theme_color, background_color
 */
export const Brand = {
  Title: {
    Base: 'big-AGI',
    Common: (process.env.NODE_ENV === 'development' ? '[DEV] ' : '') + 'big-AGI',
  },
  Meta: {
    Description: 'Launch big-AGI to unlock the full potential of AI, with precise control over your data and models. Voice interface, AI personas, advanced features, and fun UX.',
    SiteName: 'big-AGI | Precision AI for You',
    ThemeColor: '#32383E',
    TwitterSite: '@enricoros',
  },
  URIs: {
    Home: 'https://big-agi.com',
    // App: 'https://get.big-agi.com',
    CardImage: 'https://big-agi.com/icons/card-dark-1200.png',
    OpenRepo: 'https://github.com/enricoros/big-agi',
    OpenProject: 'https://github.com/users/enricoros/projects/4',
    SupportInvite: 'https://discord.gg/MkH4qj2Jp9',
    // Twitter: 'https://www.twitter.com/enricoros',
    PrivacyPolicy: 'https://big-agi.com/privacy',
    TermsOfService: 'https://big-agi.com/terms',
  },
  Docs: {
    Public: (docPage: string) => `https://big-agi.com/docs/${docPage}`,
  }
} as const;


================================================
FILE: src/common/app.nav.ts
================================================
import type { FunctionComponent } from 'react';

// App icons
import CallIcon from '@mui/icons-material/Call';
import CallOutlinedIcon from '@mui/icons-material/CallOutlined';
import DifferenceOutlinedIcon from '@mui/icons-material/DifferenceOutlined';
import Diversity2Icon from '@mui/icons-material/Diversity2';
import EventNoteIcon from '@mui/icons-material/EventNote';
import EventNoteOutlinedIcon from '@mui/icons-material/EventNoteOutlined';
import GrainIcon from '@mui/icons-material/Grain';
import ImageIcon from '@mui/icons-material/Image';
import ImageOutlinedIcon from '@mui/icons-material/ImageOutlined';
import IosShareIcon from '@mui/icons-material/IosShare';
import IosShareOutlinedIcon from '@mui/icons-material/IosShareOutlined';
// Link icons
import GitHubIcon from '@mui/icons-material/GitHub';
import { DiscordIcon } from '~/common/components/icons/3rdparty/DiscordIcon';
// Modal icons
import BuildCircleIcon from '@mui/icons-material/BuildCircle';
import SettingsIcon from '@mui/icons-material/Settings';


import { Brand } from '~/common/app.config';
import { ChatBeamIcon } from '~/common/components/icons/ChatBeamIcon';
import { PhChats } from '~/common/components/icons/phosphor/PhChats';
import { PhChatsDuotone } from '~/common/components/icons/phosphor/PhChatsDuotone';
import { hasNoChatLinkItems } from '~/modules/trade/link/store-share-link';


// enable to show all items, for layout development
const SHOW_ALL_APPS = false;

const SPECIAL_DIVIDER = '__DIVIDER__';


// Nav items

interface ItemBase {
  name: string,
  icon: FunctionComponent,
  iconActive?: FunctionComponent,
  tooltip?: string,
}

export interface NavItemApp extends ItemBase {
  type: 'app',
  mobileName?: string,
  route: string,
  landingRoute?: string,  // specify a different route than the nextjs page router route, to land to
  barTitle?: string,      // set to override the name as the bar title (unless custom bar content is used)
  hideOnMobile?: boolean, // set to true to hide the icon on mobile, unless this is the active app
  hideIcon?: boolean
    | (() => boolean),    // set to true to hide the icon, unless this is the active app
  hideBar?: boolean,      // set to true to hide the page bar
  hideDrawer?: boolean,   // set to true to hide the drawer
  panelAsMenu?: boolean,  // set to true to use the popup menu as the panel
  hideNav?: boolean
    | (() => boolean),    // set to hide the Nav bar (note: must have a way to navigate back)
  fullWidth?: boolean,    // set to true to override the user preference
  pageBrighter?: boolean, // set to true to make the page brighter (.surface instead of .level1)
  isDev?: boolean,        // show a 'dev mode' badge
  _delete?: boolean,      // delete from the UI
}

export interface NavItemModal extends ItemBase {
  type: 'modal',
  overlayId: 'settings' | 'models',
}

export interface NavItemExtLink extends ItemBase {
  type: 'extLink',
  href: string,
}

// interface MenuItemAction extends ItemBase {
//   type: 'action',
//   action: () => void,
// }


export const navItems: {
  apps: NavItemApp[],
  modals: NavItemModal[],
  links: NavItemExtLink[],
} = {

  // User-chosen apps
  apps: [
    {
      name: 'Chat',
      icon: PhChats, // was: TextsmsOutlinedIcon
      iconActive: PhChatsDuotone, // was: TextsmsIcon
      type: 'app',
      route: '/',
    },
    {
      name: 'Call',
      barTitle: 'Voice Calls',
      icon: CallOutlinedIcon,
      iconActive: CallIcon,
      type: 'app',
      route: '/call',
      hideDrawer: true,
      panelAsMenu: true,
      fullWidth: true,
    },
    // {
    //   name: 'Draw',
    //   icon: FormatPaintOutlinedIcon,
    //   iconActive: FormatPaintTwoToneIcon,
    //   type: 'app',
    //   route: '/draw',
    //   hideDrawer: true,
    //   // hideOnMobile: true,
    //   // isDev: true,
    //   _delete: true, // FIXME: not yet ready for prime time
    // },
    // {
    //   name: 'Cortex',
    //   icon: AutoAwesomeOutlinedIcon,
    //   iconActive: AutoAwesomeIcon,
    //   type: 'app',
    //   route: '/cortex',
    //   isDev: true,
    //   _delete: true,
    // },
    // {
    //   name: 'Patterns',
    //   icon: AccountTreeOutlinedIcon,
    //   iconActive: AccountTreeTwoToneIcon,
    //   type: 'app',
    //   route: '/patterns',
    //   isDev: true,
    //   _delete: true, // FIXME: not even begun
    // },
    // {
    //   name: 'Workspace',
    //   icon: WorkspacesOutlinedIcon,
    //   iconActive: WorkspacesIcon,
    //   type: 'app',
    //   route: '/workspace',
    //   hideDrawer: true,
    //   hideOnMobile: true,
    //   isDev: true,
    //   _delete: true, // FIXME: the all-in-one, not even begun
    // },
    // <-- divider here -->
    {
      name: SPECIAL_DIVIDER,
      type: 'app',
      route: SPECIAL_DIVIDER,
      icon: () => null,
    },
    {
      name: 'Create Personas',
      mobileName: 'Personas',
      icon: Diversity2Icon, // was: Outlined.. but they look the same
      // iconActive: Diversity2Icon,
      type: 'app',
      route: '/personas',
      hideBar: true,
    },
    {
      name: 'Compare Text',
      barTitle: 'Comparison',
      icon: DifferenceOutlinedIcon,
      type: 'app',
      route: '/diff',
      hideDrawer: true,
      hideOnMobile: true,
    },
    {
      name: 'Tokenize Text',
      barTitle: 'Tokenization',
      icon: GrainIcon,
      type: 'app',
      route: '/tokens',
      hideDrawer: true,
      hideOnMobile: true,
      hideIcon: true,
      isDev: true,
    },
    {
      name: 'Beam',
      icon: ChatBeamIcon,
      type: 'app',
      route: '/dev/beam',
      hideDrawer: true,
      hideIcon: true,
      isDev: true,
    },
    {
      name: 'Media Library',
      icon: ImageOutlinedIcon,
      iconActive: ImageIcon,
      type: 'app',
      route: '/media',
      isDev: true,
      _delete: true,
    },
    {
      name: 'Shared Chats',
      barTitle: 'Shared Chat',
      icon: IosShareOutlinedIcon,
      iconActive: IosShareIcon,
      type: 'app',
      route: '/link/chat/[chatLinkId]',
      landingRoute: '/link/chat/list',
      hideOnMobile: true,
      panelAsMenu: true,
      hideIcon: hasNoChatLinkItems,
      hideNav: hasNoChatLinkItems,
    },
    {
      name: 'News',
      icon: EventNoteOutlinedIcon,
      iconActive: EventNoteIcon,
      type: 'app',
      route: '/news',
      hideBar: true,
      hideDrawer: true,
      hideOnMobile: true,
    },
  ],

  // Modals
  modals: [
    {
      name: 'Configure AI Models',
      icon: BuildCircleIcon,
      type: 'modal',
      overlayId: 'models',
    },
    {
      name: 'App Preferences',
      icon: SettingsIcon,
      type: 'modal',
      overlayId: 'settings',
    },
  ],

  // External links
  links: [
    // {
    //   type: 'extLink',
    //   name: 'X',
    //   icon: TwitterIcon,
    //   href: 'https://twitter.com',
    // },
    {
      type: 'extLink',
      name: 'Discord',
      icon: DiscordIcon,
      href: Brand.URIs.SupportInvite,
    },
    {
      type: 'extLink',
      name: 'GitHub',
      icon: GitHubIcon,
      href: Brand.URIs.OpenRepo,
    },
  ],

};

// apply UI filtering right away - do it here, once, and for all
navItems.apps = navItems.apps.filter(app => !app._delete || SHOW_ALL_APPS);

export function checkDivider(app?: NavItemApp) {
  return app?.name === SPECIAL_DIVIDER;
}

export function checkVisibileIcon(app: NavItemApp, isMobile: boolean, currentApp?: NavItemApp) {
  return app.hideOnMobile && isMobile ? false : app === currentApp ? true : typeof app.hideIcon === 'function' ? !app.hideIcon() : !app.hideIcon;
}

export function checkVisibleNav(app?: NavItemApp) {
  return !app ? false : typeof app.hideNav === 'function' ? !app.hideNav() : !app.hideNav;
}


================================================
FILE: src/common/app.queryclient.ts
================================================
import { QueryClient } from '@tanstack/react-query';


let queryClient: QueryClient | null = null;

export function reactQueryClientSingleton(): QueryClient {
  if (!queryClient) {
    queryClient = new QueryClient({
      defaultOptions: {
        queries: {
          retry: false,
          // call functions even when the network is disconnected; this makes 127.0.0.1 work, while probably not causing other issues
          networkMode: 'always',
          refetchOnWindowFocus: false,
        },
        mutations: {
          retry: false,
          networkMode: 'always',
        },
      },
    });
  }
  return queryClient;
}



================================================
FILE: src/common/app.release.ts
================================================
/**
 * Copyright (c) 2024 Enrico Ros
 *
 * This file is include by both the frontend and backend, however depending on the time
 * of the build, the values may be different.
 */


/**
 * We centralize here the version information of the app, to have a uniform configuration surface.
 */
export const Release = {
  // CHANGE ME - this is the tenant ID, 'dev' reserved for development only, 'open' reserved for GitHub
  TenantSlug: 'open',

  App: {
    versionCode: '2.0.0-open-rc3',       // 1.92.0 sequentially...
    versionName: 'Big-AGI 2',
  },

  // Future compatibility
  Features: {
    // ...
    BACKEND_REVALIDATE_INTERVAL: 6 * 60 * 60 * 1000, // 6 hours
    // DISABLE_PRECISE_TOKENIZER: false, // future optimization: disables the correct tokenizer fully or over a certain input size (e.g. 1k)
    LIGHTER_ANIMATIONS: false, // optimization: disables some animations for performance
  },

  // this is here to trigger revalidation of data, e.g. models refresh
  Monotonics: {
    Aix: 23,
    NewsVersion: 192,
  },

  // Frontend: pretty features
  TechLevels: {
    AIX: '1.1', Apply: '0.8', Beam: '2.0', LFS: '0.5', /*Precog: '0.1',*/ React: '1.5',
  },
  AiFunctions: [
    // from `ContextChatGenerate_schema`
    'auto-chart', 'auto-diagram', 'auto-ui',
    'chat-call', 'chat-compress', 'chat-persona', 'chat-summary', 'chat-title',
    'create-attach-prompts', 'create-image-prompt', 'create-persona',
    'diff-whole',
    'fixup',
    'reason-beam', 'reason-merge', 'reason-react',
  ],

  /**
   * We force explicit declaration of the caller.
   */
  buildInfo: (_type: 'frontend' | 'backend') => ({
    // **NOTE**: do not change var names here, as they're matched from this point forward
    //           between the frontend and backend to ensure runtime consistency.
    deploymentType: process.env.NEXT_PUBLIC_DEPLOYMENT_TYPE,
    pkgVersion: process.env.NEXT_PUBLIC_BUILD_PKGVER,
    gitSha: process.env.NEXT_PUBLIC_BUILD_HASH,
    timestamp: process.env.NEXT_PUBLIC_BUILD_TIMESTAMP,
  }),

  IsNodeDevBuild: process.env.NODE_ENV === 'development' as const,

} as const;


export const BaseProduct = {
  ReleaseNotes: '',
  SupportForm: (_userId?: string) => 'https://github.com/enricoros/big-agi/issues',
} as const;



================================================
FILE: src/common/app.routes.ts
================================================
//
// Application Routes
//
// We will centralize them here, for UI and routing purposes.
//
// noinspection Annotator

import Router, { useRouter } from 'next/router';

import type { AppCallIntent } from '../apps/call/AppCall';
import type { AppChatIntent } from '../apps/chat/AppChat';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';

import { isBrowser } from './util/pwaUtils';


export const ROUTE_INDEX = '/';
export const ROUTE_APP_CHAT = '/';
export const ROUTE_APP_CALL = '/call';
export const ROUTE_APP_LINK_CHAT = '/link/chat/[chatLinkId]';
export const ROUTE_APP_NEWS = '/news';
export const ROUTE_APP_PERSONAS = '/personas';
const ROUTE_CALLBACK_OPENROUTER = '/link/callback_openrouter';


// Get Paths

export const getCallbackUrl = (source: 'openrouter') => {
  const callbackUrl = new URL(window.location.href);
  switch (source) {
    case 'openrouter':
      callbackUrl.pathname = ROUTE_CALLBACK_OPENROUTER;
      break;
    default:
      throw new Error(`Unknown source: ${source}`);
  }
  return callbackUrl.toString();
};

export const getChatLinkRelativePath = (chatLinkId: string) => ROUTE_APP_LINK_CHAT
  .replace('[chatLinkId]', chatLinkId);

export function useRouterQuery<TQuery>(): TQuery {
  const { query } = useRouter();
  return (query || {}) as TQuery;
}

export function useRouterRoute(): string {
  const { route } = useRouter();
  return route;
}


/// Simple Navigation

export const navigateToIndex = navigateFn(ROUTE_INDEX);

export const navigateToNews = navigateFn(ROUTE_APP_NEWS);

export const navigateToPersonas = navigateFn(ROUTE_APP_PERSONAS);

export const navigateToChatLinkList = navigateFn(ROUTE_APP_LINK_CHAT.replace('[chatLinkId]', 'list'));

export const navigateBack = Router.back;

export const reloadPage = () => isBrowser && window.location.reload();

function navigateFn(path: string) {
  return (replace?: boolean): Promise<boolean> => Router[replace ? 'replace' : 'push'](path);
}


/// Launch Apps

export async function launchAppChat(conversationId?: DConversationId) {
  return Router.push(
    {
      pathname: ROUTE_APP_CHAT,
      query: !conversationId ? undefined : {
        initialConversationId: conversationId,
        // newChat?: 'voiceInput',
      } satisfies AppChatIntent,
    },
    ROUTE_APP_CHAT,
  );
}

export function launchAppCall(conversationId: string, personaId: string) {
  void Router.push(
    {
      pathname: ROUTE_APP_CALL,
      query: {
        conversationId,
        personaId,
        backTo: 'app-chat',
      } satisfies AppCallIntent,
    },
    // ROUTE_APP_CALL,
  ).then();
}


/// Query Params utilities

export function removeQueryParam(key: string): Promise<boolean> {
  const newQuery = { ...Router.query };
  delete newQuery[key];
  return Router.replace({ pathname: Router.pathname, query: newQuery }, undefined, { shallow: true });
}

/*export function removeQueryParams(keysToRemove: string[]): Promise<boolean> {
  const newQuery = { ...Router.query };
  keysToRemove.forEach(key => delete newQuery[key]);
  return Router.replace({ pathname: Router.pathname, query: newQuery }, undefined, { shallow: true });
}*/



================================================
FILE: src/common/app.theme.ts
================================================
import createCache, { StylisElement, StylisPlugin } from '@emotion/cache';

import { Inter, JetBrains_Mono } from 'next/font/google';
import { extendTheme } from '@mui/joy';

import { animationEnterBelow } from '~/common/util/animUtils';


// Definitions
export type UIComplexityMode = 'minimal' | 'pro' | 'extra';
export type ContentScaling = 'xs' | 'sm' | 'md';


// CSS utils
export const hideOnMobile = { display: { xs: 'none', md: 'flex' } };


// Theme & Fonts

const font = Inter({
  weight: [ /* '300', sm */ '400' /* (undefined, default) */, '500' /* md */, '600' /* lg */, '700' /* xl */],
  subsets: ['latin'],
  display: 'swap',
  fallback: ['Helvetica', 'Arial', 'sans-serif'],
});
export const themeFontFamilyCss = font.style.fontFamily;

const jetBrainsMono = JetBrains_Mono({
  weight: ['400', '500', '600', '700'],
  subsets: ['latin'],
  display: 'swap',
  fallback: ['monospace'],
});
export const themeCodeFontFamilyCss = jetBrainsMono.style.fontFamily;


export const createAppTheme = (uiComplexityMinimal: boolean) => extendTheme({
  fontFamily: {
    body: themeFontFamilyCss,
    display: themeFontFamilyCss,
    code: themeCodeFontFamilyCss,
  },
  colorSchemes: {
    light: {
      palette: {
        neutral: {
          plainColor: 'var(--joy-palette-neutral-800)',     // [700 -> 800] Dropdown menu: increase text contrast a bit
          solidBg: 'var(--joy-palette-neutral-700)',        // [500 -> 700] PageBar background & Button[solid]
          solidHoverBg: 'var(--joy-palette-neutral-800)',   // [600 -> 800] Buttons[solid]:hover
        },
        // primary [800] > secondary [700 -> 800] > tertiary [600] > icon [500 -> 700]
        text: {
          icon: 'var(--joy-palette-neutral-700)',           // <IconButton color='neutral' /> icon color
          secondary: 'var(--joy-palette-neutral-800)',      // increase contrast a bit
          // tertiary: 'var(--joy-palette-neutral-700)',       // increase contrast a bit
        },
        // popup [white] > surface [50] > level1 [100] > level2 [200] > level3 [300 -> unused] > body [white -> 300]
        background: {
          // New
          surface: 'var(--joy-palette-neutral-50, #FBFCFE)',
          level1: 'var(--joy-palette-neutral-100, #F0F4F8)',
          level2: 'var(--joy-palette-neutral-200, #DDE7EE)',
          body: 'var(--joy-palette-neutral-300, #CDD7E1)',
          // Former
          // body: 'var(--joy-palette-neutral-400, #9FA6AD)',
        },
      },
    },
    dark: {
      palette: {
        text: {
          // do not increase contrast - text.primary would scream at you
          // secondary: 'var(--joy-palette-neutral-100, #EAEEF6)',
          // tertiary: 'var(--joy-palette-neutral-400, #9FA6AD)',
        },
        background: {
          // New
          popup: '#24292c', // 3: #32383E, 1: #171A1C, 2: #25282B
          surface: 'var(--joy-palette-neutral-800, #171A1C)',
          level1: 'var(--joy-palette-neutral-900, #0B0D0E)',
          level2: 'var(--joy-palette-neutral-800, #171A1C)',
          body: '#060807',
          // Former: popup > surface [900] > level 1 [black], level 2 [800] > body [black]
        },
      },
    },
  },
  components: {
    /**
     * Input
     *  - remove the box-shadow: https://github.com/mui/material-ui/commit/8d4728df8a66d710660af96ac7ff3f86d2d26382
     */
    JoyInput: {
      styleOverrides: {
        root: {
          boxShadow: 'none',
        },
      },
    },

    /**
     * Select
     * - remove the box-shadow: https://github.com/mui/material-ui/commit/8d4728df8a66d710660af96ac7ff3f86d2d26382
     * */
    JoySelect: {
      styleOverrides: {
        root: {
          boxShadow: 'none',
        },
      },
    },

    /**
     * Badge
     * - add a 'color-feature' color, to be used with the FeatureBadge component
     */
    JoyBadge: {
      styleOverrides: {
        badge: ({ ownerState }) =>
          // HACK: we set this to 'color-feature' to force the theming to our liking
          (ownerState.color as any) !== 'color-feature' ? undefined : ({
            backgroundColor: '#0288D1',
          }),
      },
    },

    // JoyMenuItem: {
    //   styleOverrides: {
    //     root: {
    //       '--Icon-fontSize': '1rem', // smaller menu(s) icon - default is 1.25rem ('xl', 20px)
    //     },
    //   },
    // },

    JoyModal: {
      styleOverrides: {
        backdrop: !uiComplexityMinimal ? undefined : {
          backdropFilter: 'none',
          // backdropFilter: 'blur(2px)',
        },
        root: uiComplexityMinimal ? undefined : {
          '& .agi-animate-enter': {
            animation: `${animationEnterBelow} 0.16s ease-out`,
          },
        },
      },
    },

    /**
     * Switch: increase the size of the thumb, to a default iconButton
     * NOTE: do not use anything else than 'md' size
     */
    JoySwitch: {
      styleOverrides: {
        root: ({ ownerState }) => ({
          ...(ownerState.size === 'md' && {
            // '--Switch-trackWidth': '36px',
            // '--Switch-trackHeight': '22px',
            // '--Switch-thumbSize': '17px',
            '--Switch-thumbSize': '16px',
          }),
        }),
      },
    },
  },
});

export const themeBgApp = 'background.level1';
export const themeBgAppDarker = 'background.level2';
export const themeBgAppChatComposer = 'background.surface';

export const lineHeightChatTextMd = 1.75;
export const lineHeightTextareaMd = 1.75;

export const themeZIndexBeamView = 10;
export const themeZIndexPageBar = 25;
export const themeZIndexDesktopDrawer = 26;
export const themeZIndexDesktopPanel = 27;
export const themeZIndexDesktopNav = 30;
export const themeZIndexChatBubble = 50;
export const themeZIndexDragOverlay = 60;
export const themeZIndexOverMobileDrawer = 1301;


// Dynamic UI Sizing

export function adjustContentScaling(scaling: ContentScaling, offset?: number) {
  if (!offset) return scaling;
  const scalingArray = ['xs', 'sm', 'md'];
  const scalingIndex = scalingArray.indexOf(scaling);
  const newScalingIndex = Math.max(0, Math.min(scalingArray.length - 1, scalingIndex + offset));
  return scalingArray[newScalingIndex] as ContentScaling;
}

interface ContentScalingOptions {
  // BlocksRenderer
  blockCodeFontSize: string;
  blockCodeMarginY: number;
  blockFontSize: string;
  blockImageGap: number;
  blockLineHeight: string | number;
  // ChatMessage
  chatMessagePadding: number;
  fragmentButtonFontSize: string;
  // ChatDrawer
  chatDrawerItemSx: { '--ListItem-minHeight': string, fontSize: string };
  chatDrawerItemFolderSx: { '--ListItem-minHeight': string, fontSize: string };
  // OptimaPanelGroup
  optimaPanelGroupSize: 'sm' | 'md';
}

export const themeScalingMap: Record<ContentScaling, ContentScalingOptions> = {
  xs: {
    blockCodeFontSize: '0.75rem',
    blockCodeMarginY: 0.5,
    blockFontSize: 'xs',
    blockImageGap: 1,
    blockLineHeight: 1.666667,
    chatMessagePadding: 1,
    fragmentButtonFontSize: 'xs',
    chatDrawerItemSx: { '--ListItem-minHeight': '2.25rem', fontSize: 'sm' },          // 36px
    chatDrawerItemFolderSx: { '--ListItem-minHeight': '2.5rem', fontSize: 'sm' },     // 40px
    optimaPanelGroupSize: 'sm',
  },
  sm: {
    blockCodeFontSize: '0.75rem',
    blockCodeMarginY: 1,
    blockFontSize: 'sm',
    blockImageGap: 1.5,
    blockLineHeight: 1.714286,
    chatMessagePadding: 1.5,
    fragmentButtonFontSize: 'sm',
    chatDrawerItemSx: { '--ListItem-minHeight': '2.25rem', fontSize: 'sm' },
    chatDrawerItemFolderSx: { '--ListItem-minHeight': '2.5rem', fontSize: 'sm' },
    optimaPanelGroupSize: 'sm',
  },
  md: {
    blockCodeFontSize: '0.875rem',
    blockCodeMarginY: 1.5,
    blockFontSize: 'md',
    blockImageGap: 2,
    blockLineHeight: 1.75,
    chatMessagePadding: 2,
    fragmentButtonFontSize: 'sm',
    chatDrawerItemSx: { '--ListItem-minHeight': '2.5rem', fontSize: 'md' },           // 40px
    chatDrawerItemFolderSx: { '--ListItem-minHeight': '2.75rem', fontSize: 'md' },    // 44px
    optimaPanelGroupSize: 'md',
  },
  // lg: {
  //   chatDrawerFoldersLineHeight: '3rem',
  // },
};


// Emotion Cache (with insertion point on the SSR pass)

const isBrowser = typeof document !== 'undefined';

const emotionStylisPlugins: StylisPlugin[] = [

  /**
   * 1. remove the default prefixer plugin: probably not needed and bloating
   */
  // prefixer,

  /**
   * 2. add a function to remove wide-matching CSS rules from Joy UI.
   * Culprit: https://github.com/mui/material-ui/blob/a705e1f15075b2deb59263868bfa7b1d9f84cdd4/packages/mui-joy/src/Checkbox/Checkbox.tsx#L59
   * These '~ *' rules are slow and cause a lot of reflows.
   *
   * To validate, search the Elements tab for JoyCheckbox-root, and see if there's the '~ *' rule.
   */
  function removeSlowCSS(element: StylisElement /*, index, children, callback*/) {
    if (
      element.type === 'rule' // only operate on rules
      && element.value.endsWith('~*')  // where the selector is broad reaching
      && Array.isArray(element.children)  // and there are children (rules)
    ) {
      // console.log('✓ Filtering out problematic selector:', element);
      element.return = ' ';  // removes the selector (empirical)
      element.children = []; // removes the rule (empirical)
    }
  },

];


export function createEmotionCache() {
  let insertionPoint: HTMLElement | undefined;

  if (isBrowser) {
    // On the client side, _document.tsx has a meta tag with the name "emotion-insertion-point" at the top of the <head>.
    // This assures that MUI styles are loaded first, and allows allows developers to easily override MUI styles with other solutions like CSS modules.
    const emotionInsertionPoint = document.querySelector<HTMLMetaElement>(
      'meta[name="emotion-insertion-point"]',
    );
    insertionPoint = emotionInsertionPoint ?? undefined;
  }

  return createCache({ key: 'mui-style', insertionPoint: insertionPoint, stylisPlugins: emotionStylisPlugins });
}

// MISC

// For next April Fools' week
// export const foolsMode = new Date().getMonth() === 3 && new Date().getDate() <= 7;



================================================
FILE: src/common/attachment-drafts/attachment.dblobs.ts
================================================
import { addDBImageAsset, DBlobDBContextId, DBlobDBScopeId, deleteDBAsset, gcDBAssetsByScope, transferDBAssetContextScope } from '~/common/stores/blob/dblobs-portability';

import { CommonImageMimeTypes, imageBlobTransform, LLMImageResizeMode } from '~/common/util/imageUtils';
import { convert_Base64WithMimeType_To_Blob } from '~/common/util/blobUtils';
import { createDMessageDataRefDBlob, createImageAttachmentFragment, DMessageAttachmentFragment, isImageRefPart } from '~/common/stores/chat/chat.fragments';

import type { AttachmentDraftSource } from './attachment.types';


/**
 * Converts an image input to a DBlob and return a DMessageAttachmentFragment
 */
export async function imageDataToImageAttachmentFragmentViaDBlob(
  inputMime: string,
  inputData: string | Blob | unknown,
  source: AttachmentDraftSource,
  title: string,
  caption: string,
  convertToMimeType: false | CommonImageMimeTypes,
  resizeMode: false | LLMImageResizeMode,
): Promise<DMessageAttachmentFragment | null> {

  // convert to Blobs if needed
  let inputImage: Blob;
  if (inputData instanceof Blob) {
    inputImage = inputData;
  } else if (typeof inputData === 'string') {
    try {
      inputImage = await convert_Base64WithMimeType_To_Blob(inputData, inputMime, 'image-attachment');
    } catch (conversionError) {
      console.warn(`[DEV] imageAttachment: Error converting string to Blob:`, { conversionError });
      return null;
    }
  } else {
    console.log('imageAttachment: Invalid input data type:', typeof inputData);
    return null;
  }

  try {

    // perform resize/type conversion if desired, and find the image dimensions
    const { blob: imageBlob, height: imageHeight, width: imageWidth } = await imageBlobTransform(inputImage, {
      resizeMode: resizeMode || undefined,
      convertToMimeType: convertToMimeType || undefined,
      convertToLossyQuality: undefined, // use default
      throwOnResizeError: true,
      throwOnTypeConversionError: true,
    });

    // add the image to the DBlobs DB
    const dblobAssetId = await addDBImageAsset('attachment-drafts', imageBlob, {
      label: title ? 'Image: ' + title : 'Image',
      metadata: {
        width: imageWidth,
        height: imageHeight,
        // description: '',
      },
      origin: { // User originated
        ot: 'user',
        source: 'attachment',
        media: source.media === 'file' ? source.origin : source.media === 'url' ? 'url' : 'unknown',
        url: source.media === 'url' ? source.url : undefined,
        fileName: source.media === 'file' ? source.refPath : undefined,
      },
    });

    // return an Image _Attachment_ Fragment
    return createImageAttachmentFragment(
      title,
      caption,
      createDMessageDataRefDBlob( // Data Reference {} for the image
        dblobAssetId,
        imageBlob.type,
        imageBlob.size,
      ),
      undefined,
      imageWidth || undefined,
      imageHeight || undefined,
    );
  } catch (error) {
    console.error('imageAttachment: Error processing image:', error);
    return null;
  }
}

/**
 * Remove the DBlob item associated with the given DMessageAttachmentFragment
 */
export async function removeAttachmentOwnedDBAsset({ part }: DMessageAttachmentFragment) {
  if (isImageRefPart(part) && part.dataRef.reftype === 'dblob') {
    await deleteDBAsset(part.dataRef.dblobAssetId);
  }
}

/**
 * Move the DBlob items associated with the given DMessageAttachmentFragment to a new context and scope
 */
export async function transferAttachmentOwnedDBAsset({ part }: DMessageAttachmentFragment, contextId: DBlobDBContextId, scopeId: DBlobDBScopeId) {
  if (isImageRefPart(part) && part.dataRef.reftype === 'dblob') {
    await transferDBAssetContextScope(part.dataRef.dblobAssetId, contextId, scopeId);
  }
}

/**
 * GC Functions for Attachment DBlobs systems: remove leftover drafts
 */
export async function gcAttachmentDBlobs() {
  // wipe all objects related to attachment drafts that could have been there from previous sessions
  await gcDBAssetsByScope('global', 'attachment-drafts', null, []);
}



================================================
FILE: src/common/attachment-drafts/attachment.livefile.ts
================================================
import { liveFileCreateOrThrow } from '~/common/livefile/store-live-file';

import type { AttachmentDraftSource } from './attachment.types';


/** Checks if the source supports LiveFile (usually attached Files with drag/drop) */
export function attachmentSourceSupportsLiveFile(source: AttachmentDraftSource): boolean {
  return source.media === 'file' && !!source.fileWithHandle.handle && typeof source.fileWithHandle.handle.getFile === 'function';
}

/** Get the ID to a LiveFile (create one if needed) */
export async function attachmentGetLiveFileId(source: AttachmentDraftSource) {
  // only files that came with a FileSystemFileHandle are supported
  if (!attachmentSourceSupportsLiveFile(source) || source.media !== 'file' || !source.fileWithHandle.handle)
    return undefined;

  // new or recycled
  return await liveFileCreateOrThrow(source.fileWithHandle.handle).catch(console.error) || undefined;
}



================================================
FILE: src/common/attachment-drafts/attachment.mimetypes.ts
================================================
/// STAGE 1 - Mimetype Guessing

type GuessedMimeType = keyof typeof GuessedMimeLookupTable;
type GuessedMimeInfo = { ext: string[] | null, dt: GuessedMimeContents }
type GuessedMimeContents =
  | 'plain'     // text/plain
  | 'markdown'  //
  | 'html'      //
  | 'code'      //
  | 'doc-pdf' | 'doc-msw' | 'doc-msxl' | 'doc-msppt'
  | 'image' | 'audio' | 'video'
  | 'other';

const GuessedMimeLookupTable: Record<string, GuessedMimeInfo> = {
  // Plain text
  // - shall be rendered and edited as plain text
  'text/plain': { ext: ['txt', 'text', 'log', 'conf', 'def', 'list', 'in', 'ini'], dt: 'plain' },

  // Markdown
  // - shall be rendered with sizes and styles, as markdown does
  'text/markdown': { ext: ['md', 'markdown', 'mdown', 'mkd'], dt: 'markdown' },

  // HTML
  // - shall be rendered as an HTML page
  'text/html': { ext: ['htm', 'html', 'shtml', 'xhtml'], dt: 'html' },

  // SVG treated as code - or shall it not be?
  'image/svg+xml': { ext: ['svg'], dt: 'code' },

  // Code (including various programming languages)
  'text/css': { ext: ['css', 'scss', 'less', 'sass'], dt: 'code' },
  'text/javascript': { ext: ['js', 'mjs', 'jsx'], dt: 'code' },
  'application/x-javascript': { ext: null, dt: 'code' },
  'text/x-typescript': { ext: ['ts', 'tsx', 'd.ts'], dt: 'code' }, // TypeScript files (recommended is application/typescript, but we standardize to text/x-typescript instead as per Gemini's standard)
  'application/x-typescript': { ext: null, dt: 'code' },
  'text/csv': { ext: ['csv', 'tsv'], dt: 'code' },
  'text/x-python': { ext: ['py', 'pyw'], dt: 'code' },
  'application/x-python-code': { ext: null, dt: 'code' },
  'application/x-ipynb+json': { ext: ['ipynb'], dt: 'code' },
  'application/json': { ext: ['json', 'jsonld'], dt: 'code' },
  'text/xml': { ext: ['xml', 'xsl', 'xsd', 'rss', 'atom'], dt: 'code' },
  'application/rtf': { ext: ['rtf'], dt: 'code' },
  'text/rtf': { ext: null, dt: 'code' },
  'text/x-java': { ext: ['java', 'jsp', 'jspx', 'jhtm', 'jhtml'], dt: 'code' },
  'text/x-c': { ext: ['c', 'h'], dt: 'code' },
  'text/x-c++': { ext: ['cpp', 'hpp', 'cc', 'hh', 'cxx', 'hxx'], dt: 'code' },
  'text/x-csharp': { ext: ['cs', 'csx'], dt: 'code' },
  'text/x-ruby': { ext: ['rb', 'rhtml', 'rjs', 'rxml', 'erb'], dt: 'code' },
  'text/x-go': { ext: ['go'], dt: 'code' },
  'text/x-rust': { ext: ['rs'], dt: 'code' },
  'text/x-sh': { ext: ['sh', 'bash', 'zsh', 'ksh'], dt: 'code' },
  'text/x-scala': { ext: ['scala'], dt: 'code' },
  'text/x-kotlin': { ext: ['kt'], dt: 'code' },
  'text/x-swift': { ext: ['swift', 'swiftui'], dt: 'code' },
  'text/x-sql': { ext: ['sql', 'ddl', 'dml'], dt: 'code' },

  // Document formats
  'application/pdf': { ext: ['pdf'], dt: 'doc-pdf' },
  'application/x-pdf': { ext: null, dt: 'doc-pdf' },
  'application/acrobat': { ext: null, dt: 'doc-pdf' },
  'application/msword': { ext: ['doc'], dt: 'doc-msw' },
  'application/vnd.openxmlformats-officedocument.wordprocessingml.document': { ext: ['docx'], dt: 'doc-msw' },
  'application/vnd.ms-excel': { ext: ['xls'], dt: 'doc-msxl' },
  'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': { ext: ['xlsx'], dt: 'doc-msxl' },
  'application/vnd.ms-powerpoint': { ext: ['ppt'], dt: 'doc-msppt' },
  'application/vnd.openxmlformats-officedocument.presentationml.presentation': { ext: ['pptx'], dt: 'doc-msppt' },

  // Image formats
  'image/jpeg': { ext: ['jpg', 'jpeg', 'jpe'], dt: 'image' },
  'image/png': { ext: ['png'], dt: 'image' },
  'image/gif': { ext: ['gif'], dt: 'image' },
  'image/bmp': { ext: ['bmp'], dt: 'image' },
  'image/webp': { ext: ['webp'], dt: 'image' },
  'image/tiff': { ext: ['tif', 'tiff'], dt: 'image' },
  'image/x-icon': { ext: ['ico'], dt: 'image' },
  'image/heic': { ext: ['heic'], dt: 'image' },
  'image/heif': { ext: ['heif'], dt: 'image' },

  // Audio formats
  'audio/wav': { ext: ['wav'], dt: 'audio' },
  'audio/mpeg': { ext: ['mp3'], dt: 'audio' },
  'audio/ogg': { ext: ['ogg'], dt: 'audio' },
  'audio/aac': { ext: ['aac', 'm4a'], dt: 'audio' },
  'audio/aiff': { ext: ['aif', 'aiff', 'aifc'], dt: 'audio' },
  'audio/flac': { ext: ['flac'], dt: 'audio' },

  // Video formats
  'video/mp4': { ext: ['mp4', 'm4v'], dt: 'video' },
  'video/mpeg': { ext: ['mpeg', 'mpg'], dt: 'video' },
  'video/mov': { ext: ['mov'], dt: 'video' },
  'video/avi': { ext: ['avi'], dt: 'video' },
  'video/x-flv': { ext: ['flv'], dt: 'video' },
  'video/webm': { ext: ['webm', 'weba'], dt: 'video' },
  'video/wmv': { ext: ['wmv'], dt: 'video' },
  'video/3gpp': { ext: ['3gp', '3gpp'], dt: 'video' },

  // Compressed files
  'application/x-compressed': { ext: ['zip', 'rar', '7z', 'tar'], dt: 'other' },
  'application/x-gzip': { ext: ['gz'], dt: 'other' },
  'application/x-bzip2': { ext: ['bz2'], dt: 'other' },
};

const MdTitleToMimeLookupTable: Record<string, GuessedMimeType> = {
  'typescript': 'text/x-typescript',
  'ts': 'text/x-typescript',
  'tsx': 'text/x-typescript',
  'javascript': 'text/javascript',
  'js': 'text/javascript',
  'jsx': 'text/javascript',
  'python': 'text/x-python',
  'py': 'text/x-python',
  'json': 'application/json',
  'html': 'text/html',
  'htm': 'text/html',
  'sql': 'text/x-sql',
  'css': 'text/css',
  'md': 'text/markdown',
  'markdown': 'text/markdown',
  'sh': 'text/x-sh',
  'bash': 'text/x-sh',
  'shell': 'text/x-sh',
  'csv': 'text/csv',
  'tsv': 'text/csv',
  'xml': 'text/xml',
  'pdf': 'application/pdf',
  'doc': 'application/msword',
  'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  'xls': 'application/vnd.ms-excel',
  'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
  'ppt': 'application/vnd.ms-powerpoint',
  'pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
};

export function reverseLookupMimeType(fileExtension: string): GuessedMimeType | null {
  for (const [mimeType, { ext }] of Object.entries(GuessedMimeLookupTable)) {
    if (ext && ext.includes(fileExtension))
      return mimeType;
  }
  return null;
}

export function reverseLookupMdTitle(mdTitle: string): { mimeType: GuessedMimeType, extension: string | null } | null {
  const guessedMimeType = MdTitleToMimeLookupTable[mdTitle] || null;
  if (guessedMimeType) {
    const { ext } = GuessedMimeLookupTable[guessedMimeType];
    return { mimeType: guessedMimeType, extension: (ext ? ext[0] : null) || null };
  }
  return null;
}

export function guessInputContentTypeFromMime(mimeType: GuessedMimeType): GuessedMimeContents {
  return GuessedMimeLookupTable[mimeType]?.dt ?? 'plain';
}

export function heuristicMimeTypeFixup(mimeType: GuessedMimeType, fileExtension?: string): GuessedMimeType {

  // Mpeg-transport video steam -> Typescript
  if (!mimeType.startsWith('text/') && fileExtension && GuessedMimeLookupTable['text/x-typescript']?.ext?.includes(fileExtension))
    return 'text/x-typescript';

  return mimeType;
}


/// STAGE 2 - Converter mimetypes, to decide which converter(s) to apply to an input

// MimeTypes to treat as plain text for attachment purposes
export function mimeTypeIsPlainText(mimeType: string): boolean {
  // we include this list: https://ai.google.dev/gemini-api/docs/prompting_with_media?lang=node#plain_text_formats
  // and include a greater number of plain text files
  const docType = GuessedMimeLookupTable[mimeType]?.dt;
  return docType === 'plain' || docType === 'markdown' || docType === 'html' || docType === 'code';
}

// Image Rules across the supported LLMs
//
// OpenAI: https://platform.openai.com/docs/guides/vision/what-type-of-files-can-i-upload
//  - Supported Image formats:
//    - Images are first scaled to fit within a 2048 x 2048 square (if larger), maintaining their aspect ratio.
//      Then, they are scaled down such that the shortest side of the image is 768px (if larger)
//    - PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-animated GIF (.gif)
//
// Google: https://ai.google.dev/gemini-api/docs/prompting_with_media
//  - Supported Image formats:
//    - models: gemini-1.5-pro, gemini-pro-vision
//    - PNG - image/png, JPEG - image/jpeg, WEBP - image/webp, HEIC - image/heic, HEIF - image/heif
//    - [strat] for prompts containing a single image, it might perform better if that image is placed before the text prompt
//    - Maximum of 16 individual images for the gemini-pro-vision and 3600 images for gemini-1.5-pro
//    - No specific limits to the number of pixels in an image; however, larger images are scaled down to
//    - fit a maximum resolution of 3072 x 3072 while preserving their original aspect ratio
//
//  - Supported Audio formats:
//    - models: gemini-1.5-pro
//    - WAV - audio/wav, MP3 - audio/mp3, AIFF - audio/aiff, AAC - audio/aac, OGG Vorbis - audio/ogg, FLAC - audio/flac
//    - The maximum supported length of audio data in a single prompt is 9.5 hours
//    - Audio files are resampled down to a 16 Kbps data resolution, and multiple channels of audio are combined into a single channel
//    - No limit of audio files in a single prompt (but < 9.5Hrs)
//
//  - Supported Video formats:
//    - models: gemini-1.5-pro
//    - video/mp4 video/mpeg, video/mov, video/avi, video/x-flv, video/mpg, video/webm, video/wmv, video/3gpp
//    - The File API service samples videos into images at 1 frame per second (FPS) and may be subject to change to provide the best
//      inference quality. Individual images take up 258 tokens regardless of resolution and quality
//
// Anthropic: https://docs.anthropic.com/en/docs/vision
//  - Supported Image formats:
//    - image/jpeg, image/png, image/gif, and image/webp
//    - If image's long edge is more than 1568 pixels, or your image is more than ~1600 tokens, it will first be scaled down
//      - Max Image Size per Aspect ratio: 1:1 1092x1092 px, 3:4 951x1268 px, 2:3 896x1344 px, 9:16 819x1456 px, 1:2 784x1568 px
//    - Max size is 5MB/image on the API
//    - Up to 20 images in a single request (note, request, not message)

// Least common denominator of the instructions above - MimeTypes to treat as supported images for attachment purposes
export function mimeTypeIsSupportedImage(mimeType: string): boolean {
  if (GuessedMimeLookupTable[mimeType]?.dt !== 'image')
    return false;
  // We actually narrow it down here to be a tad more restrictive
  return ['image/png', 'image/jpeg', 'image/webp', 'image/gif'].includes(mimeType);
}

// MimeTypes to treat as PDF documents for attachment purposes
export function mimeTypeIsPDF(mimeType: string): boolean {
  return GuessedMimeLookupTable[mimeType]?.dt === 'doc-pdf';
}

// MimeTypes to treat as Word documents for attachment purposes
export function mimeTypeIsDocX(mimeType: string): boolean {
  return GuessedMimeLookupTable[mimeType]?.dt === 'doc-msw';
}



================================================
FILE: src/common/attachment-drafts/attachment.pipeline.ts
================================================
import type { FileWithHandle } from 'browser-fs-access';

import { callBrowseFetchPageOrThrow } from '~/modules/browse/browse.client';
import { extractYoutubeVideoIDFromURL } from '~/modules/youtube/youtube.utils';
import { youTubeGetVideoData } from '~/modules/youtube/useYouTubeTranscript';

import type { CommonImageMimeTypes } from '~/common/util/imageUtils';
import { Is } from '~/common/util/pwaUtils';
import { agiCustomId, agiUuid } from '~/common/util/idUtils';
import { convert_Base64DataURL_To_Base64WithMimeType, convert_Base64WithMimeType_To_Blob } from '~/common/util/blobUtils';
import { htmlTableToMarkdown } from '~/common/util/htmlTableToMarkdown';
import { humanReadableHyphenated } from '~/common/util/textUtils';
import { pdfToImageDataURLs, pdfToText } from '~/common/util/pdfUtils';

import { createDMessageDataInlineText, createDocAttachmentFragment, DMessageAttachmentFragment, DMessageDataInline, DMessageDocPart, DVMimeType, isContentOrAttachmentFragment, isDocPart, specialContentPartToDocAttachmentFragment } from '~/common/stores/chat/chat.fragments';

import type { AttachmentCreationOptions, AttachmentDraft, AttachmentDraftConverter, AttachmentDraftId, AttachmentDraftInput, AttachmentDraftSource, AttachmentDraftSourceOriginFile, DraftEgoFragmentsInputData, DraftWebInputData, DraftYouTubeInputData } from './attachment.types';
import type { AttachmentsDraftsStore } from './store-attachment-drafts_slice';
import { attachmentGetLiveFileId, attachmentSourceSupportsLiveFile } from './attachment.livefile';
import { guessInputContentTypeFromMime, heuristicMimeTypeFixup, mimeTypeIsDocX, mimeTypeIsPDF, mimeTypeIsPlainText, mimeTypeIsSupportedImage, reverseLookupMimeType } from './attachment.mimetypes';
import { imageDataToImageAttachmentFragmentViaDBlob } from './attachment.dblobs';


// configuration
export const DEFAULT_ADRAFT_IMAGE_MIMETYPE: CommonImageMimeTypes = !Is.Browser.Safari ? 'image/webp' : 'image/jpeg';
export const DEFAULT_ADRAFT_IMAGE_QUALITY = 0.96;
const PDF_IMAGE_PAGE_SCALE = 1.5;
const PDF_IMAGE_QUALITY = 0.5;
const ENABLE_TEXT_AND_IMAGES = false; // 2.0
const DOCPART_DEFAULT_VERSION = 1;


// internal mimes, only used to route data within us (source -> input -> converters)
const INT_MIME_VND_AGI_EGO_FRAGMENTS = 'application/vnd.agi.ego.fragments';
const INT_MIME_VND_AGI_WEBPAGE = 'application/vnd.agi.webpage';
const INT_MIME_VND_AGI_YOUTUBE = 'application/vnd.agi.youtube';


/**
 * Creates a new AttachmentDraft object.
 */
export function attachmentCreate(source: AttachmentDraftSource): AttachmentDraft {
  return {
    id: agiUuid('attachment-draft'),
    source: source,
    label: 'Loading...',
    ref: '',
    inputLoading: false,
    inputError: null,
    input: undefined,
    converters: [],
    outputsConverting: false,
    outputsConversionProgress: null,
    outputFragments: [],
    // metadata: {},
  };
}

/**
 * Asynchronously loads the input for an AttachmentDraft object.
 *
 * @param {Readonly<AttachmentDraftSource>} source - The source of the attachment.
 * @param {(changes: Partial<AttachmentDraft>) => void} edit - A function to edit the AttachmentDraft object.
 */
export async function attachmentLoadInputAsync(source: Readonly<AttachmentDraftSource>, edit: (changes: Partial<Omit<AttachmentDraft, 'outputFragments'>>) => void) {
  edit({ inputLoading: true });

  switch (source.media) {

    // Download URL (page, file, ..) and attach as input
    case 'url':
      edit({ label: source.refUrl, ref: source.refUrl });

      // [YouTube] user is attaching a link to a video: try to download this as a transcript rather than a webpage
      const asYoutubeVideoId = extractYoutubeVideoIDFromURL(source.refUrl);
      if (asYoutubeVideoId) {
        const videoData = await youTubeGetVideoData(asYoutubeVideoId).catch(console.warn);
        if (videoData?.videoTitle && videoData?.transcript) {
          edit({
            label: videoData.videoTitle,
            input: {
              mimeType: INT_MIME_VND_AGI_YOUTUBE,
              data: {
                videoId: asYoutubeVideoId,
                videoTitle: videoData.videoTitle,
                videoDescription: videoData.videoDescription,
                videoThumbnailUrl: videoData.thumbnailUrl,
                videoTranscript: videoData.transcript,
              },
              urlImage: !videoData.thumbnailImage ? undefined : {
                ...videoData.thumbnailImage,
                generator: 'youtube-thumbnail',
                timestamp: Date.now(),
              },
            },
          });
          break;
        }
      }

      try {
        // fetch the web page
        const { title, content, file: urlFile, screenshot } = await callBrowseFetchPageOrThrow(
          source.url, ['text', 'markdown', 'html'], { width: 512, height: 512, quality: 98 }, true,
        );
        if (content) {
          const { html, markdown, text } = content;
          if (html || markdown || text)
            edit({
              label: title || source.refUrl,
              input: {
                mimeType: INT_MIME_VND_AGI_WEBPAGE,
                data: {
                  pageText: text ?? undefined,
                  pageMarkdown: markdown ?? undefined,
                  pageCleanedHtml: html ?? undefined,
                  pageTitle: title || undefined,
                },
                urlImage: !screenshot ? undefined : {
                  ...screenshot,
                  generator: 'web-capture',
                  timestamp: Date.now(),
                },
              },
            });
          else
            edit({ inputError: 'No content found at this link' });
        } else if (urlFile) {
          try {
            const urlBlob = await convert_Base64WithMimeType_To_Blob(urlFile.data, urlFile.mimeType, 'attachment-draft-load-input');
            edit({
              label: urlFile.fileName || source.refUrl,
              // ref: source.refUrl,
              input: {
                mimeType: urlFile.mimeType,
                data: urlBlob,
                dataSize: urlBlob.size,
              },
            });
          } catch (error: any) {
            edit({ inputError: `Issue downloading web file: ${error?.message || (typeof error === 'string' ? error : JSON.stringify(error))}` });
          }
        } else
          edit({ inputError: 'No content or file found at this link' });
      } catch (error: any) {
        edit({ inputError: `Issue downloading page: ${error?.message || (typeof error === 'string' ? error : JSON.stringify(error))}` });
      }
      break;

    // Attach file as input
    case 'file':
      edit({ label: source.refPath, ref: source.refPath });

      // fix missing/wrong mimetypes
      let fileMime: string | null = source.fileWithHandle.type;
      const fileExtension = source.refPath.split('.').pop()?.toLowerCase() || undefined;
      if (!fileMime) {
        // see note on 'attachAppendDataTransfer'; this is a fallback for drag/drop missing Mimes sometimes
        if (fileExtension)
          fileMime = reverseLookupMimeType(fileExtension);

        // unknown extension or missing extension and mime: falling back to text/plain
        if (!fileMime) {
          console.warn(`Assuming the attachment is text/plain. From: '${source.origin}', name: ${source.refPath}`);
          fileMime = 'text/plain';
        }
      } else {
        // WEAK - Fix wrongly assigned mimetypes - this is a hardcoded hack basically - please remove.
        fileMime = heuristicMimeTypeFixup(fileMime, fileExtension);
      }

      // UX: just a hint of a loading state
      // Note: disabled: the read operation will be async anyway, and
      //       we don't want to delay too long in case of large drops.
      // await new Promise(resolve => setTimeout(resolve, 50));

      try {
        edit({
          input: {
            mimeType: fileMime,
            data: source.fileWithHandle, // FileWithHandle extends File extends Blob
            dataSize: source.fileWithHandle.size,
          },
        });
      } catch (error: any) {
        const errorText = (error?.name === 'AbortError' && source.fileWithHandle.type === '')
          ? 'unsupported file type or possible folder. For folders and LiveFile support, we recommend using Google Chrome.'
          : `issue loading file: ${error?.message || (typeof error === 'string' ? error : JSON.stringify(error))}`;
        edit({ inputError: errorText });
      }
      break;

    case 'text':
      // Obsidian URLs, for dragging: we won't be able to open them, so we'll show the input error instead
      if (source.textPlain?.startsWith('obsidian://open?vault=')) {
        edit({ label: 'Obsidian Issue', inputError: 'Drag and drop does not work with Obsidian URLs. Please open/attach the file, or drag it from finder/explorer, or paste the content.' });
        break;
      }

      if (source.textHtml && source.textPlain) {
        edit({
          label: 'Rich Text',
          ref: '',
          input: {
            mimeType: 'text/plain',
            data: source.textPlain,
            dataSize: source.textPlain!.length,
            altMimeType: 'text/html',
            altData: source.textHtml,
          },
        });
      } else {
        const text = source.textHtml || source.textPlain || '';
        edit({
          label: 'Text',
          ref: '',
          input: {
            mimeType: 'text/plain',
            data: text,
            dataSize: text.length,
          },
        });
      }
      break;

    case 'ego':
      edit({
        label: source.label,
        ref: `${source.egoFragmentsInputData.messageId} - ${source.egoFragmentsInputData.conversationTitle}`,
        input: {
          mimeType: INT_MIME_VND_AGI_EGO_FRAGMENTS,
          data: source.egoFragmentsInputData,
        },
      });
      break;
  }

  edit({ inputLoading: false });
}


/**
 * Defines the possible converters for an AttachmentDraft object based on its input type.
 *
 * @param {Readonly<AttachmentDraftSource>} source - The source of the AttachmentDraft object.
 * @param {Readonly<AttachmentDraftInput>} input - The input of the AttachmentDraft object.
 * @param options conversion preferences, if any
 * @param {(changes: Partial<AttachmentDraft>) => void} edit - A function to edit the AttachmentDraft object.
 */
export function attachmentDefineConverters(source: AttachmentDraftSource, input: Readonly<AttachmentDraftInput>, options: AttachmentCreationOptions, edit: (changes: Partial<Omit<AttachmentDraft, 'outputFragments'>>) => void) {

  // return all the possible converters for the input
  const converters: AttachmentDraftConverter[] = [];

  const autoAddImages = ENABLE_TEXT_AND_IMAGES && !!options?.hintAddImages;

  switch (true) {

    // plain text types
    case mimeTypeIsPlainText(input.mimeType):
      // handle a secondary layer of HTML 'text' origins: drop, paste, and clipboard-read
      const textOriginHtml = source.media === 'text' && input.altMimeType === 'text/html' && !!input.altData;
      const isHtmlTable = !!input.altData?.startsWith('<table');

      // p1: Tables
      if (textOriginHtml && isHtmlTable)
        converters.push({ id: 'rich-text-table', name: 'Markdown Table' });

      // p2: Text
      converters.push({ id: 'text', name: attachmentSourceSupportsLiveFile(source) ? 'Text (Live)' : 'Text' });

      // p3: Html
      if (textOriginHtml) {
        converters.push({ id: 'rich-text-cleaner', name: 'Cleaner HTML' });
        converters.push({ id: 'rich-text', name: 'HTML · Heavy' });
      }
      break;

    // Images (Known/Unknown)
    case input.mimeType.startsWith('image/'):
      const inputImageMimeSupported = mimeTypeIsSupportedImage(input.mimeType);
      converters.push({ id: 'image-resized-high', name: 'Image (high detail)', disabled: !inputImageMimeSupported });
      converters.push({ id: 'image-resized-low', name: 'Image (low detail)', disabled: !inputImageMimeSupported });
      converters.push({ id: 'image-original', name: 'Image (original quality)', disabled: !inputImageMimeSupported });
      if (!inputImageMimeSupported)
        converters.push({ id: 'image-to-default', name: `As Image (${DEFAULT_ADRAFT_IMAGE_MIMETYPE})` });
      converters.push({ id: 'unhandled', name: 'No Image' });
      converters.push({ id: 'image-ocr', name: 'Add Text (OCR)', isCheckbox: true });
      break;

    // PDF
    case mimeTypeIsPDF(input.mimeType):
      converters.push({ id: 'pdf-text', name: 'PDF To Text', isActive: !autoAddImages || undefined });
      converters.push({ id: 'pdf-images', name: 'PDF To Images' });
      converters.push({ id: 'pdf-text-and-images', name: 'PDF Text & Images (best)', isActive: autoAddImages });
      break;

    // DOCX
    case mimeTypeIsDocX(input.mimeType):
      converters.push({ id: 'docx-to-html', name: 'DOCX to HTML' });
      break;

    // URL: custom converters because of a custom input structure with multiple inputs
    case input.mimeType === INT_MIME_VND_AGI_WEBPAGE:
      const pageData = input.data as DraftWebInputData;
      const preferMarkdown = !!pageData.pageMarkdown;
      if (pageData.pageText)
        converters.push({ id: 'url-page-text', name: 'Text', isActive: !preferMarkdown });
      if (pageData.pageMarkdown)
        converters.push({ id: 'url-page-markdown', name: 'Markdown (suggested)', isActive: preferMarkdown });
      if (pageData.pageCleanedHtml)
        converters.push({ id: 'url-page-html', name: 'Clean HTML', isActive: !preferMarkdown && !pageData.pageText });
      if (input.urlImage) {
        if (converters.length)
          converters.push({ id: 'url-page-null', name: 'Do not attach' });
        converters.push({ id: 'url-page-image', name: 'Add Screenshot', disabled: !input.urlImage.width || !input.urlImage.height, isCheckbox: true, isActive: autoAddImages || undefined });
      }
      break;

    // YouTube: custom converters
    case input.mimeType === INT_MIME_VND_AGI_YOUTUBE:
      converters.push({ id: 'youtube-transcript', name: 'Video Transcript', isActive: true });
      converters.push({ id: 'youtube-transcript-simple', name: 'Video Transcript (simple)' });
      if (input.urlImage)
        converters.push({ id: 'url-page-image', name: 'Add Thumbnail', disabled: !input.urlImage.width || !input.urlImage.height, isCheckbox: true, isActive: autoAddImages });
      break;

    // EGO
    case input.mimeType === INT_MIME_VND_AGI_EGO_FRAGMENTS:
      converters.push({ id: 'ego-fragments-inlined', name: 'Message' });
      break;

    // catch-all
    default:
      converters.push({ id: 'unhandled', name: `${input.mimeType}`, unsupported: true });
      converters.push({ id: 'text', name: 'As Text' });
      break;
  }

  edit({ converters });
}


function _lowCollisionRefString(prefix: string, digits: number): string {
  return `${prefix} ${agiCustomId(digits)}`;
}

function _prepareDocData(source: AttachmentDraftSource, input: Readonly<AttachmentDraftInput>, converterName: string): {
  title: string;
  caption: string;
  refString: string;
  docMeta?: DMessageDocPart['meta'];
} {
  const inputMime = input.mimeType || '';
  switch (source.media) {

    // Downloaded URL as Text, Markdown, or HTML
    case 'url':
      let pageTitle =
        inputMime === INT_MIME_VND_AGI_WEBPAGE ? (input.data as DraftWebInputData)?.pageTitle
          : inputMime === INT_MIME_VND_AGI_YOUTUBE ? (input.data as DraftYouTubeInputData)?.videoTitle
            : undefined;
      if (!pageTitle)
        pageTitle = `Web page: ${source.refUrl}`;
      const urlRefString = inputMime === INT_MIME_VND_AGI_YOUTUBE ? 'youtube-' + (input.data as DraftYouTubeInputData)?.videoId : pageTitle;
      return {
        title: pageTitle,
        caption: converterName,
        refString: humanReadableHyphenated(urlRefString),
      };

    // File of various kinds and coming from various sources
    case 'file':
      const mayBeImage = inputMime.startsWith('image/');

      let fileTitle = _lowCollisionRefString(mayBeImage ? 'Image' : 'File', 4);
      let fileCaption = '';
      const fileMeta: DMessageDocPart['meta'] = {
        srcFileName: source.fileWithHandle.name || undefined,
        srcFileSize: source.fileWithHandle.size || input.dataSize,
      };

      switch (source.origin) {
        case 'camera':
          fileTitle = source.refPath || _lowCollisionRefString('Camera Photo', 6);
          break;
        case 'screencapture':
          fileTitle = source.refPath || _lowCollisionRefString('Screen Capture', 6);
          fileCaption = 'Screen Capture';
          break;
        case 'file-open':
          fileTitle = source.refPath || _lowCollisionRefString('Uploaded File', 6);
          break;
        case 'clipboard-read':
        case 'paste':
          fileTitle = source.refPath || _lowCollisionRefString('Pasted File', 6);
          break;
        case 'drop':
          fileTitle = source.refPath || _lowCollisionRefString('Dropped File', 6);
          break;
      }
      return {
        title: fileTitle,
        caption: fileCaption,
        refString: humanReadableHyphenated(fileTitle),
        docMeta: fileMeta,
      };

    // Text from clipboard, drop, or paste
    case 'text':
      const textRef = _lowCollisionRefString('doc', 6);
      return {
        title: converterName || 'Text',
        caption: source.method === 'drop' ? 'Dropped' : 'Pasted',
        refString: humanReadableHyphenated(textRef),
      };

    // The application attaching pieces of itself
    case 'ego':
      const egoKind = source.method === 'ego-fragments' ? 'Chat Message' : '';
      return {
        title: egoKind,
        caption: 'From Chat: ' + source.egoFragmentsInputData.conversationTitle,
        refString: humanReadableHyphenated(egoKind),
      };
  }
}

function _guessDocVDT(inputMimeType: string): DMessageDocPart['vdt'] {
  if (!inputMimeType)
    return DVMimeType.TextPlain;
  const inputContentType = guessInputContentTypeFromMime(inputMimeType);
  switch (inputContentType) {
    case 'plain':
    case 'markdown':
      return DVMimeType.TextPlain;

    case 'html':
    case 'code':
      return DVMimeType.VndAgiCode;

    // these would have been converted - let's assume to code, but we don't return here as this code path won't happen
    // case 'doc-pdf': // plain or OCR, or images
    // case 'doc-msw': // code (html), or images
    // case 'doc-msxl': // code (html), or images
    // case 'doc-msppt': // code (html), or images
    // case 'image': // images won't get in docs
    // case 'audio': // same for audio
    // case 'video': // and video
    // case 'other': // and this even less
  }
  return DVMimeType.TextPlain;
}


/**
 * Converts the input of an AttachmentDraft object based on the selected converter.
 *
 * @param {Readonly<AttachmentDraft>} attachment - The AttachmentDraft object to convert.
 * @param edit - A function to edit the AttachmentDraft object.
 * @param replaceOutputFragments - A function to replace the output fragments of the AttachmentDraft object.
 */
export async function attachmentPerformConversion(
  attachment: Readonly<AttachmentDraft>,
  edit: (attachmentDraftId: AttachmentDraftId, update: Partial<Omit<AttachmentDraft, 'outputFragments'>>) => void, /* AttachmentsDraftsStore['_editAttachment'] */
  replaceOutputFragments: AttachmentsDraftsStore['_replaceAttachmentOutputFragments'],
): Promise<void> {

  // clear outputs
  // NOTE: disabled, to keep the old conversions while converting to the new - keeps the UI less 'flashing'
  // replaceOutputFragments(attachment.id, []);

  // get converter
  const { input, source } = attachment;
  if (!input)
    return;

  edit(attachment.id, {
    outputsConverting: true,
    outputsConversionProgress: null,
  });

  // apply converter to the input
  const newFragments: DMessageAttachmentFragment[] = [];
  for (const converter of attachment.converters) {
    if (!converter.isActive) continue;

    // prepare the doc data
    let { title, caption, refString, docMeta } = _prepareDocData(source, input, converter.name);

    switch (converter.id) {

      // text as-is
      case 'text':
        const possibleLiveFileId = await attachmentGetLiveFileId(source);
        const textContent = await _inputDataToString(input.data, 'text');
        const textualInlineData = createDMessageDataInlineText(textContent, input.mimeType);
        newFragments.push(createDocAttachmentFragment(title, caption, _guessDocVDT(input.mimeType), textualInlineData, refString, DOCPART_DEFAULT_VERSION, docMeta, possibleLiveFileId));
        break;

      // html as-is
      case 'rich-text':
        // NOTE: before we had the following: createTextAttachmentFragment(ref || '\n<!DOCTYPE html>', input.altData!), which
        //       was used to wrap the HTML in a code block to facilitate AutoRenderBlocks's parser. Historic note, for future debugging.
        const richTextData = createDMessageDataInlineText(input.altData || '', input.altMimeType);
        newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.VndAgiCode, richTextData, refString, DOCPART_DEFAULT_VERSION, docMeta));
        break;

      // html cleaned
      case 'rich-text-cleaner':
        const cleanerHtml = (input.altData || '')
          // remove class and style attributes
          .replace(/<[^>]+>/g, (tag) =>
            tag.replace(/ class="[^"]*"/g, '').replace(/ style="[^"]*"/g, ''),
          )
          // remove svg elements
          .replace(/<svg[^>]*>.*?<\/svg>/g, '');
        const cleanedHtmlData = createDMessageDataInlineText(cleanerHtml, 'text/html');
        newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.VndAgiCode, cleanedHtmlData, refString, DOCPART_DEFAULT_VERSION, docMeta));
        break;

      // html to markdown table
      case 'rich-text-table':
        let tableData: DMessageDataInline;
        try {
          const mdTable = htmlTableToMarkdown(input.altData!, false);
          tableData = createDMessageDataInlineText(mdTable, 'text/markdown');
        } catch (error) {
          // fallback to text/plain
          const fallbackText = await _inputDataToString(input.data, 'rich-text-table');
          tableData = createDMessageDataInlineText(fallbackText, input.mimeType);
        }
        newFragments.push(createDocAttachmentFragment(title, caption, tableData.mimeType === 'text/markdown' ? DVMimeType.TextPlain : DVMimeType.TextPlain, tableData, refString, DOCPART_DEFAULT_VERSION, docMeta));
        break;


      // image resized (default mime/quality, openai-high-res)
      case 'image-resized-high':
        if (!_expectBlob(input.data, 'image-resized')) return;
        const imageHighF = await imageDataToImageAttachmentFragmentViaDBlob(input.mimeType, input.data, source, title, caption, false, 'openai-high-res');
        if (imageHighF)
          newFragments.push(imageHighF);
        break;

      // image resized (default mime/quality, openai-low-res)
      case 'image-resized-low':
        if (!_expectBlob(input.data, 'image-resized')) return;
        const imageLowF = await imageDataToImageAttachmentFragmentViaDBlob(input.mimeType, input.data, source, title, caption, false, 'openai-low-res');
        if (imageLowF)
          newFragments.push(imageLowF);
        break;

      // image as-is
      case 'image-original':
        if (!_expectBlob(input.data, 'image-original')) return;
        const imageOrigF = await imageDataToImageAttachmentFragmentViaDBlob(input.mimeType, input.data, source, title, caption, false, false);
        if (imageOrigF)
          newFragments.push(imageOrigF);
        break;

      // image converted (potentially unsupported mime)
      case 'image-to-default':
        if (!_expectBlob(input.data, 'image-to-default')) return;
        const imageCastF = await imageDataToImageAttachmentFragmentViaDBlob(input.mimeType, input.data, source, title, caption, DEFAULT_ADRAFT_IMAGE_MIMETYPE, false);
        if (imageCastF)
          newFragments.push(imageCastF);
        break;

      // image to text
      case 'image-ocr':
        if (!_expectBlob(input.data, 'Image OCR converter')) break;
        try {
          let lastProgress = -1;
          const { recognize } = await import('tesseract.js');
          const result = await recognize(input.data, undefined, {
            errorHandler: e => console.error(e),
            logger: (message) => {
              if (message.status === 'recognizing text') {
                if (message.progress > lastProgress + 0.01) {
                  lastProgress = message.progress;
                  edit(attachment.id, { outputsConversionProgress: lastProgress });
                }
              }
            },
          });
          const imageText = result.data.text;
          newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.TextPlain, createDMessageDataInlineText(imageText, 'text/plain'), refString, DOCPART_DEFAULT_VERSION, { ...docMeta, srcOcrFrom: 'image' }));
        } catch (error) {
          console.error(error);
        }
        break;


      // pdf to text
      case 'pdf-text':
        if (!_expectBlob(input.data, 'PDF text converter')) break;
        // Convert Blob to ArrayBuffer for PDF.js
        const pdfText = await pdfToText(await input.data.arrayBuffer(), (progress: number) => {
          edit(attachment.id, { outputsConversionProgress: progress });
        });
        if (pdfText.trim().length < 2) {
          // Warn the user if no text is extracted
          // edit(attachment.id, { inputError: 'No text found in the PDF file.' });
        } else
          newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.TextPlain, createDMessageDataInlineText(pdfText, 'text/plain'), refString, DOCPART_DEFAULT_VERSION, { ...docMeta, srcOcrFrom: 'pdf' }));
        break;

      // pdf to images
      case 'pdf-images':
        if (!_expectBlob(input.data, 'PDF images converter')) break;
        // Convert Blob to ArrayBuffer for PDF.js
        try {
          const imageDataURLs = await pdfToImageDataURLs(await input.data.arrayBuffer(), DEFAULT_ADRAFT_IMAGE_MIMETYPE, PDF_IMAGE_QUALITY, PDF_IMAGE_PAGE_SCALE, (progress) => {
            edit(attachment.id, { outputsConversionProgress: progress });
          });
          for (const pdfPageImage of imageDataURLs) {
            const pdfPageImageF = await imageDataToImageAttachmentFragmentViaDBlob(pdfPageImage.mimeType, pdfPageImage.base64Data, source, `${title} (pg. ${newFragments.length + 1})`, caption, false, false);
            if (pdfPageImageF)
              newFragments.push(pdfPageImageF);
          }
        } catch (error) {
          console.error('Error converting PDF to images:', error);
        }
        break;

      // pdf to text and images
      case 'pdf-text-and-images':
        if (!_expectBlob(input.data, 'PDF text and images converter')) break;
        try {
          // Convert Blob to ArrayBuffer for PDF.js - create separate ArrayBuffers to avoid mutation
          // historical context: when we used ArrayBuffer, we had a "new Uint8Array(input.data.slice(0)).buffer" to avoid mutation
          const pdfArrayBufferForImages = await input.data.arrayBuffer();
          const pdfArrayBufferForText = await input.data.arrayBuffer();

          // duplicated from 'pdf-images' (different progress update)
          const imageFragments: DMessageAttachmentFragment[] = [];
          const imageDataURLs = await pdfToImageDataURLs(pdfArrayBufferForImages, DEFAULT_ADRAFT_IMAGE_MIMETYPE, PDF_IMAGE_QUALITY, PDF_IMAGE_PAGE_SCALE, (progress) => {
            edit(attachment.id, { outputsConversionProgress: progress / 2 }); // Update progress (0% to 50%)
          });
          for (const pdfPageImage of imageDataURLs) {
            const pdfPageImageF = await imageDataToImageAttachmentFragmentViaDBlob(pdfPageImage.mimeType, pdfPageImage.base64Data, source, `${title} (pg. ${newFragments.length + 1})`, caption, false, false);
            if (pdfPageImageF)
              imageFragments.push(pdfPageImageF);
          }

          // duplicated from 'pdf-text'
          const pdfText = await pdfToText(pdfArrayBufferForText, (progress: number) => {
            edit(attachment.id, { outputsConversionProgress: 0.5 + progress / 2 }); // Update progress (50% to 100%)
          });
          if (pdfText.trim().length < 2) {
            // Do not warn the user, as hopefully the images are useful
          } else {
            const textFragment = createDocAttachmentFragment(title, caption, DVMimeType.TextPlain, createDMessageDataInlineText(pdfText, 'text/plain'), refString, DOCPART_DEFAULT_VERSION, { ...docMeta, srcOcrFrom: 'pdf' });
            newFragments.push(textFragment);
          }

          // Add the text fragment first, then the image fragments
          newFragments.push(...imageFragments);
        } catch (error) {
          console.error('Error converting PDF to text and images:', error);
        }
        break;


      // docx to html
      case 'docx-to-html':
        if (!_expectBlob(input.data, 'DOCX converter')) break;
        try {
          const { convertDocxToHTML } = await import('./file-converters/DocxToMarkdown');
          const { html } = await convertDocxToHTML(await input.data.arrayBuffer());
          newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.VndAgiCode, createDMessageDataInlineText(html, 'text/html'), refString, DOCPART_DEFAULT_VERSION, docMeta));
        } catch (error) {
          console.error('Error in DOCX to Markdown conversion:', error);
        }
        break;


      // url page text
      case 'url-page-text':
        if (!input.data || input.mimeType !== INT_MIME_VND_AGI_WEBPAGE || !(input.data as DraftWebInputData).pageText) {
          console.log('Expected WebPageInputData for url-page-text, got:', input.data);
          break;
        }
        const pageTextData = createDMessageDataInlineText((input.data as DraftWebInputData).pageText!, 'text/plain');
        newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.TextPlain, pageTextData, refString, DOCPART_DEFAULT_VERSION, docMeta));
        break;

      // url page markdown
      case 'url-page-markdown':
        if (!input.data || input.mimeType !== INT_MIME_VND_AGI_WEBPAGE || !(input.data as DraftWebInputData).pageMarkdown) {
          console.log('Expected WebPageInputData for url-page-markdown, got:', input.data);
          break;
        }
        const pageMarkdownData = createDMessageDataInlineText((input.data as DraftWebInputData).pageMarkdown!, 'text/markdown');
        newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.VndAgiCode, pageMarkdownData, refString, DOCPART_DEFAULT_VERSION, docMeta));
        break;

      // url page html
      case 'url-page-html':
        if (!input.data || input.mimeType !== INT_MIME_VND_AGI_WEBPAGE || !(input.data as DraftWebInputData).pageCleanedHtml) {
          console.log('Expected WebPageInputData for url-page-html, got:', input.data);
          break;
        }
        const pageHtmlData = createDMessageDataInlineText((input.data as DraftWebInputData).pageCleanedHtml!, 'text/html');
        newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.VndAgiCode, pageHtmlData, refString, DOCPART_DEFAULT_VERSION, docMeta));
        break;

      // url page null
      case 'url-page-null':
        // user chose to not attach any version of the page
        break;

      // url page image
      case 'url-page-image':
        if (!input.urlImage) {
          console.log('Expected URL image data for url-image, got:', input.urlImage);
          break;
        }
        try {
          // get the data
          const { mimeType, imgDataUrl } = input.urlImage;
          const { base64Data } = convert_Base64DataURL_To_Base64WithMimeType(imgDataUrl, 'attachment-url-page-image');
          // do not convert, as we're in the optimal webp already
          // do not resize, as the 512x512 is optimal for most LLM Vendors, an a great tradeoff of quality/size/cost
          const screenshotImageF = await imageDataToImageAttachmentFragmentViaDBlob(mimeType, base64Data, source, `Screenshot of ${title}`, caption, false, false);
          if (screenshotImageF)
            newFragments.push(screenshotImageF);
        } catch (error) {
          console.error('Error attaching screenshot URL image:', error);
        }
        break;


      // youtube transcript
      case 'youtube-transcript':
      case 'youtube-transcript-simple':
        if (!input.data || input.mimeType !== INT_MIME_VND_AGI_YOUTUBE) {
          console.log('Expected YouTubeInputData for youtube-transcript, got:', input.data);
          break;
        }
        const youtubeData = input.data as DraftYouTubeInputData;
        const transcriptText =
          converter.id === 'youtube-transcript-simple' ? youtubeData.videoTranscript
            : `**YouTube Title**: ${youtubeData.videoTitle}\n\n**YouTube Description**: ${youtubeData.videoDescription}\n\n**YouTube Transcript**:\n${youtubeData.videoTranscript}\n`;
        const transcriptTextData = createDMessageDataInlineText(transcriptText, 'text/plain');
        newFragments.push(createDocAttachmentFragment(title, caption, DVMimeType.TextPlain, transcriptTextData, refString, DOCPART_DEFAULT_VERSION, docMeta, undefined));
        break;


      // ego: message
      case 'ego-fragments-inlined':
        if (!input.data || input.mimeType !== INT_MIME_VND_AGI_EGO_FRAGMENTS || !(input.data as DraftEgoFragmentsInputData).fragments?.length) {
          console.log('Expected non-empty EgoFragmentsInputData for ego-fragments-inlined, got:', input.data);
          break;
        }
        const draftEgoData = input.data as DraftEgoFragmentsInputData;
        for (const fragment of draftEgoData.fragments) {
          if (isContentOrAttachmentFragment(fragment)) {
            if (isDocPart(fragment.part)) {
              console.log('Skipping doc part in ego-fragments-inlined:', fragment);
              continue;
            }
            const fragmentTitle = `Chat Message: ${attachment.label}`;
            const fragmentCaption = 'From chat: ' + draftEgoData.conversationTitle;
            const fragmentRef = humanReadableHyphenated(refString + '-' + draftEgoData.messageId + '-' + fragment.fId);
            newFragments.push(specialContentPartToDocAttachmentFragment(fragmentTitle, fragmentCaption, DVMimeType.TextPlain, fragment.part, fragmentRef, docMeta));
          }
        }
        break;


      case 'unhandled':
        // force the user to explicitly select 'as text' if they want to proceed
        break;
    }
  }

  // update
  replaceOutputFragments(attachment.id, newFragments);
  edit(attachment.id, {
    outputsConverting: false,
    outputsConversionProgress: null,
  });
}


/**
 * Helper function to validate that input data is a Blob and log an error if not
 */
function _expectBlob(data: unknown, debugLocation: string): data is Blob {
  if (!(data instanceof Blob)) {
    console.warn(`[DEV] Expected Blob for ${debugLocation}, got:`, typeof data);
    return false;
  }
  return true;
}

/**
 * Converts the input data of an AttachmentDraft to a string, or log as an error if not possible
 */
async function _inputDataToString(data: AttachmentDraftInput['data'], debugLocation: string): Promise<string> {
  if (typeof data === 'string')
    return data;
  if (data instanceof Blob) {
    // Convert Blob to text - this is expected for text files uploaded as blobs
    try {
      return await data.text();
    } catch (error) {
      console.warn('Failed to convert Blob to text:', error);
      return '[Failed to read file content]';
    }
  }
  console.warn(`[DEV] Expected string or Blob for input data at ${debugLocation}, got:`, typeof data);
  return '';
}


/**
 * Special function to convert a list of files to Attachment Fragments, without passing through the attachments system
 *
 * Uses the default conversion whenever multiple are available, as we don't have the chance to ask
 * for user input here, whereas we do in the Attachments UI.
 *
 * Only returns the fragments that were successfully converted.
 */
export async function convertFilesToDAttachmentFragments(origin: AttachmentDraftSourceOriginFile, files: FileWithHandle[], options: AttachmentCreationOptions): Promise<DMessageAttachmentFragment[]> {
  const validOutputFragmentsList: DMessageAttachmentFragment[][] = [];

  for (const fileWithHandle of files) {

    // This is the draft we'll edit and update
    const _draft = attachmentCreate({
      media: 'file', origin, fileWithHandle, refPath: fileWithHandle.name,
    });

    // Function to update the attachment draft
    const updateDraft =
      (changes: Partial<Omit<AttachmentDraft, 'outputFragments'>>) => Object.assign(_draft, changes);

    try {
      // 1. Load the input
      await attachmentLoadInputAsync(_draft.source, updateDraft);
      if (!_draft.input) {
        console.warn('', `Failed to load input for file: ${fileWithHandle.name}`);
        continue;
      }

      // 2. Define converters
      attachmentDefineConverters(_draft.source, _draft.input, options, updateDraft);
      if (!_draft.converters.length) {
        console.warn(`No converters defined for file: ${fileWithHandle.name}`);
        continue;
      }

      // 3. Select the already (pre-selected) active, or the first (non-disabled) Converter
      if (_draft.converters.findIndex(_c => _c.isActive) === -1) {
        let activateIndex = _draft.converters.findIndex(_c => !_c.disabled);
        if (activateIndex === -1)
          activateIndex = 0;
        _draft.converters[activateIndex].isActive = true;
      }

      // 4. Perform conversion
      await attachmentPerformConversion(_draft,
        (_, update) => updateDraft(update),
        (_, fragments) => _draft.outputFragments = fragments,
      );
      if (!_draft.outputFragments.length) {
        console.warn(`[DEV] Failed to convert file: ${fileWithHandle.name}`, _draft);
        continue;
      }

      validOutputFragmentsList.push(_draft.outputFragments);
    } catch (error) {
      console.warn(`Error processing file ${fileWithHandle.name}:`, error);
      // allFragments.push([]);  // Add an empty array for failed conversions
    }
  }

  // flatten the list of lists
  return validOutputFragmentsList.flat();
}


================================================
FILE: src/common/attachment-drafts/attachment.types.ts
================================================
import type { FileWithHandle } from 'browser-fs-access';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import type { DMessageAttachmentFragment, DMessageFragment } from '~/common/stores/chat/chat.fragments';
import type { DMessageId } from '~/common/stores/chat/chat.message';


// Attachment Draft

export type AttachmentDraft = {
  readonly id: AttachmentDraftId;
  readonly source: AttachmentDraftSource,
  label: string;  // what's written in the button, such as a web page `title`
  ref: string;    // will be used in ```ref\n...``` for instance the web page `url`

  inputLoading: boolean;
  inputError: string | null;
  input?: AttachmentDraftInput;

  // options to convert the input
  converters: AttachmentDraftConverter[]; // List of available converters for this attachment

  outputsConverting: boolean;
  outputsConversionProgress: number | null;
  outputFragments: DMessageAttachmentFragment[];

  // metadata: {
  //   creationDate?: Date; // Creation date of the file
  //   modifiedDate?: Date; // Last modified date of the file
  //   altText?: string; // Alternative text for images for screen readers
  // };
};

export type AttachmentDraftId = string;


// 0. draft source (filled at the onset)

export type AttachmentDraftSource = {
  media: 'url';
  origin: AttachmentDraftSourceOriginUrl;
  url: string; // parsed valid url
  refUrl: string; // original url literal text (use this as text ref, otherwise use the url)
} | {
  media: 'file';
  origin: AttachmentDraftSourceOriginFile,
  fileWithHandle: FileWithHandle;
  refPath: string; // original file name, or path/to/file name
} | {
  media: 'text';
  method: 'clipboard-read' | AttachmentDraftSourceOriginDTO;
  textPlain?: string;
  textHtml?: string;
} | {
  // special type for attachments thar are references to self (ego, application) objects
  media: 'ego';
  method: 'ego-fragments';
  label: string;
  egoFragmentsInputData: DraftEgoFragmentsInputData;
};

export type AttachmentDraftSourceOriginFile = 'camera' | 'screencapture' | 'file-open' | 'clipboard-read' | AttachmentDraftSourceOriginDTO;

export type AttachmentDraftSourceOriginDTO = 'drop' | 'paste';

export type AttachmentDraftSourceOriginUrl = 'input-link' | 'clipboard-read' | AttachmentDraftSourceOriginDTO;

export type AttachmentCreationOptions = {
  /** Also attach an image representation of the attachment. Requires Release.Features.ENABLE_TEXT_AND_IMAGES as well. */
  hintAddImages?: boolean;
}


// 1. draft input (loaded from the source)

export type AttachmentDraftInput = {
  mimeType: string; // Original MIME type of the file, or application specific type
  data: string | Blob | DraftWebInputData | DraftYouTubeInputData | DraftEgoFragmentsInputData; // The original data of the attachment
  dataSize?: number; // Size of the original data (for plain/simple 1:1 mime)
  altMimeType?: string; // Alternative MIME type for the input
  altData?: string; // Alternative data for the input
  // [media:URL] special for download inputs
  urlImage?: {
    imgDataUrl: string;
    mimeType: string;
    width: number;
    height: number;
    // to discriminate the source
    generator: 'web-capture' | 'youtube-thumbnail';
    timestamp: number; // Unix timestamp
  };
  // preview?: AttachmentPreview; // Preview of the input
};

export type DraftWebInputData = {
  pageText?: string;
  pageMarkdown?: string;
  pageCleanedHtml?: string;
  pageTitle?: string;
}

export type DraftYouTubeInputData = {
  videoId: string;
  videoTitle: string;
  videoDescription: string;
  videoThumbnailUrl: string;
  videoTranscript: string;
}

export type DraftEgoFragmentsInputData = {
  fragments: DMessageFragment[];
  conversationTitle: string;
  conversationId: DConversationId;
  messageId: DMessageId;
}


// 2. draft converters (UI options to convert the input)

export type AttachmentDraftConverter = {
  id: AttachmentDraftConverterType;
  name: string;
  disabled?: boolean;
  unsupported?: boolean;
  isCheckbox?: boolean; // renders as checkbox and is not exclusive with the others

  // runtime properties
  isActive?: boolean; // checked, for both radio (mutually exclusive) and checkbox (additional) converters

  // outputType: ComposerOutputPartType; // The type of the output after conversion
  // isAutonomous: boolean; // Whether the conversion does not require user input
  // isAsync: boolean; // Whether the conversion is asynchronous
  // progress: number; // Conversion progress percentage (0..1)
  // errorMessage?: string; // Error message if the conversion failed
}

export type AttachmentDraftConverterType =
  | 'text' | 'rich-text' | 'rich-text-cleaner' | 'rich-text-table'
  | 'image-original' | 'image-resized-high' | 'image-resized-low' | 'image-ocr' | 'image-to-default'
  | 'pdf-text' | 'pdf-images' | 'pdf-text-and-images'
  | 'docx-to-html'
  | 'url-page-text' | 'url-page-markdown' | 'url-page-html' | 'url-page-null' | 'url-page-image'
  | 'youtube-transcript' | 'youtube-transcript-simple'
  | 'ego-fragments-inlined'
  | 'unhandled';


// 3. Output - this is done via DMessageAttachmentFragment[], to be directly compatible with our data


/*export type AttachmentDraftPreview = {
  renderer: 'noPreview',
  title: string; // A title for the preview
} | {
  renderer: 'textPreview'
  fileName: string; // The name of the file
  snippet: string; // A text snippet for documents
  tooltip?: string; // A tooltip for the preview
} | {
  renderer: 'imagePreview'
  thumbnail: string; // A thumbnail preview for images, videos, etc.
  tooltip?: string; // A tooltip for the preview
};*/



================================================
FILE: src/common/attachment-drafts/store-attachment-drafts_slice.ts
================================================
import type { StoreApi } from 'zustand';
import type { StateCreator } from 'zustand/vanilla';

import type { DBlobDBContextId, DBlobDBScopeId } from '~/common/stores/blob/dblobs-portability';

import type { DMessageAttachmentFragment } from '~/common/stores/chat/chat.fragments';

import type { AttachmentCreationOptions, AttachmentDraft, AttachmentDraftConverter, AttachmentDraftId, AttachmentDraftSource } from './attachment.types';
import { attachmentCreate, attachmentDefineConverters, attachmentLoadInputAsync, attachmentPerformConversion } from './attachment.pipeline';
import { removeAttachmentOwnedDBAsset, transferAttachmentOwnedDBAsset } from './attachment.dblobs';


/// Attachment Draft Slice: per-conversation attachments store ///

interface AttachmentDraftsState {

  attachmentDrafts: AttachmentDraft[];

}

export interface AttachmentsDraftsStore extends AttachmentDraftsState {

  createAttachmentDraft: (source: AttachmentDraftSource, options: AttachmentCreationOptions) => Promise<void>;
  removeAllAttachmentDrafts: () => void;
  removeAttachmentDraft: (attachmentDraftId: AttachmentDraftId) => void;
  moveAttachmentDraft: (attachmentDraftId: AttachmentDraftId, delta: 1 | -1) => void;
  toggleAttachmentDraftConverterAndConvert: (attachmentDraftId: AttachmentDraftId, converterIdx: number | null) => Promise<void>;

  /**
   * Extracts all fragments from the all drafts and transfers ownership to the caller.
   * This store is cleared.
   */
  takeAllFragments: (newContextId: DBlobDBContextId, newScopeId: DBlobDBScopeId) => Promise<DMessageAttachmentFragment[]>;

  /**
   * Extracts typed fragments from the attachment drafts and optionally removes them from the store.
   * If `attachmentDraftId` is null, all the attachments are processed, otherwise only this.
   */
  takeFragmentsByType: (fragmentsType: Extract<DMessageAttachmentFragment['part']['pt'], 'doc'>, attachmentDraftIdOrAll: AttachmentDraftId | null, removeFragments: boolean) => DMessageAttachmentFragment[];

  removeAttachmentDraftOutputFragment: (attachmentDraftId: AttachmentDraftId, fragmentIndex: number) => void;

  _editAttachment: (attachmentDraftId: AttachmentDraftId, update: Partial<Omit<AttachmentDraft, 'outputFragments'>> | ((attachment: AttachmentDraft) => Partial<Omit<AttachmentDraft, 'outputFragments'>>)) => void;
  _replaceAttachmentOutputFragments: (attachmentDraftId: AttachmentDraftId, outputFragments: DMessageAttachmentFragment[]) => void;
  _getAttachment: (attachmentDraftId: AttachmentDraftId) => AttachmentDraft | undefined;

}

export type AttachmentDraftsStoreApi = StoreApi<AttachmentsDraftsStore>;

export const createAttachmentDraftsStoreSlice: StateCreator<AttachmentsDraftsStore, [], [], AttachmentsDraftsStore> = (_set, _get) => ({

  // init state
  attachmentDrafts: [],

  // actions
  createAttachmentDraft: async (source: AttachmentDraftSource, options: AttachmentCreationOptions) => {
    const { _getAttachment, _editAttachment, toggleAttachmentDraftConverterAndConvert } = _get();

    const _attachmentDraft = attachmentCreate(source);
    _set(store => ({
      attachmentDrafts: [...store.attachmentDrafts, _attachmentDraft],
    }));

    const attachmentDraftId = _attachmentDraft.id;
    const editFn = (changes: Partial<Omit<AttachmentDraft, 'outputFragments'>>) => _editAttachment(attachmentDraftId, changes);

    // 1.Resolve the Input
    await attachmentLoadInputAsync(source, editFn);
    const loaded = _getAttachment(attachmentDraftId);
    if (!loaded?.input)
      return;

    // 2. Define the I->O Converters
    attachmentDefineConverters(source, loaded.input, options, editFn);
    const defined = _getAttachment(attachmentDraftId);
    if (!defined?.converters.length)
      return;

    // 3. Select the already active, or the first (non-disabled) Converter
    let cIndex = defined.converters.findIndex(_c => _c.isActive);
    if (cIndex === -1)
      cIndex = defined.converters.findIndex(_c => !_c.disabled);
    if (cIndex === -1)
      cIndex = 0;
    await toggleAttachmentDraftConverterAndConvert(attachmentDraftId, cIndex);
  },

  removeAllAttachmentDrafts: () =>
    _set(state => {

      // remove the associated DBlob items, as we still ahve
      for (const attachmentDraft of state.attachmentDrafts) {
        // Remove the DBlob items associated with the removed fragments
        for (let removedFragment of attachmentDraft.outputFragments) {
          void removeAttachmentOwnedDBAsset(removedFragment);
        }
      }

      return {
        attachmentDrafts: [],
      };
    }),

  removeAttachmentDraft: (attachmentDraftId: AttachmentDraftId) =>
    _set(state => ({
      attachmentDrafts: state.attachmentDrafts.filter(attachment => {
        if (attachment.id !== attachmentDraftId)
          return true;

        // Remove the DBlob items associated with the removed fragments
        for (let removedFragment of attachment.outputFragments) {
          void removeAttachmentOwnedDBAsset(removedFragment);
        }

        // Remove the draft
        return false;
      }),
    })),

  moveAttachmentDraft: (attachmentDraftId: AttachmentDraftId, delta: 1 | -1) =>
    _set(state => {
      const attachments = [...state.attachmentDrafts];
      const currentIdx = attachments.findIndex(a => a.id === attachmentDraftId);

      // If the draft is not found, or if trying to move beyond the array boundaries, no move is needed
      if (currentIdx === -1 || (currentIdx === 0 && delta === -1) || (currentIdx === attachments.length - 1 && delta === 1))
        return state;

      // Swap the draft with the adjacent one in the direction of delta
      const targetIdx = currentIdx + delta;
      [attachments[currentIdx], attachments[targetIdx]] = [attachments[targetIdx], attachments[currentIdx]];

      return { attachmentDrafts: attachments };
    }),

  toggleAttachmentDraftConverterAndConvert: async (attachmentDraftId: AttachmentDraftId, converterIdx: number | null) => {
    const { _getAttachment, _editAttachment, _replaceAttachmentOutputFragments } = _get();

    // null: select none, radio: change the active selection, checkbox: toggle the selection
    _editAttachment(attachmentDraftId, (draft) => {

      // null: uncheck all converters
      if (converterIdx === null) {
        return {
          converters: draft.converters.map((converter): AttachmentDraftConverter => ({ ...converter, isActive: false })),
        };
      }

      // No change if invalid index
      const targetConverter = draft.converters[converterIdx];
      if (!targetConverter) return draft;

      // if checkbox: Toggle only the target checkbox
      if (targetConverter.isCheckbox) {
        return {
          converters: draft.converters.map((converter, idx): AttachmentDraftConverter =>
            idx === converterIdx
              ? { ...converter, isActive: !converter.isActive }
              : converter,
          ),
        };
      } else {
        // For radio buttons: check the target and uncheck all others
        return {
          converters: draft.converters.map((converter, idx): AttachmentDraftConverter =>
            converter.isCheckbox
              ? converter
              : { ...converter, isActive: idx === converterIdx },
          ),
        };
      }
    });

    // Perform the conversion
    const attachmentDraft = _getAttachment(attachmentDraftId);
    if (!attachmentDraft) return;
    await attachmentPerformConversion(attachmentDraft, _editAttachment, _replaceAttachmentOutputFragments);
  },

  takeAllFragments: async (newContextId: DBlobDBContextId, newScopeId: DBlobDBScopeId) => {
    // get all the fragments
    const transferredFragments: DMessageAttachmentFragment[] =
      _get().attachmentDrafts.flatMap(draft => draft.outputFragments);

    // [dblob] transfer ownership (await for transferAttachmentOwnedDBAsset)
    for (const transferredFragment of transferredFragments)
      await transferAttachmentOwnedDBAsset(transferredFragment, newContextId, newScopeId);

    // clear state
    _set({ attachmentDrafts: [] });

    return transferredFragments;
  },

  takeFragmentsByType: (fragmentsType, attachmentDraftIdOrAll, removeFragments): DMessageAttachmentFragment[] => {
    const { attachmentDrafts } = _get();

    const takenFragments: DMessageAttachmentFragment[] = [];
    const keptDrafts: AttachmentDraft[] = [];

    for (const draft of attachmentDrafts) {

      // non-touched attachments
      if (attachmentDraftIdOrAll !== null && draft.id !== attachmentDraftIdOrAll) {
        keptDrafts.push(draft);
        continue;
      }

      // Extract 'doc' attachment fragments (the only allowed)
      const extractedDocFragments = draft.outputFragments.filter(fragment => fragment.part.pt === fragmentsType);
      takenFragments.push(...extractedDocFragments);

      // keep as-is if there's nothing to remove
      if (!removeFragments || extractedDocFragments.length === 0) {
        keptDrafts.push(draft);
        continue;
      }

      // Removal: remove associated DBlob items
      // NOTE: there shall be no DBAsset associated with this purely text 'doc' fragment, but we keep this
      // for consistency and future-proofing
      for (let removedFragment of extractedDocFragments) {
        void removeAttachmentOwnedDBAsset(removedFragment);
      }

      // Removal: leave non-doc fragments in the draft
      const keptFragments = draft.outputFragments.filter(fragment => fragment.part.pt !== fragmentsType);
      if (keptFragments.length || draft.outputsConverting) {
        keptDrafts.push({
          ...draft,
          outputFragments: keptFragments,
        });
      }
    }

    // Remove the text fragments if requested
    if (removeFragments)
      _set({
        attachmentDrafts: keptDrafts,
      });

    return takenFragments;
  },


  removeAttachmentDraftOutputFragment: (attachmentDraftId: AttachmentDraftId, fragmentIndex: number) =>
    _set((state) => {
      const { attachmentDrafts } = state;

      // Find Attachment Draft
      const attachmentIndex = attachmentDrafts.findIndex((a) => a.id === attachmentDraftId);
      if (attachmentIndex === -1) return state;

      // Find the Fragment
      const attachment = attachmentDrafts[attachmentIndex];
      const fragmentToRemove = attachment.outputFragments[fragmentIndex];
      if (!fragmentToRemove) return state;

      // Removal: rmeove associated DBlob items (there are no other references to the fragment, it's only the attachment)
      void removeAttachmentOwnedDBAsset(fragmentToRemove);

      // Create a new array of fragments without the removed one
      const newOutputFragments = [...attachment.outputFragments];
      newOutputFragments.splice(fragmentIndex, 1);

      // If there are no fragments left, remove the entire attachment draft
      if (newOutputFragments.length === 0) {
        const newAttachments = [...attachmentDrafts];
        newAttachments.splice(attachmentIndex, 1);
        return {
          attachmentDrafts: newAttachments,
        };
      }

      // Update the attachment draft with the new fragments
      const newAttachments = [...attachmentDrafts];
      newAttachments[attachmentIndex] = { ...attachment, outputFragments: newOutputFragments };
      return {
        attachmentDrafts: newAttachments,
      };
    }),


  _editAttachment: (attachmentDraftId: AttachmentDraftId, update: Partial<Omit<AttachmentDraft, 'outputFragments'>> | ((attachment: AttachmentDraft) => Partial<Omit<AttachmentDraft, 'outputFragments'>>)) =>
    _set(state => ({
      attachmentDrafts: state.attachmentDrafts.map((attachmentDraft: AttachmentDraft): AttachmentDraft =>
        attachmentDraft.id === attachmentDraftId
          ? { ...attachmentDraft, ...(typeof update === 'function' ? update(attachmentDraft) : update) }
          : attachmentDraft,
      ),
    })),

  _replaceAttachmentOutputFragments: (attachmentDraftId: AttachmentDraftId, outputFragments: DMessageAttachmentFragment[]) =>
    _set(state => ({
      attachmentDrafts: state.attachmentDrafts.map((attachmentDraft: AttachmentDraft): AttachmentDraft => {
        if (attachmentDraft.id !== attachmentDraftId)
          return attachmentDraft;

        // find the removed fragments
        const removedFragments = attachmentDraft.outputFragments.filter(f => !outputFragments.includes(f));

        // remove the DBlob items associated with the removed fragments
        for (let removedFragment of removedFragments) {
          void removeAttachmentOwnedDBAsset(removedFragment);
        }

        return {
          ...attachmentDraft,
          outputFragments,
        };
      }),
    })),

  _getAttachment: (attachmentDraftId: AttachmentDraftId) =>
    _get().attachmentDrafts.find(a => a.id === attachmentDraftId),

});



================================================
FILE: src/common/attachment-drafts/store-attachment-drafts_vanilla.ts
================================================
import { createStore as createVanillaStore } from 'zustand/vanilla';

import { AttachmentDraftsStoreApi, AttachmentsDraftsStore, createAttachmentDraftsStoreSlice } from './store-attachment-drafts_slice';


export const createAttachmentDraftsVanillaStore = (): AttachmentDraftsStoreApi => createVanillaStore<AttachmentsDraftsStore>()((...a) => ({

  // Attachments: attachment drafts
  ...createAttachmentDraftsStoreSlice(...a),

}));


// const _fallbackStoreApi = createPerChatVanillaStore();

// // usages: useAttachmentDrafts
// export const useChatAttachmentsStore = <T, >(vanillaStore: Readonly<AttachmentDraftsStoreApi> | null, selector: (store: AttachmentsDraftsStore) => T): T =>
//   useStore(vanillaStore || fallbackStoreApi, selector);



================================================
FILE: src/common/attachment-drafts/useAttachmentDrafts.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';
import type { FileWithHandle } from 'browser-fs-access';

import { addSnackbar } from '~/common/components/snackbar/useSnackbarsStore';
import { asValidURL } from '~/common/util/urlUtils';
import { getClipboardItems } from '~/common/util/clipboardUtils';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import type { DMessageFragment } from '~/common/stores/chat/chat.fragments';
import type { DMessageId } from '~/common/stores/chat/chat.message';
import { getAllFilesFromDirectoryRecursively, getDataTransferFilesOrPromises } from '~/common/util/fileSystemUtils';
import { useChatAttachmentsStore } from '~/common/chat-overlay/store-perchat_vanilla';

import type { AttachmentDraftSourceOriginDTO, AttachmentDraftSourceOriginFile, AttachmentDraftSourceOriginUrl } from './attachment.types';
import type { AttachmentDraftsStoreApi } from './store-attachment-drafts_slice';


// enable to debug operations
const ATTACHMENTS_DEBUG_INTAKE = false;


function notifyOnlyImages(item: any) {
  if (ATTACHMENTS_DEBUG_INTAKE) console.log('useAttachmentDrafts: Filtered out non-image clipboard item.', { item });
  addSnackbar({ key: 'attach-filtered', message: `Only image attachments are allowed right now.`, type: 'precondition-fail' });
}


/**
 * @param attachmentsStoreApi A Per-Chat or standalone Attachment Drafts store.
 * @param enableLoadURLsOnPaste Only used if invoking attachAppendDataTransfer or attachAppendClipboardItems.
 * @param hintAddImages Attach an additional image representation of the attachment; only if Release.Features.ENABLE_TEXT_AND_IMAGES.
 * @param onFilterAGIFile If defined, run this async function on '.agi.json' files to decide whether to load them (if returns true) or attach them (if returns false).
 * @param filterOnlyImages If true, only image attachments are allowed.
 */
export function useAttachmentDrafts(attachmentsStoreApi: AttachmentDraftsStoreApi | null, enableLoadURLsOnPaste: boolean, hintAddImages: boolean, onFilterAGIFile?: (file: File) => Promise<boolean>, filterOnlyImages?: boolean) {

  // state
  const { _createAttachmentDraft, attachmentDrafts, attachmentsRemoveAll, attachmentsTakeAllFragments, attachmentsTakeFragmentsByType } = useChatAttachmentsStore(attachmentsStoreApi, useShallow(state => ({
    _createAttachmentDraft: state.createAttachmentDraft,
    attachmentDrafts: state.attachmentDrafts,
    attachmentsRemoveAll: state.removeAllAttachmentDrafts,
    attachmentsTakeAllFragments: state.takeAllFragments,
    attachmentsTakeFragmentsByType: state.takeFragmentsByType,
  })));


  // Creation helpers

  /**
   * Append a file to the attachments.
   */
  const attachAppendFile = React.useCallback(async (origin: AttachmentDraftSourceOriginFile, fileWithHandle: FileWithHandle, overrideFileName?: string) => {
    if (ATTACHMENTS_DEBUG_INTAKE)
      console.log('attachAppendFile', origin, fileWithHandle, overrideFileName);

    // special case: intercept AGI files to potentially load them instead of attaching them
    if (fileWithHandle.name.endsWith('.agi.json'))
      if (onFilterAGIFile && await onFilterAGIFile(fileWithHandle))
        return;

    // only-images: ignore by mime
    if (filterOnlyImages && !fileWithHandle.type.startsWith('image/'))
      return notifyOnlyImages(fileWithHandle);

    return _createAttachmentDraft({
      media: 'file', origin, fileWithHandle, refPath: overrideFileName || fileWithHandle.name,
    }, { hintAddImages });
  }, [_createAttachmentDraft, filterOnlyImages, hintAddImages, onFilterAGIFile]);

  /**
   * Append a URL, likely a web page or youtube transcript, to the attachments.
   */
  const attachAppendUrl = React.useCallback((origin: AttachmentDraftSourceOriginUrl, url: string, refUrl?: string) => {
    if (ATTACHMENTS_DEBUG_INTAKE)
      console.log('attachAppendUrl', url);

    const validUrl = asValidURL(url);
    if (!validUrl)
      return false;

    // only-images: ignore URLs as they are not direct images in this flow
    if (filterOnlyImages) {
      notifyOnlyImages(url);
      return false;
    }

    return _createAttachmentDraft({
      media: 'url', origin, url: validUrl, refUrl: refUrl || url,
    }, { hintAddImages });
  }, [_createAttachmentDraft, filterOnlyImages, hintAddImages]);

  /**
   * Append data transfer to the attachments.
   */
  const attachAppendDataTransfer = React.useCallback(async (dt: DataTransfer, method: AttachmentDraftSourceOriginDTO, attachText: boolean): Promise<'as_files' | 'as_url' | 'as_text' | false> => {

    // https://github.com/enricoros/big-AGI/issues/286
    const textHtml = dt.getData('text/html') || '';
    const heuristicIsExcel = textHtml.includes('"urn:schemas-microsoft-com:office:excel"');
    // noinspection HttpUrlsUsage
    const heuristicIsPowerPoint = textHtml.includes('xmlns:m="http://schemas.microsoft.com/office/20') && textHtml.includes('<meta name=Generator content="Microsoft PowerPoint');
    const heuristicBypassImage = heuristicIsExcel || heuristicIsPowerPoint;

    if (ATTACHMENTS_DEBUG_INTAKE) {
      console.log('\nattachAppendDataTransfer', dt.types, `items: ${dt.items.length}, files: ${dt.files.length}, textHtml: ${textHtml}`);
      for (let i = 0; i < dt.items.length; i++) {
        const item = dt.items[i];
        console.log(' - item:', item.kind, item.type, item.getAsFile());
      }
    }

    // get the file items - note: important to not have any async/await or we'll lose the items of the data transfer
    const fileOrFSHandlePromises = heuristicBypassImage
      ? [] /* special case: ignore images from Microsoft Office pastes (prioritize the HTML paste) */
      : getDataTransferFilesOrPromises(dt.items, true);

    // attach File(s)
    if (fileOrFSHandlePromises.length) {

      // rename files from a common prefix, to better relate them (if the transfer contains a list of paths)
      let overrideFileNames: string[] = [];
      if (dt.types.includes('text/plain')) {
        const possiblePlainTextURIs: string[] = dt.getData('text/plain').split(/[\r\n]+/);
        overrideFileNames = mapFileURIsRemovingCommonRadix(possiblePlainTextURIs);
        if (overrideFileNames.length !== fileOrFSHandlePromises.length)
          overrideFileNames = [];
        else if (ATTACHMENTS_DEBUG_INTAKE)
          console.log(' - renamed to:', overrideFileNames);
      }

      for (let fIdx = 0; fIdx < fileOrFSHandlePromises.length; fIdx++) {
        const fileOrFSHandlePromise = fileOrFSHandlePromises[fIdx];

        // Files: nothing to do - Note: some browsers will interpret directories as files and
        // not provide a handle; if that's the case, we can't do anything, so we still add the file
        if (fileOrFSHandlePromise instanceof File) {
          const file = fileOrFSHandlePromise;

          // Directory detection from File objects weak or impossible - e.g. Firefox reports directories with size > 0 on windows (e.g. 4096)
          if (file.type === '' && file.size === 0) {
            console.warn('This browser does not support directories:', file);
          }

          await attachAppendFile(method, file, overrideFileNames[fIdx]);
          continue;
        }

        // Resolve the file system handle
        const fileSystemHandleOrFile = await fileOrFSHandlePromise;

        // Special case: the resolution just returned a File object
        if (fileSystemHandleOrFile instanceof File) {
          await attachAppendFile(method, fileSystemHandleOrFile, overrideFileNames[fIdx]);
          continue;
        }

        // Preferred case: the resolution returned a file system File or Directory handle
        const fileSystemHandle = fileSystemHandleOrFile;
        switch (fileSystemHandle?.kind) {

          // attach file with handle
          case 'file':
            const fileWithHandle = await fileSystemHandle.getFile() as FileWithHandle;
            fileWithHandle.handle = fileSystemHandle;
            await attachAppendFile(method, fileWithHandle, overrideFileNames[fIdx]);
            break;

          // attach all files in a directory as files with handles
          case 'directory':
            for (const { fileWithHandle, relativeName } of await getAllFilesFromDirectoryRecursively(fileSystemHandle))
              await attachAppendFile(method, fileWithHandle, relativeName);
            break;

          default:
            console.warn('Unhandled file system handle kind:', fileSystemHandle);
            break;

        }
      }

      return 'as_files';
    }

    // attach as URL
    const textPlain = dt.getData('text/plain') || '';
    if (textPlain && enableLoadURLsOnPaste) {
      const textPlainUrl = asValidURL(textPlain);
      if (textPlainUrl) {
        void attachAppendUrl(method, textPlainUrl, textPlain);
        return 'as_url';
      }
    }

    // attach as Text/Html (further conversion, e.g. to markdown is done later)
    if (attachText && (textHtml || textPlain)) {

      // only-images: skip this data transfer text attachment
      if (filterOnlyImages) {
        notifyOnlyImages(textPlain || textHtml);
        return false;
      }

      void _createAttachmentDraft({
        media: 'text', method, textPlain, textHtml,
      }, { hintAddImages });

      return 'as_text';
    }

    if (attachText)
      console.warn(`Unhandled '${method}' attachment: `, dt.types?.map(t => `${t}: ${dt.getData(t)}`));

    // did not attach anything from this data transfer
    return false;
  }, [_createAttachmentDraft, attachAppendFile, attachAppendUrl, enableLoadURLsOnPaste, filterOnlyImages, hintAddImages]);

  /**
   * Append clipboard items to the attachments.
   */
  const attachAppendClipboardItems = React.useCallback(async () => {

    // if there's an issue accessing the clipboard, show it passively
    const clipboardItems = await getClipboardItems();
    if (clipboardItems === null) {
      addSnackbar({
        key: 'clipboard-issue',
        type: 'issue',
        message: 'Clipboard empty or access denied',
        overrides: {
          autoHideDuration: 2000,
        },
      });
      return;
    }

    // loop on all the clipboard items
    for (const clipboardItem of clipboardItems) {

      // https://github.com/enricoros/big-AGI/issues/286
      const textHtml = clipboardItem.types.includes('text/html') ? await clipboardItem.getType('text/html').then(blob => blob.text()) : '';
      const heuristicBypassImage = textHtml.startsWith('<table ');

      if (ATTACHMENTS_DEBUG_INTAKE)
        console.log(' - attachAppendClipboardItems.item:', clipboardItem, textHtml, heuristicBypassImage);

      // attach as image
      let imageAttached = false;
      for (const mimeType of clipboardItem.types) {
        if (mimeType.startsWith('image/') && !heuristicBypassImage) {
          try {
            const imageBlob = await clipboardItem.getType(mimeType);
            const imageName = mimeType.replace('image/', 'clipboard.').replaceAll('/', '.') || 'clipboard.png';
            const imageFile = new File([imageBlob], imageName, { type: mimeType });
            void attachAppendFile('clipboard-read', imageFile);
            imageAttached = true;
          } catch (error) {
            // ignore getType error..
          }
        }
      }
      if (imageAttached)
        continue;

      // only-images: skip the rest
      if (filterOnlyImages) {
        notifyOnlyImages(clipboardItem);
        continue;
      }

      // get the Plain text
      const textPlain = clipboardItem.types.includes('text/plain') ? await clipboardItem.getType('text/plain').then(blob => blob.text()) : '';

      // attach as URL
      if (textPlain && enableLoadURLsOnPaste) {
        const textPlainUrl = asValidURL(textPlain);
        if (textPlainUrl) {
          void attachAppendUrl('clipboard-read', textPlainUrl, textPlain);
          continue;
        }
      }

      // attach as Text
      if (textHtml || textPlain) {

        // only-images: skip this clipboard text attachment
        if (filterOnlyImages) {
          notifyOnlyImages(textPlain || textHtml);
          return false;
        }

        void _createAttachmentDraft({
          media: 'text', method: 'clipboard-read', textPlain, textHtml,
        }, { hintAddImages });
        continue;
      }

      console.warn('Clipboard item has no text/html or text/plain item.', clipboardItem.types, clipboardItem);
    }
  }, [_createAttachmentDraft, attachAppendFile, attachAppendUrl, enableLoadURLsOnPaste, filterOnlyImages, hintAddImages]);

  /**
   * Append ego content to the attachments.
   */
  const attachAppendEgoFragments = React.useCallback((fragments: DMessageFragment[], label: string, conversationTitle: string, conversationId: DConversationId, messageId: DMessageId) => {
    if (ATTACHMENTS_DEBUG_INTAKE)
      console.log('attachAppendEgoContent', fragments, label, conversationId, messageId);

    return _createAttachmentDraft({
      media: 'ego',
      method: 'ego-fragments',
      label,
      egoFragmentsInputData: {
        fragments,
        conversationTitle,
        conversationId,
        messageId,
      },
    }, { hintAddImages });
  }, [_createAttachmentDraft, hintAddImages]);


  return {
    // state
    attachmentDrafts,

    // create drafts
    attachAppendClipboardItems,
    attachAppendDataTransfer,
    attachAppendEgoFragments,
    attachAppendFile,
    attachAppendUrl,

    // manage attachments
    attachmentsRemoveAll,
    attachmentsTakeAllFragments,
    attachmentsTakeFragmentsByType,
  };
}


/**
 * Maps a list of file URIs to relative paths, removing a common prefix.
 *
 * Example, takes the following files:
 * - file:///C:/Users/Me/Documents/MyFile1.txt
 * - file:///C:/Users/Me/Documents/Test/MyFile2.txt
 * - file:///C:/Users/Me/Documents/Test/MyFile3.txt
 * And returns:
 * - [ MyFile1.txt, Test/MyFile2.txt, Test/MyFile3.txt ]
 */
function mapFileURIsRemovingCommonRadix(fileURIs: string[]): string[] {

  const filePaths = fileURIs
    .filter((path) => path.startsWith('file:'))
    .map((path) => path.slice(5));

  if (filePaths.length < 2)
    return [];

  const commonRadix = _findCommonStringsPrefix(filePaths);
  if (!commonRadix.endsWith('/'))
    return [];

  return filePaths.map((path) => path.slice(commonRadix.length));
}

function _findCommonStringsPrefix(strings: string[]) {
  if (!strings.length)
    return '';

  const sortedStrings = strings.slice().sort();
  const firstString = sortedStrings[0];
  const lastString = sortedStrings[sortedStrings.length - 1];

  let commonPrefix = '';
  for (let i = 0; i < firstString.length; i++) {
    if (firstString[i] === lastString[i]) {
      commonPrefix += firstString[i];
    } else {
      break;
    }
  }

  return commonPrefix;
}



================================================
FILE: src/common/attachment-drafts/file-converters/DocxToMarkdown.ts
================================================
import { convertToHtml, images } from 'mammoth';


export async function convertDocxToHTML(input: ArrayBuffer): Promise<{ html: string }> {
  try {
    // Dynamically import mammoth
    const result = await convertToHtml({ arrayBuffer: input }, {
      convertImage: images.imgElement(function ignoreImage(image) {
        throw new Error('Images are not supported in DOCX to Markdown conversion');
      }),
    });
    if (result.messages?.length) {
      console.log('Messages from DOCX to Markdown conversion:', result.messages);
    }
    return {
      html: result.value,
    };
  } catch (error) {
    console.error('Error converting DOCX to Markdown:', error);
    throw error;
  }
}



================================================
FILE: src/common/chat-overlay/ConversationHandler.ts
================================================
import type { StoreApi } from 'zustand';

import { bareBonesPromptMixer } from '~/modules/persona/pmix/pmix';

import { SystemPurposes } from '../../data';

import { BeamStore, createBeamVanillaStore } from '~/modules/beam/store-beam_vanilla';
import { useModuleBeamStore } from '~/modules/beam/store-module-beam';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import type { DLLMId } from '~/common/stores/llms/llms.types';
import { ChatActions, getConversationSystemPurposeId, isValidConversation, useChatStore } from '~/common/stores/chat/store-chats';
import { createDMessageEmpty, createDMessageFromFragments, createDMessagePlaceholderIncomplete, createDMessageTextContent, DMessage, DMessageGenerator, DMessageId, DMessageUserFlag, MESSAGE_FLAG_VND_ANT_CACHE_AUTO, MESSAGE_FLAG_VND_ANT_CACHE_USER, messageHasUserFlag, messageSetUserFlag } from '~/common/stores/chat/chat.message';
import { createTextContentFragment, DMessageFragment, DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import { gcChatImageAssets } from '~/common/stores/chat/chat.gc';
import { getChatLLMId } from '~/common/stores/llms/store-llms';

import { getChatAutoAI } from '../../apps/chat/store-app-chat';

import { createDEphemeral, EPHEMERALS_DEFAULT_TIMEOUT } from './store-perchat-ephemerals_slice';
import { createPerChatVanillaStore, PerChatOverlayStore } from './store-perchat_vanilla';


// optimization: cache the actions
const _chatStoreActions = useChatStore.getState() as ChatActions;


/**
 * ConversationHandler is a class to overlay state onto a conversation.
 * It is a singleton per conversationId.
 *  - View classes will react to this class (or its members) to update the UI.
 *  - Controller classes will call directly methods in this class.
 */
export class ConversationHandler {

  private readonly beamStore: StoreApi<BeamStore>;
  private readonly overlayStore: StoreApi<PerChatOverlayStore>;

  constructor(private readonly conversationId: DConversationId) {
    this.beamStore = createBeamVanillaStore();
    this.overlayStore = createPerChatVanillaStore();

    // track the open status of beams - this is meant to be an accelerator for the UI
    this.beamStore.subscribe((state, prevState) => {
      if (state.isOpen === prevState.isOpen) return;
      useModuleBeamStore.getState().setBeamOpenForConversation(this.conversationId, state.isOpen);
    });
  }


  // Conversation Management

  static inlineUpdatePurposeInHistory(conversationId: DConversationId, history: DMessage[], assistantLlmId: DLLMId | undefined): void {
    const purposeId = getConversationSystemPurposeId(conversationId);
    // TODO: HACK: find the persona identiy separately from the "first system message"
    const systemMessageIndex = history.findIndex(m => m.role === 'system');

    let systemMessage: DMessage = systemMessageIndex >= 0
      ? history.splice(systemMessageIndex, 1)[0]
      : createDMessageEmpty('system'); // [chat] new system:'' (non updated)

    // TODO: move this to a proper persona identity management
    // Update the system message with the current persona's message, if formerly unset
    if (!systemMessage.updated && purposeId && SystemPurposes[purposeId]?.systemMessage) {
      systemMessage.purposeId = purposeId;
      const systemMessageText = bareBonesPromptMixer(SystemPurposes[purposeId].systemMessage, assistantLlmId);
      systemMessage.fragments = [createTextContentFragment(systemMessageText)];

      // HACK: this is a special case for the 'Custom' persona, to set the message in stone (so it doesn't get updated when switching to another persona)
      if (purposeId === 'Custom')
        systemMessage.updated = Date.now();

      // HACK: refresh the object to trigger a re-render of this message
      systemMessage = { ...systemMessage };
    }

    history.unshift(systemMessage);
  }

  static inlineUpdateAutoPromptCaching(history: DMessage[]): void {
    let setAuto = getChatAutoAI().autoVndAntBreakpoints;

    // [Anthropic] we need at least 1024 tokens for auto-caching, here we begin from 1000 to even request it
    // NOTE: this is gonna change once we have a view over the "conv (head?) x llm" tokens
    if (setAuto && history.length > 0) {
      const { gt1000 } = history.reduce((acc, message) => {
        if (acc.gt1000) return acc;
        acc.tokens += message.tokenCount || 0;
        acc.gt1000 = acc.tokens > 1000;
        return acc;
      }, { tokens: 0, gt1000: false });
      setAuto = gt1000;
    }

    // update the auto flag on the last two user messages, or remove it if disabled
    let breakpointsRemaining = 2;
    for (let i = history.length - 1; i >= 0; i--) {

      // when disabled: remove prior auto flags if set
      if (!setAuto) {
        if (messageHasUserFlag(history[i], MESSAGE_FLAG_VND_ANT_CACHE_AUTO))
          history[i] = { ...history[i], userFlags: messageSetUserFlag(history[i], MESSAGE_FLAG_VND_ANT_CACHE_AUTO, false) };
        continue;
      }

      // when enabled: set the auto flag on the last two user messages
      const isSystemInstruction = i === 0 && history[i].role === 'system';
      if (!isSystemInstruction && history[i].role !== 'user')
        continue;

      // set the auto flag on the last two user messages, unless the user flag is set on any, and reset the flag on the others
      let autoState = --breakpointsRemaining >= 0 || isSystemInstruction;
      if (autoState && messageHasUserFlag(history[i], MESSAGE_FLAG_VND_ANT_CACHE_USER))
        autoState = false;
      if (autoState !== messageHasUserFlag(history[i], MESSAGE_FLAG_VND_ANT_CACHE_AUTO))
        history[i] = { ...history[i], userFlags: messageSetUserFlag(history[i], MESSAGE_FLAG_VND_ANT_CACHE_AUTO, autoState) };
    }
  }

  setAbortController(abortController: AbortController | null, debugScope: string): void {
    _chatStoreActions.setAbortController(this.conversationId, abortController, debugScope);
  }

  clearAbortController(debugScope: string): void {
    _chatStoreActions.setAbortController(this.conversationId, null, debugScope);
  }

  isIncognito(): boolean | undefined {
    return _chatStoreActions.isIncognito(this.conversationId);
  }

  isValid(): boolean {
    return isValidConversation(this.conversationId);
  }


  // Message Management

  /**
   * @param text assistant text
   * @param generatorName LlmId or string, such as 'GPT Image' | 'DALL·E' | 'react-...' | 'web'
   */
  messageAppendAssistantText(text: string, generatorName: Extract<DMessageGenerator, { mgt: 'named' }>['name']): void {
    const message = createDMessageTextContent('assistant', text);
    message.generator = { mgt: 'named', name: generatorName };
    this.messageAppend(message);
  }

  messageAppendAssistantPlaceholder(placeholderText: string, update?: Partial<DMessage>): { assistantMessageId: DMessageId, placeholderFragmentId: DMessageFragmentId } {
    const message = createDMessagePlaceholderIncomplete('assistant', placeholderText);
    if (update)
      Object.assign(message, update);
    this.messageAppend(message);
    return { assistantMessageId: message.id, placeholderFragmentId: message.fragments[0].fId };
  }

  messageAppend(message: DMessage) {
    _chatStoreActions.appendMessage(this.conversationId, message);
  }

  messageEdit(messageId: string, update: Partial<DMessage> | ((message: DMessage) => Partial<DMessage>), messageComplete: boolean, touch: boolean) {
    _chatStoreActions.editMessage(this.conversationId, messageId, update, messageComplete, touch);
  }

  messagesDelete(messageIds: DMessageId[]): void {
    for (const messageId of messageIds)
      _chatStoreActions.deleteMessage(this.conversationId, messageId);
    void gcChatImageAssets(); // fire/forget
  }

  messageFragmentAppend(messageId: string, fragment: DMessageFragment, complete: boolean, touch: boolean) {
    _chatStoreActions.appendMessageFragment(this.conversationId, messageId, fragment, complete, touch);
  }

  messageFragmentDelete(messageId: string, fragmentId: string, complete: boolean, touch: boolean) {
    _chatStoreActions.deleteMessageFragment(this.conversationId, messageId, fragmentId, complete, touch);
  }

  messageFragmentReplace(messageId: string, fragmentId: string, newFragment: DMessageFragment, messageComplete: boolean) {
    _chatStoreActions.replaceMessageFragment(this.conversationId, messageId, fragmentId, newFragment, messageComplete, true);
  }

  messageHasUserFlag(messageId: DMessageId, userFlag: DMessageUserFlag): boolean {
    const message = _chatStoreActions.historyView(this.conversationId)?.find(m => m.id === messageId);
    if (!message) return false;
    return messageHasUserFlag(message, userFlag);
  }

  messageSetUserFlag(messageId: DMessageId, userFlag: DMessageUserFlag, on: boolean, touch: boolean): void {
    this.messageEdit(messageId, (message) => ({
      userFlags: messageSetUserFlag(message, userFlag, on),
    }), false, touch);
  }

  messageToggleUserFlag(messageId: DMessageId, userFlag: DMessageUserFlag, touch: boolean): void {
    this.messageEdit(messageId, (message) => ({
      userFlags: messageSetUserFlag(message, userFlag, !messageHasUserFlag(message, userFlag)),
    }), false, touch);
  }

  historyClear(): void {
    this.historyReplace([]);
  }

  historyReplace(messages: DMessage[]): void {
    _chatStoreActions.historyReplace(this.conversationId, messages);

    void gcChatImageAssets(); // fire/forget

    // if zeroing the messages, also terminate an active beam
    if (!messages.length)
      this.beamStore.getState().terminateKeepingSettings();
  }

  historyTruncateTo(messageId: DMessageId, offset: number = 0): void {
    _chatStoreActions.historyTruncateToIncluded(this.conversationId, messageId, offset);
  }

  historyViewHeadOrThrow(scope: string): Readonly<DMessage[]> {
    const messages = _chatStoreActions.historyView(this.conversationId);
    if (messages === undefined)
      throw new Error(`allMessages: Conversation not found, ${scope}`);
    return messages;
  }

  historyFindMessageOrThrow(messageId: DMessageId): Readonly<DMessage> | undefined {
    return _chatStoreActions.historyView(this.conversationId)?.find(m => m.id === messageId);
  }

  historyKeepLastThinkingOnly(): void {
    return _chatStoreActions.historyKeepLastThinkingOnly(this.conversationId);
  }

  title(): string | undefined {
    return _chatStoreActions.title(this.conversationId);
  }


  // Beam

  getBeamStore = () => this.beamStore;

  /**
   * Opens a beam over the given history
   *
   * @param viewHistory The history up to the point where the beam is invoked
   * @param importMessages If set, any message to import into the beam as pre-set rays
   * @param destReplaceMessageId If set, the output will replace the message with this id, otherwise it will append to the history
   */
  beamInvoke(viewHistory: Readonly<DMessage[]>, importMessages: DMessage[], destReplaceMessageId: DMessage['id'] | null): void {
    const { open: beamOpen, importRays: beamImportRays, terminateKeepingSettings } = this.beamStore.getState();

    const onBeamSuccess = (messageUpdate: Pick<DMessage, 'fragments' | 'generator'>) => {

      // set output when going back to the chat
      if (destReplaceMessageId) {
        // replace a single message in the conversation history
        this.messageEdit(destReplaceMessageId, messageUpdate, true, true); // [chat] replace assistant:Beam contentParts
      } else {
        // replace (may truncate) the conversation history and append a message
        const newMessage = createDMessageFromFragments('assistant', messageUpdate.fragments); // [chat] append Beam message
        newMessage.purposeId = getConversationSystemPurposeId(this.conversationId) ?? undefined;
        newMessage.generator = messageUpdate.generator;
        // TODO: put the other rays in the metadata?! (reqby @Techfren)
        this.messageAppend(newMessage);
      }

      // close beam
      terminateKeepingSettings();
    };

    beamOpen(viewHistory, getChatLLMId(), !!destReplaceMessageId, onBeamSuccess);
    importMessages.length && beamImportRays(importMessages, getChatLLMId());
  }


  // Ephemerals

  createEphemeralHandler(title: string, initialText: string) {
    const { ephemeralsAppend, ephemeralsUpdate, ephemeralsDelete, getEphemeral } = this.overlayActions;

    // create and append
    const ephemeral = createDEphemeral(title, initialText);
    const eId = ephemeral.id;
    ephemeralsAppend(ephemeral);

    const deleteIfMinimized = () => {
      if (getEphemeral(eId)?.minimized)
        ephemeralsDelete(eId);
    };

    // return a 'handler' (manipulation functions)
    return {
      updateText: (text: string) => ephemeralsUpdate(eId, { text }),
      updateState: (state: object) => ephemeralsUpdate(eId, { state }),
      markAsDone: () => {
        ephemeralsUpdate(eId, { done: true });
        setTimeout(deleteIfMinimized, EPHEMERALS_DEFAULT_TIMEOUT);
      },
    };
  }


  // Overlay Store

  get conversationOverlayStore() {
    return this.overlayStore;
  }

  get overlayActions() {
    return this.overlayStore.getState();
  }

}



================================================
FILE: src/common/chat-overlay/ConversationsManager.ts
================================================
import type { DConversationId } from '~/common/stores/chat/chat.conversation';

import { ConversationHandler } from './ConversationHandler';


/**
 * Singleton to get a global instance related to a conversationId. Note we don't have reference counting, and mainly because we cannot
 * do comprehensive lifecycle tracking.
 *
 * The handlers returned are used for overlaying transitory state on top of DB objects, and to provide utility methods that will survive
 * the former react-state implementation.
 */
export class ConversationsManager {
  private static _instance: ConversationsManager;
  private readonly handlers: Map<DConversationId, ConversationHandler> = new Map();

  static getHandler(conversationId: DConversationId): ConversationHandler {
    const instance = ConversationsManager._instance || (ConversationsManager._instance = new ConversationsManager());
    let handler = instance.handlers.get(conversationId);
    if (!handler) {
      handler = new ConversationHandler(conversationId);
      instance.handlers.set(conversationId, handler);
    }
    return handler;
  }

  // Acquires a ConversationHandler, ensuring automatic release when done, with debug location.
  // enable in 2025, after support from https://github.com/tc39/proposal-explicit-resource-management
  /*usingHandler(conversationId: DConversationId, debugLocation: string) {
    const handler = this.getHandler(conversationId, debugLocation);
    return {
      handler,
      [Symbol.dispose]: () => {
        this.releaseHandler(handler, debugLocation);
      },
    };
  }*/
}


================================================
FILE: src/common/chat-overlay/store-perchat-composer_slice.ts
================================================
import type { StateCreator } from 'zustand/vanilla';

import type { DMetaReferenceItem } from '~/common/stores/chat/chat.message';


/// Chat Overlay Store: per-chat overlay state ///

interface ComposerOverlayState {

  // list of all the references that the composer is holding to, before sending them out in the next message
  inReferenceTo: DMetaReferenceItem[];

}

export interface ComposerOverlayStore extends ComposerOverlayState {

  addInReferenceTo: (item: DMetaReferenceItem) => void;
  removeInReferenceTo: (item: DMetaReferenceItem) => void;
  clearInReferenceTo: () => void;

}


/**
 * NOTE: the Composer state is managed primarily by the component, however there's some state that's:
 *  - associated with the chat (e.g. in-reference-to text)
 *  - persisted across chats
 *
 * This slice manages the in-reference-to text state, but there's also a sister slice that manages the attachment drafts.
 */
export const createComposerOverlayStoreSlice: StateCreator<ComposerOverlayStore, [], [], ComposerOverlayStore> = (_set, _get) => ({

  // init state
  inReferenceTo: [],

  // actions
  addInReferenceTo: (item) => _set(state => ({
    inReferenceTo: [...state.inReferenceTo, item],
  })),

  removeInReferenceTo: (item) => _set(state => ({
    inReferenceTo: state.inReferenceTo.filter((i) => i !== item),
  })),

  clearInReferenceTo: () => _set({ inReferenceTo: [] }),

});



================================================
FILE: src/common/chat-overlay/store-perchat-ephemerals_slice.ts
================================================
import type { StateCreator } from 'zustand/vanilla';

import { agiUuid } from '~/common/util/idUtils';


// configuration
export const EPHEMERALS_DEFAULT_TIMEOUT = 6000;
const EPHEMERALS_DEFAULT_MINIMIZED = true;


/**
 * DEphemeral: For ReAct sidebars, displayed under the chat
 */
export interface DEphemeral {
  id: DEphemeralId;
  title: string;
  text: string;
  state: object;
  done: boolean;        // is complete, shall close after timeout
  minimized: boolean;   // collapsed to a single line
  showStatePane: boolean;   // show the state object
}

type DEphemeralId = string;

export function createDEphemeral(title: string, initialText: string): DEphemeral {
  return {
    id: agiUuid('chat-ephemerals-item'),
    title: title,
    text: initialText,
    state: {},
    done: false,
    minimized: lastMinimized,
    showStatePane: lastShowStatePane,
  };
}


/// Ephemerals Overlay Store ///

let lastMinimized = EPHEMERALS_DEFAULT_MINIMIZED;
let lastShowStatePane = false;

interface EphemeralsOverlayState {

  ephemerals: DEphemeral[];

}

export interface EphemeralsOverlayStore extends EphemeralsOverlayState {

  ephemeralsAppend: (ephemeral: DEphemeral) => void;
  ephemeralsDelete: (ephemeralId: DEphemeralId) => void;
  ephemeralsUpdate: (ephemeralId: DEphemeralId, update: Partial<DEphemeral>) => void;

  ephemeralsToggleMinimized: (ephemeralId: DEphemeralId) => void;
  ephemeralsToggleShowStatePane: (ephemeralId: DEphemeralId) => void;

  getEphemeral: (ephemeralId: DEphemeralId) => Readonly<DEphemeral> | undefined;

}


export const createEphemeralsOverlayStoreSlice: StateCreator<EphemeralsOverlayStore, [], [], EphemeralsOverlayStore> = (_set, _get) => ({

  // init state
  ephemerals: [],

  // actions
  ephemeralsAppend: (ephemeral) =>
    _set((state) => ({
      ephemerals: [...state.ephemerals, ephemeral],
    })),

  ephemeralsDelete: (ephemeralId) =>
    _set((state) => ({
      ephemerals: state.ephemerals.filter((e) => e.id !== ephemeralId),
    })),

  ephemeralsUpdate: (ephemeralId, update) =>
    _set((state) => {
      if (update.minimized !== undefined)
        lastMinimized = update.minimized;
      if (update.showStatePane !== undefined)
        lastShowStatePane = update.showStatePane;
      return {
        ephemerals: state.ephemerals.map((e) =>
          e.id === ephemeralId
            ? { ...e, ...update }
            : e,
        ),
      };
    }),

  ephemeralsToggleMinimized: (ephemeralId) => {
    const { ephemerals, ephemeralsUpdate } = _get();
    const ephemeral = ephemerals.find((e) => e.id === ephemeralId);
    if (ephemeral)
      ephemeralsUpdate(ephemeralId, { minimized: !ephemeral.minimized });
  },

  ephemeralsToggleShowStatePane: (ephemeralId) => {
    const { ephemerals, ephemeralsUpdate } = _get();
    const ephemeral = ephemerals.find((e) => e.id === ephemeralId);
    if (ephemeral)
      ephemeralsUpdate(ephemeralId, { showStatePane: !ephemeral.showStatePane });
  },

  getEphemeral: (ephemeralId) =>
    _get().ephemerals.find((e) => e.id === ephemeralId),

});



================================================
FILE: src/common/chat-overlay/store-perchat-variform_slice.ts
================================================
import type { StateCreator } from 'zustand/vanilla';


/// Chat Overlay Store: per-chat overlay state ///

interface VariformOverlayState {

  variformValues: Record<string, string>;

}

export interface VariformOverlayStore extends VariformOverlayState {

  setVariformValue: (key: string, value: string) => void;
  clearVariformValue: (key: string) => void;

}


export const createVariformOverlayStoreSlice: StateCreator<VariformOverlayStore, [], [], VariformOverlayStore> = (_set, _get) => ({

  // init state
  variformValues: {},

  // actions
  setVariformValue: (key, value) => _set(state => ({
    variformValues: { ...state.variformValues, [key]: value },
  })),
  clearVariformValue: (key) => _set(state => {
    const { [key]: _, ...rest } = state.variformValues;
    return { variformValues: rest };
  }),

});



================================================
FILE: src/common/chat-overlay/store-perchat_vanilla.ts
================================================
import { StoreApi, useStore } from 'zustand';
import { createStore as createVanillaStore } from 'zustand/vanilla';

import { AttachmentDraftsStoreApi, AttachmentsDraftsStore, createAttachmentDraftsStoreSlice } from '~/common/attachment-drafts/store-attachment-drafts_slice';

import { ComposerOverlayStore, createComposerOverlayStoreSlice } from './store-perchat-composer_slice';
import { createEphemeralsOverlayStoreSlice, EphemeralsOverlayStore } from './store-perchat-ephemerals_slice';
import { createVariformOverlayStoreSlice, VariformOverlayStore } from './store-perchat-variform_slice';


/* Per-chat overlay store, combining all the slices.
 * No need to merge all the slices into one object, as the store is a function.
 *
 * This is for now, but if performance is an issue, we can split it back into independent
 * vanilla stores, and just instantiate many of them per each ConversationHandler.
 */
export type PerChatOverlayStore = AttachmentsDraftsStore & ComposerOverlayStore & EphemeralsOverlayStore & VariformOverlayStore;

/* Note: at this time there is another overlay stores, beam (vanilla).
 * - EphemeralsStore was based on EventTarget and subscription/unsubscription to it (inside useEffect),
 *   using `eventUtils` but it's been ported now.
 */
export const createPerChatVanillaStore = (): StoreApi<PerChatOverlayStore> => createVanillaStore<PerChatOverlayStore>()((...a) => ({

  // Attachments: attachment drafts
  ...createAttachmentDraftsStoreSlice(...a),
  // Composer: in-reference-to
  ...createComposerOverlayStoreSlice(...a),
  // Ephemerals: ephemeral messages (ReAct sidebars)
  ...createEphemeralsOverlayStoreSlice(...a),
  // VariForm: form values
  ...createVariformOverlayStoreSlice(...a),

}));


const fallbackStoreApi = createPerChatVanillaStore();

// usages: ChatMessagesList
export const useChatOverlayStore = <T, >(vanillaStore: Readonly<StoreApi<PerChatOverlayStore>> | null, selector: (store: PerChatOverlayStore) => T): T =>
  useStore(vanillaStore || fallbackStoreApi, selector);

// usages: useAttachmentDrafts
export const useChatAttachmentsStore = <T, >(vanillaStore: Readonly<AttachmentDraftsStoreApi> | null, selector: (store: AttachmentsDraftsStore) => T): T =>
  useStore(vanillaStore || fallbackStoreApi, selector);

// usages: Composer
export const useChatComposerOverlayStore = <T, >(vanillaStore: Readonly<StoreApi<ComposerOverlayStore>> | null, selector: (store: ComposerOverlayStore) => T): T =>
  useStore(vanillaStore || fallbackStoreApi, selector);



================================================
FILE: src/common/components/AlreadySet.tsx
================================================
import * as React from 'react';

import { Typography } from '@mui/joy';

import CheckRoundedIcon from '@mui/icons-material/CheckRounded';


export function AlreadySet(props: { required?: boolean }) {
  return (
    <Typography level="body-sm" endDecorator={props.required ? undefined : <CheckRoundedIcon color="success" sx={{ fontSize: 'lg' }} />}>
      {/*Installed Already*/}
      {props.required ? 'required' : 'Already set on server'}
    </Typography>
  );
}


================================================
FILE: src/common/components/AppBreadcrumbs.tsx
================================================
import * as React from 'react';

import { Breadcrumbs, Typography } from '@mui/joy';
import KeyboardArrowRightIcon from '@mui/icons-material/KeyboardArrowRight';

import { Link } from '~/common/components/Link';


const _sx = { p: 0 };

export function AppBreadcrumbs(props: {
  size?: 'sm' | 'md' | 'lg';
  children?: React.ReactNode;
  rootTitle?: React.ReactNode;
  onRootClick?: () => void;
}) {

  // prevent default href

  const { rootTitle, onRootClick } = props;
  const handleRootClick = React.useCallback((e: React.MouseEvent) => {
    e.preventDefault();
    onRootClick?.();
  }, [onRootClick]);

  return <Breadcrumbs size={props.size || 'sm'} separator={<KeyboardArrowRightIcon />} aria-label='breadcrumbs' sx={_sx}>
    {(props.children && !!rootTitle && !!onRootClick)
      ? <AppBreadcrumbs.Link color='neutral' href='#' onClick={handleRootClick}>{props.rootTitle}</AppBreadcrumbs.Link>
      : (typeof props.rootTitle === 'string') ? <Typography>{props.rootTitle}</Typography>
        : props.rootTitle
    }
    {props.children}
    {/*{nav.pnt === 'create-new' && <Link color='neutral' href='#'>Create New</Link>}*/}
    {/*{['Characters', 'Futurama', 'TV Shows', 'Home'].map((item: string) => (*/}
    {/*  <Link key={item} color='neutral' href='#'>*/}
    {/*    {item}*/}
    {/*  </Link>*/}
    {/*))}*/}
  </Breadcrumbs>;
}

// Important, use this as Link
AppBreadcrumbs.Link = Link;

// Important, use this as Leaf
AppBreadcrumbs.Leaf = Typography;



================================================
FILE: src/common/components/AvatarDomainFavicon.tsx
================================================
import * as React from 'react';

import { Avatar } from '@mui/joy';

import { urlExtractDomain } from '~/common/util/urlUtils';


export function AvatarDomainFavicon(props: {
  url: string;
  size?: number;
  iconRes?: number;
  noHover?: boolean;
  noShadow?: boolean;
}) {
  const { url, size = 16, iconRes = 32, noShadow } = props;

  const domain = !url ? '' : urlExtractDomain(url);

  // using Google's favicon service
  const faviconUrl = !domain?.length ? undefined : `https://www.google.com/s2/favicons?domain=${domain}&sz=${iconRes}`;

  return (
    <Avatar
      component='span'
      variant='plain'
      sx={{
        mx: 0.5,
        borderRadius: noShadow ? 0 : 'xs',
        boxShadow: noShadow ? 'none' : 'xs',
        width: size,
        height: size,
        fontSize: size * 0.8,
        // bgcolor: 'neutral.softBg',
        // outline: noShadow ? undefined : '1px solid',
        // outlineColor: noShadow ? undefined : 'neutral.outlinedBorder',
        '&:hover': props.noHover ? undefined : {
          outlineColor: 'neutral.outlinedColor',
          bgcolor: 'neutral.softActiveBg',
          borderRadius: 'none',
          boxShadow: 'md',
        },
      }}
      src={faviconUrl}
    >
      {(domain || '').charAt(0).toUpperCase()}
    </Avatar>
  );
}



================================================
FILE: src/common/components/ButtonAttachFiles.tsx
================================================
import * as React from 'react';
import { fileOpen, FileWithHandle } from 'browser-fs-access';

import { Box, Button, ColorPaletteProp, IconButton, Tooltip } from '@mui/joy';
import AttachFileRoundedIcon from '@mui/icons-material/AttachFileRounded';

import { KeyStroke } from '~/common/components/KeyStroke';


export const buttonAttachSx = {
  tooltip: { px: 1, py: 0.75, lineHeight: '1.5rem' } as const,
  desktop: { justifyContent: 'flex-start' } as const,
} as const;


export async function openFileForAttaching(
  multiple: boolean,
  onAttachFiles: (files: FileWithHandle[], errorMessage: string | null) => void | Promise<void>,
): Promise<void> {
  try {
    const selectedFiles = await fileOpen({ multiple });
    if (selectedFiles) {
      if (Array.isArray(selectedFiles)) {
        if (selectedFiles.length)
          await onAttachFiles(selectedFiles, null);
      } else {
        await onAttachFiles([selectedFiles], null);
      }
    }
  } catch (error: any) {
    // ignore user abort errors, but show others
    if (error?.name !== 'AbortError') {
      console.warn('[DEV] openFileForAttaching error:', { error });
      await onAttachFiles([], error?.message || error?.toString() || 'unknown file open error');
    }
  }
}


export const ButtonAttachFilesMemo = React.memo(ButtonAttachFiles);

function ButtonAttachFiles(props: {
  color?: ColorPaletteProp,
  multiple?: boolean,
  isMobile?: boolean,
  disabled?: boolean,
  fullWidth?: boolean,
  noToolTip?: boolean,
  onAttachFiles: (files: FileWithHandle[], errorMessage: string | null) => void,
}) {

  const { onAttachFiles } = props;

  const handleAttachFilePicker = React.useCallback(() => {
    return openFileForAttaching(props.multiple || false, onAttachFiles);
  }, [onAttachFiles, props.multiple]);

  return props.isMobile ? (
    <IconButton color={props.color} disabled={props.disabled} onClick={handleAttachFilePicker}>
      <AttachFileRoundedIcon />
    </IconButton>
  ) : (
    <Tooltip arrow disableInteractive placement='top-start' title={props.noToolTip ? null : (
      <Box sx={buttonAttachSx.tooltip}>
        <b>Attach files</b><br />
        Drag & drop in chat for faster loads ⚡
        <KeyStroke combo='Ctrl + Shift + F' sx={{ mt: 1, mb: 0.5 }} />
      </Box>
    )}>
      <Button
        variant={props.color ? 'soft' : 'plain'}
        color={props.color || 'neutral'}
        disabled={props.disabled}
        fullWidth={props.fullWidth}
        onClick={handleAttachFilePicker}
        startDecorator={<AttachFileRoundedIcon />}
        sx={buttonAttachSx.desktop}
      >
        File
      </Button>
    </Tooltip>
  );
}



================================================
FILE: src/common/components/ChipExpander.tsx
================================================
import * as React from 'react';

import { Chip, chipClasses } from '@mui/joy';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';


export const chipExpanderSx = {
  px: 1.5,
  [`& .${chipClasses.endDecorator}`]: {
    transition: 'transform 0.2s',
  } as const,
  [`&[aria-expanded='true'] .${chipClasses.endDecorator}`]: {
    transform: 'rotate(-180deg)',
  } as const,
} as const;


export function ChipExpander(props: {
  text: React.ReactNode,
  expanded: boolean,
  size?: 'sm' | 'md' | 'lg',
  onToggleExpanded?: () => void
}) {
  return (
    <Chip
      variant={props.expanded ? 'solid' : 'outlined'}
      size={props.size}
      onClick={props.onToggleExpanded}
      endDecorator={<KeyboardArrowDownIcon />}
      aria-expanded={props.expanded}
      sx={chipExpanderSx}
    >
      {props.text}
    </Chip>
  );
}


================================================
FILE: src/common/components/ChipToggleButton.tsx
================================================
import * as React from 'react';

import type { VariantProp } from '@mui/joy/styles/types';
import { Chip } from '@mui/joy';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';


const _chipTBSx = {
  px: 1.5,
  // [`&[aria-checked='true'] .${chipClasses.endDecorator}`]: {
  //   transform: 'rotate(-180deg)',
  // } as const,
} as const;


export function ChipToggleButton(props: {
  text: React.ReactNode,
  active?: boolean,
  disabled?: boolean,
  size?: 'sm' | 'md' | 'lg',
  showCollapseCaret?: boolean,
  variant?: VariantProp,
  onClick?: () => void
}) {
  return (
    <Chip
      disabled={props.disabled}
      variant={props.active ? 'solid' : props.variant || 'outlined'}
      size={props.size}
      onClick={props.onClick}
      endDecorator={(props.showCollapseCaret && props.active) ? <KeyboardArrowDownIcon /> : undefined}
      aria-checked={props.active}
      sx={_chipTBSx}
    >
      {props.text}
    </Chip>
  );
}


================================================
FILE: src/common/components/CloseablePopup.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, MenuList, styled } from '@mui/joy';
import { ClickAwayListener, Popper, PopperPlacementType } from '@mui/base';


// adds the 'sx' prop to the Popper, and defaults zIndex to 1000
const Popup = styled(Popper)({
  zIndex: 1000,
});


/**
 * Workaround to the Menu in Joy 5-beta.0.
 *
 * This component addresses major changes in the Menu component in Joy 5-beta.0:
 *  - missing callback for onClose
 *  - clickaway listener not working
 *  - dynamic menus unsupported
 *  - ...
 */
export function CloseablePopup(props: {
  menu?: boolean, // whether to render as a MenuList (or as a Box otherwise)
  anchorEl: HTMLElement | null,
  onClose: () => void,

  // looks
  dense?: boolean,
  bigIcons?: boolean,

  placement?: PopperPlacementType,
  maxHeightGapPx?: number,
  noTopPadding?: boolean,
  noBottomPadding?: boolean,
  minWidth?: number,
  maxWidth?: number,
  zIndex?: number,
  sx?: SxProps,

  // unused
  placementOffset?: number[],

  children?: React.ReactNode,
}) {

  const { onClose } = props;

  const handleClose = React.useCallback((event: MouseEvent | TouchEvent | React.KeyboardEvent) => {
    event.stopPropagation();
    onClose();
  }, [onClose]);

  const handleKeyDown = React.useCallback((event: React.KeyboardEvent) => {
    if (event.key === 'Tab') {
      handleClose(event);
    } else if (event.key === 'Escape') {
      if (props.anchorEl)
        props.anchorEl?.focus();
      handleClose(event);
    }
  }, [handleClose, props.anchorEl]);


  // memos
  const modifiersMemo = React.useMemo(() => [{
    name: 'offset',
    options: {
      offset: props.placementOffset || [0, 4],
    },
  }], [props.placementOffset]);

  const styleMemoSx: SxProps = React.useMemo(() => ({

    // style
    backgroundColor: 'background.popup',
    boxShadow: 'md',
    ...(props.maxHeightGapPx !== undefined ? { maxHeight: `calc(100dvh - ${props.maxHeightGapPx}px)`, overflowY: 'auto' } : {}),
    ...(props.maxWidth !== undefined && { maxWidth: props.maxWidth }),
    ...(props.minWidth !== undefined && { minWidth: props.minWidth }),

    // MenuList customizations
    '--ListItem-minHeight': props.dense
      ? '2.25rem' /* 2.25 is the default */
      : '2.5rem', /* we enlarge the default  */
    ...(props.bigIcons && {
      '--Icon-fontSize': 'var(--joy-fontSize-xl2)',
      // '--ListItemDecorator-size': '2.75rem',
    }),
    ...(props.noBottomPadding && { pb: 0 }),
    ...(props.noTopPadding && { pt: 0 }),

    // inject
    ...(props.sx || {}),

  }), [props.dense, props.bigIcons, props.maxHeightGapPx, props.maxWidth, props.minWidth, props.noBottomPadding, props.noTopPadding, props.sx]);


  return (
    <Popup
      role={undefined}
      open={!!props.anchorEl}
      anchorEl={props.anchorEl}
      placement={props.placement}
      disablePortal={false}
      modifiers={modifiersMemo}
      sx={props.zIndex ? { zIndex: props.zIndex } : undefined}
    >
      <ClickAwayListener onClickAway={handleClose}>
        {props.menu ? (
          <MenuList onKeyDown={handleKeyDown} sx={styleMemoSx}>
            {props.children}
          </MenuList>
        ) : (
          <Box onKeyDown={handleKeyDown} sx={styleMemoSx}>
            {props.children}
          </Box>
        )}
      </ClickAwayListener>
    </Popup>
  );
}


================================================
FILE: src/common/components/DarkModeToggleButton.tsx
================================================
import * as React from 'react';

import { Button, IconButton, useColorScheme } from '@mui/joy';
import DarkModeIcon from '@mui/icons-material/DarkMode';
import LightModeIcon from '@mui/icons-material/LightMode';

export const darkModeToggleButtonSx = {
  boxShadow: 'sm',
  backgroundColor: 'background.surface',
  '&:hover': {
    backgroundColor: 'background.popup',
  },
} as const;

export function DarkModeToggleButton(props: { hasText?: boolean }) {

  // external state
  const { mode: colorMode, setMode: setColorMode } = useColorScheme();

  const handleToggleDarkMode = (event: React.MouseEvent) => {
    event.stopPropagation();
    setColorMode(colorMode === 'dark' ? 'light' : 'dark');
  };

  return props.hasText ? (
    <Button
      variant='soft'
      color='neutral'
      onClick={handleToggleDarkMode}
      sx={darkModeToggleButtonSx}
      startDecorator={colorMode !== 'dark' ? <DarkModeIcon color='primary' /> : <LightModeIcon />}
    >
      {colorMode === 'dark' ? 'Light Mode' : 'Dark Mode'}
    </Button>
  ) : (
    <IconButton size='sm' variant='soft' onClick={handleToggleDarkMode} sx={{ ml: 'auto', /*mr: '2px',*/ my: '-0.25rem' /* absorb the menuItem padding */ }}>
      {colorMode !== 'dark' ? <DarkModeIcon /> : <LightModeIcon />}
    </IconButton>
  );
}


================================================
FILE: src/common/components/DataStreamViz.tsx
================================================
/**
 * Copyright (c) 2024 Enrico Ros
 *
 * A taste of the things to come.
 */

import React from 'react';

import { Box } from '@mui/joy';


// configuration
const SHOW_GRID = false;
const GRID_SIZE = 8;
const MAJOR_GRID_INTERVAL = 5;

const MAX_TOKENS = 30;
const TOKEN_CREATION_INTERVAL = 500;

// Original grayscale color palette
const colorPalette = ['#CDD7E1', '#9FA6AD', '#636B74', '#555E68', '#32383E'];
// const shapeOpacity = { min: 0.5, max: 0.9 };

// Additional vibrant colors to use occasionally
const specialColors = ['#FF6B6B', '#4ECDC4', '#45B7D1'];

const sizeVariation = { min: 0.6, max: 1 };
const speedVariation = {
  slow: { min: 20, max: 40 },
  fast: { min: 80, max: 120 },
} as const;

type ShapeType = typeof shapes[number];
const shapes = ['circle', 'rect', 'triangle'] as const;

type Token = {
  x: number;
  y: number;
  size: number;
  speed: number;
  type: ShapeType;
  color: string;
  // opacity: number;
  entryProgress: number;
};


export function DataStreamViz(props: { height: number, speed?: number }) {

  // state
  const containerRef = React.useRef<HTMLDivElement>(null);
  const canvasRef = React.useRef<HTMLCanvasElement>(document.createElement('canvas'));

  const animationRef = React.useRef<number>(0);
  const tokensRef = React.useRef<Token[]>([]);
  const lastTimeRef = React.useRef<number>(0);
  const lastTokenTimeRef = React.useRef<number>(0);

  // derived
  const dpr = window.devicePixelRatio || 1;
  const aliasOffset = dpr / 2;


  const setupCanvas = React.useCallback((canvas: HTMLCanvasElement, width: number, height: number) => {
    canvas.width = width * dpr;
    canvas.height = height * dpr;
    canvas.style.width = `${width}px`;
    canvas.style.height = `${height}px`;

    const ctx = canvas.getContext('2d')!;
    ctx.translate(aliasOffset, aliasOffset);
    ctx.scale(dpr, dpr);
    return ctx;
  }, [aliasOffset, dpr]);


  const createToken = React.useCallback((width: number, height: number) => {
    if (tokensRef.current.length >= MAX_TOKENS) return;
    if (Math.random() > 0.7) return; // Density variation

    const size = GRID_SIZE * (sizeVariation.min + Math.random() * (sizeVariation.max - sizeVariation.min));
    const yPosition = Math.floor(Math.random() * ((height - size) / GRID_SIZE)) * GRID_SIZE;

    // Decide whether to use a special color
    const useSpecialColor = Math.random() < 0.05; // 5% chance to use a special color
    const colorArray = useSpecialColor ? specialColors : colorPalette;
    const colorIndex = Math.floor(Math.random() * colorArray.length);

    const isFast = Math.random() > 0.7 || useSpecialColor; // 30% chance to be fast
    const speed =
      (props.speed || 1) * (
        isFast ? speedVariation.fast.min + Math.random() * (speedVariation.fast.max - speedVariation.fast.min)
          : speedVariation.slow.min + Math.random() * (speedVariation.slow.max - speedVariation.slow.min)
      ) / 1000;

    tokensRef.current.push({
      x: width + size, // Start off-screen
      y: yPosition,
      size: size,
      speed: speed,
      type: shapes[Math.floor(Math.random() * shapes.length)],
      color: colorArray[colorIndex],
      // opacity: useSpecialColor ? 1 : shapeOpacity.min + Math.random() * (shapeOpacity.max - shapeOpacity.min),
      entryProgress: 0,
    });
  }, [props.speed]);


  const drawGrid = React.useCallback((ctx: CanvasRenderingContext2D, width: number, height: number) => {
    ctx.lineWidth = 0.5;

    ctx.strokeStyle = '#f0f0f0';
    for (let y = 0; y <= height; y += GRID_SIZE) {
      ctx.beginPath();
      ctx.moveTo(0, y);
      ctx.lineTo(width, y);
      ctx.stroke();
    }

    for (let x = 0; x <= width; x += GRID_SIZE) {
      ctx.beginPath();
      ctx.strokeStyle = (x / GRID_SIZE) % MAJOR_GRID_INTERVAL === 0 ? '#e0e0e0' : '#f0f0f0';
      ctx.moveTo(x, 0);
      ctx.lineTo(x, height);
      ctx.stroke();
    }
  }, []);

  // Draw token function
  const drawToken = React.useCallback((ctx: CanvasRenderingContext2D, token: Token) => {
    ctx.fillStyle = /*token.entryProgress < 1 ? specialColors[Math.floor(Math.random() * colorPalette.length)] :*/ token.color;
    ctx.strokeStyle = token.color;
    ctx.lineWidth = 0.5;
    // ctx.globalAlpha = /* token.opacity * */ (token.entryProgress < 1 ? token.entryProgress : 1);

    const x = token.x; //  /* - 10 */ * token.size * (1 - token.entryProgress);

    switch (token.type) {
      case 'circle':
        ctx.beginPath();
        ctx.arc(x + token.size / 2, token.y + token.size / 2, token.size / 2, 0, Math.PI * 2);
        ctx.fill();
        ctx.stroke();
        break;
      case 'rect':
        ctx.fillRect(x, token.y, token.size, token.size);
        ctx.strokeRect(x, token.y, token.size, token.size);
        break;
      case 'triangle':
        ctx.beginPath();
        ctx.moveTo(x, token.y + token.size);
        ctx.lineTo(x + token.size / 2, token.y);
        ctx.lineTo(x + token.size, token.y + token.size);
        ctx.closePath();
        ctx.fill();
        ctx.stroke();
        break;
    }

    ctx.globalAlpha = 1;
  }, []);

  // Animation function
  const animate = React.useCallback((currentTime: number) => {
    const canvas = canvasRef.current;
    if (!canvas) return;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    const width = canvas.width / (window.devicePixelRatio || 1);
    const height = canvas.height / (window.devicePixelRatio || 1);

    if (!lastTimeRef.current) lastTimeRef.current = currentTime;
    const deltaTime = currentTime - lastTimeRef.current;

    ctx.clearRect(-1, -1, width + 2, height + 2);

    if (SHOW_GRID) drawGrid(ctx, width, height);

    if (currentTime - lastTokenTimeRef.current > TOKEN_CREATION_INTERVAL) {
      createToken(width, height);
      lastTokenTimeRef.current = currentTime;
    }

    for (let i = tokensRef.current.length - 1; i >= 0; i--) {
      const token = tokensRef.current[i];
      if (token.entryProgress < 1) {
        token.entryProgress += deltaTime / 300; // Adjust entry animation speed
        token.entryProgress = Math.min(token.entryProgress, 1); // Ensure it doesn't exceed 1
      }

      token.x -= token.speed * deltaTime;

      drawToken(ctx, token);

      if (token.x + token.size < 0) {
        tokensRef.current.splice(i, 1);
      }
    }

    lastTimeRef.current = currentTime;
    animationRef.current = requestAnimationFrame(animate);
  }, [createToken, drawGrid, drawToken]);


  React.useEffect(() => {
    const container = containerRef.current;
    if (!container) return;

    const handleResize = () => {
      const width = container.offsetWidth;
      const ctx = setupCanvas(canvasRef.current, width, props.height);
      ctx.clearRect(-1, -1, width + 2, props.height + 2);
    };

    handleResize();
    window.addEventListener('resize', handleResize);

    animationRef.current = requestAnimationFrame(animate);

    return () => {
      window.removeEventListener('resize', handleResize);
      cancelAnimationFrame(animationRef.current);
    };
  }, [animate, props.height, setupCanvas]);


  return (
    <Box
      ref={containerRef}
      sx={{
        height: `${props.height}px`,
        overflow: 'hidden',
        position: 'relative',
        width: '100%', // Ensure the canvas fits horizontally
      }}
    >
      <canvas ref={canvasRef} />
    </Box>
  );
}



================================================
FILE: src/common/components/DebouncedInput.tsx
================================================
import * as React from 'react';

import type { InputProps } from '@mui/joy/Input';
import { Box, IconButton, Input } from '@mui/joy';
import ClearIcon from '@mui/icons-material/Clear';
import SearchIcon from '@mui/icons-material/Search';


type DebounceInputProps = Omit<InputProps, 'onChange'> & {
  /**
   * When true, this will not give up the focus on the input field, and aggressively
   * refocus it after the debounce (assuming the callee will cascade a removal, which
   * is the case for Joy UI Select components).
   */
  aggressiveRefocus?: boolean;
  debounceTimeout: number;
  minChars?: number;
  onDebounce: (value: string) => void;
};

const DebouncedInput: React.FC<DebounceInputProps> = (props: DebounceInputProps) => {

  // state
  const [inputValue, setInputValue] = React.useState('');
  const inputRef = React.useRef<HTMLInputElement>(null);
  const debounceTimerRef = React.useRef<ReturnType<typeof setTimeout>>(undefined);
  const refocusTimerRef = React.useRef<ReturnType<typeof setTimeout>>(undefined);

  // derived state
  const { debounceTimeout, minChars, onDebounce, aggressiveRefocus, ...rest } = props;

  // callbacks

  const handleChange = React.useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const newValue = event.target.value;
    setInputValue(newValue); // Update internal state immediately for a responsive UI

    if (debounceTimerRef.current)
      clearTimeout(debounceTimerRef.current);

    debounceTimerRef.current = setTimeout(() => {
      // reset the timer
      debounceTimerRef.current = undefined;

      // Don't call onDebounce if the input value is too short
      if (newValue && minChars && newValue?.length < minChars)
        return;

      // Call onDebounce with the new value
      onDebounce(newValue);

      // If requested, get back the focus
      if (aggressiveRefocus) {
        if (refocusTimerRef.current)
          clearTimeout(refocusTimerRef.current);

        refocusTimerRef.current = setTimeout(() => {
          refocusTimerRef.current = undefined;
          inputRef.current?.focus();
        }, 20);
      }
    }, debounceTimeout);
  }, [debounceTimeout, aggressiveRefocus, minChars, onDebounce]);

  const handleClear = React.useCallback(() => {
    setInputValue(''); // Clear internal state
    onDebounce(''); // Call onDebounce with empty string
  }, [onDebounce]);


  // Clear all timers on unmount
  React.useEffect(() => {
    return () => {
      if (debounceTimerRef.current)
        clearTimeout(debounceTimerRef.current);
      if (refocusTimerRef.current)
        clearTimeout(refocusTimerRef.current);
    };
  }, []);


  return (
    <Input
      {...rest}
      value={inputValue}
      onChange={handleChange}
      aria-label={rest['aria-label'] || 'Search'}
      startDecorator={<SearchIcon />}
      onKeyDownCapture={!aggressiveRefocus ? undefined : (event) => {
        /* We stop the propagation of the event to prevent the parent component from handling it.
         * This is useful only when used inside a Select with options, as the select is eager to capture
         * the focus at every keystroke. This way we keep the focus.
         */
        event.stopPropagation();
      }}
      endDecorator={
        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
          {!!inputValue && (
            <IconButton size='sm' aria-label='Clear search' onClick={handleClear}>
              <ClearIcon sx={{ fontSize: 'xl' }} />
            </IconButton>
          )}
          {rest.endDecorator}
        </Box>
      }
      slotProps={!aggressiveRefocus ? undefined : {
        input: { ref: inputRef },
      }}
    />
  );
};

export const DebouncedInputMemo = React.memo(DebouncedInput);



================================================
FILE: src/common/components/ErrorBoundary.tsx
================================================
import * as React from 'react';

import { logger } from '~/common/logger';
import { posthogCaptureException } from '~/common/components/3rdparty/PostHogAnalytics';


export interface ErrorBoundaryProps {
  /** UNUSED: just marks the fact that this boundary is the outer */
  outer?: boolean;
  /** Optional: A simple React node to display when an error is caught. */
  fallback?: React.ReactNode;
  /** Optional: A name for this boundary, useful for logging context */
  componentName?: string;
  /** Optional: Callback function when an error is caught (e.g., for external reporting like Sentry) */
  onError?: (error: Error, errorInfo: React.ErrorInfo) => void;
  /** Optional: Called when the reset button in the default fallback is clicked */
  onReset?: () => void; // Added for flexibility with default fallback
  /** Content to render when no error occurs */
  children: React.ReactNode;
}

interface ErrorBoundaryState {
  hasError: boolean;
  error: Error | null;
}


/**
 * A reusable React Error Boundary component using Sherpa styles for fallback.
 * Catches JavaScript errors anywhere in its child component tree,
 * logs those errors using the provided logger, and displays a fallback UI.
 */
export class ErrorBoundary extends React.Component<ErrorBoundaryProps, ErrorBoundaryState> {

  constructor(props: ErrorBoundaryProps) {
    super(props);
    this.state = { hasError: false, error: null };
  }

  static defaultProps: Partial<ErrorBoundaryProps> = {
    componentName: 'UnnamedBoundary',
  };

  static getDerivedStateFromError(error: Error): Partial<ErrorBoundaryState> {
    // Update state so the next render will show the fallback UI.
    return { hasError: true, error };
  }

  componentDidCatch(error: Error, errorInfo: React.ErrorInfo): void {
    const { componentName, onError } = this.props;

    // Log the error using the custom logger
    logger.error(
      `ErrorBoundary caught an error in ${componentName}`,
      {
        error: { name: error.name, message: error.message, stack: error.stack },
        componentStack: errorInfo.componentStack,
      },
    );

    // Capture exception in PostHog
    posthogCaptureException(error, {
      $exception_source: 'error-boundary',
      componentName,
      componentStack: errorInfo.componentStack,
    });

    // Call the optional onError callback for external reporting
    onError?.(error, errorInfo);
  }

  resetErrorBoundary = (): void => {
    const { onReset } = this.props;
    onReset?.();
    this.setState({ hasError: false, error: null });
  };

  render(): React.ReactNode {
    const { hasError, error } = this.state;
    const { outer, children, fallback } = this.props;

    if (hasError && error)
      return fallback ? fallback : (
        <div className='sherpa stopped' style={outer ? {
          minHeight: '100svh',
          display: 'flex',
          flexDirection: 'column',
          alignItems: 'center',
          justifyContent: 'center',
        } : {
          width: '100%',
          height: '100%',
          minHeight: 0,
        }}>
          <div className='vcontent' style={{
            display: 'flex',
            flexDirection: 'column',
            alignItems: 'center',
            gap: '0.25rem',
            marginTop: '-2%',
            marginInline: '1.5rem',
            maxWidth: '90%',
          }}>
            <div className='vivided'>
              <h2 className='heading'>Oops, we hit a snag</h2>
              <div className='message'>
                <p style={{ fontWeight: 500 }}>Something broke; this shouldn&apos;t happen.{outer ? ' Please try reloading Big-AGI.' : ''}</p>
                {/* Dev-only stack trace */}
                {/*{!Release.IsNodeDevBuild ? (*/}
                {/*  <div style={{ opacity: 0.5 }}>*/}
                {/*    {error?.message}*/}
                {/*  </div>*/}
                {/*) : (*/}
                <details>
                  <summary style={{ cursor: 'pointer' }}>Error Details (Dev)</summary>
                  <div style={{ whiteSpace: 'pre-wrap', wordBreak: 'break-word' }}>{`---\n${error?.toString()}\n---\nStack:\n${error?.stack}`}</div>
                </details>
                {/*)}*/}
              </div>
            </div>
            <div style={{ display: 'flex', gap: '0.75rem', marginTop: '1rem' }}>
              {outer ? (
                <button className='button' onClick={() => window.location.reload()}>
                  Reload Big-AGI
                </button>
              ) : (
                <button className='button' onClick={() => this.resetErrorBoundary()}>
                  Clear Error
                </button>
              )}
            </div>
          </div>
        </div>
      );

    return children;
  }
}



================================================
FILE: src/common/components/ExpanderAccordion.tsx
================================================
import * as React from 'react';

import type { SxProps, VariantProp } from '@mui/joy/styles/types';
import { Accordion, AccordionDetails, AccordionGroup, AccordionSummary, accordionSummaryClasses, Box } from '@mui/joy';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';


export function ExpanderAccordion(props: {
  title?: React.ReactNode,
  icon?: React.ReactNode,
  expandedVariant?: VariantProp,
  startCollapsed?: boolean,
  sx?: SxProps,
  children?: React.JSX.Element
}) {

  // state
  const [expanded, setExpanded] = React.useState(props.startCollapsed !== true);

  return (
    <AccordionGroup sx={props.sx}>
      <Accordion
        // variant={expanded ? 'solid' : 'soft'}
        expanded={expanded}
        onChange={(_event, expanded) => setExpanded(expanded)}
      >
        <AccordionSummary
          variant='soft'
          indicator={<KeyboardArrowDownIcon />}
          slotProps={{
            indicator: {
              sx: {
                transition: 'transform 0.2s',
              },
            },
          }}
          sx={{
            [`&.${accordionSummaryClasses.indicator}[aria-expanded='true']`]: {
              transform: 'rotate(-180deg)',
            },
          }}
        >
          {props.icon} {props.title}
        </AccordionSummary>

        <AccordionDetails variant={props.expandedVariant}>
          <Box sx={{ display: 'grid' }}>
            {expanded && props.children}
          </Box>
        </AccordionDetails>

      </Accordion>
    </AccordionGroup>
  );
}


================================================
FILE: src/common/components/ExpanderControlledBox.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, styled } from '@mui/joy';


const BoxCollapser = styled(Box)({
  display: 'grid',
  transition: 'grid-template-rows 0.2s cubic-bezier(.17,.84,.44,1)',
  gridTemplateRows: '0fr',
  '&[aria-expanded="true"]': {
    gridTemplateRows: '1fr',
  },
});

const BoxCollapsee = styled(Box)({
  overflow: 'hidden',
});


export function ExpanderControlledBox(props: { expanded: boolean, children: React.ReactNode, sx?: SxProps }) {
  return (
    <BoxCollapser aria-expanded={props.expanded} sx={props.sx}>
      <BoxCollapsee>
        {props.children}
      </BoxCollapsee>
    </BoxCollapser>
  );
}


================================================
FILE: src/common/components/ExplainerCarousel.tsx
================================================
import React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, Step, stepClasses, StepIndicator, stepIndicatorClasses, Stepper, Typography } from '@mui/joy';
import ArrowBackRoundedIcon from '@mui/icons-material/ArrowBackRounded';
import ArrowForwardRoundedIcon from '@mui/icons-material/ArrowForwardRounded';
import CheckRoundedIcon from '@mui/icons-material/CheckRounded';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';

import { ScaledTextBlockRenderer } from '~/modules/blocks/ScaledTextBlockRenderer';

import { BigAgiSquircleIcon } from '~/common/components/icons/big-agi/BigAgiSquircleIcon';
import { ChatBeamIcon } from '~/common/components/icons/ChatBeamIcon';
import { ShortcutKey, useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { animationTextShadowLimey } from '~/common/util/animUtils';
import { hasGoogleAnalytics, sendGAEvent } from '~/common/components/3rdparty/GoogleAnalytics';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUIContentScaling } from '~/common/stores/store-ui';


// configuration
const colorButtons = 'neutral' as const;
const colorStepper = 'neutral' as const;


// Steps - the top stepper

interface ExplainerStep {
  stepDigits: string,
  stepName: string,
}

const stepSequenceSx: SxProps = {
  // width: '100%',
  [`& .${stepClasses.completed}::after`]: {
    bgcolor: `${colorStepper}.500`,
  },
  [`& .${stepClasses.active} .${stepIndicatorClasses.root}`]: {
    borderColor: `${colorStepper}.500`,
  },
  [`& .${stepClasses.root}:has(+ .${stepClasses.active})::after`]: {
    color: `${colorStepper}.500`,
    backgroundColor: 'transparent',
    backgroundImage: 'radial-gradient(currentColor 2px, transparent 2px)',
    backgroundSize: '7px 7px',
    backgroundPosition: 'center left',
  },
};

const buttonBaseSx: SxProps = {
  justifyContent: 'space-between',
  minHeight: '2.5rem',
  minWidth: 120,
};

const buttonNextSx: SxProps = {
  ...buttonBaseSx,
  boxShadow: `0 8px 24px -4px rgb(var(--joy-palette-${colorButtons}-mainChannel) / 20%)`,
  minWidth: 180,
};


function AllStepsStepper(props: {
  steps: ExplainerStep[],
  activeIndex: number,
  isMobile: boolean,
  onStepClicked: (stepIndex: number) => void,
}) {
  return (
    <Stepper sx={stepSequenceSx}>
      {props.steps.map(((step, stepIndex) => {
        const completed = props.activeIndex > stepIndex;
        const active = props.activeIndex === stepIndex;
        return (
          <Step
            key={'step-' + stepIndex}
            orientation='vertical'
            completed={completed}
            active={active}
            indicator={
              <StepIndicator
                variant={(completed || active) ? 'solid' : 'outlined'}
                color={colorStepper}
                onClick={() => props.onStepClicked(stepIndex)}
                sx={{ cursor: 'pointer' }}
              >
                {completed ? <CheckRoundedIcon sx={{ fontSize: 'md' }} /> : active ? <KeyboardArrowDownIcon sx={{ fontSize: 'lg' }} /> : undefined}
              </StepIndicator>
            }
          >
            <Typography
              fontSize={props.isMobile ? 'sm' : undefined}
              fontWeight='xl'
              endDecorator={
                step.stepName && <Typography fontSize='sm' fontWeight='normal' sx={{ mr: 0.5 }}>{step.stepName}</Typography>
              }
            >{step.stepDigits ?? null}</Typography>
          </Step>
        );
      }))}
    </Stepper>
  );
}


// The Explainer - Carousel of pages

export interface ExplainerPage extends ExplainerStep {
  titlePrefix?: string,
  titleSquircle?: boolean,
  titleSpark?: string,
  titleSuffix?: string,
  mdContent: string
}

export function ExplainerCarousel(props: {
  explainerId: string,
  steps: ExplainerPage[],
  footer?: React.ReactNode,
  noStepper?: boolean,
  onFinished: () => any,
}) {

  // state
  const [stepIndex, setStepIndex] = React.useState(0);

  // external state
  const isMobile = useIsMobile();
  const contentScaling = useUIContentScaling();

  // derived state
  const { onFinished } = props;
  const isFirstPage = stepIndex === 0;
  const isLastPage = stepIndex === props.steps.length - 1;
  const activeStep = props.steps[stepIndex] ?? null;

  // handlers

  const mdText = activeStep?.mdContent ?? null;

  const handlePrevPage = React.useCallback(() => {
    setStepIndex(step => step > 0 ? step - 1 : step);
  }, []);

  const handleNextPage = React.useCallback(() => {
    if (isLastPage) {
      hasGoogleAnalytics && sendGAEvent('event', 'tutorial_complete', { tutorial_id: props.explainerId });
      onFinished();
    } else
      setStepIndex(step => step < props.steps.length - 1 ? step + 1 : step);
  }, [isLastPage, onFinished, props.explainerId, props.steps.length]);

  React.useEffect(() => {
    const recordTutorialBegun = () => {
      hasGoogleAnalytics && sendGAEvent('event', 'tutorial_begin', { tutorial_id: props.explainerId });
    };

    const timeoutId = setTimeout(recordTutorialBegun, 500);
    return () => clearTimeout(timeoutId);
  }, [props.explainerId]);


  useGlobalShortcuts('ExplainerCarousel', React.useMemo(() => [
    { key: ShortcutKey.Left, action: handlePrevPage },
    { key: ShortcutKey.Right, action: handleNextPage },
  ], [handleNextPage, handlePrevPage]));


  // [effect] restart from 0 if steps change
  // React.useEffect(() => {
  //   setStepIndex(0);
  // }, [props.steps]);


  return (
    <Box sx={{
      flex: 1,
      mx: 'auto',
      width: { sm: '92%', md: '86%' }, /* Default to 80% width */
      maxWidth: '820px',    /* But don't go over 900px */

      // content
      display: 'flex',
      flexDirection: 'column',
      justifyContent: 'space-evenly',
      gap: 2,
    }}>


      {/* Page Title */}
      <Typography
        level='h1'
        component='h1'
        sx={{
          fontSize: isMobile ? '2rem' : '2.5rem',
          fontWeight: 'md',
          textAlign: 'center',
          whiteSpace: 'balance',
        }}>
        {activeStep?.titlePrefix}{' '}
        {!!activeStep?.titleSquircle && <BigAgiSquircleIcon inverted sx={{ color: 'white', fontSize: isMobile ? '1.55rem' : '2.04rem', borderRadius: 'md' }} />}
        {!!activeStep?.titleSquircle && '-'}
        {!!activeStep?.titleSpark && <Box component='span' sx={{
          fontWeight: 'lg',
          color: 'neutral.softColor',
          animation: `${animationTextShadowLimey} 5s infinite`,
          /*, animation: `${animationTextShadowLimey} 15s linear infinite`*/
        }}>
          {activeStep.titleSpark}
        </Box>}{activeStep?.titleSuffix}
      </Typography>


      {/* Page Message */}
      <Box sx={{ display: 'flex', flexDirection: 'column', alignItems: 'center', gap: 1 }}>

        {/* Main Card with the markdown body */}
        {!!mdText && (
          <Box sx={{
            minHeight: '24rem',
            backgroundColor: 'background.popup',
            borderRadius: 'lg',
            boxShadow: '0 60px 32px -60px rgb(var(--joy-palette-primary-darkChannel) / 0.14)',
            mb: 2,
            px: { xs: 1, md: 2 },
            py: 2,

            // customize the embedded GitHub Markdown for transparent images
            ['.markdown-body img']: {
              '--color-canvas-default': 'transparent!important',
            },
          }}>
            <ScaledTextBlockRenderer
              text={mdText}
              contentScaling={contentScaling /* was: 'md' */}
              textRenderVariant='markdown'
            />
          </Box>
        )}

        {/* Advance Button */}
        <Button
          variant='solid'
          color={colorButtons}
          onClick={handleNextPage}
          endDecorator={isLastPage ? <ChatBeamIcon /> : <ArrowForwardRoundedIcon />}
          sx={buttonNextSx}
        >
          {isLastPage ? 'Start' : 'Next'}
        </Button>

        {/* Back Button */}
        <Button
          variant='plain'
          color={colorButtons}
          disabled={isFirstPage}
          onClick={handlePrevPage}
          startDecorator={<ArrowBackRoundedIcon />}
          sx={buttonBaseSx}
        >
          Previous
        </Button>

      </Box>


      {/* All Steps */}
      {props.noStepper ? null : (
        <AllStepsStepper
          steps={props.steps}
          activeIndex={stepIndex}
          isMobile={isMobile}
          onStepClicked={setStepIndex}
        />
      )}


      {/* Final words of wisdom (also perfect for centering the other components) */}
      {props.footer}

    </Box>
  );
}


================================================
FILE: src/common/components/ExternalDocsLink.tsx
================================================
import * as React from 'react';

import type { ColorPaletteProp, TypographySystem } from '@mui/joy/styles/types';
import { Brand } from '~/common/app.config';
import { ExternalLink } from '~/common/components/ExternalLink';


export function ExternalDocsLink(props: {
  docPage: string;
  color?: ColorPaletteProp,
  level?: keyof TypographySystem | 'inherit',
  highlight?: boolean;
  children: React.ReactNode,
}) {
  return (
    <ExternalLink
      href={Brand.Docs.Public(props.docPage)}
      color={props.color}
      level={props.level}
      highlight={props.highlight}
      icon='public-docs'
    >
      {props.children}
    </ExternalLink>
  );
}


================================================
FILE: src/common/components/ExternalLink.tsx
================================================
import * as React from 'react';

import type { ColorPaletteProp, SxProps, TypographySystem } from '@mui/joy/styles/types';
import AutoStoriesOutlinedIcon from '@mui/icons-material/AutoStoriesOutlined';
import LaunchIcon from '@mui/icons-material/Launch';

import { Link } from './Link';


const wowStyle: SxProps = {
  textDecoration: 'underline',
  textDecorationThickness: '0.4em',
  textDecorationColor: 'rgba(var(--joy-palette-primary-lightChannel) / 1)',
  // textDecorationColor: 'rgba(0 255 0 / 0.5)',
  textDecorationSkipInk: 'none',
  // textUnderlineOffset: '-0.5em',
};


export function ExternalLink(props: {
  href: string,
  color?: ColorPaletteProp,
  level?: keyof TypographySystem | 'inherit',
  highlight?: boolean,
  icon?: 'issue' | 'public-docs',
  children: React.ReactNode,
}) {
  return (
    <Link level={props.level} color={props.color} href={props.href} target='_blank' sx={props.highlight ? wowStyle : undefined}>
      {props.children} {(props.icon === 'issue' || props.icon === 'public-docs')
      ? <AutoStoriesOutlinedIcon sx={{ mx: 0.5, fontSize: 16 }} />
      : <LaunchIcon sx={{ mx: 0.5, fontSize: 16 }} />
    }
    </Link>
  );
}


================================================
FILE: src/common/components/FeatureBadge.tsx
================================================
import * as React from 'react';

import { Badge, BadgeProps } from '@mui/joy';

import { uiSetDismissed, useUIIsDismissed } from '~/common/stores/store-ui';


// configuration
const DEBUG_SHOW_ALL = false;  // set to true to show all badges (for debugging purposes)
const FEATURE_COLOR = 'color-feature';


export function FeatureBadge(props: Omit<BadgeProps, 'size'> & {
  /** will be prefixed with 'feature-badge-...' */
  featureKey: string;
  active: boolean;
  label?: React.ReactNode;
  size?: 'sm' | 'md' | 'lg';  // default: 'sm'
}) {

  const { featureKey: featureKeySuffix, active, label, size = 'sm', color, children, ...badgeProps } = props;
  const featureKey = 'feature-badge-' + featureKeySuffix;

  // external state
  const isDismissed = useUIIsDismissed(featureKey) ?? false;


  // [effect] mark as dismissed when the feature flips to active for the first time
  const firstFlip = !isDismissed && active;
  React.useEffect(() => {
    firstFlip && uiSetDismissed(featureKey);
  }, [featureKey, firstFlip]);


  // NOTE: changes the DOM structure (1 level less)
  const invisible = isDismissed || active;
  if (!DEBUG_SHOW_ALL && invisible)
    return children;

  return (
    <Badge
      // invisible={invisible}
      size={size}
      color={color ?? FEATURE_COLOR as any}
      badgeContent={label}
      {...badgeProps}
    >
      {children}
    </Badge>
  );
}



================================================
FILE: src/common/components/GitHubProjectIssueCard.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Card, Link as MuiLink, Typography } from '@mui/joy';
import GitHubIcon from '@mui/icons-material/GitHub';


export const GitHubProjectIssueCard = (props: {
  issue: number,
  text: string,
  note?: string | React.ReactNode,
  note2?: string | React.ReactNode,
  sx?: SxProps
}) =>
  <Card variant='outlined' color='primary' sx={props.sx}>
    <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
      <GitHubIcon />
      <Typography level='body-sm'>
        <MuiLink overlay href={`https://github.com/enricoros/big-AGI/issues/${props.issue}`} target='_blank'>
          big-AGI #{props.issue}
        </MuiLink>
        {' · '}{props.text}.
      </Typography>
    </Box>
    {!!props.note && (
      <Typography level='body-sm' sx={{ mt: 1 }}>
        {props.note}
      </Typography>
    )}
    {!!props.note2 && (
      <Typography level='body-sm' sx={{ mt: 1 }}>
        {props.note2}
      </Typography>
    )}
  </Card>;


================================================
FILE: src/common/components/GoodTooltip.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Tooltip } from '@mui/joy';


const defaultSx: SxProps = {
  maxWidth: { sm: '50vw', md: '25vw' },
  whiteSpace: 'break-spaces',
};

/**
 * Tooltip with text that wraps to multiple lines (doesn't go too long)
 */
export const GoodTooltip = (props: {
  title: React.ReactNode,
  placement?: 'top' | 'bottom' | 'top-start',
  isError?: boolean, isWarning?: boolean,
  enableInteractive?: boolean,
  arrow?: boolean,
  variantOutlined?: boolean,
  children: React.JSX.Element,
  sx?: SxProps
}) =>
  <Tooltip
    title={props.title}
    placement={props.placement}
    disableInteractive={!props.enableInteractive}
    arrow={props.arrow}
    variant={(props.isError || props.isWarning) ? 'soft' : props.variantOutlined ? 'outlined' : undefined}
    color={props.isError ? 'danger' : props.isWarning ? 'warning' : undefined}
    sx={!props.sx ? defaultSx : { ...defaultSx, ...props.sx }}
  >
    {props.children}
  </Tooltip>;



================================================
FILE: src/common/components/InlineError.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Alert, Typography } from '@mui/joy';

export function InlineError(props: { error: Error | React.JSX.Element | null | any, severity?: 'warning' | 'danger' | 'info', sx?: SxProps }) {
  const color = props.severity === 'info' ? 'primary' : props.severity || 'warning';
  return (
    <Alert variant='soft' color={color} sx={{ mt: 1, ...props.sx }}>
      <Typography level='body-sm' color={color} sx={{ wordBreak: 'break-word' /* for long-word errors to not overflow-x on mobile */}}>
        {props.error?.message || props.error || 'Unknown error'}
      </Typography>
    </Alert>
  );
}



================================================
FILE: src/common/components/InlineTextarea.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Textarea } from '@mui/joy';

import { useUIPreferencesStore } from '~/common/stores/store-ui';

/**
 * TODO: P3: use Buttons when possible instead of the Blur action. Should add them to the bottom? See `ContentPartTextEdit` for a newer impl.
 */
export function InlineTextarea(props: {
  initialText: string,
  disableAutoSaveOnBlur?: boolean // NOTE: this will disable the enter=newline as well
  placeholder?: string,
  decolor?: boolean,
  invertedColors?: boolean,
  centerText?: boolean,
  minRows?: number,
  syncWithInitialText?: boolean, // optional. if set, the text will be reset to initialText when the prop changes
  selectAllOnFocus?: boolean, // optional. if set to false, text won't be selected on focus (default: true)
  onEdit: (text: string) => void,
  onCancel?: () => void,
  sx?: SxProps,
}) {

  const [text, setText] = React.useState(props.initialText);
  const enterIsNewline = useUIPreferencesStore(state => (!props.disableAutoSaveOnBlur && state.enterIsNewline));


  // [effect] optional syncing of the text to the initial text. warning, will discard the current partial edit
  React.useEffect(() => {
    if (props.syncWithInitialText)
      setText(props.initialText);
  }, [props.syncWithInitialText, props.initialText]);


  // handlers

  const handleEditTextChanged = (e: React.ChangeEvent<HTMLTextAreaElement>) => setText(e.target.value);

  const handleEditKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter') {
      const shiftOrAlt = e.shiftKey || e.altKey;
      if (enterIsNewline ? shiftOrAlt : !shiftOrAlt) {
        e.preventDefault();
        props.onEdit(text);
      }
    } else if (e.key === 'Escape') {
      e.preventDefault();
      e.stopPropagation();
      props.onCancel?.();
    }
  };

  const handleEditBlur = () => {
    if (!props.disableAutoSaveOnBlur)
      props.onEdit(text);
  };

  return (
    <Textarea
      variant={props.invertedColors ? 'plain' : 'soft'}
      color={props.decolor ? undefined : props.invertedColors ? 'primary' : 'warning'}
      autoFocus={!props.decolor}
      minRows={props.minRows !== undefined ? props.minRows : 1}
      placeholder={props.placeholder}
      value={text}
      onChange={handleEditTextChanged}
      onKeyDown={handleEditKeyDown}
      onBlur={props.disableAutoSaveOnBlur ? undefined : handleEditBlur}
      slotProps={{
        textarea: {
          enterKeyHint: enterIsNewline ? 'enter' : 'done',
          ...(props.centerText && {
            sx: { textAlign: 'center' },
          }),
          onFocus: (props.selectAllOnFocus === false) ? undefined : (e) => {
            // Select all text when the textarea receives focus
            // This is a great default behavior for all the inline text edits
            e.target?.select();
          },
        },
      }}
      sx={props.sx}
    />
  );
}


================================================
FILE: src/common/components/KeyStroke.tsx
================================================
import * as React from 'react';

import type { SxProps, VariantProp } from '@mui/joy/styles/types';
import { Chip } from '@mui/joy';

import { Is } from '~/common/util/pwaUtils';
import { hideOnMobile } from '~/common/app.theme';


export function platformAwareKeystrokes(text: string) {
  return Is.OS.MacOS
    ? text
      .replaceAll('Ctrl', '⌃' /* Control */)
      .replaceAll('Alt', '⌥' /* Option */)
      .replaceAll('Shift', '⇧')
    // Optional: Replace "Enter" with "Return" if you want to align with Mac keyboard labeling
    // .replaceAll('Enter', 'Return')
    : text;
}

/**
 * Shows a shortcut combo in a nicely presented dark box.
 */
export function KeyStroke(props: {
  combo: string,
  size?: 'sm' | 'md' | 'lg',
  variant?: VariantProp,
  sx?: SxProps,
}) {
  return (
    <Chip
      size={props.size ?? 'md'}
      variant={props.variant}
      color='neutral'
      sx={props.sx ? { ...hideOnMobile, ...props.sx } : hideOnMobile}
    >
      {platformAwareKeystrokes(props.combo)}
    </Chip>
    // <Box sx={{
    //   position: 'relative', display: 'inline-block', px: 1, py: 0.5,
    //   bg: 'rgba(0,0,0,0.75)', color: 'white', borderRadius: 1,
    //   fontSize: 12, fontWeight: 'md', lineHeight: 1, whiteSpace: 'nowrap',
    // }}>
    //   <Box sx={{ position: 'absolute', top: 0, left: 0, width: '100%', height: '100%', bg: 'rgba(0,0,0,0.5)', borderRadius: 1 }} />
    //   {props.combo}
    // </Box>
  );
}


================================================
FILE: src/common/components/Languages.json
================================================
{
  "Afrikaans": "af-ZA",
  "አማርኛ": "am-ET",
  "Azərbaycanca": "az-AZ",
  "বাংলা": { "বাংলাদেশ": "bn-BD", "ভারত": "bn-IN" },
  "Bahasa Indonesia": "id-ID",
  "Bahasa Melayu": "ms-MY",
  "Català": "ca-ES",
  "Čeština": "cs-CZ",
  "Dansk": "da-DK",
  "Deutsch": "de-DE",
  "English": {
    "Australia": "en-AU",
    "Canada": "en-CA",
    "India": "en-IN",
    "Kenya": "en-KE",
    "Tanzania": "en-TZ",
    "Ghana": "en-GH",
    "New Zealand": "en-NZ",
    "Nigeria": "en-NG",
    "South Africa": "en-ZA",
    "Philippines": "en-PH",
    "United Kingdom": "en-GB",
    "United States": "en-US"
  },
  "Español": {
    "Argentina": "es-AR",
    "Bolivia": "es-BO",
    "Chile": "es-CL",
    "Colombia": "es-CO",
    "Costa Rica": "es-CR",
    "Ecuador": "es-EC",
    "El Salvador": "es-SV",
    "España": "es-ES",
    "Estados Unidos": "es-US",
    "Guatemala": "es-GT",
    "Honduras": "es-HN",
    "México": "es-MX",
    "Nicaragua": "es-NI",
    "Panamá": "es-PA",
    "Paraguay": "es-PY",
    "Perú": "es-PE",
    "Puerto Rico": "es-PR",
    "República Dominicana": "es-DO",
    "Uruguay": "es-UY",
    "Venezuela": "es-VE"
  },
  "Euskara": "eu-ES",
  "Filipino": "fil-PH",
  "Français": "fr-FR",
  "Basa Jawa": "jv-ID",
  "Galego": "gl-ES",
  "ગુજરાતી": "gu-IN",
  "Hrvatski": "hr-HR",
  "IsiZulu": "zu-ZA",
  "Íslenska": "is-IS",
  "Italiano": { "Italia": "it-IT", "Svizzera": "it-CH" },
  "ಕನ್ನಡ": "kn-IN",
  "ភាសាខ្មែរ": "km-KH",
  "Latviešu": "lv-LV",
  "Lietuvių": "lt-LT",
  "മലയാളം": "ml-IN",
  "मराठी": "mr-IN",
  "Magyar": "hu-HU",
  "ລາວ": "lo-LA",
  "Nederlands": "nl-NL",
  "नेपाली भाषा": "ne-NP",
  "Norsk bokmål": "nb-NO",
  "Polski": "pl-PL",
  "Português": { "Brasil": "pt-BR", "Portugal": "pt-PT" },
  "Română": "ro-RO",
  "සිංහල": "si-LK",
  "Slovenščina": "sl-SI",
  "Basa Sunda": "su-ID",
  "Slovenčina": "sk-SK",
  "Suomi": "fi-FI",
  "Svenska": "sv-SE",
  "Kiswahili": { "Tanzania": "sw-TZ", "Kenya": "sw-KE" },
  "ქართული": "ka-GE",
  "Հայերեն": "hy-AM",
  "தமிழ்": {
    "இந்தியா": "ta-IN",
    "சிங்கப்பூர்": "ta-SG",
    "இலங்கை": "ta-LK",
    "மலேசியா": "ta-MY"
  },
  "తెలుగు": "te-IN",
  "Tiếng Việt": "vi-VN",
  "Türkçe": "tr-TR",
  "اُردُو": { "پاکستان": "ur-PK", "بھارت": "ur-IN" },
  "Ελληνικά": "el-GR",
  "български": "bg-BG",
  "Pусский": "ru-RU",
  "Српски": "sr-RS",
  "Українська": "uk-UA",
  "한국어": "ko-KR",
  "中文": {
    "普通话 (中国大陆)": "cmn-Hans-CN",
    "普通话 (香港)": "cmn-Hans-HK",
    "中文 (台灣)": "cmn-Hant-TW",
    "粵語 (香港)": "yue-Hant-HK"
  },
  "日本語": "ja-JP",
  "हिन्दी": "hi-IN",
  "ภาษาไทย": "th-TH"
}


================================================
FILE: src/common/components/LanguageSelect.tsx
================================================
import * as React from 'react';

import { Option, Select } from '@mui/joy';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';

import { useUIPreferencesStore } from '~/common/stores/store-ui';


// languages are defined as a JSON file
import languages from './Languages.json';


export function LanguageSelect() {
  // external state

  const preferredLanguage = useUIPreferencesStore(state => state.preferredLanguage);

  const handleLanguageChanged = (_event: any, newValue: string | null) => {
    if (!newValue) return;
    useUIPreferencesStore.getState().setPreferredLanguage(newValue as string);

    // NOTE: disabled, to make sure the code can be adapted at runtime - will re-enable to trigger translations, if not dynamically switchable
    //if (isBrowser)
    //  window.location.reload();
  };

  const languageOptions = React.useMemo(() => Object.entries(languages).map(([language, localesOrCode]) =>
    typeof localesOrCode === 'string'
      ? (
        <Option key={localesOrCode} value={localesOrCode}>
          {language}
        </Option>
      ) : (
        Object.entries(localesOrCode).map(([country, code]) => (
          <Option key={code} value={code}>
            {`${language} (${country})`}
          </Option>
        ))
      )), []);

  return (
    <Select value={preferredLanguage} onChange={handleLanguageChanged}
            indicator={<KeyboardArrowDownIcon />}
            slotProps={{
              root: { sx: { minWidth: 200 } },
              indicator: { sx: { opacity: 0.5 } },
            }}>
      {languageOptions}
    </Select>
  );
}


================================================
FILE: src/common/components/Link.tsx
================================================
import * as React from 'react';
import { useRouter } from 'next/router';
import NextLink, { LinkProps as NextLinkProps } from 'next/link';

import { Link as MuiLink, LinkProps as MuiLinkProps, styled } from '@mui/joy';


// Add support for the sx prop for consistency with the other branches.
const Anchor = styled('a')({});

interface NextLinkComposedProps
  extends Omit<React.AnchorHTMLAttributes<HTMLAnchorElement>, 'href'>,
    Omit<NextLinkProps, 'href' | 'as' | 'passHref' | 'onMouseEnter' | 'onClick' | 'onTouchStart'> {
  to: NextLinkProps['href'];
  linkAs?: NextLinkProps['as'];
}

const NextLinkComposed = React.forwardRef<HTMLAnchorElement, NextLinkComposedProps>(
  function NextLinkComposed(props, ref) {
    const {
      to,
      linkAs,
      replace,
      scroll,
      shallow,
      prefetch,
      legacyBehavior = true,
      locale,
      ...other
    } = props;

    return (
      <NextLink
        href={to}
        prefetch={prefetch}
        as={linkAs}
        replace={replace}
        scroll={scroll}
        shallow={shallow}
        passHref
        locale={locale}
        legacyBehavior={legacyBehavior}
      >
        <Anchor ref={ref} {...other} />
      </NextLink>
    );
  },
);

export type LinkProps = {
  activeClassName?: string;
  as?: NextLinkProps['as'];
  href: NextLinkProps['href'];
  linkAs?: NextLinkProps['as']; // Useful when the as prop is shallow by styled().
  noLinkStyle?: boolean;
} & Omit<NextLinkComposedProps, 'to' | 'linkAs' | 'href'> &
  Omit<MuiLinkProps, 'href'>;

// A styled version of the Next.js Link component:
// https://nextjs.org/docs/api-reference/next/link
export const Link = React.forwardRef<HTMLAnchorElement, LinkProps>(function Link(props, ref) {
  const {
    activeClassName = 'active',
    as,
    className: classNameProps,
    href,
    legacyBehavior,
    linkAs: linkAsProp,
    locale,
    noLinkStyle,
    prefetch,
    replace,
    scroll,
    shallow,
    ...other
  } = props;

  const { pathname: routerPathname } = useRouter();
  const pathname = typeof href === 'string' ? href : href.pathname;
  const className = `${classNameProps || ''}${routerPathname === pathname ? ` ${activeClassName}` : ''}`;

  // external links: MuiLink (default) or 'a'
  const isExternal = typeof href === 'string' && (href.startsWith('http') || href.startsWith('mailto:'));
  if (isExternal)
    return noLinkStyle
      ? <Anchor className={className} href={href} ref={ref} {...other} />
      : <MuiLink className={className} href={href} ref={ref} {...other} />;

  const linkAs = linkAsProp || as;
  const nextjsProps = {
    to: href,
    linkAs,
    replace,
    scroll,
    shallow,
    prefetch,
    legacyBehavior,
    locale,
  };

  // internal (routed) links: MuiLink (default, over NextLinkComposed) or NextLinkComposed
  return noLinkStyle
    ? <NextLinkComposed className={className} ref={ref} {...nextjsProps} {...other} />
    : <MuiLink component={NextLinkComposed} className={className} ref={ref} {...nextjsProps} {...other} />;
});



================================================
FILE: src/common/components/LogoProgress.tsx
================================================
import * as React from 'react';
import Image from 'next/image';

import { Box, CircularProgress } from '@mui/joy';


/**
 * 64x64 logo with a circular progress indicator around it
 */
export function LogoProgress(props: { showProgress: boolean }) {
  return <Box sx={{
    width: 64,
    height: 64,
    position: 'relative',
    display: 'flex',
    alignItems: 'center',
    justifyContent: 'center',
  }}>
    <Box sx={{ position: 'absolute', mt: 0.75 }}>
      <Image src='/icons/favicon-32x32.png' alt='App Logo' width={32} height={32} />
    </Box>
    {props.showProgress && <CircularProgress size='lg' sx={{ position: 'absolute' }} />}
  </Box>;
}


================================================
FILE: src/common/components/Section.tsx
================================================
import * as React from 'react';

import { Box, FormHelperText, FormLabel, IconButton, Stack } from '@mui/joy';
import { SxProps } from '@mui/joy/styles/types';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';


export function Section(props: { title?: string; collapsible?: boolean, collapsed?: boolean, disclaimer?: string, asLink?: boolean, sx?: SxProps, children: React.ReactNode }) {
  const [collapsed, setCollapsed] = React.useState(props.collapsed ?? false);

  const labelSx: SxProps | null = props.asLink ? {
    textDecoration: 'underline',
    cursor: 'pointer',
  } : null;

  return <Box>

    <Stack direction='row' sx={{ mt: (props.title ? 1 : 0), alignItems: 'center', ...(props.sx ?? {}) }}>
      {!!props.title && (
        <FormLabel onClick={() => !!props.collapsible && setCollapsed(!collapsed)} sx={labelSx}>
          {props.title}
        </FormLabel>
      )}
      {!!props.collapsible && !props.asLink && (
        <IconButton onClick={() => setCollapsed(!collapsed)} sx={{ ml: 1 }}>
          {!collapsed ? <KeyboardArrowDownIcon sx={{ transform: 'rotate(180deg)' }} /> : <KeyboardArrowDownIcon />}
        </IconButton>
      )}
    </Stack>

    {!collapsed && <Box sx={{ mt: 1.5, mb: 1.5 }}>
      {props.children}
    </Box>}

    {!!props.disclaimer && !collapsed && (
      <FormHelperText>
        {props.disclaimer}
      </FormHelperText>
    )}

  </Box>;
}


================================================
FILE: src/common/components/StackedBarBreakdown.tsx
================================================
import * as React from 'react';

import { Box, Typography } from '@mui/joy';


/** Generic segment interface for stacked bar charts */
export interface StackedBarSegment {
  key: string;
  label: string;
  value: number;
  color: string;
}

export interface StackedBarBreakdownProps {
  /** Array of segments to display */
  segments: StackedBarSegment[];
  /** Optional title for the chart */
  title?: React.ReactNode;
  /** Whether to show absolute values in the legend (otherwise just percentages) */
  showValues?: boolean;
  /** Function to format values for display and tooltips */
  valueFormatter?: (value: number) => string;
  /** Optional description text below the chart */
  description?: string;
}


export function StackedBarBreakdown({ segments, title, showValues = false, valueFormatter = (v) => v.toString(), description }: StackedBarBreakdownProps) {
  // Calculate total for percentages
  const total = segments.reduce((sum, seg) => sum + seg.value, 0) || 1;

  // Filter out zero-value segments
  const nonZeroSegments = segments.filter(seg => seg.value > 0);

  return (
    <Box>
      {title && (
        typeof title === 'string'
          ? <Typography level='title-md' mb={1}>{title}</Typography>
          : title
      )}

      {/* The stacked bar */}
      <Box sx={{
        display: 'flex',
        height: 8,
        borderRadius: 8,
        overflow: 'hidden',
        my: 1,
      }}>
        {nonZeroSegments.map(({ key, value, color }) => {
          const percentage = (value / total) * 100;
          return (
            <Box
              key={key}
              title={`${valueFormatter(value)} (${percentage.toFixed(0)}%)`}
              sx={{
                width: `${percentage}%`,
                backgroundColor: color,
                transition: 'width 0.3s ease-in-out',
              }}
            />
          );
        })}
      </Box>

      {/* Legend with colored squares */}
      <Box sx={{ display: 'flex', flexWrap: 'wrap', gap: 1 }}>
        {nonZeroSegments.map(({ key, label, value, color }) => {
          const percentage = (value / total) * 100;
          return (
            <Box key={key} sx={{ display: 'flex', alignItems: 'center', gap: 0.5 }}>
              <Box sx={{ width: 10, height: 10, backgroundColor: color, borderRadius: 2 }} />
              <Typography level='body-xs'>
                {label} {showValues
                ? `${valueFormatter(value)} (${percentage.toFixed(0)}%)`
                : `(${percentage.toFixed(0)}%)`}
              </Typography>
            </Box>
          );
        })}
      </Box>

      {description && (
        <Typography level='body-sm' mt={1}>{description}</Typography>
      )}
    </Box>
  );
}



================================================
FILE: src/common/components/TooltipOutlined.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Tooltip, TooltipProps } from '@mui/joy';


const largePaneSx: SxProps = {
  backgroundColor: 'background.popup',
  boxShadow: 'lg',
};


export function TooltipOutlined(props: {
  title: React.ReactNode;
  color?: TooltipProps['color'];
  variant?: TooltipProps['variant'];
  placement?: TooltipProps['placement'];
  slowEnter?: boolean;
  asLargePane?: boolean;
  enableInteractive?: boolean;
  children: React.JSX.Element;
}) {
  return (
    <Tooltip
      title={props.title}
      color={props.color}
      enterDelay={props.slowEnter ? 600 : 0}
      variant={props.variant ?? 'outlined'}
      arrow
      disableInteractive={!props.enableInteractive}
      placement={props.placement ?? 'top'}
      sx={props.asLargePane ? largePaneSx : undefined}
    >
      {props.children}
    </Tooltip>
  );
}



================================================
FILE: src/common/components/useCameraCapture.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Slider } from '@mui/joy';
import ZoomInIcon from '@mui/icons-material/ZoomIn';

import { Is } from '~/common/util/pwaUtils';


// we need to use local state to avoid race conditions with start/stops (triggered by react/strict mode)
let currMediaStream: MediaStream | null = null;


/**
 * `useCameraCapture` is our React hook for interacting with a camera device.
 *
 * It accepts a MediaDeviceInfo object representing the selected device,
 * and returns an object containing states and methods for controlling the camera.
 *
 * Be sure to set the video ref to the video element in your component.
 */
export function useCameraCapture() {

  // state
  const [cameras, setCameras] = React.useState<MediaDeviceInfo[]>([]);
  const [cameraIdx, setCameraIdx] = React.useState<number>(-1);
  const [zoomControl, setZoomControl] = React.useState<React.ReactNode>(null);
  const [info, setInfo] = React.useState<string | null>(null);
  const [error, setError] = React.useState<string | null>(null);
  const videoRef = React.useRef<HTMLVideoElement>(null); // null because the <video> unmount will set this to null


  // stop the video stream
  const resetVideo = React.useCallback(() => {
    if (currMediaStream) {
      const tracks = currMediaStream.getTracks();
      tracks.forEach((track) => track.stop());
      currMediaStream = null;
    } else
      console.log('stopVideo: no video stream to stop');
    if (videoRef.current)
      videoRef.current.srcObject = null;
    setZoomControl(null);
    setError(null);
  }, []);

  // Function to enumerate devices and update the camera list
  const enumerateCameras = React.useCallback(() => {
    navigator.mediaDevices
      .enumerateDevices()
      .then((devices) => {

        // get video devices
        const newVideoDevices = devices.filter((device) => device.kind === 'videoinput');
        setCameras(newVideoDevices);

        // auto-select the last device 'facing back', or the first device
        if (newVideoDevices.length > 0) {
          const newBackCamIdx = newVideoDevices
            .map((device) => device.label)
            .findLastIndex((label) => {
              if (Is.OS.iOS) return label.toLowerCase().includes('back camera');
              return label.toLowerCase().includes('back') || label.toLowerCase().includes('rear');
            });
          setCameraIdx((prevIdx) => (prevIdx === -1 ? (newBackCamIdx >= 0 ? newBackCamIdx : 0) : prevIdx));
        } else {
          setCameraIdx(-1);
          setError('No cameras found');
        }
      })
      .catch((error) => {
        console.warn('[DEV] useCameraCapture: enumerateDevices error:', error);
        setError(error.message);
      });
  }, []);

  // (once) enumerate video devices
  React.useEffect(() => {
    if (!navigator.mediaDevices) return;

    // Initial enumeration of devices
    enumerateCameras();

    // Listen for permission changes
    const permissionName = 'camera' as PermissionName;
    if (navigator.permissions?.query)
      navigator.permissions
        .query({ name: permissionName })
        .then((permissionStatus) => {
          permissionStatus.onchange = () => {
            // re-enumerate devices if permission changes
            if (permissionStatus.state === 'granted' || permissionStatus.state === 'prompt')
              enumerateCameras();
          };
        })
        .catch((error) => {
          console.warn('[DEV] useCameraCapture: permissions error:', error);
        });

    // Listen for device changes
    navigator.mediaDevices.addEventListener('devicechange', enumerateCameras);
    return () => navigator.mediaDevices.removeEventListener('devicechange', enumerateCameras);
  }, [enumerateCameras]);

  // auto start the camera when the cameraIdx changes, and stop on unmount
  React.useEffect(() => {

    // do nothing if no device is selected
    const selectedDevice = cameraIdx !== -1 ? cameras[cameraIdx] ?? null : null;
    if (selectedDevice === null) return;

    // start the camera if we have a selected device
    setError(null);
    setInfo(null);
    setZoomControl(null);
    _startVideo(selectedDevice, videoRef)
      .then(({ info, zoomControl }) => {
        setInfo(info);
        setZoomControl(zoomControl);
      })
      .catch((error) => {
        setError(error.message);
      });

    return () => resetVideo();
  }, [cameraIdx, cameras, resetVideo]);


  return {
    // the html video element
    videoRef,
    // list and select camera
    cameras,
    cameraIdx,
    setCameraIdx,
    zoomControl,
    info,
    error,
    resetVideo,
  };
}


const sliderContainerSx: SxProps = {
  fontSize: 'sm',
  display: 'flex',
  alignItems: 'center',
  mx: 0.75,
  gap: 3,
};


async function _startVideo(selectedDevice: MediaDeviceInfo, videoRef: React.RefObject<HTMLVideoElement | null>) {

  if (!selectedDevice || !navigator.mediaDevices?.getUserMedia)
    throw new Error('Browser has no camera access');

  const searchConstraints: MediaStreamConstraints & { video: { zoom: boolean } } = {
    video: {
      deviceId: selectedDevice.deviceId,
      width: { ideal: 1920 }, // or any desired width
      height: { ideal: 1440 }, // or any desired height
      frameRate: { ideal: 30 }, // or any desired frame rate
      zoom: true, // added for requesting zooming
    },
  };

  let stream: MediaStream;
  let track: MediaStreamTrack;
  try {
    // find the media stream
    stream = await navigator.mediaDevices.getUserMedia(searchConstraints);

    // attach it to the Video html element (will begin playing)
    if (videoRef?.current)
      videoRef.current.srcObject = stream;

    // get the video track
    [track] = stream.getVideoTracks();
  } catch (error: any) {
    console.log('useCameraCapture: startVideo error:', error);
    throw (error.name === 'NotAllowedError') ? new Error('Camera access denied, please grant permissions.') : error;
  }

  if (!track)
    throw new Error('No video track found');

  // assume we started it
  currMediaStream = stream;

  // Get capabilities (for the zoom ranges)
  const capabilities = track.getCapabilities() as MediaTrackCapabilities & { zoom: { min: number; max: number; step: number } };
  const settings = track.getSettings();

  // Map zoom to a slider element.
  let zoomControl: React.ReactNode | null = null;
  if (capabilities.zoom) {
    const { min, max, step } = capabilities.zoom;
    zoomControl = (
      <Box sx={sliderContainerSx}>
        <span>Zoom:</span>
        <Slider
          variant='solid'
          color='neutral'
          size='lg'
          defaultValue={1}
          min={min} max={max} step={step}
          onChange={(_event, value) => track.applyConstraints({ advanced: [{ zoom: value as number }] } as any)}
        />
        <ZoomInIcon opacity={0.5} />
      </Box>
    );
  }

  return {
    info: `Settings: ${JSON.stringify(settings, null, 2)}\n\nCapabilities: ${JSON.stringify(capabilities, null, 2)}`,
    zoomControl: zoomControl,
  };
}



================================================
FILE: src/common/components/useCapabilities.ts
================================================
/*
 * This file contains code to detect features on the client and server side,
 * and exposes hooks to list the availabilities of those features.
 *
 * Client features include:
 *  - speech recognition: availability and correctness of configuration
 *
 * Server features include:
 *  - tba
 */


/// Speech Recognition (browser)

export interface CapabilityBrowserSpeechRecognition {
  mayWork: boolean; // Is the SpeechRecognition API available in the user's browser and device
  isApiAvailable: boolean; // Is the SpeechRecognition API available in the user's browser
  isDeviceNotSupported: boolean; // Is the user's device not supported (e.g., iPhone)
  warnings: string[];
}

export { browserSpeechRecognitionCapability as useCapabilityBrowserSpeechRecognition } from './speechrecognition/useSpeechRecognition';


/// Speech Synthesis: ElevenLabs

export interface CapabilityElevenLabsSpeechSynthesis {
  mayWork: boolean;
  isConfiguredServerSide: boolean;
  isConfiguredClientSide: boolean;
}

export { useCapability as useCapabilityElevenLabs } from '~/modules/elevenlabs/elevenlabs.client';


/// Image Generation

export interface TextToImageProvider {
  providerId: string;                 // unique ID of this provider, used for selecting in a list (e.g. 'openai-2' or 'localai')
  vendor: TextToImageVendor;
  // UI attributes
  label: string;              // e.g. 'OpenAI #2'
  painter: string;            // e.g. 'GPT Image', 'DALL·E', 'Grok', ...
  description: string;
  configured: boolean;
}

type TextToImageVendor =
  | 'gemini'
  | 'localai'
  | 'openai'
  | 'xai'
  ;


export interface CapabilityTextToImage {
  mayWork: boolean;
  mayEdit: boolean;
  providers: TextToImageProvider[],
  activeProviderId: string | null;
  setActiveProviderId: (providerId: string | null) => void;
}

export { useCapabilityTextToImage } from '~/modules/t2i/t2i.client';


/// Browsing

export interface CapabilityBrowsing {
  mayWork: boolean;
  isServerConfig: boolean;
  isClientConfig: boolean;
  isClientValid: boolean;
  inComposer: boolean;
  inReact: boolean;
  inPersonas: boolean;
}

// export { useBrowseCapability as useCapabilityBrowse } from '~/modules/browse/store-module-browsing';


================================================
FILE: src/common/components/useChipBoolean.tsx
================================================
import * as React from 'react';

import { ChipExpander } from './ChipExpander';


export function useChipBoolean(text: React.ReactNode, initialExpand = false): [boolean, React.JSX.Element] {

  // state
  const [expanded, setExpanded] = React.useState(initialExpand);

  const component = React.useMemo(() => (
    <ChipExpander text={text} expanded={expanded} onToggleExpanded={() => setExpanded(on => !on)} />
  ), [expanded, text]);

  return [expanded, component];
}


================================================
FILE: src/common/components/useDebouncer.ts
================================================
// import * as React from 'react';
//
// export function useDebouncer<TValue = string | number>(
//   initialValue: TValue,
//   delayMs: number,
//   deadlineMs?: number,
//   immediate?: boolean,
// ): [TValue, TValue, (newValue: TValue | ((prevState: TValue) => TValue)) => void, () => TValue] {
//   const [immediateValue, setImmediateValue] = React.useState<TValue>(initialValue);
//   const [debouncedValue, setDebouncedValue] = React.useState<TValue>(initialValue);
//   const valueRef = React.useRef(initialValue);
//   const debounceTimeoutRef = React.useRef<ReturnType<typeof setTimeout>>(undefined);
//   const deadlineTimeoutRef = React.useRef<ReturnType<typeof setTimeout>>(undefined);
//
//   const clearDebounceTimeout = React.useCallback(() => {
//     if (debounceTimeoutRef.current) {
//       clearTimeout(debounceTimeoutRef.current);
//       debounceTimeoutRef.current = undefined;
//     }
//   }, []);
//
//   const clearDeadlineTimeout = React.useCallback(() => {
//     if (deadlineTimeoutRef.current) {
//       clearTimeout(deadlineTimeoutRef.current);
//       deadlineTimeoutRef.current = undefined;
//     }
//   }, []);
//
//   const setValue = React.useCallback((_newValue: TValue | ((prevState: TValue) => TValue)) => {
//     clearDebounceTimeout();
//     // @ts-expect-error _newValue can be a function type (cannot, but lint doesn't know)
//     const newValue: TValue = typeof _newValue === 'function' ? _newValue(valueRef.current) : _newValue;
//     valueRef.current = newValue;
//     // trigger an immediate update
//     if (immediate)
//       setImmediateValue(newValue);
//
//     const handler = () => {
//       setDebouncedValue(valueRef.current);
//       clearDeadlineTimeout();
//     };
//
//     // Set the debounce timeout
//     debounceTimeoutRef.current = setTimeout(handler, delayMs);
//
//     // Set the deadline timeout if it hasn't been set already
//     if (typeof deadlineMs === 'number' && deadlineMs > delayMs && deadlineTimeoutRef.current === undefined)
//       deadlineTimeoutRef.current = setTimeout(handler, deadlineMs);
//
//   }, [clearDebounceTimeout, immediate, delayMs, deadlineMs, clearDeadlineTimeout]);
//
//   const getValue = React.useCallback(() => valueRef.current, []);
//
//   React.useEffect(() => {
//     return () => {
//       clearDebounceTimeout();
//       clearDeadlineTimeout();
//     };
//   }, [clearDebounceTimeout, clearDeadlineTimeout]);
//
//   return [immediateValue, debouncedValue, setValue, getValue];
// }
//
//
// /*
//
// // This function is well tested, and without the deadline.
// export function useDebouncer2<TValue = string | number>(initialValue: TValue, delayMs: number): [TValue, (newValue: TValue) => void, () => TValue] {
//   const [debouncedValue, setDebouncedValue] = useState<TValue>(initialValue);
//   const valueRef = useRef<TValue>(initialValue);
//   const timeoutIdRef = useRef<number>();
//
//   const clearDebounce = useCallback(() => {
//     if (timeoutIdRef.current) {
//       clearTimeout(timeoutIdRef.current);
//       timeoutIdRef.current = undefined;
//     }
//   }, []);
//
//   const getCurrentValue = useCallback(() => valueRef.current, []);
//
//   const setValue = useCallback((newValue: TValue) => {
//     valueRef.current = newValue;
//     clearDebounce();
//     timeoutIdRef.current = window.setTimeout(
//       () => setDebouncedValue(newValue),
//       delayMs,
//     );
//   }, [clearDebounce, delayMs]);
//
//   useEffect(() => {
//     return clearDebounce;
//   }, [clearDebounce]);
//
//   return [debouncedValue, setValue, getCurrentValue];
// }
// */


================================================
FILE: src/common/components/useDebugHook.ts
================================================
// noinspection JSUnusedGlobalSymbols
import * as React from 'react';


/**
 * Useful for debugging React hooks.
 * - will show a stable unique Id, consistent during the lifetime of the component
 * - will show how many times the component has been rendered
 *   - note: increment is a bit misleading, as it's incremented globally for all components across all renders
 *   - although it's assigned to useRef, useRef will only remember the first value assigned to it
 */
export const useDebugHook = (app: string) => {

  // test behavior of React.useState - note the function syntax, so we don't call the initializer on every render
  const [hookId, setTest] = React.useState<number>(() => _getRandom1000());

  // test behavior of React.useRef with instance counter
  const testRef = React.useRef<number>(_increment(app));

  console.log(app + ' render', hookId, testRef.current);

  React.useEffect(() => {
    console.log(app + ' effect start', hookId, testRef.current);
    return () => {
      // eslint-disable-next-line react-hooks/exhaustive-deps
      console.log(app + ' effect cleanup', hookId, testRef?.current);
    };
  }, [app, hookId]);

  return { test: hookId, setTest };
};


let debugGlobalIncrement = 0;

function _increment(app: string) {
  const number = ++debugGlobalIncrement;
  console.log(`+increment: ${number} (${app})`);
  return number;
}

function _getRandom1000() {
  const number = Math.round(Math.random() * 1000);
  console.log(' ~random', number);
  return number;
}

/**
 * Detects what changes within an array of dependencies between renders.
 */
export function useDebugHookChanges(debugLocation: string, deps: React.DependencyList) {
  const prevDeps = React.useRef<React.DependencyList>(deps);

  /* eslint-disable react-hooks/exhaustive-deps */
  React.useEffect(() => {
    const changedDeps = deps
      .map((dep, i) => {
        if (dep !== prevDeps.current[i]) {
          return {
            index: i,
            from: prevDeps.current[i],
            to: dep,
          };
        }
        return null;
      })
      .filter(
        (change): change is { index: number; from: any; to: any } => change !== null,
      );

    if (changedDeps.length > 0)
      console.log(debugLocation, 'deps changed:', changedDeps);

    prevDeps.current = deps;
  }, deps);
}


================================================
FILE: src/common/components/useDontBlurTextarea.ts
================================================
import * as React from 'react';


export function useDontBlurTextarea() {
  return React.useCallback((event: React.MouseEvent) => {
    const isTextAreaFocused = document.activeElement?.tagName === 'TEXTAREA';
    // If a textarea is focused, prevent the default blur behavior
    if (isTextAreaFocused)
      event.preventDefault();
  }, []);
}


================================================
FILE: src/common/components/useFullscreenElement.tsx
================================================
/**
 * Copyright (c) 2024 Enrico Ros
 *
 * Hook to manage fullscreen mode for a given element.
 */

import * as React from 'react';

export function useFullscreenElement<T extends HTMLElement>(elementRef: React.RefObject<T | null>) {

  // state
  const [isFullscreen, setIsFullscreen] = React.useState<boolean>(false);

  // methods
  const enterFullscreen = React.useCallback(async () => {
    if (!elementRef.current) return;
    try {
      await elementRef.current.requestFullscreen();
    } catch (error) {
      console.error('Error attempting to enable fullscreen mode:', error);
    }
  }, [elementRef]);

  const exitFullscreen = React.useCallback(async () => {
    if (document.fullscreenElement) {
      try {
        await document.exitFullscreen();
      } catch (error) {
        console.error('Error attempting to exit fullscreen mode:', error);
      }
    }
  }, []);

  // monitor fullscreen changes
  React.useEffect(() => {
    const onFullscreenChange = () => {
      setIsFullscreen(document.fullscreenElement === elementRef.current);
    }
    document.addEventListener('fullscreenchange', onFullscreenChange);
    return () => document.removeEventListener('fullscreenchange', onFullscreenChange);
  }, [elementRef]);

  return { isFullscreen, enterFullscreen, exitFullscreen };
}



================================================
FILE: src/common/components/useIsBrowserTranslating.tsx
================================================
import * as React from 'react';

import { Alert, IconButton } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { useUICounter } from '~/common/stores/store-ui';


export function useIsBrowserTranslating(timeout: number = 5000): boolean {
  // state
  const [isTranslating, setIsTranslating] = React.useState(false);

  React.useEffect(() => {

    const htmlElementMutationCallback: MutationCallback = (mutationsList, observer) => {
      for (const mutation of mutationsList) {
        // only look for class attribute changes
        if (mutation.type !== 'attributes' || mutation.attributeName !== 'class')
          continue;

        const target = mutation.target as HTMLElement;
        const isTranslatingChrome = target.classList?.contains('translated-ltr') || target.classList?.contains('translated-rtl');
        setIsTranslating(isTranslatingChrome);
        break;
      }
    };

    // Start observing the <html> element for only attribute changes to 'class'
    const observer = new MutationObserver(htmlElementMutationCallback);
    observer.observe(document.documentElement, {
      attributes: true,
      attributeFilter: ['class'],
    });
    return () => observer.disconnect();
  }, []);

  return isTranslating;
}

export function useBrowserTranslationWarning() {

  // state
  const [hideWarning, setHideWarning] = React.useState(false);

  // external state
  const isTranslating = useIsBrowserTranslating();
  const { novel: lessThanFive, touch } = useUICounter('acknowledge-translation-warning', 5);

  const showWarning = isTranslating && !hideWarning && lessThanFive;

  return React.useMemo(() => showWarning ? (
    <Alert
      variant='outlined' color='warning'
      startDecorator={<WarningRoundedIcon />}
      endDecorator={
        <IconButton color='warning'>
          <CloseRoundedIcon onClick={() => {
            setHideWarning(true);
            touch();
          }} />
        </IconButton>
      }
    >
      This page is being translated by your browser. It is recommended to turn OFF translation as it may cause issues,
      such as &quot;a client-side exception has occurred&quot;.
    </Alert>
  ) : null, [showWarning, touch]);
}


================================================
FILE: src/common/components/useMatchMedia.ts
================================================
import * as React from 'react';

import { isBrowser } from '~/common/util/pwaUtils';


export function getIsMobile() {
  return isBrowser ? window.matchMedia(_isMobileQuery).matches : false;
}

export function useIsMobile(): boolean {
  return useMatchMedia(_isMobileQuery, false);
}

export function useIsTallScreen(): boolean {
  // Adjust the aspect ratio value as needed (e.g., 1 or 10/9 for a slightly taller than square ratio)
  return useMatchMedia('(max-aspect-ratio: 1)', false);
}


// the query was was ${appTheme.breakpoints.values.md: { xs: 0, sm: 600, md: 900, lg: 1200, xl: 1536 } - 1}px
const _isMobileQuery: string = `(max-width: 899px)`;

function useMatchMedia(query: string, ssrValue: boolean): boolean {
  const [matches, setMatches] = React.useState(isBrowser ? window.matchMedia(query).matches : ssrValue);

  React.useEffect(() => {
    if (!isBrowser) return undefined;

    // creates a query that will emit events
    const mediaQueryList = window.matchMedia(query);
    setMatches(mediaQueryList.matches);

    // watch for changes in the media query, and cleanup when component unmounts
    const documentChangeHandler = (event: MediaQueryListEvent) => setMatches(event.matches);
    mediaQueryList.addEventListener('change', documentChangeHandler);
    return () => mediaQueryList.removeEventListener('change', documentChangeHandler);
  }, [query]);

  return matches;
}



================================================
FILE: src/common/components/useNextLoadProgress.tsx
================================================
import * as React from 'react';
import type { Router } from 'next/router';
import { default as NProgress } from 'nprogress';


/**
 * Not show the bar for very fast loads (with a delay), and for the same route
 * NOTE: make sure that the application is importing nprogress.css!
 */
export function useNextLoadProgress(route: string, events: typeof Router.events, delay = 500) {

  // this fires both when the page is refreshed, and when the route changes
  React.useEffect(() => {

    NProgress.configure({
      showSpinner: false,
    });

    // timeout to not show the progress bar for very fast loads
    let timeoutId: ReturnType<typeof setTimeout>;

    const handleStop = () => {
      clearTimeout(timeoutId);
      NProgress.done();
    };

    const handleStart = (newRoute: string) => {
      if (newRoute === route) return;

      clearTimeout(timeoutId);
      timeoutId = setTimeout(() => {
        NProgress.start();
      }, delay);
    };

    events.on('routeChangeStart', handleStart);
    events.on('routeChangeComplete', handleStop);
    events.on('routeChangeError', handleStop);

    return () => {
      handleStop();
      events.off('routeChangeStart', handleStart);
      events.off('routeChangeComplete', handleStop);
      events.off('routeChangeError', handleStop);
    };
  }, [delay, events, route]);
}


================================================
FILE: src/common/components/useSingleTabEnforcer.ts
================================================
import * as React from 'react';

/**
 * The AloneDetector class checks if the current client is the only one present for a given app. It uses
 * BroadcastChannel to talk to other clients. If no other clients reply within a short time, it assumes it's
 * the only one and tells the caller.
 */
class AloneDetector {
  private readonly clientId: string;
  private readonly bChannel: BroadcastChannel;

  private aloneCallback: ((isAlone: boolean) => void) | null;
  private aloneTimerId: number | undefined;

  constructor(channelName: string, onAlone: (isAlone: boolean) => void) {

    this.clientId = Math.random().toString(36).substring(2, 10);
    this.aloneCallback = onAlone;

    this.bChannel = new BroadcastChannel(channelName);
    this.bChannel.onmessage = this.handleIncomingMessage;

  }

  public onUnmount(): void {
    // close channel
    this.bChannel.onmessage = null;
    this.bChannel.close();

    // clear timeout
    if (this.aloneTimerId)
      clearTimeout(this.aloneTimerId);

    this.aloneTimerId = undefined;
    this.aloneCallback = null;
  }

  public checkIfAlone(): void {

    // triggers other clients
    this.bChannel.postMessage({ type: 'CHECK', sender: this.clientId });

    // if no response within 500ms, assume this client is alone
    this.aloneTimerId = window.setTimeout(() => {
      this.aloneTimerId = undefined;
      this.aloneCallback?.(true);
    }, 500);

  }

  private handleIncomingMessage = (event: MessageEvent): void => {

    // ignore self messages
    if (event.data.sender === this.clientId) return;

    switch (event.data.type) {

      case 'CHECK':
        this.bChannel.postMessage({ type: 'ALIVE', sender: this.clientId });
        break;

      case 'ALIVE':
        // received an ALIVE message, tell the client they're not alone
        if (this.aloneTimerId) {
          clearTimeout(this.aloneTimerId);
          this.aloneTimerId = undefined;
        }
        this.aloneCallback?.(false);
        this.aloneCallback = null;
        break;

    }
  };
}


/**
 * React hook that checks whether the current tab is the only one open for a specific channel.
 *
 * @param {string} channelName - The name of the BroadcastChannel to communicate on.
 * @returns {boolean | null} - True if the current tab is alone, false if not, or null before the check completes.
 */
export function useSingleTabEnforcer(channelName: string): boolean | null {
  const [isAlone, setIsAlone] = React.useState<boolean | null>(null);

  React.useEffect(() => {
    const tabManager = new AloneDetector(channelName, setIsAlone);
    tabManager.checkIfAlone();
    return () => {
      tabManager.onUnmount();
    };
  }, [channelName]);

  return isAlone;
}


================================================
FILE: src/common/components/VideoPlayerVimeo.tsx
================================================
import * as React from 'react';

import ReactPlayer from 'react-player';
import type { ReactPlayerProps } from 'react-player/types';

export function VideoPlayerVimeo(props: ReactPlayerProps & {
  vimeoVideoId: string; // set this to not set the full URL
  responsive?: boolean; // make the player responsive
}) {

  const { responsive, vimeoVideoId, ...playerProps } = props;

  // responsive patch
  if (responsive) {
    playerProps.width = '100%';
    playerProps.height = '100%';
  }

  // src from video id
  if (vimeoVideoId)
    playerProps.src = `https://vimeo.com/${vimeoVideoId}`;

  return <ReactPlayer {...playerProps} />;
}


================================================
FILE: src/common/components/VideoPlayerYouTube.tsx
================================================
import * as React from 'react';

import ReactPlayer from 'react-player';
import type { ReactPlayerProps } from 'react-player/types';

export function VideoPlayerYouTube(props: ReactPlayerProps & {
  youTubeVideoId: string; // set this to not set the full URL
  responsive?: boolean; // make the player responsive
}) {

  const { responsive, youTubeVideoId, ...playerProps } = props;

  // responsive patch
  if (responsive) {
    playerProps.width = '100%';
    playerProps.height = '100%';
  }

  // src from video id
  if (youTubeVideoId)
    playerProps.src = `https://www.youtube.com/watch?v=${youTubeVideoId}`;

  return <ReactPlayer {...playerProps} />;
}


================================================
FILE: src/common/components/3rdparty/GoogleAnalytics.tsx
================================================
import * as React from 'react';
import Script from 'next/script';

import { Release } from '~/common/app.release';


export const hasGoogleAnalytics = !!process.env.NEXT_PUBLIC_GA4_MEASUREMENT_ID;

export function getGA4MeasurementId(): string | null {
  return process.env.NEXT_PUBLIC_GA4_MEASUREMENT_ID || null;
}

export function sendGAEvent(..._args: Object[]) {
  if (currDataLayerName === undefined)
    return console.warn('[DEV] GA has not been initialized yet');

  if (window[currDataLayerName])
    window[currDataLayerName]?.push(arguments);
  else
    console.warn('[DEV] GA dataLayer does not exist');
}


//
// Google Analytics implementation
// Taken from Vercel: https://github.com/vercel/next.js/blob/b996171654f8ae25b7409dc7a0f27d5217abf35e/packages/third-parties/src/google/ga.tsx
//

// defined during the first render
let currDataLayerName: 'dataLayer' | undefined = undefined;

declare global {
  // noinspection JSUnusedGlobalSymbols
  interface Window {
    dataLayer?: Object[];
  }
}


/**
 * This has been adapted from Vercel, with:
 * - removal of the performance.mark and useEffect
 * - removal of custom dataLayer name
 * - add user_properties: https://developers.google.com/analytics/devguides/collection/ga4/reference/config#user_properties
 */
function NextGoogleAnalytics(props: {
  gaId: string
  debugMode?: boolean
  nonce?: string
}) {
  const { gaId, debugMode, nonce } = props;

  if (currDataLayerName === undefined)
    currDataLayerName = 'dataLayer';

  const fBuild = Release.buildInfo('frontend');

  return (
    <>
      <Script
        id='_next-ga-init'
        dangerouslySetInnerHTML={{
          __html: `
          window['${currDataLayerName}'] = window['${currDataLayerName}'] || [];
          function gtag(){window['${currDataLayerName}'].push(arguments);}
          gtag('js', new Date());

          gtag('config', '${gaId}', {
            ${debugMode ? ' \'debug_mode\': true,' : ''}
            'user_properties': {
              'app_tenant': '${Release.TenantSlug}',
              'app_build_hash': '${fBuild.gitSha || 'unknown'}',
              'app_pkg_version': '${fBuild.pkgVersion || 'unknown'}',
              'app_deployment_type': '${fBuild.deploymentType || 'unknown'}'
            }
          });`,
        }}
        nonce={nonce}
      />
      <Script
        id='_next-ga'
        src={`https://www.googletagmanager.com/gtag/js?id=${gaId}`}
        nonce={nonce}
      />
    </>
  );
}


/**
 * Note: we are using this third-party component from Vercel which is very experimental
 * and has just been launched weeks back (at the time of writing this code). There could
 * be issues.
 *
 * Note: this causes a 2.8kb increase in the bundle size.
 */
export function OptionalGoogleAnalytics() {
  const gaId = getGA4MeasurementId();
  return gaId ? <NextGoogleAnalytics gaId={gaId} /> : null;
}


================================================
FILE: src/common/components/3rdparty/PostHogAnalytics.tsx
================================================
import * as React from 'react';
import type { PostHog, Properties } from 'posthog-js';

import { isBrowser } from '~/common/util/pwaUtils';
import { Release } from '~/common/app.release';


export const hasPostHogAnalytics = !!process.env.NEXT_PUBLIC_POSTHOG_KEY;


// global to survive route changes
let _posthog: undefined | PostHog | null = undefined; // underined: not loaded, null: loading or opt-out, PostHog: loaded


// unused yet
export function posthogAnalyticsOptOut() {
  if (isBrowser) {
    localStorage.setItem('app-analytics-posthog-optout', 'true');
    _posthog?.opt_out_capturing();
  }
}

// unused yet
export function posthogCaptureEvent(eventName: string, properties?: Properties) {
  if (isBrowser && hasPostHogAnalytics) {
    _posthog?.capture(eventName, properties);
  }
}

export function posthogCaptureException(error: Error | unknown, additionalProperties?: Properties) {
  if (isBrowser && hasPostHogAnalytics && _posthog) {
    _posthog.captureException(error, additionalProperties);
  }
}


// unused yet
export function posthogUser(userId: string, userProperties?: Record<string, any>) {
  if (isBrowser && hasPostHogAnalytics) {
    _posthog?.identify(userId, {
      subscription_tier: userProperties?.subscriptionTier || 'free',
      tenant_id: userProperties?.tenantId,
      ...userProperties,
    });
  }
}


/**
 * PostHog Analytics implementation - with dynamic loading
 * follows latest PostHog best practices: https://posthog.com/docs/libraries/next-js?tab=Pages+router
 *
 * This is an optional component in Big-AGI, available to anyone that wants to use PostHog.
 *
 * To enable it, you must set the 'NEXT_PUBLIC_POSTHOG_KEY' environment variable at build time.
 *
 * @see also `GoogleAnalytics.tsx`
 */
export function OptionalPostHogAnalytics() {

  // state
  // const [initialized, setInitialized] = React.useState(false);


  // [effect] PostHog > Initialize (if on) - the effect avoids hydration issues
  React.useEffect(() => {

    if (!hasPostHogAnalytics || !isBrowser || _posthog !== undefined) return;
    _posthog = null;

    // do not proceed with user opt-out
    const hasOptedOut = localStorage.getItem('app-analytics-posthog-optout') === 'true';

    // Dynamically load PostHog
    import('posthog-js')
      .then(({ posthog }) => {
        _posthog = posthog;

        if (hasOptedOut) {
          _posthog.opt_out_capturing();
          return;
        }

        // initialize
        _posthog.init(process.env.NEXT_PUBLIC_POSTHOG_KEY || '', {
          api_host: '/a/ph', // client analytics host - default: process.env.NEXT_PUBLIC_POSTHOG_HOST || 'https://us.i.posthog.com'
          ui_host: 'https://us.i.posthog.com',
          defaults: '2025-05-24',
          // capture_pageview: false, // we used to handle this manually, but changed to the 'defaults' option which captures pageviews automatically
          // capture_pageleave: true, // we used to track goodbyes, now included in 'defaults'
          person_profiles: 'identified_only',
          disable_surveys: true, // disable surveys
          loaded: (ph) => {
            if (Release.IsNodeDevBuild) ph.debug();
          },
        });

        // add deployment context - see `next.config.mjs`
        const fBuild = Release.buildInfo('frontend');
        _posthog.register({
          app_tenant: Release.TenantSlug,
          app_build_hash: fBuild.gitSha || 'unknown',
          app_pkg_version: fBuild.pkgVersion || 'unknown',
          app_deployment_type: fBuild.deploymentType || 'unknown',
        });

        // trigger router hooks
        // setInitialized(true);
      })
      .catch(err => console.error('Failed to load PostHog:', err));
  }, []);


  // [effect] PostHog > PageViews
  // React.useEffect(() => {
  //   if (!hasPostHogAnalytics || !initialized || !_posthog) return;
  //
  //   const handleRouteChange = () => {
  //     // better representation of the next.js URL, compared to reading the window
  //     const url = window.location.origin + Router.asPath;
  //     _posthog?.capture('$pageview', { $current_url: url });
  //   };
  //
  //   // initial page view
  //   handleRouteChange();
  //
  //   // ongoing page views
  //   Router.events.on('routeChangeComplete', handleRouteChange);
  //   return () => Router.events.off('routeChangeComplete', handleRouteChange);
  // }, [initialized]);

  // nothing to render - this component is just for the side effects
  return null;
}



================================================
FILE: src/common/components/dnd-dt/GlobalDragOverlay.tsx
================================================
import * as React from 'react';

import { Box } from '@mui/joy';

import { WindowFocusObserver } from '~/common/util/windowUtils';
import { animationOpacityFadeIn } from '~/common/util/animUtils';
import { themeZIndexDragOverlay } from '~/common/app.theme';

import { EXCLUDE_SELF_TYPE } from './useDragDropDataTransfer';
import { useGlobalDragStore } from './volstore-drag-global';


// configuration
const DEBUG_DND_GLOBAL_OVERLAY = false;
const TIMEOUT_DRAG_RESET = 15 * 1000; // avoids getting stuck in drag state


const _dragOverlaySx = {
  position: 'fixed',
  inset: 0,
  zIndex: themeZIndexDragOverlay,
  backgroundColor: 'rgba(var(--joy-palette-neutral-darkChannel) / 0.1)',
  animation: `${animationOpacityFadeIn} 0.5s ease-in-out`,
  pointerEvents: 'none', // let events pass through
} as const;


function _setDragState(active: boolean, data?: DataTransfer | null) {
  useGlobalDragStore.setState({
    isWindowDragActive: active,
    dragHasFiles: !data ? false : Array.from(data.items).some(item => item.kind === 'file'),
  });
}


export function GlobalDragOverlay() {

  const { isWindowDragActive } = useGlobalDragStore();

  React.useEffect(() => {

    // counter to stack dragenter/dragleave events
    let dragCounter = 0;

    // window blur event listener - on demand
    let unsubFromWindowBlur: undefined | (() => void);


    // safety procedure to get un-stuck on browser bad dispatches
    let lastTimeoutId: number | null = null;

    const clearTimerDeadline = () => {
      if (!lastTimeoutId) return;
      window.clearTimeout(lastTimeoutId);
      lastTimeoutId = null;
    };


    const handleDragClear = () => {
      dragCounter = 0;
      if (DEBUG_DND_GLOBAL_OVERLAY)
        console.log('handleDragClear');

      clearTimerDeadline();

      if (unsubFromWindowBlur) {
        unsubFromWindowBlur();
        unsubFromWindowBlur = undefined;
      }

      _setDragState(false);
    };

    const handleDragEnter = (e: DragEvent) => {
      dragCounter = dragCounter < 0 ? 1 : dragCounter + 1;
      if (DEBUG_DND_GLOBAL_OVERLAY)
        console.log('handleDragEnter', dragCounter, e.dataTransfer?.types);

      // Skip if this came from within our app
      if (e.dataTransfer?.types.includes(EXCLUDE_SELF_TYPE))
        return;

      // move forward the emergency timer deadline
      clearTimerDeadline();
      lastTimeoutId = window.setTimeout(() => {
        if (DEBUG_DND_GLOBAL_OVERLAY)
          console.log('forceDragReset: emergency reset of drag state');
        handleDragClear();
      }, TIMEOUT_DRAG_RESET);

      // begin monitoring window blur
      if (!unsubFromWindowBlur) {
        unsubFromWindowBlur = WindowFocusObserver.getInstance().subscribe((focused) => {
          if (!focused) {
            if (DEBUG_DND_GLOBAL_OVERLAY)
              console.log('handleWindowBlur: resetting drag state');
            handleDragClear();
          }
        });
      }

      _setDragState(true, e.dataTransfer || null);
    };

    const handleDragLeave = (e: DragEvent) => {
      // using max to avoid negative numbers - shouldn't happen but those events tend to be flaky in browsers
      dragCounter = Math.max(0, dragCounter - 1);
      if (DEBUG_DND_GLOBAL_OVERLAY)
        console.log('handleDragLeave', dragCounter, e.dataTransfer?.types);

      if (dragCounter === 0)
        handleDragClear();
    };


    document.addEventListener('dragenter', handleDragEnter);
    document.addEventListener('dragleave', handleDragLeave);
    document.addEventListener('dragend', handleDragClear);
    document.addEventListener('drop', handleDragClear);

    return () => {
      document.removeEventListener('dragenter', handleDragEnter);
      document.removeEventListener('dragleave', handleDragLeave);
      document.removeEventListener('dragend', handleDragClear);
      document.removeEventListener('drop', handleDragClear);

      // ensure state reset when unmounting
      handleDragClear();
    };
  }, []);

  return !isWindowDragActive ? null : <Box sx={_dragOverlaySx} />;
}



================================================
FILE: src/common/components/dnd-dt/useDragDropDataTransfer.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Card, SvgIcon, Typography } from '@mui/joy';

import { themeZIndexDragOverlay } from '~/common/app.theme';

import { useGlobalDragStore } from './volstore-drag-global';


// constants
const zIndexComposerOverlayDrop = 20;
export const EXCLUDE_SELF_TYPE = 'x-app/agi';


// styles

const dragContainerSx: SxProps = {
  position: 'relative', /* for Drop overlay */
} as const;

const dropCardInactiveSx: SxProps = {
  display: 'none',
  position: 'absolute',
  inset: 0,
  pointerEvents: 'none',
  zIndex: zIndexComposerOverlayDrop,
} as const;

const dropCardDraggingCardSx: SxProps = {
  ...dropCardInactiveSx,
  pointerEvents: undefined,
  outline: '1px dashed', // was border - outline has a 1px rendering offset artifact, but looks better than the opposite which had a -1px offset
  borderRadius: 'sm',
  boxShadow: 'inset 1px 0px 3px -2px var(--joy-palette-success-softColor)',
  display: 'flex',
  alignItems: 'center',
  justifyContent: 'center',
  gap: 2,
} as const;

const dropCardPotentialTargetSx: SxProps = {
  ...dropCardDraggingCardSx,
  zIndex: themeZIndexDragOverlay + 1,
  // backgroundColor: 'background.popup',
  // borderStyle: 'none',
  // boxShadow: 'inset 2px 1px 4px -4px var(--joy-palette-success-outlinedColor)',
  // boxShadow: '0 4px 16px 0px var(--joy-palette-background-backdrop)',
  // animation: `${animationEnterModal} 0.2s ease-in-out`,
} as const;


// Drag/Drop that can be used in any component and invokes a DataTransfer callback on success

export function useDragDropDataTransfer(
  enabled: boolean,
  dropText: string, // that the button says
  DropIcon: typeof SvgIcon | null, // icon on the button
  dropVariant: 'largeIcon' | 'startDecorator',
  acceptOnlyFiles: boolean,
  onDropCallback: (dataTransfer: DataTransfer) => Promise<any>,
) {

  // state
  const [isDragging, setIsDragging] = React.useState(false);

  // external state
  const { isWindowDragActive, dragHasFiles } = useGlobalDragStore();

  // derived
  const isPotentialTarget = enabled && isWindowDragActive && !isDragging && (!acceptOnlyFiles || dragHasFiles);


  const _eatDragEvent = React.useCallback((event: React.DragEvent) => {
    event.preventDefault();
    event.stopPropagation();
  }, []);


  // Container events

  const handleContainerDragEnter = React.useCallback((event: React.DragEvent) => {
    const isFromSelf = event.dataTransfer.types.includes(EXCLUDE_SELF_TYPE);
    if (acceptOnlyFiles) {
      const hasFiles = Array.from(event.dataTransfer.items).some(item => item.kind === 'file');
      if (!hasFiles)
        return;
    }
    if (!isFromSelf) {
      _eatDragEvent(event);
      setIsDragging(true);
    }
  }, [_eatDragEvent, acceptOnlyFiles]);

  const handleContainerDragStart = React.useCallback((event: React.DragEvent) => {
    // This is for drags that originate from the container (e.g. anything within the Textarea's surroundings in Composer)
    event.dataTransfer.setData(EXCLUDE_SELF_TYPE, 'do-not-intercept');
  }, []);


  // Drop Target events

  const _handleDragOver = React.useCallback((event: React.DragEvent) => {
    _eatDragEvent(event);
    // this makes sure we don't "transfer" (or move) the item, but we tell the sender we'll copy it
    event.dataTransfer.dropEffect = 'copy';
  }, [_eatDragEvent]);

  const _handleDragLeave = React.useCallback((event: React.DragEvent) => {
    _eatDragEvent(event);
    setIsDragging(false);
  }, [_eatDragEvent]);

  const _handleDrop = React.useCallback(async (event: React.DragEvent) => {
    _eatDragEvent(event);
    setIsDragging(false);
    await onDropCallback(event.dataTransfer);
  }, [_eatDragEvent, onDropCallback]);


  // Standardized component looks, only customized based on `dropText` and `DropIcon`
  const dropComponent = React.useMemo(() => {
    if (!enabled) return null;

    return (
      <Card
        color={isDragging ? 'success' : isPotentialTarget ? 'success' : undefined}
        variant={isDragging ? 'soft' : isPotentialTarget ? 'soft' : undefined}
        invertedColors={isDragging}
        onDragLeave={_handleDragLeave}
        onDragOver={_handleDragOver}
        onDrop={_handleDrop}
        sx={isDragging ? dropCardDraggingCardSx : isPotentialTarget ? dropCardPotentialTargetSx : dropCardInactiveSx}
      >
        {isDragging && dropVariant === 'largeIcon' && !!DropIcon && (
          <DropIcon sx={{ width: 36, height: 36, pointerEvents: 'none' }} />
        )}
        {isDragging && (
          <Typography
            level='title-sm'
            startDecorator={dropVariant === 'startDecorator' && !!DropIcon && <DropIcon />}
            sx={{ pointerEvents: 'none' }}
          >
            {dropText}
          </Typography>
        )}
        {!isDragging && isPotentialTarget && (
          DropIcon ? (
            <DropIcon sx={{ width: 20, height: 20, pointerEvents: 'none' }} />
          ) : (
            <Typography level='title-sm'>Drop here</Typography>
          )
        )}
      </Card>
    );
  }, [enabled, isPotentialTarget, isDragging, _handleDragLeave, _handleDragOver, _handleDrop, dropVariant, DropIcon, dropText]);


  return {
    dragContainerSx,
    dropComponent,
    handleContainerDragEnter,
    handleContainerDragStart,
    isDragging,
  };
}



================================================
FILE: src/common/components/dnd-dt/volstore-drag-global.ts
================================================
import { create } from 'zustand';


interface GlobalDragState {

  // is something dragged over the window
  isWindowDragActive: boolean;

  // for potential filtering
  dragHasFiles: boolean;

}

export const useGlobalDragStore = create<GlobalDragState>((_set) => ({

  // initial state

  isWindowDragActive: false,
  dragHasFiles: false,

}));



================================================
FILE: src/common/components/forms/FormChipControl.tsx
================================================
import * as React from 'react';

import { Box, Chip, ColorPaletteProp, FormControl } from '@mui/joy';

import type { Immutable } from '~/common/types/immutable.types';

import type { FormRadioOption } from './FormRadioControl';
import { FormLabelStart } from './FormLabelStart';


const _styles = {

  control: {
    justifyContent: 'space-between',
    alignItems: 'center',
  } as const,

  chipGroup: {
    display: 'flex',
    flexWrap: 'wrap',
    gap: 1,
  } as const,

  chip: {
    '--Chip-minHeight': '1.75rem', // this makes it prob better
    px: 1.5,
  } as const,

} as const;


/**
 * Exact drop-in replacement for FormRadioControl, but with Chips.
 */
export const FormChipControl = <TValue extends string>(props: {
  // specific
  size?: 'sm' | 'md' | 'lg',
  color?: ColorPaletteProp,
  // =FormRadioControl
  title: string | React.JSX.Element;
  description?: string | React.JSX.Element;
  tooltip?: string | React.JSX.Element;
  disabled?: boolean;
  options: Immutable<FormRadioOption<TValue>[]>;
  value?: TValue;
  onChange: (value: Immutable<TValue>) => void;
}) => {

  const { onChange } = props;

  const handleChipClick = React.useCallback((value: Immutable<TValue>) => {
    if (!props.disabled)
      onChange(value);
  }, [onChange, props.disabled]);

  return (
    <FormControl orientation='horizontal' disabled={props.disabled} sx={_styles.control}>
      {(!!props.title || !!props.description) && <FormLabelStart title={props.title} description={props.description} tooltip={props.tooltip} />}
      <Box sx={_styles.chipGroup}>
        {props.options.map((option) => (
          <Chip
            key={'opt-' + option.value}
            color={props.color}
            size={props.size}
            disabled={option.disabled || props.disabled}
            variant={props.value === option.value ? 'solid' : 'outlined'}
            // color={props.value === option.value ? 'neutral' : 'neutral'}
            onClick={() => handleChipClick(option.value)}
            sx={_styles.chip}
          >
            {option.label}
          </Chip>
        ))}
      </Box>
    </FormControl>
  );
};



================================================
FILE: src/common/components/forms/FormInputKey.tsx
================================================
import * as React from 'react';

import { Box, FormControl, FormHelperText, FormLabel, IconButton, Input } from '@mui/joy';
import KeyIcon from '@mui/icons-material/Key';
import VisibilityIcon from '@mui/icons-material/Visibility';
import VisibilityOffIcon from '@mui/icons-material/VisibilityOff';

import { getIsMobile } from '~/common/components/useMatchMedia';


export function FormInputKey(props: {
  autoCompleteId: string, // introduced to avoid clashes
  label?: string, rightLabel?: string | React.JSX.Element,
  description?: string | React.JSX.Element,
  value: string, onChange: (value: string) => void,
  placeholder?: string,
  initiallyShowKey?: boolean,
  required: boolean, isError?: boolean,
  noKey?: boolean,
}) {

  // internal state is only whether the text is visible or not - the actual value is stored in the parent
  const [isVisible, setIsVisible] = React.useState(!!props.initiallyShowKey);

  // if mobile, start without autocompletion
  const disableAutoFocus = getIsMobile();

  const handleChange = (e: React.ChangeEvent) => props.onChange((e.target as HTMLInputElement).value);

  const endDecorator = React.useMemo(() => !!props.value && !props.noKey && (
    <IconButton onClick={() => setIsVisible(!isVisible)}>
      {isVisible ? <VisibilityIcon /> : <VisibilityOffIcon />}
    </IconButton>
  ), [props.value, props.noKey, isVisible]);

  const acId = (props.noKey ? 'input-text-' : 'input-key-') + props.autoCompleteId;

  return (
    <FormControl id={acId}>

      {!!props.label && <Box sx={{ display: 'flex', flexDirection: 'row', alignItems: 'baseline', flexWrap: 'wrap', justifyContent: 'space-between' }}>
        <FormLabel>{props.label}</FormLabel>
        {!!props.rightLabel && <FormHelperText sx={{ display: 'block' }}>
          {props.rightLabel}
        </FormHelperText>}
      </Box>}

      <Input
        key={acId}
        name={acId}
        autoComplete='off'
        autoFocus={disableAutoFocus ? undefined : !props.required ? undefined : props.value ? undefined : true}
        // autoComplete={props.noKey ? 'off' : 'new-password'}
        variant={props.required ? 'outlined' : 'outlined' /* 'soft */}
        value={props.value} onChange={handleChange}
        placeholder={props.required ? props.placeholder ? 'required: ' + props.placeholder : 'required' : props.placeholder || '...'}
        type={(isVisible || !!props.noKey) ? 'text' : 'password'}
        error={props.isError}
        startDecorator={!props.noKey && <KeyIcon />}
        endDecorator={endDecorator}
      />

      {props.description && <FormHelperText sx={{ display: 'block' }}>{props.description}</FormHelperText>}

    </FormControl>
  );
}


================================================
FILE: src/common/components/forms/FormLabelStart.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { FormHelperText, FormLabel } from '@mui/joy';
import InfoIcon from '@mui/icons-material/Info';

import { GoodTooltip } from '~/common/components/GoodTooltip';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';


const _styles = {
  label: {
    flexWrap: 'nowrap',
    whiteSpace: 'nowrap',
  } as const,
  labelClickable: {
    flexWrap: 'nowrap',
    whiteSpace: 'nowrap',
    cursor: 'pointer',
    textDecoration: 'underline',
  } as const,
} as const;


/**
 * Shared label part (left side)
 */
export const FormLabelStart = React.memo(function FormLabelStartBase(props: {
  title: React.ReactNode,
  description?: React.ReactNode,
  tooltip?: React.ReactNode,
  tooltipWarning?: boolean,
  onClick?: (event: React.MouseEvent) => void,
  sx?: SxProps,
}) {
  return <div>
    {/* Title */}
    <FormLabel
      onClick={props.onClick}
      sx={props.onClick ? _styles.labelClickable
        : props.sx ? { ..._styles.label, ...props.sx }
          : _styles.label
      }
    >
      {props.title} {!!props.tooltip && (
      <GoodTooltip title={props.tooltip} arrow placement='top'>
        {props.tooltipWarning
          ? <WarningRoundedIcon sx={{ ml: 0.5, cursor: 'pointer', fontSize: 'md', color: 'red' }} />
          : <InfoIcon sx={{ ml: 0.5, cursor: 'pointer', fontSize: 'md', color: 'primary.solidBg' }} />
        }
      </GoodTooltip>
    )}
    </FormLabel>

    {/* [SubTitle] */}
    {!!props.description && (
      <FormHelperText
        sx={{
          fontSize: 'xs',
          display: 'block',
        }}
      >
        {props.description}
      </FormHelperText>
    )}
  </div>;
});



================================================
FILE: src/common/components/forms/FormRadioControl.tsx
================================================
import * as React from 'react';

import { FormControl, Radio, RadioGroup } from '@mui/joy';

import type { Immutable } from '~/common/types/immutable.types';

import { FormLabelStart } from './FormLabelStart';


export type FormRadioOption<T extends string> = {
  value: T,
  label: string | React.JSX.Element,
  disabled?: boolean
};


export const FormRadioControl = <TValue extends string>(props: {
  title: string | React.JSX.Element,
  description?: string | React.JSX.Element,
  tooltip?: string | React.JSX.Element,
  disabled?: boolean;
  options: Immutable<FormRadioOption<TValue>[]>;
  value?: TValue;
  onChange: (value: TValue) => void;
}) =>
  <FormControl orientation='horizontal' disabled={props.disabled} sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
    {(!!props.title || !!props.description) && <FormLabelStart title={props.title} description={props.description} tooltip={props.tooltip} />}
    <RadioGroup
      orientation='horizontal'
      value={props.value}
      onChange={(event: React.ChangeEvent<HTMLInputElement>) => event.target.value && props.onChange(event.target.value as TValue)}
      sx={{ flexWrap: 'wrap' }}
    >
      {props.options.map((option) =>
        <Radio key={'opt-' + option.value} value={option.value} label={option.label} disabled={option.disabled || props.disabled} />,
      )}
    </RadioGroup>
  </FormControl>;


================================================
FILE: src/common/components/forms/FormSelectControl.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { FormControl, Option, Select, SelectSlotsAndSlotProps } from '@mui/joy';

import { FormLabelStart } from './FormLabelStart';


// copied from useLLMSelect.tsx - inspired by optimaSelectSlotProps.listbox
const _selectSlotProps: SelectSlotsAndSlotProps<false>['slotProps'] = {
  button: {
    sx: {
      // whiteSpace: 'inherit', // note: we try to keep it in one line for now
      wordBreak: 'break-word',
      minWidth: '6rem',
    } as const,
  } as const,
} as const;


export type FormSelectOption<T extends string> = {
  value: T;
  label: string;
  description: string;
  disabled?: boolean;
};


export const FormSelectControl = <TValue extends string>(props: {
  title?: React.ReactNode;
  tooltip?: React.ReactNode;
  disabled?: boolean;
  options: Readonly<FormSelectOption<TValue>[]>;
  value?: TValue;
  onChange: (value: TValue) => void;
  placeholder?: React.ReactNode;
  selectSx?: SxProps;
}) => {
  const selectedOption = props.options.find(option => option.value === props.value);

  return (
    <FormControl orientation='horizontal' disabled={props.disabled} sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      {!!props.title && (
        <FormLabelStart
          title={props.title}
          description={selectedOption?.description}
          tooltip={props.tooltip}
        />
      )}
      <Select
        value={props.value}
        onChange={(_, value) => value && props.onChange(value as TValue)}
        placeholder={props.placeholder}
        slotProps={_selectSlotProps}
        sx={props.selectSx}
      >
        {props.options.map((option, idx) => (
          <Option
            key={option.value || `opt-${idx}`}
            value={option.value}
            disabled={option.disabled || props.disabled}
          >
            {option.label}
          </Option>
        ))}
      </Select>
    </FormControl>
  );
};



================================================
FILE: src/common/components/forms/FormSliderControl.tsx
================================================
import * as React from 'react';

import { FormControl, Slider, VariantProp } from '@mui/joy';

import { FormLabelStart } from './FormLabelStart';


/**
 * Slider Control
 */
export function FormSliderControl(props: {
  title: string | React.JSX.Element, description?: string | React.JSX.Element, ariaLabel?: string,
  disabled?: boolean,
  variant?: VariantProp,
  min?: number, max?: number, step?: number, defaultValue?: number,
  valueLabelDisplay?: 'on' | 'auto' | 'off',
  value: number | number[] | null, onChange: (value: number) => void,
  startAdornment?: React.ReactNode,
  endAdornment?: React.ReactNode,
}) {
  return (
    <FormControl disabled={props.disabled} orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title={props.title} description={props.description} />
      {props.startAdornment}
      <Slider
        aria-label={props.ariaLabel}
        color='neutral'
        variant={props.variant}
        disabled={props.disabled}
        min={props.min} max={props.max} step={props.step} defaultValue={props.defaultValue}
        value={props.value === null ? undefined : props.value} onChange={(_event, value) => props.onChange(value as number)}
        valueLabelDisplay={props.valueLabelDisplay}
        // sx={{ py: 1, mt: 1.1 }}
      />
      {props.endAdornment}
    </FormControl>
  );
}


================================================
FILE: src/common/components/forms/FormSwitchControl.tsx
================================================
import * as React from 'react';

import { FormControl, Switch } from '@mui/joy';

import { FormLabelStart } from './FormLabelStart';


/**
 * Switch control
 */
export function FormSwitchControl(props: {
  title: string | React.JSX.Element, description?: string | React.JSX.Element,
  on?: React.ReactNode, off?: string, fullWidth?: boolean,
  checked: boolean, onChange: (on: boolean) => void,
  disabled?: boolean,
  tooltip?: React.ReactNode,
}) {
  return (
    <FormControl orientation='horizontal' disabled={props.disabled} sx={{ flexWrap: 'wrap', justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title={props.title} description={props.description} tooltip={props.tooltip} />
      <Switch
        checked={props.checked}
        onChange={event => props.onChange(event.target.checked)}
        endDecorator={props.checked ? props.on || 'On' : props.off || 'Off'}
        sx={props.fullWidth ? { flexGrow: 1 } : undefined}
        slotProps={{ endDecorator: { sx: { minWidth: 26 } } }}
      />
    </FormControl>
  );
}


================================================
FILE: src/common/components/forms/FormTextField.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { FormControl, Input } from '@mui/joy';

import { FormLabelStart } from './FormLabelStart';


const formControlSx: SxProps = {
  flexWrap: 'wrap',
  justifyContent: 'space-between',
  alignItems: 'center',
};


/**
 * Text form field (e.g. enter a host)
 */
export function FormTextField(props: {
  autoCompleteId: string,
  title: string | React.JSX.Element,
  description?: string | React.JSX.Element,
  tooltip?: string | React.JSX.Element,
  placeholder?: string, isError?: boolean, disabled?: boolean,
  value: string | undefined, onChange: (text: string) => void,
}) {
  const acId = 'text-' + props.autoCompleteId;
  return (
    <FormControl
      id={acId}
      orientation='horizontal'
      disabled={props.disabled}
      sx={formControlSx}
    >
      <FormLabelStart title={props.title} description={props.description} tooltip={props.tooltip} />
      <Input
        key={acId}
        name={acId}
        autoComplete='off'
        variant='outlined' placeholder={props.placeholder} error={props.isError}
        value={props.value} onChange={event => props.onChange(event.target.value)}
        sx={{ flexGrow: 1 }}
      />
    </FormControl>
  );
}


================================================
FILE: src/common/components/forms/SetupFormRefetchButton.tsx
================================================
import * as React from 'react';

import { Box, Button, FormLabel } from '@mui/joy';
import SyncIcon from '@mui/icons-material/Sync';

import type { ToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';


/**
 * Bottom row: model reload and optional 'advanced' toggle
 */
export function SetupFormRefetchButton(props: {
  refetch: () => void,
  disabled: boolean,
  loading: boolean,
  error: boolean,
  leftButton?: React.ReactNode,
  advanced?: ToggleableBoolean
}) {
  return (
    <Box sx={{ display: 'flex', alignItems: 'end', justifyContent: 'space-between' }}>

      {props.leftButton}

      {!!props.advanced && (
        <FormLabel onClick={props.advanced.toggle} sx={{ textDecoration: 'underline', cursor: 'pointer', color: 'text.tertiary' }}>
          {props.advanced.on ? 'Hide Advanced' : 'Advanced'}
        </FormLabel>
      )}

      <Button
        color={props.error ? 'warning' : 'primary'}
        disabled={props.disabled}
        loading={props.loading}
        endDecorator={<SyncIcon />}
        onClick={props.refetch}
        sx={{ minWidth: 120, ml: 'auto' }}
      >
        Models
      </Button>

    </Box>
  );
}


================================================
FILE: src/common/components/forms/useFormEditTextArray.tsx
================================================
import * as React from 'react';

import { Box, FormControl, IconButton, Textarea, Tooltip } from '@mui/joy';
import ReplayIcon from '@mui/icons-material/Replay';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';


/**
 * A simple UI component, string array (ant titles array) in -> edited string array out
 */
export function useFormEditTextArray(initialStrings: string[], titles: string[]) {

  // state
  const [strings, setStrings] = React.useState<string[]>(initialStrings);

  const editString = React.useCallback((i: number, text: string) => {
    setStrings(s => s.map((s, j) => j === i ? text : s));
  }, []);

  const stringEditors = React.useMemo(() => strings.map((text, i) =>
    <FormControl key={i} orientation='vertical'>
      <FormLabelStart title={i > 0 ? `${i}. ${titles[i]}` : titles[i]} />
      <Box sx={{ display: 'flex', alignItems: 'start', gap: 1 }}>
        <Textarea
          value={text}
          size='sm'
          variant='outlined'
          onChange={event => editString(i, event.target.value)}
          sx={{ flex: 1, backgroundColor: 'background.level1', boxShadow: 'none' }}
        />
        <Tooltip title='Reset'>
          <IconButton size='sm' onClick={() => editString(i, initialStrings[i])}>
            <ReplayIcon />
          </IconButton>
        </Tooltip>
      </Box>
    </FormControl>,
  ), [editString, initialStrings, strings, titles]);

  return { strings, stringEditors };
}


================================================
FILE: src/common/components/forms/useFormRadio.tsx
================================================
import * as React from 'react';

import { FormControl, FormLabel, Radio, RadioGroup } from '@mui/joy';

import { FormRadioOption } from './FormRadioControl';


/**
 * Warning: this must be a constant to avoid re-rendering the radio group
 */
export function useFormRadio<T extends string>(initialValue: T, options: FormRadioOption<T>[], label?: string, hidden?: boolean): [T | null, React.JSX.Element | null, React.Dispatch<React.SetStateAction<T | null>>] {

  // state
  const [value, setValue] = React.useState<T | null>(initialValue);

  const handleChange = React.useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    setValue(event.target.value as T | null);
  }, []);

  const component = React.useMemo(() => hidden === true ? null : (
    <FormControl /* size='sm' NOTE: this would make all forms smaller, but requires an adaptation of all the other <RadioGroups> as well, including settings */>
      {!!label && <FormLabel>{label}</FormLabel>}
      <RadioGroup
        orientation='horizontal'
        value={value} onChange={handleChange}
        sx={{ gap: 0.5 }}
      >
        {options.map((option) =>
          <Radio key={option.value} disabled={option.disabled} value={option.value} label={option.label} />)}
      </RadioGroup>
    </FormControl>
  ), [handleChange, hidden, label, options, value]);

  return [value, component, setValue];
}


================================================
FILE: src/common/components/forms/useFormRadioLlmType.tsx
================================================
import * as React from 'react';

import type { DLLM, DLLMId } from '~/common/stores/llms/llms.types';
import { useLLMs } from '~/common/stores/llms/llms.hooks';

import type { FormRadioOption } from './FormRadioControl';
import { useFormRadio } from './useFormRadio';
import { useModelDomain } from '~/common/stores/llms/hooks/useModelDomain';


type LlmType = 'run' | 'util';

export function useFormRadioLlmType(label: string, runModelId: DLLMId | null, initialModelType: LlmType): [DLLM | undefined, React.JSX.Element | null] {

  // external state
  const { domainModelId: utilModelId } = useModelDomain('fastUtil');
  const [runLLM, utilLLM] = useLLMs([runModelId ?? '', utilModelId ?? '']);


  const hidden = !runLLM || !utilLLM || runLLM === utilLLM;

  const options = React.useMemo((): FormRadioOption<LlmType>[] => [
    { label: runLLM?.label ?? '[missing llm]', value: 'run' },
    { label: utilLLM?.label ?? '[missing util llm]', value: 'util' },
  ], [runLLM, utilLLM]);

  const [llmType, component] = useFormRadio<LlmType>(initialModelType, options, label, hidden);
  const value = (llmType === 'run' || !utilLLM) ? runLLM : utilLLM;

  return [value, component];
}


================================================
FILE: src/common/components/forms/useLLMSelect.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Chip, ColorPaletteProp, FormControl, IconButton, ListDivider, ListItemDecorator, Option, optionClasses, Select, SelectSlotsAndSlotProps, SvgIconProps, VariantProp } from '@mui/joy';
import AutoModeIcon from '@mui/icons-material/AutoMode';

import type { IModelVendor } from '~/modules/llms/vendors/IModelVendor';
import { findModelVendor } from '~/modules/llms/vendors/vendors.registry';
import { llmsGetVendorIcon, LLMVendorIcon } from '~/modules/llms/components/LLMVendorIcon';

import type { DModelDomainId } from '~/common/stores/llms/model.domains.types';
import { DLLM, DLLMId, LLM_IF_OAI_Reasoning, LLM_IF_Outputs_Audio, LLM_IF_Outputs_Image, LLM_IF_Tools_WebSearch } from '~/common/stores/llms/llms.types';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { getChatLLMId, llmsStoreActions } from '~/common/stores/llms/store-llms';
import { optimaOpenModels } from '~/common/layout/optima/useOptima';
import { useVisibleLLMs } from '~/common/stores/llms/llms.hooks';

import { FormLabelStart } from './FormLabelStart';


// configuration
const LLM_SELECT_REDUCE_OPTIONS = 10; // optimization: number of options over which only the selected is kept when closed (we'll have special notes for accessibility)
const LLM_SELECT_SHOW_REASONING_ICON = false;
const LLM_TEXT_PLACEHOLDER = 'Models …';
const LLM_TEXT_CONFIGURE = 'Add Models …';


/*export function useLLMSelectGlobalState(): [DLLMId | null, (llmId: DLLMId | null) => void] {
  return ...(useShallow(state => [state.chatLLMId, state.setChatLLMId]));
}*/

export function useLLMSelectLocalState(initFromGlobal: boolean): [DLLMId | null, (llmId: DLLMId | null) => void] {
  return React.useState<DLLMId | null>(initFromGlobal ? () => {
    return getChatLLMId();
  } : null);
}

const llmSelectSx: SxProps = {
  flex: 1,
  backgroundColor: 'background.popup',
  // minWidth: '200',
} as const;

const styleChips: SxProps = {
  ml: 'auto',
  backgroundColor: 'background.popup',
  boxShadow: 'xs',
} as const;

const _slotProps: SelectSlotsAndSlotProps<false>['slotProps'] = {
  // see the OptimaBarDropdown.listbox for a well made customization (max-height, max-width, etc.)
  listbox: {
    sx: {
      // larger list
      '--ListItem-paddingLeft': '1rem',
      '--ListItem-minHeight': '2.5rem', // note that in the Optima Dropdowns we use 2.75rem

      // No need for larger SVG icons here
      // '--Icon-fontSize': 'var(--joy-fontSize-xl2)',

      // No need to remove the gutter
      // paddingBlock: 0,

      // v-size: keep the default
      // maxHeight: 'calc(100dvh - 56px - 24px)',

      // Decorator: do not change the emoji size
      // [`& .${listItemDecoratorClasses.root}`]: {
      //   fontSize: 'var(--joy-fontSize-lg)',
      // } as const,

      // Option: clip width to 200...360px
      [`& .${optionClasses.root}`]: {
        // NOTE: was maxWidth: 'min(600px, calc(100dvw - 0.25rem))', however llmSelect could be wider on Beam
        maxWidth: 'calc(100dvw - 0.25rem)', // the small reduction is to avoid accidental h-scrolling because of the border
        minWidth: 200,
      } as const,

      // minWidth: '100%',
      zIndex: 1300, // on top of ScratchChat
    } as const,
  } as const,
  button: {
    'aria-description': 'Options may be filtered when closed. Open dropdown to see all options.',
    sx: {
      // show the full name on the button
      whiteSpace: 'inherit',
      wordBreak: 'break-word',
      minWidth: '6rem',
    } as const,
  } as const,
} as const;


interface LLMSelectOptions {
  label: string;
  sx?: SxProps;
  color?: ColorPaletteProp;
  variant?: VariantProp;
  larger?: boolean;
  disabled?: boolean;
  placeholder?: string;
  isHorizontal?: boolean;
  autoRefreshDomain?: DModelDomainId;
}

/**
 * Select the Model, synced with either Global (Chat) LLM state, or local
 *
 * @param llmId (required) the LLM id
 * @param setLlmId (required) the function to set the LLM id
 * @param options (optional) any array of options
 */
export function useLLMSelect(
  llmId: undefined | DLLMId | null, // undefined: not set at all, null: has the meaning of no-llm-wanted here
  setLlmId: (llmId: DLLMId | null) => void,
  options: LLMSelectOptions,
): [DLLM | null, React.JSX.Element | null, React.FunctionComponent<SvgIconProps> | undefined] {

  // state
  const [controlledOpen, setControlledOpen] = React.useState(false);

  // external state
  const _filteredLLMs = useVisibleLLMs(llmId);

  // derived state
  const { label, larger = false, disabled = false, placeholder = LLM_TEXT_PLACEHOLDER, isHorizontal = false, autoRefreshDomain } = options;
  const noIcons = false; //smaller;
  const llm = !llmId ? null : _filteredLLMs.find(llm => llm.id === llmId) ?? null;
  const isReasoning = !LLM_SELECT_SHOW_REASONING_ICON ? false : llm?.interfaces?.includes(LLM_IF_OAI_Reasoning) ?? false;


  // memo LLM Options

  const optimizeToSingleVisibleId = (!controlledOpen && _filteredLLMs.length > LLM_SELECT_REDUCE_OPTIONS) ? llmId : null; // id to keep visible when optimizing

  const optionsArray = React.useMemo(() => {
    // create the option items
    let formerVendor: IModelVendor | null = null;
    return _filteredLLMs.reduce((acc, llm, _index) => {

      if (optimizeToSingleVisibleId && llm.id !== optimizeToSingleVisibleId)
        return acc;

      const vendor = findModelVendor(llm.vId);
      const vendorChanged = vendor !== formerVendor;
      if (vendorChanged)
        formerVendor = vendor;

      // add separators if the vendor changed (and more than one vendor)
      const addSeparator = vendorChanged && formerVendor !== null;
      if (addSeparator && !optimizeToSingleVisibleId)
        acc.push(<ListDivider key={'llm-sep-' + llm.id}>{vendor?.name}</ListDivider>);

      let features = '';
      const isNotSymlink = !llm.label.startsWith('🔗');
      const seemsFree = !!llm.pricing?.chat?._isFree;
      if (isNotSymlink) {
        // check features
        if (seemsFree) features += 'free ';
        if (llm.interfaces.includes(LLM_IF_OAI_Reasoning))
          features += '🧠 '; // can reason
        if (llm.interfaces.includes(LLM_IF_Tools_WebSearch))
          features += '🌐 '; // can web search
        if (llm.interfaces.includes(LLM_IF_Outputs_Audio))
          features += '🔊 '; // can output audio
        if (llm.interfaces.includes(LLM_IF_Outputs_Image))
          features += '🖼️ '; // can draw images
      }

      // the option component
      acc.push(
        <Option
          key={llm.id}
          value={llm.id}
          // Disabled to avoid regenerating the memo too frequently
          // sx={llm.id === llmId ? { fontWeight: 'md' } : undefined}
          label={llm.label}
        >
          {!noIcons && (
            <ListItemDecorator>
              {llm.userStarred ? '⭐ ' : vendor?.id ? <LLMVendorIcon vendorId={vendor.id} /> : null}
            </ListItemDecorator>
          )}
          {/*<Tooltip title={llm.description}>*/}

          <div className='agi-ellipsize'>{llm.label}</div>

          {/* Features Chips - sync with `ModelsList.tsx` */}
          {!!features && <Chip size='sm' color={seemsFree ? 'success' : undefined} variant='plain' sx={styleChips}>{features.trim().replace(' ', ' ')}</Chip>}

          {/*</Tooltip>*/}
          {/*{llm.gen === 'sdxl' && <Chip size='sm' variant='outlined'>XL</Chip>} {llm.label}*/}
        </Option>,
      );

      return acc;
    }, [] as React.JSX.Element[]);
  }, [_filteredLLMs, noIcons, optimizeToSingleVisibleId]);


  const onSelectChange = React.useCallback((_event: unknown, value: DLLMId | null) => value && setLlmId(value), [setLlmId]);

  const hasNoModels = _filteredLLMs.length === 0;
  const showNoOptions = !optionsArray.length;

  // memo Select
  const llmSelectComponent = React.useMemo(() => (
    <FormControl orientation={(isHorizontal || autoRefreshDomain) ? 'horizontal' : undefined}>
      {!!label && <FormLabelStart title={label} sx={/*{ mb: '0.25rem' }*/ undefined} />}
      {/*<Box sx={{ display: 'flex', justifyContent: 'space-between' }}>*/}
      <Select
        color={options.color}
        variant={options.variant ?? 'outlined'}
        value={showNoOptions ? null : llmId ?? null}
        size={larger ? undefined : 'sm'}
        disabled={disabled}
        onChange={onSelectChange}
        listboxOpen={controlledOpen}
        onListboxOpenChange={hasNoModels ? optimaOpenModels : setControlledOpen}
        placeholder={hasNoModels ? LLM_TEXT_CONFIGURE : placeholder}
        slotProps={_slotProps}
        endDecorator={autoRefreshDomain ?
          <TooltipOutlined title='Auto-select the model'>
            <IconButton onClick={() => llmsStoreActions().assignDomainModelId(autoRefreshDomain, null)}>
              <AutoModeIcon />
            </IconButton>
          </TooltipOutlined>
          : isReasoning ? '🧠' : undefined}
        sx={options.sx ?? llmSelectSx}
      >
        {optionsArray}
      </Select>
      {/*</Box>*/}
    </FormControl>
  ), [autoRefreshDomain, controlledOpen, disabled, hasNoModels, isHorizontal, isReasoning, label, larger, llmId, onSelectChange, options.color, options.sx, options.variant, optionsArray, placeholder, showNoOptions]);

  // Memo the vendor icon for the chat LLM
  const chatLLMVendorIconFC = React.useMemo(() => {
    return !llm?.vId ? undefined : llmsGetVendorIcon(llm.vId);
  }, [llm?.vId]);

  return [llm, llmSelectComponent, chatLLMVendorIconFC];
}


================================================
FILE: src/common/components/icons/CalloutTopRightIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function CalloutTopRightIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' fill='currentColor' {...props}>
    <path d='m 20.51,21.14 c 0,0.78 -0.753041,1.02737 -1.51,0.86 -4,-1 -9,-5.21 -9,-9 0,-2.73 1.08,-5.27 2.75,-7.25 l -1.9,-1.9 C 10.54,3.54 10.76,3 11.21,3 H 16.5 C 16.78,3 17,3.22 17,3.5 v 5.29 c 0,0.45 -0.54,0.67 -0.85,0.35 L 14.18,7.17 C 12.84,8.82 12,10.88 12,13 c 0,3.13 5.217575,6.965474 7.723789,7.314527 C 20.228179,20.373224 20.51,20.79 20.51,21.14' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/ChatBeamIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function ChatBeamIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='currentColor' fill='currentColor' strokeLinejoin='round'  {...props}>
      <path d='M 4,12 14,9' />
      <path d='M 14,15 4,12' />
      <path d='m 14,15 6,-3' />
      <path d='m 4,12 10,9' />
      <path d='M 14,3 4,12' />
      <rect width='4' height='4' x='2' y='10' />
      <rect width='2' height='2' x='19' y='11' strokeWidth={2} />
      <rect width='2' height='2' x='13' y='2' />
      <rect width='2' height='2' x='13' y='8' />
      <rect width='2' height='2' x='13' y='14' />
      <rect width='2' height='2' x='13' y='20' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/ChatMulticastOffIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: the PodcastsIcon from '@mui/icons-material/Podcasts';
 */
export function ChatMulticastOffIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...props}>
      <path d='M14 12c0 .74-.4 1.38-1 1.72V22h-2v-8.28c-.6-.35-1-.98-1-1.72 0-1.1.9-2 2-2s2 .9 2 2m-2-6c-3.31 0-6 2.69-6 6 0 1.74.75 3.31 1.94 4.4l1.42-1.42C8.53 14.25 8 13.19 8 12c0-2.21 1.79-4 4-4s4 1.79 4 4c0 1.19-.53 2.25-1.36 2.98l1.42 1.42C17.25 15.31 18 13.74 18 12c0-3.31-2.69-6-6-6'></path>
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/ChatMulticastOnIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: the PodcastsIcon from '@mui/icons-material/Podcasts';
 */
export function ChatMulticastOnIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...props}>
      <path d='M14 12c0 .74-.4 1.38-1 1.72V22h-2v-8.28c-.6-.35-1-.98-1-1.72 0-1.1.9-2 2-2s2 .9 2 2m-2-6c-3.31 0-6 2.69-6 6 0 1.74.75 3.31 1.94 4.4l1.42-1.42C8.53 14.25 8 13.19 8 12c0-2.21 1.79-4 4-4s4 1.79 4 4c0 1.19-.53 2.25-1.36 2.98l1.42 1.42C17.25 15.31 18 13.74 18 12c0-3.31-2.69-6-6-6m0-4C6.48 2 2 6.48 2 12c0 2.85 1.2 5.41 3.11 7.24l1.42-1.42C4.98 16.36 4 14.29 4 12c0-4.41 3.59-8 8-8s8 3.59 8 8c0 2.29-.98 4.36-2.53 5.82l1.42 1.42C20.8 17.41 22 14.85 22 12c0-5.52-4.48-10-10-10'></path>
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/CodiconSplitHorizontal.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function CodiconSplitHorizontal(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 16 16' width={16} height={16} fill='currentColor' {...props}>
      <path d='M2 1 1 2v12l1 1h12l1-1V2l-1-1H2Zm0 13V2h7v12H2Z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/CodiconSplitHorizontalRemove.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function CodiconSplitHorizontalRemove(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 16 16' width={16} height={16} fill='currentColor' {...props}>
      <path d='M2 1 1 2v12l1 1h12l1-1V2l-1-1Zm0 1h12v12H2Zm6 2v3h1V4Zm0 5v3h1V9Z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/CodiconSplitVertical.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function CodiconSplitVertical(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 16 16' width={16} height={16} fill='currentColor' {...props}>
      <path d='M2 1 1 2v12l1 1h12l1-1V2l-1-1H2Zm0 9V2h12v8H2Z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/CodiconSplitVerticalRemove.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function CodiconSplitVerticalRemove(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 16 16' width={16} height={16} fill='currentColor' {...props}>
      <path d='M2 1 1 2v12l1 1h12l1-1V2l-1-1H2zm0 1h12v12H2V2zm2 6v1h3V8H4zm5 0v1h3V8H9z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/CodiconUnsplit.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function CodiconUnsplit(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 16 16' width={16} height={16} fill='currentColor' {...props}>
      <path d='m1 2 1-1h12l1 1v12l-1 1H2l-1-1zm1 0v12h12V2Z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/FoldersToggleOff.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function FoldersToggleOff(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' fill='currentColor' {...props}>
    <path d='m9.17 6 2 2H20v10H4V6zM10 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V8c0-1.1-.9-2-2-2h-8z' />
    <path d='M 16,11 12,16 8,11 Z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/FoldersToggleOn.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function FoldersToggleOn(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' fill='currentColor' {...props}>
    <path d='m9.17 6 2 2H20v10H4V6zM10 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V8c0-1.1-.9-2-2-2h-8z' />
    <path d='M 16,15 12,10 8,15 Z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/LayoutSidebarRight.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function LayoutSidebarRight(props: SvgIconProps) {
  return (
    <SvgIcon
      viewBox='0 0 16 16'
      width={16}
      height={16}
      fill='currentColor'
      {...props}
    >
      <path d='M2 1 1 2v12l1 1h12l1-1V2l-1-1H2zm0 1h6v12H2V2zm7 0h5v12H9V2zm1 1v1h3V3h-3zm0 2v1h3V5h-3zm0 2v1h3V7h-3z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/LiveFilePatchIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: the MultipleStopIcon from '@mui/icons-material/Podcasts';
 */
export function LiveFilePatchIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...props}>
      <path d='m 11,7 v 4 h 2 V 7 h 3 L 12,3 8,7 Z m 0,7 c 0,0.55 0.45,1 1,1 0.55,0 1,-0.45 1,-1 0,-0.55 -0.45,-1 -1,-1 -0.55,0 -1,0.45 -1,1 m 0,4 c 0,0.55 0.45,1 1,1 0.55,0 1,-0.45 1,-1 0,-0.55 -0.45,-1 -1,-1 -0.55,0 -1,0.45 -1,1' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/MarkHighlightIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: '@mui/icons-material/DriveFileRenameOutline';
 */
export function MarkHighlightIcon(props: SvgIconProps & { hcolor?: string }) {
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...props}>
      <path d='M18.41 5.8 17.2 4.59c-.78-.78-2.05-.78-2.83 0l-2.68 2.68L3 15.96V20h4.04l8.74-8.74 2.63-2.63c.79-.78.79-2.05 0-2.83M6.21 18H5v-1.21l8.66-8.66 1.21 1.21z'></path>
      <path d='M11 20l4-4h6v4z' fill={props.hcolor || 'currentColor'} stroke={props.hcolor ? 'currentColor' : undefined} strokeWidth={1.5}></path>
      {props.hcolor && <path d='M6.21 18H5v-1.21l8.66-8.66 1.21 1.21z' fill={props.hcolor}></path>}
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/WindowPaneRightClose.tsx
================================================
// import * as React from 'react';
//
// import { SvgIcon, SvgIconProps } from '@mui/joy';
//
// export function WindowPaneRightClose(props: SvgIconProps) {
//   return (
//     <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...props}>
//       <path d='M 9 3 L 9 21 L 11 21 L 11 3 L 9 3 z M 14 6.7558594 C 13.744381 6.7558594 13.488837 6.8529596 13.292969 7.0488281 C 12.901232 7.4405645 12.901232 8.0731073 13.292969 8.4648438 L 16.830078 12 L 13.292969 15.535156 C 12.901232 15.926893 12.901232 16.557482 13.292969 16.949219 C 13.684705 17.340955 14.317249 17.340955 14.708984 16.949219 L 18.951172 12.707031 C 19.342908 12.315295 19.342908 11.684705 18.951172 11.292969 L 14.708984 7.0488281 C 14.513117 6.8529599 14.255619 6.7558594 14 6.7558594 z' />
//       {/* thin <path d='M 4,2 C 2.9000033,2 2,2.9000033 2,4 v 16 c 0,1.099997 0.9000033,2 2,2 h 16 c 1.099997,0 2,-0.900003 2,-2 V 4 C 22,2.9000033 21.099997,2 20,2 Z M 3,3 H 21 V 21 H 3 Z m 9,3.7558594 c -0.255619,0 -0.511163,0.0971 -0.707031,0.2929687 -0.391737,0.3917368 -0.391737,1.0242789 0,1.4160157 L 14.830078,12 11.292969,15.535156 c -0.391737,0.391737 -0.391737,1.022326 0,1.414063 0.391737,0.391737 1.024279,0.391737 1.416015,0 l 4.242188,-4.242188 c 0.391737,-0.391737 0.391737,-1.022325 0,-1.414062 L 12.708984,7.0488281 C 12.513116,6.8529597 12.255619,6.7558594 12,6.7558594 Z' />*/}
//       {/* normal <path d='M 4 2 C 2.9000033 2 2 2.9000033 2 4 L 2 20 C 2 21.099997 2.9000033 22 4 22 L 20 22 C 21.099997 22 22 21.099997 22 20 L 22 4 C 22 2.9000033 21.099997 2 20 2 L 4 2 z M 4 4 L 20 4 L 20 20 L 4 20 L 4 4 z M 12 6.7558594 C 11.744381 6.7558594 11.488837 6.8529597 11.292969 7.0488281 C 10.901232 7.4405649 10.901232 8.073107 11.292969 8.4648438 L 14.830078 12 L 11.292969 15.535156 C 10.901232 15.926893 10.901232 16.557482 11.292969 16.949219 C 11.684706 17.340956 12.317248 17.340956 12.708984 16.949219 L 16.951172 12.707031 C 17.342909 12.315294 17.342909 11.684706 16.951172 11.292969 L 12.708984 7.0488281 C 12.513116 6.8529597 12.255619 6.7558594 12 6.7558594 z ' />*/}
//     </SvgIcon>
//   );
// }


================================================
FILE: src/common/components/icons/WindowPaneRightOpen.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function WindowPaneRightOpen(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...props}>
      <path d='M 4,2 C 2.9000011,2 2,2.9000011 2,4 v 16 c 0,1.099999 0.9000011,2 2,2 h 16 c 1.099999,0 2,-0.900001 2,-2 V 4 C 22,2.9000011 21.099999,2 20,2 Z m 0,2 h 7 V 20 H 4 Z m 9,0 h 7 v 16 h -7 z m 1,2 v 2 h 5 V 6 Z m 0,3 v 2 h 5 V 9 Z m 0,3 v 2 h 5 v -2 z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/3rdparty/AuthGitHubIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function AuthGitHubIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' {...props}>
    <path d='M12 .3a12 12 0 0 0-3.8 23.38c.6.12.83-.26.83-.57L9 21.07c-3.34.72-4.04-1.61-4.04-1.61-.55-1.39-1.34-1.76-1.34-1.76-1.08-.74.09-.73.09-.73 1.2.09 1.84 1.24 1.84 1.24 1.07 1.83 2.8 1.3 3.49 1 .1-.78.42-1.31.76-1.61-2.66-.3-5.47-1.33-5.47-5.93 0-1.31.47-2.38 1.24-3.22-.14-.3-.54-1.52.1-3.18 0 0 1-.32 3.3 1.23a11.5 11.5 0 0 1 6 0c2.28-1.55 3.29-1.23 3.29-1.23.64 1.66.24 2.88.12 3.18a4.65 4.65 0 0 1 1.23 3.22c0 4.61-2.8 5.63-5.48 5.92.42.36.81 1.1.81 2.22l-.01 3.29c0 .31.2.69.82.57A12 12 0 0 0 12 .3' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/3rdparty/AuthGoogleIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function AuthGoogleIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' {...props}>
    <path fill='#EA4335' d='M5.27 9.76A7.08 7.08 0 0 1 16.42 6.5L19.9 3A11.97 11.97 0 0 0 1.24 6.65l4.03 3.11Z' />
    <path fill='#34A853' d='M16.04 18.01A7.4 7.4 0 0 1 12 19.1a7.08 7.08 0 0 1-6.72-4.82l-4.04 3.06A11.96 11.96 0 0 0 12 24a11.4 11.4 0 0 0 7.83-3l-3.79-2.99Z' />
    <path fill='#4A90E2' d='M19.83 21c2.2-2.05 3.62-5.1 3.62-9 0-.7-.1-1.47-.27-2.18H12v4.63h6.44a5.4 5.4 0 0 1-2.4 3.56l3.8 2.99Z' />
    <path fill='#FBBC05' d='M5.28 14.27a7.12 7.12 0 0 1-.01-4.5L1.24 6.64A11.93 11.93 0 0 0 0 12c0 1.92.44 3.73 1.24 5.33l4.04-3.06Z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/3rdparty/CodePenIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/**
 * This is taken from the Codepen website - all rights reserved to them.
 * This is the code of the public facing website, we embed it to send traffic to them.
 */
export function CodePenIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 100 100' width='100' height='100' stroke='none' fill='currentColor' {...props}>
    <path d='M100 34.2c-.4-2.6-3.3-4-5.3-5.3-3.6-2.4-7.1-4.7-10.7-7.1-8.5-5.7-17.1-11.4-25.6-17.1-2-1.3-4-2.7-6-4-1.4-1-3.3-1-4.8 0-5.7 3.8-11.5 7.7-17.2 11.5L5.2 29C3 30.4.1 31.8 0 34.8c-.1 3.3 0 6.7 0 10v16c0 2.9-.6 6.3 2.1 8.1 6.4 4.4 12.9 8.6 19.4 12.9 8 5.3 16 10.7 24 16 2.2 1.5 4.4 3.1 7.1 1.3 2.3-1.5 4.5-3 6.8-4.5 8.9-5.9 17.8-11.9 26.7-17.8l9.9-6.6c.6-.4 1.3-.8 1.9-1.3 1.4-1 2-2.4 2-4.1V37.3c.1-1.1.2-2.1.1-3.1 0-.1 0 .2 0 0zM54.3 12.3 88 34.8 73 44.9 54.3 32.4V12.3zm-8.6 0v20L27.1 44.8 12 34.8l33.7-22.5zM8.6 42.8 19.3 50 8.6 57.2V42.8zm37.1 44.9L12 65.2l15-10.1 18.6 12.5v20.1zM50 60.2 34.8 50 50 39.8 65.2 50 50 60.2zm4.3 27.5v-20l18.6-12.5 15 10.1-33.6 22.4zm37.1-30.5L80.7 50l10.8-7.2-.1 14.4z' />
    {/*<path d='M75 0L100 0L100 25Z' />*/}
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/3rdparty/DiscordIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

// missing from MUI, using Tabler for Discord
export function DiscordIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='currentColor' fill='none' strokeLinecap='round' strokeLinejoin='round' {...props}>
    <path stroke='none' d='M0 0h24v24H0z' fill='none'></path>
    <path d='M14.983 3l.123 .006c2.014 .214 3.527 .672 4.966 1.673a1 1 0 0 1 .371 .488c1.876 5.315 2.373 9.987 1.451 12.28c-1.003 2.005 -2.606 3.553 -4.394 3.553c-.94 0 -2.257 -1.596 -2.777 -2.969l-.02 .005c.838 -.131 1.69 -.323 2.572 -.574a1 1 0 1 0 -.55 -1.924c-3.32 .95 -6.13 .95 -9.45 0a1 1 0 0 0 -.55 1.924c.725 .207 1.431 .373 2.126 .499l.444 .074c-.477 1.37 -1.695 2.965 -2.627 2.965c-1.743 0 -3.276 -1.555 -4.267 -3.644c-.841 -2.206 -.369 -6.868 1.414 -12.174a1 1 0 0 1 .358 -.49c1.392 -1.016 2.807 -1.475 4.717 -1.685a1 1 0 0 1 .938 .435l.063 .107l.652 1.288l.16 -.019c.877 -.09 1.718 -.09 2.595 0l.158 .019l.65 -1.287a1 1 0 0 1 .754 -.54l.123 -.01zm-5.983 6a2 2 0 0 0 -1.977 1.697l-.018 .154l-.005 .149l.005 .15a2 2 0 1 0 1.995 -2.15zm6 0a2 2 0 0 0 -1.977 1.697l-.018 .154l-.005 .149l.005 .15a2 2 0 1 0 1.995 -2.15z' strokeWidth='0' fill='currentColor'></path>
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/3rdparty/ExternalTickIcon.tsx
================================================
// import * as React from 'react';
//
// import { SvgIcon, SvgIconProps } from '@mui/joy';
//
// export function ExternalTickIcon(props: SvgIconProps) {
//   return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' fill='currentColor' {...props}>
//     <path d='M17 0L24 0L24 7Z' />
//   </SvgIcon>;
// }


================================================
FILE: src/common/components/icons/3rdparty/GoogleColabIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/**
 * This is taken from wikipedia: https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg
 */
export function GoogleColabIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='977' height='602' stroke='none' fill='currentColor' {...props}>
    <path d='M4.54,9.46,2.19,7.1a6.93,6.93,0,0,0,0,9.79l2.36-2.36A3.59,3.59,0,0,1,4.54,9.46Z' fill='#E8710A' />
    <path d='M2.19,7.1,4.54,9.46a3.59,3.59,0,0,1,5.08,0l1.71-2.93h0l-.1-.08h0A6.93,6.93,0,0,0,2.19,7.1Z' fill='#F9AB00' />
    <path d='M11.34,17.46h0L9.62,14.54a3.59,3.59,0,0,1-5.08,0L2.19,16.9a6.93,6.93,0,0,0,9,.65l.11-.09' fill='#F9AB00' />
    <path d='M12,7.1a6.93,6.93,0,0,0,0,9.79l2.36-2.36a3.59,3.59,0,1,1,5.08-5.08L21.81,7.1A6.93,6.93,0,0,0,12,7.1Z' fill='#F9AB00' />
    <path d='M21.81,7.1,19.46,9.46a3.59,3.59,0,0,1-5.08,5.08L12,16.9A6.93,6.93,0,0,0,21.81,7.1Z' fill='#E8710A' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/3rdparty/JSFiddleIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/**
 * This is taken from the JSFiddle website - all rights reserved to them.
 * This is the code of the public facing website, we embed it to send traffic to them.
 */
export function JSFiddleIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox="0 0 46 33" width="46" height="33" strokeWidth={4} stroke="currentColor" {...props}>
      <g fill="none" fillRule="evenodd">
        <path
          d="M23.4888889,20.543316 C21.4404656,18.4187374 19.0750303,15.6666667 16.4832014,15.6666667 C13.8721947,15.6666667 11.7555556,17.6366138 11.7555556,20.0666667 C11.7555556,22.4967196 13.8721947,24.4666667 16.4832014,24.4666667 C18.8347252,24.4666667 19.9845474,23.0125628 20.6429148,22.312473"
          strokeLinecap="round"
        ></path>
        <path
          d="M22.5111111,19.5900174 C24.5595344,21.7145959 26.9249697,24.4666667 29.5167986,24.4666667 C32.1278053,24.4666667 34.2444444,22.4967196 34.2444444,20.0666667 C34.2444444,17.6366138 32.1278053,15.6666667 29.5167986,15.6666667 C27.1652748,15.6666667 26.0154526,17.1207706 25.3570852,17.8208603"
          strokeLinecap="round"
        ></path>
        <path
          d="M45,22.7331459 C45,19.1499462 42.7950446,16.079593 39.6628004,14.7835315 C39.6774469,14.5246474 39.7003932,14.2674038 39.7003932,14.0035978 C39.7003932,6.82243304 33.8412885,1 26.611593,1 C21.3985635,1 16.9102123,4.03409627 14.8051788,8.41527616 C13.7828502,7.62878013 12.503719,7.15547161 11.1134367,7.15547161 C7.77825654,7.15547161 5.07450503,9.84159999 5.07450503,13.1544315 C5.07450503,13.7760488 5.16938207,14.3779791 5.3477444,14.9418479 C2.74863428,16.4787471 1,19.2867709 1,22.5105187 C1,27.3287502 4.89630545,31.2367856 9.72803666,31.31094 L36.3341301,31.3109406 C41.1201312,31.3406346 45,27.4870665 45,22.7331459 L45,22.7331459 Z"
          strokeLinejoin="round"
        ></path>
      </g>
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/3rdparty/StackBlitzIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/**
 * This is taken from the StackBlitz website - all rights reserved to them.
 * This is the code of the public facing website, we embed it to send traffic to them.
 */
export function StackBlitzIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 28 28' width='28' height='28' stroke='none' fill='currentColor' {...props}>
    <path d='M12.747 16.273h-7.46L18.925 1.5l-3.671 10.227h7.46L9.075 26.5l3.671-10.227z' />
    {/*<path d='M21 0L28 0L28 7Z' />*/}
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/big-agi/BigAgiCircleIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';


export function BigAgiCircleIcon(props: { innerColor?: string, compensateThinLine?: boolean } & SvgIconProps) {
  const { innerColor, compensateThinLine, ...rest } = props;
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...rest}>
      {props.innerColor && <circle cx='12' cy='12' r={props.compensateThinLine ? 11.925 : 12} fill={props.innerColor} />}
      <path d='M12 0C5.352 0 0 5.353 0 12.002A11.973 11.973 0 0 0 11.813 24l.017-7.962s.023-.82-.091-1.332c-.107-.45-.198-.734-.49-1.104-1.148-.013-.64.03-2.762-1.336-.091-.059.065-.303.132-.35.084-.057.658-.259 1.008-.46.27-.154 1.128-.706 1.399-1.624.081-.277.195-.811-.02-1.962-.114-.57-.246-1.14-.266-1.723-.042-1.542.647-2.278.99-2.603.39-.37.856-.644 1.327-.895.532-.264 1.07-.527 1.648-.672l2.237 1.58c-.57.087-1.095.348-1.61.594-1.202.624-2.276 1.325-2.164 3.235.033.554.222 1.265.293 1.676.146.837.139 1.518-.033 2.06-.31.98-1.164 1.593-1.488 1.796.56.38 1.156.72 1.513 1.319.461.68.525 1.124.545 1.87.01 2.608.001 5.164-.006 7.73A11.972 11.972 0 0 0 24 12.003C24 5.352 18.648 0 12 0Z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/big-agi/BigAgiCircleInnerIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';


export function BigAgiCircleInnerIcon(props: { outerColor: string, compensateThinline?: boolean } & SvgIconProps) {
  const { outerColor, compensateThinline, ...rest } = props;
  return (
    <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...rest}>
      {props.outerColor && <circle cx='12' cy='12' r={props.compensateThinline ? 11.95 : 12} fill={props.outerColor} />}
      <path d='M14.703 1.977c-.579.144-1.118.408-1.65.671-.471.252-.936.528-1.326.897-.345.326-1.035 1.061-.993 2.605.02.584.154 1.155.268 1.725.215 1.151.101 1.685.02 1.963-.271.92-1.13 1.472-1.4 1.627-.351.2-.927.404-1.01.46-.069.047-.224.29-.133.348 2.125 1.368 1.615 1.327 2.763 1.34.293.37.386.654.492 1.104.115.513.092 1.334.092 1.334l-.017 7.935A12 12 0 0 0 12 24a12 12 0 0 0 1.99-.186c.007-2.555.016-5.1.006-7.697-.02-.745-.083-1.187-.545-1.869-.358-.599-.954-.942-1.515-1.322.324-.204 1.18-.815 1.49-1.795.172-.543.18-1.225.033-2.063-.072-.411-.26-1.123-.293-1.677-.112-1.912.96-2.615 2.164-3.239.515-.246 1.043-.509 1.613-.595l-2.24-1.58z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/icons/big-agi/BigAgiSquircleIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function BigAgiSquircleIcon(props: { inverted?: boolean, altColor?: string } & SvgIconProps) {
  const { inverted, altColor, ...rest } = props;
  return <SvgIcon
    titleAccess='logo mark'
    viewBox='0 0 6.3500006 6.3499996' width='24' height='24'
    stroke='none' strokeWidth={0.691986} strokeLinecap='round' strokeLinejoin='round'
    {...rest}
  >
    <g transform='translate(51.117939,-42.425365)'>
      <g transform='matrix(0.07058825,0,0,0.07058823,-47.509613,39.430634)'>
        <rect
          fill={inverted ? (altColor || '#000000') : 'currentColor'}
          width='89.958321'
          height='89.958321'
          x='-51.117939'
          y='42.425365'
          ry='20' />
        <path
          fill={inverted ? 'currentColor' : (altColor || '#000000')}
          fillOpacity={1}
          d='m 4.0021675,49.836309 -5.2e-4,5.1e-4 c -2.16855,0.54197 -4.18593997,1.53104 -6.17895,2.51871 -1.76404,0.94102 -3.50957,1.96574 -4.97024,3.34864 -1.01158,0.95772 -1.10871,1.18722 -1.9327,2.2934 -1.3708395,2.32511 -1.8551195,4.78906 -1.7817995,7.46827 0.0135,0.49268 0.0709,0.98327 0.10645,1.47485 0.16185,1.68282 0.58029,3.32246 0.8893495,4.98006 0.21008,1.12671 0.202,1.19346 0.3514,2.34404 0.16811,1.66717 0.20579,3.37783 -0.27285,5.00331 -0.3570295,1.21244 -0.5419495,1.37085 -1.1849395,2.46755 -1.08741,1.46507 -2.46987,2.7206 -4.05712,3.62975 -0.6278,0.35961 -1.54734,0.75252 -2.21226,1.05007 -0.14695,0.0581 -1.32968,0.50363 -1.5658,0.66559 -0.2541,0.17428 -0.83933,1.09089 -0.49868,1.31 7.95779,5.11884 6.04665,4.96385 10.3476895,5.0121 0.0404,0.005 0.0678,0.008 0.10749,0.0129 0.32616,0.47435 0.62621,0.96314 0.85524,1.48931 0.37498,0.86147 0.50729,1.81227 0.6718,2.7373 0.28715,1.61456 0.45546,3.251761 0.54673,4.889111 0.20491,3.67585 0,11.0448 0,11.0448 0,0 -0.05519,9.95619 -0.08888,18.80712 h 8.17676 c 0.01797,-5.68374 0.03669,-12.27573 0.03669,-12.27573 v -7.44658 -5.50302 c 0,0 0.0305,-3.26895 0,-4.90358 -0.0285,-1.06103 -0.0599,-1.85635 -0.25373,-2.759521 -0.12533997,-0.58405 -0.33168997,-1.15279 -0.58238997,-1.69499 -0.32913,-0.7118 -0.76001,-1.37445 -1.19993,-2.02364 -0.43112003,-0.63621 -0.86978003,-1.27635 -1.40611003,-1.82677 -0.49313,-0.50609 -1.06346,-0.93626 -1.6459,-1.33635 -0.92028,-0.63214 -1.76336,-1.21583 -2.62258,-1.77663 1.65441,-1.03826 3.09438,-2.40552 4.23334,-3.98839 0.71381,-1.21567 0.92029,-1.40723 1.34255003,-2.73937 0.54445,-1.71766 0.58905,-3.53149 0.43822,-5.3113 -0.11668,-1.06503 -0.13236,-1.36869 -0.3142,-2.41433 -0.28433,-1.63494 -0.74152003,-3.23741 -0.94723003,-4.88704 -0.0502,-0.46371 -0.1235,-0.92552 -0.15089,-1.39113 -0.14629,-2.48733 0.20532,-4.71974 1.46813003,-6.89363 0.77186,-1.01913 0.85052,-1.21803 1.80814997,-2.09238 1.42824,-1.30403 3.1314,-2.25506 4.837439,-3.13934 1.92892,-0.92218 3.8955405,-1.89816 6.0301205,-2.22312 z' />
      </g>
    </g>
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/phosphor/PhChats.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/' - chats
 */
export function PhChats(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M216,80H184V48a16,16,0,0,0-16-16H40A16,16,0,0,0,24,48V176a8,8,0,0,0,13,6.22L72,154V184a16,16,0,0,0,16,16h93.59L219,230.22a8,8,0,0,0,5,1.78,8,8,0,0,0,8-8V96A16,16,0,0,0,216,80ZM66.55,137.78,40,159.25V48H168v88H71.58A8,8,0,0,0,66.55,137.78ZM216,207.25l-26.55-21.47a8,8,0,0,0-5-1.78H88V152h80a16,16,0,0,0,16-16V96h32Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhChatsDuotone.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/' - chats
 */
export function PhChatsDuotone(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M224,96V224l-39.58-32H88a8,8,0,0,1-8-8V144h88a8,8,0,0,0,8-8V88h40A8,8,0,0,1,224,96Z' opacity='0.2' />
      <path d='M216,80H184V48a16,16,0,0,0-16-16H40A16,16,0,0,0,24,48V176a8,8,0,0,0,13,6.22L72,154V184a16,16,0,0,0,16,16h93.59L219,230.22a8,8,0,0,0,5,1.78,8,8,0,0,0,8-8V96A16,16,0,0,0,216,80ZM66.55,137.78,40,159.25V48H168v88H71.58A8,8,0,0,0,66.55,137.78ZM216,207.25l-26.55-21.47a8,8,0,0,0-5-1.78H88V152h80a16,16,0,0,0,16-16V96h32Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhGearSixIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/?q=%22gear-six%22';
 */
export function PhGearSixIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path
        d='M128,80a48,48,0,1,0,48,48A48.05,48.05,0,0,0,128,80Zm0,80a32,32,0,1,1,32-32A32,32,0,0,1,128,160Zm109.94-52.79a8,8,0,0,0-3.89-5.4l-29.83-17-.12-33.62a8,8,0,0,0-2.83-6.08,111.91,111.91,0,0,0-36.72-20.67,8,8,0,0,0-6.46.59L128,41.85,97.88,25a8,8,0,0,0-6.47-.6A112.1,112.1,0,0,0,54.73,45.15a8,8,0,0,0-2.83,6.07l-.15,33.65-29.83,17a8,8,0,0,0-3.89,5.4,106.47,106.47,0,0,0,0,41.56,8,8,0,0,0,3.89,5.4l29.83,17,.12,33.62a8,8,0,0,0,2.83,6.08,111.91,111.91,0,0,0,36.72,20.67,8,8,0,0,0,6.46-.59L128,214.15,158.12,231a7.91,7.91,0,0,0,3.9,1,8.09,8.09,0,0,0,2.57-.42,112.1,112.1,0,0,0,36.68-20.73,8,8,0,0,0,2.83-6.07l.15-33.65,29.83-17a8,8,0,0,0,3.89-5.4A106.47,106.47,0,0,0,237.94,107.21Zm-15,34.91-28.57,16.25a8,8,0,0,0-3,3c-.58,1-1.19,2.06-1.81,3.06a7.94,7.94,0,0,0-1.22,4.21l-.15,32.25a95.89,95.89,0,0,1-25.37,14.3L134,199.13a8,8,0,0,0-3.91-1h-.19c-1.21,0-2.43,0-3.64,0a8.08,8.08,0,0,0-4.1,1l-28.84,16.1A96,96,0,0,1,67.88,201l-.11-32.2a8,8,0,0,0-1.22-4.22c-.62-1-1.23-2-1.8-3.06a8.09,8.09,0,0,0-3-3.06l-28.6-16.29a90.49,90.49,0,0,1,0-28.26L61.67,97.63a8,8,0,0,0,3-3c.58-1,1.19-2.06,1.81-3.06a7.94,7.94,0,0,0,1.22-4.21l.15-32.25a95.89,95.89,0,0,1,25.37-14.3L122,56.87a8,8,0,0,0,4.1,1c1.21,0,2.43,0,3.64,0a8.08,8.08,0,0,0,4.1-1l28.84-16.1A96,96,0,0,1,188.12,55l.11,32.2a8,8,0,0,0,1.22,4.22c.62,1,1.23,2,1.8,3.06a8.09,8.09,0,0,0,3,3.06l28.6,16.29A90.49,90.49,0,0,1,222.9,142.12Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhPaintBrush.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/' - paint-brush-household
 */
export function PhPaintBrush(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M232,32a8,8,0,0,0-8-8c-44.08,0-89.31,49.71-114.43,82.63A60,60,0,0,0,32,164c0,30.88-19.54,44.73-20.47,45.37A8,8,0,0,0,16,224H92a60,60,0,0,0,57.37-77.57C182.3,121.31,232,76.08,232,32ZM92,208H34.63C41.38,198.41,48,183.92,48,164a44,44,0,1,1,44,44Zm32.42-94.45q5.14-6.66,10.09-12.55A76.23,76.23,0,0,1,155,121.49q-5.9,4.94-12.55,10.09A60.54,60.54,0,0,0,124.42,113.55Zm42.7-2.68a92.57,92.57,0,0,0-22-22c31.78-34.53,55.75-45,69.9-47.91C212.17,55.12,201.65,79.09,167.12,110.87Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhPaintBrushHousehold.tsx
================================================
// import * as React from 'react';
//
// import { SvgIcon, SvgIconProps } from '@mui/joy';
//
// /*
//  * Source: 'https://phosphoricons.com/' - paint-brush-household
//  */
// export function PhPaintBrushHousehold(props: SvgIconProps) {
//   return (
//     <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
//       <path d='M230.64,25.36a32,32,0,0,0-45.26,0q-.21.21-.42.45L131.55,88.22,121,77.64a24,24,0,0,0-33.95,0l-76.69,76.7a8,8,0,0,0,0,11.31l80,80a8,8,0,0,0,11.31,0L178.36,169a24,24,0,0,0,0-33.95l-10.58-10.57L230.19,71c.15-.14.31-.28.45-.43A32,32,0,0,0,230.64,25.36ZM96,228.69,79.32,212l22.34-22.35a8,8,0,0,0-11.31-11.31L68,200.68,55.32,188l22.34-22.35a8,8,0,0,0-11.31-11.31L44,176.68,27.31,160,72,115.31,140.69,184ZM219.52,59.1l-68.71,58.81a8,8,0,0,0-.46,11.74L167,146.34a8,8,0,0,1,0,11.31l-15,15L83.32,104l15-15a8,8,0,0,1,11.31,0l16.69,16.69a8,8,0,0,0,11.74-.46L196.9,36.48A16,16,0,0,1,219.52,59.1Z' />
//     </SvgIcon>
//   );
// }



================================================
FILE: src/common/components/icons/phosphor/PhRobot.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/' - robot
 */
export function PhRobot(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M200,48H136V16a8,8,0,0,0-16,0V48H56A32,32,0,0,0,24,80V192a32,32,0,0,0,32,32H200a32,32,0,0,0,32-32V80A32,32,0,0,0,200,48Zm16,144a16,16,0,0,1-16,16H56a16,16,0,0,1-16-16V80A16,16,0,0,1,56,64H200a16,16,0,0,1,16,16Zm-52-56H92a28,28,0,0,0,0,56h72a28,28,0,0,0,0-56Zm-24,16v24H116V152ZM80,164a12,12,0,0,1,12-12h8v24H92A12,12,0,0,1,80,164Zm84,12h-8V152h8a12,12,0,0,1,0,24ZM72,108a12,12,0,1,1,12,12A12,12,0,0,1,72,108Zm88,0a12,12,0,1,1,12,12A12,12,0,0,1,160,108Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhSlidersHorizontalIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/?q=%22sliders-horizontal%22';
 */
export function PhSlidersHorizontalIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M40,88H73a32,32,0,0,0,62,0h81a8,8,0,0,0,0-16H135a32,32,0,0,0-62,0H40a8,8,0,0,0,0,16Zm64-24A16,16,0,1,1,88,80,16,16,0,0,1,104,64ZM216,168H199a32,32,0,0,0-62,0H40a8,8,0,0,0,0,16h97a32,32,0,0,0,62,0h17a8,8,0,0,0,0-16Zm-48,24a16,16,0,1,1,16-16A16,16,0,0,1,168,192Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhSlidersIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/?q=%22sliders%22';
 */
export function PhSlidersIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M64,105V40a8,8,0,0,0-16,0v65a32,32,0,0,0,0,62v49a8,8,0,0,0,16,0V167a32,32,0,0,0,0-62Zm-8,47a16,16,0,1,1,16-16A16,16,0,0,1,56,152Zm80-95V40a8,8,0,0,0-16,0V57a32,32,0,0,0,0,62v97a8,8,0,0,0,16,0V119a32,32,0,0,0,0-62Zm-8,47a16,16,0,1,1,16-16A16,16,0,0,1,128,104Zm104,64a32.06,32.06,0,0,0-24-31V40a8,8,0,0,0-16,0v97a32,32,0,0,0,0,62v17a8,8,0,0,0,16,0V199A32.06,32.06,0,0,0,232,168Zm-32,16a16,16,0,1,1,16-16A16,16,0,0,1,200,184Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhSquaresFour.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/' - squares-four - U+E464
 */
export function PhSquaresFour(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M104,40H56A16,16,0,0,0,40,56v48a16,16,0,0,0,16,16h48a16,16,0,0,0,16-16V56A16,16,0,0,0,104,40Zm0,64H56V56h48v48Zm96-64H152a16,16,0,0,0-16,16v48a16,16,0,0,0,16,16h48a16,16,0,0,0,16-16V56A16,16,0,0,0,200,40Zm0,64H152V56h48v48Zm-96,32H56a16,16,0,0,0-16,16v48a16,16,0,0,0,16,16h48a16,16,0,0,0,16-16V152A16,16,0,0,0,104,136Zm0,64H56V152h48v48Zm96-64H152a16,16,0,0,0-16,16v48a16,16,0,0,0,16,16h48a16,16,0,0,0,16-16V152A16,16,0,0,0,200,136Zm0,64H152V152h48v48Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/phosphor/PhUsers.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

/*
 * Source: 'https://phosphoricons.com/' - users
 */
export function PhUsers(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 256 256' stroke='none' fill='currentColor' width='24' height='24' {...props}>
      <path d='M117.25,157.92a60,60,0,1,0-66.5,0A95.83,95.83,0,0,0,3.53,195.63a8,8,0,1,0,13.4,8.74,80,80,0,0,1,134.14,0,8,8,0,0,0,13.4-8.74A95.83,95.83,0,0,0,117.25,157.92ZM40,108a44,44,0,1,1,44,44A44.05,44.05,0,0,1,40,108Zm210.14,98.7a8,8,0,0,1-11.07-2.33A79.83,79.83,0,0,0,172,168a8,8,0,0,1,0-16,44,44,0,1,0-16.34-84.87,8,8,0,1,1-5.94-14.85,60,60,0,0,1,55.53,105.64,95.83,95.83,0,0,1,47.22,37.71A8,8,0,0,1,250.14,206.7Z' />
    </SvgIcon>
  );
}



================================================
FILE: src/common/components/icons/vendors/AlibabaCloudIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

// This icon has been converted from the official SVG of the Alibaba Cloud logo
export function AlibabaCloudIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' {...props}>
    <path d='m 8.025,12.9 h 7.95 v -1.8 h -7.95 z' />
    <path d='M 19.9875,4.5 H 14.7 l 1.275,1.8 3.8625,1.2 C 20.55,7.725 21,8.3625 21,9.1125 v 5.775 c 0,0.75 -0.45,1.3875 -1.1625,1.6125 L 15.975,17.7 14.7,19.5 h 5.2875 C 22.2375,19.5 24,17.7 24,15.4875 V 8.5125 C 24,6.2625 22.2,4.5 19.9875,4.5 m -15.975,0 H 9.3 L 8.025,6.3 4.1625,7.5 A 1.6875,1.6875 0 0 0 3,9.1125 v 5.775 c 0,0.75 0.45,1.3875 1.1625,1.6125 L 8.025,17.7 9.3,19.5 H 4.0125 C 1.7625,19.5 0,17.7 0,15.4875 V 8.5125 C 0,6.2625 1.8,4.5 4.0125,4.5' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/AnthropicIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function AnthropicIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='10 15 225 225' width='24' height='24' stroke='currentColor' fill='none' strokeLinecap='round' strokeLinejoin='round' {...props}>
    <path d='M47.1 124.4l-30.1 76c0 .3 7.6.6 16.9.6h16.9l3.6-9.2 6-15.8 2.4-6.5 31.5-.3 31.5-.2 3 7.7 6.2 16 3.2 8.3h16.9c9.3 0 16.9-.2 16.9-.4s-8.5-21.7-18.9-47.8L123 77.2 111.8 49H94.5 77.2l-30.1 75.4zm57.3-10.4l9.6 25.2c0 .5-8.8.8-19.5.8s-19.5-.3-19.5-.8c0-.4 3.4-9.5 7.6-20.2l9.6-24.8c1.1-2.9 2.1-5.2 2.3-5s4.7 11.3 9.9 24.8zM140 50.2c0 .7 13.4 34.8 29.8 75.8l29.7 74.5 16.9.3c9.9.1 16.6-.1 16.4-.7-.1-.5-13.8-34.7-30.2-76l-30-75.1h-16.3c-12.4 0-16.3.3-16.3 1.2z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/AzureIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function AzureIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='currentColor' strokeWidth={1.5} fill='none' strokeLinecap='round' strokeLinejoin='round' {...props}>
    {/*<path stroke='none' d='M0 0h24v24H0z' fill='none'></path>*/}
    <path stroke='none' d='M0 0h24v24H0z' fill='none' />
    <path d='M6 7.5l-4 9.5h4l6 -15z' />
    <path d='M22 20l-7 -15l-3 7l4 5l-8 3z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/DeepseekIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function DeepseekIcon(props: SvgIconProps) {
  return <SvgIcon viewBox="0 0 56.2 41.3594" width="56.2" height="41.359375" strokeWidth={0} stroke='none' fill='currentColor' strokeLinecap='butt' strokeLinejoin='miter' {...props}>
    <path id="path" d="M55.6128 3.47119C55.0175 3.17944 54.7611 3.73535 54.413 4.01782C54.2939 4.10889 54.1932 4.22729 54.0924 4.33667C53.2223 5.26587 52.2057 5.87646 50.8776 5.80347C48.9359 5.69409 47.2781 6.30469 45.8126 7.78979C45.5012 5.9585 44.4663 4.86499 42.8909 4.16357C42.0667 3.79907 41.2332 3.43457 40.6561 2.64185C40.2532 2.07715 40.1432 1.44849 39.9418 0.828857C39.8135 0.455322 39.6853 0.0725098 39.2548 0.00878906C38.7877 -0.0639648 38.6045 0.327637 38.4213 0.655762C37.6886 1.99512 37.4047 3.47119 37.4321 4.96533C37.4962 8.32739 38.9159 11.0059 41.7369 12.9102C42.0575 13.1289 42.1399 13.3474 42.0392 13.6665C41.8468 14.3225 41.6178 14.9602 41.4164 15.6162C41.2881 16.0354 41.0957 16.1265 40.647 15.9441C39.0991 15.2974 37.7618 14.3406 36.5803 13.1836C34.5745 11.2429 32.761 9.10181 30.4988 7.42529C29.9675 7.03345 29.4363 6.66919 28.8867 6.32275C26.5786 4.08154 29.189 2.24097 29.7935 2.02246C30.4254 1.79468 30.0133 1.01099 27.9708 1.02026C25.9283 1.0293 24.0599 1.71265 21.6786 2.62378C21.3306 2.7605 20.9641 2.8606 20.5886 2.94263C18.4271 2.53271 16.1831 2.44141 13.8384 2.70581C9.42371 3.19775 5.89758 5.28418 3.30554 8.84668C0.191406 13.1289 -0.54126 17.9941 0.356323 23.0691C1.29968 28.4172 4.02905 32.8452 8.22388 36.3076C12.5745 39.8972 17.5845 41.6558 23.2997 41.3186C26.771 41.1182 30.6361 40.6536 34.9958 36.9636C36.0948 37.5103 37.2489 37.7288 39.1632 37.8928C40.6378 38.0295 42.0575 37.8201 43.1565 37.5923C44.8784 37.2278 44.7594 35.6333 44.1366 35.3418C39.09 32.9912 40.1981 33.9478 39.1907 33.1733C41.7552 30.1394 45.6204 26.9868 47.1316 16.7732C47.2506 15.9624 47.1499 15.4521 47.1316 14.7961C47.1224 14.3953 47.214 14.2405 47.672 14.1948C48.9359 14.0491 50.1632 13.7029 51.2898 13.0833C54.5596 11.2976 55.8784 8.36377 56.1898 4.84692C56.2357 4.30933 56.1807 3.75342 55.6128 3.47119ZM27.119 35.123C22.2281 31.2783 19.856 30.0117 18.8759 30.0664C17.96 30.1211 18.1249 31.1689 18.3263 31.8523C18.537 32.5264 18.8118 32.9912 19.1964 33.5833C19.462 33.9751 19.6453 34.5581 18.9309 34.9956C17.3555 35.9705 14.6169 34.6675 14.4886 34.6038C11.3014 32.7268 8.63611 30.2485 6.75842 26.8594C4.94495 23.5974 3.89172 20.0989 3.71765 16.3633C3.67188 15.4614 3.9375 15.1423 4.83508 14.9785C6.0166 14.7598 7.23474 14.7141 8.41626 14.8872C13.408 15.6162 17.6577 17.8484 21.2206 21.3835C23.2539 23.397 24.7926 25.8025 26.3772 28.1531C28.0624 30.6494 29.8759 33.0276 32.184 34.9773C32.9991 35.6606 33.6494 36.1799 34.2722 36.5627C32.3947 36.7722 29.2622 36.8179 27.119 35.123ZM29.4637 20.0442C29.4637 19.6433 29.7843 19.3245 30.1874 19.3245C30.2789 19.3245 30.3613 19.3425 30.4346 19.3699C30.5354 19.4065 30.627 19.4612 30.7002 19.543C30.8285 19.6707 30.9017 19.8528 30.9017 20.0442C30.9017 20.4451 30.5812 20.7639 30.1782 20.7639C29.7751 20.7639 29.4637 20.4451 29.4637 20.0442ZM36.7452 23.7798C36.2781 23.9712 35.811 24.135 35.3622 24.1533C34.6661 24.1897 33.9059 23.9072 33.4938 23.561C32.8527 23.0234 32.3947 22.7229 32.2023 21.7844C32.1199 21.3835 32.1656 20.7639 32.239 20.4087C32.4038 19.6433 32.2206 19.1514 31.6803 18.7048C31.2406 18.3403 30.6819 18.2402 30.0682 18.2402C29.8392 18.2402 29.6287 18.1399 29.4729 18.0579C29.2164 17.9304 29.0059 17.6116 29.2073 17.2197C29.2714 17.0923 29.5829 16.7825 29.6561 16.7278C30.4896 16.2539 31.4513 16.4089 32.3397 16.7642C33.1641 17.1013 33.7869 17.7209 34.6844 18.5955C35.6003 19.6523 35.7651 19.9441 36.2872 20.7366C36.6995 21.3562 37.075 21.9939 37.3314 22.7229C37.4871 23.1785 37.2856 23.552 36.7452 23.7798Z"/>
  </SvgIcon>;
}



================================================
FILE: src/common/components/icons/vendors/GeminiIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function GeminiIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' strokeWidth={0} stroke='none' fill='currentColor' {...props}>
    <g transform='matrix(0.25528557,0,0,0.25528409,1.353,-9.2592294)'>
      <path
        d='m 26.1532,123.14 c 5.223,2.151 10.7916,3.226 16.7058,3.226 5.9911,0 11.4445,-0.96 16.3602,-2.88 4.9157,-1.92 9.1786,-4.647 12.7886,-8.18 3.61,-3.533 6.4135,-7.719 8.4105,-12.558 1.997,-4.9159 2.9955,-10.2925 2.9955,-16.1299 v -0.1152 c 0,-1.0753 -0.0768,-2.0739 -0.2304,-2.9956 -0.0768,-0.9217 -0.192,-1.8818 -0.3457,-2.8803 H 43.0895 v 9.5627 h 29.9552 c -0.3073,4.6085 -1.3826,8.6025 -3.226,11.9823 -1.7666,3.303 -4.0324,6.029 -6.7975,8.18 -2.6883,2.15 -5.799,3.763 -9.3322,4.839 -3.4564,0.998 -7.0664,1.498 -10.83,1.498 -4.1476,0 -8.1801,-0.769 -12.0973,-2.305 -3.9172,-1.536 -7.412,-3.763 -10.4843,-6.682 -2.9955,-2.919 -5.3766,-6.414 -7.1432,-10.4844 -1.7666,-4.1476 -2.6499,-8.7945 -2.6499,-13.9407 0,-5.1461 0.8449,-9.7546 2.5347,-13.8255 1.7666,-4.1476 4.1477,-7.6424 7.1432,-10.4843 2.9955,-2.9187 6.4519,-5.1462 10.3691,-6.6823 3.994,-1.5362 8.1033,-2.3043 12.3277,-2.3043 3.1492,0 6.1447,0.4225 8.9866,1.2674 2.8419,0.768 5.4534,1.8818 7.8344,3.3411 2.4579,1.4594 4.5701,3.226 6.3367,5.2998 l 7.1432,-7.3736 C 69.7035,48.598 65.287,45.564 59.9105,43.4134 54.6107,41.2628 48.9269,40.1875 42.859,40.1875 c -5.8374,0 -11.3676,1.0753 -16.5906,3.2259 C 21.1223,45.564 16.5522,48.598 12.5582,52.5152 8.64093,56.4324 5.5686,61.0025 3.34116,66.2255 1.11372,71.4484 0,77.1323 0,83.2769 c 0,6.1447 1.11372,11.8285 3.34116,17.0511 4.4683256,10.47753 12.538557,18.51982 22.81204,22.812 z' />
    </g>
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/GroqIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function GroqIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 834 305' width='24' height='24' fill='currentColor' stroke='none' strokeLinecap='round' strokeLinejoin='round' {...props}>
    <path
      d='M499.3.5c-57.6 0-104.4 46.7-104.4 104.4s46.7 104.4 104.4 104.4 104.4-46.7 104.4-104.4C603.6 47.3 556.9.6 499.3.5m0 169.6c-36 0-65.2-29.2-65.2-65.2s29.2-65.2 65.2-65.2 65.2 29.2 65.2 65.2-29.2 65.2-65.2 65.2M355.2.9c-3.6-.4-7.1-.6-10.7-.6-1.8 0-3.5 0-5.2.1s-3.5.2-5.2.3c-7 .5-14 1.7-20.8 3.6-13.9 3.7-27 10.3-38.3 19.2-11.6 9.2-20.8 21-27.1 34.4-3.1 6.7-5.4 13.8-6.9 21-.7 3.6-1.2 7.2-1.6 10.8-.1 1.8-.3 3.6-.3 5.4l-.1 2.7v2.5l.1 35 .1 34.9.2 34.9h39.1l.2-34.9.1-34.9.1-35v-3.7c0-1.1.2-2.2.2-3.3.2-2.2.6-4.3 1-6.5.9-4.2 2.2-8.3 4-12.2 3.6-7.8 9-14.6 15.7-20 7-5.6 15.1-9.7 23.7-12 4.4-1.2 9-2 13.6-2.4 1.2-.1 2.3-.2 3.5-.2s2.4-.1 3.5-.1c2.2 0 4.5.1 6.7.3 8.9.9 17.5 3.6 25.4 8l19.5-33.9C383.3 7.1 369.5 2.5 355.2.9M105.3 0C47.7-.5.5 45.8 0 103.4s45.8 104.8 103.4 105.3h36.2v-39.1h-34.3c-36 .4-65.6-28.4-66-64.5s28.4-65.6 64.5-66h1.5c36 0 65.2 29.2 65.4 65.2v96.1c0 35.7-29.1 64.8-64.7 65.2-17.1-.1-33.4-7-45.4-19.1l-27.7 27.7c19.2 19.3 45.2 30.3 72.4 30.5h1.4c56.9-.8 102.6-47 102.9-103.9v-99.1C208.2 45.2 161.9.1 105.3 0M729.7.5c-57.6 0-104.4 46.7-104.3 104.4 0 57.6 46.7 104.3 104.3 104.3h35.7v-39.1h-35.7c-36 0-65.2-29.2-65.2-65.2s29.2-65.2 65.2-65.2c33.8 0 62 25.9 65 59.6h-.1v200.4h39.1V104.9C833.7 47.3 787.2.5 729.7.5' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/LMStudioIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function LMStudioIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' fill='currentColor' {...props}>
    <rect width='11' height='2' x='3' y='4' ry='1' />
    <rect width='10.5' height='2' x='7.5' y='7' ry='1' />
    <rect width='10.5' height='2' x='5' y='10' ry='1' />
    <rect width='10.5' height='2' x='2' y='13' ry='1' />
    <rect width='10.5' height='2' x='5' y='16' ry='1' />
    <rect width='7' height='2' x='11.5' y='19' ry='1' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/LocalAIIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function LocalAIIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='none' fill='currentColor' {...props}>
    <path
      d='M 11.2 1.5 L 10.7 1.6 L 9.8 2.9 L 8.8 3.7 L 9.1 3.9 L 8.3 4.3 L 7.4 4.4 L 6.8 4.2 L 5.5 3.4 L 5.3 3 L 4.9 2.1 L 4.3 2 L 4.3 3.1 L 4.6 4.4 L 5.5 5.1 L 4.6 5.7 L 4 6.3 L 5.2 6.3 L 7.2 6.3 L 7.2 6.6 L 6.8 6.6 L 6.8 7 L 7.2 7 L 7.2 7.1 L 6.8 7.1 L 6.7 7.4 L 7.2 7.4 L 7.2 7.9 L 7.1 7.9 L 7.1 7.6 L 6.7 7.6 L 6.7 7.9 L 6.6 7.8 L 6.6 7.8 L 6.4 7.8 L 6.4 8.1 L 6.2 8.1 L 6.2 7.8 L 6 7.8 L 5.9 8 L 5.7 8 L 5.7 7.8 L 5.4 7.7 L 5.3 7 L 4.8 7 L 4.8 7.4 L 4.6 7.7 L 3.3 7.7 L 3.3 7.7 L 3.6 7.7 L 3.1 8.2 L 3.3 8.4 L 3.2 8.5 L 3.3 9.3 L 3.8 9.5 L 4.3 10.3 L 4.9 10.2 L 4.8 11.9 L 5.2 14.2 L 6 16 L 4.7 17.3 L 3.3 18.2 L 3.3 19.7 L 3 21.5 L 3.3 22.4 L 3.7 22.3 L 4.2 21.3 L 3.7 21.1 L 4.1 20.9 L 4.1 20.7 L 3.9 20.7 L 3.7 20.4 L 4.2 20.2 L 4.2 20.1 L 4 20.1 L 4.1 19.2 L 4.6 19.1 L 4.8 18.7 L 5.2 18.6 L 4.8 19.3 L 4.8 19.8 L 5.2 20.6 L 6 21.6 L 6.7 22.3 L 6.9 22.6 L 7.1 22.2 L 7.3 21.5 L 7 21.2 L 6.7 21.1 L 6.4 20.8 L 6.6 20.6 L 6.6 20.5 L 6.2 20.6 L 5.8 20.4 L 6.6 20.1 L 6.6 20 L 5.7 20.2 L 5.4 20 L 7.5 19.4 L 7.6 19.6 L 9.3 19.1 L 9.4 19.4 L 17.6 17.4 L 17.6 17.6 L 11.7 19.2 L 11.8 19.5 L 20.1 17.6 L 17.8 18.3 L 14 19.3 L 14 20.1 L 21.8 17.9 L 21.8 17.7 L 21.1 17.8 L 20.9 17.7 L 22.4 17.3 L 22.3 17 L 21 17.3 L 20.9 17 L 22.2 16.5 L 22.2 16.4 L 20.5 16.9 L 20.5 16.7 L 24 15.7 L 24 15.4 L 22.6 15.7 L 22.8 15.6 L 22.7 15.4 L 22.1 15.6 L 22 15.4 L 23.7 15 L 23.7 14.7 L 20.3 15.3 L 20.3 15.2 L 23.9 14.3 L 23.9 14.1 L 21.7 14.6 L 21.7 14.4 L 22.7 14.1 L 22.7 13.9 L 17.1 15.2 L 17.1 15 L 24 13.2 L 24 13 L 21.3 13.6 L 21.3 13.4 L 24 12.7 L 24 12.3 L 22.5 12.6 L 22.5 12.4 L 22.3 12.2 L 22.5 11.8 L 20.3 12.5 L 19.5 12.5 L 21.2 12 L 21.1 11.8 L 16.5 13 L 15.9 12.7 L 22.3 11.2 L 22.3 10.8 L 20.9 11.1 L 20.9 10.8 L 16.8 11.7 L 16.9 11.5 L 20 10.8 L 20 10.5 L 14.2 11.9 L 13.8 12.3 L 12.8 12.8 L 10.8 12.9 L 10 12.3 L 9.7 11.6 L 9.6 11.6 L 9.3 11 L 9.7 11.2 L 9.4 10.8 L 9.8 10.8 L 9.5 10.4 L 9.4 10.2 L 9.7 10.2 L 9.4 9.9 L 9.1 9.4 L 9.6 9.8 L 9.5 9.3 L 9.9 9.3 L 9.5 8.9 L 9.2 8.4 L 9.4 8.4 L 9.2 7.7 L 9.6 7.7 L 9.2 7.3 L 9.5 7.1 L 9.1 6.8 L 9.7 6.7 L 8.8 6.2 L 9.3 6.1 L 9.6 5.8 L 9.3 5.5 L 9.5 5.8 L 10.1 5.4 L 9.8 5.4 L 10.4 5 L 10.1 4.9 L 10.7 4.2 L 10.4 4.3 L 10.8 3.5 L 10.6 3.5 L 11.1 2.9 L 10.9 2.8 L 11 2.3 L 11 1.8 L 11.2 1.5 Z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/MistralIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function MistralIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' strokeWidth={0} stroke='none' fill='currentColor' strokeLinecap='butt' strokeLinejoin='miter' {...props}>
    <path d='m 2,2 v 4 4 V 14 v 4 4 h 4 v -4 -4 h 4 v 4 h 4 v -4 h 4 v 4 4 h 4 v -4 -4 -4 -4 V 2 h -4 v 4 h -4 v 4 h -4 v -4 H 6 V 2 Z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/OllamaIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function OllamaIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 6.3499999 6.35' width='24' height='24' stroke='none' fill='currentColor' {...props}>
    <path
      d='M 0.88527195,6.2762083 C 0.86826445,6.2321409 0.86118155,6.0733062 0.86798175,5.8810146 0.87733375,5.6082404 0.89036855,5.5320638 0.95275115,5.378502 L 1.0263252,5.1975018 0.95587065,5.0534782 C 0.84896675,4.8349544 0.80883525,4.6475472 0.80892005,4.3672221 0.80900485,4.0953122 0.85095095,3.8700413 0.94028255,3.6616277 L 0.99560285,3.5325426 0.93172235,3.4207258 C 0.64491465,2.918759 0.73330325,2.2667869 1.1487613,1.8200687 L 1.309004,1.647755 1.297383,1.2726555 C 1.2840583,0.85056068 1.3211906,0.60932999 1.438523,0.35298528 1.5531926,0.10247873 1.6814095,0 1.8800668,0 2.1832778,0 2.3465985,0.241494 2.4815266,0.88930002 l 0.015021,0.0721281 0.1154349,-0.0510704 c 0.3884708,-0.17183187 0.7804221,-0.17100999 1.1202307,0.00234 0.059914,0.0305797 0.1146131,0.0499083 0.1215567,0.042993 0.0068,-0.0068 0.029816,-0.0951692 0.050845,-0.19612014 C 4.0094218,0.25681958 4.2008995,4.2412012e-6 4.4709061,4.2412012e-6 4.6779689,4.2412012e-6 4.8043747,0.09922643 4.9205521,0.35298953 5.0379141,0.60933438 5.074928,0.85056499 5.061721,1.2726598 L 5.049818,1.6477594 5.2102307,1.8202431 c 0.088227,0.094863 0.1882725,0.2335133 0.222339,0.3081172 0.1933202,0.4233544 0.1914948,0.9131148 -0.00481,1.2736684 l -0.067453,0.1239156 0.056739,0.1323896 c 0.09074,0.2116822 0.1326919,0.4356734 0.132777,0.7088987 8.5e-5,0.2803243 -0.04005,0.4677336 -0.146962,0.6862562 l -0.070456,0.1440236 0.073574,0.1810003 c 0.062406,0.1535631 0.07527,0.2297382 0.084759,0.5025124 C 5.4974277,6.0733164 5.490433,6.232152 5.4733057,6.2762189 5.4460982,6.3463231 5.4360656,6.3499 5.2668386,6.3499 H 5.0889603 L 5.1051143,6.262825 C 5.1716035,5.9055038 5.1455579,5.6596469 5.0145353,5.407871 4.9220286,5.2301556 4.9134695,5.1244831 4.9841529,5.0339712 5.2440727,4.7011638 5.2663774,4.1938628 5.0413457,3.7325654 4.954479,3.5545212 4.9390613,3.5007412 4.9594388,3.4471456 4.9733261,3.4108268 4.9975862,3.3730564 5.0135142,3.3632137 5.0682987,3.3293547 5.1790851,3.0755661 5.2061512,2.9219101 5.258781,2.6230658 5.1413341,2.2672372 4.9158409,2.0424878 4.7315647,1.858815 4.5676235,1.7880445 4.3105123,1.7811775 4.1958426,1.7780602 4.0966475,1.7701243 4.0900439,1.7636062 4.0835267,1.7570889 4.0297051,1.6768542 3.9706413,1.5854543 3.7178352,1.1943108 3.2073854,1.0446643 2.7861262,1.2381912 2.5952746,1.3258783 2.4183699,1.4872525 2.3390987,1.6459681 c -0.033613,0.067282 -0.069295,0.1234538 -0.079328,0.124814 -0.00992,0.00134 -0.1086329,0.00425 -0.2191646,0.0068 C 1.7798356,1.7829721 1.5882273,1.8730481 1.401066,2.077829 1.2134452,2.2831005 1.145568,2.4671973 1.1446039,2.7731665 c -6.094e-4,0.1958963 0.011056,0.2671656 0.061583,0.3798868 0.034291,0.076314 0.086725,0.1607107 0.1165407,0.1875498 0.1103047,0.099333 0.1095116,0.1563888 -0.00537,0.3920629 -0.2250315,0.4612969 -0.202755,0.9685983 0.057193,1.3014054 0.070681,0.090512 0.062099,0.1961854 -0.030382,0.3739002 -0.1310241,0.2517757 -0.157098,0.4976318 -0.090581,0.8549532 L 1.269739,6.35 H 1.0918689 C 0.92264175,6.35 0.91260905,6.346433 0.88540065,6.2763193 Z M 1.9793013,1.4206581 C 2.0667348,1.4201508 2.099129,1.4070545 2.1227942,1.3629276 2.1595817,1.2942286 2.1361151,0.97378779 2.076768,0.73680269 2.035277,0.57080906 1.9226759,0.34830865 1.8801918,0.34830865 c -0.1250141,0 -0.275451,0.64731595 -0.228971,0.98530575 l 0.018421,0.1334298 0.098401,-0.022956 c 0.054133,-0.01247 0.1492183,-0.02324 0.2113423,-0.023523 z M 4.7076336,1.0378328 C 4.6843936,0.708195 4.5646792,0.34830865 4.4783227,0.34830865 c -0.042484,0 -0.1550845,0.22250586 -0.1965765,0.38849383 -0.059261,0.23698793 -0.082814,0.55741482 -0.046027,0.62612492 0.02409,0.045006 0.057306,0.057759 0.15687,0.060254 0.069465,0.00175 0.1625101,0.011053 0.2066946,0.02069 0.07485,0.016154 0.081907,0.011054 0.1026527,-0.076861 0.012186,-0.051893 0.014738,-0.200003 0.00567,-0.3291645 z M 2.7458364,4.1423652 C 2.1572035,3.9516921 2.0138013,3.3215576 2.4664177,2.9146131 2.6713266,2.7303933 2.849569,2.6689612 3.1792257,2.6689612 c 0.3296569,0 0.5079049,0.06143 0.7128082,0.2456519 0.4213754,0.3788477 0.3307903,0.9569416 -0.1870538,1.193776 -0.1033045,0.04725 -0.1838228,0.057764 -0.4855576,0.06343 -0.2479313,0.00465 -0.3968997,-0.00462 -0.4735889,-0.029455 z M 3.5436462,3.908047 C 3.9326245,3.7778141 4.0357025,3.3855835 3.751786,3.1160347 3.5993088,2.9712741 3.4248217,2.9078186 3.1792371,2.9078186 c -0.2455789,0 -0.4200745,0.063456 -0.5725489,0.2082161 C 2.326731,3.3818342 2.4245941,3.7735471 2.8041433,3.906213 2.9135131,3.944446 3.4311107,3.945729 3.5436575,3.908043 Z M 3.0857499,3.657563 c -0.019272,-0.023382 -0.02579,-0.068506 -0.015588,-0.1092095 0.013604,-0.054443 0.00278,-0.080876 -0.05059,-0.1228585 -0.03741,-0.029421 -0.06799,-0.076305 -0.06799,-0.1041905 0,-0.069784 0.091911,-0.1162153 0.1589957,-0.080316 0.035455,0.01896 0.074595,0.019073 0.1238239,4.053e-4 0.051155,-0.019442 0.082701,-0.018506 0.1089163,0.00328 0.05467,0.045382 0.045091,0.1517947 -0.016721,0.1848432 -0.039366,0.021058 -0.053594,0.056098 -0.053594,0.1320411 0,0.069534 -0.013887,0.1086823 -0.042371,0.1196247 -0.067622,0.025961 -0.1094265,0.019158 -0.1448817,-0.02358 z M 1.7776488,3.1337129 c -0.096106,-0.089535 -0.070995,-0.303317 0.046223,-0.3932982 0.076012,-0.058351 0.2275255,-0.041369 0.2977359,0.033372 0.2009978,0.213958 -0.1294356,0.5597613 -0.3439466,0.3599267 z m 2.47297,-0.026102 C 4.0983967,2.9487227 4.186992,2.7050706 4.396294,2.7069327 c 0.1545177,0.00138 0.2431699,0.1026057 0.2431699,0.2776659 0,0.2030693 -0.2395423,0.2788505 -0.3888451,0.1230123 z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/OpenAIIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function OpenAIIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' stroke='currentColor' strokeWidth={1.5} fill='none' strokeLinecap='round' strokeLinejoin='round' {...props}>
    {/*<path stroke='none' d='M0 0h24v24H0z' fill='none'></path>*/}
    <path d='M11.217 19.384a3.501 3.501 0 0 0 6.783 -1.217v-5.167l-6 -3.35' fill='none' />
    <path d='M5.214 15.014a3.501 3.501 0 0 0 4.446 5.266l4.34 -2.534v-6.946' fill='none' />
    <path d='M6 7.63c-1.391 -.236 -2.787 .395 -3.534 1.689a3.474 3.474 0 0 0 1.271 4.745l4.263 2.514l6 -3.348' fill='none' />
    <path d='M12.783 4.616a3.501 3.501 0 0 0 -6.783 1.217v5.067l6 3.45' fill='none' />
    <path d='M18.786 8.986a3.501 3.501 0 0 0 -4.446 -5.266l-4.34 2.534v6.946' fill='none' />
    <path d='M18 16.302c1.391 .236 2.787 -.395 3.534 -1.689a3.474 3.474 0 0 0 -1.271 -4.745l-4.308 -2.514l-5.955 3.42' fill='none' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/OpenPipeIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function OpenPipeIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' strokeWidth={0} stroke='none' fill='currentColor' strokeLinecap='butt' strokeLinejoin='miter' {...props}>
    <path
      d='m 6.181795,6.5454213 h 11.63641 V 21.276364 A 0.7236348,0.7236348 0 0 1 17.09457,21.999999 H 6.90543 A 0.7236348,0.7236348 0 0 1 6.181795,21.276364 Z'
      stroke='currentColor' strokeWidth={1}
    />
    <path
      d='M 4.763652,2.7236346 A 0.7236348,0.7236348 0 0 1 5.487287,1.9999998 h 13.025426 a 0.7236348,0.7236348 0 0 1 0.723635,0.7236348 V 6.185413 A 0.7236348,0.7236348 0 0 1 18.512713,6.9090478 H 5.487287 A 0.7236348,0.7236348 0 0 1 4.763652,6.185413 Z'
      stroke='currentColor' strokeWidth={1}
    />
    {/* This is the orange part - comment? */}
    <path
      d='M 6.5817845,6.9091382 H 17.418216 V 21.238193 A 0.3618174,0.3618174 0 0 1 17.056398,21.60001 H 6.9436019 A 0.3618174,0.3618174 0 0 1 6.5817845,21.238193 Z M 5.1636412,2.7254436 A 0.3618174,0.3618174 0 0 1 5.5254586,2.3636262 H 18.510904 a 0.3618174,0.3618174 0 0 1 0.361818,0.3618174 V 6.1473317 A 0.3618174,0.3618174 0 0 1 18.510904,6.5091491 H 5.5254586 A 0.3618174,0.3618174 0 0 1 5.1636412,6.1473317 Z'
      fill='#ff5733' />
    <path
      d='M 8.6909086,7.1635863 H 10.436406 V 21.509646 H 8.6908181 V 7.1635863 Z'
      fill='#ffffff' />
    <path
      d='m 15.672718,6.9091382 h 1.745498 V 21.238193 a 0.3618174,0.3618174 0 0 1 -0.361818,0.361817 h -1.38368 z'
      fill='#ffffff' fillOpacity={0.25} />
    <path
      d='M 8.2545568,7.1635863 H 8.6909086 V 21.509646 H 8.2545568 Z'
      fill='#ffffff' fillOpacity={0.5} />
    <path
      d='M 7.818205,2.3636262 H 9.5999748 V 6.434072 H 7.8182954 V 2.3636262 Z'
      fill='#ffffff' />
    <path
      d='m 17.090861,2.3636262 h 1.420043 a 0.3618174,0.3618174 0 0 1 0.361818,0.3618174 v 3.4218881 a 0.3618174,0.3618174 0 0 1 -0.361818,0.3618174 h -1.420043 z'
      fill='#ffffff' fillOpacity={0.25} />
    <path
      d='M 7.3818532,2.3636262 H 7.818205 V 6.434072 H 7.3818532 Z'
      fill='#ffffff' fillOpacity={0.25} />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/OpenRouterIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function OpenRouterIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 512 512' width='24' height='24' strokeWidth={0} stroke='currentColor' fill='none' strokeLinecap='round' strokeLinejoin='round' {...props}>
    <path d='M3 248.945C18 248.945 76 236 106 219C136 202 136 202 198 158C276.497 102.293 332 120.945 423 120.945' strokeWidth={70} />
    <path d='M511 121.5L357.25 210.268L357.25 32.7324L511 121.5Z' />
    <path d='M0 249C15 249 73 261.945 103 278.945C133 295.945 133 295.945 195 339.945C273.497 395.652 329 377 420 377' strokeWidth={70} />
    <path d='M508 376.445L354.25 287.678L354.25 465.213L508 376.445Z' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/PerplexityIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function PerplexityIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 24 24' width='24' height='24' fill='none' stroke='currentColor' strokeWidth={1.5} strokeLinecap='round' strokeLinejoin='round' {...props}>
    <path d='M 11.977248,8.1395615 5.6952727,2.280012 v 5.8595495 z' fill='none' />
    <path d='M 12.103816,8.1395615 18.385789,2.280012 v 5.8595495 z' fill='none' />
    <path d='M 11.984325,1.333998 V 22.797381' fill='none' />
    <path d='M 18.259392,13.921732 11.977418,8.1453013 v 8.0095097 l 6.281974,5.601423 z' fill='none' />
    <path d='M 5.70235,13.921732 11.984325,8.1453013 V 16.154811 L 5.70235,21.756234 Z' fill='none' />
    <path d='M 3.1231247,8.1395615 V 16.515528 H 5.7008663 V 13.915992 L 11.984301,8.1395615 Z' fill='none' />
    <path d='m 11.977418,8.2166075 6.281974,5.7764065 v 2.599535 h 2.617484 V 8.2166075 Z' fill='none' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/TogetherIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function TogetherIcon(props: SvgIconProps) {
  return <SvgIcon viewBox='0 0 976 180' width='24' height='24' strokeWidth={0} stroke='none' fill='currentColor' strokeLinecap='butt' strokeLinejoin='miter' {...props}>
    <path d='M973,3 C971,1 968,0 965,0 C962,0 960,1 958,3 C956,5 955,7 955,10 C955,13 956,16 958,18 C960,20 962,21 965,21 C968,21 971,20 973,18 C975,16 975,13 975,10 C975,7 975,5 973,3' />
    <polygon points='957 139 973 139 973 39 957 39' />
    <path d='M571,48 C564,41 554,37 542,37 C534,37 527,39 522,42 C516,46 512,50 509,55 L509,1 L493,1 L493,139 L509,139 L509,89 C509,77 511,68 517,62 C523,56 530,52 539,52 C548,52 554,55 559,60 C564,66 566,74 566,84 L566,139 L582,139 L582,83 C582,67 579,56 571,48' />
    <path d='M629,59 C635,54 641,52 649,52 C657,52 664,54 670,59 C675,63 679,70 679,78 L619,78 C620,70 623,64 629,59 Z M696,92 C696,89 696,86 696,85 C696,75 694,67 690,60 C686,53 680,47 673,43 C666,39 658,37 649,37 C640,37 632,40 626,44 C619,48 611,54 607,62 C603,69 601,78 601,89 C601,99 603,108 607,116 C611,123 617,129 625,134 C633,138 641,140 651,140 C662,140 672,137 680,130 C688,124 693,115 695,105 L679,105 C677,111 673,116 668,120 C663,124 657,125 650,125 C641,125 634,122 628,117 C622,111 619,103 619,93 L619,92 L696,92 Z' />
    <path d='M767,39 L767,54 L759,54 C750,54 743,57 739,64 C735,70 733,78 733,88 L733,139 L717,139 L717,39 L731,39 L733,54 C736,49 739,45 744,43 C748,40 754,39 763,39 L767,39' />
    <path d='M431,53 L413,53 L413,39 L431,39 L431,11 L447,11 L447,39 L472,39 L472,53 L447,53 L447,112 C447,116 448,119 449,121 C451,123 454,124 458,124 L475,124 L475,139 L457,139 C448,139 441,137 437,133 C433,129 431,123 431,112 L431,53' />
    <path d='M337,59 C343,54 349,52 357,52 C365,52 372,54 378,59 C383,63 386,70 387,78 L327,78 C328,70 331,64 337,59 Z M404,92 C404,89 404,86 404,85 C404,75 402,67 398,60 C394,53 388,47 381,43 C374,39 366,37 357,37 C348,37 340,40 333,44 C326,48 319,54 315,62 C311,69 309,78 309,89 C309,99 311,108 315,116 C319,123 325,129 333,134 C341,138 349,140 359,140 C370,140 380,137 388,130 C396,124 401,115 403,105 L387,105 C385,111 382,116 377,120 C372,124 366,125 359,125 C350,125 343,122 337,117 C332,111 329,103 329,93 L329,92 L404,92 Z' />
    <path d='M269,108 C266,113 262,118 257,121 C252,124 246,125 240,125 C230,125 222,122 216,115 C210,108 207,99 207,89 C207,78 210,69 216,62 C222,55 230,52 240,52 C246,52 252,54 257,57 C262,60 266,64 269,70 C272,75 273,82 273,89 C273,96 272,102 269,108 Z M275,39 L273,56 C270,50 265,45 259,42 C253,39 246,38 238,38 C229,38 221,40 214,44 C207,48 201,54 197,62 C193,69 191,78 191,89 C191,99 193,108 197,116 C201,123 207,129 214,134 C222,138 230,140 240,140 C254,140 265,134 273,122 L273,133 C273,154 262,165 240,165 C232,165 225,164 220,160 C215,157 211,152 210,146 L193,146 C195,157 199,165 207,171 C216,177 226,179 239,179 C272,179 289,164 289,134 L289,39 L275,39' />
    <g transform='translate(0, 11)'>
      <path d='M153,97 C150,103 146,107 141,110 C136,113 130,115 124,115 C118,115 112,113 107,110 C102,107 98,103 95,97 C92,91 91,85 91,78 C91,71 92,65 95,59 C98,53 102,49 107,46 C112,43 118,41 124,41 C130,41 136,43 141,46 C146,49 150,53 153,59 C156,65 157,71 157,78 C157,85 156,91 153,97 Z M167,51 C163,43 157,37 150,33 C142,29 134,27 124,27 C115,27 106,29 99,33 C91,37 85,43 81,51 C77,59 75,68 75,78 C75,88 77,97 81,105 C85,112 91,118 99,123 C106,127 115,129 124,129 C134,129 142,127 150,123 C157,118 163,112 167,105 C171,97 173,88 173,78 C173,68 171,59 167,51' />
      <path d='M18,43 L-0,43 L-0,28 L18,28 L18,0 L34,0 L34,28 L59,28 L59,43 L34,43 L34,102 C34,106 35,109 36,111 C38,113 41,114 45,114 L62,114 L62,129 L44,129 C35,129 28,127 24,123 C20,119 18,113 18,102 L18,43' />
    </g>
    <path d='M911 98 C911 106 908 113 903 118 C897 123 889 126 880 126 C873 126 868 125 864 122 C860 119 858 115 858 110 C858 98 865 93 880 93 L911 93 L911 98 Z M934 124 C929 124 927 121 927 117 L927 74 C927 62 924 53 917 47 C910 41 900 37 887 37 C875 37 865 40 858 46 C850 51 846 59 845 69 L861 69 C862 64 865 59 869 56 C874 53 879 52 886 52 C894 52 900 54 905 57 C909 61 911 66 911 73 L911 79 L882 79 C869 79 859 82 852 87 C845 93 842 100 842 111 C842 120 845 127 852 132 C859 137 868 140 878 140 C893 140 904 135 912 123 C912 128 914 132 916 135 C919 137 924 139 930 139 L939 139 L939 124 L934 124 Z' />
    <path d='M796 138 C804 138 811 131 811 123 C811 114 804 108 796 108 C787 108 780 114 780 123 C780 131 787 138 796 138' />
  </SvgIcon>;
}


================================================
FILE: src/common/components/icons/vendors/XAIIcon.tsx
================================================
import * as React from 'react';

import { SvgIcon, SvgIconProps } from '@mui/joy';

export function XAIIcon(props: SvgIconProps) {
  return (
    <SvgIcon viewBox='0 0 24 24' width={24} height={24} fill='currentColor' {...props}>
      <path d='m3.005 8.858 8.783 12.544h3.904L6.908 8.858zm3.9 6.967L3 21.402h3.907l1.951-2.788zM16.585 2l-6.75 9.64 1.953 2.79L20.492 2zm.707 5.965v13.437h3.2V3.395z' />
    </SvgIcon>
  );
}


================================================
FILE: src/common/components/modals/ConfirmationModal.tsx
================================================
import * as React from 'react';

import { Box, Button, Divider, Typography } from '@mui/joy';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { GoodModal } from '~/common/components/modals/GoodModal';


/**
 * A confirmation dialog (Joy Modal)
 * Pass the question and the positive answer, and get called when it's time to close the dialog, or when the positive action is taken
 */
export function ConfirmationModal(props: {
  open?: boolean, onClose?: () => void, onPositive: () => void,
  title?: React.ReactNode,
  noTitleBar?: boolean,
  lowStakes?: boolean,
  confirmationText: React.ReactNode,
  positiveActionText: React.ReactNode,
  negativeActionText?: React.ReactNode,
  negativeActionStartDecorator?: React.ReactNode,
}) {
  return (
    <GoodModal
      open={props.open === undefined ? true : props.open}
      title={props.noTitleBar ? undefined : (props.title || 'Confirmation')}
      titleStartDecorator={props.noTitleBar ? undefined : <WarningRoundedIcon sx={{ color: 'danger.solidBg' }} />}
      noTitleBar={props.noTitleBar}
      onClose={props.onClose}
      hideBottomClose
    >
      {!props.noTitleBar && <Divider />}

      <Typography component='div' level='body-md'>
        {props.confirmationText}
      </Typography>

      <Box sx={{ display: 'flex', gap: 1, justifyContent: 'flex-end', mt: 2 }}>
        {!!props.onClose && (
          <Button autoFocus variant='plain' color='neutral' onClick={props.onClose} startDecorator={props.negativeActionStartDecorator}>
            {props.negativeActionText || 'Cancel'}
          </Button>
        )}
        <Button
          variant={props.lowStakes ? 'soft' : 'solid'}
          color={props.lowStakes ? undefined : 'danger'}
          onClick={props.onPositive}
          sx={{ lineHeight: '1.5em' }}
        >
          {props.positiveActionText}
        </Button>
      </Box>
    </GoodModal>
  );
}


================================================
FILE: src/common/components/modals/GoodModal.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ColorPaletteProp, Divider, Modal, ModalClose, ModalDialog, ModalOverflow, Typography } from '@mui/joy';


export const noBackdropSlotProps = {
  backdrop: {
    sx: {
      backdropFilter: 'none',
    },
  },
};


/**
 * Base for our Modal components (Preferences, Models Setup, etc.)
 */
export function GoodModal(props: {
  title?: React.ReactNode,
  titleStartDecorator?: React.JSX.Element,
  strongerTitle?: boolean,
  noTitleBar?: boolean,
  dividers?: boolean,
  themedColor?: ColorPaletteProp,
  closeText?: string, // defaults to 'Close'
  animateEnter?: boolean,
  unfilterBackdrop?: boolean, // this should be left to the theme, but we're gonna use it for the models
  /** if true, if true, forces contents to stay within the screen viewport, inner scrollable (not outer) */
  autoOverflow?: boolean,
  open: boolean,
  onClose?: ((event: React.BaseSyntheticEvent, reason: 'backdropClick' | 'escapeKeyDown' | 'closeClick') => void) | undefined,
  disableBackdropClose?: boolean, // if true, the backdrop will not close the modal on click
  disableEscapeKeyClose?: boolean, // if true, the escape key will not close the modal
  hideBottomClose?: boolean,
  darkBottomClose?: boolean,
  startButton?: React.JSX.Element,
  /** sx of the ModalDialog (Modal > ModalOverflow > ModalDialog), not the Modal */
  sx?: SxProps,
  children: React.ReactNode,
}) {

  const { onClose } = props;
  const showBottomClose = !!onClose && props.hideBottomClose !== true;

  const dialogSx: SxProps = React.useMemo(() => ({
    borderRadius: 'xl',
    boxShadow: props.themedColor ? 'none' : undefined,
    minWidth: { xs: 360, sm: 500, md: 600, lg: 700 },
    maxWidth: 700,
    display: 'grid',
    gap: 'var(--Card-padding)',
    // apply autoOverflow if set, otherwise leave the default behavior
    ...(props.autoOverflow ? {
      // maxHeight: '80lvh',
      overflow: 'auto',
    } : {}),
    ...props.sx,
  }), [props.autoOverflow, props.sx, props.themedColor]);

  const backdropSx = React.useMemo(() => {
    return props.themedColor ? {
      backdrop: {
        sx: {
          backgroundColor: `rgba(var(--joy-palette-${props.themedColor}-darkChannel) / 0.3)`,
          backdropFilter: props.unfilterBackdrop ? 'none' : 'blur(32px)',
        },
      },
    } : props.unfilterBackdrop ? noBackdropSlotProps : undefined;
  }, [props.themedColor, props.unfilterBackdrop]);


  // Fix the issue where the backdrop will fire on clicks that initiated on the dialog
  const dragFromDialogRef = React.useRef(false);

  const handleMouseDownWithinDialog = React.useCallback(() => {
    dragFromDialogRef.current = true;
  }, []);

  const handleOnClose = React.useCallback((event: React.BaseSyntheticEvent, reason: 'backdropClick' | 'escapeKeyDown' | 'closeClick') => {
    // ignore clicks on the backdrop that started from within the dialog
    const ignoreDragOnBackdrop = reason === 'backdropClick' && (dragFromDialogRef.current || !!props.disableBackdropClose);
    dragFromDialogRef.current = false;
    if (ignoreDragOnBackdrop) return;

    // normal propagation
    onClose?.(event, reason);
  }, [onClose, props.disableBackdropClose]);

  return (
    <Modal
      open={props.open}
      onClose={!onClose ? undefined : handleOnClose}
      disableEscapeKeyDown={props.disableEscapeKeyClose}
      slotProps={backdropSx}
    >
      <ModalOverflow sx={{ p: 1 }}>
        <ModalDialog
          color={props.themedColor}
          variant={props.themedColor ? 'soft' : 'plain' /* switched from bordered (undefined) to borderless (plain) */}
          invertedColors={props.themedColor ? true : undefined}
          className={props.animateEnter ? 'agi-animate-enter' : ''}
          onMouseDown={handleMouseDownWithinDialog /* to fix the Backdrop drag-closes issue */}
          sx={dialogSx}
        >

          {!props.noTitleBar && <Box sx={{ display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
            <Typography component='h1' level={props.strongerTitle !== true ? 'title-md' : 'title-lg'} startDecorator={props.titleStartDecorator}>
              {props.title || ''}
            </Typography>
            {!!props.onClose && <ModalClose aria-label='Close Dialog' sx={{ position: 'static', my: -1, mr: -0.5 }} />}
          </Box>}

          {props.dividers === true && <Divider />}

          {/*<Box sx={{ maxHeight: '80lvh', overflowY: 'auto', display: 'grid', gap: 'var(--Card-padding)' }}>*/}
          {props.children}
          {/*</Box>*/}

          {props.dividers === true && (!!props.startButton || showBottomClose) && <Divider />}

          {(!!props.startButton || showBottomClose) && <Box sx={{
            mt: 'auto',
            ...props.darkBottomClose && {
              m: 'calc(-1* var(--Card-padding))',
              p: 'var(--Card-padding)',
              backgroundColor: 'background.level1',
            },
            display: 'flex',
            flexWrap: 'wrap',
            gap: 1,
            justifyContent: 'space-between',
          }}>
            {props.startButton}
            {showBottomClose && <Button aria-label='Close Dialog' variant='solid' color='neutral' onClick={(event) => props.onClose?.(event, 'closeClick')} sx={{ ml: 'auto', minWidth: 100 }}>
              {props.closeText || 'Close'}
            </Button>}
          </Box>}

        </ModalDialog>
      </ModalOverflow>
    </Modal>
  );
}



================================================
FILE: src/common/components/modals/SherpaModal.tsx
================================================
import * as React from 'react';

import { ColorPaletteProp, Modal, ModalClose, ModalOverflow } from '@mui/joy';

import { noBackdropSlotProps } from './GoodModal';


/**
 * A simple modal that centers content and uses the 'sherpa' theme.
 */
export function SherpaModal(props: {
  themedColor?: ColorPaletteProp,
  unfilterBackdrop?: boolean,
  onClose: () => void,
  children: React.ReactNode,
}) {

  const backdropSx = React.useMemo(() => props.themedColor ? {
    backdrop: {
      sx: {
        backgroundColor: `rgba(var(--joy-palette-${props.themedColor}-darkChannel) / 0.3)`,
        backdropFilter: props.unfilterBackdrop ? 'none' : 'blur(32px)',
      },
    },
  } : props.unfilterBackdrop ? noBackdropSlotProps : undefined, [props.themedColor, props.unfilterBackdrop]);

  return (
    <Modal open onClose={props.onClose} slotProps={backdropSx}>
      <ModalOverflow>
        <ModalClose />
        {props.children}
      </ModalOverflow>
    </Modal>
  );
}



================================================
FILE: src/common/components/panes/GoodPanelResizeHandler.tsx
================================================
import { Box, styled } from '@mui/joy';


export const PanelResizeInset = styled(Box)({
  width: '100%',
  height: '100%',

  // 4px
  minWidth: '0.25rem',
  minHeight: '0.25rem',

  // 0px
  // minWidth: 0,
  // minHeight: 0,

  // backgroundColor: 'var(--joy-palette-divider)',
  transition: 'background-color 0.1s',
  '&:hover': {
    backgroundColor: 'var(--joy-palette-primary-solidBg)',
  },
});



================================================
FILE: src/common/components/shortcuts/globalShortcutsHandler.ts
================================================
import { useGlobalShortcutsStore } from './store-global-shortcuts';


export function ensureGlobalShortcutHandler() {
  const hasShortcuts = useGlobalShortcutsStore.getState().hasShortcuts;
  if (hasShortcuts && !isHandlerInstalled) {
    _installGlobalShortcutHandler();
  } else if (!hasShortcuts && isHandlerInstalled) {
    _uninstallGlobalShortcutHandler();
  }
}


function _handleGlobalShortcutKeyDown(event: KeyboardEvent) {

  // Quicker-out: if the key is null, stop here
  if (!event.key)
    return;

  // Quick-out: either the key is escape/left/right, or we have a modifier key pressed -- otherwise we exit
  const lcEventKey = event.key.toLowerCase();
  if (lcEventKey !== 'escape' && lcEventKey !== 'arrowleft' && lcEventKey !== 'arrowright' &&
    !event.ctrlKey && !event.shiftKey && !event.altKey && lcEventKey !== 'enter')
    return;


  const shortcuts = useGlobalShortcutsStore.getState().getAllShortcuts();

  for (const shortcut of shortcuts) {

    // Check if the key matches (case-insensitive)
    if (lcEventKey !== shortcut.key.toLowerCase())
      continue;

    // Check modifier keys
    if ((shortcut.ctrl && !event.ctrlKey) || (!shortcut.ctrl && event.ctrlKey) ||
      (shortcut.shift && !event.shiftKey) || (!shortcut.shift && event.shiftKey))
      continue;

    // Execute the action (and prevent the default browser action)
    event.preventDefault();
    event.stopPropagation();

    if (shortcut.action === '_specialPrintShortcuts')
      console.log('Global Shortcuts:', useGlobalShortcutsStore.getState().shortcutGroups);
    else
      shortcut.action();

    // Stop searching for more shortcuts
    break;
  }
}

let isHandlerInstalled = false;

function _installGlobalShortcutHandler() {
  if (!isHandlerInstalled) {
    window.addEventListener('keydown', _handleGlobalShortcutKeyDown);
    isHandlerInstalled = true;
  }
}

function _uninstallGlobalShortcutHandler() {
  if (isHandlerInstalled) {
    window.removeEventListener('keydown', _handleGlobalShortcutKeyDown);
    isHandlerInstalled = false;
  }
}



================================================
FILE: src/common/components/shortcuts/store-global-shortcuts.ts
================================================
import { create } from 'zustand';

import type { ShortcutObject } from './useGlobalShortcuts';


type ShortcutGroupId = string;

interface ShortcutsStore {
  // state
  shortcutGroups: Record<ShortcutGroupId, ShortcutObject[]>;
  hasShortcuts: boolean;
  // actions
  setGroupShortcuts: (groupId: ShortcutGroupId, shortcuts: ShortcutObject[]) => void;
  removeGroup: (groupId: ShortcutGroupId) => void;
  getAllShortcuts: () => ShortcutObject[];
}


export const useGlobalShortcutsStore = create<ShortcutsStore>((set, get) => ({

  shortcutGroups: {},
  hasShortcuts: false,

  setGroupShortcuts: (groupId: ShortcutGroupId, shortcuts: ShortcutObject[]) =>
    set((state) => ({
      shortcutGroups: { ...state.shortcutGroups, [groupId]: shortcuts },
      hasShortcuts: true,
    })),

  removeGroup: (groupId) =>
    set((state) => {
      const { [groupId]: _, ...rest } = state.shortcutGroups;
      return {
        shortcutGroups: rest,
        hasShortcuts: Object.keys(rest).length > 0,
      };
    }),

  /**
   * Returns all shortcuts, priritized by level (descending).
   */
  getAllShortcuts: () => Object.values(get().shortcutGroups)
    .flat()
    .sort((a, b) => (b.level ?? 0) - (a.level ?? 0)),

}));



================================================
FILE: src/common/components/shortcuts/useGlobalShortcuts.ts
================================================
import * as React from 'react';

import { SvgIcon } from '@mui/joy';

import { useGlobalShortcutsStore } from './store-global-shortcuts';

import { ensureGlobalShortcutHandler } from './globalShortcutsHandler';


export const ShortcutKey = {
  Backspace: 'Backspace',
  Enter: 'Enter',
  Esc: 'Escape',
  Left: 'ArrowLeft',
  Right: 'ArrowRight',
  Up: 'ArrowUp',
  Down: 'ArrowDown',
  PageUp: 'PageUp',
  PageDown: 'PageDown',
};

export interface ShortcutObject {
  key: string;
  ctrl?: boolean;
  shift?: boolean;
  // altForNonMac?: boolean;
  disabled?: boolean;
  action: (() => void) | '_specialPrintShortcuts';
  description?: string;
  endDecoratorIcon?: typeof SvgIcon;
  level?: number; // if set, it will exclusively show icons at that level of priority and hide the others
}


/**
 * Hook to register global shortcuts for a specific group.
 *
 * Important notes below:
 * - [MAC only] the Alt key is ignored even if defined in the shortcut
 * - [MAC only] are not using the command key at the moment, as it interfered with browser shortcuts
 * - stabilize the shortcuts definition (e.g. React.useMemo()) to avoid re-registering the shortcuts at every render
 *
 */
export const useGlobalShortcuts = (groupId: string, shortcuts: ShortcutObject[]) => {
  React.useEffect(() => {
    const { setGroupShortcuts, removeGroup } = useGlobalShortcutsStore.getState();

    setGroupShortcuts(groupId, shortcuts);
    ensureGlobalShortcutHandler();

    return () => {
      removeGroup(groupId);
      ensureGlobalShortcutHandler();
    };
  }, [groupId, shortcuts]);
};



================================================
FILE: src/common/components/snackbar/SnackbarInsert.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { IconButton, Snackbar, SnackbarTypeMap } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';

import { SNACKBAR_ANIMATION_DURATION, SnackbarMessage, useSnackbarsStore } from './useSnackbarsStore';


const defaultTypeConfig: {
  [key in SnackbarMessage['type']]: (Partial<SnackbarTypeMap['props']> & {
    clickAway: boolean,
    closeButton: boolean;
  })
} = {
  'success': {
    color: 'success',
    variant: 'soft',
    autoHideDuration: 5000,
    clickAway: false,
    closeButton: true,
  },
  'info': {
    color: 'primary',
    variant: 'soft',
    autoHideDuration: 2000,
    clickAway: false,
    closeButton: true,
  },
  'issue': {
    color: 'warning',
    variant: 'solid',
    autoHideDuration: null, // Will not auto-hide
    clickAway: false,
    closeButton: true,
  },
  'center-title': {
    color: 'neutral',
    variant: 'plain',
    autoHideDuration: 2000,
    clickAway: false,
    closeButton: false,
    anchorOrigin: { vertical: 'top', horizontal: 'center' },
  },
  'precondition-fail': {
    color: 'warning',
    variant: 'outlined',
    autoHideDuration: 2000,
    clickAway: false,
    closeButton: true,
  },
};

const typeDefaultSx: SxProps = {
  border: '1px solid',
};

const typeTitleSx: SxProps = {
  '--Snackbar-inset': '64px',
  borderRadius: 'md',
  boxShadow: 'md',
  backgroundColor: 'background.popup',
  // bgcolor: `rgba(${theme.vars.palette.background.popup} / 0.5)`,
  // backdropFilter: 'blur(6px)',
  // '--Snackbar-padding': config.closeButton ? '0.5rem' : '1rem',
};


/**
 * Simple cycler through the snackbars.
 */
export function SnackbarInsert() {

  // external state
  const { activeMessage, activeSnackbarOpen, animateCloseSnackbar } = useSnackbarsStore();

  // create a
  const config = React.useMemo(() => activeMessage ? ({
    ...defaultTypeConfig[activeMessage.type],
    ...activeMessage.overrides,
    ...(activeMessage.closeButton === undefined ? {} : { closeButton: activeMessage.closeButton }),
  }) : null, [activeMessage]);

  if (!activeMessage || !config)
    return null;

  return (
    <Snackbar
      key={activeMessage.key}
      open={activeSnackbarOpen}
      color={config.color}
      variant={config.variant}
      autoHideDuration={config.autoHideDuration ?? null}
      animationDuration={SNACKBAR_ANIMATION_DURATION}
      invertedColors={config.closeButton}
      anchorOrigin={config.anchorOrigin || { vertical: 'bottom', horizontal: 'right' }}
      onClose={(_event, reason) => {
        if (reason === 'timeout' || ((reason === 'clickaway' || reason === 'escapeKeyDown') && config.clickAway)) {
          animateCloseSnackbar();
        }
      }}
      startDecorator={config.startDecorator}
      endDecorator={!config.closeButton ? undefined : (
        <IconButton
          onClick={animateCloseSnackbar}
          size='sm'
          sx={{ my: '-0.4rem' }}
        >
          <CloseRoundedIcon />
        </IconButton>
      )}
      sx={activeMessage.type === 'center-title' ? typeTitleSx : typeDefaultSx}
    >
      {activeMessage.message}
    </Snackbar>
  );
}



================================================
FILE: src/common/components/snackbar/useSnackbarsStore.ts
================================================
import { create } from 'zustand';

import type { SnackbarTypeMap } from '@mui/joy';

import { agiUuid } from '~/common/util/idUtils';


export const SNACKBAR_ANIMATION_DURATION = 200;

export interface SnackbarMessage {
  key: string;
  message: string;
  type: 'success' | 'issue' | 'center-title' | 'info' | 'precondition-fail';
  closeButton?: boolean,
  overrides?: Partial<SnackbarTypeMap['props']>;
}

interface SnackbarStore {

  // state
  activeMessage: SnackbarMessage | null;
  activeSnackbarOpen: boolean;
  snackbarQueue: SnackbarMessage[];

  // actions
  addSnackbar: (snackbar: SnackbarMessage) => string;
  animateCloseSnackbar: () => void;
  closeSnackbar: () => void;
  removeSnackbar: (key: string) => void;

}


export const useSnackbarsStore = create<SnackbarStore>()(
  (_set, _get) => ({

    activeMessage: null,
    activeSnackbarOpen: true,
    snackbarQueue: [],

    addSnackbar: (snackbar: SnackbarMessage): string => {
      const { activeMessage } = _get();
      let { key, ...rest } = snackbar;

      // unique key
      key += '-' + agiUuid('snackbar-item');

      // append the snackbar
      const newSnackbar = { key, ...rest };
      _set(activeMessage === null
        ? {
          activeMessage: newSnackbar,
          activeSnackbarOpen: true,
        }
        : {
          snackbarQueue: [..._get().snackbarQueue, newSnackbar],
        });

      return key;
    },

    closeSnackbar: () =>
      _set((state) => {
        let nextActiveSnackbar = null;
        let nextQueue = [...state.snackbarQueue];
        if (nextQueue.length > 0)
          nextActiveSnackbar = nextQueue.shift(); // Remove the first snackbar from the queue
        return {
          activeMessage: nextActiveSnackbar,
          activeSnackbarOpen: nextActiveSnackbar !== null,
          snackbarQueue: nextQueue,
        };
      }),

    animateCloseSnackbar: () => {
      _set({
        activeSnackbarOpen: false,
      });
      setTimeout(() => {
        _get().closeSnackbar();
      }, SNACKBAR_ANIMATION_DURATION); // Delay needs to match match your CSS animation duration
    },

    // mostly added for useEffect's unmounts
    removeSnackbar: (key: string) =>
      _set((state) => {
        let nextActiveSnackbar = state.activeMessage;
        let nextQueue = [...state.snackbarQueue];
        if (nextActiveSnackbar?.key === key) {
          if (nextQueue.length > 0)
            nextActiveSnackbar = nextQueue.shift() as SnackbarMessage; // Remove the first snackbar from the queue
          else
            nextActiveSnackbar = null;
          return {
            activeMessage: nextActiveSnackbar,
            activeSnackbarOpen: nextActiveSnackbar !== null,
            snackbarQueue: nextQueue,
          };
        }
        return {
          snackbarQueue: nextQueue.filter(snackbar => snackbar.key !== key),
        };
      }),

  }),
);

/**
 * This is here to quickly trace back to "unexpected" branches in the code
 */
export function addSnackUnexpected(userMessage: string) {
  if (process.env.NODE_ENV === 'development')
    console.warn(`[DEV] Unexpected branch reached: ${userMessage}`);
  return addSnackbar({ key: 'unexpected', message: userMessage, type: 'precondition-fail' });
}

export function addSnackbar(snackbar: SnackbarMessage) {
  return useSnackbarsStore.getState().addSnackbar(snackbar);
}

export function removeSnackbar(key: string) {
  return useSnackbarsStore.getState().removeSnackbar(key);
}


================================================
FILE: src/common/components/speechrecognition/AudioRecorderEngine.ts
================================================
import { createSpeechRecognitionResults, IRecognitionEngine, SpeechDoneReason, SpeechRecognitionState, SpeechResult } from './useSpeechRecognition';


/**
 * Engine which uses the MediaRecorder API -> online Transcription for speech recognition.
 */
export class AudioRecorderEngine implements IRecognitionEngine {
  public readonly engineType = 'audioRecorder';

  // save parameters
  private onResultCallback: (result: SpeechResult) => void;
  private readonly setState: (state: Partial<SpeechRecognitionState>) => void;

  // state
  private _mediaRecorder: MediaRecorder | null = null;
  private _mediaStream: MediaStream | null = null;
  private audioChunks: BlobPart[] = [];
  private results: SpeechResult = createSpeechRecognitionResults();

  constructor(
    _preferredLanguageIgnored: string,
    _softStopTimeoutIgnored: number,
    onResultCallback: (result: SpeechResult) => void,
    setState: (state: Partial<SpeechRecognitionState>) => void,
  ) {
    // Save parameters
    this.setState = setState;
    this.onResultCallback = onResultCallback;

    // all ready
    setState({ isAvailable: true });
  }

  async start() {
    if (!navigator?.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      this.setState({ errorMessage: 'Media devices API not supported.' });
      return;
    }

    // Initialize results
    this.results = createSpeechRecognitionResults();
    this.onResultCallback(this.results);

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 48000,
          sampleSize: 16,
          channelCount: 1,
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        },
      });
      this._mediaStream = stream;
      this._mediaRecorder = new MediaRecorder(stream);

      this._mediaRecorder.onstart = () => {
        this.setState({ isActive: true, hasAudio: true });
        this.audioChunks = [];
      };

      this._mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0)
          this.audioChunks.push(event.data);
      };

      this._mediaRecorder.onstop = async () => {
        this.setState({ isActive: false, hasAudio: false });

        // Stop all tracks to release microphone
        if (this._mediaStream) {
          this._mediaStream.getTracks().forEach(track => track.stop());
          this._mediaStream = null;
        }

        // Transcribe audio
        const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
        await this._handleAudioBlob(audioBlob);

        // Clean up MediaRecorder
        if (this._mediaRecorder) {
          this._mediaRecorder.onstart = null;
          this._mediaRecorder.ondataavailable = null;
          this._mediaRecorder.onstop = null;
          this._mediaRecorder.onerror = null;
          this._mediaRecorder = null;
        }
      };

      this._mediaRecorder.onerror = (event) => {
        console.error('AudioRecorderEngine error:', event);
        this._handleError('Recording failed.');
      };

      this._mediaRecorder.start();
    } catch (error: any) {
      console.error('MediaDevices.getUserMedia error:', error);
      this._handleError('Microphone access denied or not available.');
    }
  }

  stop(reason: SpeechDoneReason, sendOnDone: boolean) {
    this.results.doneReason = reason;
    this.results.flagSendOnDone = sendOnDone;

    if (this._mediaRecorder && this._mediaRecorder.state === 'recording')
      this._mediaRecorder.stop();
  }

  dispose() {
    // if is running
    if (this._mediaStream) {
      this.results.doneReason = 'react-unmount';
      this.stop(this.results.doneReason, false);
      // Stop media streams
      this._mediaStream.getTracks().forEach(track => track.stop());
      this._mediaStream = null;
    }

    // Clean up MediaRecorder
    if (this._mediaRecorder) {
      if (this._mediaRecorder.state !== 'inactive')
        this._mediaRecorder.stop();
      this._mediaRecorder.onstart = null;
      this._mediaRecorder.ondataavailable = null;
      this._mediaRecorder.onstop = null;
      this._mediaRecorder.onerror = null;
      this._mediaRecorder = null;
    }
  }

  isBetweenBeginEnd() {
    return !!this._mediaStream;
  }

  updateConfiguration(_language: string, _softStopTimeout: number, onResultCallback: (result: SpeechResult) => void) {
    this.onResultCallback = onResultCallback;
  }

  private async _handleAudioBlob(audioBlob: Blob) {
    try {
      this.results.transcript = await _transcribeDeepframFrontend(audioBlob);
      this.results.interimTranscript = '';
      this.results.done = true;
      this.results.doneReason = this.results.doneReason ?? 'api-unknown-timeout';
      this.onResultCallback(this.results);
    } catch (error: any) {
      console.error('Recognition error:', error);
      this._handleError('Recognition failed: ' + error?.message);
    }
  }

  private _handleError(message: string) {
    this.setState({ errorMessage: message });
    this.results.doneReason = 'api-error';
    this.results.done = true;
    this.onResultCallback(this.results);
    if (this._mediaRecorder && this._mediaRecorder.state === 'recording')
      this._mediaRecorder.stop();
    this.setState({ isActive: false, hasAudio: false });
  }

}

async function _transcribeDeepframFrontend(audioBlob: Blob): Promise<string> {
  const formData = new FormData();
  formData.append('file', audioBlob, 'audio.webm');

  const response = await fetch('https://api.deepgram.com/v1/listen?model=nova-2&smart_format=true', {
    method: 'POST',
    body: formData,
    headers: {
      'Authorization': 'Token YOUR_API_KEY_FROM_FRONTEND', // omitted
      'Content-Type': 'audio/webm',
    },
  });
  if (!response.ok) {
    console.log('Transcription API failed:', response);
    throw new Error('Transcription API failed: ' + response.statusText);
  }
  const { /*metadata,*/ results } = await response.json();
  return results?.['channels']?.[0]?.['alternatives']?.[0]?.['transcript'] ?? '';
}



================================================
FILE: src/common/components/speechrecognition/useSpeechRecognition.ts
================================================
import * as React from 'react';

import { Is, isBrowser } from '~/common/util/pwaUtils';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { CapabilityBrowserSpeechRecognition } from '../useCapabilities';

import { AudioRecorderEngine } from './AudioRecorderEngine';
import { getSpeechRecognitionClass, WebSpeechApiEngine } from './WebSpeechApiEngine';

// configuration
export const PLACEHOLDER_INTERIM_TRANSCRIPT = 'Listening...';


/// Capability interface

let cachedCapability: CapabilityBrowserSpeechRecognition | null = null;

export const browserSpeechRecognitionCapability = (): CapabilityBrowserSpeechRecognition => {
  if (!cachedCapability) {
    const isApiAvailable = !!getSpeechRecognitionClass();
    const isDeviceNotSupported = false;
    cachedCapability = {
      mayWork: isApiAvailable && !isDeviceNotSupported,
      isApiAvailable,
      isDeviceNotSupported,
      warnings: Is.OS.iOS ? ['Not tested on this browser/device.'] : [],
    };
  }
  return cachedCapability;
};


// Interfaces used by Engines

type RecognitionEngineType = 'webSpeechApi' | 'audioRecorder';

export interface IRecognitionEngine {
  engineType: RecognitionEngineType;
  start: () => void;
  stop: (reason: SpeechDoneReason, sendOnDone: boolean) => void;
  dispose: () => void;
  isBetweenBeginEnd: () => boolean;
  updateConfiguration: (language: string, softStopTimeout: number, onResultCallback: SpeechResultCallback) => void;
}

export interface SpeechResult {
  transcript: string;             // the portion of the transcript that is finalized (or all the transcript if done)
  interimTranscript: string;      // for the continuous (interim) listening, this is the current transcript
  done: boolean;                  // true if the recognition is done - no more updates after this
  doneReason: SpeechDoneReason;   // the reason why the recognition is done
  flagSendOnDone: boolean | undefined; // user flags set on 'startRecognition' - passive
}

export function createSpeechRecognitionResults(): SpeechResult {
  return {
    transcript: '',
    interimTranscript: PLACEHOLDER_INTERIM_TRANSCRIPT,
    done: false,
    doneReason: undefined,
    flagSendOnDone: undefined,
  };
}

export type SpeechDoneReason =
  | undefined             // upon start: not done yet
  | 'manual'              // user clicked the stop button
  | 'continuous-deadline' // we hit our `softStopTimeout` while listening continuously
  | 'api-unknown-timeout' // a timeout has occurred
  | 'api-error'           // underlying .onerror
  | 'api-no-speech'       // underlying .onerror, user did not speak
  | 'switch-engine'       // the engine is switching
  | 'react-unmount';      // the component is unmounting - the App shall never see this (set on unmount and not transmitted)


export interface SpeechRecognitionState {
  isAvailable: boolean;
  isActive: boolean;
  hasAudio: boolean;
  hasSpeech: boolean;
  errorMessage: string | null;
  currentEngine: RecognitionEngineType;
}

type SpeechResultCallback = (result: SpeechResult) => void;


/**
 * Hook for speech recognition that supports switching between engines.
 * @param onResultCallback - Callback when a result is received
 * @param softStopTimeout - Timeout for continuous listening
 * @param engineType - The type of capture engine to use
 */
export const useSpeechRecognition = (
  engineType: RecognitionEngineType,
  onResultCallback: SpeechResultCallback,
  softStopTimeout: number,
) => {

  // state
  const [recognitionState, setRecognitionState] = React.useState<SpeechRecognitionState>({
    isAvailable: false,
    isActive: false,
    hasAudio: false,
    hasSpeech: false,
    errorMessage: null,
    currentEngine: engineType,
  });

  // external state (will update this function when changed)
  const preferredLanguage = useUIPreferencesStore(state => state.preferredLanguage);

  // refs
  const onResultCallbackRef = React.useRef<SpeechResultCallback>(onResultCallback);
  const softStopTimeoutRef = React.useRef<number>(softStopTimeout);
  const preferredLanguageRef = React.useRef<string>(preferredLanguage);
  const engineRef = React.useRef<IRecognitionEngine | null>(null);


  // hooks

  const updateState = React.useCallback((state: Partial<SpeechRecognitionState>) => {
    setRecognitionState((prevState) => ({ ...prevState, ...state }));
  }, []);

  // Params: update refs when params change
  React.useEffect(() => {
    // detect changes
    if (onResultCallbackRef.current === onResultCallback
      && preferredLanguageRef.current === preferredLanguage
      && softStopTimeoutRef.current === softStopTimeout)
      return;

    // remember local values
    onResultCallbackRef.current = onResultCallback;
    softStopTimeoutRef.current = softStopTimeout;
    preferredLanguageRef.current = preferredLanguage;

    // update the values in the running instance
    engineRef.current?.updateConfiguration(preferredLanguage, softStopTimeout, onResultCallback);
  }, [onResultCallback, preferredLanguage, softStopTimeout]);

  // Recreate the engine if the type changes (and upon load, and destroy it on unmount)
  React.useEffect(() => {
    if (!isBrowser) return;

    // prevent re-creating the engine if it's the same type, and multiple instances
    if (engineRef.current?.engineType === engineType)
      return;

    if (engineRef.current) {
      engineRef.current.stop('switch-engine', false);
      engineRef.current = null;
    }

    updateState({
      isAvailable: false,
      isActive: false,
      hasAudio: false,
      hasSpeech: false,
      errorMessage: null,
      currentEngine: engineType,
    });

    switch (engineType) {
      case 'webSpeechApi':

        // check if the device is supported
        // if (browserSpeechRecognitionCapability().isDeviceNotSupported) {
        //   setErrorMessage('Speech recognition is not supported on this device.');
        //   return;
        // }

        // check if the API is available
        const webSpeechAPI = getSpeechRecognitionClass();
        if (!webSpeechAPI) {
          updateState({ errorMessage: 'Speech recognition API is not available in this browser.' });
          return;
        }

        engineRef.current = new WebSpeechApiEngine(
          webSpeechAPI,
          preferredLanguageRef.current,
          softStopTimeoutRef.current,
          onResultCallbackRef.current,
          updateState,
        );
        break;

      case 'audioRecorder':
        engineRef.current = new AudioRecorderEngine(
          preferredLanguageRef.current,
          softStopTimeoutRef.current,
          onResultCallbackRef.current,
          updateState,
        );
        break;
    }

    return () => {
      if (engineRef.current) {
        updateState({ isAvailable: false });
        engineRef.current.dispose();
        engineRef.current = null;
      }
    };
  }, [engineType, updateState]);


  const startRecognition = React.useCallback(() => {
    if (!engineRef.current) return console.error('startRecognition: Speech recognition is not supported or not initialized.');
    if (engineRef.current.isBetweenBeginEnd()) return console.error('startRecognition: Start recording called while already recording.');

    try {
      updateState({ errorMessage: null });
      engineRef.current.start();
    } catch (error: any) {
      updateState({ errorMessage: 'Issue starting the speech recognition.' });
      console.log('Speech recognition error - clicking too quickly?', error?.message);
    }
  }, [updateState]);

  const stopRecognition = React.useCallback((sendOnDone: boolean) => {
    if (!engineRef.current) return console.error('stopRecognition: Speech recognition is not supported or not initialized.');
    if (!engineRef.current.isBetweenBeginEnd()) return console.error('stopRecognition: Stop recognition called while not recognizing.');
    engineRef.current.stop('manual', sendOnDone);
  }, []);

  const hasError = !!recognitionState.errorMessage;

  const toggleRecognition = React.useCallback((sendOnDone?: boolean) => {
    if (!engineRef.current) return;

    // start or stop
    if (hasError || engineRef.current?.isBetweenBeginEnd()) {
      stopRecognition(sendOnDone === true);
      updateState({ errorMessage: null });
    } else
      startRecognition();
  }, [hasError, startRecognition, stopRecognition, updateState]);


  return {
    recognitionState,
    startRecognition,
    stopRecognition,
    toggleRecognition,
  };
};



================================================
FILE: src/common/components/speechrecognition/WebSpeechApiEngine.ts
================================================
import { Is } from '~/common/util/pwaUtils';

import { createSpeechRecognitionResults, IRecognitionEngine, PLACEHOLDER_INTERIM_TRANSCRIPT, SpeechDoneReason, SpeechRecognitionState, SpeechResult } from './useSpeechRecognition';


/**
 * Engine which uses the WebSpeech API for speech recognition.
 */
export class WebSpeechApiEngine implements IRecognitionEngine {
  public readonly engineType = 'webSpeechApi';

  // save parameters
  private softStopTimeout: number;
  private onResultCallback: (result: SpeechResult) => void;

  // state
  private _api: ISpeechRecognition;
  private inactivityTimeoutId: ReturnType<typeof setTimeout> | null;
  private results: SpeechResult;
  private withinBeginEnd: boolean;


  constructor(
    WebSpeechAPIClass: ISpeechRecognition,
    preferredLanguage: string,
    softStopTimeout: number,
    onResultCallback: (result: SpeechResult) => void,
    setState: (state: Partial<SpeechRecognitionState>) => void,
  ) {
    // save parameters
    this.softStopTimeout = softStopTimeout;
    this.onResultCallback = onResultCallback;


    // clean state
    this.inactivityTimeoutId = null;
    this.results = createSpeechRecognitionResults();
    this.withinBeginEnd = false;


    // create the SpeechRecognition instance
    this._api = new WebSpeechAPIClass();

    // configure the instance
    this._api.lang = preferredLanguage;
    this._api.interimResults =
      Is.Desktop                      // verified on Chrome desktop, and Safari desktop
      && softStopTimeout > 0;         // only if we perform the stopping on the client side
    this._api.maxAlternatives = 1;
    this._api.continuous = true;

    // bind event handlers
    this._api.onaudiostart = () => setState({ hasAudio: true });
    this._api.onaudioend = () => setState({ hasAudio: false });

    this._api.onspeechstart = () => setState({ hasSpeech: true });
    this._api.onspeechend = () => setState({ hasSpeech: false });


    this._api.onstart = () => {
      this.withinBeginEnd = true;          // instant
      setState({ isActive: true });   // delayed

      // reinitialize the results
      this.results = createSpeechRecognitionResults();
      this.onResultCallback(this.results);

      // let the system handle the first stop (as long as possible)
      // if (this._api.interimResults)
      //   _reloadInactivityTimeout(2 * this.softStopTimeout);
    };

    this._api.onend = () => {
      this._clearInactivityTimeout();

      this.withinBeginEnd = false;          // instant
      setState({ isActive: false });  // delayed

      /**
       * Important edge case: when termination is not manually requested, or in general when the end comes before
       * an onresult with a final result, we may lose the last interim result.
       */
      if (this.results.interimTranscript && this.results.interimTranscript !== PLACEHOLDER_INTERIM_TRANSCRIPT) {
        this.results.transcript = _chunkExpressionReplaceEN(((this.results.transcript + ' ').trim() + this.results.interimTranscript + ' '));
      }
      this.results.interimTranscript = '';
      this.results.done = true;
      this.results.doneReason = this.results.doneReason ?? 'api-unknown-timeout';
      this.onResultCallback(this.results);

      // (future) Resolve the promise when recording ends
      // recordingDonePromiseResolveRef.current?.(speechResult);
      // recordingDonePromiseResolveRef.current = null;
    };

    this._api.onerror = (event: any) => {
      let errorMessage;
      switch (event.error) {
        case 'no-speech':
          this.results.doneReason = 'api-no-speech';
          break;

        case 'aborted':
          // the user clicked the stop button, so nothing to really do as the manual done reason is already set
          // this.results.doneReason = 'manual';
          return;

        case 'not-allowed':
          errorMessage = 'Microphone access blocked by the user. Enable it in your browser settings to use speech recognition.';
          break;

        case 'service-not-allowed':
          errorMessage = 'Speech Recognition permission denied. Check your System Settings.';
          break;

        case 'audio-capture':
          errorMessage = `Audio capture failed (${event.message}). Please try again.`;
          break;

        case 'network':
          errorMessage = 'Network communication required to complete the service, but failed.';
          break;

        default:
          console.error('Speech recognition error:', event.error, event.message);
          errorMessage = `Browser speech recognition issue ${event.error}: ${event.message}`;
          break;
      }
      if (errorMessage) setState({ errorMessage });
      this.results.doneReason = 'api-error';
    };

    this._api.onresult = (event: ISpeechRecognitionEvent) => {
      if (!event?.results?.length) return;

      // coalesce all the final pieces into a cohesive string
      this.results.transcript = '';
      this.results.interimTranscript = '';
      for (const result of event.results) {
        let chunk = result[0]?.transcript?.trim();
        if (!chunk) continue;

        // Capitalize
        if (chunk.length >= 2 && (result.isFinal || !this.results.interimTranscript))
          chunk = chunk.charAt(0).toUpperCase() + chunk.slice(1);

        // Punctuate
        if (result.isFinal && !/[.!?;:,\s]$/.test(chunk))
          chunk += '.';

        if (result.isFinal)
          this.results.transcript = _chunkExpressionReplaceEN(this.results.transcript + chunk + ' ');
        else
          this.results.interimTranscript = _chunkExpressionReplaceEN(this.results.interimTranscript + chunk + ' ');
      }
      this.onResultCallback(this.results);

      // move the timeout deadline, if in continuous (manually stopped) mode
      if (this._api.interimResults)
        this._reloadInactivityTimeout(this.softStopTimeout, 'continuous-deadline');
    };


    // all ready
    setState({ isAvailable: true });
  }


  start() {
    this.results.flagSendOnDone = undefined;
    this._api.start();
  }

  stop(reason: SpeechDoneReason, sendOnDone: boolean) {
    this.results.doneReason = reason;
    this.results.flagSendOnDone = sendOnDone;
    this._api.stop();
  }

  dispose() {
    // Clear any inactivity timeout to prevent it from running after unmount
    this._clearInactivityTimeout();

    // Explicitly remove event listeners
    this._api.onaudiostart = undefined;
    this._api.onaudioend = undefined;
    this._api.onspeechstart = undefined;
    this._api.onspeechend = undefined;
    this._api.onstart = undefined;
    this._api.onend = undefined;
    this._api.onerror = undefined;
    this._api.onresult = undefined;

    // Stop the recognition if it is still active
    if (this.withinBeginEnd) {
      this.withinBeginEnd = false;
      this.results.doneReason = 'react-unmount';
      this._api.stop();
    }
  }

  isBetweenBeginEnd() {
    return this.withinBeginEnd;
  }

  updateConfiguration(language: string, softStopTimeout: number, onResultCallback: (result: SpeechResult) => void) {
    this._api.lang = language;
    this.softStopTimeout = softStopTimeout;
    this.onResultCallback = onResultCallback;
  }

  private _clearInactivityTimeout() {
    if (this.inactivityTimeoutId) {
      clearTimeout(this.inactivityTimeoutId);
      this.inactivityTimeoutId = null;
    }
  }

  private _reloadInactivityTimeout(timeoutMs: number, doneReason: SpeechDoneReason) {
    this._clearInactivityTimeout();
    this.inactivityTimeoutId = setTimeout(() => {
      this.inactivityTimeoutId = null;
      this.results.doneReason = doneReason;
      this._api.stop();
    }, timeoutMs);
  }

}

export function getSpeechRecognitionClass(): ISpeechRecognition | null {
  if (typeof window !== 'undefined') {
    return (
      (window as any).SpeechRecognition ||
      (window as any).webkitSpeechRecognition ||
      (window as any).mozSpeechRecognition ||
      (window as any).msSpeechRecognition || null
    );
  }
  return null;
}

// Helper function
function _chunkExpressionReplaceEN(fullText: string): string {
  return fullText
    .replaceAll(/\.?\scomma\b/gi, ',')
    .replaceAll(/\.?\speriod\b/gi, '.')
    .replaceAll(/\.?\squestion mark\b/gi, '?')
    .replaceAll(/\.?\sexclamation mark\b/gi, '!');
}


interface ISpeechRecognition extends EventTarget {
  new(): ISpeechRecognition;

  lang: string;
  continuous: boolean;
  interimResults: boolean;
  maxAlternatives: number;

  start: () => void;
  stop: () => void;
  // abort: () => void;

  onaudiostart?: (event: any) => void;
  // onsoundstart?: (event: any) => void;
  onspeechstart?: (event: any) => void;
  onspeechend?: (event: any) => void;
  // onsoundend?: (event: any) => void;
  onaudioend?: (event: any) => void;
  onresult?: (event: ISpeechRecognitionEvent) => void;
  // onnomatch?: (event: any) => void;
  onerror?: (event: any) => void;
  onstart?: (event: any) => void;
  onend?: (event: any) => void;
}

interface ISpeechRecognitionEvent extends Event {
  // readonly resultIndex: number;
  readonly results: SpeechRecognitionResult[];
}




================================================
FILE: src/common/events/events.bus.ts
================================================
import EventEmitter from 'eventemitter3';

import { Release } from '~/common/app.release';
import { agiUuid } from '~/common/util/idUtils';
import { logger } from '~/common/logger';

import type { EventData, EventDomainName, EventListener, EventName, EventPayload, EventUnsubscribe, WildcardEventListener } from './events.types';


type EventExtraOptions = {
  source?: string;
  correlationId?: string;
}


type EventHistoryEntry = {
  domain: string;
  name: string;
  payload: EventPayload<unknown>;
}


export class EventBus {

  // core
  #emitter = new EventEmitter();
  #wildcardListeners: WildcardEventListener[] = [];

  // debugging
  #debug = false;
  #debugHistory: EventHistoryEntry[] = [];
  #debugHistoryLimit = 1000;


  /** Emit a domain-specific event */
  emit<D extends EventDomainName, E extends EventName<D>>(
    domain: D,
    name: E,
    data: EventData<D, E>,
    options: EventExtraOptions = {},
  ): string {

    const fullEventName = `${String(domain)}:${String(name)}`;
    const payload: EventPayload<EventData<D, E>> = {
      id: agiUuid('event-id'),
      timestamp: Date.now(),
      ...options,
      data,
    };

    if (this.#debug) {
      this.#debugHistory.push({
        domain: String(domain),
        name: String(name),
        payload,
      });
      if (this.#debugHistory.length > this.#debugHistoryLimit)
        this.#debugHistory.shift();
    }

    this.#emitter.emit(fullEventName, payload);

    for (const listener of this.#wildcardListeners) {
      try {
        listener(String(domain), String(name), payload);
      } catch (error) {
        logger.error(`Error in wildcard listener for ${fullEventName}:`, error);
        // NOTE: re-throw?
      }
    }

    return payload.id;
  }

  /** Listen for domain-specific events */
  on<D extends EventDomainName, E extends EventName<D>>(
    domain: D,
    name: E,
    listener: EventListener<D, E>,
  ): EventUnsubscribe {

    const fullEventName = `${String(domain)}:${String(name)}`;

    const wrappedListener = (payload: EventPayload<EventData<D, E>>) => {
      try {
        listener(payload);
      } catch (error) {
        logger.error(`Error in listener for ${fullEventName}:`, error);
        // NOTE: re-throw?
      }
    };

    this.#emitter.on(fullEventName, wrappedListener);

    return () => {
      this.#emitter.off(fullEventName, wrappedListener);
    };
  }

  /** Listen for an event once */
  once<D extends EventDomainName, E extends EventName<D>>(
    domain: D,
    name: E,
    listener: EventListener<D, E>,
  ): EventUnsubscribe {

    const fullEventName = `${String(domain)}:${String(name)}`;

    const wrappedListener = (payload: EventPayload<EventData<D, E>>) => {
      try {
        listener(payload);
      } catch (error) {
        logger.error(`Error in once listener for ${fullEventName}:`, error);
        // NOTE: re-throw?
      }
    };

    this.#emitter.once(fullEventName, wrappedListener);

    return () => {
      this.#emitter.off(fullEventName, wrappedListener);
    };
  }

  /** FOR DEBUG ONLY - listen for all events across all domains */
  onAny(listener: WildcardEventListener): EventUnsubscribe {
    this.#wildcardListeners.push(listener);

    return () => {
      const index = this.#wildcardListeners.indexOf(listener);
      if (index !== -1)
        this.#wildcardListeners.splice(index, 1);
    };
  }


  /** Clear all listeners and history */
  dispose(): void {
    this.#emitter.removeAllListeners();
    this.#wildcardListeners = [];
    this.#debugHistory = [];
  }

  /** Create a domain-specific helper */
  forDomain<D extends EventDomainName>(domain: D): DomainEventHelper<D> {
    return new DomainEventHelper<D>(this, domain);
  }


  // /** Create an event flow for tracking related events */
  // createFlow(flowId = crypto.randomUUID()): EventFlow {
  //   return new EventFlow(flowId, this);
  // }


  /** Enable debug mode which retains a history of emitted events */
  enableDebug(enabled = true, historyLimit = 1000): void {
    this.#debug = enabled;
    this.#debugHistoryLimit = historyLimit;
    if (!enabled)
      this.#debugHistory = [];
  }

  /** Get event history (only available in debug mode) */
  getDebugEventHistory(filter?: {
    domain?: string;
    name?: string;
    since?: number;
  } & EventExtraOptions): EventHistoryEntry[] {
    if (!this.#debug) {
      console.warn('Event history is only available when debug mode is enabled');
      return [];
    }

    if (!filter)
      return [...this.#debugHistory];

    return this.#debugHistory.filter(entry => {
      if (filter.domain && entry.domain !== filter.domain) return false;
      if (filter.name && entry.name !== filter.name) return false;
      if (filter.since && entry.payload.timestamp < filter.since) return false;
      if (filter.source && entry.payload.source !== filter.source) return false;
      return !(filter.correlationId && entry.payload.correlationId !== filter.correlationId);
    });
  }

}


/**
 * Helper class for working with a specific domain
 * Collects unsubscribe functions and provides a single dispose method to prevent memory leaks
 */
export class DomainEventHelper<D extends EventDomainName> {
  private readonly unsubscribeFunctions: EventUnsubscribe[] = [];

  constructor(
    protected readonly bus: EventBus,
    protected readonly domain: D,
  ) {
  }

  /** Emit an event in this domain */
  emit<E extends EventName<D>>(
    name: E,
    data: EventData<D, E>,
    options: EventExtraOptions = {},
  ): string {
    return this.bus.emit(this.domain, name, data, options);
  }

  /** Listen for an event in this domain */
  on<E extends EventName<D>>(
    name: E,
    listener: EventListener<D, E>,
  ): EventUnsubscribe {
    const unsubscribe = this.bus.on(this.domain, name, listener);
    this.unsubscribeFunctions.push(unsubscribe);
    return () => {
      const index = this.unsubscribeFunctions.indexOf(unsubscribe);
      if (index !== -1)
        this.unsubscribeFunctions.splice(index, 1);
      unsubscribe();
    };
  }

  /** Listen for an event once in this domain */
  once<E extends EventName<D>>(
    name: E,
    listener: EventListener<D, E>,
  ): EventUnsubscribe {
    const unsubscribe = this.bus.once(this.domain, name, listener);
    this.unsubscribeFunctions.push(unsubscribe);
    return () => {
      const index = this.unsubscribeFunctions.indexOf(unsubscribe);
      if (index !== -1)
        this.unsubscribeFunctions.splice(index, 1);
      unsubscribe();
    };
  }

  /** Dispose of this helper and unsubscribe from all events */
  disposeUnsubscribeAll(): void {
    for (const unsubscribe of this.unsubscribeFunctions)
      unsubscribe();
    this.unsubscribeFunctions.length = 0;
  }
}


/**
 * Singleton App-wide Bus.
 *
 * Make sure to Unsubscribe from events even during unmounts/Domain lifecycle unmounts,
 * otherwise hot module reload could still dispatch to older instances in memory.
 */
export const appEvents = new EventBus();

// HMR handling - only runs in development when hot module replacement is active
// if (Release.IsNodeDevBuild && typeof module !== 'undefined' && 'hot' in module) {
//   logger.info(`~HMR detected: appEvents regenerated - some components may still be listening to the old EventBus.`);
//   (module.hot as any).dispose(() => ...);
// }



================================================
FILE: src/common/events/events.flow.ts
================================================
// NOTE: Not needed for now, but kept for future reference in case we do
// Helper class for tracking a sequence of related events
//
// export class EventFlow {
//   private events: Array<{
//     domain: string;
//     name: string;
//     payload: EventPayload<unknown>;
//     timestamp: number;
//   }> = [];
//   readonly #startTime: number;
//   private endTime?: number;
//   readonly #cleanup: EventUnsubscribe;
//
//   constructor(
//     public readonly flowId: string,
//     private bus: EventBus,
//   ) {
//     this.#startTime = Date.now();
//
//     // Auto-track events with this correlation ID
//     this.#cleanup = this.bus.onAny((domain, name, payload) => {
//       if (payload.correlationId === this.flowId) {
//         this.events.push({
//           domain,
//           name,
//           payload,
//           timestamp: Date.now(),
//         });
//       }
//     });
//   }
//
//   // Emit an event as part of this flow
//   emit<D extends EventDomainName, E extends EventName<D>>(
//     domain: D,
//     name: E,
//     data: EventData<D, E>,
//     options: { source?: string } = {},
//   ): string {
//     return this.bus.emit(domain, name, data, {
//       ...options,
//       correlationId: this.flowId,
//     });
//   }
//
//   // Stop tracking and release resources
//   complete(): void {
//     this.endTime = Date.now();
//     this.#cleanup();
//   }
//
//   // Get the flow duration in milliseconds
//   get duration(): number {
//     return (this.endTime || Date.now()) - this.#startTime;
//   }
//
//   // Get all events in this flow
//   getEvents(): Array<{
//     domain: string;
//     name: string;
//     payload: EventPayload<unknown>;
//     timestamp: number;
//   }> {
//     return [...this.events];
//   }
// }
// export function createEventFlow(flowId = crypto.randomUUID()): EventFlow {
//   return appEvents.createFlow(flowId);
// }



================================================
FILE: src/common/events/events.stateful.ts
================================================
import { logger } from '~/common/logger';

import type { EventData, EventDomainName, EventName, EventUnsubscribe } from './events.types';
import { appEvents, DomainEventHelper } from './events.bus';

/**
 * LiveEventState vs Regular Events: When to use each
 *
 * Stateful Events (this file):
 * - Maintain a current value that can be accessed immediately (state.value)
 * - Notify new subscribers with the current value right away
 * - Represent ongoing conditions/properties (network status, theme, auth state)
 * - Use when components need the current state immediately upon mounting
 *
 * Regular Events (events.bus.ts):
 * - Signal one-time actions or changes (button clicks, sync started/completed)
 * - No state retention between emissions
 * - More flexible data structures specific to each event
 * - Use for triggering processes or broadcasting notifications
 *
 * StatefulEventsManager vs LiveEventState:
 *
 * The StatefulEventsManager is a factory that creates and manages LiveEventState
 * instances for a specific domain. Each LiveEventState holds the actual state value.
 *
 * Example:
 *
 * // 1. Create a state manager for the 'ui' domain
 * const uiEvents = createStatefulEventsManagerFor('ui');
 *
 * // 2. Create a live state for theme preference
 * const themeState = uiEvents.createLiveEventState<'theme:changed', 'light' | 'dark' | 'system'>(
 *   'theme:changed',  // Event name
 *   'system',         // Initial value
 *   'ThemeManager'    // Source label
 * );
 *
 * // 3. Access the current value anywhere
 * const currentTheme = themeState.value;  // 'system'
 *
 * // 4. Update the value (will notify subscribers and emit an event)
 * themeState.update('dark');
 *
 * // 5. Subscribe to changes (immediately gets current value + future updates)
 * const unsubscribe = themeState.subscribe(theme => {
 *   console.log(`Theme changed to: ${theme}`);  // 'Theme changed to: dark'
 * });
 *
 * // 6. Clean up when done
 * unsubscribe();
 */

export interface LiveEventStateData<TValue> {
  value: TValue;
  previousValue: TValue;

  [key: string]: any;
}


/**
 * Manager for LiveEventState instances in a specific domain
 */
export class StatefulEventsManager<
  Dn extends EventDomainName
> extends DomainEventHelper<Dn> {

  #namedLiveStates = new Map<string, LiveEventState<any, Dn, any>>();

  /** Create or get a live state for a specific event */
  createLiveEventState<En extends EventName<Dn>, TValue>(
    eventName: En,
    initialValue: TValue,
    sourceLabel?: string,
  ): LiveEventState<TValue, Dn, En> {
    const key = String(eventName);

    if (!this.#namedLiveStates.has(key)) {
      const liveEventState = new LiveEventState<TValue, Dn, En>(
        initialValue,
        this.domain,
        eventName,
        sourceLabel,
      );
      this.#namedLiveStates.set(key, liveEventState);
    }

    return this.#namedLiveStates.get(key) as LiveEventState<TValue, Dn, En>;
  }

  /** Get a live state if it exists */
  getLiveEventState<E extends EventName<Dn>, TValue>(eventName: E): LiveEventState<TValue, Dn, E> | undefined {
    return this.#namedLiveStates.get(String(eventName)) as LiveEventState<TValue, Dn, E> | undefined;
  }

  /** Remove a live state and dispose its resources */
  removeLiveEventState<E extends EventName<Dn>>(eventName: E): boolean {
    const key = String(eventName);
    const state = this.#namedLiveStates.get(key);

    if (state) {
      state.dispose();
      this.#namedLiveStates.delete(key);
      return true;
    }

    return false;
  }

  /** Clean up all live states in this domain */
  disposeAll(): void {
    for (const state of this.#namedLiveStates.values())
      state.dispose();
    this.#namedLiveStates.clear();
  }
}


/**
 * A live state value that can be observed with automatic notifications
 *
 * NOTE: For proper type safety, ensure all domain events that will be used with LiveEventState
 *
 * conform to the LiveEventStateData<TValue> interface, which includes:
 * - value: TValue - The current state value
 * - previousValue: TValue - The previous state value
 * - ...any additional metadata
 *
 * The type casting to EventData<Dn, En> is necessary because TypeScript doesn't allow
 * us to constrain En to only event names with compatible data structures at the class level.
 *
 * When defining domain events meant for state usage, use this pattern:
 * ```typescript
 * declare module './events.types' {
 *   interface EventDomains {
 *     'domain': {
 *       'event:name': LiveEventStateData<YourValueType>;
 *     }
 *   }
 * }
 * ```
 */
export class LiveEventState<
  TValue,
  Dn extends EventDomainName,
  En extends EventName<Dn> = EventName<Dn>, // auto
  TListener extends (value: TValue) => void = (value: TValue) => void, // auto
> {

  #currentValue: TValue;
  #listeners = new Set<TListener>();

  constructor(
    initialValue: TValue,
    private readonly domainName: Dn,
    private readonly eventName: En,
    private readonly sourceLabel?: string, // sets the event source optional param, or 'LiveEventState'
  ) {
    this.#currentValue = initialValue;
  }

  /** Get current value */
  get value(): Readonly<TValue> {
    return this.#currentValue;
  }

  /** Sets the current value and emits */
  update(newValue: TValue, metadata: { [key: string]: any } = {}): void {

    // shallow-check for change, or skip
    if (newValue === this.#currentValue) return;

    const oldValue = this.#currentValue;
    this.#currentValue = newValue;

    this.#listeners.forEach(listener => {
      try {
        listener(newValue);
      } catch (error) {
        logger.error(`Error in LiveEventState listener for ${this.domainName}:${String(this.eventName)}:`, error);
        // NOTE: re-throw?
      }
    });

    // emit the change event
    appEvents.emit(
      this.domainName,
      this.eventName,
      ({
        value: newValue,
        previousValue: oldValue,
        ...metadata,
      } satisfies LiveEventStateData<TValue>) as EventData<Dn, En>,
      { source: this.sourceLabel || 'LiveEventState' },
    );
  }

  /** Subscribe to changes, immediately receiving the current value */
  subscribe(listener: TListener): EventUnsubscribe {
    this.#listeners.add(listener);

    try {
      listener(this.#currentValue);
    } catch (error) {
      logger.error(`Error in initial LiveEventState callback:`, error);
      // NOTE: re-throw?
    }

    return () => {
      this.#listeners.delete(listener);
    };
  }

  /** Clean up all listeners */
  dispose(): void {
    this.#listeners.clear();
  }
}


/** Create a state manager for a specific domain */
export function createStatefulEventsManagerFor<D extends EventDomainName>(domain: D): StatefulEventsManager<D> {
  return new StatefulEventsManager<D>(appEvents, domain);
}



================================================
FILE: src/common/events/events.types.ts
================================================
/**
 * Base event payload structure
 */
export interface EventPayload<T /*= unknown*/> {
  id: string;             // unique ID
  timestamp: number;      // when the event was emitted
  source?: string;        // optional component/module that emitted the event
  correlationId?: string; // optional for tracking related events
  data: T;                // event-specific data
}

/**
 * !!! Augmentation Target for Events (domains, events, data) extension !!!
 * Domain registry - Extended via module augmentation by each domain
 */
export interface EventDomains {
  // default: nothing
}


export type EventDomainName = keyof EventDomains;

export type EventName<D extends EventDomainName> = keyof EventDomains[D];
export type EventData<D extends EventDomainName, E extends EventName<D>> = EventDomains[D][E];

export type FullEventName<D extends EventDomainName, E extends EventName<D>> =
  `${string & D}:${string & E}`;


export type EventListener<D extends EventDomainName, E extends EventName<D>> =
  (event: EventPayload<EventData<D, E>>) => void;

export type WildcardEventListener =
  (domain: string, name: string, event: EventPayload<unknown>) => void;

export type EventUnsubscribe = () => void;



================================================
FILE: src/common/events/index.ts
================================================
import { Release } from '~/common/app.release';
import { logger } from '~/common/logger';

import type { EventData, EventDomainName, EventName } from './events.types';
import { appEvents } from './events.bus';


// re-export types
export type { EventPayload, EventDomains, EventDomainName, EventName, EventData, EventListener, EventUnsubscribe } from './events.types';

// re-export event bus
export { appEvents, DomainEventHelper, EventBus } from './events.bus';

// re-export live event state
export type { LiveEventStateData } from './events.stateful';
export { LiveEventState, StatefulEventsManager, createStatefulEventsManagerFor } from './events.stateful';


// configuration
const EVENTS_DEBUG_ENABLE = false;


/** Type-safe helper to emit events */
export function appEmitEvent<D extends EventDomainName, E extends EventName<D>>(
  domain: D,
  name: E,
  data: EventData<D, E>,
  options?: {
    source?: string;
    correlationId?: string;
  },
): string {
  return appEvents.emit(domain, name, data, options);
}


// Future: domain-specific exports
// export { networkEvents, networkConnected, initNetworkMonitor } from './domains/network';
// export { uiEvents, currentTheme, sidebarState } from './domains/ui';
// export function initEventSystem(): void {
//   initNetworkMonitor();
//   console.log('[EventSystem] Initialized');
// }

// Enable debugging in development
if (EVENTS_DEBUG_ENABLE && Release.IsNodeDevBuild) {
  appEvents.enableDebug(true);
  appEvents.onAny((domain, name, payload) =>
    logger.debug(`[Event] ${domain}:${name}`, payload.data),
  );
}


================================================
FILE: src/common/layout/withLayout.tsx
================================================
import * as React from 'react';

import type { NextPageWithLayout } from '~/common/types/next.page';

import { ContainerLayout } from '~/common/layout/container/ContainerLayout';
import { OptimaLayout } from './optima/OptimaLayout';


type PerPageLayoutOptions = {
  // Center in a container at 100dvh
  type: 'container';
} | {
  // No layout, just the page
  type: 'noop';
} | {
  // Flexible layout with pluggable components
  type: 'optima';
  suspendAutoModelsSetup?: boolean;
};


/**
 * Next.js page-level layouting: a wrapper that adds the layout around the page as a layout function.
 */
export function withNextJSPerPageLayout(options: PerPageLayoutOptions, page: NextPageWithLayout): NextPageWithLayout {

  const { type, ...rest } = options;

  switch (type) {

    case 'container':
      page.getLayout = (page: React.ReactElement) => <ContainerLayout {...rest}>{page}</ContainerLayout>;
      return page;

    case 'noop':
      page.getLayout = (page: React.ReactElement) => page;
      return page;

    case 'optima':
      page.getLayout = (page: React.ReactElement) => <OptimaLayout {...rest}>{page}</OptimaLayout>;
      return page;

    default:
      console.error('No layout specified for this top-level page');
      return page;

  }
}


// /**
//  * Dynamic page-level layouting: a wrapper that adds the layout around the children.
//  */
// export function withLayout(layoutOptions: LayoutOptions, children: React.ReactNode): React.ReactElement {
//
//   const { type, ...rest } = layoutOptions;
//
//   switch (type) {
//
//     case 'optima':
//       return <OptimaLayout {...rest}>{children}</OptimaLayout>;
//
//     case 'plain':
//       return <PlainLayout {...rest}>{children}</PlainLayout>;
//
//     default:
//       console.error('No layout specified for this top-level page');
//       return <>{children}</>;
//
//   }
// }
//



================================================
FILE: src/common/layout/container/ContainerLayout.tsx
================================================
import * as React from 'react';

import { Box, Container } from '@mui/joy';

import { themeBgApp } from '~/common/app.theme';


export function ContainerLayout(props: { children?: React.ReactNode }) {
  return <>

    {/* Headers as needed */}

    <Container disableGutters>
      <Box sx={{
        backgroundColor: themeBgApp,
        display: 'flex', flexDirection: 'column',
        minHeight: '100dvh',
      }}>

        {props.children}

      </Box>
    </Container>

    {/* Footers as needed */}

  </>;
}


================================================
FILE: src/common/layout/optima/InvertedBar.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Sheet, styled, useTheme } from '@mui/joy';


export const InvertedBarCornerItem = styled(Box)({
  width: 'var(--Bar)',
  height: 'var(--Bar)',
  display: 'flex',
  justifyContent: 'center',
  alignItems: 'center',
});


const StyledSheet = styled(Sheet)({
  // customization
  '--Bar': 'var(--AGI-Nav-width)',

  // layout
  display: 'flex',
  justifyContent: 'space-between',
  alignItems: 'center',
}) as typeof Sheet;


// This is the PageBar and the MobileAppNav and DesktopNav
export const InvertedBar = (props: {
  id?: string,
  component: React.ElementType,
  direction: 'horizontal' | 'vertical',
  sx?: SxProps
  children: React.ReactNode,
  onMouseEnter?: () => void,
  onMouseLeave?: () => void,
}) => {

  // check for dark mode
  const theme = useTheme();
  const isDark = theme?.palette.mode === 'dark';


  // memoize the Sx for stability, based on direction
  const sx: SxProps = React.useMemo(() => (
    props.direction === 'horizontal'
      ? {
        // minHeight: 'var(--Bar)',
        flexDirection: 'row',
        // overflow: 'hidden',
        ...props.sx,
      } : {
        // minWidth: 'var(--Bar)',
        flexDirection: 'column',
        ...props.sx,
      }
  ), [props.direction, props.sx]);


  return (
    <StyledSheet
      id={props.id}
      component={props.component}
      variant={isDark ? 'soft' : 'solid'}
      invertedColors={!isDark ? true : undefined}
      onMouseEnter={props.onMouseEnter}
      onMouseLeave={props.onMouseLeave}
      sx={sx}
    >
      {props.children}
    </StyledSheet>
  );
};


================================================
FILE: src/common/layout/optima/Modals.tsx
================================================
import * as React from 'react';

import { optimaActions, optimaOpenPreferences, useOptimaModals } from './useOptima';

// auto-open models trigger
import { optimaOpenModels } from '~/common/layout/optima/useOptima';
import { runWhenIdle } from '~/common/util/pwaUtils';
import { useModelsZeroState } from '~/common/stores/llms/hooks/useModelsZeroState';

// Modals
import { AixDebuggerDialog } from '~/modules/aix/client/debugger/AixDebuggerDialog';
import { LogViewerDialog } from '~/common/logger/viewer/LoggerViewerDialog';
import { ShortcutsModal } from '../../../apps/settings-modal/ShortcutsModal';

// Lazy-loaded Modals
const ModelsModalsLazy = React.lazy(() => import('~/modules/llms/models-modal/ModelsModals').then(module => ({ default: module.ModelsModals })));
const SettingsModalLazy = React.lazy(() => import('../../../apps/settings-modal/SettingsModal').then(module => ({ default: module.SettingsModal })));


export function Modals(props: { suspendAutoModelsSetup?: boolean }) {

  // external state
  const { preferencesTab, showAIXDebugger, showKeyboardShortcuts, showLogger, showPreferences, showModels, showModelOptions } = useOptimaModals();

  // derived state
  const { closeAIXDebugger, closeKeyboardShortcuts, closeLogger, closePreferences, openKeyboardShortcuts } = optimaActions();


  // [effect] Auto-open the configurator - anytime no service is selected
  const hasNoServices = useModelsZeroState();
  const autoOpenTrigger = hasNoServices && !props.suspendAutoModelsSetup;
  React.useEffect(() => {
    if (autoOpenTrigger)
      return runWhenIdle(() => optimaOpenModels(), 2000);
  }, [autoOpenTrigger]);


  return <>

    {/* Overlay - Preferences Modal */}
    {showPreferences && (
      <React.Suspense fallback={null}>
        <SettingsModalLazy
          open={showPreferences}
          tab={preferencesTab}
          setTab={optimaOpenPreferences}
          onClose={closePreferences}
          onOpenShortcuts={openKeyboardShortcuts}
        />
      </React.Suspense>
    )}

    {/* Overlay Models + LLM Options */}
    {(showModels || showModelOptions) && (
      <React.Suspense fallback={null}>
        <ModelsModalsLazy />
      </React.Suspense>
    )}

    {/* Logger */}
    {showLogger && <LogViewerDialog onClose={closeLogger} />}

    {/* AIX Debugger Dialog */}
    {showAIXDebugger && <AixDebuggerDialog onClose={closeAIXDebugger} />}

    {/* Overlay Shortcuts */}
    {showKeyboardShortcuts && (
      <ShortcutsModal onClose={closeKeyboardShortcuts} />
    )}

  </>;
}


================================================
FILE: src/common/layout/optima/optima.config.ts
================================================
// configuration
export const OPTIMA_DRAWER_BACKGROUND = 'var(--joy-palette-background-popup)';
export const OPTIMA_DRAWER_MOBILE_RADIUS = 'var(--joy-radius-lg)';
export const OPTIMA_OPEN_DEBOUNCE = 100; // ms - prevent accidental immediate close
export const OPTIMA_PEEK_HOVER_ENTER_DELAY = 150; // ms - enter delay: prevents accidental triggers
export const OPTIMA_PEEK_HOVER_ENTER_DELAY_PANEL = 1000; // ms - enter delay: prevents accidental triggers
export const OPTIMA_PEEK_HOVER_TIMEOUT = 300; // ms - exit delay: time to hide after mouse leaves
export const OPTIMA_NAV_RADIUS = 'sm';
export const OPTIMA_PANEL_GROUPS_SPACING = 2.5;

// debug
export const OPTIMA_DEBUG_PORTALS = false;



================================================
FILE: src/common/layout/optima/OptimaLayout.tsx
================================================
import * as React from 'react';
import { useRouter } from 'next/router';
import { PanelGroup } from 'react-resizable-panels';

import { GlobalDragOverlay } from '~/common/components/dnd-dt/GlobalDragOverlay';
import { Is } from '~/common/util/pwaUtils';
import { checkVisibleNav, navItems } from '~/common/app.nav';
import { useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { ScratchClip } from './scratchclip/ScratchClip';
import { scratchClipSupported } from './scratchclip/store-scratchclip';
import { useGlobalClipboardSaver } from './scratchclip/useGlobalClipboardSaver';

import { DesktopDrawer } from './drawer/DesktopDrawer';
import { DesktopNav } from './nav/DesktopNav';
import { DesktopPanel } from './panel/DesktopPanel';
import { MobileDrawer } from './drawer/MobileDrawer';
import { MobilePanel } from './panel/MobilePanel';
import { Modals } from './Modals';
import { PageWrapper } from './PageWrapper';
import { optimaActions, optimaOpenModels, optimaOpenPreferences } from './useOptima';


// this undoes the PanelGroup styling on mobile, as it's not needed
// NOTE: there may be benefits with the PanelGroup layout, namely that
// it's already 100% x 100% and doesn't scroll, so there would be no
// chance of overflow, and outer limits are set here
const undoPanelGroupSx: React.CSSProperties = {
  display: 'block',
  marginLeft: undefined,
  marginRight: undefined,
  width: undefined,
  height: undefined,
  overflow: undefined,
};


/**
 * Core layout of big-AGI, used by all the Primary applications therein.
 *
 * Main functions:
 *  - modern responsive layout
 *  - core layout of the application, with the Nav, Panes, PageBar, etc.
 *    - the child(ren) of this layout are placed in the main content area
 *  - allows for pluggable components of children applications, via usePluggableOptimaLayout
 *  - overlays and displays various modals
 *  - flicker free
 */
export function OptimaLayout(props: { suspendAutoModelsSetup?: boolean, children: React.ReactNode }) {

  // external state
  const { route } = useRouter();
  const isMobile = useIsMobile();

  // external: clipboard snippet support
  const supportsClip = scratchClipSupported();
  useGlobalClipboardSaver(supportsClip);

  // derived state
  const currentApp = navItems.apps.find(item => item.route === route);

  // global shortcuts for Optima
  useGlobalShortcuts('OptimaApp', React.useMemo(() => [
    // Preferences & Model dialogs
    { key: ',', ctrl: true, action: optimaOpenPreferences },
    { key: 'm', ctrl: true, shift: true, action: optimaOpenModels },
    { key: 'g', ctrl: true, shift: true, action: optimaActions().openLogger },
    { key: 'a', ctrl: true, shift: true, action: optimaActions().openAIXDebugger },
    // Font Scale
    { key: '+', ctrl: true, shift: true, action: useUIPreferencesStore.getState().increaseContentScaling },
    { key: '-', ctrl: true, shift: true, action: useUIPreferencesStore.getState().decreaseContentScaling },
    // Shortcuts
    { key: Is.OS.MacOS ? '/' : '?', ctrl: true, shift: true, action: optimaActions().openKeyboardShortcuts },
    { key: 'h', ctrl: true, shift: true, action: '_specialPrintShortcuts' },
  ], []));

  return <>

    <PanelGroup direction='horizontal' id='root-layout' style={isMobile ? undoPanelGroupSx : undefined}>


      {/* Desktop: 4 horizontal sections: Nav | Drawer | Page | Panel */}

      {!isMobile && checkVisibleNav(currentApp) && <DesktopNav component='nav' currentApp={currentApp} />}

      {!isMobile && <DesktopDrawer key='optima-drawer' component='aside' currentApp={currentApp} />}

      {/*<Panel defaultSize={100}>*/}
      <PageWrapper key='app-page-wrapper' component='main' isMobile={isMobile} currentApp={currentApp}>
        {props.children}
      </PageWrapper>
      {/*</Panel>*/}

      {!isMobile && <DesktopPanel key='optima-panel' component='aside' currentApp={currentApp} />}


      {/* Mobile - 2 panes overlay the Page */}

      {isMobile && <MobileDrawer key='optima-drawer' component='aside' currentApp={currentApp} />}

      {isMobile && <MobilePanel key='optima-panel' component='aside' currentApp={currentApp} />}


    </PanelGroup>

    {/* Global Window Overlay */}
    {Is.Desktop && <GlobalDragOverlay />}

    {/* Overlay Modals */}
    <Modals suspendAutoModelsSetup={props.suspendAutoModelsSetup} />

    {/* Shared Clipboard History */}
    {supportsClip && <ScratchClip />}

  </>;
}



================================================
FILE: src/common/layout/optima/OptimaMOTD.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, IconButton, Sheet, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';

import { Release } from '~/common/app.release';
import { frontendHashString } from '~/common/util/textUtils';
import { themeZIndexPageBar } from '~/common/app.theme';
import { uiSetDismissed, useUIIsDismissed } from '~/common/stores/store-ui';


// configuration
const MOTD_COLOR = 'primary';
const MOTD_PREFIX = 'motd-';


// toggles the component
export const optimaHasMOTD = !!process.env.NEXT_PUBLIC_MOTD;


/**
 * Message of the day. If set, displays a message on this deployment.
 * The message can be permanently dismissed.
 */
export function OptimaMOTD() {

  // expand special variables in the MOTD
  const { message, hash, buildTimestamp } = React.useMemo(() => {
    const rawMOTD = process.env.NEXT_PUBLIC_MOTD;
    if (!rawMOTD?.trim()) return { message: null, hash: null, buildTimestamp: null };

    const buildInfo = Release.buildInfo('frontend');
    const message = rawMOTD
      .replace(/{{app_build_hash}}/g, buildInfo.gitSha || '')
      .replace(/{{app_build_pkgver}}/g, buildInfo.pkgVersion || '')
      // .replace(/{{app_build_time}}/g, new Date(buildInfo.timestamp || '').toLocaleDateString()) // we don't do this anymore, as we handle it with TimeAgo.
      .replace(/{{app_deployment_type}}/g, buildInfo.deploymentType || '');

    return {
      message,
      hash: frontendHashString(message),
      buildTimestamp: buildInfo.timestamp || '',
    };
  }, []);


  // external state
  const dismissed = useUIIsDismissed(!hash ? null : MOTD_PREFIX + hash);

  // skip if no MOTD
  if (!message || dismissed === true)
    return null;


  /**
   * Special render function to split '{{app_build_time}}' and insert a TimeAgo component.
   */
  function renderMessageWithTimeAgo(message: string) {
    if (message.includes('{{app_build_time}}')) {
      const parts = message.split('{{app_build_time}}');
      return <>{parts[0]}{buildTimestamp && <TimeAgo date={buildTimestamp} />}{parts[1]}</>;
    }
    return message;
  }

  return (
    <Sheet
      id='optima-motd'
      component='header'
      variant='solid'
      sx={{ zIndex: themeZIndexPageBar }}
    >
      <Typography
        component='div'
        level='title-sm'
        variant='soft'
        color={MOTD_COLOR}
        endDecorator={
          <IconButton
            size='sm'
            variant='soft'
            color={MOTD_COLOR}
            onClick={() => uiSetDismissed(MOTD_PREFIX + hash)}
            sx={{ ml: 'auto' }}
          >
            <CloseRoundedIcon />
          </IconButton>
        }
        sx={{
          mt: 1,
          mx: 1,
          borderRadius: 'sm',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'space-between',
        }}
      >
        <Box sx={{ p: 1, lineHeight: 'xl' }}>
          {renderMessageWithTimeAgo(message)}
        </Box>
      </Typography>
    </Sheet>
  );
}



================================================
FILE: src/common/layout/optima/PageCore.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { themeBgApp, themeZIndexPageBar } from '~/common/app.theme';
import type { NavItemApp } from '~/common/app.nav';

// import { MobileNav } from './MobileNav';
import { OptimaBar } from '~/common/layout/optima/bar/OptimaBar';
import { optimaHasMOTD, OptimaMOTD } from '~/common/layout/optima/OptimaMOTD';


const pageCoreSx: SxProps = {
  // background: 'url(/images/big-agi-background-3.png) no-repeat center bottom fixed',
  backgroundColor: themeBgApp,
  height: '100dvh',
  display: 'flex', flexDirection: 'column',
  transition: 'background-color 0.5s cubic-bezier(.17,.84,.44,1)',
};

const pageCoreFullSx: SxProps = {
  ...pageCoreSx,
  backgroundColor: 'transparent',
} as const;

const pageCoreBrighterSx: SxProps = {
  ...pageCoreSx,
  backgroundColor: 'background.surface',
};

const pageCoreBarSx: SxProps = {
  zIndex: themeZIndexPageBar,
};

const pageCoreMobileNavSx: SxProps = {
  flex: 0,
};


export const PageCore = (props: {
  component: React.ElementType,
  currentApp?: NavItemApp,
  isFull: boolean,
  isMobile: boolean,
  children: React.ReactNode,
}) =>
  <Box
    component={props.component}
    sx={props.currentApp?.pageBrighter ? pageCoreBrighterSx : props.isFull ? pageCoreFullSx : pageCoreSx}
  >

    {/* Optional deployment MOTD */}
    {optimaHasMOTD && <OptimaMOTD />}

    {/* Responsive page bar (pluggable App Center Items and App Menu) */}
    <OptimaBar
      component='header'
      currentApp={props.currentApp}
      isMobile={props.isMobile}
      sx={pageCoreBarSx}
    />

    {/* Page (NextJS) must make the assumption they're in a flex-col layout */}
    {props.children}

    {/* [Mobile] Nav bar at the bottom */}
    {/*{!!props.isMobile && (*/}
    {/*  <MobileNav*/}
    {/*    component='nav'*/}
    {/*    currentApp={props.currentApp}*/}
    {/*    hideOnFocusMode*/}
    {/*    sx={pageCoreMobileNavSx}*/}
    {/*  />*/}
    {/*)}*/}

  </Box>;


================================================
FILE: src/common/layout/optima/PageWrapper.tsx
================================================
import * as React from 'react';

import { Box, Container } from '@mui/joy';

import type { NavItemApp } from '~/common/app.nav';
import { isPwa } from '~/common/util/pwaUtils';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { PageCore } from './PageCore';
import { useOptimaDrawerOpen, useOptimaPanelOpen } from './useOptima';


/**
 * Wraps the NextJS Page Component (from the pages router).
 *  - mobile: just the 100dvh pageCore
 *  - desktop: animated left margin (sync with the drawer) and centering via the Container, then the PageCore
 */
export function PageWrapper(props: { component: React.ElementType, currentApp?: NavItemApp, isMobile: boolean, children: React.ReactNode }) {

  // external state
  const isDrawerOpen = useOptimaDrawerOpen();
  const { panelShownAsPanel } = useOptimaPanelOpen(props.isMobile, props.currentApp);
  const amplitude = useUIPreferencesStore(state =>
    (isPwa() || props.isMobile || props.currentApp?.fullWidth) ? 'full' : state.centerMode,
  );

  // mobile: match the desktop container structure, to keep state across layour changes
  if (props.isMobile)
    return (
      <Box>
        <Container id='app-page-container' disableGutters maxWidth={false}>
          <PageCore component={props.component} currentApp={props.currentApp} isFull isMobile>
            {props.children}
          </PageCore>
        </Container>
      </Box>
    );

  const isFull = amplitude === 'full';

  return (

    // This wrapper widens the Container/PageCore when the drawer is closed
    <Box
      sx={{
        // full width (this is to the right of the fixed-size desktop drawer)
        flex: '1 1 0px',
        overflow: 'hidden',

        // when the drawer is off, compensate with a negative margin
        // NOTE: this will cause a transition on the container as well, meaning when we
        // resize the window, the contents will wobble slightly
        marginLeft: !isDrawerOpen // NOTE: we should have `|| isDrawerPeeking`, however it only happens when the drawer is in the closed state (e.g. OR is unnecessary)
          ? 'calc(-1 * var(--AGI-Desktop-Drawer-width))'
          : 0,
        marginRight: !panelShownAsPanel
          ? 'calc(-1 * var(--AGI-Desktop-Panel-width))'
          : 0,
        transition: 'margin-left 0.42s cubic-bezier(.17,.84,.44,1), margin-right 0.42s cubic-bezier(.17,.84,.44,1)',
        willChange: 'margin-left, margin-right',
      }}
    >

      <Container
        id='app-page-container'
        disableGutters
        maxWidth={isFull ? false : amplitude === 'narrow' ? 'md' : 'xl'}
        sx={{
          boxShadow: {
            xs: 'none',
            md: amplitude === 'narrow' ? '0px 0px 4px 0 rgba(50 56 62 / 0.12)' : 'none',
            xl: !isFull ? '0px 0px 4px 0 rgba(50 56 62 / 0.12)' : 'none',
          },
        }}
      >

        <PageCore component={props.component} currentApp={props.currentApp} isFull={isFull} isMobile={false}>
          {props.children}
        </PageCore>

      </Container>

    </Box>
  );
}


================================================
FILE: src/common/layout/optima/store-layout-optima.ts
================================================
import { create } from 'zustand';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { getIsMobile } from '~/common/components/useMatchMedia';
import { isBrowser } from '~/common/util/pwaUtils';
import { navItems } from '~/common/app.nav';

import { OPTIMA_OPEN_DEBOUNCE, OPTIMA_PEEK_HOVER_ENTER_DELAY, OPTIMA_PEEK_HOVER_ENTER_DELAY_PANEL, OPTIMA_PEEK_HOVER_TIMEOUT } from './optima.config';


export type PreferencesTabId = 'chat' | 'voice' | 'draw' | 'tools' | undefined;


interface OptimaState {

  // modes
  // isFocusedMode: boolean; // when active, the Mobile App menu is not displayed

  // panes
  drawerIsOpen: boolean;
  drawerIsPeeking: boolean;
  panelIsOpen: boolean;
  panelIsPeeking: boolean;

  // modals
  showAIXDebugger: boolean;
  showKeyboardShortcuts: boolean;
  showLogger: boolean;
  showModelOptions: DLLMId | false;
  showModels: boolean;
  showPreferences: boolean;
  preferencesTab: PreferencesTabId;

  // timing for panels
  lastDrawerOpenTime: number;
  lastPanelOpenTime: number;
}

function initialDrawerOpen() {
  // mobile: closed by default
  if (getIsMobile() || !isBrowser)
    return false;

  // desktop: open by default, unless the route has 'hideDrawer' set - then we boot to closed
  const bootNavItem = navItems.apps.find(item => item.route === window.location.pathname);
  return bootNavItem ? !bootNavItem.hideDrawer : false;
}

const modalsClosedState = {
  showAIXDebugger: false,
  showKeyboardShortcuts: false,
  showLogger: false,
  showModelOptions: false,
  showModels: false,
  showPreferences: false,
} as const;

const initialState: OptimaState = {

  // modes
  // isFocusedMode: false,

  // panes
  drawerIsOpen: initialDrawerOpen(),
  drawerIsPeeking: false,
  panelIsOpen: false,
  panelIsPeeking: false,

  // modals that can overlay anything
  ...modalsClosedState,
  preferencesTab: 'chat',

  // timings
  lastDrawerOpenTime: 0,
  lastPanelOpenTime: 0,
} as const;

export interface OptimaActions {

  // setIsFocusedMode: (isFocusedMode: boolean) => void;

  closeDrawer: () => void;
  openDrawer: () => void;
  toggleDrawer: () => void;
  peekDrawerEnter: () => void;
  peekDrawerLeave: () => void;

  closePanel: () => void;
  openPanel: () => void;
  togglePanel: () => void;
  peekPanelEnter: () => void;
  peekPanelLeave: () => void;

  closeAIXDebugger: () => void;
  openAIXDebugger: () => void;

  closeKeyboardShortcuts: () => void;
  openKeyboardShortcuts: () => void;

  closeLogger: () => void;
  openLogger: () => void;

  closeModelOptions: () => void;
  openModelOptions: (id: DLLMId) => void;

  closeModels: () => void;
  openModels: () => void;

  closePreferences: () => void;
  openPreferences: (changeTab?: PreferencesTabId) => void;

}


const drawerPeek = createPeekHandlers('drawerIsOpen', 'drawerIsPeeking');
const panelPeek = createPeekHandlers('panelIsOpen', 'panelIsPeeking', OPTIMA_PEEK_HOVER_ENTER_DELAY_PANEL);

function createPeekHandlers<
  TOpenKey extends keyof OptimaState,
  TPeekingKey extends keyof OptimaState,
>(isOpenKey: TOpenKey, isPeekingKey: TPeekingKey, overrideEnterDelay?: number) {
  let enterTimer: any = null;
  let leaveTimer: any = null;

  return {
    cancel: () => {
      clearTimeout(enterTimer);
      clearTimeout(leaveTimer);
      enterTimer = null;
      leaveTimer = null;
    },
    enter: (_get: () => OptimaState, _set: (state: Partial<OptimaState>) => void) => {
      clearTimeout(leaveTimer);
      leaveTimer = null;

      const state = _get();
      if (state[isOpenKey] || state[isPeekingKey]) return;

      clearTimeout(enterTimer);
      enterTimer = setTimeout(() => {
        _set({ [isPeekingKey]: true } as Partial<OptimaState>);
        enterTimer = null;
      }, overrideEnterDelay ?? OPTIMA_PEEK_HOVER_ENTER_DELAY);
    },
    leave: (_get: () => OptimaState, _set: (state: Partial<OptimaState>) => void) => {
      clearTimeout(enterTimer);
      enterTimer = null;

      const state = _get();
      if (!state[isPeekingKey]) return;

      clearTimeout(leaveTimer);
      leaveTimer = setTimeout(() => {
        _set({ [isPeekingKey]: false } as Partial<OptimaState>);
        leaveTimer = null;
      }, OPTIMA_PEEK_HOVER_TIMEOUT);
    },
  };
}


export const useLayoutOptimaStore = create<OptimaState & OptimaActions>((_set, _get) => ({

  ...initialState,

  // setIsFocusedMode: (isFocusedMode) => _set({ isFocusedMode }),

  closeDrawer: () => {
    // prevent accidental immediate close (e.g. double-click, animation protection)
    if (Date.now() - _get().lastDrawerOpenTime < OPTIMA_OPEN_DEBOUNCE) return;
    drawerPeek.cancel();
    _set({ drawerIsOpen: false, drawerIsPeeking: false });
  },
  openDrawer: () => {
    drawerPeek.cancel();
    _set({ drawerIsOpen: true, drawerIsPeeking: false, lastDrawerOpenTime: Date.now() });
  },
  toggleDrawer: () => _get().drawerIsOpen ? _get().closeDrawer() : _get().openDrawer(),
  peekDrawerEnter: () => drawerPeek.enter(_get, _set),
  peekDrawerLeave: () => drawerPeek.leave(_get, _set),

  closePanel: () => {
    // prevent accidental immediate close (e.g. double-click, animation protection)
    if (Date.now() - _get().lastPanelOpenTime < OPTIMA_OPEN_DEBOUNCE) return;
    panelPeek.cancel();
    _set({ panelIsOpen: false, panelIsPeeking: false });
  },
  openPanel: () => {
    panelPeek.cancel();
    _set({ panelIsOpen: true, panelIsPeeking: false, lastPanelOpenTime: Date.now() });
  },
  togglePanel: () => _get().panelIsOpen ? _get().closePanel() : _get().openPanel(),
  peekPanelEnter: () => panelPeek.enter(_get, _set),
  peekPanelLeave: () => panelPeek.leave(_get, _set),

  closeAIXDebugger: () => _set({ showAIXDebugger: false }),
  openAIXDebugger: () => _set({ ...modalsClosedState, showAIXDebugger: true }),

  closeKeyboardShortcuts: () => _set({ showKeyboardShortcuts: false }),
  openKeyboardShortcuts: () => _set({ showKeyboardShortcuts: true }),

  closeLogger: () => _set({ showLogger: false }),
  openLogger: () => _set({ ...modalsClosedState, showLogger: true }),

  closeModelOptions: () => _set({ showModelOptions: false }),
  openModelOptions: (id: DLLMId) => _set({ showModelOptions: id }),

  closeModels: () => _set({ showModels: false }),
  openModels: () => _set({ showModels: true }),

  closePreferences: () => _set({ showPreferences: false }),
  openPreferences: (tab) => _set({ showPreferences: true, ...(tab !== undefined && { preferencesTab: tab }) }),

}));



================================================
FILE: src/common/layout/optima/useOptima.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { OptimaActions, PreferencesTabId, useLayoutOptimaStore } from './store-layout-optima';
import { NavItemApp } from '~/common/app.nav';
import { useOptimaPortalHasInputs } from '~/common/layout/optima/portals/useOptimaPortalHasInputs';


// Drawer

export function optimaCloseDrawer() {
  useLayoutOptimaStore.getState().closeDrawer();
}

export function optimaOpenDrawer(event?: React.MouseEvent) {
  _eatMouseEvent(event);
  useLayoutOptimaStore.getState().openDrawer();
}

export function optimaToggleDrawer(event?: React.MouseEvent) {
  _eatMouseEvent(event);
  useLayoutOptimaStore.getState().toggleDrawer();
}

export function useOptimaDrawerOpen() {
  return useLayoutOptimaStore(({ drawerIsOpen }) => drawerIsOpen);
}

export function useOptimaDrawerPeeking() {
  return useLayoutOptimaStore(({ drawerIsPeeking }) => drawerIsPeeking);
}


// Panel

export function optimaClosePanel() {
  useLayoutOptimaStore.getState().closePanel();
}

export function optimaOpenPanel(event?: React.MouseEvent) {
  _eatMouseEvent(event);
  useLayoutOptimaStore.getState().openPanel();
}

export function optimaTogglePanel(event?: React.MouseEvent) {
  _eatMouseEvent(event);
  useLayoutOptimaStore.getState().togglePanel();
}

export function useOptimaPanelOpen(isMobile: boolean, currentApp?: NavItemApp) {
  const { panelIsOpen, panelIsPeeking } = useLayoutOptimaStore(useShallow(state => ({
    panelIsOpen: state.panelIsOpen,
    panelIsPeeking: state.panelIsPeeking,
  })));
  const panelAsPopup = !isMobile && currentApp?.panelAsMenu === true;
  const panelHasContent = useOptimaPortalHasInputs('optima-portal-panel') || isMobile;

  return {
    panelIsOpen,
    panelAsPopup,
    panelHasContent,
    panelShownAsPanel: panelIsOpen && panelHasContent && !panelAsPopup,
    panelShownAsPeeking: panelIsPeeking && !panelIsOpen && panelHasContent && !panelAsPopup,
    panelShownAsPopup: panelIsOpen && panelHasContent && panelAsPopup,
  };
}


// Modals

export function optimaActions(): Omit<OptimaActions,
  | 'closeDrawer' | 'openDrawer' | 'toggleDrawer'
  | 'closePanel' | 'openPanel' | 'togglePanel'
  | 'openModels'
  | 'openPreferences'
> {
  return useLayoutOptimaStore.getState();
}

export function optimaOpenModels() {
  useLayoutOptimaStore.getState().openModels();
}

export function optimaOpenPreferences(changeTab?: PreferencesTabId) {
  useLayoutOptimaStore.getState().openPreferences(changeTab);
}

export function useOptimaModals() {
  return useLayoutOptimaStore(useShallow(state => ({
    showAIXDebugger: state.showAIXDebugger,
    showKeyboardShortcuts: state.showKeyboardShortcuts,
    showLogger: state.showLogger,
    showModelOptions: state.showModelOptions,
    showModels: state.showModels,
    showPreferences: state.showPreferences,
    preferencesTab: state.preferencesTab,
  })));
}


// helpers

function _eatMouseEvent(event?: (React.MouseEvent | React.TouchEvent)) {
  if (event) {
    if ('preventDefault' in event) event.preventDefault();
    // if ('stopPropagation' in event) event.stopPropagation();
  }
}



================================================
FILE: src/common/layout/optima/bar/OptimaBar.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, IconButton, Typography } from '@mui/joy';
import ArrowBackIcon from '@mui/icons-material/ArrowBack';
import MenuIcon from '@mui/icons-material/Menu';
import MoreVertIcon from '@mui/icons-material/MoreVert';
import NavigateNextIcon from '@mui/icons-material/NavigateNext';

import { BigAgiSquircleIcon } from '~/common/components/icons/big-agi/BigAgiSquircleIcon';
import { Brand } from '~/common/app.config';
import { LayoutSidebarRight } from '~/common/components/icons/LayoutSidebarRight';
import { Link } from '~/common/components/Link';
import { checkVisibleNav, NavItemApp } from '~/common/app.nav';
import { navigateToIndex, ROUTE_INDEX } from '~/common/app.routes';

import { InvertedBar, InvertedBarCornerItem } from '../InvertedBar';
import { PopupPanel } from '../panel/PopupPanel';
import { optimaActions, optimaOpenDrawer, optimaOpenPanel, optimaTogglePanel, useOptimaPanelOpen } from '../useOptima';
import { useOptimaPortalHasInputs } from '../portals/useOptimaPortalHasInputs';
import { useOptimaPortalOutRef } from '../portals/useOptimaPortalOutRef';


// Center Items (Portal)

const centerItemsContainerSx: SxProps = {
  flexGrow: 1,
  minHeight: 'var(--Bar)',
  display: 'flex', flexFlow: 'row wrap', justifyContent: 'center', alignItems: 'center',
  my: 'auto',
  gap: { xs: 0, md: 1 },
  // ensure we can keep the plugged center bars in check
  overflow: 'hidden',
  // [electron] make the blank part of the bar draggable (and not the contents)
  WebkitAppRegion: 'drag',
  '& > *': { WebkitAppRegion: 'no-drag' },
};

function CenterItemsPortal(props: { currentApp?: NavItemApp }) {

  // external state
  const portalToolbarRef = useOptimaPortalOutRef('optima-portal-toolbar', 'PageBar.CenterItemsContainer');
  const hasInputs = useOptimaPortalHasInputs('optima-portal-toolbar');

  return (
    <Box ref={portalToolbarRef} sx={centerItemsContainerSx}>

      {/* Only if nobody's injecting in the Toolbar portal, show the fallback */}
      {!hasInputs && <CenterItemsFallback currentApp={props.currentApp} />}

    </Box>
  );
}

function CenterItemsFallback(props: { currentApp?: NavItemApp }) {
  return <Box sx={{
    display: 'flex',
    alignItems: 'center',
    gap: { xs: 1, md: 2 },
  }}>

    {/* Squircle */}
    <Link href={ROUTE_INDEX}>
      <BigAgiSquircleIcon inverted sx={{ width: 32, height: 32, color: 'white' }} />
    </Link>

    {/* Title */}
    <Typography level='title-md'>
      {props.currentApp?.barTitle || props.currentApp?.name || Brand.Title.Base}
    </Typography>

  </Box>;
}


/**
 * Top bar displayed on the Optima Layout
 */
export function OptimaBar(props: { component: React.ElementType, currentApp?: NavItemApp, isMobile: boolean, sx?: SxProps }) {

  // state
  const appMenuAnchor = React.useRef<HTMLButtonElement>(null);

  // external state
  const hasDrawerContent = useOptimaPortalHasInputs('optima-portal-drawer');
  const { panelAsPopup, panelHasContent, panelShownAsPanel, panelShownAsPeeking, panelShownAsPopup } = useOptimaPanelOpen(props.isMobile, props.currentApp);

  // derived state
  const navIsShown = checkVisibleNav(props.currentApp);

  // [Desktop] optionally hide the Bar if the current app asks for it
  if (props.currentApp?.hideBar && !props.isMobile && !panelHasContent)
    return null;

  return <>

    {/* Bar: [Drawer control] [Center Items] [Panel/Menu control] */}
    <InvertedBar component={props.component} direction='horizontal' sx={props.sx}>

      {/* [Mobile] Drawer button */}
      {(props.isMobile || !navIsShown) && (
        <InvertedBarCornerItem>
          {(hasDrawerContent && navIsShown) ? (
            // show the drawer button
            <IconButton disabled={!hasDrawerContent} onPointerDown={optimaOpenDrawer}>
              <MenuIcon />
            </IconButton>
          ) : (
            // back button
            <IconButton onClick={() => navigateToIndex()}>
              <ArrowBackIcon />
            </IconButton>
          )}
        </InvertedBarCornerItem>
      )}

      {/* Pluggable Toolbar Items */}
      <CenterItemsPortal currentApp={props.currentApp} />

      {/* We used to have the Preview (lightbulb) menu here */}

      {/* Panel Open: has content always on Mobile (the app menu) */}
      {panelHasContent && (
        <InvertedBarCornerItem
           onMouseEnter={(props.isMobile || panelAsPopup || panelShownAsPanel) ? undefined : optimaActions().peekPanelEnter}
           onMouseLeave={(props.isMobile || panelShownAsPeeking) ? undefined : optimaActions().peekPanelLeave}
        >
          {/*<Tooltip disableInteractive title={contentToPopup ? (panelIsOpen ? 'Close' : 'Open') + ' Menu' : (panelIsOpen ? 'Close' : 'Open')}>*/}
          <IconButton
            ref={appMenuAnchor}
            // disabled={contentToPopup ? !appMenuAnchor : false}
            onClick={optimaTogglePanel /* onPointerDown doesn't work well with a menu (the 'up' event would close it), so we're still with onClick */}
            onContextMenu={optimaOpenPanel /* important to get the 'preventDefault' for the Right mouse click (to prevent the menu) */}
          >
            {panelShownAsPanel ? <NavigateNextIcon />
              : panelAsPopup ? <MoreVertIcon />
                : <LayoutSidebarRight /> /* aa*/} {/* WindowPaneRightOpen */}
          </IconButton>
          {/*</Tooltip>*/}
        </InvertedBarCornerItem>
      )}

    </InvertedBar>

    {/* Use a Popup containing the Panel Portal */}
    {panelShownAsPopup && !!appMenuAnchor.current && <PopupPanel anchorEl={appMenuAnchor.current} />}

  </>;
}


================================================
FILE: src/common/layout/optima/bar/OptimaBarDropdown.tsx
================================================
import * as React from 'react';

import type { SelectSlotsAndSlotProps } from '@mui/joy/Select/SelectProps';
import { Box, ListDivider, listItemButtonClasses, ListItemDecorator, listItemDecoratorClasses, Option, optionClasses, Select, selectClasses } from '@mui/joy';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';


// set to true to enable the dense mode, which is default in the rest of the app
const useDenseDropdowns = false;
// set to false to use normal icons - check with similar menus
const useBigIcons = true;


export const optimaSelectSlotProps: SelectSlotsAndSlotProps<false>['slotProps'] = {
  root: {
    sx: {
      backgroundColor: 'transparent',
      // minWidth: selectMinWidth, // 160
      maxWidth: 'calc(100dvw - 4.5rem)', /* 36px * 2 buttons (2 * var(--Bar)) */
      // disappear when the 'agi-gone' class is set
      '&.agi-gone': {
        display: 'none',
      } as const,
    } as const,
  } as const,

  button: {
    className: 'agi-ellipsize',
    sx: {
      // these + the ellipsize class will ellipsize the text in the button
      display: 'inline-block',
      maxWidth: 300,
    } as const,
  } as const,

  indicator: {
    sx: {
      // additive white 50%
      color: 'rgba(255 255 255 / 0.5)',
      // revolves around when clicked
      transition: '0.2s',
      [`&.${selectClasses.expanded}`]: {
        transform: 'rotate(-180deg)',
      } as const,
    } as const,
  } as const,

  listbox: {
    // Note: we explored disablePortal, which could optimize performance, but it breaks the colors (as they'll look inverted)
    // disablePortal: false,
    variant: 'outlined',
    sx: {
      // in sync with CloseableMenu
      '--ListItem-minHeight': useDenseDropdowns
        ? '2.25rem' /* 2.25 is the default */
        : '2.75rem', /* we enlarge the default  */
      ...(useBigIcons && {
        '--Icon-fontSize': 'var(--joy-fontSize-xl2)',
        // '--ListItemDecorator-size': '2.75rem',
      }),

      // transfer the padding onto the scrollable box
      paddingBlock: 0,

      // v-size: do not exceed the height of the screen
      maxHeight: 'calc(100dvh - 56px - 24px)',

      // Option: clip width to 160...360px
      [`& .${optionClasses.root}`]: {
        maxWidth: 'min(360px, calc(100dvw - 1rem))',
        minWidth: 200,
      } as const,

      // Decorator: icon size
      [`& .${listItemDecoratorClasses.root}`]: {
        fontSize: 'var(--joy-fontSize-lg)',
      } as const,

      // Button styles
      [`& .${listItemButtonClasses.root}`]: {
        minWidth: 200,
      } as const,
    } as const,
  } as const,
} as const;

const _styles = {

  prependGap: {
    height: 'var(--ListDivider-gap)',
  } as const,

  itemsScrollable: {
    overflow: 'auto',
    paddingBlock: 'var(--ListDivider-gap)',
  } as const,

  divider: {
    my: 0,
  } as const,

} as const;


export type OptimaDropdownItems = Record<string, {
  title: string,
  symbol?: string,
  type?: 'separator'
  icon?: React.ReactNode,
}>;


export const OptimaBarDropdownMemo = React.memo(React.forwardRef(OptimaBarDropdown));

export type OptimaBarControlMethods = {
  openListbox: () => void,
  // closeListbox: () => void,
};

/**
 * A Select component that blends-in nicely (cleaner, easier to the eyes)
 */
function OptimaBarDropdown<TValue extends string>(props: {
  // required
  items: OptimaDropdownItems,
  value: undefined | TValue | null, // undefined means no value is present, null means 'no/unset/force-empty' value
  onChange: (value: TValue | null) => void,
  // optional
  activeEndDecorator?: React.JSX.Element,
  prependOption?: React.JSX.Element
  appendOption?: React.JSX.Element,
  placeholder?: string,
  showSymbols?: boolean | 'compact',
  showGone?: boolean,
}, ref: React.Ref<OptimaBarControlMethods>) {

  // state
  const [listboxOpen, setListboxOpen] = React.useState(false);

  // Expose control methods via the ref
  React.useImperativeHandle(ref, () => ({
    openListbox: () => {
      setListboxOpen(true);
    },
    // closeListbox: () => {
    //   setListboxOpen(false);
    // },
  }), []);

  // derived state
  const { onChange } = props;

  const handleOnChange = React.useCallback((_event: any, value: TValue | null) => {
    onChange(value);
  }, [onChange]);

  const handleOnOpenChange = React.useCallback((isOpen: boolean) => {
    if (isOpen !== listboxOpen)
      setListboxOpen(isOpen);
  }, [listboxOpen]);

  const itemsKeys = Object.keys(props.items);
  const hasItems = itemsKeys.length >= 1;

  return (
    <Select
      variant='plain'
      value={props.value ?? null /* remove 'undefined' as an option */}
      onChange={handleOnChange}
      placeholder={props.placeholder}
      listboxOpen={listboxOpen}
      onListboxOpenChange={handleOnOpenChange}
      indicator={<KeyboardArrowDownIcon />}
      slotProps={optimaSelectSlotProps}
      className={props.showGone ? 'agi-gone' : ''}
    >

      {/* Prepender */}
      {!!props.prependOption && <Box sx={_styles.prependGap} />}
      {props.prependOption}
      {/*{!!props.prependOption && hasItems && <ListDivider sx={_styles.divider} />}*/}

      {/* Scrollable Items list*/}
      {hasItems && <Box sx={_styles.itemsScrollable}>
        {itemsKeys.map((_itemKey: string, idx: number) => {
          const _item = props.items[_itemKey];
          const isActive = _itemKey === props.value;

          // Label & Decorators
          const safeTitle = _item.title || '';
          const label = (props.showSymbols && _item.symbol && !(_item.title === 'Default' && _item.symbol === '🧠')) ? `${_item.symbol} ${safeTitle}` : safeTitle;
          const iconOrSymbol = _item.icon || _item.symbol || '';

          return _item.type === 'separator' ? (
            <ListDivider key={_itemKey || `sep-${idx}`}>
              {/*<Box sx={{ display: 'flex', alignItems: 'center', gap: 1, '--Icon-fontSize': 'var(--joy-fontSize-lg)' }}>*/}
              {/*{_item.icon} */}
              {_item.title}
              {/*</Box>*/}
            </ListDivider>
          ) : (
            <Option key={_itemKey} value={_itemKey} label={label}>
              {/* Icon / Symbol */}
              {(props.showSymbols === true || (props.showSymbols === 'compact' && !!iconOrSymbol)) && <ListItemDecorator>
                {iconOrSymbol}
              </ListItemDecorator>}

              {/* Text */}
              <div className='agi-ellipsize'>{safeTitle}</div>

              {/* Optional End Decorator */}
              {isActive && props.activeEndDecorator}
            </Option>
          );
        })}
      </Box>}

      {/* Appender */}
      {!!props.appendOption && hasItems && <ListDivider sx={_styles.divider} />}
      {props.appendOption}
      {/*{!!props.appendOption && <Box sx={{ height: 'var(--ListDivider-gap)' }} />}*/}

    </Select>
  );
}


================================================
FILE: src/common/layout/optima/drawer/DesktopDrawer.tsx
================================================
import * as React from 'react';

import { Box, Sheet, styled } from '@mui/joy';

import { checkVisibleNav, NavItemApp } from '~/common/app.nav';
import { themeZIndexDesktopDrawer } from '~/common/app.theme';

import { OPTIMA_DRAWER_BACKGROUND } from '../optima.config';
import { optimaCloseDrawer, optimaOpenDrawer, useOptimaDrawerOpen, useOptimaDrawerPeeking } from '../useOptima';
import { useOptimaPortalOutRef } from '../portals/useOptimaPortalOutRef';


// Desktop Drawer

const DesktopDrawerFixRoot = styled(Box)({
  // fix the drawer size
  width: 'var(--AGI-Desktop-Drawer-width)',
  flexShrink: 0,
  flexGrow: 0,

  // Base state
  zIndex: themeZIndexDesktopDrawer,

  '&[data-closed="true"]': {
    contain: 'strict',
    pointerEvents: 'none',
  },

  '&.drawer-peeking': {
    zIndex: themeZIndexDesktopDrawer + 1, // elevate z-index when peeking
  },
});

const DesktopDrawerTranslatingSheet = styled(Sheet)(({ theme }) => ({
  // layout
  width: '100%',
  height: '100dvh',
  zIndex: 1, // just to allocate a layer; this was: themeZIndexDesktopDrawer

  // styling
  backgroundColor: OPTIMA_DRAWER_BACKGROUND,
  borderRight: '1px solid',
  // the border right color is from: theme.palette.divider, which is this /0.2 (light) and /0.16 (dark)
  borderRightColor: 'rgba(var(--joy-palette-neutral-mainChannel, 99 107 116) / 0.4)',
  // borderTopRightRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
  // borderBottomRightRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
  // contain: 'strict',
  // boxShadow: theme.shadow.md, // too thin and complex; also tried 40px blurs
  boxShadow: `0px 0px 6px 0 rgba(${theme.palette.neutral.darkChannel} / 0.12)`,

  // content layout
  display: 'flex',
  flexDirection: 'column',


  // base state (normal open/close, and peeking exit)
  transform: 'none',
  transition: 'transform 0.42s cubic-bezier(.17,.84,.44,1), box-shadow 0.42s cubic-bezier(.17,.84,.44,1)',
  willChange: 'transform, box-shadow',

  // Closed state via data attribute
  '&[data-closed="true"]': {
    transform: 'translateX(-101%)', // the extra 1% takes care of fractional units (custom monitor scaling)
    borderRightColor: 'transparent',
  },

  // Peek state via class
  '&.drawer-peeking': {
    transition: 'transform 0.25s cubic-bezier(.4,0,.2,1)', // faster enter animation, shadow as-is
    boxShadow: '0 0 48px rgba(var(--joy-palette-primary-mainChannel) / 0.6)', // stronger shadow when peeking, was theme.shadow.lg
    borderRightColor: 'transparent',
  },
})) as typeof Sheet;


export function DesktopDrawer(props: { component: React.ElementType, currentApp?: NavItemApp }) {

  // state
  const drawerPortalRef = useOptimaPortalOutRef('optima-portal-drawer', 'DesktopDrawer');

  // external state
  const _isDrawerOpen = useOptimaDrawerOpen();
  const isDrawerPeeking = useOptimaDrawerPeeking();
  const isDrawerOpen = _isDrawerOpen || isDrawerPeeking;
  // const hasDrawerContent = useOptimaPortalHasInputs('optima-portal-drawer');


  // Desktop-only?: close the drawer if the current app doesn't use it
  const currentAppUsesDrawer = !props.currentApp?.hideDrawer;
  React.useEffect(() => {
    if (!currentAppUsesDrawer)
      optimaCloseDrawer();
  }, [currentAppUsesDrawer]);

  // [special case] remove in the future
  const shallOpenNavForSharedLink = !props.currentApp?.hideDrawer && checkVisibleNav(props.currentApp);
  React.useEffect(() => {
    if (shallOpenNavForSharedLink)
      optimaOpenDrawer();
  }, [shallOpenNavForSharedLink]);


  return (
    <DesktopDrawerFixRoot
      data-closed={!isDrawerOpen}
      className={isDrawerPeeking ? 'drawer-peeking' : undefined}
    >

      <DesktopDrawerTranslatingSheet
        ref={drawerPortalRef}
        component={props.component}
        data-closed={!isDrawerOpen}
        className={isDrawerPeeking ? 'drawer-peeking' : undefined}
      >

        {/* NOTE: this sort of algo was not used when we migrated this to Portals on 2024-07-30, so not restoring it ... */}
        {/*/!* [UX Responsiveness] Keep Mounted for now *!/*/}
        {/*{(!softDrawerUnmount || isDrawerOpen || !UNMOUNT_DELAY_MS) &&*/}
        {/*  appDrawerContent*/}
        {/*}*/}

      </DesktopDrawerTranslatingSheet>

    </DesktopDrawerFixRoot>
  );
}


================================================
FILE: src/common/layout/optima/drawer/MobileDrawer.tsx
================================================
import * as React from 'react';

import { Box, Drawer } from '@mui/joy';

import type { NavItemApp } from '~/common/app.nav';

import { MobileNavItems } from '../nav/MobileNavItems';
import { OPTIMA_DRAWER_BACKGROUND, OPTIMA_DRAWER_MOBILE_RADIUS } from '../optima.config';
import { optimaCloseDrawer, useOptimaDrawerOpen } from '../useOptima';
import { useOptimaPortalOutRef } from '../portals/useOptimaPortalOutRef';


function DrawerContentPortal() {
  const drawerPortalRef = useOptimaPortalOutRef('optima-portal-drawer', 'MobileDrawer');
  return (
    <Box
      ref={drawerPortalRef}
      sx={{
        // make this compressible
        overflow: 'hidden',
        // expand to fix - note: relies on contents being scrollable
        flex: 1,
        // layout: column
        display: 'flex',
        flexDirection: 'column',
        // (optional) style: cast shadow to the nav items
        // zIndex: 1,
        // boxShadow: '0 2px 4px rgb(var(--joy-palette-neutral-darkChannel) / 14%)',
      }}
    />
  );
}

export function MobileDrawer(props: { component: React.ElementType, currentApp?: NavItemApp }) {

  // external state
  const isDrawerOpen = useOptimaDrawerOpen();

  /* NOTE on `disableEnforceFocus`:
   * This is a workaround for mobile drawer focus issues, when pressing the 3-dot menu button
   * on the `Search...` input field will flash-and-hide the menu.
   *
   * This prop disables the default focus trap behavior of the Drawer.
   * It allows focus to move freely outside the Drawer, which is useful
   * when the Drawer contains components (like Menus) that need to manage
   * their own focus.
   *
   * This prevents unexpected focus resets to the Drawer content when interacting with
   * nested interactive elements.
   *
   * See also `windowUtils.useDocumentFocusDebugger` for debugging focus issues.
   */
  return (
    <Drawer
      id='mobile-drawer'
      component={props.component}
      disableEnforceFocus
      open={isDrawerOpen}
      onClose={optimaCloseDrawer}
      sx={{
        '--Drawer-horizontalSize': 'round(clamp(30%, var(--AGI-Mobile-Drawer-width), 100%), 1px)',
        '--Drawer-transitionDuration': '0.2s',
        // '& .MuiDrawer-paper': {
        //   width: 256,
        //   boxSizing: 'border-box',
        // },
      }}
      slotProps={{
        backdrop: {
          sx: {
            backdropFilter: 'none',
          },
        },
        content: {
          sx: {
            // style: round the right drawer corners
            backgroundColor: OPTIMA_DRAWER_BACKGROUND,
            borderTopRightRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
            borderBottomRightRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
            // boxShadow: 'none',
          },
        },
      }}
    >

      {/* Insertion point for the Drawer - expands even if empty */}
      <DrawerContentPortal />

      {/* [Mobile] Nav Items */}
      <MobileNavItems currentApp={props.currentApp} />

    </Drawer>
  );
}



================================================
FILE: src/common/layout/optima/drawer/OptimaDrawerHeader.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, IconButton, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';

import { Link } from '~/common/components/Link';


export const OptimaDrawerHeader = (props: {
  title: string,
  onClose: () => void,
  onTitleClick?: () => void,
  sx?: SxProps,
  children?: React.ReactNode,
}) =>
  <Box
    // variant='soft'
    // invertedColors
    sx={{
      minHeight: 'var(--AGI-Nav-width)',
      px: 1,

      // style
      backgroundColor: 'background.popup',
      // borderLeft: 'none',
      // borderRight: 'none',
      // borderTop: 'none',
      // borderTopRightRadius: OPTIMA_DRAWER_MOBILE_RADIUS,

      // layout
      display: 'flex',
      alignItems: 'center',
      justifyContent: 'space-between',
    }}
  >

    {props.children || <IconButton disabled />}

    {props.onTitleClick ? (
      <Link href='#' color='neutral' onClick={props.onTitleClick}>
        <Typography level='title-md'>
          {props.title}
        </Typography>
      </Link>) : (
      <Typography level='title-md'>
        {props.title}
      </Typography>
    )}

    <IconButton aria-label='Close Drawer' size='sm' onClick={props.onClose}>
      <CloseRoundedIcon />
    </IconButton>

  </Box>;


================================================
FILE: src/common/layout/optima/drawer/OptimaDrawerList.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { ColorPaletteProp, List, VariantProp } from '@mui/joy';


export const PageDrawerTallItemSx: SxProps = {
  // TODO: start from this to update the buttons/listbuttons sizes and have uniformity
  '--ListItem-minHeight': '2.75rem',
};


/**
 * Used by pluggable layouts to have a standardized list appearance
 */
export function OptimaDrawerList(props: {
  variant?: VariantProp,
  color?: ColorPaletteProp,
  onClick?: () => void,
  largeIcons?: boolean,
  tallRows?: boolean,
  noTopPadding?: boolean,
  noBottomPadding?: boolean,
  children: React.ReactNode
}) {


  // memoize the Sx for stability
  const sx: SxProps = React.useMemo(() => ({
    // size of the list items
    '--List-radius': 0,
    ...props.largeIcons && {
      '--Icon-fontSize': 'var(--joy-fontSize-xl2)',
      // '--ListItemDecorator-size': '2.75rem', // icon width
    },
    ...(props.tallRows && PageDrawerTallItemSx),

    // style
    // backgroundColor: 'background.popup', // no need, the desktop/mobile drawer already has background
    border: 'none',
    // borderBottomRightRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
    ...(!!props.noTopPadding && { pt: 0 }),
    ...(!!props.noBottomPadding && { pb: 0 }),

    // clipping/scrolling
    overflow: 'hidden',
  }), [props.largeIcons, props.tallRows, props.noTopPadding, props.noBottomPadding]);


  return (
    <List
      variant={props.variant}
      color={props.color}
      onClick={props.onClick}
      sx={sx}
    >
      {props.children}
    </List>
  );
}


================================================
FILE: src/common/layout/optima/nav/BringTheLove.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Button, Tooltip } from '@mui/joy';

import { Link } from '~/common/components/Link';
import { animationColorRainbow } from '~/common/util/animUtils';

import { DesktopNavIcon, navItemClasses } from './DesktopNavIcon';


export function BringTheLove(props: { text: string, link: string, asIcon?: boolean, icon: React.FC, sx?: SxProps }) {
  // state
  const [loved, setLoved] = React.useState(false);

  // reset loved after 6.9 seconds
  React.useEffect(() => {
    if (loved) {
      const timer = setTimeout(() => setLoved(false), 6900 + 420);
      return () => clearTimeout(timer);
    }
  }, [loved]);

  const icon = loved ? '❤️' : props.icon ? <props.icon /> : null; // '❤️' : '🤍';

  return (
    <Tooltip title={props.text}>
      {props.asIcon ? (
        <DesktopNavIcon
          variant='solid'
          className={navItemClasses.typeLinkOrModal}
          component={Link} href={props.link} target='_blank'
          onClick={() => setLoved(true)}
          sx={{
            background: 'transparent',
            // color: 'text.tertiary',
            '&:hover': {
              animation: `${animationColorRainbow} 5s linear infinite`,
            },
          }}
        >
          {icon}
        </DesktopNavIcon>
      ) : (
        <Button
          variant='plain'
          color='neutral'
          component={Link} href={props.link} target='_blank' noLinkStyle
          onClick={() => setLoved(true)}
          sx={{
            '&:hover': { animation: `${animationColorRainbow} 5s linear infinite` },
            ...props.sx,
          }}
        >
          {props.text}
          {/*{icon}*/}
        </Button>
      )}
    </Tooltip>
  );
}


================================================
FILE: src/common/layout/optima/nav/DesktopNav.tsx
================================================
import * as React from 'react';
import Router from 'next/router';

import type { SxProps } from '@mui/joy/styles/types';
import { Divider, Dropdown, ListDivider, ListItem, ListItemButton, ListItemDecorator, Menu, MenuButton, MenuItem, Tooltip, Typography } from '@mui/joy';
import CodeIcon from '@mui/icons-material/Code';
import HistoryIcon from '@mui/icons-material/History';
import LightbulbOutlinedIcon from '@mui/icons-material/LightbulbOutlined';
import MenuIcon from '@mui/icons-material/Menu';
import PushPinOutlinedIcon from '@mui/icons-material/PushPinOutlined';

import { blocksRenderHTMLIFrameCss } from '~/modules/blocks/code/code-renderers/RenderCodeHtmlIFrame';

import { BuildInfoCard } from '../../../../apps/news/AppNews';

import { BaseProduct } from '~/common/app.release';
import { BigAgiSquircleIcon } from '~/common/components/icons/big-agi/BigAgiSquircleIcon';
import { FeatureBadge } from '~/common/components/FeatureBadge';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { PhSquaresFour } from '~/common/components/icons/phosphor/PhSquaresFour';
import { checkDivider, checkVisibileIcon, NavItemApp, navItems } from '~/common/app.nav';
import { themeZIndexDesktopNav } from '~/common/app.theme';
import { useHasLLMs } from '~/common/stores/llms/llms.hooks';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';

import { BringTheLove } from './BringTheLove';
import { DesktopNavGroupBox, DesktopNavIcon, navItemClasses } from './DesktopNavIcon';
import { InvertedBar, InvertedBarCornerItem } from '../InvertedBar';
import { optimaActions, optimaOpenModels, optimaOpenPreferences, optimaToggleDrawer, useOptimaDrawerOpen, useOptimaDrawerPeeking, useOptimaModals } from '../useOptima';
import { scratchClipSupported, useScratchClipVisibility } from '../scratchclip/store-scratchclip';


const desktopNavBarSx: SxProps = {
  zIndex: themeZIndexDesktopNav,
};

const bottomGroupSx: SxProps = {
  mb: 'calc(2 * var(--GroupMarginY))',
};

const navItemsDividerSx: SxProps = {
  my: 1,
  width: '50%',
  mx: 'auto',
};


export function DesktopNav(props: { component: React.ElementType, currentApp?: NavItemApp }) {

  // state
  const [releaseNotesShown, setReleaseNotesShown] = React.useState(false);

  /**
   * NOTE: shall we fall back to the 'standard' release notes when not available on the tenant?
   * - prob not because this could be a per-company deployment, and we don't know the tenant's release notes
   */
  const releaseNotesUrl = BaseProduct.ReleaseNotes;

  // external state
  const isDrawerOpen = useOptimaDrawerOpen();
  const isDrawerPeeking = useOptimaDrawerPeeking();
  const { showPromisedOverlay } = useOverlayComponents();
  const { showModels, showPreferences } = useOptimaModals();
  const { peekDrawerEnter, peekDrawerLeave } = optimaActions();
  const { isVisible: isScratchClipVisible, toggleVisibility: toggleScratchClipVisibility } = useScratchClipVisibility();

  // derived state
  const noLLMs = !useHasLLMs();


  // handlers

  const handleShowReleaseNotes = React.useCallback(async () => {
    if (!releaseNotesUrl) return;
    setReleaseNotesShown(true);
    return await showPromisedOverlay('app-recent-changes', { rejectWithValue: false }, ({ onUserReject }) =>
      <GoodModal
        open
        onClose={onUserReject}
        noTitleBar
        themedColor='neutral'
        unfilterBackdrop
        sx={{ minWidth: { xs: 400, sm: 580, md: 780, lg: 890 } }}
      >
        <iframe
          src={releaseNotesUrl}
          style={{ ...blocksRenderHTMLIFrameCss, height: '70svh' }}
          title='Release Notes Embed'
          loading='lazy' // do not load until visible in the viewport
        />
      </GoodModal>,
    );
  }, [releaseNotesUrl, showPromisedOverlay]);

  const handleShowTechnologies = React.useCallback(async () => {
    return await showPromisedOverlay<boolean>('app-recent-changes', { rejectWithValue: false }, ({ onUserReject }) =>
      <GoodModal open onClose={onUserReject} noTitleBar unfilterBackdrop>
        <BuildInfoCard noMargin />
      </GoodModal>,
    );
  }, [showPromisedOverlay]);


  // show/hide the pane when clicking on the logo
  const appUsesDrawer = !props.currentApp?.hideDrawer;
  const logoButtonTogglesPane = (appUsesDrawer && !isDrawerOpen) || isDrawerOpen;


  // App items
  const navAppItems = React.useMemo(() => {

    // group apps into visible (rendered as of now) and overflow (rendered with a dropdown menu)
    let crossedDivider = false;
    const visibleApps: NavItemApp[] = [];
    const overflowApps: NavItemApp[] = [];

    navItems.apps.forEach((app) => {
      if (checkVisibileIcon(app, false, props.currentApp)) {
        if (!crossedDivider || app === props.currentApp)
          visibleApps.push(app);
        else
          overflowApps.push(app);
        crossedDivider = crossedDivider || checkDivider(app);
      }
    });

    // Application buttons (and group separator)
    const components: React.JSX.Element[] = visibleApps.map((app, appIdx) => {
      const isActive = app === props.currentApp;
      const isDrawerable = isActive && !app.hideDrawer;
      const isPaneOpen = isDrawerable && isDrawerOpen;

      if (checkDivider(app))
        return <Divider key={'app-sep-' + appIdx} sx={navItemsDividerSx} />;

      return (
        <Tooltip key={'n-m-' + app.route.slice(1)} disableInteractive enterDelay={600} title={app.name + (app.isDev ? ' [DEV]' : '')}>
          <DesktopNavIcon
            variant={isActive ? 'solid' : undefined}
            onPointerDown={isDrawerable ? optimaToggleDrawer : () => Router.push(app.landingRoute || app.route)}
            className={`${navItemClasses.typeApp} ${isActive ? navItemClasses.active : ''} ${isPaneOpen ? navItemClasses.paneOpen : ''} ${app.isDev ? navItemClasses.dev : ''}`}
            sx={appIdx !== 0 ? undefined : { '--Icon-fontSize': '1.375rem!important' /* temp patch for the first icon, to go at 22px rather than 1.25rem (20px) */ }}
          >
            {(isActive && app.iconActive) ? <app.iconActive /> : <app.icon />}
            {/*<app.icon />*/}
          </DesktopNavIcon>
        </Tooltip>
      );
    });

    components.push(
      <Dropdown key='nav-quick-menu'>

        <Tooltip disableInteractive enterDelay={600} title='Apps & Tools'>
          <MenuButton slots={{ root: DesktopNavIcon }} slotProps={{ root: { className: navItemClasses.typeApp } }}>
            <PhSquaresFour />
          </MenuButton>
        </Tooltip>

        <Menu
          variant="outlined"
          placement="right-start"
          popperOptions={{ modifiers: [{ name: 'offset', options: { offset: [0, -2] } }] }}
          sx={{ minWidth: 260 }}
        >

          {/* APPS Section */}
          {overflowApps.length > 0 && (
            <>
              <ListItem>
                <Typography level="body-xs" sx={{ textTransform: 'uppercase', fontWeight: 600 }}>
                  Apps
                </Typography>
              </ListItem>
              {overflowApps.map((app, appIdx) =>
                <MenuItem key={'nav-app-extra-' + appIdx} onClick={() => Router.push(app.landingRoute || app.route)}>
                  <ListItemDecorator>
                    <app.icon />
                  </ListItemDecorator>
                  {app.name + (app.isDev ? ' [DEV]' : '')}
                </MenuItem>,
              )}
              <ListDivider />
            </>
          )}

          {/* QUICK TOOLS Section */}
          <ListItem>
            <Typography level="body-xs" sx={{ textTransform: 'uppercase', fontWeight: 600 }}>
              Quick Tools
            </Typography>
          </ListItem>
          <MenuItem disabled={!scratchClipSupported()} onClick={toggleScratchClipVisibility}>
            <ListItemDecorator><HistoryIcon /></ListItemDecorator>
            {isScratchClipVisible ? 'Hide ' : ''}Clipboard {scratchClipSupported() ? 'History' : '(not supported)'}
          </MenuItem>
          <ListDivider />

          {/* SUPPORT Section */}
          <ListItem>
            <Typography level="body-xs" sx={{ textTransform: 'uppercase', fontWeight: 600 }}>
              Support
            </Typography>
          </ListItem>
          <ListItemButton component="a" href={BaseProduct.SupportForm()} target="_blank">
            <ListItemDecorator><LightbulbOutlinedIcon /></ListItemDecorator>
            I Have Feedback
          </ListItemButton>
          {!!releaseNotesUrl && (
            <MenuItem onClick={handleShowReleaseNotes}>
              <ListItemDecorator>
                <FeatureBadge featureKey='nav-quick-menu' active={releaseNotesShown}>
                  <CodeIcon />
                </FeatureBadge>
              </ListItemDecorator>
              Release Notes
            </MenuItem>
          )}
          <MenuItem onClick={handleShowTechnologies}>
            {/*<ListItemDecorator><BuildCircleOutlinedIcon /></ListItemDecorator>*/}
            <ListItemDecorator />
            Build Info
          </MenuItem>

        </Menu>
      </Dropdown>);

    return components;
  }, [toggleScratchClipVisibility, isScratchClipVisible, releaseNotesUrl, handleShowReleaseNotes, releaseNotesShown, handleShowTechnologies, props.currentApp, isDrawerOpen]);


  // External link items
  const navExtLinkItems = React.useMemo(() => {
    return navItems.links.map((item, index) =>
      <BringTheLove
        key={'nav-ext-' + item.name}
        asIcon
        text={item.name}
        icon={item.icon}
        link={item.href}
        sx={{
          p: 1,
          mb: index > 0 ? 1 : 0,
        }}
      />,
    );
  }, []);


  // Modal items
  const navModalItems = React.useMemo(() => {
    return navItems.modals.map(item => {

      // map the overlayId to the corresponding state and action
      const stateActionMap: { [key: string]: { isActive: boolean, showModal: (event: React.MouseEvent) => void } } = {
        settings: { isActive: showPreferences, showModal: () => optimaOpenPreferences(/* avoid passing an event as param */) },
        models: { isActive: showModels, showModal: () => optimaOpenModels() },
        0: { isActive: false, showModal: () => console.log('Action missing for ', item.overlayId) },
      };
      const { isActive, showModal } = stateActionMap[item.overlayId] ?? stateActionMap[0];

      // attract the attention to the models configuration when no LLMs are available (a bit hardcoded here)
      const isAttractive = noLLMs && item.overlayId === 'models';

      // skip the models configuration, unless it is required
      if (item.overlayId === 'models' && !isAttractive) return null;

      return (
        <Tooltip key={'n-m-' + item.overlayId} title={isAttractive ? 'Add Language Models - REQUIRED' : item.name}>
          <DesktopNavIcon
            variant={isActive ? 'soft' : undefined}
            onClick={showModal}
            className={`${navItemClasses.typeLinkOrModal} ${isActive ? navItemClasses.active : ''} ${isAttractive ? navItemClasses.attractive : ''}`}
          >
            {(isActive && item.iconActive) ? <item.iconActive /> : <item.icon />}
          </DesktopNavIcon>
        </Tooltip>
      );
    }).filter(component => !!component); // filter out null components
  }, [noLLMs, showModels, showPreferences]);


  return (
    <InvertedBar
      id='desktop-nav'
      component={props.component}
      direction='vertical'
      sx={desktopNavBarSx}
      onMouseEnter={appUsesDrawer ? peekDrawerEnter : undefined}
      onMouseLeave={peekDrawerLeave}
    >

      <InvertedBarCornerItem>
        <Tooltip disableInteractive title={isDrawerPeeking ? 'Pin Drawer' : (isDrawerOpen ? 'Close Drawer' /* for Aria reasons */ : 'Open Drawer')}>
          <DesktopNavIcon
            disabled={!logoButtonTogglesPane}
            onPointerDown={logoButtonTogglesPane ? optimaToggleDrawer : undefined}
            className={navItemClasses.typeMenu}
          >
            {logoButtonTogglesPane ? (isDrawerPeeking ? <PushPinOutlinedIcon sx={{ fontSize: 'xl', transform: 'rotate(45deg)' }} /> : <MenuIcon />) : <BigAgiSquircleIcon inverted sx={{ color: 'white' }} />}
          </DesktopNavIcon>
        </Tooltip>
      </InvertedBarCornerItem>

      <DesktopNavGroupBox>
        {navAppItems}
      </DesktopNavGroupBox>

      <DesktopNavGroupBox sx={bottomGroupSx}>
        {/*<UserNavIcon />*/}
        {navExtLinkItems}
        {navModalItems}
      </DesktopNavGroupBox>

    </InvertedBar>
  );
}


================================================
FILE: src/common/layout/optima/nav/DesktopNavIcon.tsx
================================================
import { Box, IconButton, styled } from '@mui/joy';

import { animationColorBeamScatterINV } from '~/common/util/animUtils';

import { OPTIMA_NAV_RADIUS } from '../optima.config';


export const DesktopNavGroupBox = styled(Box)({
  // flex column
  display: 'flex',
  flexDirection: 'column',
  flexWrap: 'wrap',
  justifyContent: 'center',
  alignItems: 'center',

  // nav items, reduce the marginBlock a little
  '--GroupMarginY': '0.125rem',

  // style
  // backgroundColor: 'rgba(0 0 0 / 0.5)',
  // borderRadius: '1rem',
  // paddingBlock: '0.5rem',
  // overflow: 'hidden',
});


export const navItemClasses = {
  typeMenu: 'NavButton-typeMenu',
  typeApp: 'NavButton-typeApp',
  typeLinkOrModal: 'NavButton-typeLink',
  dev: 'NavButton-dev',
  active: 'NavButton-active',
  paneOpen: 'NavButton-paneOpen',
  attractive: 'NavButton-attractive',
};

export const DesktopNavIcon = styled(IconButton)(({ theme }) => ({
  // --Bar is defined in InvertedBar
  '--MarginX': '0.25rem',

  // border: '1px solid red',
  marginBlock: 'var(--GroupMarginY)',
  //marginInline: .. not needd because we center the items
  padding: 0,

  [`&.${navItemClasses.typeApp},&.${navItemClasses.typeLinkOrModal}`]: {
    // NOTE: 1.5 would be 24px, the native icon size - maybe we should use that for the selected app?
    '--Icon-fontSize': '1.25rem',
  },

  // hamburger menu: quick rotate on click
  [`&.${navItemClasses.typeMenu}`]: {
    transition: 'rotate 0.6s',
    '&:active': {
      rotate: '90deg',
      transition: 'rotate 0.2s',
    },
  },

  [`&.${navItemClasses.typeApp}`]: {
    '--IconButton-size': 'calc(var(--Bar) - 2 * var(--MarginX))',
    transition: 'border-radius 0.4s, margin 0.2s, padding 0.2s', // background-color 0.3s, color 0.2s
  },

  [`&.${navItemClasses.typeApp}:hover`]: {
    backgroundColor: 'var(--variant-solidHoverBg)',
    // backgroundColor: theme.palette.neutral.softHoverBg,
    color: theme.palette.neutral.softColor,
  },

  // [`&.${navItemClasses.typeLinkOrModal}`]: {
  //   borderRadius: '50%',
  //   transition: 'font-size 5s, color 0.2s',
  // },

  // app active (non hover)
  // [`&.${navItemClasses.typeApp}.${navItemClasses.active}`]: {},

  // pane open: show a connected half
  [`&.${navItemClasses.paneOpen}`]: {
    // squircle animation
    borderStartStartRadius: `var(--joy-radius-${OPTIMA_NAV_RADIUS})`,
    borderEndStartRadius: `var(--joy-radius-${OPTIMA_NAV_RADIUS})`,
    // borderStartStartRadius: 'calc(var(--IconButton-size) / 4)',
    // borderEndStartRadius: 'calc(var(--IconButton-size) / 4)',
    borderStartEndRadius: 0,
    borderEndEndRadius: 0,
    marginLeft: 'calc(2 * var(--MarginX))',
    paddingRight: 'calc(2 * var(--MarginX))',
  },
  [`&.${navItemClasses.paneOpen}:hover`]: {
    borderRadius: `var(--joy-radius-${OPTIMA_NAV_RADIUS})`,
    // borderRadius: 'var(--joy-radius-md, 0.5rem)',
    marginLeft: 0,
    paddingRight: 0,
  },

  // attractive: attract the user to click on this element
  [`&.${navItemClasses.attractive}`]: {
    '--Icon-fontSize': '2rem',
    animation: `${animationColorBeamScatterINV} 4s infinite`,
  },

  // debug: show a red outline
  [`&.${navItemClasses.dev}`]: {
    border: '2px dashed red',
  },

})) as typeof IconButton;


================================================
FILE: src/common/layout/optima/nav/MobileNav.tsx
================================================
import * as React from 'react';
import Router from 'next/router';

import type { SxProps } from '@mui/joy/styles/types';

import { checkDivider, checkVisibileIcon, NavItemApp, navItems } from '~/common/app.nav';

import { InvertedBar } from '../InvertedBar';
import { MobileNavGroupBox, MobileNavIcon, mobileNavItemClasses } from './MobileNavIcon';


export function MobileNav(props: {
  component: React.ElementType,
  currentApp?: NavItemApp,
  hideOnFocusMode?: boolean,
  sx?: SxProps,
}) {

  // external state
  // const { isFocusedMode } = useOptima...();


  // App items
  const navAppItems = React.useMemo(() => {
    return navItems.apps
      .filter(app => checkVisibileIcon(app, true, undefined))
      .map((app) => {
        const isActive = app === props.currentApp;

        if (checkDivider(app)) {
          // return <Divider key={'div-' + appIdx} sx={{ mx: 1, height: '50%', my: 'auto' }} />;
          return null;
        }

        return (
          <MobileNavIcon
            key={'n-m-' + app.route.slice(1)}
            aria-label={app.mobileName || app.name}
            variant={isActive ? 'solid' : undefined}
            onClick={() => Router.push(app.landingRoute || app.route)}
            className={`${mobileNavItemClasses.typeApp} ${isActive ? mobileNavItemClasses.active : ''}`}
          >
            {/*{(isActive && app.iconActive) ? <app.iconActive /> : <app.icon />}*/}
            <app.icon />
          </MobileNavIcon>
        );
      });
  }, [props.currentApp]);


  // NOTE: this may be abrupt a little
  // if (isFocusedMode && props.hideOnFocusMode)
  //   return null;

  return (
    <InvertedBar
      id='mobile-nav'
      component={props.component}
      direction='horizontal'
      sx={props.sx}
    >

      <MobileNavGroupBox>
        {navAppItems}
      </MobileNavGroupBox>

    </InvertedBar>
  );
}


================================================
FILE: src/common/layout/optima/nav/MobileNavIcon.tsx
================================================
import { Box, IconButton, styled } from '@mui/joy';


export const MobileNavGroupBox = styled(Box)({
  // layout
  flex: 1,
  minHeight: 'var(--Bar)',

  // contents
  display: 'flex',
  flexDirection: 'row',
  flexWrap: 'wrap',
  justifyContent: 'space-evenly',
  alignItems: 'center',

  // style
  // backgroundColor: 'rgba(0 0 0 / 0.5)', // darken bg

  // debug
  // '& > *': { border: '1px solid red' },
});

export const mobileNavItemClasses = {
  typeApp: 'NavButton-typeApp',
  active: 'NavButton-active',
};

export const MobileNavIcon = styled(IconButton)(({ theme }) => ({

  // custom vars
  '--MarginY': '0.5rem',
  '--ExtraPadX': '1rem',

  // IconButton customization
  '--Icon-fontSize': '1.25rem',
  '--IconButton-size': 'calc(var(--Bar) - 2 * var(--MarginY))',
  paddingInline: 'var(--ExtraPadX)',
  border: 'none',

  [`&.${mobileNavItemClasses.typeApp}:hover`]: {
    backgroundColor: 'var(--variant-solidHoverBg)',
    // backgroundColor: theme.palette.neutral.softHoverBg,
    color: theme.palette.neutral.softColor,
  },

  // app active (non hover)
  // [`&.${mobileNavItemClasses.typeApp}.${mobileNavItemClasses.active}`]: {
  //   backgroundColor: ...
  // },

})) as typeof IconButton;


================================================
FILE: src/common/layout/optima/nav/MobileNavItems.tsx
================================================
import * as React from 'react';
import Router from 'next/router';

import { Box, Button, ButtonGroup, ColorPaletteProp, Sheet } from '@mui/joy';

import { ROUTE_APP_NEWS } from '~/common/app.routes';
import { checkDivider, checkVisibileIcon, NavItemApp, navItems } from '~/common/app.nav';

import { BringTheLove } from './BringTheLove';
import { optimaCloseDrawer, optimaOpenModels } from '../useOptima';


// configuration
const INVERT_PANE = true; // if true, the pane will be darker
const COLOR_PANE: ColorPaletteProp = 'neutral';


const _styles = {

  sheet: {
    // borderTopLeftRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
    // borderTopRightRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
    display: 'grid',
    rowGap: 0.5,
    py: 2,
    ...(INVERT_PANE ? {} : {
      borderTop: '1px solid',
      borderTopColor: 'divider',
    }),
  } as const,

  appsButtonGroup: {
    '--ButtonGroup-separatorSize': 0,
    '--ButtonGroup-connected': 0,
    gap: 1,
    justifyContent: 'center',
    overflowX: 'auto',
  } as const,

  button: {
    minWidth: '5.5rem',
    p: '0.5rem 0 0.375rem',
    borderRadius: 'sm',
    color: INVERT_PANE ? 'text.secondary' : undefined,
    fontWeight: 'sm',
    lineHeight: 'xs',
    '&[aria-selected="true"]': {
      boxShadow: INVERT_PANE ? `inset 1px 1px 3px -2px var(--joy-palette-${COLOR_PANE}-solidBg)` : undefined,
      // backgroundColor: INVERT_PANE ? undefined : 'background.popup',
      color: INVERT_PANE ? 'text.primary' : undefined,
      fontWeight: 'lg',
    },
    // layout
    flexDirection: 'column',
    gap: 0.75,
  } as const,

  linksGroup: {
    display: 'flex',
    justifyContent: 'center',
    gap: 1,
  } as const,

} as const;


/**
 * This can be plugged to the Drawer or Panel, to have nav items on Mobile.
 */
export function MobileNavItems(props: { currentApp?: NavItemApp }) {

  // group apps into visible (rendered as of now) and overflow (rendered with a dropdown menu)
  let crossedDivider = false;
  const visibleApps: NavItemApp[] = [];
  // const overflowApps: NavItemApp[] = [];

  const handleNavigate = React.useCallback((path: string, closeDrawer: boolean = true) => {
    void Router.push(path);
    if (closeDrawer)
      optimaCloseDrawer();
  }, []);

  navItems.apps.forEach((app) => {
    if (!checkVisibileIcon(app, true, props.currentApp)) return;
    if (checkDivider(app)) {
      crossedDivider = true;
      return;
    }
    // NOTE: using the 'hideOnMobile' flag instead of the crossing
    // if (!crossedDivider)
    visibleApps.push(app);
    // else overflowApps.push(app);
  });

  return (

    <Sheet color={COLOR_PANE} variant={INVERT_PANE ? 'solid' : 'soft'} invertedColors={INVERT_PANE} sx={_styles.sheet}>

      {/* Group 1: Apps */}
      <ButtonGroup
        component='nav'
        sx={_styles.appsButtonGroup}
      >
        {visibleApps.map((app) => {
          const isActive = app === props.currentApp;
          return (
            <Button
              key={'app-' + (app.mobileName || app.name)}
              aria-selected={isActive}
              size='sm'
              color={COLOR_PANE}
              variant={isActive ? (INVERT_PANE ? 'soft' : 'solid') : 'plain'}
              onClick={() => handleNavigate(app.landingRoute || app.route, !!app.hideDrawer)}
              sx={_styles.button}
            >
              {(isActive && app.iconActive) ? <app.iconActive /> : <app.icon />}
              <Box component='span'>
                {app.mobileName || app.name}
              </Box>
            </Button>
          );
        })}
      </ButtonGroup>

      {/* Group 2: Modals & Social Links */}
      <Box sx={_styles.linksGroup}>
        <Button
          size='sm'
          color='neutral'
          aria-selected={props.currentApp?.route === '/news'}
          variant={props.currentApp?.route === '/news' ? (INVERT_PANE ? 'soft' : 'solid') : 'plain'}
          onClick={() => handleNavigate(ROUTE_APP_NEWS, true)}
          sx={_styles.button}
        >
          News
        </Button>

        {/* HARDCODED: Models */}
        <Button
          size='sm'
          color='neutral'
          variant='plain'
          onClick={optimaOpenModels}
          sx={_styles.button}
        >
          Models
        </Button>

        {/* HARDCODED: Discord */}
        <BringTheLove
          text={navItems.links[0].name}
          icon={navItems.links[0].icon}
          link={navItems.links[0].href}
          sx={_styles.button}
        />
      </Box>

    </Sheet>

  );
}


================================================
FILE: src/common/layout/optima/page/OptimaAppPageHeading.tsx
================================================
import * as React from 'react';

import { Box, ListDivider, Typography } from '@mui/joy';

import { useIsMobile } from '~/common/components/useMatchMedia';


const _styles = {
  root: {
    mb: 2.25,
  },
  title: {
    textAlign: 'start',
  },
  textClickable: {
    cursor: 'pointer',
    '&:hover': {
      textDecoration: 'underline',
    },
  },
  accentedTagline: {
    textAlign: 'start',
    mt: 0.75,
  },
  tagline: {
    color: 'text.secondary',
    textAlign: 'start',
    mt: 0.75,
  },
  divisor: {
    mt: 2.25,
  },
} as const;


export function OptimaAppPageHeading(props: {
  title: React.ReactNode;
  tagline?: React.ReactNode;
  accentedTagline?: boolean;
  startDecorator?: React.ReactNode;
  endDecorator?: React.ReactNode;
  noDivider?: boolean;
  noMarginBottom?: boolean;
  onClick?: (event: React.MouseEvent) => void;
}) {

  // external state
  const isMobile = useIsMobile();

  return (
    <Box mb={props.noMarginBottom ? undefined : 2.25}>
      {!!props.title && <Typography level={isMobile ? 'h3' : 'h2'} startDecorator={props.startDecorator} endDecorator={props.endDecorator} sx={_styles.title}>
        {props.onClick ? <Box component='span' sx={_styles.textClickable} onClick={props.onClick}>{props.title}</Box> : props.title}
      </Typography>}
      {!!props.tagline && <Typography level='body-sm' sx={props.accentedTagline ? _styles.accentedTagline : _styles.tagline}>
        {props.tagline}
      </Typography>}
      {!props.noDivider && <ListDivider sx={_styles.divisor} />}
    </Box>
  );
}


================================================
FILE: src/common/layout/optima/panel/DesktopPanel.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, List, Sheet, styled } from '@mui/joy';

import { NavItemApp } from '~/common/app.nav';
import { adjustContentScaling, themeScalingMap, themeZIndexDesktopPanel, } from '~/common/app.theme';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUIContentScaling } from '~/common/stores/store-ui';

import { PanelContentPortal } from './PanelContentPortal';
import { optimaClosePanel, useOptimaPanelOpen } from '../useOptima';


// Desktop side Panel with the Portal content

const DesktopPanelFixRoot = styled(Box)({
  // fix the panel size
  width: 'var(--AGI-Desktop-Panel-width)',
  flexShrink: 0,
  flexGrow: 0,
  
  // Base state
  zIndex: themeZIndexDesktopPanel,

  '&[data-closed="true"]': {
    contain: 'strict',
    pointerEvents: 'none',
  },
  
  '&.panel-peeking': {
    zIndex: themeZIndexDesktopPanel + 1, // elevate z-index when peeking
  },
});

const DesktopPanelTranslatingSheet = styled(Sheet)(({ theme }) => ({
  // layout
  width: '100%',
  height: '100dvh',
  zIndex: 1, // just to allocate a layer; this was: themeZIndexDesktopPanel

  // styling
  backgroundColor: 'var(--joy-palette-background-surface)',
  borderLeft: '1px solid',
  // the border left color is from: theme.palette.divider, which is this /0.2 (light) and /0.16 (dark)
  borderLeftColor: 'rgba(var(--joy-palette-neutral-mainChannel, 99 107 116) / 0.4)',
  // borderTopLeftRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
  // borderBottomLeftRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
  // contain: 'strict',
  // boxShadow: theme.shadow.md, // too thin and complex; also tried 40px blurs
  boxShadow: `0px 0px 6px 0 rgba(${theme.palette.neutral.darkChannel} / 0.12)`,

  // content layout
  display: 'flex',
  flexDirection: 'column',

  overflowY: 'auto', // NOTE: this was not present on DesktopDrawer -- we added it here

  // base state (normal open/close, and peeking exit)
  transform: 'none',
  transition: 'transform 0.42s cubic-bezier(.17,.84,.44,1), box-shadow 0.42s cubic-bezier(.17,.84,.44,1)',
  willChange: 'transform, box-shadow',

  // Closed state via data attribute
  '&[data-closed="true"]': {
    transform: 'translateX(101%)', // the extra 1% takes care of fractional units (custom monitor scaling)
    borderLeftColor: 'transparent',
  },

  // Peek state via class
  '&.panel-peeking': {
    transition: 'transform 0.25s cubic-bezier(.4,0,.2,1)', // faster enter animation, shadow as-is
    boxShadow: '0 0 48px rgba(var(--joy-palette-neutral-darkChannel) / 0.4)', // stronger shadow when peeking, was theme.shadow.lg
    borderLeftColor: 'transparent',
  },
})) as typeof Sheet;


export function DesktopPanel(props: { component: React.ElementType, currentApp?: NavItemApp }) {

  // external state
  const isMobile = useIsMobile();
  const contentScaling = adjustContentScaling(useUIContentScaling(), isMobile ? 1 : 0);
  const { panelShownAsPanel, panelShownAsPeeking, panelAsPopup } = useOptimaPanelOpen(false, props.currentApp);
  const isOpen = panelShownAsPanel || panelShownAsPeeking;

  // Close the panel if the current page goes for a popup instead
  React.useEffect(() => {
    if (panelAsPopup)
      optimaClosePanel();
  }, [panelAsPopup]);

  return (
    <DesktopPanelFixRoot
      data-closed={!isOpen}
      className={panelShownAsPeeking ? 'panel-peeking' : undefined}
    >

      <DesktopPanelTranslatingSheet
        component={props.component}
        data-closed={!isOpen}
        className={panelShownAsPeeking ? 'panel-peeking' : undefined}
      >

        <List size={themeScalingMap[contentScaling]?.optimaPanelGroupSize} sx={{ '--ListItem-minHeight': '2.5rem', py: 0 /*0.75*/, flex: 0 }}>
          {/*<OptimaPanelGroupedList>*/}
          {/*<UserAccountListItem />*/}
          {/*<PreferencesListItem />*/}
          {/*</OptimaPanelGroupedList>*/}
        </List>

        {/* [Desktop] Portal in the Panel */}
        {!panelAsPopup && <PanelContentPortal />}

      </DesktopPanelTranslatingSheet>

    </DesktopPanelFixRoot>
  );
}


================================================
FILE: src/common/layout/optima/panel/MobilePanel.tsx
================================================
import * as React from 'react';

import { Box, Drawer } from '@mui/joy';

import type { NavItemApp } from '~/common/app.nav';

import { MobilePreferencesListItem } from './MobilePreferencesListItem';
import { OPTIMA_DRAWER_MOBILE_RADIUS, OPTIMA_PANEL_GROUPS_SPACING } from '../optima.config';
import { OptimaPanelGroupedList } from './OptimaPanelGroupedList';
import { PanelContentPortal } from './PanelContentPortal';
import { optimaClosePanel, useOptimaPanelOpen } from '../useOptima';


export function MobilePanel(props: { component: React.ElementType, currentApp?: NavItemApp }) {

  // external state
  const { panelShownAsPanel } = useOptimaPanelOpen(true, props.currentApp);

  // NOTE on `disableEnforceFocus` (Joy UI): see MobileDrawer
  return (
    <Drawer
      id='mobile-panel'
      component={props.component}
      disableEnforceFocus
      anchor='right'
      open={panelShownAsPanel}
      onClose={optimaClosePanel}
      sx={{
        '--Drawer-horizontalSize': 'round(clamp(30%, var(--AGI-Mobile-Panel-width), 100%), 1px)',
        '--Drawer-transitionDuration': '0.2s',
        // '& .MuiDrawer-paper': {
        //   width: 256,
        //   boxSizing: 'border-box',
        // },
      }}
      slotProps={{
        backdrop: {
          sx: {
            backdropFilter: 'none',
          },
        },
        content: {
          sx: {
            // style: round the right drawer corners
            // backgroundColor: 'transparent',
            borderTopLeftRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
            borderBottomLeftRadius: OPTIMA_DRAWER_MOBILE_RADIUS,
          },
        },
      }}
    >

      {/* Preferences */}
      <Box sx={{
        // mb: OPTIMA_PANEL_GROUPS_SPACING,
        // make the [Account, Preferences, Portal] stack scrollable
        height: '100%',
        overflowY: 'auto',
      }}>

        <Box sx={{ py: 0.25, mb: OPTIMA_PANEL_GROUPS_SPACING }}>
          <OptimaPanelGroupedList>
            <MobilePreferencesListItem />
          </OptimaPanelGroupedList>
        </Box>

        {/* [Mobile] Panel within the Drawer */}
        <PanelContentPortal />

      </Box>


    </Drawer>
  );
}



================================================
FILE: src/common/layout/optima/panel/MobilePreferencesListItem.tsx
================================================
import * as React from 'react';

import { ListItem, ListItemButton, ListItemDecorator } from '@mui/joy';
import SettingsIcon from '@mui/icons-material/Settings';

import { DarkModeToggleButton } from '~/common/components/DarkModeToggleButton';

import { optimaClosePanel, optimaOpenPreferences } from '../useOptima';


export function MobilePreferencesListItem(props: { autoClosePanel?: boolean }) {

  const handleShowPreferences = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    optimaOpenPreferences();
    if (props.autoClosePanel)
      optimaClosePanel();
  }, [props.autoClosePanel]);

  return (
    <ListItem endAction={<DarkModeToggleButton />}>
      <ListItemButton onClick={handleShowPreferences}>
        <ListItemDecorator><SettingsIcon /></ListItemDecorator>
        Preferences{/*<KeyStroke combo='Ctrl + ,' />*/}
      </ListItemButton>
    </ListItem>
  );
}



================================================
FILE: src/common/layout/optima/panel/OptimaPanelGroupedList.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Checkbox, MenuList } from '@mui/joy';

import { ExpanderControlledBox } from '~/common/components/ExpanderControlledBox';
import { adjustContentScaling, themeScalingMap, } from '~/common/app.theme';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useUIContentScaling } from '~/common/stores/store-ui';


const gutterSx: SxProps = {
  px: 'var(--ListItem-paddingX)',
  py: 'var(--ListItem-paddingY)',
  display: 'flex',
  flexDirection: 'column',
  gap: 1.5,
};

export function OptimaPanelGroupGutter(props: { children?: React.ReactNode }) {
  return (
    <Box sx={gutterSx}>
      {props.children}
    </Box>
  );
}


// Header

const headerSx: SxProps = {
  // style
  backgroundColor: 'background.level1',
  borderBottom: '1px solid',
  borderTop: '1px solid',
  borderTopColor: 'var(--joy-palette-neutral-outlinedDisabledBorder)',
  borderBottomColor: 'rgba(var(--joy-palette-neutral-mainChannel) / 0.05)',

  // mimics ListItem
  px: 'var(--ListItem-paddingX, 0.75rem)',
  py: 'var(--ListItem-paddingY, 0.25rem)',
  minBlockSize: 'var(--ListItem-minHeight, 2.25rem)',

  // layout
  display: 'flex',
  alignItems: 'center',
  justifyContent: 'space-between',
  gap: 1,

  // '--A': 'var(--joy-palette-background-level1)',
  // '--B': 'var(--joy-palette-background-popup)',
  // background: 'linear-gradient(45deg, var(--A) 25%, var(--B) 25%, var(--B) 50%, var(--A) 50%, var(--A) 75%, var(--B) 75%)',
  // backgroundSize: '40px 40px',
  // boxShadow: 'xs',

  // if the role is button, show the cursor
  '&[role="button"]': {
    cursor: 'pointer',
    transition: 'background-color 0.2s',
    '&:hover': {
      backgroundColor: 'background.level2',
    },
  },

  // if expanded, soften the bottom border
  '&[aria-expanded="false"]': {
    backgroundColor: 'background.surface',
    borderColor: 'transparent',
  },
};

const headerTitleSx: SxProps = {
  color: 'text.tertiary',
  // fontSize: 'xs',
  fontWeight: 'lg',
};


// List containing the items

const groupListSx: SxProps = {
  border: 'none',
  borderRadius: 0,
  background: 'transparent',
  flexGrow: 0,

  // NOTE 2: removed the margin-bottom, so the spacing is used as gap only
  // NOTE: switched to smaller margin on mobile, keeping it larger on desktop
  // mb: { xs: 1, md: OPTIMA_PANEL_GROUPS_SPACING } as const,
  // mb: OPTIMA_PANEL_GROUPS_SPACING,

  // fontSize: '0.9375rem', // 15px (14 too small, 16 too big?)
  // py: 0,
  // py: 'var(--ListDivider-gap)',
} as const;


export function OptimaPanelGroupedList(props: {
  title?: string;
  endDecorator?: React.ReactNode;
  children?: React.ReactNode;
  persistentCollapsibleId?: string;
  startExpanded?: boolean;
}) {

  // state
  // TODO: persist by id
  const [_expanded, setExpanded] = React.useState(props.startExpanded === true);

  // external state
  const isMobile = useIsMobile();
  const contentScaling = adjustContentScaling(useUIContentScaling(), isMobile ? 1 : 0);
  const smallerContentScaling = adjustContentScaling(contentScaling, -1);

  // derived state
  const isCollapsible = !!props.persistentCollapsibleId;
  const isExpanded = !isCollapsible || _expanded;

  // handlers

  const toggleExpanded = React.useCallback(() => {
    setExpanded(expanded => !expanded);
  }, []);


  return (
    <Box>

      {/* Header */}
      {(!!props.title || isCollapsible) && (
        <Box
          aria-expanded={isExpanded}
          onClick={isCollapsible ? toggleExpanded : undefined}
          role={isCollapsible ? 'button' : undefined}
          sx={headerSx}
        >
          <Box fontSize={smallerContentScaling} sx={headerTitleSx}>{props.title}</Box>
          {isCollapsible && <Checkbox size='md' variant='outlined' color='neutral' checked={isExpanded} />}
        </Box>
      )}

      {/* Collapsible Items  */}
      <ExpanderControlledBox expanded={isExpanded}>
        <MenuList size={themeScalingMap[contentScaling]?.optimaPanelGroupSize} sx={groupListSx}>
          {props.children}
        </MenuList>
      </ExpanderControlledBox>

    </Box>
  );
}



================================================
FILE: src/common/layout/optima/panel/PanelContentPortal.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { OPTIMA_PANEL_GROUPS_SPACING } from '../optima.config';
import { useOptimaPortalOutRef } from '../portals/useOptimaPortalOutRef';


const portalContentSx: SxProps = {
  flex: 1,
  display: 'flex',
  flexDirection: 'column',
  gap: OPTIMA_PANEL_GROUPS_SPACING,
  // gap: 'var(--ListDivider-gap)'
};


export function PanelContentPortal() {

  // external state
  const panelPortalRef = useOptimaPortalOutRef('optima-portal-panel', 'PanelPortal');

  return <Box ref={panelPortalRef} sx={portalContentSx} />;
}


================================================
FILE: src/common/layout/optima/panel/PopupPanel.tsx
================================================
import * as React from 'react';

import { CloseablePopup } from '~/common/components/CloseablePopup';

import { PanelContentPortal } from './PanelContentPortal';
import { optimaClosePanel } from '../useOptima';


export function PopupPanel(props: { anchorEl: HTMLElement | null }) {
  return (
    <CloseablePopup
      menu // this is NOT needed or wanted, but improves the look compared to the Box alternative
      anchorEl={props.anchorEl} onClose={optimaClosePanel}
      maxHeightGapPx={56 + 24}
      minWidth={280}
      placement='bottom-end'
    >

      {/* [Desktop] Portal within the Popup - [Mobile] always use the panel */}
      <PanelContentPortal />

    </CloseablePopup>
  );
}


================================================
FILE: src/common/layout/optima/portals/OptimaPortalsIn.tsx
================================================
import * as React from 'react';
import { createPortal } from 'react-dom';

import { OPTIMA_PANEL_GROUPS_SPACING } from '../optima.config';
import { OptimaPortalId, useLayoutPortalsStore } from './store-layout-portals';
import { optimaActions } from '../useOptima';


const drawerWrapperStyle = {
  height: '100%',
  display: 'flex',
  flexDirection: 'column',
} as const;

const panelWrapperStyle = {
  flex: 1,
  ...drawerWrapperStyle,

  // replicates PanelContentPortal.portalContentSx.gap, as we have added a div which deletes the gap
  gap: `${OPTIMA_PANEL_GROUPS_SPACING / 2}rem`, //
} as const;


export function OptimaDrawerIn(props: { children: React.ReactNode }) {
  const portalElement = useOptimaPortalTargetElement('optima-portal-drawer');
  if (!portalElement) return null;

  // wrap portal contents in a div that updates the hover state of the drawer
  const { peekDrawerEnter, peekDrawerLeave } = optimaActions();
  return createPortal(
    <div
      data-optima-piw='drawer' // portal input wrapper
      onMouseEnter={peekDrawerEnter}
      onMouseLeave={peekDrawerLeave}
      style={drawerWrapperStyle}
    >
      {props.children}
    </div>, portalElement);
}

export function OptimaPanelIn(props: { children: React.ReactNode }) {
  const portalElement = useOptimaPortalTargetElement('optima-portal-panel');
  if (!portalElement) return null;

  // wrap portal contents in a div that updates the hover state of the panel
  const { peekPanelEnter, peekPanelLeave } = optimaActions();
  return createPortal(
    <div
      data-optima-piw='panel' // portal input wrapper
      onMouseEnter={peekPanelEnter}
      onMouseLeave={peekPanelLeave}
      style={panelWrapperStyle}
    >
      {props.children}
    </div>, portalElement);
}

export function OptimaToolbarIn(props: { children: React.ReactNode }) {
  const portalElement = useOptimaPortalTargetElement('optima-portal-toolbar');
  return portalElement ? createPortal(props.children, portalElement) : null;
}


/**
 * Hook to get the target element for a portal.
 */
function useOptimaPortalTargetElement(targetPortalId: OptimaPortalId) {
  // get the output element
  const targetPortalEl = useLayoutPortalsStore(state => state.portals[targetPortalId]?.element ?? null);

  // increment/decrement input count
  React.useEffect(() => {
    const { incrementInputs, decrementInputs } = useLayoutPortalsStore.getState();
    incrementInputs(targetPortalId);
    return () => decrementInputs(targetPortalId);
  }, [targetPortalId]);

  // return the output element
  return targetPortalEl;
}



================================================
FILE: src/common/layout/optima/portals/store-layout-portals.ts
================================================
import { create } from 'zustand';

import { OPTIMA_DEBUG_PORTALS } from '../optima.config';


export type OptimaPortalId =
  | 'optima-portal-drawer'
  | 'optima-portal-panel'
  | 'optima-portal-toolbar';


interface OptimaPortalState {
  portals: Record<OptimaPortalId, {
    element: HTMLElement | null;
    inputs: number;
  }>;
}

interface OptimaPortalActions {

  // store output elements
  setElement: (id: OptimaPortalId, element: HTMLElement | null) => void;

  // reference counting
  incrementInputs: (id: OptimaPortalId) => void;
  decrementInputs: (id: OptimaPortalId) => void;

}


export const useLayoutPortalsStore = create<OptimaPortalState & OptimaPortalActions>((_set, _get) => ({

  // init state
  portals: {
    'optima-portal-drawer': { element: null, inputs: 0 },
    'optima-portal-panel': { element: null, inputs: 0 },
    'optima-portal-toolbar': { element: null, inputs: 0 },
  },

  // actions

  setElement: (id, element) => _set((state) => {
    // sanity check
    if (element && _get().portals[id].element)
      console.warn(`useOptimaPortalsStore.setElement: expected element to be null for ${id}`);
    if (OPTIMA_DEBUG_PORTALS)
      console.log(`${element ? 'Set' : 'Remove'} portal element`, id);
    return {
      portals: {
        ...state.portals,
        [id]: { ...state.portals[id], element: element },
      },
    };
  }),

  incrementInputs: (id) => _set((state) => {
    const newInputs = state.portals[id].inputs + 1;
    // sanity check
    if (newInputs > 1)
      console.warn(`useOptimaPortalsStore.incrementInputs: expected inputs to not exceed 1 for ${id}`);
    if (OPTIMA_DEBUG_PORTALS)
      console.log(' + store.incrementInputs', id, newInputs);
    return {
      portals: {
        ...state.portals,
        [id]: { ...state.portals[id], inputs: newInputs },
      },
    };
  }),

  decrementInputs: (id) => _set((state) => {
    const newInputs = Math.max(0, state.portals[id].inputs - 1);
    if (OPTIMA_DEBUG_PORTALS)
      console.log(' - store.decrementInputs', id, newInputs);
    return {
      portals: {
        ...state.portals,
        [id]: { ...state.portals[id], inputs: newInputs },
      },
    };
  }),

}));



================================================
FILE: src/common/layout/optima/portals/useOptimaPortalHasInputs.ts
================================================
import { OptimaPortalId, useLayoutPortalsStore } from './store-layout-portals';

export function useOptimaPortalHasInputs(portalTargetId: OptimaPortalId) {
  return useLayoutPortalsStore(state => state.portals[portalTargetId]?.inputs >= 1);
}



================================================
FILE: src/common/layout/optima/portals/useOptimaPortalOutRef.ts
================================================
import * as React from 'react';

import { OptimaPortalId, useLayoutPortalsStore } from './store-layout-portals';


/**
 * Defines a React output portal for a given target id. Will return a ref that
 * must be attached to the target element.
 *
 * Note: this hook assumes that the ref is created by when useLayoutEffect is called,
 * and will warn otherwise.
 *
 * If the ref is created after the layout effect, the portal will not be added. In
 * that case, consider returning a Callback instead, with:
 * `const setRef = React.useCallback((node: HTMLElement | null) => { ... }, [portalTargetId]);`
 */
export function useOptimaPortalOutRef(portalTargetId: OptimaPortalId, debugCallerName: string) {

  // state
  const ref = React.useRef<HTMLElement>(null);

  React.useLayoutEffect(() => {
    const { setElement } = useLayoutPortalsStore.getState();
    if (!ref.current) {
      console.warn(`useOptimaPortalOut: ref.current is null for type ${portalTargetId} (called by ${debugCallerName})`);
    } else {
      setElement(portalTargetId, ref.current);
      ref.current.dataset['optimaOutId'] = portalTargetId.replace('optima-portal-', '');
    }
    return () => setElement(portalTargetId, null);
  }, [debugCallerName, portalTargetId]);

  return ref;
}



================================================
FILE: src/common/layout/optima/scratchclip/ScratchClip.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, Button, IconButton, List, ListItem, ListItemContent, ListItemDecorator, Tooltip, Typography } from '@mui/joy';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import ContentPasteGoIcon from '@mui/icons-material/ContentPasteGo';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import ClearAllIcon from '@mui/icons-material/ClearAll';
import HistoryIcon from '@mui/icons-material/History';

import { GoodModal } from '~/common/components/modals/GoodModal';
import { addSnackbar } from '~/common/components/snackbar/useSnackbarsStore';
import { animationEnterScaleUp } from '~/common/util/animUtils';
import { copyToClipboard, getClipboardItems, supportsClipboardRead } from '~/common/util/clipboardUtils';

import { ClipboardHistoryItem, scratchClipActions, useScratchClipHistory } from './store-scratchclip';


// configuration
const MAX_DISPLAY_LENGTH = 100; // and still will be ellipsized


export function ScratchClip() {

  // external state
  const { history, isVisible } = useScratchClipHistory();


  // handlers

  const handleClose = React.useCallback(() => {
    scratchClipActions().setClipboardVisibility(false);
  }, []);

  const handleRestoreSnippet = React.useCallback((item: ClipboardHistoryItem, event: React.MouseEvent) => {
    event.stopPropagation();
    copyToClipboard(item.text, 'Snippet from history');
    // addSnackbar({ message: 'Snippet restored to clipboard.', type: 'success', key: 'clip-restore' });
    // Optionally close after restore: handleClose();
  }, []);

  const handleRemoveSnippet = React.useCallback((id: string, event: React.MouseEvent) => {
    event.stopPropagation();
    scratchClipActions().removeSnippet(id);
  }, []);

  const handleClearHistory = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    scratchClipActions().clearHistory();
    addSnackbar({ message: 'Clipboard history cleared.', type: 'info', key: 'clip-clear' });
  }, []);

  const handleReadClipboard = React.useCallback(async () => {
    const clipboardItems = await getClipboardItems();

    if (!clipboardItems || clipboardItems.length === 0) {
      addSnackbar({ key: 'clipboard-issue', type: 'issue', message: 'Clipboard empty or access denied', overrides: { autoHideDuration: 2000, } });
      return;
    }

    // Process clipboard items
    for (const item of clipboardItems) {
      const types = item.types;

      // Try to get text content
      if (types.includes('text/plain')) {
        try {
          const blob = await item.getType('text/plain');
          const text = await blob.text();

          if (text.trim()) {
            scratchClipActions().addSnippet(text);
            addSnackbar({ message: 'Added clipboard content to history', type: 'success', key: 'clip-read-success' });
          }
        } catch (error) {
          console.warn('Failed to read clipboard text:', error);
        }
      }
    }
  }, []);


  // conditional rendering
  // if (!isVisible) return null;


  return (
    <GoodModal
      open={isVisible}
      onClose={handleClose}
      titleStartDecorator={<HistoryIcon />}
      unfilterBackdrop
      title={
        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>

          {/* Title */}
          <Typography>
            Clipboard History
          </Typography>

          {/* Clear Button */}
          {history.length > 0 && (
            <Tooltip title='Clear All History' variant='solid' placement='bottom'>
              <IconButton size='sm' variant='plain' color='neutral' onClick={handleClearHistory} sx={{ mr: 1 }}>
                <ClearAllIcon />
              </IconButton>
            </Tooltip>
          )}

        </Box>
      }
      startButton={!supportsClipboardRead() ? undefined : (
        <Button
          variant='soft'
          color='neutral'
          startDecorator={<ContentPasteGoIcon />}
          onClick={handleReadClipboard}
        >
          Add from Clipboard
        </Button>
      )}
      sx={{ animation: `${animationEnterScaleUp} 0.2s cubic-bezier(.07,1.14,.85,1.02)` }}
    >

      {/* Content */}
      {!history.length ? (
        <Typography sx={{ p: 3, textAlign: 'center' }}>
          Local clipboard history is empty.
        </Typography>
      ) : (
        <List
          variant='outlined'
          sx={{
            p: 0,
            borderRadius: 'md',
            boxShadow: 'lg',
            overflowY: 'auto',

            // items looks
            '& > li': {
              borderRadius: '0px',
              py: 1,
            },
            '& > li:not(:last-child)': {
              borderBottom: '1px solid',
              borderColor: 'divider',
            },
          }}
        >
          {history.map((item) => (
            <ListItem key={item.id}>

              {/* > Copy */}
              <ListItemDecorator>
                <Tooltip title='Copy to Clipboard' variant='outlined' placement='left'>
                  <IconButton
                    size='sm'
                    // color='primary'
                    onClick={(e) => handleRestoreSnippet(item, e)}
                  >
                    <ContentCopyIcon />
                  </IconButton>
                </Tooltip>
              </ListItemDecorator>

              {/* > Preview */}
              <ListItemContent sx={{ overflow: 'hidden' }}>
                <Typography level='body-sm' noWrap textColor='text.secondary'>
                  {item.text.length > MAX_DISPLAY_LENGTH ? item.text.substring(0, MAX_DISPLAY_LENGTH) + '...' : item.text}
                </Typography>
                <Typography level='body-xs'>
                  <TimeAgo date={item.timestamp} />
                  {/*{item.source && <Box component='span' color='text.tertiary'> · from {item.source}</Box>}*/}
                </Typography>
              </ListItemContent>

              {/* > Delete */}
              <IconButton
                size='sm'
                // color='danger'
                onClick={(e) => handleRemoveSnippet(item.id, e)}
              >
                <DeleteOutlineIcon />
              </IconButton>
            </ListItem>
          ))}
        </List>
      )}

    </GoodModal>
  );
}



================================================
FILE: src/common/layout/optima/scratchclip/store-scratchclip.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import { agiUuid } from '~/common/util/idUtils';
import { useShallow } from 'zustand/react/shallow';
import { supportsClipboardRead } from '~/common/util/clipboardUtils';


// configuration
const MAX_HISTORY_ITEMS = 10;
const MAX_SNIPPET_LENGTH = 20000;


export interface ClipboardHistoryItem {
  id: string;
  text: string;
  timestamp: number;
  source?: string; // Optional: e.g., 'textarea', 'contentEditable'
}


interface ScratchClipState {
  history: ClipboardHistoryItem[];
  isVisible: boolean; // not persisted
}

interface ScratchClipActions {
  addSnippet: (text: string, sourceElement?: HTMLElement) => void;
  removeSnippet: (id: string) => void;
  clearHistory: () => void;
  toggleVisibility: () => void;
  setClipboardVisibility: (isVisible: boolean) => void; // Explicit set
}

type ScratchClipStore = ScratchClipState & ScratchClipActions;


const useScratchClipStore = create<ScratchClipStore>()(persist(
  (set, _get) => ({

    // initial state
    history: [],
    isVisible: false,


    addSnippet: (text, sourceElement) => {
      const trimmedText = text.trim();
      if (!trimmedText || trimmedText.length === 0 || trimmedText.length > MAX_SNIPPET_LENGTH) {
        console.log('ScratchClip: Snippet empty or too long, not adding.');
        return;
      }

      set((state) => {
        // Avoid adding if it's the exact same as the most recent one
        if (state.history.length > 0 && state.history[0].text === trimmedText) {
          const existingItemIndex = state.history.findIndex(item => item.text === trimmedText);
          if (existingItemIndex === 0) return state; // Already the most recent
        }

        let sourceDescription: string | undefined = undefined;
        if (sourceElement) {
          sourceDescription = sourceElement.id || sourceElement.tagName?.toLowerCase() || 'unknown';
          // Example: const parentEditor = sourceElement.closest('[data-editor-id]');
          // if (parentEditor) sourceDescription = `Editor: ${parentEditor.dataset.editorId}`;
        }

        const newSnippet: ClipboardHistoryItem = {
          id: agiUuid('clip-history'),
          text: trimmedText,
          timestamp: Date.now(),
          source: sourceDescription,
        };

        // Remove existing occurrences of the same text to avoid duplicates, then add new one to top
        const filteredHistory = state.history.filter(item => item.text !== trimmedText);
        const newHistory = [newSnippet, ...filteredHistory].slice(0, MAX_HISTORY_ITEMS);
        return { history: newHistory };
      });
    },

    removeSnippet: (id: string) => {
      set((state) => ({
        history: state.history.filter(item => item.id !== id),
      }));
    },

    clearHistory: () => set({ history: [] }),

    toggleVisibility: () => set((state) => ({ isVisible: !state.isVisible })),
    setClipboardVisibility: (isVisible) => set({ isVisible }),

  }),
  {

    name: 'agi-scratch-clip',

    partialize: ({ history }) => ({
      history, // only persist history
    }),

  }),
);


// actions

export function scratchClipSupported() {
  return supportsClipboardRead();
}

export function scratchClipActions(): ScratchClipActions {
  return useScratchClipStore.getState();
}


// hooks

export function useScratchClipHistory() {
  return useScratchClipStore(useShallow(state => ({
    history: state.history,
    isVisible: state.isVisible,
  })));
}

export function useScratchClipVisibility() {
  const isVisible = useScratchClipStore((state) => state.isVisible);
  return { isVisible, toggleVisibility: useScratchClipStore.getState().toggleVisibility };
}



================================================
FILE: src/common/layout/optima/scratchclip/useGlobalClipboardSaver.ts
================================================
import * as React from 'react';

import { scratchClipActions } from './store-scratchclip';


// basic check for typical editable elements
function isTargetTypicallyEditable(target: EventTarget | null): target is HTMLElement {
  if (!(target instanceof HTMLElement)) return false;
  return (
    target instanceof HTMLInputElement ||
    target instanceof HTMLTextAreaElement ||
    target.isContentEditable || false
  );
}


export function useGlobalClipboardSaver(enabled: boolean) {
  React.useEffect(() => {
    if (!enabled) return;

    const handleClipboardAction = (event: ClipboardEvent) => {
      const targetElement = event.target as HTMLElement | null;

      // ensure the event originated from within our document body
      if (!targetElement || !document.body.contains(targetElement)) {
        return;
      }

      // try to get text from clipboardData first (most reliable for copy/cut)
      let selectedText: string | undefined = undefined;
      if (event.clipboardData) {
        try {
          selectedText = event.clipboardData.getData('text/plain');
        } catch (e) {
          // This can happen in some edge cases or if data type isn't available
          // console.warn('Could not getData from clipboardData:', e);
        }
      }

      // Fallback to window.getSelection() if clipboardData is empty or unavailable
      // This is crucial because sometimes clipboardData might be empty on 'copy' event
      // until the default action completes. However, for our purpose of logging what
      // *was* selected, window.getSelection() is good.
      if (!selectedText || selectedText.trim().length === 0) {
        const selection = window.getSelection();
        if (selection)
          selectedText = selection.toString();
      }

      if (selectedText && selectedText.trim().length > 0) {
        // Only add if the target is editable or there's a general text selection
        // This avoids capturing copies from non-text elements unless text was explicitly selected.
        if (isTargetTypicallyEditable(targetElement) || (window.getSelection()?.toString()?.trim()?.length ?? 0) > 0)
          scratchClipActions().addSnippet(selectedText, targetElement instanceof HTMLElement ? targetElement : undefined);
        // else console.log('ScratchClip: Ignoring copy from non-editable or non-text-selection target.');
      }

      // DO NOT call event.preventDefault() or event.stopPropagation().
      // The native copy/cut operation should proceed as usual.
    };

    // capture both the copy and cut events
    document.addEventListener('copy', handleClipboardAction);
    document.addEventListener('cut', handleClipboardAction);

    return () => {
      document.removeEventListener('copy', handleClipboardAction);
      document.removeEventListener('cut', handleClipboardAction);
    };
  }, [enabled]);
}



================================================
FILE: src/common/layout/overlays/OverlaysInsert.tsx
================================================
import * as React from 'react';

import { useLayoutOverlaysStore } from './store-layout-overlays';


export const OverlaysInsert: React.FC = () => {

  // external state
  const overlays = useLayoutOverlaysStore(state => state.overlays);

  // Transient Overlays / Modals
  return overlays.map(({ id, component }) => (
    <React.Fragment key={id}>{component}</React.Fragment>
  ));
};



================================================
FILE: src/common/layout/overlays/store-layout-overlays.ts
================================================
import * as React from 'react';
import { create } from 'zustand';


// configuration
const STRICT_OVERLAY_CHECKS = process.env.NODE_ENV === 'development';


interface OverlayState {
  overlays: OverlayItem[];
}

interface OverlayItem {
  id: GlobalOverlayId;
  component: React.ReactNode;
  // rejectFn: (reason: any) => void;
}

export type GlobalOverlayId = // string - disabled so we keep an orderliness
  | 'app-recent-changes'                  // Recent changes in the app, only private branch
  | 'chat-attachments-clear'
  | 'chat-delete-confirmation'
  | 'chat-reset-confirmation'
  | 'chat-message-delete-confirmation'
  | 'chat-message-inline-aux'
  | 'livefile-overwrite'
  | 'shortcuts-confirm-close'
  | 'blocks-off-enhance-code'
  | 'llms-service-remove'
  | 'composer-unsupported-attachments'    // The LLM does not seem to support this mime type - continue anyway?
  | 'composer-open-or-attach'             // Open a file or attach it to the chat?
// | 'agi-patch-workflow-save' // make sure we use it
  ;

interface OverlayActions {
  overlayExists: (id: GlobalOverlayId) => boolean;
  appendOverlay: (id: GlobalOverlayId, component: React.ReactNode) => void;
  removeOverlay: (id: GlobalOverlayId) => void;
  overlayToFront: (id: GlobalOverlayId) => void;
  // removeOverlaysBy: (predicate: (item: OverlayItem) => boolean) => void;
}

export const useLayoutOverlaysStore = create<OverlayState & OverlayActions>((set, get) => ({

  // state
  overlays: [],

  // actions

  overlayExists: (id) => get().overlays.some(o => o.id === id),

  appendOverlay: (id, component) =>
    set(state => {

      // sanity check: don't allow duplicate IDs
      if (state.overlayExists(id)) {
        if (STRICT_OVERLAY_CHECKS)
          throw new Error(`appendOverlay: Overlay ID "${id}" already exists`);
        else
          console.warn(`Overlay ID "${id}" already exists`);
      }

      return {
        overlays: [
          ...state.overlays,
          { id, component },
        ],
      };
    }),

  /**
   * This MUST only be called in the context of the calling hook, not by other parties, as it would leave
   * the promises hangind.
   * In this regard, these functions are just dumb for component insertion/removal.
   */
  removeOverlay: (id) =>
    set(state => {
      // sanity check: don't allow removal of non-existent overlays
      if (!state.overlayExists(id)) {
        if (STRICT_OVERLAY_CHECKS)
          throw new Error(`removeOverlay: Overlay ID "${id}" does not exist`);
        else
          console.warn(`Overlay ID "${id}" does not exist`);
      }

      // if (overlay && reason)
      //   overlay.rejectFn(reason);
      return {
        overlays: state.overlays.filter(o => o.id !== id),
      };
    }),

  /**
   * Bring the overlay to the front, which means to move it to the end of the list.
   * @param id
   */
  overlayToFront: (id) =>
    set(state => {
      if (!state.overlayExists(id)) {
        if (STRICT_OVERLAY_CHECKS)
          throw new Error(`overlayToFront: Overlay ID "${id}" does not exist`);
        else
          console.warn(`Overlay ID "${id}" does not exist`);
        return state; // Return the current state without changes
      }

      const overlay = state.overlays.find(o => o.id === id);
      if (!overlay) return state; // This shouldn't happen due to the check above, but TypeScript doesn't know that
      console.log('reordering');
      return {
        overlays: [
          ...state.overlays.filter(o => o !== overlay),
          overlay,
        ],
      };
    }),

  // removeOverlaysBy: (predicate) =>
  //   set(state => {
  //     // const overlaysToRemove = state.overlays.filter(predicate);
  //     // overlaysToRemove.forEach(overlay => {
  //     //   if (reason)
  //     //     overlay.rejectFn(reason);
  //     // });
  //     return {
  //       overlays: state.overlays.filter(o => !predicate(o)),
  //     };
  //   }),

}));



================================================
FILE: src/common/layout/overlays/useOverlayComponents.tsx
================================================
import * as React from 'react';

import { GlobalOverlayId, useLayoutOverlaysStore } from './store-layout-overlays';


enum OverlayCloseReason {
  USER_REJECTED = 'USER_REJECTED',
  UNMOUNTED = 'UNMOUNTED',
  REPLACED = 'REPLACED',
  ALREADY_SHOWN = 'ALREADY_SHOWN',
}

type OverlayComponentProps<TResolve> = {
  onResolve: (value: TResolve) => void;
  onUserReject: () => void;
};

interface ShowOverlayOptions<TResolve> {
  doNotRejectOnUnmount?: boolean;
  rejectWithValue?: Exclude<TResolve, undefined>; // saves a try/catch in the caller
}


// The type of the function that will be returned by the hook
type TShowPromiseOverlay = <TResolve>(
  overlayId: GlobalOverlayId,
  options: ShowOverlayOptions<TResolve>,
  Component: React.ComponentType<OverlayComponentProps<TResolve>>,
) => Promise<TResolve>;


/**
 * Show overlays with promise-like callbacks. IDs are global and unique, for ease of deduplication.
 * - When the component unmounts, by default it will reject all the overlays that don't have
 *   the `doNotRejectOnUnmount` option set.
 * - When a new overlay is requested, it will check if it's already open and reject it if so,
 *   and bring it to the front.
 */
export function useOverlayComponents(): {
  showPromisedOverlay: TShowPromiseOverlay;
} {

  // keep track of active overlays
  // NOTE: this keeps track of the IDs that are open where this hook is used, while the store keeps track of all the components
  // NOTE2:
  const activeOverlaysRef = React.useRef<{
    id: GlobalOverlayId;
    doReject: (reason: OverlayCloseReason) => void;
  }[]>([]);

  // on unmount, reject all active overlays
  React.useEffect(() => {
    return () => {
      for (const { doReject } of activeOverlaysRef.current)
        doReject(OverlayCloseReason.UNMOUNTED);
      activeOverlaysRef.current = [];
    };
  }, []);

  // create a new overlay component with promise-like callbacks
  const showPromisedOverlay = React.useCallback(<TResolve, >(
    overlayId: GlobalOverlayId,
    options: ShowOverlayOptions<TResolve> = {},
    Component: React.ComponentType<OverlayComponentProps<TResolve>>,
  ): Promise<TResolve> => {
    return new Promise<TResolve>((pResolve, pReject) => {

      const { appendOverlay, overlayExists, overlayToFront, removeOverlay } = useLayoutOverlaysStore.getState();

      // Check if the overlay already exists and exit early
      // This is like doReject, but doesn't remove the overlay as we don't insert it
      if (overlayExists(overlayId)) {

        // Look if we own a reference to the former overlay to replace
        const overlayToReplace = activeOverlaysRef.current.find(o => o.id === overlayId);
        if (!overlayToReplace) {
          console.log(`Note: Overlay "${overlayId}" already exists, but we don't have a reference to it. Recovery successful.`);
          if (options.rejectWithValue !== undefined)
            pResolve(options.rejectWithValue);
          else
            pReject(OverlayCloseReason.ALREADY_SHOWN);
          overlayToFront(overlayId);
          return;
        }

        // if it's one of ours, we reject the existing overlay, and remove it, then continue with adding the new one
        overlayToReplace.doReject(OverlayCloseReason.REPLACED);
      }

      const _doRemove = (): boolean => {
        if (!overlayExists(overlayId))
          return false;
        removeOverlay(overlayId);
        activeOverlaysRef.current = activeOverlaysRef.current.filter(o => o.id !== overlayId);
        return true;
      };

      const doResolve = (value: TResolve) => {
        if (_doRemove())
          pResolve(value);
      };

      const doReject = (reason: OverlayCloseReason) => {
        if (_doRemove()) {
          if (options.rejectWithValue !== undefined)
            pResolve(options.rejectWithValue);
          else
            pReject(reason);
        }
      };

      appendOverlay(overlayId,
        <Component
          onResolve={doResolve}
          onUserReject={() => {
            doReject(OverlayCloseReason.USER_REJECTED);
          }}
        />,
      );

      if (!options.doNotRejectOnUnmount)
        activeOverlaysRef.current.push({ id: overlayId, doReject });
    });
  }, []);

  return { showPromisedOverlay };
}



================================================
FILE: src/common/livefile/liveFile.icons.ts
================================================
import { styled } from '@mui/joy';

// import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
// import SystemUpdateAltIcon from '@mui/icons-material/SystemUpdateAlt';
// import UploadFileIcon from '@mui/icons-material/UploadFile';
import FileDownloadOutlinedIcon from '@mui/icons-material/FileDownloadOutlined';
import FileOpenOutlinedIcon from '@mui/icons-material/FileOpenOutlined';
import MobiledataOffIcon from '@mui/icons-material/MobiledataOff';
import MultipleStopIcon from '@mui/icons-material/MultipleStop';
import SaveIcon from '@mui/icons-material/SaveOutlined';

import { LiveFilePatchIcon } from '~/common/components/icons/LiveFilePatchIcon';

export const LiveFileIcon = styled(MultipleStopIcon)({
  rotate: '90deg',
});

export { FileOpenOutlinedIcon as LiveFileChooseIcon };
export { LiveFilePatchIcon as LiveFilePatchIcon };
export { MobiledataOffIcon as LiveFileCloseIcon };
export { SaveIcon as LiveFileSaveIcon };
export { FileDownloadOutlinedIcon as LiveFileReloadIcon };



================================================
FILE: src/common/livefile/livefile.theme.ts
================================================
import type { SxProps } from '@mui/joy/styles/types';

export const liveFileSheetSx: SxProps = {
  p: 1,
  backgroundColor: 'rgb(var(--joy-palette-neutral-lightChannel) / 20%)',
  border: '1px solid',
  borderRadius: 'sm',
  borderColor: 'neutral.outlinedBorder',
  boxShadow: `inset 0 4px 6px -6px rgb(var(--joy-palette-neutral-darkChannel) / 40%)`,
  fontSize: 'sm',
  display: 'flex',
  flexWrap: 'wrap',
  alignItems: 'center',
  gap: 1,
  'button': {
    backgroundColor: 'background.surface',
  },
  'button:hover': {
    backgroundColor: 'background.popup',
    boxShadow: 'xs',
  },
};




================================================
FILE: src/common/livefile/liveFile.types.ts
================================================
export interface LiveFile {
  // literals
  readonly id: LiveFileId;                 // Unique identifier for the LiveFile
  readonly fsHandle: FileSystemFileHandle; // File system handle for file operations

  // last-reloaded content of the file
  content: string | null;         // File content (null if not loaded / last loading failed)

  // metadata
  name: string;                   // File name
  type: string;                   // MIME type of the file
  size: number;                   // File size in bytes
  lastModified: number;           // Last modification timestamp
  created: number;                // Creation timestamp of the LiveFile (not the file itself)

  // dynamic state
  isLoading: boolean;             // Whether the file is currently being loaded
  isSaving: boolean;              // Whether the file is currently being saved
  error: string | null;           // Any error message related to file operations

  // unused
  // references: Set<string>;        // IDs of components/conversations referencing this file

}

export type LiveFileId = string;

// cherry pick some fields from LiveFile
export type LiveFileMetadata = Pick<LiveFile,
  | 'id'                          // Unique identifier matching the LiveFile
  | 'name'                        // File name
  | 'type'                        // MIME type of the file
  | 'size'                        // File size in bytes
  | 'lastModified'                // Last modification timestamp
  | 'created'                     // Creation timestamp of the LiveFile
> & {
  isPairingValid: boolean;        // Whether the file has a valid file system handle and can be operated on
  // referenceCount: number;         // Number of references to this file
};



================================================
FILE: src/common/livefile/store-live-file.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import { agiUuid } from '~/common/util/idUtils';

// import { workspaceActions } from '~/common/stores/workspace/store-client-workspace';
import { Is } from '~/common/util/pwaUtils';

import type { LiveFile, LiveFileId, LiveFileMetadata } from './liveFile.types';


// configuration
const MAX_PER_TEXT_FILE_SIZE = 10 * 1024 * 1024; // 10 MB - this would be a LOT of text, and it's likely an error


// Store State and Actions

interface LiveFileState {

  // Storage of all LiveFile objects
  // NOTE: FileSystemFileHandle objects are stored here BUT they are NOT serializable
  liveFiles: Record<LiveFileId, LiveFile>;

}

interface LiveFileActions {

  // CRUD
  addLiveFile: (fileSystemFileHandle: FileSystemFileHandle) => Promise<LiveFileId>;
  metadataGet: (fileId: LiveFileId) => LiveFileMetadata | null;
  metadataUpdate: (fileId: LiveFileId, metadata: Partial<Omit<LiveFileMetadata, 'id' | 'referenceCount'>>) => void;
  // removeLiveFile: (fileId: LiveFileId) => void;

  // content updates
  contentClose: (fileId: LiveFileId) => Promise<void>;
  contentReloadFromDisk: (fileId: LiveFileId) => Promise<string | null>;
  contentWriteAndReload: (fileId: LiveFileId, content: string) => Promise<boolean>;

}


export const useLiveFileStore = create<LiveFileState & LiveFileActions>()(persist(
  (_set, _get) => ({

    // default state before loading from storage
    liveFiles: {},


    // CRUD

    addLiveFile: async (fileSystemFileHandle: FileSystemFileHandle) => {

      // Reuse existing LiveFile if possible
      for (const otherLiveFile of Object.values(_get().liveFiles)) {
        if (checkPairingValid(otherLiveFile)) {
          const isMatch = await fileSystemFileHandle.isSameEntry(otherLiveFile.fsHandle);
          if (isMatch)
            return otherLiveFile.id;
        }
      }

      // Check for size limit: we're supposed to support medium-sized text files
      const file = await fileSystemFileHandle.getFile();
      if (file.size > MAX_PER_TEXT_FILE_SIZE)
        throw new Error(`Text file too large: ${file.size} bytes. Unsupported.`);

      // Create and store a new LiveFile
      const id = agiUuid('livefile-item');
      const now = Date.now();
      const newLiveFile: LiveFile = {
        id,
        fsHandle: fileSystemFileHandle,
        name: file.name,
        type: file.type,
        size: file.size,
        content: null,
        lastModified: file.lastModified,
        created: now,
        isLoading: false,
        isSaving: false,
        error: null,
        // references: new Set(),
      };

      _set((state) => ({
        liveFiles: {
          ...state.liveFiles,
          [id]: newLiveFile,
        },
      }));

      // Do not auto-load the file here, as this is just creating the
      // LiveFile, but the liveFile is not hot yet (content: null).

      return id;
    },

    metadataGet: (fileId: LiveFileId): LiveFileMetadata | null => {
      const liveFile = _get().liveFiles[fileId];
      if (!liveFile) return null;
      return {
        id: liveFile.id,
        name: liveFile.name,
        type: liveFile.type,
        size: liveFile.size,
        lastModified: liveFile.lastModified,
        created: liveFile.created,
        isPairingValid: checkPairingValid(liveFile),
        // referenceCount: liveFile.references.size,
      };
    },

    metadataUpdate: (fileId: LiveFileId, metadata: Partial<Omit<LiveFileMetadata, 'id' /*| 'referenceCount'*/>>) =>
      _set((state) => {
        const liveFile = state.liveFiles[fileId];
        if (!liveFile) return state;
        return {
          liveFiles: {
            ...state.liveFiles,
            [fileId]: { ...liveFile, ...metadata },
          },
        };
      }),

    // removeLiveFile: (fileId: LiveFileId) =>
    //   _set((state) => {
    //     const { [fileId]: _dropped, ...otherFiles } = state.liveFiles;
    //     // [workspace] remove this LiveFile from all workspaces that have it
    //     // NOTE: the caller will have to also call:
    //     // - workspaceActions().liveFileUnassignFromAll(fileId);
    //     // we can't do it from here, because it will circularly depend on workspaceActions
    //     return {
    //       liveFiles: otherFiles,
    //     };
    //   }),


    // Content updates

    contentClose: async (fileId: LiveFileId) => {
      const liveFile = _get().liveFiles[fileId];
      if (!liveFile || liveFile.isSaving) return;

      _set((state) => ({
        liveFiles: {
          ...state.liveFiles,
          [fileId]: { ...liveFile, content: null, error: null },
        },
      }));
    },

    contentReloadFromDisk: async (fileId: LiveFileId): Promise<string | null> => {
      const liveFile = _get().liveFiles[fileId];

      // Note: .isLoading will also coalesce multiple concurrent reloads into one, as only the first goes through basically
      if (!liveFile || liveFile.isLoading || liveFile.isSaving) return null;

      _set((state) => ({
        liveFiles: {
          ...state.liveFiles,
          [fileId]: { ...liveFile, isLoading: true, error: null },
        },
      }));

      try {
        const file = await liveFile.fsHandle.getFile();
        const fileContent = await file.text();

        _set((state) => ({
          liveFiles: {
            ...state.liveFiles,
            [fileId]: {
              ...liveFile,
              content: fileContent,
              lastModified: file.lastModified,
              isLoading: false,
              error: null,
            },
          },
        }));
        return fileContent;
      } catch (error: any) {
        _set((state) => ({
          liveFiles: {
            ...state.liveFiles,
            [fileId]: {
              ...liveFile,
              content: null,
              isLoading: false,
              error: `Error reading: ${error?.message || typeof error === 'string' ? error : 'Unknown error'}`,
            },
          },
        }));
        return null;
      }
    },

    contentWriteAndReload: async (fileId: LiveFileId, newContent: string): Promise<boolean> => {
      const liveFile = _get().liveFiles[fileId];
      if (!liveFile || liveFile.isSaving) return false;

      _set((state) => ({
        liveFiles: {
          ...state.liveFiles,
          [fileId]: { ...liveFile, isSaving: true, error: null },
        },
      }));

      try {
        // Perform the write
        const writable = await liveFile.fsHandle.createWritable();
        await writable.write(newContent);
        await writable.close();

        // emulate a 'reload' by replacing the content
        _set((state) => ({
          liveFiles: {
            ...state.liveFiles,
            [fileId]: {
              ...liveFile,
              content: newContent,
              isSaving: false,
              lastModified: Date.now(),
            },
          },
        }));

        return true;
      } catch (error: any) {
        _set((state) => ({
          liveFiles: {
            ...state.liveFiles,
            [fileId]: {
              ...liveFile,
              isSaving: false,
              error: `Error saving File: ${error?.message || typeof error === 'string' ? error : 'Unknown error'}`,
            },
          },
        }));
        return false;
      }
    },

  }),
  {

    name: 'agi-live-file',
    // getStorage: () => ...?

    onRehydrateStorage: () => (state) => {
      if (!state) return;

      /* [GC] Remove invalid LiveFiles that did not survive serialization.
       * - Note: `store-chats` [GC] will also depend on this
       *
       * This is an issue because a new LiveFile creation and Pairing will be required.
       * However, it's something we can live with at the moment.
       *
       * In the future, we can use a serializable storage such as IndexedDB:
       * https://developer.chrome.com/docs/capabilities/web-apis/file-system-access#storing_file_handles_or_directory_handles_in_indexeddb
       *
       * Note that we also do this for GC - we could leave the objects here to contain older metadata,
       * but it's probably not worth it.
       */
      state.liveFiles = Object.fromEntries(
        Object.entries(state.liveFiles || {}).filter(([_, file]) => checkPairingValid(file)),
      );

    },

  },
));


// public accessors

/**
 * Checks for Browser support for FileSystemFileHandle, which is the core of the LiveFile feature.
 * - we only check for FileSystemFileHandle for now, not other supports.
 * - within the Attachments subsystem, the presence of FileSystemFileHandle drives the creation, so we don't check for suport there.
 * - in the (at-rest) fragments, we link to the generic LiveFileId, which gets checked for validity at load.
 * - in the Attachment Doc Fragments UI, we check the flag to show the LiveFileControlButton at all.
 * - in the EnhancedRenderCode component, we check the flag to let the user choose/pair the file or not.
 */
export function isLiveFileSupported(): boolean {
  return 'FileSystemFileHandle' in window && typeof FileSystemFileHandle === 'function' && !Is.OS.Android && !Is.OS.iOS && !Is.Browser.Safari;
}

export function liveFileCreateOrThrow(fileSystemFileHandle: FileSystemFileHandle): Promise<LiveFileId> {
  return useLiveFileStore.getState().addLiveFile(fileSystemFileHandle);
}

export function liveFileGetAllValidIDs(): LiveFileId[] {
  return Object.entries(useLiveFileStore.getState().liveFiles)
    .filter(([_, file]) => checkPairingValid(file))
    .map(([id, _]) => id);
}

export function checkPairingValid(file: LiveFile): boolean {
  return typeof (file.fsHandle?.getFile) === 'function';
}



================================================
FILE: src/common/livefile/useLiveFileContent.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { LiveFileId } from './liveFile.types';
import { checkPairingValid, useLiveFileStore } from './store-live-file';


export function useLiveFileContent(liveFileId: LiveFileId | null) {

  // React to changes in data
  const stableData = useLiveFileStore(useShallow((store) => {

    // Reference the file
    const liveFile = liveFileId ? store.liveFiles[liveFileId] ?? null : null;
    if (!liveFile) return {
      isPairingValid: false,
    };

    // Extract stable data
    const { fsHandle, ...rest } = liveFile;
    return {
      ...rest,
      isPairingValid: checkPairingValid(liveFile),
    };
  }));


  // Callbacks

  const liveFileContentClose = React.useCallback(async () => {
    if (!liveFileId) return;
    await useLiveFileStore.getState().contentClose(liveFileId);
  }, [liveFileId]);

  const liveFileContentReloadFromDisk = React.useCallback(async (loadDifferentFileId?: LiveFileId) => {
    const idToLoad = loadDifferentFileId || liveFileId;
    if (idToLoad)
      await useLiveFileStore.getState().contentReloadFromDisk(idToLoad);
  }, [liveFileId]);

  const liveFileContentWriteAndReload = React.useCallback(async (content: string) => {
    if (!liveFileId) return false;
    return await useLiveFileStore.getState().contentWriteAndReload(liveFileId, content);
  }, [liveFileId]);


  // Return data and methods
  const { isPairingValid, ...fileData } = stableData;
  return {
    // data
    isPairingValid,
    fileData: ('id' in fileData) ? fileData : null,

    // methods
    liveFileContentClose,
    liveFileContentReloadFromDisk,
    liveFileContentWriteAndReload,
  };
}



================================================
FILE: src/common/livefile/useLiveFileMetadata.tsx
================================================
import type { LiveFileId, LiveFileMetadata } from '~/common/livefile/liveFile.types';
import { useLiveFileStore } from '~/common/livefile/store-live-file';
import { useShallow } from 'zustand/react/shallow';

export function useLiveFileMetadata(liveFileId: LiveFileId | undefined): LiveFileMetadata | null {
  return useLiveFileStore(useShallow((store) =>
    !liveFileId ? null : store.metadataGet(liveFileId),
  ));
}


================================================
FILE: src/common/logger/index.ts
================================================
// re-export the core functionality
export type { LogEntry, LogLevel, LogSource } from './logger.types';

// re-export the global handlers
export { setupClientFetchErrorsLogging } from './interceptors/logger.network';
export { setupClientUncaughtErrorsLogging } from './interceptors/logger.unhandled';

// re-export the core functionality
export { logger } from './logger.client';

// re-export the module logger factory
export type { ClientLogger } from './logger.types';
export { createModuleLogger } from './logger.factory';



================================================
FILE: src/common/logger/logger.client.ts
================================================
import { maybeDebuggerBreak, serializeError } from '~/common/util/errorUtils';

import type { ClientLogger, LogEntry, LogLevel, LogOptions, LogSource } from './logger.types';
import { LoggerActions, useLoggerStore } from './store-logger';


class LoggerImplementation implements ClientLogger {

  constructor(private readonly _actions: LoggerActions) {
  }

  // Level to method mapping

  DEV = (message: string, details?: any, source?: LogSource, options?: LogOptions): string =>
    this.#log('DEV', message, details, source, options);

  debug = (message: string, details?: any, source?: LogSource, options?: LogOptions): string =>
    this.#log('debug', message, details, source, options);

  info = (message: string, details?: any, source?: LogSource, options?: LogOptions): string =>
    this.#log('info', message, details, source, options);

  warn = (message: string, details?: any, source?: LogSource, options?: LogOptions): string =>
    this.#log('warn', message, details, source, options);

  error = (message: string, details?: any, source?: LogSource, options?: LogOptions): string =>
    this.#log('error', message, details, source, options);

  critical = (message: string, details?: any, source?: LogSource, options?: LogOptions): string =>
    this.#log('critical', message, details, source, options);


  async executeAction(logId: string, actionId?: string): Promise<void> {

    const entry = this._actions.getEntry(logId);
    if (!entry?.actions?.length)
      throw new Error(`No actions available for log entry ${logId}`);

    // find the specific action to execute, or the first non-completed action
    const action = entry.actions.find(a => actionId ? a.id === actionId : !a.completed);
    if (!action)
      throw new Error(`No action found for log entry ${logId}`);

    if (actionId && action.completed)
      throw new Error(`Action ${actionId} already completed for log entry ${logId}`);

    try {
      await action.handler();
      this._actions.markActionCompleted(logId, action.id);
    } catch (error) {

      // log the failure but don't mark as completed
      this.error(
        `Failed to execute action "${action.label}" for log: ${entry.message}`,
        { error, originalLogId: logId },
        entry.source,
      );

      // re-throw for caller handling
      throw error;
    }
  }


  // Pass-through methods to store actions

  markActionCompleted = (logId: string, actionId?: string): void =>
    this._actions.markActionCompleted(logId, actionId);

  markDismissed = (logId: string): void =>
    this._actions.markDismissed(logId);

  getPendingActions = (): LogEntry[] =>
    this._actions.getPendingActionEntries();


  /// Internal ///

  #log(level: LogLevel, message: string, details?: any, source?: LogSource, options?: LogOptions): string {

    // if param 3 is an object but not a valid source, assume it's the options and source was omitted
    if (source && typeof source === 'object' && !options) {
      options = source as any;
      source = undefined;
    }

    // combine options
    const finalOptions = options || {};
    const finalSource = source || finalOptions.source || 'unknown';
    const finalDetails = serializeError(details || finalOptions.details); // serializeError because otherwise 'Error' wouldn't be serializable, and would appear as {}

    // prepare actions - handle both options.action and options.actions
    let actions = finalOptions.actions || [];
    if (finalOptions.action && !actions.length)
      actions = [finalOptions.action];

    // Add debugger break for error and critical levels
    if ((level === 'error' || level === 'critical' || level === 'DEV') && !finalOptions.skipDebuggerBreak)
      maybeDebuggerBreak();

    return this._actions._addEntry({
      level,
      message,
      details: finalDetails,
      source: finalSource,
      ...(actions.length > 0 ? { actions } : {}),
    });
  }

}

const _logger = new LoggerImplementation(useLoggerStore.getState());


/** Global logger instance */
export const logger = _logger;


================================================
FILE: src/common/logger/logger.factory.ts
================================================
import type { ClientLogger, LogOptions, LogSource } from './logger.types';
import { logger } from './logger.client';


/**
 * Creates a module-specific logger with a predefined source and optional event prefix.
 *
 * @param source The source identifier for all logs from this module
 * @param prefix Optional prefix/function prefix to prepend to all log messages
 * @returns A logger instance with preset source and prefix
 */
export function createModuleLogger(source: LogSource | string, prefix?: string | (() => string)): ClientLogger & { source: string } {

  // format message with prefix if provided
  const prefixMessage =
    typeof prefix === 'function' ? (message: string): string => `${prefix()} ${message}`
      : prefix ? (message: string): string => `${prefix}: ${message}`
        : (message: string): string => message;

  return {
    DEV: (message: string, details?: any, _overrideSource?: LogSource, options?: LogOptions) =>
      logger.DEV(prefixMessage('[DEV] ' + message), details, source as LogSource, options),

    debug: (message: string, details?: any, _overrideSource?: LogSource, options?: LogOptions) =>
      logger.debug(prefixMessage(message), details, source as LogSource, options),

    info: (message: string, details?: any, _overrideSource?: LogSource, options?: LogOptions) =>
      logger.info(prefixMessage(message), details, source as LogSource, options),

    warn: (message: string, details?: any, _overrideSource?: LogSource, options?: LogOptions) =>
      logger.warn(prefixMessage(message), details, source as LogSource, options),

    error: (message: string, details?: any, _overrideSource?: LogSource, options?: LogOptions) =>
      logger.error(prefixMessage(message), details, source as LogSource, options),

    critical: (message: string, details?: any, _overrideSource?: LogSource, options?: LogOptions) =>
      logger.critical(prefixMessage(message), details, source as LogSource, options),

    // forward action methods directly to the main logger
    executeAction: logger.executeAction,
    markActionCompleted: logger.markActionCompleted,
    markDismissed: logger.markDismissed,
    getPendingActions: logger.getPendingActions,

    // the name
    source,
  };
}



================================================
FILE: src/common/logger/logger.types.ts
================================================
/**
 * Client-side centralized logging system
 * For inspect-able and debuggable logs.
 */
export interface ClientLogger {

  // Logging methods (by level)
  DEV: (message: string, details?: any, source?: LogSource, options?: LogOptions) => LogEntryId;
  debug: (message: string, details?: any, source?: LogSource, options?: LogOptions) => LogEntryId;
  info: (message: string, details?: any, source?: LogSource, options?: LogOptions) => LogEntryId;
  warn: (message: string, details?: any, source?: LogSource, options?: LogOptions) => LogEntryId;
  error: (message: string, details?: any, source?: LogSource, options?: LogOptions) => LogEntryId;
  critical: (message: string, details?: any, source?: LogSource, options?: LogOptions) => LogEntryId;

  /**
   * Execute an action associated with a log entry
   * @returns Promise that resolves when the action completes, or rejects if it fails (handler throws/rejects)
   */
  executeAction: (logId: LogEntryId, actionId?: LogActionId) => Promise<void>;

  /** Mark an action as completed without executing its handler */
  markActionCompleted: (logId: LogEntryId, actionId?: LogActionId) => void;
  /** Mark a log entry as dismissed */
  markDismissed: (logId: LogEntryId) => void;
  /** Get all log entries with pending actions */
  getPendingActions: () => LogEntry[];

}

export type LogLevel =
  | 'DEV'
  | 'debug'
  | 'info'
  | 'warn'
  | 'error'
  | 'critical';

export type LogSource =
  | 'unknown'   // DO NOT USE
  | 'unhandled' // uncaught exceptions
  | 'client'    // includes uncaught exceptions
  | 'network'   // network errors - includes the automatic fetch interceptor
// add new sources here as we continue using this system
// | 'server'
// | 'storage'
// | 'sync'
// | 'ai-service'
// | 'application'
  ;

/** Options object for logging methods */
export interface LogOptions {
  details?: any;
  source?: LogSource;
  action?: Omit<LogEntryAction, 'completed' | 'completedTimestamp'>; // Single action convenience
  actions?: Omit<LogEntryAction, 'completed' | 'completedTimestamp'>[]; // Multiple actions
  skipDebuggerBreak?: boolean; // Skip debugger break even if applicable to the level/build/env
}

/** Potential action associated with an entry */
export interface LogEntryAction {
  id?: LogActionId;             // optional action ID (for choosing which to execute on multiple actions)
  label: string;                // action button text
  handler: () => Promise<any>;  // async action handler
  completed?: boolean;          // (at the end) whether action was completed (via handler or manually)
  completedTimestamp?: number;  // when action was completed
}


export interface LogEntry {
  id: LogEntryId;
  timestamp: number;         // UNIX timestamp in ms
  level: LogLevel;           // Severity level
  source: LogSource;         // Origin component/system
  message: string;           // Human readable description
  details?: any;             // Optional structured data
  actions?: LogEntryAction[];     // Optional array of actions

  // State flags
  shown?: boolean;           // Whether displayed to user (for notifications)
  dismissed?: boolean;       // Whether explicitly dismissed by user
  hasPendingActions?: boolean; // Calculated flag: has actions not completed/dismissed
  
  // Repetition tracking
  repetitionCount?: number;  // Number of times this exact message was repeated
}

type LogEntryId = string;
type LogActionId = string;



================================================
FILE: src/common/logger/store-logger.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import { Release } from '~/common/app.release';
import { agiUuid } from '~/common/util/idUtils';

import type { LogEntry } from './logger.types';

//
// Note: right now it's not persisted - to persist uncomment the persistence code below
//

// configuration
const DEFAULT_MAX_ENTRIES = 500;
const DEFAULT_MAX_PERSISTED = 100;
const DEFAULT_MAX_PERSISTED_DETAILS_LEN = 500;
const DEBUG_NEW_LOG = Release.IsNodeDevBuild;


const _checkPendingActions = (entry: LogEntry): boolean => {
  return !!entry.actions?.some(a => !a.completed) && !entry.dismissed;
};


// --- Logger Store ---

interface LoggerState {

  entries: LogEntry[];
  maxEntries: number;

}

export interface LoggerActions {

  // internal actions
  _addEntry: (entry: Omit<LogEntry, 'id' | 'timestamp' | 'hasPendingActions'>) => string;
  _updateEntry: (id: string, update: Partial<LogEntry>) => void;

  // queries
  getEntry: (id: string) => LogEntry | undefined;
  getPendingActionEntries: () => LogEntry[];

  // public actions
  markShown: (id: string) => void;
  markDismissed: (id: string) => void;
  markActionCompleted: (id: string, actionId?: string) => void;
  clearAll: () => void;

}

export const useLoggerStore = create<LoggerState & LoggerActions>()(
  persist(
    (set, get) => ({

      // initial state

      entries: [],
      maxEntries: DEFAULT_MAX_ENTRIES,


      // actions

      _addEntry: (entryData) => {

        // assign default action IDs, if missing
        let actions = entryData.actions;
        if (actions?.length)
          actions = actions.map((a, index) => ({
            ...a,
            id: a.id || `action_${index}`,
          }));

        const timestamp = Date.now();

        // Check if this is a duplicate of the most recent message
        const state = get();
        const lastEntry = state.entries[0]; // Most recent entry is first

        if (lastEntry && !lastEntry.dismissed &&
          lastEntry.message === entryData.message &&
          lastEntry.level === entryData.level &&
          lastEntry.source === entryData.source &&
          JSON.stringify(lastEntry.details) === JSON.stringify(entryData.details)) {

          // update the last entry with incremented repetitions
          const updatedEntry = {
            ...lastEntry,
            repetitionCount: (lastEntry.repetitionCount || 1) + 1,
            timestamp, // reflect when we last saw this message
          };

          set((state) => ({
            entries: [
              updatedEntry,
              ...state.entries.slice(1),
            ].slice(0, state.maxEntries),
          }));

          // console output in DEV mode
          if (DEBUG_NEW_LOG) {
            const consoleMethod = {
              DEV: console.warn,
              debug: console.log,
              info: console.info, warn: console.warn,
              error: console.error, critical: console.error,
            }[updatedEntry.level] || console.log;
            // NOTE: we don't show repetition count in the console, to let the browser perform its own deduplication
            // consoleMethod(`[${updatedEntry.source || 'client'}] ${updatedEntry.message} (repeated ${updatedEntry.repetitionCount} times)`, updatedEntry.details || '', updatedEntry.actions ? '(Actionable)' : '');
            const consoleMessage = `[${updatedEntry.source || 'client'}] ${updatedEntry.message}${updatedEntry.actions ? ' (Actionable)' : ''}`;
            if (updatedEntry.details) consoleMethod(consoleMessage, updatedEntry.details);
            else consoleMethod(consoleMessage);
          }

          return lastEntry.id;
        }

        // create new log entry
        const id = agiUuid('logger');
        const newEntry: LogEntry = {
          ...entryData,
          id,
          timestamp,
          actions,
        };

        newEntry.hasPendingActions = _checkPendingActions(newEntry);

        // prepend the entry
        set((state) => ({
          entries: [newEntry, ...state.entries].slice(0, state.maxEntries),
        }));

        // console output in DEV mode
        if (DEBUG_NEW_LOG) {
          const consoleMethod = {
            DEV: console.warn, // messages for developers - they represent unexpected behaviors which should be addressed
            debug: console.log, // upping this, because otherwise no output
            info: console.info, warn: console.warn,
            error: console.error, critical: console.error,
          }[newEntry.level] || console.log;
          const consoleMessage = `[${newEntry.source || 'client'}] ${newEntry.message}${newEntry.actions ? ' (Actionable)' : ''}`;
          if (newEntry.details) consoleMethod(consoleMessage, newEntry.details);
          else consoleMethod(consoleMessage);
        }

        return id;
      },

      _updateEntry: (id, update) => {
        set((state) => {

          // find entry
          const index = state.entries.findIndex(e => e.id === id);
          if (index === -1) return state;

          const updatedEntries = [...state.entries];
          const existingEntry = updatedEntries[index];
          const updatedEntry = {
            ...existingEntry,
            ...update,
            // Ensure actions array exists if updating it
            actions: ('actions' in update && update.actions)
              ? [...update.actions]
              : existingEntry.actions ? [...existingEntry.actions]
                : undefined,
          };

          // Recalculate pending status if actions or dismissed status changed
          if ('actions' in update || 'dismissed' in update)
            updatedEntry.hasPendingActions = _checkPendingActions(updatedEntry);

          updatedEntries[index] = updatedEntry;
          return { entries: updatedEntries };
        });
      },

      markShown: (id) => get()._updateEntry(id, { shown: true }),

      markDismissed: (id) => get()._updateEntry(id, { dismissed: true }),

      markActionCompleted: (id, actionId) => {

        const entry = get().getEntry(id);
        if (!entry?.actions) return;

        let actionMarked = false;
        const updatedActions = entry.actions.map(a => {
          // mark specific action or the first pending one if no ID provided
          if (!a.completed && ((actionId && a.id === actionId) || (!actionId))) {
            actionMarked = true;
            return { ...a, completed: true, completedTimestamp: Date.now() };
          }
          return a;
        });

        // only update if an action was actually marked
        if (actionMarked)
          get()._updateEntry(id, { actions: updatedActions });
      },

      clearAll: () => set({ entries: [] }),

      getEntry: (id) => get().entries.find(e => e.id === id),

      getPendingActionEntries: () => get().entries.filter(e => e.hasPendingActions),

    }),
    {

      name: 'agi-logger-log',

      // persist non-debug, non-dismissed entries, or those with pending actions
      partialize: (state) => ({
        ...state,
        entries: state.entries
          .filter(e => e.level !== 'debug' && !e.dismissed)
          .slice(0, DEFAULT_MAX_PERSISTED)
          .map(e => {
            // remove any actions
            const { actions, hasPendingActions, ...rest } = e;
            // Truncate details if too large
            if (rest.details) {
              const detailsStr = JSON.stringify(rest.details);
              if (detailsStr.length > 1000) {
                rest.details = {
                  truncated: true,
                  preview: detailsStr.substring(0, DEFAULT_MAX_PERSISTED_DETAILS_LEN) + '...',
                };
              }
            }
            return rest;
          }),
      }),

    },
  ),
);



================================================
FILE: src/common/logger/hooks/useClientLoggerInterception.ts
================================================
import * as React from 'react';

import { setupClientFetchErrorsLogging, setupClientUncaughtErrorsLogging } from '~/common/logger';


/**
 * Custom React hook that sets up client-side logging interceptors exactly once,
 * even under Strict Mode, without double initialization.
 */
export function useClientLoggerInterception(captureUnhandledErrors: boolean, captureFetchErrors: boolean) {
  React.useEffect(() => {
    // mount
    const cleanupFetch = !captureFetchErrors ? undefined : setupClientFetchErrorsLogging();
    const cleanupUncaught = !captureUnhandledErrors ? undefined : setupClientUncaughtErrorsLogging();

    // unmount
    return () => {
      cleanupFetch?.();
      cleanupUncaught?.();
    };
  }, [captureFetchErrors, captureUnhandledErrors]);
}



================================================
FILE: src/common/logger/interceptors/logger.network.ts
================================================
import { isBrowser } from '~/common/util/pwaUtils';
import { logger } from '~/common/logger';


/**
 * Wraps fetch to log network errors
 */
export function setupClientFetchErrorsLogging(): () => void {
  if (!isBrowser) return () => { /* no-op */
  };

  const originalFetch = window.fetch;

  window.fetch = async function wrappedFetch(input, init) {
    try {
      const response = await originalFetch.apply(this, [input, init]);

      // log unsuccessful responses
      if (!response.ok)
        logger.error(`Network request failed: ${response.status} ${response.statusText}`, {
          url: typeof input === 'string' ? input : input instanceof URL ? input.toString() : input.url,
          method: init?.method || 'GET',
          status: response.status,
          statusText: response.statusText,
        }, 'network');

      return response;

    } catch (error: any) {

      // log connection errors (offline, etc.)
      logger.error(`Network request error`, {
        url: typeof input === 'string' ? input : input instanceof URL ? input.toString() : input.url,
        method: init?.method || 'GET',
        error: error?.message || error.toString(),
      }, 'network', {
        action: {
          // example action - shall open connection troubleshooting panel or check connection
          label: 'Check Connection',
          handler: async () => {
            if (navigator.onLine)
              logger.info('Device appears to be online. Issue might be server-related.');
            else
              logger.warn('Device is offline. Please check your internet connection.');
          },
        },
      });

      throw error;
    }
  };

  // cleanup function
  const justWrappedFetch = window.fetch;
  return () => {
    if (window.fetch === justWrappedFetch)
      window.fetch = originalFetch;
  };
}



================================================
FILE: src/common/logger/interceptors/logger.unhandled.ts
================================================
import { isBrowser } from '~/common/util/pwaUtils';
import { logger } from '~/common/logger';


/**
 * Intercept & log global uncaught client errors
 */
export function setupClientUncaughtErrorsLogging(): () => void {
  if (!isBrowser) return () => { /* no-op */
  };

  // Handle uncaught exceptions
  const handleError = (event: ErrorEvent) => {
    logger.error('Uncaught error', {
      message: event.error?.message || event.message,
      stack: event.error?.stack,
      filename: event.filename,
      lineno: event.lineno,
      colno: event.colno,
    }, 'unhandled');
  };

  // Handle unhandled promise rejections
  const handleRejection = (event: PromiseRejectionEvent) => {
    logger.error('Unhandled promise rejection', {
      reason: event.reason,
      message: event.reason?.message,
      stack: event.reason?.stack,
    }, 'unhandled');
  };

  // install
  window.addEventListener('error', handleError);
  window.addEventListener('unhandledrejection', handleRejection);

  // cleanup function
  return () => {
    window.removeEventListener('error', handleError);
    window.removeEventListener('unhandledrejection', handleRejection);
  };
}



================================================
FILE: src/common/logger/viewer/LogEntryDetails.tsx
================================================
import * as React from 'react';

import { Box, Button, Card, Chip, CircularProgress, Divider, Stack, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import CheckCircleIcon from '@mui/icons-material/CheckCircle';

import { logger } from '~/common/logger';

import type { LogEntry } from '../logger.types';


function _formatTime(timestamp: number) {
  return new Date(timestamp).toLocaleString();
}


export function LogEntryDetails(props: {
  entry: LogEntry;
  onCloseDetails: () => void;
}) {

  // state
  const [executing, setExecuting] = React.useState<string | null>(null);
  const [executionError, setExecutionError] = React.useState<string | null>(null);

  const { entry } = props;


  const handleExecuteAction = async (actionId?: string) => {
    setExecuting(actionId || 'default');
    setExecutionError(null);
    try {
      await logger.executeAction(entry.id, actionId);
    } catch (error) {
      setExecutionError((error as Error).message || 'Action failed');
    } finally {
      setExecuting(null);
    }
  };


  return (
    <Card variant='outlined' sx={{ backgroundColor: 'background.popup' }}>
      <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
        <Typography level='title-md'>{entry.message}</Typography>
        <Button
          size='sm'
          variant='plain'
          color='neutral'
          onClick={props.onCloseDetails}
          startDecorator={<CloseRoundedIcon />}
        >
          Close
        </Button>
      </Box>

      <Divider />

      {/* Log Info */}
      <Box sx={{ mt: 1, display: 'grid', gridTemplateColumns: 'auto 1fr auto 1fr', gap: 1, fontSize: 'sm' }}>
        <Box fontWeight='bold'>Level:</Box>
        <div>{entry.level}</div>
        <Box fontWeight='bold'>Source:</Box>
        <div>{entry.source}</div>
        <Box fontWeight='bold'>Time:</Box>
        <div>{_formatTime(entry.timestamp)}</div>
        {entry.repetitionCount && (
          <>
            <Box fontWeight='bold'>Repetitions:</Box>
            <div>{entry.repetitionCount} times</div>
          </>
        )}
      </Box>

      {/* Log Details */}
      {entry.details && (
        <Card
          variant='outlined'
          sx={{
            fontFamily: 'code',
            fontSize: 'xs',
            whiteSpace: 'pre-wrap',
            wordBreak: 'break-all',
            maxHeight: '300px',
            overflow: 'auto',
            p: 1,
          }}
        >
          {typeof entry.details === 'string'
            ? entry.details
            : JSON.stringify(entry.details, null, 2)
          }
        </Card>
      )}

      {/* Actions */}
      {entry.actions && entry.actions.length > 0 && (
        <>
          <Typography level='title-sm' sx={{ mb: 1 }}>Actions</Typography>
          <Stack direction='row' spacing={1} flexWrap='wrap' sx={{ mb: 1 }}>
            {entry.actions.map((action, index) => (
              <Button
                key={action.id || index}
                size='sm'
                variant={action.completed ? 'soft' : 'solid'}
                color={action.completed ? 'success' : 'primary'}
                disabled={action.completed || !!executing}
                startDecorator={
                  action.completed
                    ? <CheckCircleIcon />
                    : executing === (action.id || 'default')
                      ? <CircularProgress size='sm' />
                      : null
                }
                onClick={() => handleExecuteAction(action.id)}
                sx={{ mb: 1 }}
              >
                {action.label}
                {action.completed && action.completedTimestamp && (
                  <Chip size='sm' variant='soft' color='success' sx={{ ml: 1 }}>
                    {new Date(action.completedTimestamp).toLocaleTimeString()}
                  </Chip>
                )}
              </Button>
            ))}
          </Stack>

          {/* Execution error */}
          {executionError && (
            <Card variant='soft' color='danger' sx={{ mt: 1 }}>
              <Typography level='body-sm'>{executionError}</Typography>
            </Card>
          )}
        </>
      )}
    </Card>
  );
}



================================================
FILE: src/common/logger/viewer/LoggerViewerDialog.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import type { ColorPaletteProp } from '@mui/joy/styles/types';
import { Box, Button, Chip, Divider, FormControl, FormLabel, Option, Select, Table, Typography } from '@mui/joy';
import BugReportIcon from '@mui/icons-material/BugReport';
import ClearAllIcon from '@mui/icons-material/ClearAll';
import ErrorIcon from '@mui/icons-material/Error';
import InfoIcon from '@mui/icons-material/Info';
import NotificationsActiveIcon from '@mui/icons-material/NotificationsActive';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { GoodModal } from '~/common/components/modals/GoodModal';

import type { LogEntry, LogLevel, LogSource } from '../logger.types';
import { useLoggerStore } from '../store-logger';

import { LogEntryDetails } from './LogEntryDetails';


function _getLogLevelIcon(level: LogLevel) {
  switch (level) {
    case 'debug':
      return <BugReportIcon fontSize='small' color='action' />;
    case 'info':
      return <InfoIcon fontSize='small' color='info' />;
    case 'warn':
      return <WarningRoundedIcon fontSize='small' color='warning' />;
    case 'error':
      return <ErrorIcon fontSize='small' color='error' />;
    case 'critical':
      return <NotificationsActiveIcon fontSize='small' color='error' />;
    default:
      return null;
  }
}

function _getLogLevelColor(level: LogLevel): ColorPaletteProp {
  return ({
    'DEV': 'warning',
    'debug': 'neutral',
    'info': 'primary',
    'warn': 'warning',
    'error': 'danger',
    'critical': 'danger',
  } satisfies { [level: string]: ColorPaletteProp })[level] || 'neutral';
}

// function _formatTime(timestamp: number) {
//   return new Date(timestamp).toLocaleTimeString();
// }


export function LogViewerDialog(props: {
  onClose: () => void;
}) {

  // state
  const [filterLevel, setFilterLevel] = React.useState<LogLevel | 'all'>('all');
  const [filterSource, setFilterSource] = React.useState<LogSource | 'all'>('all');
  const [selectedLogId, setSelectedLogId] = React.useState<LogEntry['id'] | null>(null);

  // external state
  const entries = useLoggerStore(state => state.entries);


  // derived state

  // unique sources for filter dropdown
  const availableSources = React.useMemo(() => {
    const sources = new Set(entries.map(e => e.source));
    return Array.from(sources);
  }, [entries]);

  const filteredEntries = React.useMemo(() => {
    return entries.filter(entry =>
      (filterLevel === 'all' || entry.level === filterLevel) &&
      (filterSource === 'all' || entry.source === filterSource),
    );
  }, [entries, filterLevel, filterSource]);

  const entry = React.useMemo(() => {
    return !selectedLogId ? undefined : entries.find(e => e.id === selectedLogId);
  }, [entries, selectedLogId]);


  // handlers

  const handleClearAll = React.useCallback(() => {
    useLoggerStore.getState().clearAll();
    setSelectedLogId(null);
  }, []);


  return (
    <GoodModal
      open
      onClose={props.onClose}
      title='Client Logs'
      unfilterBackdrop
      // themedColor='neutral'
      sx={{ maxWidth: undefined, overflow: 'hidden' }}
    >
      <Box sx={{ display: 'flex', flexDirection: { xs: 'column', md: 'row' }, gap: 2, mb: 1 }}>

        {/* Level Filter */}
        <FormControl sx={{ flex: 1 }}>
          <FormLabel>Level</FormLabel>
          <Select
            size='sm'
            value={filterLevel}
            onChange={(_, value) => value !== null && setFilterLevel(value)}
            sx={{ backgroundColor: 'background.popup' }}
          >
            <Option value='all'>All Levels</Option>
            <Option value='debug'>Debug</Option>
            <Option value='info'>Info</Option>
            <Option value='warn'>Warning</Option>
            <Option value='error'>Error</Option>
            <Option value='critical'>Critical</Option>
          </Select>
        </FormControl>

        {/* Source Filter */}
        <FormControl sx={{ flex: 1 }}>
          <FormLabel>Source</FormLabel>
          <Select
            size='sm'
            value={filterSource}
            onChange={(_, value) => value !== null && setFilterSource(value)}
            sx={{ backgroundColor: 'background.popup' }}
          >
            <Option value='all'>All Sources</Option>
            {availableSources.map(source => (
              <Option key={source} value={source}>{source}</Option>
            ))}
          </Select>
        </FormControl>

        {/* Clear Button */}
        <Box sx={{ display: 'flex', alignItems: 'flex-end' }}>
          <Button
            size='sm'
            color='danger'
            onClick={handleClearAll}
            startDecorator={<ClearAllIcon />}
            disabled={entries.length === 0}
          >
            Clear Logs
          </Button>
        </Box>
      </Box>

      {/*<Divider />*/}

      {/* Log entries table */}
      {filteredEntries.length === 0 ? (
        <Box sx={{ display: 'flex', justifyContent: 'center', alignItems: 'center', height: '200px' }}>
          <Typography level='body-lg'>No logs to display</Typography>
        </Box>
      ) : (
        <Box sx={{ minHeight: '12rem', overflow: 'auto', my: 1 }}>
          <Table
            size='sm'
            variant='outlined'
            sx={{
              '& th': { fontWeight: 'bold', whiteSpace: 'nowrap', p: 1 },
              '& td': { p: 1 },
              '& tr:hover': { backgroundColor: 'background.level1', cursor: 'pointer' },
              '& tr.selected': { backgroundColor: 'background.level2' },
              backgroundColor: 'background.popup',
              overflow: 'hidden',
            }}
          >
            <thead>
            <tr>
              <th style={{ width: '30px' }}></th>
              <th style={{ width: '120px' }}>Time</th>
              <th style={{ width: '80px' }}>Level</th>
              <th style={{ width: '120px' }}>Source</th>
              <th style={{ minWidth: '100px' }}>Message</th>
              <th style={{ width: '100px' }}>Actions</th>
            </tr>
            </thead>
            <tbody>
            {filteredEntries.map((entry) => (
              <tr
                key={entry.id}
                onClick={() => setSelectedLogId(entry.id)}
                className={selectedLogId === entry.id ? 'selected' : undefined}
              >
                <td>{_getLogLevelIcon(entry.level)}</td>
                <td>
                  <TimeAgo date={entry.timestamp} />
                  {entry.repetitionCount && (
                    <Typography 
                      level='body-xs' 
                      sx={{ ml: 0.5, color: 'text.secondary' }}
                    >
                      (×{entry.repetitionCount})
                    </Typography>
                  )}
                </td>
                {/*<td>{_formatTime(entry.timestamp)}</td>*/}
                <td>
                  <Chip
                    size='sm'
                    color={_getLogLevelColor(entry.level)}
                    variant='soft'
                  >
                    {entry.level}
                  </Chip>
                </td>
                <td style={{ whiteSpace: 'nowrap' }}>{entry.source}</td>
                <td className='agi-ellipsize'>
                  {entry.message}
                  {entry.repetitionCount && (
                    <Typography level='body-xs' sx={{ ml: 1, color: 'text.secondary', display: 'inline' }}>
                      (×{entry.repetitionCount})
                    </Typography>
                  )}
                </td>
                <td>
                  {entry.actions && entry.actions.length > 0 && (
                    <Chip size='sm' variant='outlined'>
                      {entry.hasPendingActions ? 'Pending' : 'Complete'}
                    </Chip>
                  )}
                </td>
              </tr>
            ))}
            </tbody>
          </Table>
        </Box>
      )}

      {/* Selected Log Details */}
      {entry && <>

        <Divider />

        <Box sx={{ mt: 1 }}>
          <LogEntryDetails
            entry={entry}
            onCloseDetails={() => setSelectedLogId(null)}
          />
        </Box>
      </>}
    </GoodModal>
  );
}



================================================
FILE: src/common/logic/ProcessingQueue.ts
================================================
import * as React from 'react';

import { agiUuid } from '~/common/util/idUtils';


/**
 * Pure async function that operates on an item, can monitor the abort signal, and return or throw
 * optionally it can update progress using the given updateProgress function
 */
export type ItemAsyncWorker<T> =
  (item: T, updateProgress: (progress: number) => void, signal: AbortSignal) => Promise<T>;


/**
 * A queue for processing items of the same type with an async processing function, under the constraints of
 * concurrency limit and rate limit.
 */
export class ProcessingQueue<TItem> extends EventTarget {
  private queue: QueuedItem<TItem>[] = [];
  private inProgress = new Map<string, QueuedItem<TItem>>();
  private rateLimitTimer: ReturnType<typeof setTimeout> | null = null;

  constructor(
    private maxConcurrent: number,
    private rateLimit: number, // Tasks per second
    private itemWorker: ItemAsyncWorker<TItem>,
  ) {
    super();
  }

  // returns a promise that resolves after processing
  enqueueItem(item: TItem, priority: number = 0): Promise<TItem> {
    const taskId = agiUuid('processing-queue-task');
    const enqueuedAt = Date.now();

    // Create a new AbortController for each task
    const abortController = new AbortController();

    // Return a new promise. The resolve and reject functions of this promise are stored in the task object,
    // so they can be called when the task is processed or if an error occurs.
    // noinspection UnnecessaryLocalVariableJS
    const taskItemPromise = new Promise<TItem>((resolve, reject) => {
      const task: QueuedItem<TItem> = { item, priority, resolve, reject, taskId, enqueuedAt, progress: 0, abortController };
      this.queue.push(task);
      this.sortQueue();
      this.dispatchEvent(new QueueUpdatedEvent(this.getQueueState()));
      this.processQueue();
    });

    return taskItemPromise;
  }

  // cancel a task, either in the queue or being executed
  cancel(taskId: string): void {
    // Check if the task is in the queue and remove it
    this.queue = this.queue.filter(task => task.taskId !== taskId);

    // Check if the task is in progress
    if (this.inProgress.has(taskId)) {
      const task = this.inProgress.get(taskId);
      task?.abortController.abort(); // Abort the task
      this.inProgress.delete(taskId); // Remove the task from inProgress
    }

    // Emit a queue updated event
    this.dispatchEvent(new QueueUpdatedEvent(this.getQueueState()));
  }

  // cancel all tasks
  cancelAll(): void {
    this.queue = [];
    this.inProgress.forEach(task => task.abortController.abort());
    this.inProgress.clear();
    this.dispatchEvent(new QueueUpdatedEvent(this.getQueueState()));
  }

  private sortQueue(): void {
    this.queue.sort((a, b) =>
      a.priority !== b.priority
        ? b.priority - a.priority
        : b.enqueuedAt - a.enqueuedAt);
  }

  private processQueue(): void {
    // If the maximum concurrency has been reached, or there are no tasks in the queue, or the rate limit timer is active, return
    if (this.inProgress.size >= this.maxConcurrent || this.queue.length === 0 || this.rateLimitTimer !== null)
      return;

    // Calculate the delay based on the rate limit
    const delay = Math.round(1000 / this.rateLimit);
    this.rateLimitTimer = setTimeout(() => {
      this.rateLimitTimer = null;
      if (this.queue.length === 0) return;

      const task = this.queue.shift()!;
      this.inProgress.set(task.taskId, task);

      const updateProgress = (progress: number) => {
        task.progress = progress;
        this.dispatchEvent(new QueueUpdatedEvent(this.getQueueState()));
      };

      updateProgress(0);

      this.itemWorker(task.item, updateProgress, task.abortController.signal)
        .then(result => {
          // if (task.abortController.signal.aborted) {
          //   return task.reject(new Error('Task was aborted and worker did not throw'));
          // }
          task.resolve(result);
          task.progress = 100;
          this.inProgress.delete(task.taskId);
        })
        .catch(error => {
          task.reject(error);
          this.inProgress.delete(task.taskId);
          // Dev-only message
          console.error(`Task ${task.taskId} failed: ${error.message}`);
        })
        .finally(() => {
          this.dispatchEvent(new QueueUpdatedEvent(this.getQueueState()));
          this.processQueue();
        });
    }, delay);
  }

  getQueueState() {
    return {
      totalSize: this.queue.length + this.inProgress.size,
      queueSize: this.queue.length,
      inProgressSize: this.inProgress.size,
      items: [...this.inProgress.values(), ...this.queue],
    };
  }

}


export type QueuedItem<TItem> = {
  item: TItem;
  priority: number;
  resolve: (value: TItem) => void; // Function to resolve the promise returned by enqueue
  reject: (reason?: any) => void; // Function to reject the promise returned by enqueue
  enqueuedAt: number; // Time the task was enqueued
  taskId: string; // Unique identifier for the task
  progress: number; // Progress of the task
  abortController: AbortController; // Controller to abort the task
}


// Mechanisms for Hooks

type QueueState<TItem> = ReturnType<typeof ProcessingQueue<TItem>['prototype']['getQueueState']>;

// set to the return type of the getQueueState method of ProcessingQueue
class QueueUpdatedEvent<TItem> extends CustomEvent<QueueState<TItem>> {
  constructor(detail: QueueState<TItem>) {
    super('queueUpdated', { detail });
  }
}

export function useProcessingQueue<TItem>(myItemQueue: ProcessingQueue<TItem>) {

  // initial state
  const [queueState, setQueueState] = React.useState(myItemQueue.getQueueState());

  // state updates
  React.useEffect(() => {
    const handleQueueUpdated = (event: Event) => {
      const queueUpdatedEvent = event as QueueUpdatedEvent<QueueState<TItem>>;
      setQueueState(queueUpdatedEvent.detail);
    };

    myItemQueue.addEventListener('queueUpdated', handleQueueUpdated);
    return () => myItemQueue.removeEventListener('queueUpdated', handleQueueUpdated);
  }, [myItemQueue]);

  // stabilize callbacks
  const queueAddItem = React.useCallback((item: TItem, priority: number = 0) => myItemQueue.enqueueItem(item, priority), [myItemQueue]);
  const queueCancelAll = React.useCallback(() => myItemQueue.cancelAll(), [myItemQueue]);

  return { queueState, queueAddItem, queueCancelAll };
}


// Define the public task information interface
// interface TaskInformation<T> {
//   item: T;
//   priority: number;
//   taskId: string;
//   progress: number;
// }
// Define the error handling strategy type
// type ErrorHandlingStrategy<T> = {
//   retries: number;
//   onRetry: (error: Error, item: T) => void;
//   onGiveUp: (error: Error, item: T) => void;
// };



================================================
FILE: src/common/logic/reconfigureBackendModels.ts
================================================
import { findAllModelVendors } from '~/modules/llms/vendors/vendors.registry';
import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';
import { llmsUpdateModelsForServiceOrThrow } from '~/modules/llms/llm.client';

import type { DModelsService, DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { llmsStoreActions, llmsStoreState } from '~/common/stores/llms/store-llms';


// Note: this function is designed to be called once per session
let _isConfiguring = false;
let _isConfigurationDone = false;


/**
 * Reload models because of:
 * - updated backend capabilities (e.g. new service added)
 * - AIX/LLMs updated, in which case we'd have to re-scan services
 */
export async function reconfigureBackendModels(lastLlmReconfigHash: string, setLastReconfigHash: (hash: string) => void, remoteServices: boolean, existingServices: boolean) {

  // Note: double-calling is only expected to happen in react strict mode
  if (_isConfiguring || _isConfigurationDone)
    return;

  // skip if there haven't been any changes in the backend configuration
  // Note: the hash captures both AIX/LLMs changes and new backend-configured services
  const backendCaps = getBackendCapabilities();
  const backendReconfigHash = backendCaps.hashLlmReconfig;
  if (!backendReconfigHash || lastLlmReconfigHash === backendReconfigHash) {
    _isConfiguring = false;
    _isConfigurationDone = true;
    return;
  }

  // begin configuration
  _isConfiguring = true;
  // FIXME: future: move this to the end of the function, but also with strong retry count and error catching, so one's app wouldn't loop upon each boot
  setLastReconfigHash(backendReconfigHash);
  const initiallyEmpty = !llmsStoreState().llms?.length;

  // reconfigure these
  const servicesToReconfigure: DModelsService[] = [];

  // add the backend services
  if (remoteServices)
    findAllModelVendors()
      .filter(vendor => vendor.hasServerConfigKey && backendCaps[vendor.hasServerConfigKey])
      .forEach(remoteVendor => {

        // find the first service for this vendor
        const { sources: services } = llmsStoreState();
        const remoteService = services.find(s => s.vId === remoteVendor.id)
          || llmsStoreActions().createModelsService(remoteVendor);
        servicesToReconfigure.push(remoteService);

      });

  // add any other local services
  if (existingServices)
    llmsStoreState().sources
      .filter(s => !servicesToReconfigure.includes(s))
      .forEach(s => servicesToReconfigure.push(s));


  // track in order the services that were configured
  const configuredServiceIds: DModelsServiceId[] = [];

  // sequentially re-configure
  await servicesToReconfigure.reduce(async (promiseChain, service) => {
    return promiseChain
      .then(async () => {
        // keep track of the configured service IDs
        configuredServiceIds.push(service.id);

        // auto-configure this service
        await llmsUpdateModelsForServiceOrThrow(service.id, true);
      })
      .catch(error => {
        // catches errors and logs them, but does not stop the chain
        console.error('Auto-configuration failed for service:', service.label, error);
      })
      .then(() => {
        // short delay between vendors
        return new Promise(resolve => setTimeout(resolve, 50));
      });
  }, Promise.resolve());

  // Re-rank the LLMs based on the order of configured services
  llmsStoreActions().rerankLLMsByServices(configuredServiceIds);

  // Auto-assignment conditions
  if (initiallyEmpty) {
    // in case we refreshed all vendors, auto-assign the primary chat model, so it doesn't get locked to the first vendor
    llmsStoreActions().assignDomainModelId('primaryChat', null);
  } else {
    // in case the chat model becomes unavailable/hidden, we'll auto-reassign it
    llmsStoreActions().autoReassignDomainModel('primaryChat', true, true);
    llmsStoreActions().autoReassignDomainModel('codeApply', true, false);
    llmsStoreActions().autoReassignDomainModel('fastUtil', true, false);
  }

  // end configuration
  _isConfiguring = false;
  _isConfigurationDone = true;
  return true;
}


================================================
FILE: src/common/logic/store-logic-sherpa.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import { useShallow } from 'zustand/react/shallow';

import { Release } from '~/common/app.release';
import { estimatePersistentStorageOrThrow, requestPersistentStorageSafe } from '~/common/util/storageUtils';
import { gcAttachmentDBlobs } from '~/common/attachment-drafts/attachment.dblobs';
import { reconfigureBackendModels } from './reconfigureBackendModels';


// Sherpa State: navigation thought the app, remembers the counters for progressive disclosure of complex features

interface SherpaStore {

  usageCount: number;

  lastLlmReconfigHash: string;
  lastSeenNewsVersion: number;

  chatComposerPrefill: string | null; // if not null, the composer will load this text at startup
  setChatComposerPrefill: (text: string | null) => void;

}

export const useLogicSherpaStore = create<SherpaStore>()(
  persist(
    (set) => ({

      usageCount: 0,

      lastLlmReconfigHash: '',
      lastSeenNewsVersion: 0,

      chatComposerPrefill: null,
      setChatComposerPrefill: (text) => set({ chatComposerPrefill: text }),

    }),
    {
      name: 'app-state',
    },
  ),
);

// increment the usage count
useLogicSherpaStore.setState((state) => ({ usageCount: (state.usageCount || 0) + 1 }));


/// News Navigation

export function shallRedirectToNews() {
  const { lastSeenNewsVersion, usageCount } = useLogicSherpaStore.getState();

  // first time user - ignore the news up to the next refresh
  if (lastSeenNewsVersion === 0) {
    markNewsAsSeen();
    return false;
  }

  // if the news is outdated and the user has used the app a few times, show the news
  const isNewsOutdated = (lastSeenNewsVersion || 0) < Release.Monotonics.NewsVersion;
  return isNewsOutdated && usageCount >= 3;
}

export function markNewsAsSeen() {
  useLogicSherpaStore.setState({ lastSeenNewsVersion: Release.Monotonics.NewsVersion });
}


// Reconfigure Backend Models

export async function sherpaReconfigureBackendModels() {
  return reconfigureBackendModels(
    useLogicSherpaStore.getState().lastLlmReconfigHash,
    (hash: string) => useLogicSherpaStore.setState({ lastLlmReconfigHash: hash }),
    true, true
  );
}


// Storage Maintenance & Garbage Collection

export async function sherpaStorageMaintenanceNoChats_delayed() {

  // Request persistent storage for the current origin, so that indexedDB's content is not evicted
  const persisted = await requestPersistentStorageSafe(); // doesn't throw
  if (persisted) {
    try {
      const usage = await estimatePersistentStorageOrThrow();
      if (!usage)
        console.warn('Issue requesting persistent storage');
      else
        console.log('Persistent storage statistics:', usage);
    } catch (error) {
      console.error('Error estimating persistent storage:', error);
    }
  }

  // GC: Remove chat dblobs (not persisted in chat fragments)
  // NOTE: DISABLED! THIS WAS LOADING THE FULL DB TOO EARLY
  //       we moved this to the rehydration phase of the chat store
  // void gcChatImageAssets(); // fire/forget

  // GC: Remove old attachment drafts (not persisted in chats)
  void gcAttachmentDBlobs(); // fire/forget

}


// Chat Composer Prefill

export const setComposerStartupText = (text: string | null) => {
  useLogicSherpaStore.getState().setChatComposerPrefill(text);
};

export const useComposerStartupText = (): [string | null, (text: string | null) => void] => {
  return useLogicSherpaStore(useShallow(state => [state.chatComposerPrefill, state.setChatComposerPrefill]));
};



================================================
FILE: src/common/providers/ProviderBackendCapabilities.tsx
================================================
import * as React from 'react';

import { useKnowledgeOfBackendCaps } from '~/modules/backend/store-backend-capabilities';

import { Release } from '~/common/app.release';
import { apiQuery } from '~/common/util/trpc.client';
import { themeFontFamilyCss } from '~/common/app.theme';


// Configuration
const BACKEND_WARNING_TIMEOUT = 6000;


// Styles, all manual without depending on Emotion/Joy UI
const styles: Record<string, React.CSSProperties> = {
  container: {
    // looks
    background: 'var(--joy-palette-background-level1)',
    color: 'var(--joy-palette-text-primary)',
    fontFamily: themeFontFamilyCss,
    minHeight: '100vh',
    // layout
    display: 'flex',
    flexDirection: 'column',
    alignItems: 'center',
    justifyContent: 'center',
  },
  content: {
    display: 'flex',
    alignItems: 'center',
  },
  content2: {
    display: 'flex',
    flexDirection: 'column',
    alignItems: 'center',
    gap: '0.25rem',
  },
  leftbox: {
    borderRight: `1px solid var(--joy-palette-neutral-400)`,
    margin: '0 1.5rem 0 0',
    padding: '0 1.5rem 0 0',
  },
  heading: {
    margin: 0,
    fontSize: '1.5rem',
    fontWeight: 500,
  },
  version: {
    fontSize: '12px',
  },
  message: {
    margin: 0,
    fontSize: '14px',
    fontWeight: 400,
  },
  button: {
    color: 'var(--joy-palette-neutral-solidColor, #fff)',
    background: 'var(--joy-palette-neutral-solidBg, #000)',
    padding: '0.75rem 1.25rem',
    fontSize: '14px',
    fontWeight: 500,
    border: 'none',
    borderRadius: '4px',
    cursor: 'pointer',
    transition: 'opacity 0.2s ease',
  },
};


/**
 * Note: we used to have a NoSSR wrapper inside the AppLayout component (which was delaying rendering 1 cycle),
 * however this wrapper is now providing the same function, given the network roundtrip.
 */
export function ProviderBackendCapabilities(props: { children: React.ReactNode }) {

  // state
  const [backendTimeout, setBackendTimeout] = React.useState(false);
  const [versionVerified, setVersionVerified] = React.useState<boolean | null>(null);

  // external state
  const [haveCapabilities, storeBackendCapabilities] = useKnowledgeOfBackendCaps();


  // fetch capabilities
  const { data } = apiQuery.backend.listCapabilities.useQuery(undefined, {
    staleTime: Release.Features.BACKEND_REVALIDATE_INTERVAL,
    refetchOnWindowFocus: true, // refetch after a long idle
    refetchOnReconnect: true, // refetch after a network change
  });


  // [effect] copy from the backend capabilities payload to the frontend state store
  React.useEffect(() => {
    if (data) {
      storeBackendCapabilities(data);

      // Match frontend and backend versions
      const clientBuildInfo = Release.buildInfo('frontend');
      const serverBuildInfo = data.build || {};
      setVersionVerified(clientBuildInfo.gitSha === serverBuildInfo.gitSha && clientBuildInfo.pkgVersion === serverBuildInfo.pkgVersion);
    }
  }, [data, storeBackendCapabilities]);


  // [effect] set the timeout flag if waiting too long for the capabilities
  React.useEffect(() => {
    if (!haveCapabilities) return;
    const timeout = setTimeout(() => setBackendTimeout(true), BACKEND_WARNING_TIMEOUT);
    return () => {
      clearTimeout(timeout);
      setBackendTimeout(false);
    };
  }, [haveCapabilities]);


  //
  // Rendering Gates
  //

  // Version mismatch notice
  if (versionVerified === false) {
    return (
      <div style={styles.container}>
        <div style={styles.content}>
          <div style={styles.leftbox}>
            <h2 style={styles.heading}>Updated</h2>
            {/*<div style={styles.version}>*/}
            {/*  version. {Release.buildInfo('frontend').pkgVersion}*/}
            {/*</div>*/}
          </div>
          <button
            style={styles.button}
            onClick={() => window.location.reload()}
            onMouseOver={(e) => e.currentTarget.style.opacity = '0.8'}
            onMouseOut={(e) => e.currentTarget.style.opacity = '1'}
          >
            Reload Now
          </button>
        </div>
      </div>
    );
  }

  // Backend timeout notice
  if (backendTimeout && versionVerified !== true) {
    return (
      <div style={styles.container}>
        <div style={styles.content2}>
          <h2 style={styles.heading}>Connection Error</h2>
          <h2 style={styles.message}>Unable to connect to the server.<br /><br /></h2>
          <button
            style={styles.button}
            onClick={() => window.location.reload()}
            onMouseOver={(e) => e.currentTarget.style.opacity = '0.8'}
            onMouseOut={(e) => e.currentTarget.style.opacity = '1'}
          >
            Reload Now
          </button>
        </div>
      </div>
    );
  }

  // Wait for the backend to respond
  if (versionVerified === null) {
    return null;
    // return (
    //   <div style={containerStyle}>
    //     <p style={messageStyle}>
    //       Loading application...
    //     </p>
    //   </div>
    // );
  }

  // Render the children when ready
  return props.children;
}


================================================
FILE: src/common/providers/ProviderBootstrapLogic.tsx
================================================
import * as React from 'react';
import { useRouter } from 'next/router';

import { markNewsAsSeen, shallRedirectToNews, sherpaReconfigureBackendModels, sherpaStorageMaintenanceNoChats_delayed } from '~/common/logic/store-logic-sherpa';
import { navigateToNews, ROUTE_APP_CHAT } from '~/common/app.routes';
import { preloadTiktokenLibrary } from '~/common/tokens/tokens.text';
import { useClientLoggerInterception } from '~/common/logger/hooks/useClientLoggerInterception';
import { useNextLoadProgress } from '~/common/components/useNextLoadProgress';


export function ProviderBootstrapLogic(props: { children: React.ReactNode }) {

  // external state
  const { route, events } = useRouter();

  // AUTO-LOG events from this scope on; note that we are past the Sherpas
  useClientLoggerInterception(true, false);

  // wire-up the NextJS router to a loading bar to be displayed while routes change
  useNextLoadProgress(route, events);


  // [boot-up] logic
  const isOnChat = route === ROUTE_APP_CHAT;
  const doRedirectToNews = isOnChat && shallRedirectToNews();


  // redirect Chat -> News if fresh news
  const isRedirectingToNews = React.useMemo(() => {
    if (doRedirectToNews) {
      navigateToNews().then(() => markNewsAsSeen()).catch(console.error);
      return true;
    }
    return false;
  }, [doRedirectToNews]);


  // decide what to launch
  const launchPreload = isOnChat && !isRedirectingToNews;
  const launchAutoConf = isOnChat && !isRedirectingToNews;
  const launchStorageGC = true;


  // [preload] kick-off a preload of the Tiktoken library right when proceeding to the UI
  React.useEffect(() => {
    if (!launchPreload) return;

    void preloadTiktokenLibrary(); // fire/forget (large WASM payload)

  }, [launchPreload]);

  // [autoconf] initiate the llm auto-configuration process if on the chat
  React.useEffect(() => {
    if (!launchAutoConf) return;

    void sherpaReconfigureBackendModels(); // fire/forget (background server-driven model reconfiguration)

  }, [launchAutoConf]);

  // storage maintenance and garbage collection
  React.useEffect(() => {
    if (!launchStorageGC) return;

    const timeout = setTimeout(sherpaStorageMaintenanceNoChats_delayed, 1000);
    return () => clearTimeout(timeout);

  }, [launchStorageGC]);

  //
  // Render Gates
  //

  if (isRedirectingToNews)
    return null;

  return props.children;
}



================================================
FILE: src/common/providers/ProviderSingleTab.tsx
================================================
import * as React from 'react';

import { Button, Sheet, Typography } from '@mui/joy';

import { reloadPage } from '../app.routes';
import { useSingleTabEnforcer } from '../components/useSingleTabEnforcer';


export const ProviderSingleTab = (props: { disabled?: boolean, children: React.ReactNode }) => {

  // state
  const isSingleTab = useSingleTabEnforcer('big-agi-tabs');

  // pass-through until we know for sure that other tabs are open
  if (props.disabled || isSingleTab === null || isSingleTab)
    return props.children;


  return (
    <Sheet
      variant='solid'
      invertedColors
      sx={{
        flexGrow: 1,
        display: 'flex', flexDirection: { xs: 'column', md: 'row' }, justifyContent: 'center', alignItems: 'center', gap: 2,
        p: 3,
      }}
    >

      <Typography>
        It looks like this app is already running in another browser Tab or Window.<br />
        To continue here, please close the other instance first.
      </Typography>

      <Button onClick={reloadPage}>
        Reload
      </Button>

    </Sheet>
  );
};


================================================
FILE: src/common/providers/ProviderTheming.tsx
================================================
import * as React from 'react';

import { CacheProvider, EmotionCache } from '@emotion/react';
import { CssBaseline, CssVarsProvider } from '@mui/joy';

import { createAppTheme, createEmotionCache } from '~/common/app.theme';
import { useUIComplexityIsMinimal } from '~/common/stores/store-ui';


// Client-side cache, shared for the whole session of the user in the browser.
const clientSideEmotionCache = createEmotionCache();


/**
 * As part of the theming, we define global SVG filters here. This will add
 * texture and tactileness to the design. They should be in the appTheme file,
 * but I did not want to have react components in that file.
 */
const _GlobalSVGFiltersMemo = React.memo(function GlobalSVGFilters() {
  return (
    <svg style={{ position: 'absolute', width: 0, height: 0 }}>
      <defs>
        {/*<filter id='agi-roughpaper'>*/}
        {/*  <feTurbulence type='fractalNoise' baseFrequency='0.04' result='noise' numOctaves='5' />*/}
        {/*  <feDiffuseLighting in='noise' lightingColor='#fff' surfaceScale='2'>*/}
        {/*    <feDistantLight azimuth='45' elevation='60' />*/}
        {/*  </feDiffuseLighting>*/}
        {/*</filter>*/}

        {/*<filter id='agi-futuristic-glow'>*/}
        {/*  <feGaussianBlur in='SourceGraphic' stdDeviation='4' result='blur' />*/}
        {/*  <feColorMatrix in='blur' mode='matrix' values='1 0 0 0 0  0 1 0 0 0  0 0 1 0 0  0 0 0 40 -7' result='glow' />*/}
        {/*  <feBlend in='SourceGraphic' in2='glow' mode='multiply' />*/}
        {/*</filter>*/}

        {/*<filter id='agi-holographic'>*/}
        {/*  <feTurbulence type='fractalNoise' baseFrequency='0.01' numOctaves='7' result='noise' />*/}
        {/*  <feDisplacementMap in='SourceGraphic' in2='noise' scale='50' xChannelSelector='R' yChannelSelector='G' />*/}
        {/*</filter>*/}

        {/*<filter id='agi-ai-texture'>*/}
        {/*  <feTurbulence type='fractalNoise' baseFrequency='1' numOctaves='1' />*/}
        {/*  <feColorMatrix type='saturate' values='0.2' />*/}
        {/*  <feBlend in='SourceGraphic' mode='multiply' />*/}
        {/*</filter>*/}
      </defs>
    </svg>
  );
});


export const ProviderTheming = (props: { emotionCache?: EmotionCache, children: React.ReactNode }) => {

  // external state
  const zenMode = useUIComplexityIsMinimal();

  // recreate the theme only to apply zen touches
  const theme = React.useMemo(() => createAppTheme(zenMode), [zenMode]);

  return (
    <CacheProvider value={props.emotionCache || clientSideEmotionCache}>
      <CssVarsProvider defaultMode='light' theme={theme}>
        <CssBaseline />
        {/* Disabled for now, we don't use those */}
        {/*<_GlobalSVGFiltersMemo />*/}
        {props.children}
      </CssVarsProvider>
    </CacheProvider>
  );
};


================================================
FILE: src/common/scroll-to-bottom/ScrollToBottom.tsx
================================================
/**
 * Copyright (c) 2023-2024 Enrico Ros
 *
 * This subsystem is responsible for 'snap-to-bottom' and 'scroll-to-bottom' features,
 * with an animated, gradual scroll.
 *
 * See the `ScrollToBottomButton` component for the button that triggers the scroll.
 *
 * Example usage:
 *   <ScrollToBottom bootToBottom stickToBottom sx={{ overflowY: 'auto', height: '100%' }}>
 *     <LongMessagesList />
 *     <ScrollToBottomButton />
 *   </ScrollToBottom>
 *
 * Within the Context (children components), functions are made available by using:
 *  const { notifyBooting, setStickToBottom } = useScrollToBottom();
 *
 */
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { isBrowser } from '~/common/util/pwaUtils';

import { ScrollToBottomState, UseScrollToBottomProvider } from './useScrollToBottom';


// set this to true to debug this component
const DEBUG_SCROLL_TO_BOTTOM = false;

// NOTE: in Chrome a wheel scroll event is 100px
// If you make this too small, the button may show when jumping lines on mobile
// if you make it too large, the user would need a very large flick to unlock the view
const USER_STICKY_MARGIN = 60;

// during the 'booting' timeout, scrolls happen instantly instead of smoothly
const BOOTING_TIMEOUT = 400;


function DebugBorderBox(props: { heightPx: number, color: string }) {
  return (
    <Box sx={{
      position: 'absolute', bottom: 0, right: 0, left: 0,
      height: `${props.heightPx}px`,
      border: `1px solid ${props.color}`,
      pointerEvents: 'none',
    }} />
  );
}

const scrollableBoxSx: SxProps = {
  // allows the content to be scrolled (all browsers)
  overflowY: 'auto',
  // actually make sure this scrolls & fills
  height: '100%',
} as const;


/**
 * This scroller works best with a single oversized child component.
 * The scrollbar (overflowY: 'auto') is handled here.
 *
 * NOTE: the first (possibly only) child shall have { minHeight: '100%' } to auto-fill
 */
export function ScrollToBottom(props: {
  bootToBottom?: boolean,
  bootSmoothly?: boolean,
  stickToBottomInitial?: boolean,
  disableAutoStick?: boolean, // disables auto-sticking when at the bottom - only the button will make it stick
  sx?: SxProps,
  children: React.ReactNode,
}) {

  // state

  const [state, setState] = React.useState<ScrollToBottomState>({
    stickToBottom: props.stickToBottomInitial || false,
    booting: props.bootToBottom || false,
    atBottom: undefined,
  });

  // track scrollable (for events and to scroll it)
  const scrollableElementRef = React.useRef<HTMLDivElement>(null);

  // track programmatic scrolls
  const isProgrammaticScroll = React.useRef(false);

  // skip the next scroll event (when we want to stay where we are)
  const skipNextScrollCounter = React.useRef(0);
  const skipResetTimeoutRef = React.useRef<NodeJS.Timeout | null>(null);


  // derived state

  const bootToBottom = props.bootToBottom || false;
  const scrollBehavior: ScrollBehavior = (state.booting && !props.bootSmoothly) ? 'auto' : 'smooth';

  const stateRef = React.useRef(state);
  stateRef.current = state;


  // [Debugging]
  if (DEBUG_SCROLL_TO_BOTTOM)
    console.log('ScrollToBottom', { ...state });


  // main programmatic scroll to bottom function

  const doScrollToBottom = React.useCallback(() => {
    const scrollable = scrollableElementRef.current;
    if (scrollable) {
      if (DEBUG_SCROLL_TO_BOTTOM)
        console.log('  -> doScrollToBottom()', { scrollHeight: scrollable.scrollHeight, offsetHeight: scrollable.offsetHeight, skipCounter: skipNextScrollCounter.current });

      if (skipNextScrollCounter.current > 0) {
        skipNextScrollCounter.current--;
        if (DEBUG_SCROLL_TO_BOTTOM)
          console.log('  -> Skipping scroll, counter now:', skipNextScrollCounter.current);
        return;
      }

      // eat the next scroll event
      isProgrammaticScroll.current = true;

      // smooth scrolling only after booting
      scrollable.scrollTo({ top: scrollable.scrollHeight, behavior: scrollBehavior });
    }
  }, [scrollBehavior]);


  /**
   * Booting state reset (after BOOTING_TIMEOUT ms)
   *  - the "Booting" window will scroll instantly instead of smoothly
   */
  React.useEffect(() => {
    if (!state.booting || !isBrowser) return;

    const _clearBootingHandler = () => {
      if (DEBUG_SCROLL_TO_BOTTOM)
        console.log(' -> booting done');

      setState(state => ({ ...state, booting: false }));

      if (bootToBottom)
        doScrollToBottom();
    };

    // cancelable listener
    const timeout = window.setTimeout(_clearBootingHandler, BOOTING_TIMEOUT);
    return () => clearTimeout(timeout);
  }, [bootToBottom, doScrollToBottom, state.booting]);

  /**
   * Children elements resize event listener
   *  - note that the 'scrollable' will likely have a fixed size, while its children are the ones who become scrollable
   */
  React.useEffect(() => {
    const scrollable = scrollableElementRef.current;
    if (!scrollable) return;

    const _containerResizeObserver = new ResizeObserver(entries => {
      if (DEBUG_SCROLL_TO_BOTTOM)
        console.log(' -> scrollable children resized', entries.length);

      // Edge case: when the content is smaller, we need to reset the bottom state (#312)
      const atTop = scrollable.scrollTop == 0;
      const unScrollable = scrollable.scrollHeight <= scrollable.offsetHeight;
      if (unScrollable && atTop) {
        if (DEBUG_SCROLL_TO_BOTTOM)
          console.log('   -> large enough window', entries.length);

        // update state only if this changed
        if (stateRef.current.atBottom !== true)
          setState(state => ({ ...state, atBottom: true }));
      }

      if (entries.length > 0 && stateRef.current.stickToBottom)
        doScrollToBottom();
    });

    // cancelable observer of resize of scrollable's children elements
    Array.from(scrollable.children).forEach(child => _containerResizeObserver.observe(child));
    return () => _containerResizeObserver.disconnect();

  }, [doScrollToBottom]);

  /**
   * (User) Scroll events listener
   *  - will cancel any state.stickToBottom, if the user dragged the scroll bar
   */
  React.useEffect(() => {
    if (state.booting) return;

    const scrollable = scrollableElementRef.current;
    if (!scrollable) return;

    const _scrollEventsListener = () => {
      // ignore scroll events during programmatic scrolls
      // NOTE: some will go through, but somewhat the framework is stable
      if (isProgrammaticScroll.current) {
        isProgrammaticScroll.current = false;
        return;
      }

      // compute intersections
      const atBottom = scrollable.scrollHeight - scrollable.scrollTop <= scrollable.offsetHeight + USER_STICKY_MARGIN;

      // assume this is = to the user intention
      const stickToBottom = atBottom;

      // update state only if anything changed
      setState(state => state.stickToBottom !== stickToBottom || state.atBottom !== atBottom
        ? {
          ...state,
          stickToBottom: props.disableAutoStick ? (state.stickToBottom && stickToBottom) : stickToBottom,
          atBottom,
        }
        : state,
      );
    };

    // _scrollEventsListener(true);

    // cancelable listener (user and programatic scroll events)
    scrollable.addEventListener('scroll', _scrollEventsListener);
    return () => scrollable.removeEventListener('scroll', _scrollEventsListener);

  }, [props.disableAutoStick, state.booting]);

  /**
   * Cleanup the skipNextScrollCounter
   */
  React.useEffect(() => {
    return () => {
      if (skipResetTimeoutRef.current) {
        clearTimeout(skipResetTimeoutRef.current);
        skipResetTimeoutRef.current = null;
      }
    };
  }, []);


  // actions for this context

  const notifyBooting = React.useCallback(() => {
    if (bootToBottom)
      setState(state => state.booting ? state : ({ ...state, booting: true }));
  }, [bootToBottom]);

  /*const notifyContentUpdated = React.useCallback(() => {
    if (DEBUG_SCROLL_TO_BOTTOM)
      console.log('-= notifyContentUpdated');

    if (state.stickToBottom)
      doScrollToBottom();
  }, [doScrollToBottom, state.stickToBottom]);*/

  const setStickToBottom = React.useCallback((stickToBottom: boolean) => {
    if (DEBUG_SCROLL_TO_BOTTOM)
      console.log('-= setStickToBottom', stickToBottom);

    setState(state => state.stickToBottom !== stickToBottom
      ? ({ ...state, stickToBottom })
      : state,
    );

    if (stickToBottom)
      doScrollToBottom();
  }, [doScrollToBottom]);

  const skipNextAutoScroll = React.useCallback(() => {
    skipNextScrollCounter.current += 2;
    if (DEBUG_SCROLL_TO_BOTTOM)
      console.log('  -> Skip next scroll requested, counter now:', skipNextScrollCounter.current);

    // Clear any existing timeout
    if (skipResetTimeoutRef.current)
      clearTimeout(skipResetTimeoutRef.current);

    // Set a new timeout to reset the counter if not used
    skipResetTimeoutRef.current = setTimeout(() => {
      if (skipNextScrollCounter.current > 0) {
        if (DEBUG_SCROLL_TO_BOTTOM)
          console.log('  -> Resetting unused skip counter');
        skipNextScrollCounter.current = 0;
      }
    }, 200); // Reset after 0.25 seconds if not used
  }, []);


  return (
    <UseScrollToBottomProvider value={{
      ...state,
      notifyBooting,
      setStickToBottom,
      skipNextAutoScroll,
    }}>
      {/* Scrollable v-maxed */}
      <Box ref={scrollableElementRef} role={'scrollable' /* hardcoded, important */} sx={!props.sx ? scrollableBoxSx : ({
        ...scrollableBoxSx,
        ...props.sx,
      } as SxProps)}>
        {props.children}
        {DEBUG_SCROLL_TO_BOTTOM && <DebugBorderBox heightPx={USER_STICKY_MARGIN} color='red' />}
        {DEBUG_SCROLL_TO_BOTTOM && <DebugBorderBox heightPx={100} color='blue' />}
      </Box>
    </UseScrollToBottomProvider>
  );
}


================================================
FILE: src/common/scroll-to-bottom/ScrollToBottomButton.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { IconButton } from '@mui/joy';
import KeyboardDoubleArrowDownIcon from '@mui/icons-material/KeyboardDoubleArrowDown';

import { themeZIndexBeamView } from '~/common/app.theme';

import { useScrollToBottom } from './useScrollToBottom';


const inlineButtonSx: SxProps = {
  // style it
  // NOTE: just an IconButton when inline

  // for usage inside BeamGatherPane, to not enlarge the row
  my: -0.25,

  // fade it in when hovering
  // transition: 'all 0.15s',
  // '&:hover': {
  //   transform: 'scale(1.1)',
  // },
} as const;

const absoluteButtonSx: SxProps = {
  ...inlineButtonSx,

  // more style when float
  backgroundColor: 'background.surface',
  border: '1px solid',
  borderColor: 'neutral.500',
  borderRadius: '50%',
  boxShadow: 'sm',
  zIndex: themeZIndexBeamView + 1, // stay on top of the Chat Message buttons (e.g. copy)

  // place this on the bottom-right corner (FAB-like)
  position: 'absolute',
  bottom: '2rem',
  right: {
    xs: '1rem',
    md: '2rem',
  },
} as const;


export function ScrollToBottomButton(props: { inline?: boolean }) {

  // state
  const { atBottom, stickToBottom, setStickToBottom } = useScrollToBottom();

  const handleStickToBottom = React.useCallback(() => {
    setStickToBottom(true);
  }, [setStickToBottom]);

  // do not render the button at all if we're already snapping
  if (atBottom || stickToBottom)
    return null;

  return (
    <IconButton
      aria-label='Scroll To Bottom'
      variant='plain'
      onClick={handleStickToBottom}
      size={props.inline ? 'sm' : undefined}
      sx={props.inline ? inlineButtonSx : absoluteButtonSx}
    >
      <KeyboardDoubleArrowDownIcon sx={{ fontSize: 'xl' }} />
    </IconButton>
  );
}


================================================
FILE: src/common/scroll-to-bottom/useScrollToBottom.tsx
================================================
import * as React from 'react';

/**
 * State is minimal - to keep state machinery stable and simple
 */
export interface ScrollToBottomState {
  // config
  stickToBottom: boolean;

  // state
  booting: boolean;
  atBottom: boolean | undefined;
}

/**
 * Actions are very simplified, for providing a minimal control surface from the outside
 */
export interface ScrollToBottomActions {
  notifyBooting: () => void;
  setStickToBottom: (stick: boolean) => void;
  skipNextAutoScroll: () => void;
}

type ScrollToBottomContext = ScrollToBottomState & ScrollToBottomActions;

const UseScrollToBottom = React.createContext<ScrollToBottomContext | undefined>(undefined);

export const UseScrollToBottomProvider = UseScrollToBottom.Provider;


// This has been added because one usage of this hook was outside of the provider
const _oocFallback: ScrollToBottomContext = {
  stickToBottom: false,
  booting: false,
  atBottom: false,
  notifyBooting: console.log,
  setStickToBottom: console.log,
  skipNextAutoScroll: () => {
    // ignore - when used by DocAttachmentFragmentPane outside of a provider
  },
} as const;

export const useScrollToBottom = (): ScrollToBottomContext => {

  // NOTE: we are relaxing the 'throw' because when used outside of a provider, we want to simply do nothing

  // const context = React.useContext(UseScrollToBottom);
  // if (!context)
  //   throw new Error('useScrollToBottom must be used within a ScrollToBottomProvider');
  // return context;

  return React.useContext(UseScrollToBottom) ?? _oocFallback;
};


================================================
FILE: src/common/stores/store-client.ts
================================================
import { create } from 'zustand/index';
import { persist } from 'zustand/middleware';

import { agiId } from '~/common/util/idUtils';
import { generateDeviceName, isBrowser, isPwa } from '~/common/util/pwaUtils';


/// Store ///

interface PerClientStore {

  /**
   * Global (same per each users in this browser/device) device identifier.
   */
  localDeviceId: string;

}

const useDeviceStore = create<PerClientStore>()(persist(
  () => ({

    // initial state
    localDeviceId: '',

  }),
  {
    name: 'app-device',
    version: 1,
  },
));


/// Global Device ID ///

/**
 * Gets or generates the global device ID (hardware-specific).
 * This ID is shared across all users on the same device.
 * Thread-safe: multiple calls return the same ID.
 */
export function deviceGetGlobalDeviceId(): string {
  // SSR: return a dummy id
  if (!isBrowser) return 'ssr-dummy-device-id';

  let { localDeviceId } = useDeviceStore.getState();

  // Return existing ID if available
  if (localDeviceId)
    return localDeviceId;

  // Generate new ID and persist
  localDeviceId = _generateLocalDeviceIdentifier();
  useDeviceStore.setState({ localDeviceId });
  return localDeviceId;
}


/// Device/ID functions ///

interface DeviceRegistrationClientPayload {
  deviceId: string;               // device identifier for sync
  deviceName: string;             // human-readable name
  environment: {
    language: string;
    timezone: string;
    screen: string;               // screen resolution
    form: 'web' | 'pwa' | 'app';  // format of the client
  };
}

/**
 * Creates a complete device registration payload when needed
 * Nothing except the deviceId is stored locally
 */
export function deviceCreateRegistrationPayload(): DeviceRegistrationClientPayload {
  return {
    deviceId: deviceGetGlobalDeviceId(),
    deviceName: generateDeviceName(),
    // generated at call time, server-side checked for consistency
    environment: {
      language: navigator.language || '',
      timezone: Intl.DateTimeFormat().resolvedOptions().timeZone || '',
      screen: (isBrowser && window.screen?.width && window.screen?.height) ? `${window.screen.width}x${window.screen.height}` : '',
      form: isPwa() ? 'pwa' : 'web',
    },
  };
}


/**
 * Generates a local device identifier for sync capabilities.
 * This ID combines a timestamp component with random characters for patterned uniqueness.
 *
 * Format: 6 random chars + 4 timestamp chars = 10 chars total
 * Example: "a7f3g9h812"  (where "12" is from the timestamp)
 *
 * This ID is only used to distinguish between devices during sync operations.
 * It never leaves your device/browser unless you explicitly enable sync functionality.
 *
 * NOTE: This is the hardware device ID used for device registration only.
 * Vector clocks can use a separate user-scoped device ID generated server-side
 * to prevent conflicts when multiple users share the same device.
 */
function _generateLocalDeviceIdentifier(): string {
  // Generate 6 random characters
  const random = agiId('vector-device-id10').slice(0, 6);

  // Use a 4 char suffix from current timestamp
  const timestamp = Date.now().toString(36).slice(-4);

  // Combine for a total of 10 characters
  return random + timestamp;
}



================================================
FILE: src/common/stores/store-ui.ts
================================================
import * as React from 'react';
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import type { ContentScaling, UIComplexityMode } from '~/common/app.theme';
import { BrowserLang } from '~/common/util/pwaUtils';


// UI Preferences

interface UIPreferencesStore {

  // UI Features

  preferredLanguage: string;
  setPreferredLanguage: (preferredLanguage: string) => void;

  centerMode: 'narrow' | 'wide' | 'full';
  setCenterMode: (centerMode: 'narrow' | 'wide' | 'full') => void;

  complexityMode: UIComplexityMode;
  setComplexityMode: (complexityMode: UIComplexityMode) => void;

  contentScaling: ContentScaling;
  setContentScaling: (contentScaling: ContentScaling) => void;
  increaseContentScaling: () => void;
  decreaseContentScaling: () => void;

  disableMarkdown: boolean;
  setDisableMarkdown: (disableMarkdown: boolean) => void;

  doubleClickToEdit: boolean;
  setDoubleClickToEdit: (doubleClickToEdit: boolean) => void;

  enterIsNewline: boolean;
  setEnterIsNewline: (enterIsNewline: boolean) => void;

  renderCodeLineNumbers: boolean;
  setRenderCodeLineNumbers: (renderCodeLineNumbers: boolean) => void;

  renderCodeSoftWrap: boolean;
  setRenderCodeSoftWrap: (renderCodeSoftWrap: boolean) => void;

  showPersonaFinder: boolean;
  setShowPersonaFinder: (showPersonaFinder: boolean) => void;

  composerQuickButton: 'off' | 'call' | 'beam';
  setComposerQuickButton: (composerQuickButton: 'off' | 'call' | 'beam') => void;

  // UI Dismissals

  dismissals: Record<string, boolean>;
  dismiss: (key: string) => void;

  // UI Counters

  actionCounters: Record<string, number>;
  incrementActionCounter: (key: string) => void;
  resetActionCounter: (key: string) => void;

}

export const useUIPreferencesStore = create<UIPreferencesStore>()(
  persist(
    (set) => ({

      // UI Features

      preferredLanguage: BrowserLang.orUS,
      setPreferredLanguage: (preferredLanguage: string) => set({ preferredLanguage }),

      centerMode: 'full',
      setCenterMode: (centerMode: 'narrow' | 'wide' | 'full') => set({ centerMode }),

      complexityMode: 'pro',
      setComplexityMode: (complexityMode: UIComplexityMode) => set({ complexityMode }),

      // 2024-07-14: 'sm' is the new default, down from 'md'
      contentScaling: 'sm',
      setContentScaling: (contentScaling: ContentScaling) => set({ contentScaling: contentScaling }),
      increaseContentScaling: () => set((state) => state.contentScaling === 'md' ? state : { contentScaling: state.contentScaling === 'xs' ? 'sm' : 'md' }),
      decreaseContentScaling: () => set((state) => state.contentScaling === 'xs' ? state : { contentScaling: state.contentScaling === 'md' ? 'sm' : 'xs' }),

      doubleClickToEdit: false,
      setDoubleClickToEdit: (doubleClickToEdit: boolean) => set({ doubleClickToEdit }),

      disableMarkdown: false,
      setDisableMarkdown: (disableMarkdown: boolean) => set({ disableMarkdown }),

      enterIsNewline: false,
      setEnterIsNewline: (enterIsNewline: boolean) => set({ enterIsNewline }),

      renderCodeLineNumbers: false,
      setRenderCodeLineNumbers: (renderCodeLineNumbers: boolean) => set({ renderCodeLineNumbers }),

      renderCodeSoftWrap: false,
      setRenderCodeSoftWrap: (renderCodeSoftWrap: boolean) => set({ renderCodeSoftWrap }),

      // Deprecated
      showPersonaFinder: false,
      setShowPersonaFinder: (showPersonaFinder: boolean) => set({ showPersonaFinder }),

      composerQuickButton: 'beam',
      setComposerQuickButton: (composerQuickButton: 'off' | 'call' | 'beam') => set({ composerQuickButton }),

      // UI Dismissals

      dismissals: {},
      dismiss: (key: string) => set((state) => ({
        dismissals: { ...state.dismissals, [key]: true },
      })),

      // UI Counters

      actionCounters: {},
      incrementActionCounter: (key: string) =>
        set((state) => ({
          actionCounters: { ...state.actionCounters, [key]: (state.actionCounters[key] || 0) + 1 },
        })),
      resetActionCounter: (key: string) =>
        set((state) => ({
          actionCounters: { ...state.actionCounters, [key]: 0 },
        })),

    }),
    {
      name: 'app-ui',

      /* versioning:
       * 1: rename 'enterToSend' to 'enterIsNewline' (flip the meaning)
       * 2: new Big-AGI 2 defaults
       * 3: centerMode: 'full' is the new default
       */
      version: 3,

      migrate: (state: any, fromVersion: number): UIPreferencesStore => {

        // 1: rename 'enterToSend' to 'enterIsNewline' (flip the meaning)
        if (state && fromVersion < 1)
          state.enterIsNewline = state['enterToSend'] === false;

        // 2: new Big-AGI 2 defaults
        if (state && fromVersion < 2) {
          state.contentScaling = 'sm';
          state.doubleClickToEdit = false;
        }

        // 3: centerMode: 'full' is the new default
        if (state && fromVersion < 3) {
          state.centerMode = 'full';
        }

        return state;
      },
    },
  ),
);


export function useUIComplexityMode(): UIComplexityMode {
  return useUIPreferencesStore((state) => state.complexityMode);
}

export function useUIComplexityIsMinimal(): boolean {
  return useUIPreferencesStore((state) => state.complexityMode === 'minimal');
}

export function useUIContentScaling(): ContentScaling {
  return useUIPreferencesStore((state) => state.contentScaling);
}


export function useUIIsDismissed(key: string | null): boolean | undefined {
  return useUIPreferencesStore((state) => !key ? undefined : Boolean(state.dismissals[key]));
}

export function uiSetDismissed(key: string): void {
  useUIPreferencesStore.getState().dismiss(key);
}


// former:
//  'export-share'                    // used the export function
//  'share-chat-link'                 // not shared a Chat Link yet
type KnownKeys =
  | 'acknowledge-translation-warning' // displayed if Chrome is translating the page (may crash)
  | 'beam-wizard'                     // first Beam
  | 'call-wizard'                     // first Call
  | 'composer-shift-enter'            // not used Shift + Enter in the Composer yet
  | 'composer-alt-enter'              // not used Alt + Enter in the Composer yet
  | 'composer-ctrl-enter'             // not used Ctrl + Enter in the Composer yet
  | 'models-setup-first-visit'        // first visit to the Models Setup
  ;

export function useUICounter(key: KnownKeys, novelty: number = 1) {
  const value = useUIPreferencesStore((state) => state.actionCounters[key] || 0);

  const touch = React.useCallback(() => useUIPreferencesStore.getState().incrementActionCounter(key), [key]);

  const forget = React.useCallback(() => useUIPreferencesStore.getState().resetActionCounter(key), [key]);

  return {
    // value,
    novel: value < novelty,
    touch,
    forget,
  };
}

export function resetUICounter(key: KnownKeys) {
  useUIPreferencesStore.getState().resetActionCounter(key);
}


================================================
FILE: src/common/stores/store-ux-labs.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import { Is } from '~/common/util/pwaUtils';


// UX Labs Experiments

// UxLabsSettings.tsx contains the graduated settings, but the following are not stated:
//  - Text Tools: dynamically shown where applicable
//  - Chat Mode: Follow-Ups; moved to Chat Advanced UI
interface UXLabsStore {

  labsAttachScreenCapture: boolean;
  setLabsAttachScreenCapture: (labsAttachScreenCapture: boolean) => void;

  labsCameraDesktop: boolean;
  setLabsCameraDesktop: (labsCameraDesktop: boolean) => void;

  labsChatBarAlt: false | 'title',
  setLabsChatBarAlt: (labsChatBarAlt: false | 'title') => void;

  labsEnhanceCodeBlocks: boolean;
  setLabsEnhanceCodeBlocks: (labsEnhanceCodeBlocks: boolean) => void;

  labsEnhanceCodeLiveFile: boolean;
  setLabsEnhanceCodeLiveFile: (labsEnhanceCodeLiveFile: boolean) => void;

  labsHighPerformance: boolean;
  setLabsHighPerformance: (labsHighPerformance: boolean) => void;

  labsShowCost: boolean;
  setLabsShowCost: (labsShowCost: boolean) => void;

  labsAutoHideComposer: boolean;
  setLabsAutoHideComposer: (labsAutoHideComposer: boolean) => void;

  labsShowShortcutBar: boolean;
  setLabsShowShortcutBar: (labsShowShortcutBar: boolean) => void;

  // [DEV MODE] only shown on localhost

  labsDevMode: boolean;
  setLabsDevMode: (labsDevMode: boolean) => void;

  labsDevNoStreaming: boolean;
  setLabsDevNoStreaming: (labsDevNoStreaming: boolean) => void;

}

export const useUXLabsStore = create<UXLabsStore>()(
  persist(
    (set) => ({

      labsAttachScreenCapture: true,
      setLabsAttachScreenCapture: (labsAttachScreenCapture: boolean) => set({ labsAttachScreenCapture }),

      labsCameraDesktop: false,
      setLabsCameraDesktop: (labsCameraDesktop: boolean) => set({ labsCameraDesktop }),

      labsChatBarAlt: false,
      setLabsChatBarAlt: (labsChatBarAlt: false | 'title') => set({ labsChatBarAlt }),

      labsEnhanceCodeBlocks: true,
      setLabsEnhanceCodeBlocks: (labsEnhanceCodeBlocks: boolean) => set({ labsEnhanceCodeBlocks }),

      labsEnhanceCodeLiveFile: false,
      setLabsEnhanceCodeLiveFile: (labsEnhanceCodeLiveFile: boolean) => set({ labsEnhanceCodeLiveFile }),

      labsHighPerformance: false,
      setLabsHighPerformance: (labsHighPerformance: boolean) => set({ labsHighPerformance }),

      labsShowCost: true, // release 1.16.0 with this enabled by default
      setLabsShowCost: (labsShowCost: boolean) => set({ labsShowCost }),

      labsAutoHideComposer: false,
      setLabsAutoHideComposer: (labsAutoHideComposer: boolean) => set({ labsAutoHideComposer }),

      labsShowShortcutBar: true,
      setLabsShowShortcutBar: (labsShowShortcutBar: boolean) => set({ labsShowShortcutBar }),

      // [DEV MODE] - maybe move them from here

      labsDevMode: false,
      setLabsDevMode: (labsDevMode: boolean) => set({ labsDevMode }),

      labsDevNoStreaming: false,
      setLabsDevNoStreaming: (labsDevNoStreaming: boolean) => set({ labsDevNoStreaming }),

    }),
    {
      name: 'app-ux-labs',

      // Migrations:
      // - 1: turn on the screen capture by default
      version: 1,
      migrate: (state: any, fromVersion: number): UXLabsStore => {
        // 0 -> 1: turn on the screen capture by default
        if (state && fromVersion < 1 && !state.labsAttachScreenCapture)
          return { ...state, labsAttachScreenCapture: true };
        return state;
      },

    },
  ),
);

export function getUXLabsHighPerformance() {
  return useUXLabsStore.getState().labsHighPerformance;
}

export function useLabsDevMode() {
  return useUXLabsStore((state) => state.labsDevMode) && Is.Deployment.Localhost;
}

export function getLabsDevMode() {
  return useUXLabsStore.getState().labsDevMode && Is.Deployment.Localhost;
}

export function getLabsDevNoStreaming() {
  // returns true if in dev mode and no streaming is active
  const { labsDevMode, labsDevNoStreaming } = useUXLabsStore.getState();
  return labsDevMode && labsDevNoStreaming;
}



================================================
FILE: src/common/stores/blob/dblobs-portability.ts
================================================
// Direct re-exports - no proxy functions needed
export {
  // Image operations
  addDBImageAsset,
  getImageAsset,
  gcDBImageAssets,
} from '~/modules/dblobs/dblobs.images';

export {
  // Generic operations
  deleteDBAsset,
  transferDBAssetContextScope,
  gcDBAssetsByScope,
  getDBAsset, // Add this if used directly
} from '~/modules/dblobs/dblobs.db';

export {
  // React hooks
  useDBAsset,
  useDBAssetsByScopeAndType,
} from '~/modules/dblobs/dblobs.hooks';

// Re-export select enums
export {
  DBlobAssetType,
  DBlobMimeType,
} from '~/modules/dblobs/dblobs.types';
// Re-export select types
export type {
  DBlobAssetId,
  DBlobDBAsset,
  DBlobDBContextId,
  DBlobDBScopeId,
  DBlobImageAsset,
} from '~/modules/dblobs/dblobs.types';



================================================
FILE: src/common/stores/chat/chat.conversation.ts
================================================
import { defaultSystemPurposeId, SystemPurposeId } from '../../../data';

import { agiUuid } from '~/common/util/idUtils';

import { DMessage, DMessageId, duplicateDMessage } from './chat.message';


/// Conversation

export interface DConversation {
  id: DConversationId;                // unique identifier for this conversation

  messages: DMessage[];               // linear list of messages in this conversation

  // editable
  userTitle?: string;
  autoTitle?: string;

  isArchived?: boolean;               // TODO: this is too simple - convert to improved meta information - for now this will do

  // temp flags
  _isIncognito?: boolean;             // simple implementation: won't store this conversation (note: side effects should be evaluated, images seem to be gc'd correctly, but not sure if this is really incognito)
  userSymbol?: string;                // TODO: let the user customize this - there may be a mapping elsewhere, but this is small enough and will do for now

  // TODO: [x Head] - this should be the system purpose of current head of the conversation
  // there should be the concept of the audience of the current head
  systemPurposeId: SystemPurposeId;   // system purpose of this conversation

  // when updated is null, we don't have messages yet (timestamps as Date.now())
  created: number;                    // creation timestamp
  updated: number | null;             // last update timestamp

  // TODO: @deprecated - should be a view-related cache
  tokenCount: number;                 // f(messages, llmId)

  // Not persisted, used while in-memory, or temporarily by the UI
  // TODO: @deprecated - shouls not be in here - it's actually a per-message/operation thing
  _abortController: AbortController | null;

  // future additions:
  // draftUserMessage?: { text: string; attachments: any[] };
  // isMuted: boolean; isStarred: boolean;
  // participants: personaIds...[];
}

export type DConversationId = string;


// helpers - creation

export function createDConversation(systemPurposeId?: SystemPurposeId): DConversation {
  return {
    id: agiUuid('chat-dconversation'),

    messages: [],

    // absent
    // userTitle: undefined,
    // autoTitle: undefined,
    // userSymbol: undefined,
    // isArchived: undefined,

    // @deprecated
    systemPurposeId: systemPurposeId || defaultSystemPurposeId,
    // @deprecated
    tokenCount: 0,

    created: Date.now(),
    updated: Date.now(),

    _abortController: null,
  };
}

export function duplicateDConversation(conversation: DConversation, lastMessageId: undefined | DMessageId, skipVoid: boolean): DConversation {

  // cut short messages, if requested
  let messagesToKeep = conversation.messages.length; // By default, include all messages if messageId is null
  if (lastMessageId) {
    const messageIndex = conversation.messages.findIndex(_m => _m.id === lastMessageId);
    if (messageIndex >= 0)
      messagesToKeep = messageIndex + 1;
  }

  // auto-increment title (1)
  const newTitle = getNextBranchTitle(conversationTitle(conversation));

  return {
    id: agiUuid('chat-dconversation'),

    messages: conversation.messages
      .slice(0, messagesToKeep)
      .map(message => duplicateDMessage(message, skipVoid)), // [*] duplicate conversation - see downstream

    // userTitle: conversation.userTitle, // undefined
    autoTitle: newTitle,
    userSymbol: conversation.userSymbol,
    ...(conversation.isArchived !== undefined ? { isArchived: conversation.isArchived } : {}), // copy archival state if set

    systemPurposeId: conversation.systemPurposeId,
    tokenCount: conversation.tokenCount,

    created: conversation.created,
    updated: Date.now(),

    _abortController: null,
  };
}


// helpers - title

export const conversationTitle = (conversation: DConversation, fallback?: string): string =>
  conversation.userTitle || conversation.autoTitle || fallback || ''; // 👋💬🗨️

function getNextBranchTitle(currentTitle: string): string {
  const numberPrefixRegex = /^\((\d+)\)\s+/; // Regex to find "(number) " at the beginning of the title
  const match = currentTitle.match(numberPrefixRegex);

  if (match) {
    const number = parseInt(match[1], 10) + 1;
    return currentTitle.replace(numberPrefixRegex, `(${number}) `);
  } else
    return `(1) ${currentTitle}`;
}


// helpers - System Instruction

export function hasSystemMessageInHistory(chatHistory: Readonly<DMessage[]>): boolean {
  return !!chatHistory?.length && chatHistory[0].role === 'system';
}

export function isSystemMessageUserEdited(message: DMessage): boolean {
  // make it explicit that '.updated' is the key to check for
  return message.role === 'system' && !!message.updated;
}

export function splitSystemMessageFromHistory(chatHistory: Readonly<DMessage[]>): {
  chatSystemInstruction: DMessage | null,
  chatHistory: Readonly<DMessage[]>,
} {
  const chatSystemInstruction = hasSystemMessageInHistory(chatHistory) ? chatHistory[0] : null;
  return {
    chatSystemInstruction,
    chatHistory: chatSystemInstruction ? chatHistory.slice(1) : chatHistory,
  };
}

export function excludeSystemMessages(messages: Readonly<DMessage[]>, showAll?: boolean): Readonly<DMessage[]> {
  if (showAll) return messages;
  return messages.filter(_m => _m.role !== 'system');
}

export function remapMessagesSysToUsr(messages: Readonly<DMessage[]> | null): DMessage[] {
  return (messages || []).map(_m => _m.role === 'system' ? { ..._m, role: 'user' as const } : _m); // (MUST: [0] is the system message of the original chat) cast system chat messages to the user role
}



================================================
FILE: src/common/stores/chat/chat.fragments.ts
================================================
import type { DBlobAssetId } from '~/common/stores/blob/dblobs-portability';

import type { LiveFileId } from '~/common/livefile/liveFile.types';
import { agiId } from '~/common/util/idUtils';


/// Fragments - forward compatible ///

// The Message Fragment is the smallest unit of a message, and can be of different types that wrap
// a 'Part' with a type discriminator and extra information (like a title). Notes:
// - fId: Fragment ID (8 bytes), unique within the container only

/*export type DSystemInstructionFragment = DMessageBaseFragment<'system',
  | DMessageTextPart
> & {
  // UI attributes for a great system message, e.g. has it been edited, etc.
  editable?: boolean;
  deletable?: boolean;
  modified?: boolean;
};*/

export type DMessageFragment =
  | DMessageContentFragment
  | DMessageAttachmentFragment
  | DMessageVoidFragment
  // | DMessageBeamFragment
  | _SentinelFragment
  ;

/**
 * Content Fragments: understood by ai and humans, processed by llms and stored
 */
export type DMessageContentFragment = _DMessageFragmentWrapper<'content',
  | DMessageTextPart              // plain text or mixed content -> BlockRenderer
  | DMessageImageRefPart          // large image
  | DMessageToolInvocationPart    // shown to dev only, singature of the llm function call
  | DMessageToolResponsePart      // shown to dev only, response of the llm
  | DMessageErrorPart             // red message, e.g. non-content application issues
  | _SentinelPart
>;

/**
 * Attachment Fragments: higher level representation of content, usually from attachments,
 * - image references, documents, etc.
 * - may still have upstream links for instance
 */
export type DMessageAttachmentFragment = _DMessageFragmentWrapper<'attachment',
  | DMessageDocPart               // document Attachment
  | DMessageImageRefPart          // image Attachment
  | _SentinelPart
> & {
  title: string;                  // label of the attachment (filename, named id, content overview, title..)
  caption: string;                // additional information, such as provenance, content preview, etc.
  created: number;
  liveFileId?: LiveFileId;        // [LiveFile] Optional. Relate to a LiveFile; if present, it may still be invalid, hence we cleanup on load
};

/**
 * Void Fragments: no meaning, pure cosmetic, not stored, not processed
 */
export type DMessageVoidFragment = _DMessageFragmentWrapper<'void',
  | DVoidModelAnnotationsPart     // (non submitted) model references, citations, etc.
  | DVoidModelAuxPart             // (non submitted) model auxiliary information, from the model itself
  | DVoidPlaceholderPart          // (non submitted) placeholder to be replaced by another part
  | _SentinelPart
>;


// Future Examples: up to 1 per message, containing the Rays and Merges that would be used to restore the Beam state - could be volatile (omitted at save)
// could not be the data store itself, but only used for save/reload
// export type DMessageBeamFragment = DMessageBaseFragment<'beam'> & {
//   ft: 'beam',
//   fId: DMessageFragmentId;
//   beam: { rays: any[], merges: any[], ... };
// }

// Sentinel: force the typesystem to work, bark, and detect/reveal corner cases - unused aside from revealing fragment type issues
type _SentinelFragment = { ft: '_ft_sentinel', fId: DMessageFragmentId };

export type DMessageFragmentId = string; // not unique, 8 bytes
type _DMessageFragmentWrapper<TFragment, TPart extends { pt: string }> = {
  ft: TFragment;
  fId: DMessageFragmentId;
  part: TPart;
}


/// Parts - STABLE ///

// - Data at rest: these are used in the DMessage objects
// - DO NOT CHANGE - think twice (data at rest)
// Small and efficient (larger objects need to only be referred to)

export type DMessageTextPart = { pt: 'text', text: string };

export type DMessageErrorPart = { pt: 'error', error: string };

export type DMessageImageRefPart = { pt: 'image_ref', dataRef: DMessageDataRef, altText?: string, width?: number, height?: number };

export type DMessageDocPart = { pt: 'doc', vdt: DMessageDocMimeType, data: DMessageDataInline, ref: string, l1Title: string, version?: number, meta?: DMessageDocMeta };
type DMessageDocMimeType =
// | 'application/vnd.agi.ego.fragments'         // for attaching messages
// | 'application/vnd.agi.imageRef'    // for image attachments with da - NO: makes no sense, as doc contains data
// | 'application/vnd.agi.plantuml'
// | 'image/svg+xml'
// | 'text/csv'                        // table editor
// | 'text/html'                       // can be rendered in iframes (RenderCode[HTML])
// | 'text/markdown'                   // can be rendered as markdown (note that text/plain can also)
  | 'application/vnd.agi.code'        // Blocks > RenderCode (it's a text/plain)
  | 'application/vnd.agi.ocr'         // images/pdfs converted as text
  | 'text/plain'                      // e.g. clipboard paste
  ;
type DMessageDocMeta = {
  codeLanguage?: string;
  srcFileName?: string;
  srcFileSize?: number;
  srcOcrFrom?: 'image' | 'pdf';
}

export type DMessageToolInvocationPart = {
  pt: 'tool_invocation',
  id: string,
  invocation: {
    type: 'function_call'
    name: string;             // Name of the function as passed from the definition
    args: string /*| null*/;  // JSON-encoded object (only objects are supported), if null there are no args and it's just a plain invocation
    // temporary, not stored
    _description?: string;    // Description from the definition
    _args_schema?: object;    // JSON Schema { type: 'object', properties: { ... } } from the definition
  } | {
    type: 'code_execution';
    language: string;
    code: string;
    author: 'gemini_auto_inline';
  }
};

export type DMessageToolResponsePart = {
  pt: 'tool_response',
  id: string,
  error: boolean | string,
  response: {
    type: 'function_call';
    name: string;             // Name of the function that produced the result
    result: string;           // The output
  } | {
    type: 'code_execution';
    result: string;           // The output
    executor: 'gemini_auto_inline';
  },
  environment: DMessageToolEnvironment,
};
type DMessageToolEnvironment = 'upstream' | 'server' | 'client';


type DVoidModelAnnotationsPart = {
  pt: 'annotations',
  annotations: readonly DVoidWebCitation[],
};

export type DVoidWebCitation = {
  type: 'citation',
  url: string,
  title: string,
  refNumber?: number,
  pubTs?: number, // publication timestamp
  ranges: readonly { startIndex: number, endIndex: number, textSnippet?: string }[],
};


export type DVoidModelAuxPart = {
  pt: 'ma',
  aType: 'reasoning', // note, we don't specialize to 'ant-thinking' here, as we can infer it from the presence of textSignature or redactedData
  aText: string,
  // [Anthropic] attributes, if present, they imply "Extended Thinking" object(s)
  textSignature?: string,
  redactedData?: readonly string[],
};

type DVoidPlaceholderPart = { pt: 'ph', pText: string, pType?: 'chat-gen-follow-up', /* 2025-02-23: added for non-pure-text placeholders */ };

type _SentinelPart = { pt: '_pt_sentinel' };


//
// Message Data - DO NOT CHANGE - think twice (data at rest)
//
// We use a Ref and the DBlob framework to store media locally, or remote URLs
//

export type DMessageDataInline =
  | { idt: 'text', text: string, mimeType?: string /* optional, assuming the upper layers have mime already */ }; // | { idt: 'base64', base64: string };

export type DMessageDataRef =
  | { reftype: 'url'; url: string } // remotely accessible URL - NOTE: not used right now, this is more of a sentinel
  | { reftype: 'dblob'; dblobAssetId: DBlobAssetId, mimeType: string; bytesSize: number; } // reference to a DBlob
  ;


/// Helpers - Fragment Type Guards - (we don't need 'fragment is X' since TypeScript 5.5.2)

export function isContentFragment(fragment: DMessageFragment): fragment is DMessageContentFragment {
  return fragment.ft === 'content' && !!fragment.part?.pt;
}

export function isTextContentFragment(fragment: DMessageFragment): fragment is DMessageContentFragment & { part: DMessageTextPart } {
  return fragment.ft === 'content' && fragment.part.pt === 'text';
}

export function isAttachmentFragment(fragment: DMessageFragment): fragment is DMessageAttachmentFragment {
  return fragment.ft === 'attachment' && !!fragment.part?.pt;
}

export function isContentOrAttachmentFragment(fragment: DMessageFragment) {
  return fragment.ft === 'content' || fragment.ft === 'attachment';
}


export function isVoidFragment(fragment: DMessageFragment): fragment is DMessageVoidFragment {
  return fragment.ft === 'void' && !!fragment.part?.pt;
}

export function isVoidAnnotationsFragment(fragment: DMessageFragment): fragment is DMessageVoidFragment & { part: DVoidModelAnnotationsPart } {
  return fragment.ft === 'void' && fragment.part.pt === 'annotations';
}

export function isVoidThinkingFragment(fragment: DMessageFragment): fragment is DMessageVoidFragment & { part: DVoidModelAuxPart } {
  return fragment.ft === 'void' && fragment.part.pt === 'ma' && fragment.part.aType === 'reasoning';
}


export function isDocPart(part: DMessageContentFragment['part'] | DMessageAttachmentFragment['part']) {
  return part.pt === 'doc';
}

export function isImageRefPart(part: DMessageContentFragment['part'] | DMessageAttachmentFragment['part']) {
  return part.pt === 'image_ref';
}

export function isTextPart(part: DMessageContentFragment['part']) {
  return part.pt === 'text';
}

export function isErrorPart(part: DMessageContentFragment['part']) {
  return part.pt === 'error';
}

export function isToolResponseFunctionCallPart(part: DMessageContentFragment['part']): part is DMessageToolResponsePart & { response: { type: 'function_call' } } {
  return part.pt === 'tool_response' && part.response.type === 'function_call';
}

export function isAnnotationsPart(part: DMessageVoidFragment['part']) {
  return part.pt === 'annotations';
}

export function isModelAuxPart(part: DMessageVoidFragment['part']) {
  return part.pt === 'ma';
}

export function isPlaceholderPart(part: DMessageVoidFragment['part']) {
  return part.pt === 'ph';
}


/// Content Fragments - Creation & Duplication

export function createTextContentFragment(text: string): DMessageContentFragment {
  return _createContentFragment(_create_Text_Part(text));
}

export function createErrorContentFragment(error: string): DMessageContentFragment {
  return _createContentFragment(_create_Error_Part(error));
}

export function createImageContentFragment(dataRef: DMessageDataRef, altText?: string, width?: number, height?: number): DMessageContentFragment {
  return _createContentFragment(_create_ImageRef_Part(dataRef, altText, width, height));
}

export function create_FunctionCallInvocation_ContentFragment(id: string, functionName: string, args: string /*| null*/): DMessageContentFragment {
  return _createContentFragment(_create_FunctionCallInvocation_Part(id, functionName, args));
}

export function create_CodeExecutionInvocation_ContentFragment(id: string, language: string, code: string, author: 'gemini_auto_inline'): DMessageContentFragment {
  return _createContentFragment(_create_CodeExecutionInvocation_Part(id, language, code, author));
}

export function create_FunctionCallResponse_ContentFragment(id: string, error: boolean | string, name: string, result: string, environment: DMessageToolEnvironment): DMessageContentFragment {
  return _createContentFragment(_create_FunctionCallResponse_Part(id, error, name, result, environment));
}

export function create_CodeExecutionResponse_ContentFragment(id: string, error: boolean | string, result: string, executor: 'gemini_auto_inline', environment: DMessageToolEnvironment): DMessageContentFragment {
  return _createContentFragment(_create_CodeExecutionResponse_Part(id, error, result, executor, environment));
}

function _createContentFragment(part: DMessageContentFragment['part']): DMessageContentFragment {
  return { ft: 'content', fId: agiId('chat-dfragment' /* -content */), part };
}


/// Attachment Fragments - Creation & Duplication

export function createDocAttachmentFragment(l1Title: string, caption: string, vdt: DMessageDocMimeType, data: DMessageDataInline, ref: string, version: number, meta?: DMessageDocMeta, liveFileId?: LiveFileId): DMessageAttachmentFragment {
  return _createAttachmentFragment(l1Title, caption, _create_Doc_Part(vdt, data, ref, l1Title, version, meta), liveFileId);
}

export function createImageAttachmentFragment(title: string, caption: string, dataRef: DMessageDataRef, imgAltText?: string, width?: number, height?: number): DMessageAttachmentFragment {
  return _createAttachmentFragment(title, caption, _create_ImageRef_Part(dataRef, imgAltText, width, height), undefined);
}

export function specialContentPartToDocAttachmentFragment(title: string, caption: string, vdt: DMessageDocMimeType, contentPart: DMessageContentFragment['part'], ref: string, docMeta?: DMessageDocMeta): DMessageAttachmentFragment {
  switch (true) {
    case isTextPart(contentPart):
      return createDocAttachmentFragment(title, caption, vdt, createDMessageDataInlineText(contentPart.text, 'text/plain'), ref, 2 /* As we attach our messages, we start from 2 */, docMeta);
    case isImageRefPart(contentPart):
      return createImageAttachmentFragment(title, caption, _duplicate_DataReference(contentPart.dataRef), contentPart.altText, contentPart.width, contentPart.height);
    default:
      return createDocAttachmentFragment('Error', 'Content to Attachment', vdt, createDMessageDataInlineText(`Conversion of '${contentPart.pt}' is not supported yet.`, 'text/plain'), ref, 1 /* error has no version really */, docMeta);
  }
}

function _createAttachmentFragment(title: string, caption: string, part: DMessageAttachmentFragment['part'], liveFileId: LiveFileId | undefined): DMessageAttachmentFragment {
  return { ft: 'attachment', fId: agiId('chat-dfragment' /* -attachment */), title, caption, created: Date.now(), part, liveFileId };
}


/// Void Fragments - Creation & Duplication

export function createAnnotationsVoidFragment(annotations: DVoidWebCitation[]): DMessageVoidFragment {
  return _createVoidFragment(_create_Annotations_Part(annotations));
}

export function createModelAuxVoidFragment(aType: DVoidModelAuxPart['aType'], aText: string, textSignature?: string, redactedData?: string[]): DMessageVoidFragment {
  return _createVoidFragment(_create_ModelAux_Part(aType, aText, textSignature, redactedData));
}

export function createPlaceholderVoidFragment(placeholderText: string, placeholderType?: DVoidPlaceholderPart['pType']): DMessageVoidFragment {
  return _createVoidFragment(_create_Placeholder_Part(placeholderText, placeholderType));
}

function _createVoidFragment(part: DMessageVoidFragment['part']): DMessageVoidFragment {
  return { ft: 'void', fId: agiId('chat-dfragment' /* -void */), part };
}


/// Sentinel Fragments - only here to force the typesystem to work

function _createSentinelFragment(): _SentinelFragment {
  return { ft: '_ft_sentinel', fId: agiId('chat-dfragment' /* -_sentinel */) };
}


export function duplicateDMessageFragments(fragments: Readonly<DMessageFragment[]>, skipVoid: boolean): DMessageFragment[] {
  return !skipVoid ? fragments.map(_duplicateFragment)
    : fragments.map(_duplicateFragment).filter(f => f.ft !== 'void');
}

function _duplicateFragment(fragment: DMessageFragment): DMessageFragment {
  switch (fragment.ft) {
    case 'content':
      return _createContentFragment(_duplicate_Part(fragment.part));

    case 'attachment':
      return _createAttachmentFragment(fragment.title, fragment.caption, _duplicate_Part(fragment.part), fragment.liveFileId);

    case 'void':
      return _createVoidFragment(_duplicate_Part(fragment.part));

    case '_ft_sentinel':
      return _createSentinelFragment();

    default:
      console.warn('[DEV] _duplicateFragment: Unknown fragment type, will duplicate as Error', { fragment });
      return createErrorContentFragment(`Unknown fragment type '${(fragment as any)?.ft || '(undefined)'}'`);
  }
}


/// Helpers - Parts Creation & Duplication

function _create_Text_Part(text: string): DMessageTextPart {
  return { pt: 'text', text };
}

function _create_Error_Part(error: string): DMessageErrorPart {
  return { pt: 'error', error };
}

function _create_Doc_Part(vdt: DMessageDocMimeType, data: DMessageDataInline, ref: string, l1Title: string, version: number, meta?: DMessageDocMeta): DMessageDocPart {
  return { pt: 'doc', vdt, data, ref, l1Title, version, meta };
}

function _create_ImageRef_Part(dataRef: DMessageDataRef, altText?: string, width?: number, height?: number): DMessageImageRefPart {
  return { pt: 'image_ref', dataRef, altText, width, height };
}

function _create_FunctionCallInvocation_Part(id: string, functionName: string, args: string /*| null*/): DMessageToolInvocationPart {
  return { pt: 'tool_invocation', id, invocation: { type: 'function_call', name: functionName, args } };
}

function _create_CodeExecutionInvocation_Part(id: string, language: string, code: string, author: 'gemini_auto_inline'): DMessageToolInvocationPart {
  return { pt: 'tool_invocation', id, invocation: { type: 'code_execution', language, code, author } };
}

function _create_FunctionCallResponse_Part(id: string, error: boolean | string, name: string, result: string, environment: DMessageToolEnvironment): DMessageToolResponsePart {
  return { pt: 'tool_response', id, error, response: { type: 'function_call', name, result }, environment };
}

function _create_CodeExecutionResponse_Part(id: string, error: boolean | string, result: string, executor: 'gemini_auto_inline', environment: DMessageToolEnvironment): DMessageToolResponsePart {
  return { pt: 'tool_response', id, error, response: { type: 'code_execution', result, executor }, environment };
}

export function createDVoidWebCitation(url: string, title: string, refNumber?: number, rangeStartIndex?: number, rangeEndIndex?: number, rangeTextSnippet?: string, pubTs?: number): DVoidWebCitation {
  return {
    type: 'citation', url, title, ...(refNumber !== undefined ? { refNumber } : {}), ...(pubTs !== undefined ? { pubTs } : {}),
    ranges: (rangeStartIndex !== undefined && rangeEndIndex !== undefined) ? [{
      startIndex: rangeStartIndex,
      endIndex: rangeEndIndex,
      ...(rangeTextSnippet ? { textSnippet: rangeTextSnippet } : {}),
    }] : [],
  };
}

function _create_Annotations_Part(annotations: DVoidWebCitation[]): DVoidModelAnnotationsPart {
  return { pt: 'annotations', annotations };
}

function _create_ModelAux_Part(aType: DVoidModelAuxPart['aType'], aText: string, textSignature?: string, redactedData?: Readonly<string[]>): DVoidModelAuxPart {
  return {
    pt: 'ma', aType, aText,
    ...(textSignature !== undefined ? { textSignature } : undefined),
    ...(redactedData ? { redactedData: Array.from(redactedData) /* creates a mutable copy of the array */ } : undefined),
  };
}

function _create_Placeholder_Part(placeholderText: string, pType?: DVoidPlaceholderPart['pType']): DVoidPlaceholderPart {
  return { pt: 'ph', pText: placeholderText, ...(pType ? { pType } : undefined) };
}

function _create_Sentinel_Part(): _SentinelPart {
  return { pt: '_pt_sentinel' };
}

function _duplicate_Part<TPart extends (DMessageContentFragment | DMessageAttachmentFragment | DMessageVoidFragment)['part']>(part: TPart): TPart {
  const pt = part.pt;
  switch (pt) {
    case 'doc':
      const newDocVersion = Number(part.version ?? 1); // we don't increase the version on duplication (not sure we should?)
      return _create_Doc_Part(part.vdt, _duplicate_InlineData(part.data), part.ref, part.l1Title, newDocVersion, part.meta ? { ...part.meta } : undefined) as TPart;

    case 'error':
      return _create_Error_Part(part.error) as TPart;

    case 'image_ref':
      return _create_ImageRef_Part(_duplicate_DataReference(part.dataRef), part.altText, part.width, part.height) as TPart;

    case 'annotations':
      const annotationsDeepCopy = part.annotations.map(citation => ({
        ...citation,
        ranges: citation.ranges.map(range => ({
          ...range,
        })),
      }));
      return _create_Annotations_Part(annotationsDeepCopy) as TPart;

    case 'ma':
      return _create_ModelAux_Part(part.aType, part.aText, part.textSignature, part.redactedData) as TPart;

    case 'ph':
      return _create_Placeholder_Part(part.pText, part.pType) as TPart;

    case 'text':
      return _create_Text_Part(part.text) as TPart;

    case 'tool_invocation':
      return part.invocation.type === 'function_call'
        ? _create_FunctionCallInvocation_Part(part.id, part.invocation.name, part.invocation.args) as TPart
        : _create_CodeExecutionInvocation_Part(part.id, part.invocation.language, part.invocation.code, part.invocation.author) as TPart;

    case 'tool_response':
      return part.response.type === 'function_call'
        ? _create_FunctionCallResponse_Part(part.id, part.error, part.response.name, part.response.result, part.environment) as TPart
        : _create_CodeExecutionResponse_Part(part.id, part.error, part.response.result, part.response.executor, part.environment) as TPart;

    case '_pt_sentinel':
      return _create_Sentinel_Part() as TPart;

    default:
      const _exhaustiveCheck: never = pt;

      // console.warn('[DEV] _duplicate_Part: Unknown part type, will duplicate as Error', { part });
      // return _create_Error_Part(`Unknown part type '${(part as any)?.pt || '(undefined)'}'`) as TPart;

      // unexpected case: if we are here, the best to do is probably to return a clone of the part, as returning
      // nothing would corrupt the Fragment
      return structuredClone(part) as TPart; // fallback to structured clone for unknown parts
  }
}


/// Helpers - Data Reference Creation & Duplication

/**
 * Document View Mimetype - 3 uses:
 * - DMessageDocPart.vdt: the visual interpretation of the document (the mimetype of data is in .data.mimeType)
 * - AixWire_Parts.DocPart_schema: gives extra semantic meaning to the Doc part (in conjunction with DMessageDocMeta)
 * - used at rest, and in flight - be very careful not to change anything
 */
export const DVMimeType = {
  VndAgiCode: 'application/vnd.agi.code',
  VndAgiOcr: 'application/vnd.agi.ocr',
  TextPlain: 'text/plain',
} as const;

export function createDMessageDataInlineText(text: string, mimeType?: string): DMessageDataInline {
  return { idt: 'text', text, mimeType };
}

function _duplicate_InlineData(data: DMessageDataInline): DMessageDataInline {
  switch (data.idt) {
    case 'text':
      return createDMessageDataInlineText(data.text, data.mimeType);

    // case 'base64':
    //   return createDMessageDataInlineBase64(data.base64);
  }
}

export function createDMessageDataRefDBlob(dblobAssetId: DBlobAssetId, mimeType: string, bytesSize: number): DMessageDataRef {
  return { reftype: 'dblob', dblobAssetId: dblobAssetId, mimeType, bytesSize };
}

export function createDMessageDataRefUrl(url: string): DMessageDataRef {
  return { reftype: 'url', url };
}

function _duplicate_DataReference(ref: DMessageDataRef): DMessageDataRef {
  switch (ref.reftype) {
    case 'dblob':
      return createDMessageDataRefDBlob(ref.dblobAssetId, ref.mimeType, ref.bytesSize);

    case 'url':
      return createDMessageDataRefUrl(ref.url);
  }
}


/// Editor Helpers - Fragment Editing

export function splitFragmentsByType(fragments: DMessageFragment[]) {
  // also see `useFragmentBuckets.ts` which inspired this function
  return fragments.reduce((acc, frag) => {
    if (isContentFragment(frag))
      acc.contentFragments.push(frag);
    else if (isAttachmentFragment(frag))
      acc.attachmentFragments.push(frag);
    else if (isVoidFragment(frag))
      acc.voidFragments.push(frag);
    else
      console.warn('[DEV] splitFragmentsByType: Unexpected fragment type:', frag.ft);
    return acc;
  }, {
    contentFragments: [] as DMessageContentFragment[],
    attachmentFragments: [] as DMessageAttachmentFragment[],
    voidFragments: [] as DMessageVoidFragment[],
  });
}

export function filterDocAttachmentFragments(fragments: DMessageAttachmentFragment[]) {
  return fragments.filter(fragment => isDocPart(fragment.part));
}

/**
 * Updates a fragment with the edited text, ensuring the fragment retains its type and structure.
 * @returns A new fragment with the edited text applied or null if the fragment type isn't handled.
 */
export function updateFragmentWithEditedText(fragment: DMessageContentFragment, editedText: string): DMessageContentFragment | null;
export function updateFragmentWithEditedText(fragment: DMessageAttachmentFragment, editedText: string): DMessageAttachmentFragment | null;
export function updateFragmentWithEditedText(fragment: DMessageFragment, editedText: string): DMessageFragment | null;
export function updateFragmentWithEditedText(
  fragment: DMessageFragment,
  editedText: string,
): DMessageFragment | null {

  // NOTE: we transfer the responsibility of this to the caller
  // if (editedText.length === 0) {
  //   // If the edited text is empty, we may choose to delete the fragment (depending on the caller's logic)
  //   return null;
  // }

  if (isContentFragment(fragment)) {
    const { fId, part } = fragment;

    if (isTextPart(part)) {
      // Create a new text content fragment with the same fId and the edited text
      const newFragment = createTextContentFragment(editedText);
      return { ...newFragment, fId }; // Preserve original fId
    } else if (part.pt === 'error') {
      const newFragment = createErrorContentFragment(editedText);
      return { ...newFragment, fId }; // Preserve original fId
    } else if (part.pt === 'tool_invocation') {
      if (part.invocation.type === 'function_call') {
        // Create a new tool invocation fragment with the edited args
        const newFragment = create_FunctionCallInvocation_ContentFragment(
          part.id, // Keep same id
          part.invocation.name,
          editedText, // args (if empty, it calls the funciton without params)
        );
        return { ...newFragment, fId }; // Preserve original fId
      } else if (part.invocation.type === 'code_execution') {
        const newFragment = create_CodeExecutionInvocation_ContentFragment(
          part.id, // Keep same id
          part.invocation.language,
          editedText, // code
          part.invocation.author,
        );
        return { ...newFragment, fId };
      }
    } else if (part.pt === 'tool_response') {
      if (part.error) {
        // Update the error field in 'tool_response' part
        const newPart = {
          ...part,
          error: editedText,
        };
        return { ...fragment, part: newPart };
      } else {
        // Update the result field in 'tool_response' part
        const response = part.response;
        if (response.type === 'function_call') {
          const newFragment = create_FunctionCallResponse_ContentFragment(
            part.id,
            part.error,
            response.name,
            editedText, // result
            part.environment,
          );
          return { ...newFragment, fId };
        } else if (response.type === 'code_execution') {
          const newFragment = create_CodeExecutionResponse_ContentFragment(
            part.id,
            part.error,
            editedText, // result
            response.executor,
            part.environment,
          );
          return { ...newFragment, fId };
        }
      }
    }
  } else if (isAttachmentFragment(fragment)) {
    const { fId, part, title, caption, liveFileId } = fragment;

    if (isDocPart(part)) {
      // Create a new doc attachment fragment with the edited text
      const newDataInline: DMessageDataInline = createDMessageDataInlineText(
        editedText,
        part.data.mimeType,
      );
      const newFragment = createDocAttachmentFragment(
        part.l1Title || title,
        caption,
        part.vdt,
        newDataInline,
        part.ref,
        Number(part.version ?? 1) + 1, // Increment version as this has been edited - note: we could have used ?? to be more correct, but || is safer
        part.meta,
        liveFileId,
      );
      return { ...newFragment, fId }; // Preserve original fId
    }
    // Handle other attachment parts if needed
  }

  // Return null if the fragment type is not handled
  return null;
}

export function editTextPartsInline(fragments: DMessageFragment[], editText: (text: string, idx: number) => string): void {
  fragments.forEach((fragment, idx) => {
    if (isTextContentFragment(fragment))
      fragment.part.text = editText(fragment.part.text, idx);
  });
}

export function prependTextPartsInline(fragments: DMessageFragment[], textPrefix: string): void {
  for (const fragment of fragments) {
    if (!isTextContentFragment(fragment))
      continue;
    fragment.part.text = textPrefix + ' ' + fragment.part.text;
    return;
  }
  fragments.unshift(createTextContentFragment(textPrefix));
}



================================================
FILE: src/common/stores/chat/chat.gc.ts
================================================
import { DBlobAssetId, gcDBImageAssets } from '~/common/stores/blob/dblobs-portability';

import type { DConversation } from './chat.conversation';
import { isContentOrAttachmentFragment, isImageRefPart } from './chat.fragments';
import { useChatStore } from './store-chats';

/**
 * Garbage collect unreferenced dblobs in global chats
 * - This is ran as a side effect of the chat store rehydration
 * - This is also ran when a conversation or message is deleted, or when a conversation messages history is replaced
 */
export async function gcChatImageAssets(conversations?: DConversation[]) {

  // find all the dblob references in all chats
  const chatsAssetIDs: Set<DBlobAssetId> = new Set();
  const _conversations = conversations || useChatStore.getState().conversations;
  for (const chat of _conversations) {
    for (const message of chat.messages) {
      for (const fragment of message.fragments) {
        if (!isContentOrAttachmentFragment(fragment) || !isImageRefPart(fragment.part))
          continue;
        if (fragment.part.dataRef.reftype !== 'dblob')
          continue;
        chatsAssetIDs.add(fragment.part.dataRef.dblobAssetId);
      }
    }
  }

  // sanity check: if no blobs are referenced, do nothing; in case we have a state bug and we don't wipe the db
  if (!chatsAssetIDs.size)
    return;

  // perform the GC (set to array)
  await gcDBImageAssets('global', 'app-chat', Array.from(chatsAssetIDs));
}


================================================
FILE: src/common/stores/chat/chat.message.ts
================================================
import { agiUuid } from '~/common/util/idUtils';

import { createPlaceholderVoidFragment, createTextContentFragment, DMessageFragment, duplicateDMessageFragments, isAttachmentFragment, isContentFragment, isVoidFragment } from './chat.fragments';

import type { ModelVendorId } from '~/modules/llms/vendors/vendors.registry';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import type { DMetricsChatGenerate_Md } from '~/common/stores/metrics/metrics.chatgenerate';


// Message

export interface DMessage {
  id: DMessageId;                     // unique message ID

  role: DMessageRole;
  fragments: DMessageFragment[];      // fragments can be content/attachments/... implicitly ordered

  // pending state (not stored)
  pendingIncomplete?: boolean;        // if true, the message is incomplete (e.g. tokens won't be computed)

  // TODO: @deprecated - move to a Persona ID of the persona who wrote it, and still, could be teamwork...
  purposeId?: string;                 // only assistant/system

  metadata?: DMessageMetadata;        // Semantic augmentation, mainly at creation

  generator?: DMessageGenerator;      // Assistant generator info, and metrics

  userFlags?: DMessageUserFlag[];     // (UI) user-set per-message flags

  // TODO: @deprecated remove this, it's really view-dependent
  tokenCount: number;                 // cache for token count, using the current Conversation model (0 = not yet calculated)

  // TODO: add a Beam JSON state load/store
  // volatileBeamRestore?: object;

  created: number;                    // created timestamp
  updated: number | null;             // updated timestamp - null means incomplete - TODO: disambiguate vs pendingIncomplete
}

export type DMessageId = string;

export type DMessageRole = 'user' | 'assistant' | 'system';


// Message > Metadata

export interface DMessageMetadata {
  inReferenceTo?: DMetaReferenceItem[]; // text this was in reply to
  entangled?: DMessageEntangled; // entangled messages info
  // NOTE: if adding fields, manually update `duplicateDMessageMetadata`
}

/** A textual reference to a text snipped, by a certain role. */
export interface DMetaReferenceItem {
  mrt: 'dmsg';                        // for future type discrimination
  mText: string;
  mRole: DMessageRole;
  // messageId?: string;
}

/** Entangled messages info for coordinated multi-chat operations. */
export interface DMessageEntangled {
  id: string;           // entanglement group ID
  color: string;        // hex color for visual connection
  count: number;        // total number of chats this was sent to
}


// Message > User Flags

export type DMessageUserFlag =
  | 'aix.skip'                        // mark this message as skipped during generation (won't be sent to the LLM)
  | 'starred'                         // user has starred this message
  | 'notify.complete'                 // user has requested a notification when this message is complete
  | 'vnd.ant.cache.auto'              // [Anthropic] user requested breakpoints to be added automatically (per conversation)
  | 'vnd.ant.cache.user'              // [Anthropic] user requestd for a breakpoint to be added here specifically
  ;

export const MESSAGE_FLAG_AIX_SKIP: DMessageUserFlag = 'aix.skip';
export const MESSAGE_FLAG_STARRED: DMessageUserFlag = 'starred';
export const MESSAGE_FLAG_NOTIFY_COMPLETE: DMessageUserFlag = 'notify.complete';
export const MESSAGE_FLAG_VND_ANT_CACHE_AUTO: DMessageUserFlag = 'vnd.ant.cache.auto';
export const MESSAGE_FLAG_VND_ANT_CACHE_USER: DMessageUserFlag = 'vnd.ant.cache.user';


// Message > Generator

export type DMessageGenerator = ({
  // A named generator is a simple string, presented as-is
  mgt: 'named';
  name: 'web' | 'issue' | 'help' | string;
  // xeOpCode?: 'op-draw-text',
} | {
  // An AIX generator preserves information about original model and vendor:
  // - vendor ids will be stable across time
  // - no guarantee of consistency on the model, e.g. could be across different devices
  mgt: 'aix',
  name: string;                       // model that handled the request
  aix: {
    vId: ModelVendorId;               // Models Vendor Id (note we deleted sId, was too much, but can add it later)
    mId: DLLMId;                      // Models Id
  },
}) & {
  metrics?: DMetricsChatGenerate_Md;   // medium-sized metrics stored in the message
  tokenStopReason?:
    | 'client-abort'                  // if the generator stopped due to a client abort signal
    | 'filter'                        // (inline filter message injected) if the generator stopped due to a filter
    | 'issue'                         // (error fragment follows) if the generator stopped due to an issue
    | 'out-of-tokens'                 // if the generator stopped due to running out of tokens
};


// helpers - creation

export function createDMessageEmpty(role: DMessageRole) {
  return createDMessageFromFragments(role, []);
}

export function createDMessageTextContent(role: DMessageRole, text: string): DMessage {
  return createDMessageFromFragments(role, [createTextContentFragment(text)]);
}

export function createDMessagePlaceholderIncomplete(role: DMessageRole, placeholderText: string): DMessage {
  const placeholderFragment = createPlaceholderVoidFragment(placeholderText, undefined);
  const message = createDMessageFromFragments(role, [placeholderFragment]);
  message.pendingIncomplete = true;
  return message;
}

export function createDMessageFromFragments(role: DMessageRole, fragments: DMessageFragment[]): DMessage {
  return {
    id: agiUuid('chat-dmessage'),

    role: role,
    fragments,

    // pending state
    // pendingIncomplete: false,  // we leave it undefined, same as false

    // absent
    // purposeId: undefined, // @deprecated
    // metadata: undefined,
    // generator: undefined,
    // userFlags: undefined,

    // @deprecated
    tokenCount: 0,

    created: Date.now(),
    updated: null,
  };
}


// helpers - duplication

export function duplicateDMessage(message: Readonly<DMessage>, skipVoid: boolean): DMessage {
  return {
    id: agiUuid('chat-dmessage'),

    role: message.role,
    fragments: duplicateDMessageFragments(message.fragments, skipVoid), // [*] full message duplication (see downstream)

    ...(message.pendingIncomplete ? { pendingIncomplete: true } : {}),

    purposeId: message.purposeId,

    metadata: message.metadata ? duplicateDMessageMetadata(message.metadata) : undefined,
    generator: message.generator ? duplicateDMessageGenerator(message.generator) : undefined,
    userFlags: message.userFlags ? [...message.userFlags] : undefined,

    tokenCount: message.tokenCount,

    created: message.created,
    updated: message.updated,
  };
}

export function duplicateDMessageMetadata(metadata: Readonly<DMessageMetadata>): DMessageMetadata {
  // NOTE: update this function when adding metadata fields
  return {
    ...(metadata.inReferenceTo ? {
      inReferenceTo: metadata.inReferenceTo.map(refItem => ({ ...refItem })),
    } : {}),
    ...(metadata.entangled ? {
      entangled: { ...metadata.entangled },
    } : {}),
  };
}

export function duplicateDMessageGenerator(generator: Readonly<DMessageGenerator>): DMessageGenerator {
  switch (generator.mgt) {
    case 'named':
      return {
        mgt: 'named',
        name: generator.name,
        // ...(generator.xeOpCode ? { xeOpCode: generator.xeOpCode } : {}),
        ...(generator.metrics ? { metrics: { ...generator.metrics } } : {}),
        ...(generator.tokenStopReason ? { tokenStopReason: generator.tokenStopReason } : {}),
      };
    case 'aix':
      return {
        mgt: 'aix',
        name: generator.name,
        aix: { ...generator.aix },
        ...(generator.metrics ? { metrics: { ...generator.metrics } } : {}),
        ...(generator.tokenStopReason ? { tokenStopReason: generator.tokenStopReason } : {}),
      };
  }
}


// helpers - status checks

export function messageWasInterruptedAtStart(message: Pick<DMessage, 'generator' | 'fragments'>): boolean {
  return message.generator?.tokenStopReason === 'client-abort' && !message.fragments?.length;
}

// export function messageOnlyContainsPlaceholder(message: Pick<DMessage, 'fragments'>): boolean {
//   return message.fragments.length === 1 && isVoidFragment(message.fragments[0]) && isPlaceholderPart(message.fragments[0].part);
// }


// helpers - user flags

const flag2EmojiMap: Record<DMessageUserFlag, string> = {
  [MESSAGE_FLAG_AIX_SKIP]: '',
  [MESSAGE_FLAG_STARRED]: '⭐️',
  [MESSAGE_FLAG_NOTIFY_COMPLETE]: '', //'🔔',
  [MESSAGE_FLAG_VND_ANT_CACHE_AUTO]: '',
  [MESSAGE_FLAG_VND_ANT_CACHE_USER]: '',
};

export function messageUserFlagToEmoji(flag: DMessageUserFlag): string {
  return flag2EmojiMap[flag] ?? '❓';
}

export function messageHasUserFlag(message: Pick<DMessage, 'userFlags'>, flag: DMessageUserFlag): boolean {
  return message.userFlags?.includes(flag) ?? false;
}

export function messageSetUserFlag(message: Pick<DMessage, 'userFlags'>, flag: DMessageUserFlag, on: boolean): DMessageUserFlag[] {
  if (on) {
    if (message.userFlags?.includes(flag))
      return message.userFlags;
    return [...(message.userFlags || []), flag];
  } else {
    if (!message.userFlags?.includes(flag))
      return message.userFlags || [];
    return (message.userFlags || []).filter(_f => _f !== flag);
  }
}


// helpers during the transition from V3

export function messageFragmentsReduceText(fragments: DMessageFragment[], fragmentSeparator: string = '\n\n', excludeAttachmentFragments?: boolean): string {

  // quick path for empty fragments
  if (!fragments.length)
    return '';

  return fragments
    .map(fragment => {
      switch (true) {
        case isContentFragment(fragment):
          switch (fragment.part.pt) {
            case 'text':
              return fragment.part.text;
            case 'error':
              return fragment.part.error;
            case 'image_ref':
              return '';
            case 'tool_invocation':
            case 'tool_response':
              // Ignore tools for the text reduction
              return '';
          }
          break;
        case isAttachmentFragment(fragment):
          if (excludeAttachmentFragments)
            return '';
          switch (fragment.part.pt) {
            case 'doc':
              return fragment.part.data.text;
            case 'image_ref':
              return '';
          }
          break;
        case isVoidFragment(fragment):
          // all void fragments are ignored by definition when doing a text reduction
          return '';
      }
      console.warn(`[DEV] messageFragmentsReduceText: unexpected '${fragment.ft}' fragment with '${(fragment as any)?.part?.pt}' part`);
      return '';
    })
    .filter(text => !!text)
    .join(fragmentSeparator);
}



================================================
FILE: src/common/stores/chat/chat.tokens.ts
================================================
import type { DLLM } from '~/common/stores/llms/llms.types';
import { imageTokensForLLM } from '~/common/tokens/tokens.image';
import { textTokensForLLM } from '~/common/tokens/tokens.text';

import type { DMessageRole } from './chat.message';
import { DMessageAttachmentFragment, DMessageFragment, isAttachmentFragment, isContentFragment, isContentOrAttachmentFragment, isDocPart, isVoidFragment } from './chat.fragments';


export function estimateTokensForFragments(llm: DLLM, role: DMessageRole, fragments: DMessageFragment[], addTopGlue: boolean, debugFrom: string) {
  return fragments.reduce((acc, fragment) => {
    let fragmentTokens = _fragmentTokens(llm, role, fragment, debugFrom);
    if (acc > 0 || addTopGlue)
      fragmentTokens += _glueForFragmentTokens(llm);
    return acc + fragmentTokens;
  }, 0);
}


// Text

export function estimateTextTokens(text: string, llm: DLLM, debugFrom: string): number {
  return textTokensForLLM(text, llm, debugFrom) ?? 0;
}

function estimateImageTokens(width: number | undefined, height: number | undefined, debugTitle: string | undefined, llm: DLLM): number {
  return imageTokensForLLM(width, height, debugTitle, llm);
}


// Content Parts

function _fragmentTokens(llm: DLLM, role: DMessageRole, fragment: DMessageFragment, debugFrom: string): number {
  // non content/attachment fragments are ignored
  if (!isContentOrAttachmentFragment(fragment) || fragment.part.pt === '_pt_sentinel')
    return 0;

  // attachment fragments
  if (isAttachmentFragment(fragment)) {
    const aPart = fragment.part;
    switch (aPart.pt) {
      case 'doc':
        const likelyRendition = marshallWrapText(aPart.data.text, aPart.ref, 'markdown-code');
        return estimateTextTokens(likelyRendition, llm, debugFrom);
      case 'image_ref':
        // NOTE: should not happen with attachments, unless someone '/a' a message with an image attached
        const forcedSize = role === 'assistant' ? 512 : undefined;
        return estimateImageTokens(forcedSize || aPart.width, forcedSize || aPart.height, fragment.title, llm);
    }
  } else if (isContentFragment(fragment)) {
    const cPart = fragment.part;
    switch (cPart.pt) {
      case 'error':
        return estimateTextTokens(cPart.error, llm, debugFrom);
      case 'image_ref':
        const forcedSize = role === 'assistant' ? 512 : undefined;
        return estimateImageTokens(forcedSize || cPart.width, forcedSize || cPart.height, debugFrom, llm);
      case 'text':
        return estimateTextTokens(cPart.text, llm, debugFrom);
      case 'tool_invocation':
      case 'tool_response':
        console.warn('Unhandled token preview for content type:', cPart.pt);
        return 0;
    }
  } else if (isVoidFragment(fragment)) {
    // all void fragments are ignored by definition and never sent to the llm
    // NOTE: make sure you collapse/don't account for the containing message as well, if left empty
    return 0;
  } else {
    console.warn('Unhandled token preview for fragment type:', (fragment as any).ft);
    return 0;
  }
}


// Attachment Fragments

export type TextAttachmentWrapFormat = false | 'markdown-code';

/**
 * API Note: you should not use this function much, as it lowers the grade of higher level information
 */
export function marshallWrapText(text: string, blockTitle: string | undefined, wrapFormat: TextAttachmentWrapFormat): string {
  if (wrapFormat === 'markdown-code')
    return `\`\`\`${blockTitle || ''}\n${text}\n\`\`\``;
  return text;
}

/**
 * API Note: you should not use this function much, as it lowers the grade of higher level information
 */
export function marshallWrapDocFragments(initialText: string | null, fragments: (/*DMessageContentFragment |*/ DMessageAttachmentFragment)[], wrapFormat: TextAttachmentWrapFormat, separator: string): string {
  let inlinedText = initialText || '';
  for (const fragment of fragments) {
    // warn on non-text fragments, which are not handled - it's an API error to call this function to non-text-part fragments
    if (!isDocPart(fragment.part)) {
      console.warn('marshallWrapTextFragments: unhandled part type:', fragment.part.pt);
      continue;
    }

    if (inlinedText.length)
      inlinedText += separator;

    const docPart = fragment.part;
    inlinedText += marshallWrapText(docPart.data.text, docPart.ref, wrapFormat);
  }
  return inlinedText;
}


// Encoding Glue - TODO: implement these correctly and based off LLMs

function _glueForFragmentTokens(_llm: DLLM): number {
  return 4;
}

export function glueForMessageTokens(_llm: DLLM): number {
  return 4;
}


================================================
FILE: src/common/stores/chat/chats.converters.ts
================================================
import type { SystemPurposeId } from '../../../data';

import type { DFolder } from '~/common/stores/folders/store-chat-folders';
import type { LiveFileId } from '~/common/livefile/liveFile.types';
import { liveFileGetAllValidIDs } from '~/common/livefile/store-live-file';

import type { DModelsService } from '~/common/stores/llms/llms.service.types';

import { createDConversation, DConversation, type DConversationId } from './chat.conversation';
import { createDMessageTextContent, DMessage, MESSAGE_FLAG_NOTIFY_COMPLETE, messageSetUserFlag } from './chat.message';
import { createErrorContentFragment, isAttachmentFragment, isContentFragment, isContentOrAttachmentFragment, isDocPart, isPlaceholderPart, isTextContentFragment, isVoidFragment } from './chat.fragments';


// configuration
const EMERGENCY_CLEANUP_PARTS = false;


export namespace V4ToHeadConverters {

  export function inMemHeadCleanDConversations(cs: ReadonlyArray<DConversation>): void {
    const validLiveFileIDs = liveFileGetAllValidIDs();
    for (const c of cs)
      _inMemHeadCleanDConversation(c, validLiveFileIDs);
  }

  function _inMemHeadCleanDConversation(c: DConversation, validLiveFileIDs: LiveFileId[]): void {
    // re-add transient properties
    c._abortController = null;

    // fixup .messages[]
    if (!c.messages)
      c.messages = [];

    for (const message of c.messages)
      inMemHeadCleanDMessage(message, validLiveFileIDs);
  }


  /** Used by: chat-store (load), recreation of DMessage */
  export function inMemHeadCleanDMessage(m: DMessage, validLiveFileIDs: LiveFileId[]): void {

    // reset transient properties
    delete m.pendingIncomplete;

    // cleanup pre-v4 properties (if reimported somehow)
    delete (m as any).sender;
    delete (m as any).typing;

    // fixup .fragments[]
    for (let i = 0; i < m.fragments.length; i++) {
      const fragment = m.fragments[i];

      // [SANITIZE] If the fragment is damaged (e.g. null or missing the 'ft' property), remove it
      if (!fragment || !fragment.ft) {
        m.fragments.splice(i, 1);
        i--; // Adjust index since we modified the array
        continue;
      }

      // [GC][LiveFile] remove LiveFile references to invalid objects (also done in store-client-workspace)
      if (isAttachmentFragment(fragment) && fragment.liveFileId)
        if (!validLiveFileIDs.includes(fragment.liveFileId))
          delete fragment.liveFileId;

      // show the aborted ops: convert a Placeholder fragment [part.pt='ph'] to an Error fragment
      if ((isVoidFragment(fragment) && isPlaceholderPart(fragment.part))
        || (isContentFragment(fragment) && (fragment.part as any)?.pt === 'ph') /* NOTE: REMOVE FOR 2.0: helper during the 'void' fragment transition */)
        m.fragments[i] = createErrorContentFragment(`${(fragment.part as any).pText} (did not complete)`);

      // [Emergency] validate part types, can mess up in development
      if (EMERGENCY_CLEANUP_PARTS) {
        // If a text part has 'object' in place of 'string' for pText: remove the part altogether
        if (isTextContentFragment(fragment)) {
          // noinspection SuspiciousTypeOfGuard
          if (typeof fragment.part.text !== 'string') {
            // Remove this fragment
            m.fragments.splice(i, 1);
            i--; // Adjust index since we modified the array
            // noinspection UnnecessaryContinueJS
            continue;
          }
        }
      }

    }

    // remove notification flags
    m.userFlags = messageSetUserFlag(m, MESSAGE_FLAG_NOTIFY_COMPLETE, false);

    // run dev upgrades
    dev_inMemHeadUpgradeDMessage(m);

  }

  export function dev_inMemHeadUpgradeDMessage(m: DMessage): void {
    // TODO: remove insides for 2.0.0

    // uplevel fragments
    for (const fragment of m.fragments) {

      // Result of a rename of DMessageDocPart.type -> .vdt
      if (isContentOrAttachmentFragment(fragment) && isDocPart(fragment.part)) {
        const docPart = fragment.part as any;
        if ('type' in docPart && !('vdt' in docPart)) {
          docPart.vdt = docPart.type;
          delete docPart.type;
        }
      }
    }

    // uplevel metadata: if (metadata?.inReplyToText) cm.metadata = { inReferenceTo: [{ mrt: 'dmsg', mText: metadata.inReplyToText, mRole: 'assistant' }] };
    if (m.metadata && 'inReplyToText' in m.metadata && m.metadata.inReplyToText) {
      const replyToText = m.metadata.inReplyToText as string;
      delete m.metadata.inReplyToText;
      m.metadata.inReferenceTo = [{
        mrt: 'dmsg', mText: replyToText, mRole: 'assistant',
      }];
    }

    // uplevel generator (REMOVE FOR 2.0.0)
    if ('originLLM' in m && !m.generator) {
      m.generator = { 'mgt': 'named', name: m.originLLM as string };
      delete m.originLLM;
    }
  }

}


export namespace V3StoreDataToHead {

  /** Used by: chat-store.migrate() for direct data conversion to V4 from V3 */
  export function recreateConversations(ic: ImportConversationV3[]): DConversation[] {
    return (ic || []).map(recreateConversation);
  }

  /** Used by: ^, DataAtRestV1.recreateConversation */
  export function recreateConversation(ic: (
    | ImportConversationV3
    | DataAtRestV1.RestChatJsonV1 /* this is here because a chat at rest JsonV1 basically overlapped with V3 data */
    // | DConversation /* this is here because a V4 could have been exported too, and we want to force type overlaps */
    )): DConversation {
    const {
      id,
      userTitle, autoTitle,
      systemPurposeId,
      messages,
      updated,
      created,
    } = ic;

    const cc = createDConversation(systemPurposeId as SystemPurposeId);
    if (id) cc.id = id;
    cc.messages = messages.map(_recreateMessage);
    if (userTitle) cc.userTitle = userTitle;
    if (autoTitle) cc.autoTitle = autoTitle;
    if (created) cc.created = created;
    if (updated) cc.updated = updated;
    cc.tokenCount = ('tokenCount' in ic) ? ic.tokenCount || 0 : cc.tokenCount || 0;

    return cc;
  }

  function _recreateMessage(im: (ImportMessageV3 | DMessage)): DMessage {
    let cm: DMessage | undefined = _isDMessageV4(im) ? im : undefined;
    if (!cm) {
      const {
        id,
        text,
        role,
        purposeId,
        originLLM,
        metadata,
        userFlags,
        tokenCount,
        created,
        updated,
      } = im as ImportMessageV3;

      cm = createDMessageTextContent(role, text);
      if (id) cm.id = id;
      if (purposeId) cm.purposeId = purposeId;
      if (originLLM) cm.generator = { 'mgt': 'named', name: originLLM };
      if (metadata?.inReplyToText) {
        if (!cm.metadata) cm.metadata = {};
        cm.metadata.inReferenceTo = [{ mrt: 'dmsg', mText: metadata.inReplyToText, mRole: 'assistant' }];
      }
      if (userFlags) cm.userFlags = userFlags;
      cm.tokenCount = tokenCount || 0;
      if (created) cm.created = created;
      if (updated) cm.updated = updated;

    }
    V4ToHeadConverters.inMemHeadCleanDMessage(cm, liveFileGetAllValidIDs());
    return cm;
  }


  /// Types before the May 2024 Multi-Part refactor. ///

  type ImportConversationV3 = {
    id: string;
    messages: ImportMessageV3[];
    systemPurposeId: string;
    userTitle?: string;
    autoTitle?: string;
    tokenCount: number;
    created: number;
    updated: number | null;
  }

  export type ImportMessageV3 = {
    id: string;
    text: string;                     // big 'tell' that this is a V3 message
    // sender: 'You' | 'Bot' | string;   // (ignored in conversion) pretty name
    // avatar: string | null;            // (ignored in conversion) null, or image url
    // typing: boolean;                  // (ignored in conversion)
    role: 'assistant' | 'system' | 'user';

    purposeId?: string;               // only assistant/system
    originLLM?: string;               // only assistant - model that generated this message, goes beyond known models

    metadata?: {                      // metadata, mainly at creation and for UI
      inReplyToText?: string;         // V3: text this was in reply to
    };
    userFlags?: ('starred')[];        // (UI) user-set per-message flags

    tokenCount: number;               // cache for token count, using the current Conversation model (0 = not yet calculated)

    created: number;                  // created timestamp
    updated: number | null;           // updated timestamp
  }

  function _isDMessageV4(message: DMessage | ImportMessageV3): message is DMessage {
    return 'fragments' in message && Array.isArray(message.fragments);
  }

}


export namespace DataAtRestV1 {


  /// Rest V1 -> Head ///

  /** Used by: AppLinkChat.fetchStoredChatV1, trade_client.loadSingleChatFromAtRestV1 */
  export function recreateConversation(chatJV1: RestChatJsonV1 & { tokenCount?: number }): DConversation | null {

    // sanity check
    if (!chatJV1 || !chatJV1.id || !chatJV1.messages) {
      console.warn('createDConversationFromJsonV1: invalid conversation json', chatJV1);
      return null;
    }

    // RestChatJsonV1 could be EITHER a V3 or V4/Head message - uncomment below to see little difference
    // const sentinel1: RestChatJsonV1 = {} as DConversation;
    // const sentinel1: DConversation = {} as RestChatJsonV1;
    // TODO: probably better to fork off the saving already, so imports are only V3's

    // heuristic to find out if we're dealing with a V3 or V4 message
    // const v3Count = chatJV1.messages.filter((m) => 'text' in m).length;
    // const v4Count = chatJV1.messages.filter((m) => 'fragments' in m).length;
    // if (v3Count > v4Count) {
    //   we are dealing with a V3 message
    //  ...
    // }

    return V3StoreDataToHead.recreateConversation(chatJV1);
  }

  /** Used by: trade_client.loadConversationsFromAtRestV1 */
  export function recreateFolders(part: RestFolderJsonV1[]): DFolder[] {
    return (part || []).map(_recreateFolder).filter((f) => f) as DFolder[];
  }

  function _recreateFolder(part: RestFolderJsonV1): DFolder | null {

    // sanity check
    if (!part || !part.id || !part.title || !part.conversationIds) {
      console.warn('createFolderFromJsonV1: invalid folder json', part);
      return null;
    }

    return {
      id: part.id,
      title: part.title,
      conversationIds: part.conversationIds,
      color: part.color,
    };
  }


  /// Head -> Rest V1 ///

  /** Used by: downloadAllJsonV1B */
  export function formatAllToJsonV1B(conversations: DConversation[], modelSources: DModelsService[], folders: DFolder[], enableFolders: boolean): RestAllJsonV1B {
    return {
      conversations: (conversations || []).map(formatChatToJsonV1),
      models: { sources: modelSources },
      folders: { folders, enableFolders },
    };
  }

  /** Used by: ^, downloadSingleChat, ChatLinkExport.handleCreate */
  export function formatChatToJsonV1(ec: DConversation): RestChatJsonV1 {
    return {
      id: ec.id,
      messages: ec.messages,
      systemPurposeId: ec.systemPurposeId,
      userTitle: ec.userTitle,
      autoTitle: ec.autoTitle,
      created: ec.created,
      updated: ec.updated,
    };
  }


  /// STORED TYPES definitions ///
  /// do not change(!) these - consider people's backups and stored data

  export type RestAllJsonV1B = {
    conversations: RestChatJsonV1[];
    models: { sources: DModelsService[] };
    folders?: { folders: RestFolderJsonV1[]; enableFolders: boolean };
  }

  export type RestChatJsonV1 = {
    id: string;
    messages: (DMessage | V3StoreDataToHead.ImportMessageV3)[];
    systemPurposeId: string;
    userTitle?: string;
    autoTitle?: string;
    created: number;
    updated: number | null;
  }

  type RestFolderJsonV1 = {
    id: string;
    title: string;
    conversationIds: DConversationId[];
    color?: string; // Optional color property
  }

}



================================================
FILE: src/common/stores/chat/store-chats.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import { useShallow } from 'zustand/react/shallow';

import type { SystemPurposeId } from '../../../data';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { findLLMOrThrow, getChatLLMId } from '~/common/stores/llms/store-llms';

import { agiUuid } from '~/common/util/idUtils';
import { backupIdbV3, createIDBPersistStorage } from '~/common/util/idbUtils';

import { workspaceActions } from '~/common/stores/workspace/store-client-workspace';
import { workspaceForConversationIdentity } from '~/common/stores/workspace/workspace.types';

import { DMessage, DMessageId, DMessageMetadata, MESSAGE_FLAG_AIX_SKIP, messageHasUserFlag } from './chat.message';
import { DMessageFragment, DMessageFragmentId, isVoidThinkingFragment } from './chat.fragments';
import { V3StoreDataToHead, V4ToHeadConverters } from './chats.converters';
import { conversationTitle, createDConversation, DConversation, DConversationId, duplicateDConversation } from './chat.conversation';
import { estimateTokensForFragments } from './chat.tokens';
import { gcChatImageAssets } from '~/common/stores/chat/chat.gc';


/// Conversations Store

interface ChatState {
  conversations: DConversation[];
}

export interface ChatActions {

  // CRUD conversations
  prependNewConversation: (personaId: SystemPurposeId | undefined, isIncognito: boolean) => DConversationId;
  importConversation: (c: DConversation, preventClash: boolean) => DConversationId;
  branchConversation: (cId: DConversationId, mId: DMessageId | null) => DConversationId | null;
  deleteConversations: (cIds: DConversationId[], newConversationPersonaId?: SystemPurposeId) => DConversationId;

  // within a conversation
  isIncognito: (cId: DConversationId) => boolean | undefined;
  setAbortController: (cId: DConversationId, _abortController: AbortController | null, debugScope: string) => void;
  abortConversationTemp: (cId: DConversationId) => void;
  historyReplace: (cId: DConversationId, messages: DMessage[]) => void;
  historyTruncateToIncluded: (cId: DConversationId, mId: DMessageId, offset: number) => void;
  historyKeepLastThinkingOnly: (cId: DConversationId) => void;
  historyView: (cId: DConversationId) => Readonly<DMessage[]> | undefined;
  appendMessage: (cId: DConversationId, message: DMessage) => void;
  deleteMessage: (cId: DConversationId, mId: DMessageId) => void;
  editMessage: (cId: DConversationId, mId: DMessageId, update: Partial<DMessage> | ((message: DMessage) => Partial<DMessage>), removePendingState: boolean, touchUpdated: boolean) => void;
  appendMessageFragment: (cId: DConversationId, mId: DMessageId, fragment: DMessageFragment, removePendingState: boolean, touchUpdated: boolean) => void;
  deleteMessageFragment: (cId: DConversationId, mId: DMessageId, fId: DMessageFragmentId, removePendingState: boolean, touchUpdated: boolean) => void;
  replaceMessageFragment: (cId: DConversationId, mId: DMessageId, fId: DMessageFragmentId, newFragment: DMessageFragment, removePendingState: boolean, touchUpdated: boolean) => void;
  updateMetadata: (cId: DConversationId, mId: DMessageId, metadataDelta: Partial<DMessageMetadata>, touchUpdated?: boolean) => void;
  setSystemPurposeId: (cId: DConversationId, personaId: SystemPurposeId) => void;
  setAutoTitle: (cId: DConversationId, autoTitle: string) => void;
  setUserTitle: (cId: DConversationId, userTitle: string) => void;
  setUserSymbol: (cId: DConversationId, userSymbol: string | null) => void;
  setArchived: (cId: DConversationId, isArchived: boolean) => void;
  title: (cId: DConversationId) => string | undefined;

  // utility function
  _editConversation: (cId: DConversationId, update: Partial<DConversation> | ((conversation: DConversation) => Partial<DConversation>)) => void;
}

type ConversationsStore = ChatState & ChatActions;

const defaultConversations: DConversation[] = [createDConversation()];

export const useChatStore = create<ConversationsStore>()(/*devtools(*/
  persist(
    (_set, _get) => ({

      // default state
      conversations: defaultConversations,

      prependNewConversation: (personaId: SystemPurposeId | undefined, isIncognito: boolean): DConversationId => {
        const newConversation = createDConversation(personaId);
        if (isIncognito) newConversation._isIncognito = true;

        _set(state => ({
          conversations: [newConversation, ...state.conversations],
        }));

        // [workspace] import messages' LiveFiles
        workspaceActions().importAssignmentsFromMessages(workspaceForConversationIdentity(newConversation.id), newConversation.messages);

        return newConversation.id;
      },

      /** Used by:
       * - openAndLoadConversations (via DataAtRestV1.recreateConversation),
       * - LinkChatViewer(from RestV1),
       * - ImportChats.handleChatGptLoad(H)
       */
      importConversation: (conversation: DConversation, preventClash: boolean): DConversationId => {
        const { conversations } = _get();

        // if there's a clash, abort the former conversation, and optionally change the ID
        const existing = conversations.find(_c => _c.id === conversation.id);
        if (existing) {
          existing?._abortController?.abort();
          if (preventClash) {
            conversation.id = agiUuid('chat-dconversation');
            console.warn('Conversation ID clash, changing ID to', conversation.id);
          }
        }

        // every path that leads here should have an equivalent function ran, however, for extra
        // caution, we sanitize and re-run this here, to upgrade the message to the current version
        V4ToHeadConverters.inMemHeadCleanDConversations([conversation]);

        conversation.tokenCount = updateMessagesTokenCounts(conversation.messages, true, 'importConversation');

        _set({
          conversations: [conversation, ...conversations.filter(_c => _c.id !== conversation.id)],
        });

        // [workspace] import messages' LiveFiles
        workspaceActions().importAssignmentsFromMessages(workspaceForConversationIdentity(conversation.id), conversation.messages);

        return conversation.id;
      },

      branchConversation: (conversationId: DConversationId, messageId: DMessageId | null): DConversationId | null => {
        const { conversations } = _get();
        const conversation = conversations.find(_c => _c.id === conversationId);
        if (!conversation)
          return null;

        const branched = duplicateDConversation(conversation, messageId ?? undefined, false);

        _set({
          conversations: [branched, ...conversations],
        });

        // [workspace] assign all files of workspace1 to workspace2 (HACK until we have workspaces != conversations)
        workspaceActions().copyAssignments(workspaceForConversationIdentity(conversation.id), workspaceForConversationIdentity(branched.id));

        return branched.id;
      },

      deleteConversations: (conversationIds: DConversationId[], newConversationPersonaId?: SystemPurposeId): DConversationId => {
        const { conversations } = _get();

        // find the index of first conversation to delete
        const cIndex = conversationIds.length > 0 ? conversations.findIndex(_c => _c.id === conversationIds[0]) : -1;

        // abort all pending requests
        conversationIds.forEach(conversationId => conversations.find(_c => _c.id === conversationId)?._abortController?.abort());

        // remove from the list
        const newConversations = conversations.filter(_c => !conversationIds.includes(_c.id));

        // create a new conversation if there are no more
        if (!newConversations.length)
          newConversations.push(createDConversation(newConversationPersonaId));

        _set({
          conversations: newConversations,
        });

        // [workspace] since conversation=workspace for now, remove all workspaces too
        conversationIds.forEach(conversationId => workspaceActions().remove(workspaceForConversationIdentity(conversationId)));

        // return the next conversation Id in line, if valid
        return newConversations[(cIndex >= 0 && cIndex < newConversations.length) ? cIndex : 0].id;
      },


      // within a conversation

      _editConversation: (conversationId: DConversationId, update: Partial<DConversation> | ((conversation: DConversation) => Partial<DConversation>)) =>
        _set(state => ({
          conversations: state.conversations.map((conversation): DConversation =>
            conversation.id === conversationId
              ? {
                ...conversation,
                ...(typeof update === 'function' ? update(conversation) : update),
              }
              : conversation,
          ),
        })),

      isIncognito: (conversationId: DConversationId): boolean | undefined =>
        _get().conversations.find(_c => _c.id === conversationId)?._isIncognito ?? undefined,

      setAbortController: (conversationId: DConversationId, _nextController: AbortController | null, debugScope: string) =>
        _get()._editConversation(conversationId, ({ _abortController: _currentController }) => {
          // [DEV] Debug state management of controllers - FIXME: migrate away from a per-chat, unless done properly (cascade triggering)
          if (_nextController !== null && _currentController) {
            const isAlreadyAborted = _currentController.signal.aborted;
            if (process.env.NODE_ENV === 'development')
              console.warn(`[DEV] setAbortController (${debugScope}): race condition (${isAlreadyAborted ? 'Already aborted' : 'Not aborted'}) for conversation ${conversationId}`);
            if (!isAlreadyAborted)
              _currentController.abort();
          }
          return {
            _abortController: _nextController,
          };
        }),

      abortConversationTemp: (conversationId: DConversationId) =>
        _get()._editConversation(conversationId, conversation => {
          conversation._abortController?.abort();
          return {
            _abortController: null,
          };
        }),


      historyReplace: (conversationId: DConversationId, newMessages: DMessage[]) =>
        _get()._editConversation(conversationId, conversation => {
          conversation._abortController?.abort();

          // [workspace]
          // Note: not doing it for now, as all the callers' flows do not contain different LiveFiles,
          // however, in general, we should act on the messages being replaced!

          return {
            messages: newMessages,
            ...(!!newMessages.length ? {} : {
              autoTitle: undefined,
            }),
            tokenCount: updateMessagesTokenCounts(newMessages, false, 'historyReplace'),
            updated: Date.now(),
            _abortController: null,
          };
        }),

      historyTruncateToIncluded: (conversationId: DConversationId, messageId: DMessageId, offset: number) =>
        _get()._editConversation(conversationId, conversation => {
          const messageIndex = conversation.messages.findIndex(m => m.id === messageId);
          if (messageIndex < 0 || messageIndex + 1 + offset >= conversation.messages.length)
            return {};

          conversation._abortController?.abort();

          const truncatedMessages = conversation.messages.slice(0, Math.max(0, messageIndex + 1 + offset));

          // [workspace]
          // Note: simple chat truncation does not side-effect workspaces

          return {
            messages: truncatedMessages,
            tokenCount: updateMessagesTokenCounts(truncatedMessages, false, 'historyTruncateToIncluded'),
            updated: Date.now(),
            _abortController: null,
          };
        }),

      historyKeepLastThinkingOnly: (conversationId: DConversationId) =>
        _get()._editConversation(conversationId, ({ messages: _currentMessages }) => {
          let madeChanges = false;
          const updatedMessages = [..._currentMessages];
          let foundLastAssistant = false;

          // reverse iterate
          for (let i = updatedMessages.length - 1; i >= 0; i--) {
            const message = updatedMessages[i];

            // skip non-assistant messages
            if (message.role !== 'assistant') continue;

            // skip the last assistant message
            if (!foundLastAssistant) {
              foundLastAssistant = true;
              continue;
            }

            // skip if doesn't have thinking blocks
            const hasThinkingBlocks = message.fragments.some(isVoidThinkingFragment);
            if (!hasThinkingBlocks) continue;

            // Filter out thinking blocks
            updatedMessages[i] = {
              ...message,
              fragments: message.fragments.filter(fragment => !isVoidThinkingFragment(fragment)),
            };
            madeChanges = true;
          }

          if (!madeChanges) return {};

          return {
            messages: updatedMessages,
            // No need to update the following as void fragments don't contribute
            // tokenCount: updateMessagesTokenCounts(updatedMessages, true, 'historyKeepLastThinkingOnly'),
            // updated: Date.now(),
          };
        }),

      historyView: (conversationId: DConversationId): Readonly<DMessage[]> | undefined =>
        _get().conversations.find(_c => _c.id === conversationId)?.messages ?? undefined,


      appendMessage: (conversationId: DConversationId, message: DMessage) =>
        _get()._editConversation(conversationId, conversation => {

          // [workspace] import message's resources into the workspace
          workspaceActions().importAssignmentsFromMessages(workspaceForConversationIdentity(conversationId), [message]);

          if (!message.pendingIncomplete)
            updateMessagesTokenCounts([message], true, 'appendMessage');

          const messages = [...conversation.messages, message];

          return {
            messages,
            tokenCount: messages.reduce((sum, message) => sum + 4 + message.tokenCount || 0, 3),
            updated: Date.now(),
          };
        }),

      deleteMessage: (conversationId: DConversationId, messageId: DMessageId) =>
        _get()._editConversation(conversationId, conversation => {

          const messages = conversation.messages.filter(message => message.id !== messageId);

          // [workspace]
          // Note: simple deletion of a message does not side-effect workspaces

          return {
            messages,
            tokenCount: messages.reduce((sum, message) => sum + 4 + message.tokenCount || 0, 3),
            updated: Date.now(),
          };
        }),

      editMessage: (conversationId: DConversationId, messageId: DMessageId, update: Partial<DMessage> | ((message: DMessage) => Partial<DMessage>), removePendingState: boolean, touchUpdated: boolean) =>
        _get()._editConversation(conversationId, conversation => {

          const messages = conversation.messages.map((message): DMessage => {
            if (message.id !== messageId)
              return message;

            const updatedMessage: DMessage = {
              ...message,
              ...(typeof update === 'function' ? update(message) : update),
              ...(touchUpdated && { updated: Date.now() }),
            };

            if (removePendingState)
              delete updatedMessage.pendingIncomplete;

            if (!updatedMessage.pendingIncomplete)
              updateMessageTokenCount(updatedMessage, getChatLLMId(), true, 'editMessage(incomplete=false)');

            return updatedMessage;
          });

          // [workspaces]
          // NOTE: we assume that no workspace side-effect-producing change is performed

          return {
            messages,
            tokenCount: messages.reduce((sum, message) => sum + 4 + message.tokenCount || 0, 3),
            updated: touchUpdated ? Date.now() : conversation.updated,
          };
        }),


      appendMessageFragment: (conversationId: DConversationId, messageId: DMessageId, fragment: DMessageFragment, removePendingState: boolean, touchUpdated: boolean) => {
        _get().editMessage(conversationId, messageId, message => ({
          fragments: [...message.fragments, fragment],
        }), removePendingState, touchUpdated);

        // [workspace]
        // Note: in the future when we have side-effect appends (e.g. new Attachment/Docs/Etc) we may
        // need implementation of the fragment methods here
      },

      deleteMessageFragment: (conversationId: DConversationId, messageId: DMessageId, fragmentId: DMessageFragmentId, removePendingState: boolean, touchUpdated: boolean) =>
        _get().editMessage(conversationId, messageId, message => ({
          fragments: message.fragments.filter(f => f.fId !== fragmentId),
        }), removePendingState, touchUpdated),

      replaceMessageFragment: (conversationId: DConversationId, messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment, removePendingState: boolean, touchUpdated: boolean) =>
        _get().editMessage(conversationId, messageId, message => {

          // Warn if the fragment is not found
          const fragmentIndex = message.fragments.findIndex(f => f.fId === fragmentId);
          if (fragmentIndex < 0) {
            console.error(`replaceFragment: fragment not found for ID ${fragmentId}`);
            return {};
          }

          // Replace the fragment
          return {
            fragments: message.fragments.map((fragment, index) =>
              (index === fragmentIndex)
                ? { ...newFragment } // force the object tree to change, just in case the contents changed but not the object reference
                : fragment,
            ),
          };
        }, removePendingState, touchUpdated),

      updateMetadata: (conversationId: DConversationId, messageId: DMessageId, metadataDelta: Partial<DMessageMetadata>, touchUpdated: boolean = true) => {
        _get()._editConversation(conversationId, conversation => {
          const messages = conversation.messages.map(message =>
            message.id !== messageId ? message
              : {
                ...message,
                metadata: {
                  ...message.metadata,
                  ...metadataDelta,
                },
                updated: touchUpdated ? Date.now() : message.updated,
              },
          );

          return {
            messages,
            updated: touchUpdated ? Date.now() : conversation.updated,
          };
        });
      },

      setSystemPurposeId: (conversationId: DConversationId, personaId: SystemPurposeId) =>
        _get()._editConversation(conversationId,
          {
            systemPurposeId: personaId,
          }),

      setAutoTitle: (conversationId: DConversationId, autoTitle: string) =>
        _get()._editConversation(conversationId,
          {
            autoTitle,
          }),

      setUserTitle: (conversationId: DConversationId, userTitle: string) =>
        _get()._editConversation(conversationId,
          {
            userTitle,
            ...(!userTitle && { autoTitle: undefined }), // clear autotitle when clearing usertitle
          }),

      title: (conversationId: DConversationId): string | undefined => {
        const existing = _get().conversations.find(_c => _c.id === conversationId);
        return existing ? conversationTitle(existing) : undefined;
      },

      setUserSymbol: (conversationId: DConversationId, userSymbol: string | null) =>
        _get()._editConversation(conversationId,
          {
            userSymbol: userSymbol || undefined,
          }),

      setArchived: (conversationId: DConversationId, isArchived: boolean) =>
        _get()._editConversation(conversationId,
          {
            isArchived: isArchived,
            // updated: Date.now(), // don't update this - the 'entity state' shall update, but not this soft time
          }),

    }),
    {
      name: 'app-chats',
      /* Version history:
       *  - 1: [2023-03-18] App launch, single chat
       *  - 2: [2023-04-10] Multi-chat version - invalidating data to be sure
       *  - 3: [2023-09-19] Switch to IndexedDB - no data shape change,
       *                    but we swapped the backend (localStorage -> IndexedDB)
       *  - 4: [2024-05-14] Convert messages to multi-part, removed the IDB migration
       */
      version: 4,
      storage: createIDBPersistStorage<ConversationsStore>(),

      // Migrations
      migrate: async (state: any, fromVersion: number) => {

        // 3 -> 4: Convert messages to multi-part
        if (fromVersion < 4 && state && state.conversations && state.conversations.length) {

          if (await backupIdbV3('app-chats', 'app-chats-v3'))
            console.warn('Migrated app-chats from v3 to v4');

          state.conversations = V3StoreDataToHead.recreateConversations(state.conversations);
        }

        return state;
      },

      /**
       * Note: default impl:
       *   merge: (persistedState: unknown, currentState: S) => ({
       *     ...currentState,
       *     ...(persistedState as object),
       *   }),
       */
      merge: (persistedState, currentState: ConversationsStore): ConversationsStore => {

        // concatenate-merge conversations reloaded from storage
        const mergedConversations = [...(currentState?.conversations || [])];
        if (persistedState && typeof persistedState === 'object' && 'conversations' in persistedState) {
          const storedConversations = persistedState.conversations as ChatState['conversations'];
          if (storedConversations.length)
            mergedConversations.push(...storedConversations);
        }

        return {
          // default shallow merge
          ...currentState,
          ...(persistedState as object),
          // ad-hoc concat merge
          conversations: mergedConversations,
        };
      },

      // Pre-Saving: remove transient properties
      partialize: (state) => ({
        ...state,
        conversations: state.conversations
          .filter((c, _ignoreIdx, all) => {
            // do not save incognito conversations
            if (c._isIncognito) return false;
            // do not save empty conversations, begin saving them when they have content
            return c.messages?.length || c.userTitle || c.autoTitle || all.length <= 1;
          })
          .map((conversation: DConversation) => {
            // remove the converation AbortController (current data structure version)
            const { _abortController, ...rest } = conversation;
            return rest;
          }),
      }),

      // Post-Loading: re-add transient properties and cleanup state
      onRehydrateStorage: () => (state) => {
        if (!state) return;

        // fixup conversations in-memory
        V4ToHeadConverters.inMemHeadCleanDConversations(state.conversations || []);

        // [GC] Chat Image Assets
        // NOTE: this used to be in 'sherpa', but that caused the storage to be read too early, so we do it here post hydration
        //       and synchronously, as it's a rather quick operation (most of the times there won't be any effect).
        void gcChatImageAssets(state.conversations);

      },

    }),
  /*{ name: 'AppChats', enabled: false }), */
);


// Convenience function to update a set of messages, using the current chatLLM
function updateMessagesTokenCounts(messages: DMessage[], forceUpdate: boolean, debugFrom: string): number {
  const chatLLMId = getChatLLMId();
  return 3 + messages.reduce((sum, message) => {
    return 4 + updateMessageTokenCount(message, chatLLMId, forceUpdate, debugFrom) + sum;
  }, 0);
}

// Convenience function to count the tokens in a DMessage object
function updateMessageTokenCount(message: DMessage, llmId: DLLMId | null, forceUpdate: boolean, debugFrom: string): number {
  if (forceUpdate || !message.tokenCount) {
    // if flagged as skip, do not include this message in the count
    if (messageHasUserFlag(message, MESSAGE_FLAG_AIX_SKIP)) {
      message.tokenCount = 0;
      return 0;
    }

    // if there's no LLM, we can't count tokens
    if (!llmId) {
      message.tokenCount = 0;
      return 0;
    }

    // find the LLM from the ID
    try {
      const dllm = findLLMOrThrow(llmId);
      message.tokenCount = estimateTokensForFragments(dllm, message.role, message.fragments, false, debugFrom);
    } catch (e) {
      console.error(`updateMessageTokenCount: LLM not found for ID ${llmId}`);
      message.tokenCount = 0;
    }
  }
  return message.tokenCount;
}


export function isValidConversation(conversationId?: DConversationId | null): conversationId is DConversationId {
  return !!conversationId && getConversation(conversationId) !== null;
}

export function getConversation(conversationId: DConversationId | null): DConversation | null {
  return conversationId ? useChatStore.getState().conversations.find(_c => _c.id === conversationId) ?? null : null;
}

export function getConversationSystemPurposeId(conversationId: DConversationId | null): SystemPurposeId | null {
  return getConversation(conversationId)?.systemPurposeId || null;
}


export const useConversation = (conversationId: DConversationId | null) => useChatStore(useShallow(state => {
  const { conversations } = state;

  // this object will change if any sub-prop changes as well
  const conversation = conversationId ? conversations.find(_c => _c.id === conversationId) ?? null : null;
  const title = conversation ? conversationTitle(conversation) : null;
  const isEmpty = conversation ? !conversation.messages.length : true;
  const isDeveloper = conversation?.systemPurposeId === 'Developer';
  const conversationIdx = conversation ? conversations.findIndex(_c => _c.id === conversation.id) : -1;

  const hasConversations = conversations.length > 1 || (conversations.length === 1 && !!conversations[0].messages.length);
  const recycleNewConversationId = (conversations.length && !conversations[0].messages.length) ? conversations[0].id : null;

  return {
    title,
    isEmpty,
    isDeveloper,
    conversationIdx,
    hasConversations,
    recycleNewConversationId,
    prependNewConversation: state.prependNewConversation,
    branchConversation: state.branchConversation,
    deleteConversations: state.deleteConversations,
  };
}));



================================================
FILE: src/common/stores/chat/hooks/useChatsCount.ts
================================================
import { useChatStore } from '../store-chats';


export function useChatsCount() {
  return useChatStore(({ conversations }) => conversations.length);
}


================================================
FILE: src/common/stores/chat/hooks/useConversationTitle.ts
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { conversationTitle, DConversationId } from '../chat.conversation';
import { useChatStore } from '../store-chats';


export function useConversationTitle(conversationId: DConversationId | null, fallbackTitle?: string) {

  // react to the title
  const { title, setUserTitle: storeSetUserTitle } = useChatStore(useShallow(({ conversations, setUserTitle }) => {
    const conversation = conversationId ? conversations.find(_c => _c.id === conversationId) : null;
    return {
      title: conversation ? conversationTitle(conversation, fallbackTitle) : null,
      setUserTitle,
    };
  }));

  // closure to set the title
  const setUserTitle = React.useCallback((newTitle: string) => {
    conversationId && storeSetUserTitle(conversationId, newTitle);
  }, [conversationId, storeSetUserTitle]);

  return { title, setUserTitle };
}



================================================
FILE: src/common/stores/chat/hooks/useFragmentBuckets.ts
================================================
import * as React from 'react';

import { shallowEquals } from '~/common/util/hooks/useShallowObject';

import { DMessageAttachmentFragment, DMessageContentFragment, DMessageFragment, DMessageVoidFragment, isAttachmentFragment, isContentFragment, isImageRefPart, isVoidFragment } from '../chat.fragments';


interface FragmentBuckets {
  voidFragments: DMessageVoidFragment[];
  contentFragments: DMessageContentFragment[];
  imageAttachments: DMessageAttachmentFragment[];
  nonImageAttachments: DMessageAttachmentFragment[];
}

/**
 * Split Fragments into renderable groups, while only recalculating when the input changes, and when content really changes
 */
export function useFragmentBuckets(messageFragments: DMessageFragment[]): FragmentBuckets {

  // Refs to store the last stable value for each bucket
  const voidFragmentsRef = React.useRef<DMessageVoidFragment[]>([]);
  const contentFragmentsRef = React.useRef<DMessageContentFragment[]>([]);
  const imageAttachmentsRef = React.useRef<DMessageAttachmentFragment[]>([]);
  const nonImageAttachmentsRef = React.useRef<DMessageAttachmentFragment[]>([]);

  // Use useMemo to recalculate buckets only when messageFragments changes
  return React.useMemo(() => {

    const voidFragments: DMessageVoidFragment[] = [];
    const contentFragments: DMessageContentFragment[] = [];
    const imageAttachments: DMessageAttachmentFragment[] = [];
    const nonImageAttachments: DMessageAttachmentFragment[] = [];

    messageFragments.forEach(fragment => {
      if (isContentFragment(fragment))
        contentFragments.push(fragment);
      else if (isAttachmentFragment(fragment)) {
        if (isImageRefPart(fragment.part))
          imageAttachments.push(fragment);
        else
          nonImageAttachments.push(fragment);
      } else if (isVoidFragment(fragment)) {
        voidFragments.push(fragment);
      } else
        console.warn('[DEV] Unexpected fragment type:', { fragment });
    });

    // For each bucket, return the new value if it's different, otherwise return the stable ref
    if (!shallowEquals(voidFragments, voidFragmentsRef.current))
      voidFragmentsRef.current = voidFragments;

    if (!shallowEquals(contentFragments, contentFragmentsRef.current))
      contentFragmentsRef.current = contentFragments;

    if (!shallowEquals(imageAttachments, imageAttachmentsRef.current))
      imageAttachmentsRef.current = imageAttachments;

    if (!shallowEquals(nonImageAttachments, nonImageAttachmentsRef.current))
      nonImageAttachmentsRef.current = nonImageAttachments;

    return {
      voidFragments: voidFragmentsRef.current,
      contentFragments: contentFragmentsRef.current,
      imageAttachments: imageAttachmentsRef.current,
      nonImageAttachments: nonImageAttachmentsRef.current,
    };
  }, [messageFragments]);
}


================================================
FILE: src/common/stores/folders/store-chat-folders.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { agiUuid } from '~/common/util/idUtils';


export interface DFolder {
  id: string;
  title: string;
  conversationIds: DConversationId[];
  color?: string; // Optional color property
}

interface FolderState {
  folders: DFolder[];
  enableFolders: boolean; // user setting - default to off until we get enough feedback
}

interface FolderActions {
  importFoldersAppend: (folders: DFolder[], enableFolders: boolean) => void;
  createFolder: (title: string, color?: string) => void;
  deleteFolder: (folderId: string) => void;
  moveFolder: (fromIndex: number, toIndex: number) => void;
  setFolderName: (folderId: string, title: string) => void;
  setFolderColor: (folderId: string, color: string) => void;
  addConversationToFolder: (folderId: string, conversationId: DConversationId) => void;
  removeConversationFromFolder: (folderId: string, conversationId: DConversationId) => void;
  toggleEnableFolders: () => void;
}

type FolderStore = FolderState & FolderActions;

export const useFolderStore = create<FolderStore>()(/*devtools(*/
  persist(
    (set, _get) => ({

      // Initial state
      folders: [],
      enableFolders: false,

      // Actions
      importFoldersAppend: (folders: DFolder[], enableFolders: boolean) =>
        set(state => ({
          folders: [
            ...state.folders.filter(f => !folders.find(f2 => f2.id === f.id)),
            ...folders,
          ],
          enableFolders: enableFolders || state.enableFolders,
        })),

      createFolder: (title: string, color?: string) => {
        const newFolder: DFolder = {
          id: agiUuid('chat-folders-item'),
          title,
          conversationIds: [],
          color,
        };

        set(state => ({
          folders: [...state.folders, newFolder],
        }));
      },

      deleteFolder: (folderId: string): void =>
        set(state => ({
          folders: state.folders.filter(folder => folder.id !== folderId),
        })),

      moveFolder: (fromIndex: number, toIndex: number): void =>
        set(state => {
          const newFolders = [...state.folders];
          const [movedFolder] = newFolders.splice(fromIndex, 1);
          newFolders.splice(toIndex, 0, movedFolder);
          return { folders: newFolders };
        }),

      setFolderName: (folderId: string, title: string): void =>
        set(state => ({
          folders: state.folders.map(folder =>
            folder.id === folderId
              ? { ...folder, title }
              : folder,
          ),
        })),

      setFolderColor: (folderId: string, color: string): void =>
        set(state => ({
          folders: state.folders.map(folder =>
            folder.id === folderId
              ? { ...folder, color }
              : folder,
          ),
        })),

      addConversationToFolder: (folderId: string, conversationId: string) =>
        set(state => {
          const folders = state.folders.map(folder => {
            // Check if this is the correct folder and if the conversationId is not already present
            if (folder.id === folderId && !folder.conversationIds.includes(conversationId)) {
              // Use the spread operator to create a new array with the conversationId added
              return { ...folder, conversationIds: [...folder.conversationIds, conversationId] };
            }
            return folder;
          });
          return { folders };
        }),

      removeConversationFromFolder: (folderId: string, conversationId: DConversationId): void =>
        set(state => ({
          folders: state.folders.map(folder =>
            folder.id === folderId
              ? { ...folder, conversationIds: folder.conversationIds.filter(id => id !== conversationId) }
              : folder,
          ),
        })),

      toggleEnableFolders: () => set(state => ({
        enableFolders: !state.enableFolders,
      })),

    }),
    {
      name: 'app-folders',
    },
  ),
);


export const FOLDERS_COLOR_PALETTE = [
  '#828282',
  '#f22a85',
  '#f13d41',
  '#cb6701',
  '#42940f',
  '#068fa6',
  '#407cf8',

  '#626262',
  '#b91e64',
  '#b72e30',
  '#9b4d01',
  '#2f7007',
  '#076c7e',
  '#1c5dc8',

  '#474747',
  '#8c0f49',
  '#891e20',
  '#713804',
  '#1f5200',
  '#004f5d',
  '#1d4294',
];

export function getRotatingFolderColor(): string {
  const randomIndex = Math.floor(Math.random() * (FOLDERS_COLOR_PALETTE.length / 3));
  return FOLDERS_COLOR_PALETTE[randomIndex];
}


================================================
FILE: src/common/stores/llms/llms.hooks.ts
================================================
import { useShallow } from 'zustand/react/shallow';

import type { DLLM, DLLMId } from './llms.types';
import type { DModelsServiceId } from './llms.service.types';
import { useModelsStore } from './store-llms';


export function useLLM(llmId: undefined | DLLMId | null): DLLM | undefined {
  return useModelsStore(state => !llmId ? undefined : state.llms.find(llm => llm.id === llmId));
}

export function useLLMs(llmIds: ReadonlyArray<DLLMId>): ReadonlyArray<DLLM | undefined> {
  return useModelsStore(useShallow(state => {
    return llmIds.map(llmId => !llmId ? undefined : state.llms.find(llm => llm.id === llmId));
  }));
}

export function useLLMsByService(serviceId: false | DModelsServiceId): DLLM[] {
  return useModelsStore(useShallow(
    state => !serviceId ? state.llms : state.llms.filter(llm => llm.sId === serviceId),
  ));
}

export function useVisibleLLMs(includeLlmId: undefined | DLLMId | null): ReadonlyArray<DLLM> {
  return useModelsStore(useShallow(
    ({ llms }) => llms.filter(llm => !llm.hidden || (includeLlmId && llm.id === includeLlmId)),
  ));
}

export function useHasLLMs(): boolean {
  return useModelsStore(state => !!state.llms.length);
}

export function useModelsServices() {
  return useModelsStore(useShallow(state => ({
    modelsServices: state.sources,
    confServiceId: state.confServiceId,
    setConfServiceId: state.setConfServiceId,
  })));
}


================================================
FILE: src/common/stores/llms/llms.parameters.ts
================================================
/**
 * Parameter Registry and Model Configuration
 *
 * This module provides a type-safe parameter management system for LLM models.
 * It handles parameter definitions, validation, and runtime values while
 * maintaining strict type safety throughout the application.
 *
 * Key concepts:
 * - ParameterRegistry: Defines all possible parameters and their constraints
 * - ParameterSpec: Model-specific parameter configurations
 * - ParameterValues: Runtime parameter values (initial and user overrides)
 *
 * @module llms
 */


// shared constants
export const FALLBACK_LLM_PARAM_RESPONSE_TOKENS = 4096;
export const FALLBACK_LLM_PARAM_TEMPERATURE = 0.5;
// const FALLBACK_LLM_PARAM_REF_UNKNOWN = 'unknown_id';


/// Registry

export const DModelParameterRegistry = {

  /// Common parameters, normally available in all models ///
  // Note: we still use pre-v2 names for compatibility and ease of migration

  llmRef: {
    label: 'Model ID',
    type: 'string' as const,
    description: 'Upstream model reference',
    hidden: true,
  } as const,

  llmResponseTokens: {
    label: 'Maximum Tokens',
    type: 'integer' as const,
    description: 'Maximum length of generated text',
    nullable: {
      meaning: 'Explicitly avoid sending max_tokens to upstream API',
    } as const,
    requiredFallback: FALLBACK_LLM_PARAM_RESPONSE_TOKENS,   // if required and not specified/user overridden, use this value
  } as const,

  llmTemperature: {
    label: 'Temperature',
    type: 'float' as const,
    description: 'Controls randomness in the output',
    range: [0.0, 2.0] as const,
    nullable: {
      meaning: 'Explicitly avoid sending temperature to upstream API',
    } as const,
    requiredFallback: FALLBACK_LLM_PARAM_TEMPERATURE,
  } as const,

  /// Extended parameters, specific to certain models/vendors

  llmTopP: {
    label: 'Top P',
    type: 'float' as const,
    description: 'Nucleus sampling threshold',
    range: [0.0, 1.0] as const,
    requiredFallback: 1.0,
    incompatibleWith: ['temperature'] as const,
  } as const,

  /**
   * First introduced as a user-configurable parameter for the 'Verification' required by o3.
   * [2025-04-16] Adding parameter to disable streaming for o3, and possibly more models.
   */
  llmForceNoStream: {
    label: 'Disable Streaming',
    type: 'boolean' as const,
    description: 'Disables streaming for this model',
    // initialValue: false, // we don't need the initial value here, will be assumed off
  } as const,

  llmVndAntThinkingBudget: {
    label: 'Thinking Budget',
    type: 'integer' as const,
    description: 'Budget for extended thinking',
    range: [1024, 65536] as const,
    initialValue: 8192,
    nullable: {
      meaning: 'Disable extended thinking',
    } as const,
  } as const,

  llmVndGeminiShowThoughts: {
    label: 'Show Thoughts',
    type: 'boolean' as const,
    description: 'Show Gemini\'s reasoning process',
    initialValue: true,
  } as const,

  llmVndGeminiThinkingBudget: {
    label: 'Thinking Budget',
    type: 'integer' as const,
    /**
     * can be overwritten, as gemini models seem to have different ranges which also does not include 0
     * - value = 0 disables thinking
     * - value = undefined means 'auto thinking budget'.
     */
    range: [0, 24576] as const,
    // initialValue: unset, // auto-budgeting
    description: 'Budget for extended thinking. 0 disables thinking. If not set, the model chooses automatically.',
  } as const,

  llmVndOaiReasoningEffort: {
    label: 'Reasoning Effort',
    type: 'enum' as const,
    description: 'Constrains effort on reasoning for OpenAI reasoning models',
    values: ['low', 'medium', 'high'] as const,
    requiredFallback: 'medium',
  } as const,

  llmVndOaiRestoreMarkdown: {
    label: 'Restore Markdown',
    type: 'boolean' as const,
    description: 'Restore Markdown formatting in the output',
    initialValue: true,
  } as const,

  llmVndOaiWebSearchContext: {
    label: 'Search Context Size',
    type: 'enum' as const,
    description: 'Amount of context retrieved from the web',
    values: ['low', 'medium', 'high'] as const,
    requiredFallback: 'medium',
  } as const,

  llmVndOaiWebSearchGeolocation: {
    // NOTE: for now this is a boolean to enable/disable using client-side geolocation, but
    // in the future we could have it a more complex object. Note that the payload that comes
    // back if of type AixAPI_Model.userGeolocation, which is the AIX Wire format for the
    // location payload.
    label: 'Add User Location (Geolocation API)',
    type: 'boolean' as const,
    description: 'Approximate location for search results',
    initialValue: false,
  } as const,

  // Perplexity-specific parameters

  // llmVndPerplexityReasoningEffort - we reuse the OpenAI reasoning effort parameter

  llmVndPerplexityDateFilter: {
    label: 'Date Range',
    type: 'enum' as const,
    description: 'Filter results by publication date',
    values: ['unfiltered', '1m', '3m', '6m', '1y'] as const,
    // requiredFallback: 'unfiltered',
  } as const,

  llmVndPerplexitySearchMode: {
    label: 'Search Mode',
    type: 'enum' as const,
    description: 'Type of sources to search',
    values: ['default', 'academic'] as const,
    // requiredFallback: 'default', // or leave unset for "unspecified"
  } as const,

  // xAI-specific parameters

  llmVndXaiSearchMode: {
    label: 'Search Mode',
    type: 'enum' as const,
    description: 'Controls when to use live search',
    values: ['auto', 'on', 'off'] as const,
    initialValue: 'auto', // we default to auto for our users, to get them search out of the box
  } as const,

  llmVndXaiSearchSources: {
    label: 'Search Sources',
    type: 'string' as const,
    description: 'Comma-separated sources (web,x,news,rss)',
    initialValue: 'web,x', // defaults to web,x as per xAI docs
  } as const,

  llmVndXaiSearchDateFilter: {
    label: 'Search From Date',
    type: 'enum' as const,
    description: 'Filter search results by publication date',
    values: ['unfiltered', '1d', '1w', '1m', '6m', '1y'] as const,
    // requiredFallback: 'unfiltered',
  } as const,

} as const;


/// Types

// this is the client-side typescript definition that matches ModelParameterSpec_schema in `llm.server.types.ts`
export interface DModelParameterSpec<T extends DModelParameterId> {
  paramId: T;
  required?: boolean;
  hidden?: boolean;
  initialValue?: boolean | number | string | null;
  // upstreamDefault?: DModelParameterValue<T>;
  /**
   * (optional, rare) Special: [min, max] range override for this parameter.
   * Used by llmVndGeminiThinkingBudget to allow different ranges for different models.
   */
  rangeOverride?: [number, number];
}

export type DModelParameterValues = {
  [K in DModelParameterId]?: DModelParameterValue<K>;
}

export type DModelParameterId = keyof typeof DModelParameterRegistry;
// type _ExtendedParameterId = keyof typeof _ExtendedParameterRegistry;

type _EnumValues<T> = T extends { type: 'enum', values: readonly (infer U)[] } ? U : never;

type DModelParameterValue<T extends DModelParameterId> =
  typeof DModelParameterRegistry[T]['type'] extends 'integer'
    ? typeof DModelParameterRegistry[T] extends { nullable: any }
      ? number | null
      : number :
    typeof DModelParameterRegistry[T]['type'] extends 'float'
      ? typeof DModelParameterRegistry[T] extends { nullable: any }
        ? number | null
        : number :
      typeof DModelParameterRegistry[T]['type'] extends 'string' ? string :
        typeof DModelParameterRegistry[T]['type'] extends 'boolean' ? boolean :
          typeof DModelParameterRegistry[T]['type'] extends 'enum'
            ? _EnumValues<typeof DModelParameterRegistry[T]>
            : never;


/// Utility Functions

export function applyModelParameterInitialValues(destValues: DModelParameterValues, parameterSpecs: DModelParameterSpec<DModelParameterId>[], overwriteExisting: boolean): void {
  for (const param of parameterSpecs) {
    const paramId = param.paramId;

    // skip if already present
    if (!overwriteExisting && paramId in destValues)
      continue;

    // 1. (if present) apply Spec.initialValue
    if (param.initialValue !== undefined) {
      destValues[paramId] = param.initialValue as DModelParameterValue<typeof paramId>;
      continue;
    }

    // 2. (if present) apply Registry[paramId].initialValue
    const registryDef = DModelParameterRegistry[paramId];
    if (registryDef) {
      if ('initialValue' in registryDef && registryDef.initialValue !== undefined)
        destValues[paramId] = registryDef.initialValue as DModelParameterValue<typeof paramId>;
    } else
      console.warn(`applyModelParameterInitialValues: unknown parameter id '${paramId}'`);
  }
}


const _requiredParamId: DModelParameterId[] = ['llmRef', 'llmResponseTokens', 'llmTemperature'] as const;

export function getAllModelParameterValues(initialParameters: undefined | DModelParameterValues, userParameters?: DModelParameterValues): DModelParameterValues {

  // fallback values
  const fallbackParameters: DModelParameterValues = {};
  for (const requiredParamId of _requiredParamId) {
    if ('requiredFallback' in DModelParameterRegistry[requiredParamId])
      fallbackParameters[requiredParamId] = DModelParameterRegistry[requiredParamId].requiredFallback as DModelParameterValue<typeof requiredParamId>;
  }

  // accumulate initial and user values
  return {
    ...fallbackParameters,
    ...initialParameters,
    ...userParameters,
  };
}


export function getModelParameterValueOrThrow<T extends DModelParameterId>(
  paramId: T,
  initialValues: undefined | DModelParameterValues,
  userValues: undefined | DModelParameterValues,
  fallbackValue: undefined | DModelParameterValue<T>,
): DModelParameterValue<T> {

  // check user values first
  if (userValues && paramId in userValues) {
    const value = userValues[paramId];
    if (value !== undefined) return value;
  }

  // then check initial values
  if (initialValues && paramId in initialValues) {
    const value = initialValues[paramId];
    if (value !== undefined) return value;
  }

  // then try provided fallback
  if (fallbackValue !== undefined) return fallbackValue;

  // finally the global registry fallback
  const paramDef = DModelParameterRegistry[paramId];
  if ('requiredFallback' in paramDef && paramDef.requiredFallback !== undefined)
    return paramDef.requiredFallback as DModelParameterValue<T>;

  // if we're here, we couldn't find a value
  // [DANGER] VERY DANGEROUS, but shall NEVER happen
  throw new Error(`getModelParameterValue: missing required parameter '${paramId}'`);
}



================================================
FILE: src/common/stores/llms/llms.pricing.ts
================================================
import type { DLLM } from './llms.types';


/**
 * Stored in the LLMS DB - IMPORTANT: do not break.
 * Pricing is denominated in $/MegaTokens.
 */
export type DModelPricing = {
  chat?: DPricingChatGenerate,
}

// NOTE: (!) keep this in sync with PricingChatGenerate_schema (modules/llms/server/llm.server.types.ts)
export type DPricingChatGenerate = {
  // unit: 'USD_Mtok',
  input?: DTieredPricing;
  output?: DTieredPricing;
  cache?: {
    cType: 'ant-bp';
    read: DTieredPricing;
    write: DTieredPricing;
    duration: number; // seconds
  } | {
    cType: 'oai-ac';
    read: DTieredPricing;
    // write: DTieredPricing; // Not needed, as it's automatic
  };
  // NOT in AixWire_API_ListModels.PricingChatGenerate_schema
  _isFree?: boolean; // precomputed, so we avoid recalculating it
}

type DTieredPricing = DPricePerMToken | DPriceUpTo[];

type DPriceUpTo = {
  upTo: number | null,
  price: DPricePerMToken
};

type DPricePerMToken = number | 'free';


/// detect Free Pricing

export function isModelPricingFree(pricingChatGenerate: DPricingChatGenerate): boolean {
  if (!pricingChatGenerate) return true;
  return _isPricingFree(pricingChatGenerate.input) && _isPricingFree(pricingChatGenerate.output);
}

function _isPricingFree(pricing: DTieredPricing | undefined): boolean {
  if (pricing === 'free') return true;
  if (pricing === undefined) return false;
  if (typeof pricing === 'number') return pricing === 0;
  return pricing.every(tier => tier.price === 'free' || tier.price === 0);
}


/// Human readable cost

export function getLlmCostForTokens(tierTokens: number, tokens: number, pricing: DTieredPricing | undefined): number | undefined {
  if (!pricing) return undefined;
  if (pricing === 'free') return 0;

  // Cost = tokens * price / 1e6
  if (typeof pricing === 'number') return tokens * pricing / 1e6;

  // Find the applicable tier based on input tokens
  const applicableTier = pricing.find(tier => tier.upTo === null || tierTokens <= tier.upTo);
  if (!applicableTier) {
    console.log('[DEV] getLlmCostForTokens: No applicable tier found for input tokens', { tierTokens, pricing });
    return undefined;
  }

  // Cost = tier pricing * tokens / 1e6 (or free)
  if (applicableTier.price === 'free') return 0;
  // Note: apply the pricing of the found tier to all tokens
  return tokens * applicableTier.price / 1e6;
}


// Compatibility layer for pricing V2 -> V3

interface Was_DModelPricingV2 {
  chatIn?: number
  chatOut?: number,
}

export function portModelPricingV2toV3(llm: DLLM): void {
  if (!llm.pricing) return;
  if (typeof llm.pricing !== 'object') return;

  const pretendIsV2 = llm.pricing as Was_DModelPricingV2;
  if (pretendIsV2.chatIn || pretendIsV2.chatOut) {
    const V3pcg: DPricingChatGenerate = {};
    if (pretendIsV2.chatIn)
      V3pcg.input = pretendIsV2.chatIn;
    if (pretendIsV2.chatOut)
      V3pcg.output = pretendIsV2.chatOut;
    V3pcg._isFree = isModelPricingFree(V3pcg);
    llm.pricing = { chat: V3pcg };
    delete pretendIsV2.chatIn;
    delete pretendIsV2.chatOut;
  }
}


================================================
FILE: src/common/stores/llms/llms.service.types.ts
================================================
//
// WARNING: Everything here is data at rest. Know what you're doing.
//

import type { ModelVendorId } from '~/modules/llms/vendors/vendors.registry';

/**
 * Models Service - configured to be a unique origin of models (data object, stored)
 */
export interface DModelsService<TServiceSettings extends object = {}> {
  id: DModelsServiceId;
  label: string;

  // service -> vendor of that service
  vId: ModelVendorId;

  // service-specific
  setup: Partial<TServiceSettings>;
}

export type DModelsServiceId = string;


================================================
FILE: src/common/stores/llms/llms.types.ts
================================================
//
// WARNING: Everything here is data at rest. Know what you're doing.
//

import type { ModelVendorId } from '~/modules/llms/vendors/vendors.registry';

import type { DModelParameterId, DModelParameterSpec, DModelParameterValues } from './llms.parameters';
import type { DModelPricing } from './llms.pricing';
import type { DModelsServiceId } from './llms.service.types';


/**
 * Identifies a model in the DB. Used to refer to Big-AGI client-side models, by their
 * IDs only. E.g. will use hooks with the store to react to them.
 */
export type DLLMId = string;

/**
 * Large Language Model - description and configuration (data object, stored)
 */
export interface DLLM {
  id: DLLMId;

  // editable properties (kept on update, if isEdited)
  label: string;
  created: number | 0;
  updated?: number | 0;
  description: string;
  hidden: boolean;                  // hidden from UI selectors

  // hard properties (overwritten on update)
  contextTokens: number | null;     // null: must assume it's unknown
  maxOutputTokens: number | null;   // null: must assume it's unknown
  trainingDataCutoff?: string;      // 'Apr 2029'
  interfaces: DModelInterfaceV1[];  // if set, meaning this is the known and comprehensive set of interfaces
  benchmark?: { cbaElo?: number, cbaMmlu?: number }; // benchmark values
  pricing?: DModelPricing;

  // parameters system
  parameterSpecs: DModelParameterSpec<DModelParameterId>[];
  initialParameters: DModelParameterValues;

  // references
  sId: DModelsServiceId;
  vId: ModelVendorId;

  // user edited properties - if not undefined/missing, they override the others
  userLabel?: string;
  userHidden?: boolean;
  userStarred?: boolean;
  userParameters?: DModelParameterValues; // user has set these parameters
}


/// Interfaces ///

// do not change anything below! those will be persisted in data
export type DModelInterfaceV1 =
  | 'oai-chat'
  | 'oai-chat-fn'
  | 'oai-chat-json'
  | 'oai-chat-vision'
  | 'oai-chat-reasoning'
  | 'oai-complete'
  | 'ant-prompt-caching'
  | 'oai-prompt-caching'
  | 'oai-realtime'
  | 'oai-responses'
  | 'oai-needs-audio'
  | 'gem-code-execution'
  | 'outputs-audio'            // TEMP: ui flag - supports audio output (e.g., text-to-speech)
  | 'outputs-image'            // TEMP: ui flag - supports image output (image generation)
  | 'outputs-no-text'          // disable text outputs (used in conjunction with alt-outputs) - assumed off
  | 'tools-web-search'         // TEMP: ui flag - supports integrated web search tool
  | 'hotfix-no-stream'         // disable streaming for o1-preview (old) and o1 (20241217)
  | 'hotfix-no-temperature'    // disable temperature for deepseek-r1
  | 'hotfix-strip-images'      // strip images from the input
  | 'hotfix-strip-sys0'        // strip the system instruction (unsupported)
  | 'hotfix-sys0-to-usr0'      // cast sys0 to usr0
  ;

// Model interfaces (chat, and function calls) - here as a preview, will be used more broadly in the future
// FIXME: keep this in sync with the server side on modules/llms/server/llm.server.types.ts
export const LLM_IF_OAI_Chat: DModelInterfaceV1 = 'oai-chat';
export const LLM_IF_OAI_Fn: DModelInterfaceV1 = 'oai-chat-fn';
export const LLM_IF_OAI_Json: DModelInterfaceV1 = 'oai-chat-json'; // for Structured Outputs (or JSON mode at worst)
// export const LLM_IF_OAI_JsonSchema: ... future?
export const LLM_IF_OAI_Vision: DModelInterfaceV1 = 'oai-chat-vision';
export const LLM_IF_OAI_Reasoning: DModelInterfaceV1 = 'oai-chat-reasoning';
export const LLM_IF_Outputs_Audio: DModelInterfaceV1 = 'outputs-audio';
export const LLM_IF_Outputs_Image: DModelInterfaceV1 = 'outputs-image';
export const LLM_IF_Outputs_NoText: DModelInterfaceV1 = 'outputs-no-text';
export const LLM_IF_Tools_WebSearch: DModelInterfaceV1 = 'tools-web-search';
export const LLM_IF_OAI_Complete: DModelInterfaceV1 = 'oai-complete';
export const LLM_IF_ANT_PromptCaching: DModelInterfaceV1 = 'ant-prompt-caching';
export const LLM_IF_OAI_PromptCaching: DModelInterfaceV1 = 'oai-prompt-caching';
export const LLM_IF_OAI_Realtime: DModelInterfaceV1 = 'oai-realtime';
export const LLM_IF_OAI_Responses: DModelInterfaceV1 = 'oai-responses';
export const LLM_IF_OAI_NeedsAudio: DModelInterfaceV1 = 'oai-needs-audio';
export const LLM_IF_GEM_CodeExecution: DModelInterfaceV1 = 'gem-code-execution';
export const LLM_IF_HOTFIX_NoStream: DModelInterfaceV1 = 'hotfix-no-stream';
export const LLM_IF_HOTFIX_NoTemperature: DModelInterfaceV1 = 'hotfix-no-temperature';
export const LLM_IF_HOTFIX_StripImages: DModelInterfaceV1 = 'hotfix-strip-images';
export const LLM_IF_HOTFIX_StripSys0: DModelInterfaceV1 = 'hotfix-strip-sys0';
export const LLM_IF_HOTFIX_Sys0ToUsr0: DModelInterfaceV1 = 'hotfix-sys0-to-usr0';

// TODO: just remove this, and move to a capabilities array (I/O/...)
// FIXME: keep this in sync with the client side on llms.types.ts
export const LLMS_ALL_INTERFACES = [
  // Declare common capabilities
  LLM_IF_OAI_Chat,            // MUST SUPPORT - chat interface
  LLM_IF_OAI_Vision,          // GREAT TO HAVE - image inputs
  LLM_IF_OAI_Fn,              // IMPORTANT - support for function calls
  LLM_IF_OAI_Json,            // not used for now: structured outputs
  // Generalized capabilities
  LLM_IF_OAI_Reasoning,       // COSMETIC ONLY - may show a 'brain' icon in supported screens
  LLM_IF_Outputs_Audio,       // COSMETIC ONLY FOR NOW - Models that generate audio output (TTS models)
  LLM_IF_Outputs_Image,       // COSMETIC ONLY FOR NOW - Models that can generate images (Gemini, DALL-E, etc.)
  LLM_IF_Outputs_NoText,      // Disable Text Outputs - e.g. Gemini pure TTS
  LLM_IF_Tools_WebSearch,     // Models with web search capability (Perplexity, GPT-4o Search, etc.)
  // Vendor-specific capabilities
  LLM_IF_ANT_PromptCaching,   // [Anthropic] model supports anthropic-specific caching
  LLM_IF_GEM_CodeExecution,   // [Gemini] Tool: code execution
  LLM_IF_OAI_PromptCaching,   // [OpenAI] model supports OpenAI prompt caching
  LLM_IF_OAI_Realtime,        // [OpenAI] realtime API support - unused
  LLM_IF_OAI_Responses,       // [OpenAI] Responses API (new) support
  // Hotfixes to patch specific model quirks
  LLM_IF_HOTFIX_NoStream,     // disable streaming (e.g., o1-preview(old))
  LLM_IF_HOTFIX_NoTemperature,// disable temperature parameter (e.g., deepseek-r1)
  LLM_IF_HOTFIX_StripImages,  // remove images from input (e.g. o3-mini-2025-01-31)
  LLM_IF_HOTFIX_StripSys0,    // strip system instruction (e.g. Gemini Image Generation 2025-03-13), excludes Sys0ToUsr0
  LLM_IF_HOTFIX_Sys0ToUsr0,   // downgrade system to user messages for this model (e.g. o1-mini-2024-09-12)
  // old/unused
  LLM_IF_OAI_Complete,        // UNUSED - older text completion, pre-chats
  LLM_IF_OAI_NeedsAudio,      // audio input processing
] as const;

// Future changes?
// export type DModelPartKind = 'text' | 'image' | 'audio' | 'video' | 'pdf';
// export type DModelCapability =
//   | 'input-text'
//   | 'input-image-data'
//   | 'input-multipart'
//   | 'output-text'
//   | 'output-function'
//   | 'output-image-data'
//   | 'if-chat'
//   | 'if-fast-chat'
//   ;
// modelcaps: DModelCapability[];
// inputTypes: {                     // future? the supported input formats
//   [key in DModelPartKind]?: {
//     // maxItemsPerInput?: number;
//     // maxFileSize?: number; // in bytes
//     // maxDurationPerInput?: number; // in seconds, for audio and video
//     // maxPagesPerInput?: number; // for PDF
//     // encodings?: ('base64' | 'utf-8')[];
//     mimeTypes?: string[];
//   }
// };



================================================
FILE: src/common/stores/llms/model.domains.registry.ts
================================================
import type { DModelDomainId } from './model.domains.types';
import { DModelInterfaceV1, LLM_IF_OAI_Fn } from './llms.types';


type ModelDomainSpec = {
  label: string;
  confLabel: string;
  confTooltip: string;
  description: string;
  recommended?: string;
  /**
   * If non-empty, this domain demands that the assigned LLM
   * must have *all* the listed interfaces. If no LLM matches,
   * we'll fallback to ignoring the filter.
   */
  requiredInterfaces?: DModelInterfaceV1[];
  autoStrategy: 'topVendorTopLlm' | 'topVendorLowestCost';
  fallbackDomain?: DModelDomainId;
};


export const ModelDomainsList: DModelDomainId[] = ['primaryChat', 'codeApply', 'fastUtil'] as const;

export const ModelDomainsRegistry: Record<DModelDomainId, ModelDomainSpec> = {
  primaryChat: {
    label: 'Primary Chat',
    confLabel: 'Chat',
    confTooltip: 'Default model for new Chats',
    description: 'Main conversational model',
    requiredInterfaces: [],
    autoStrategy: 'topVendorTopLlm',
  },
  codeApply: {
    label: 'Code Editor',
    confLabel: 'Code',
    confTooltip: 'Model for applying code changes and other code-related complex operations. E.g. Sonnet 3.5',
    description: 'Code changes editor and applicator',
    recommended: 'Sonnet 3.5',
    requiredInterfaces: [LLM_IF_OAI_Fn],
    autoStrategy: 'topVendorTopLlm',
    fallbackDomain: 'fastUtil',
  },
  fastUtil: {
    label: 'Fast Utility',
    confLabel: 'Fast',
    confTooltip: 'Use this Model for "fast" features, such as Auto-Title, Summarize, etc.',
    description: 'Quick response model for simple tasks',
    autoStrategy: 'topVendorLowestCost',
    requiredInterfaces: [LLM_IF_OAI_Fn], // NOTE: we do enforce this already, although this may not be correctly set for all vendors
  },
};


// NOTE: the following is not ready and is even misleading.
//       For now, we'll only have a single type for the domainId, for tracking.
//
// ModelSpace - ideas:
// - Tiers: primary, secondary, utility, ...
// - Capabilities: expert, standard, basic, ...
// - Functions: reasoning, creative, processing, ...
// - Domains: general, specialized, task-specific, ...
//
// const ModelSpaceDimensionRegistry = {
//
//   modelTier: {
//     label: 'Model Tier',
//     type: 'enum' as const,
//     values: ['primary', 'utility'] as const,
//     description: 'The tier of the model',
//   } as const,
//
//   modelFunction: {
//     label: 'Model Function',
//     type: 'enum' as const,
//     values: ['reasoning', 'creative', 'processing'] as const,
//     description: 'The primary function of the model',
//   },
//
//   // ...
//
// } as const;



================================================
FILE: src/common/stores/llms/model.domains.types.ts
================================================
/**
 * Stored type - edit with care
 */
export type DModelDomainId =
  |
  /**
   * Primary Chat model - used in the Chat window, inferred from .messages[].generator, or set on the Persona
   */
  'primaryChat'
  |
  /**
   * Code Editor - used in the Code Editor, for applying code changes -- currently, only Sonnet 3.5 is recommended
   */
  'codeApply'
  |
  /**
   * Fast Utility model; must have function calling, but we won't enforce in the code for now until all LLMs are correctly identified as FC or not - used for quick responses and simple tasks
   */
  'fastUtil'
  ;


================================================
FILE: src/common/stores/llms/modelconfiguration.types.ts
================================================
import type { DLLMId } from './llms.types';
import type { DModelDomainId } from './model.domains.types';
import type { DModelParameterValues } from './llms.parameters';


/**
 * This is used for Global models, as well as Per-Persona (or in the future per-project even) models.
 */
export type DModelConfiguration = {
  mct: 'model-parametric';

  // simpler version of a search space
  domainId: DModelDomainId;

  // configuration of the model and its parameters
  modelId: DLLMId | null; // null: "I don't want to use any model for this domain", which is different than an unconfigured domain, which can still have a 'fallback'
  modelParameters?: DModelParameterValues; // this is an override, to be overlaid on top of other configurations, if any
}


/// helpers - creation

export function createDModelConfiguration(domainId: DModelDomainId, modelId: DLLMId | null, modelParameters?: DModelParameterValues): DModelConfiguration {
  return {
    mct: 'model-parametric',
    domainId: domainId,
    modelId: modelId,
    ...(modelParameters !== undefined ? { modelParameters: modelParameters } : {}),
  };
}


// TODO: remove this
export function createDModelConfigurationPrimaryChat(modelId: DLLMId | null, modelParameters?: DModelParameterValues): DModelConfiguration {
  return createDModelConfiguration('primaryChat', modelId, modelParameters);
}



================================================
FILE: src/common/stores/llms/store-llms-domains_slice.ts
================================================
import type { StateCreator } from 'zustand/vanilla';

import type { ModelVendorId } from '~/modules/llms/vendors/vendors.registry';

import type { DLLM, DLLMId } from './llms.types';
import type { DModelDomainId } from './model.domains.types';
import { LlmsRootState, useModelsStore } from './store-llms';
import { ModelDomainsList, ModelDomainsRegistry } from './model.domains.registry';
import { createDModelConfiguration, DModelConfiguration } from './modelconfiguration.types';
import { getLlmCostForTokens } from './llms.pricing';


/// LLMs Assignments Slice

export interface LlmsAssignmentsState {

  modelAssignments: Partial<Record<DModelDomainId, DModelConfiguration>>;

}

export interface LlmsAssignmentsActions {

  assignDomainModelConfiguration: (config: DModelConfiguration) => void;
  assignDomainModelId: (domainId: DModelDomainId, llmId: DLLMId | null) => void;

  autoReassignDomainModel: (domainId: DModelDomainId, ifNotPresent: boolean, ifNotVisible: boolean) => void;

}


export type LlmsAssignmentsSlice = LlmsAssignmentsState & LlmsAssignmentsActions;

export const createLlmsAssignmentsSlice: StateCreator<LlmsRootState & LlmsAssignmentsSlice, [], [], LlmsAssignmentsSlice> = (_set, _get) => ({

  // init state
  modelAssignments: {},

  // actions
  assignDomainModelConfiguration: (config) =>
    _set(state => ({
      modelAssignments: {
        ...state.modelAssignments,
        [config.domainId]: config,
      },
    })),

  assignDomainModelId: (domainId, llmId) =>
    _set(state => {

      // auto-assign if null, to prevent a domain from being left without a model
      if (!llmId) {
        const autoModelConfiguration = _autoModelConfiguration(domainId, state.llms);
        if (autoModelConfiguration)
          return {
            modelAssignments: {
              ...state.modelAssignments,
              [domainId]: autoModelConfiguration,
            },
          };
        // if no auto-assign, fall through, which will set the model to null
      }

      return {
        modelAssignments: {
          ...state.modelAssignments,
          [domainId]: createDModelConfiguration(domainId, llmId),
        },
      };
    }),

  autoReassignDomainModel: (domainId, ifNotPresent, ifNotVisible) => {
    const { llms, modelAssignments } = _get();

    // do not perform reassignment under certain conditions
    const domainAssignment = modelAssignments[domainId] ?? undefined;
    if (domainAssignment) {
      const llmId = domainAssignment.modelId;
      if (llmId) {
        if (!ifNotPresent)
          return; // assigned and maybe present: nothing to do
        // check if present
        const llm = llms.find(({ id }) => id === llmId);
        if (llm) {
          if (!ifNotVisible)
            return; // present and maybe visible: nothing to do
          if (!llm.hidden)
            return; // present and visible: nothing to do
        }
      }
    }

    // re-assign
    const autoModelConfiguration = _autoModelConfiguration(domainId, llms);
    if (autoModelConfiguration)
      _set(state => ({
        modelAssignments: {
          ...state.modelAssignments,
          [domainId]: autoModelConfiguration,
        },
      }));
  },

});


// --- Heuristics ---

type RankedVendorLLMs = {
  vendorId: ModelVendorId,
  llmsByElo: {
    id: DLLMId,
    cbaElo: number | undefined,
    costRank: number | undefined,
  }[],
};
type PreferredRankedVendors = RankedVendorLLMs[];


/**
 * Heuristics to return the top LLMs from different vendors (diverse), based on their elo,
 * until there are vendors, otherwise loops, and pads with the fallback.
 *
 * @param count returns up to this number of LLMs
 * @param requireElo if true, only LLMs with elo are returned
 * @param fallback the LLM to use if there are not enough LLMs
 */
export function llmsHeuristicGetTopDiverseLlmIds(count: number, requireElo: boolean, fallback: DLLMId | null): DLLMId[] {
  const llmIDs: DLLMId[] = [];

  // iterate through the groups, and top to bottom
  const { llms } = useModelsStore.getState();
  const groupedLlms = _groupLlmsByVendorRankedByElo(llms);
  let groupLevel = 0;
  while (llmIDs.length < count) {
    let added = false;

    for (const group of groupedLlms) {
      if (groupLevel < group.llmsByElo.length) {
        const llmEntry = group.llmsByElo[groupLevel];
        if (!llmEntry.id || (requireElo && llmEntry.cbaElo === undefined))
          continue;
        llmIDs.push(llmEntry.id);
        added = true;
        if (llmIDs.length === count) break; // fast exit
      }
    }

    if (!added)
      break;
    groupLevel++;
  }

  // pad with the fallback
  while (llmIDs.length < count && fallback)
    llmIDs.push(fallback);

  return llmIDs;
}


/**
 * Heuristic to update the assignments (either missing or invalid due to removed models).
 */
export function llmsHeuristicUpdateAssignments(allLlms: ReadonlyArray<DLLM>, existingAssignments: Partial<Record<DModelDomainId, DModelConfiguration>>): LlmsAssignmentsState['modelAssignments'] {
  return ModelDomainsList.reduce((acc, domainId: DModelDomainId) => {

    // reuse the existing assignment, if present
    const existingAssignment = existingAssignments[domainId] ?? undefined;
    if (existingAssignment && (
      existingAssignment.modelId === null || // we allow for "don't have a model", which is the null option
      allLlms.find(({ id }) => id === existingAssignment.modelId) // otherwise we must have a valid model
    )) {
      acc[domainId] = existingAssignment;
      return acc;
    }

    // apply the spec strategy for the domain
    const autoModelConfiguration = _autoModelConfiguration(domainId, allLlms);
    if (autoModelConfiguration)
      acc[domainId] = autoModelConfiguration;

    return acc;
  }, {} as LlmsAssignmentsState['modelAssignments']);
}


// Private - Strategies

function _autoModelConfiguration(domainId: DModelDomainId, llms: ReadonlyArray<DLLM>): DModelConfiguration | undefined {
  const domainSpec = ModelDomainsRegistry[domainId] ?? undefined;

  // Filter LLMs based on required interfaces, but relax the filter if none matches
  let filteredLlms = llms;
  if (domainSpec.requiredInterfaces?.length) {
    const reqIfs = domainSpec.requiredInterfaces;
    const subset = llms.filter(llm => reqIfs.every(reqIf => llm.interfaces.includes(reqIf)));
    // only apply filter if we have at least one matching model
    if (subset.length > 0)
      filteredLlms = subset;
  }

  // Now group the final chosen set
  const vendors = _groupLlmsByVendorRankedByElo(filteredLlms);

  // Students: The rest is the existing strategy logic
  switch (domainSpec?.autoStrategy) {

    case 'topVendorTopLlm':
      const topRankedLLMId = _strategyTopQuality(vendors);
      if (topRankedLLMId)
        return createDModelConfiguration(domainId, topRankedLLMId);
      break;

    case 'topVendorLowestCost':
      const lowCostLLMId = _strategyTopVendorLowestCost(vendors);
      if (lowCostLLMId)
        return createDModelConfiguration(domainId, lowCostLLMId);
      break;

    default:
      console.log('[DEV] unknown strategy for LLM domain', domainId);
  }

  // console.log('[DEV] cannot auto-assign for domain', domainId, llms.length, filteredLlms.length);
  return undefined;
}

function _strategyTopQuality(vendors: PreferredRankedVendors): DLLMId | undefined {
  // return the 1st vendor, 1st model -- great if ranked, but if not, at least return one model
  return vendors.length ? vendors[0].llmsByElo[0]?.id : undefined;
}

function _strategyTopVendorLowestCost(vendors: PreferredRankedVendors, requireEloRating: boolean = true): DLLMId | undefined {

  // based on the assumption that the lowest (but non-zero) cost will happen for:
  // - newest models
  // - which also means better models (if the assumption holds over time)
  // if the top provider doesn't have any, we move to the second, etc.

  if (!vendors.length) return undefined;
  for (const vendor of vendors) {

    // sort by increasing cost, with 0 ('free' at the end, to exclude experimental models)
    const sorted = vendor.llmsByElo.toSorted((a, b) => {
      if (!a.costRank && !b.costRank)
        return 0;
      if (!a.costRank)
        return 1;
      if (!b.costRank)
        return -1;
      return a.costRank - b.costRank;
    });

    // get the first that has cbaElo, assuming those are more 'social proofed' models
    if (requireEloRating) {
      const firstWithElo = sorted.find(llm => llm.cbaElo);
      if (firstWithElo)
        return firstWithElo.id;
    }

    if (sorted.length && sorted[0].id)
      return sorted[0].id;
  }
  return undefined;
}


// Private - LLM ELO Ranking functions

function _groupLlmsByVendorRankedByElo(llms: ReadonlyArray<DLLM>): PreferredRankedVendors {
  // group all LLMs by vendor
  const grouped = llms.reduce((acc, llm) => {
    if (llm.hidden) return acc;
    const group = acc.find(v => v.vendorId === llm.vId);
    const eloCostItem = {
      id: llm.id,
      cbaElo: llm.benchmark?.cbaElo,
      costRank: !llm.pricing ? undefined : _getLlmCostBenchmark(llm),
    };
    if (!group)
      acc.push({ vendorId: llm.vId, llmsByElo: [eloCostItem] });
    else
      group.llmsByElo.push(eloCostItem);
    return acc;
  }, [] as PreferredRankedVendors);

  // sort each vendor's LLMs by elo, decreasing
  for (const vendor of grouped)
    vendor.llmsByElo.sort((a, b) => (b.cbaElo ?? -1) - (a.cbaElo ?? -1));

  // sort all vendors by their highest elo, decreasing
  grouped.sort((a, b) => (b.llmsByElo[0].cbaElo ?? -1) - (a.llmsByElo[0].cbaElo ?? -1));
  return grouped;
}

// Hypothetical cost benchmark for a model, based on total cost of 100k input tokens and 10k output tokens.
function _getLlmCostBenchmark(llm: DLLM): number | undefined {
  if (!llm.pricing?.chat) return undefined;
  const costIn = getLlmCostForTokens(100000, 100000, llm.pricing.chat.input);
  const costOut = getLlmCostForTokens(100000, 10000, llm.pricing.chat.output);
  return (costIn !== undefined && costOut !== undefined) ? costIn + costOut : undefined;
}



================================================
FILE: src/common/stores/llms/store-llms.ts
================================================
//
// WARNING: Everything here is data at rest. Know what you're doing.
//

import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import type { DOpenRouterServiceSettings } from '~/modules/llms/vendors/openrouter/openrouter.vendor';
import type { IModelVendor } from '~/modules/llms/vendors/IModelVendor';
import type { ModelVendorId } from '~/modules/llms/vendors/vendors.registry';

import type { DModelDomainId } from './model.domains.types';
import type { DModelParameterId, DModelParameterValues } from './llms.parameters';
import type { DModelsService, DModelsServiceId } from './llms.service.types';
import { DLLM, DLLMId, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision } from './llms.types';
import { createDModelConfiguration, DModelConfiguration } from './modelconfiguration.types';
import { createLlmsAssignmentsSlice, LlmsAssignmentsActions, LlmsAssignmentsSlice, LlmsAssignmentsState, llmsHeuristicUpdateAssignments } from './store-llms-domains_slice';
import { getDomainModelConfiguration } from './hooks/useModelDomain';
import { portModelPricingV2toV3 } from './llms.pricing';


/// ModelsStore - a store for configured LLMs and configured services

export interface LlmsRootState {

  llms: DLLM[];

  sources: DModelsService<any>[];

  confServiceId: DModelsServiceId | null;

}

interface LlmsRootActions {

  setServiceLLMs: (serviceId: DModelsServiceId, serviceLLMs: ReadonlyArray<DLLM>, keepUserEdits: boolean, keepMissingLLMs: boolean) => void;
  removeLLM: (id: DLLMId) => void;
  rerankLLMsByServices: (serviceIdOrder: DModelsServiceId[]) => void;
  updateLLM: (id: DLLMId, partial: Partial<DLLM>) => void;
  updateLLMUserParameters: (id: DLLMId, partial: Partial<DModelParameterValues>) => void;
  deleteLLMUserParameter: (id: DLLMId, parameterId: DModelParameterId) => void;

  createModelsService: (vendor: IModelVendor) => DModelsService;
  removeService: (id: DModelsServiceId) => void;
  updateServiceSettings: <TServiceSettings>(id: DModelsServiceId, partialSettings: Partial<TServiceSettings>) => void;

  setConfServiceId: (id: DModelsServiceId | null) => void;

  // special
  setOpenRouterKey: (key: string) => void;

}


type LlmsRootSlice = LlmsRootState & LlmsRootActions;
type LlmsStore = LlmsRootSlice & LlmsAssignmentsSlice;


export const useModelsStore = create<LlmsStore>()(persist(
  (set, get, _store) => ({

    // include slices
    ...createLlmsAssignmentsSlice(set, get, _store),

    // initial state

    llms: [],
    sources: [],
    confServiceId: null,

    // actions

    setServiceLLMs: (serviceId: DModelsServiceId, serviceLLMs: ReadonlyArray<DLLM>, keepUserEdits: boolean, keepMissingLLMs: boolean) =>
      set(({ llms: existingLLMs, modelAssignments }) => {

        // keep existing model customizations
        if (keepUserEdits) {
          serviceLLMs = serviceLLMs.map((llm: DLLM): DLLM => {
            const existing = existingLLMs.find(m => m.id === llm.id);
            return !existing ? llm : {
              ...llm,
              ...(existing.userLabel !== undefined ? { userLabel: existing.userLabel } : {}),
              ...(existing.userHidden !== undefined ? { userHidden: existing.userHidden } : {}),
              ...(existing.userStarred !== undefined ? { userStarred: existing.userStarred } : {}),
              ...(existing.userParameters !== undefined ? { userParameters: { ...existing.userParameters } } : {}),
            };
          });
        }

        // remove models that are not in the new list
        if (!keepMissingLLMs)
          existingLLMs = existingLLMs.filter(llm => llm.sId !== serviceId);

        // replace existing llms with the same id
        const newLlms = [...serviceLLMs, ...existingLLMs.filter(existingLlm => !serviceLLMs.some(newLlm => newLlm.id === existingLlm.id))];
        return {
          llms: newLlms,
          modelAssignments: llmsHeuristicUpdateAssignments(newLlms, modelAssignments),
        };
      }),

    removeLLM: (id: DLLMId) =>
      set(state => {
        const newLlms = state.llms.filter(llm => llm.id !== id);
        return {
          llms: newLlms,
          modelAssignments: llmsHeuristicUpdateAssignments(newLlms, state.modelAssignments),
        };
      }),

    rerankLLMsByServices: (serviceIdOrder: DModelsServiceId[]) =>
      set(state => {
        // Create a mapping of service IDs to their index in the provided order
        const serviceIdToIndex = serviceIdOrder.reduce((acc, sId, idx) => {
          acc[sId] = idx;
          return acc;
        }, {} as Record<DModelsServiceId, number>);

        // Sort the LLMs based on the order of their service IDs
        const orderedLlms = [...state.llms].sort((a, b) => {
          const aIndex = serviceIdToIndex[a.sId] ?? Number.MAX_SAFE_INTEGER;
          const bIndex = serviceIdToIndex[b.sId] ?? Number.MAX_SAFE_INTEGER;
          return aIndex - bIndex;
        });

        return {
          llms: orderedLlms,
        };
      }),

    updateLLM: (id: DLLMId, partial: Partial<DLLM>) =>
      set(state => ({
        llms: state.llms.map((llm: DLLM): DLLM =>
          llm.id === id
            ? { ...llm, ...partial }
            : llm,
        ),
      })),

    updateLLMUserParameters: (id: DLLMId, partialUserParameters: Partial<DModelParameterValues>) =>
      set(({ llms }) => ({
        llms: llms.map((llm: DLLM): DLLM =>
          llm.id === id
            ? { ...llm, userParameters: { ...llm.userParameters, ...partialUserParameters } }
            : llm,
        ),
      })),

    deleteLLMUserParameter: (id: DLLMId, parameterId: DModelParameterId) =>
      set(({ llms }) => ({
        llms: llms.map((llm: DLLM): DLLM =>
          llm.id === id && llm.userParameters
            ? { ...llm, userParameters: Object.fromEntries(Object.entries(llm.userParameters).filter(([key]) => key !== parameterId)) }
            : llm,
        ),
      })),

    createModelsService: (vendor: IModelVendor): DModelsService => {

      function _locallyUniqueServiceId(vendorId: ModelVendorId, existingServices: DModelsService[]): DModelsServiceId {
        let serviceId: DModelsServiceId = vendorId;
        let serviceIdx = 0;
        while (existingServices.find(s => s.id === serviceId)) {
          serviceIdx++;
          serviceId = `${vendorId}-${serviceIdx}`;
        }
        return serviceId;
      }

      function _relabelServicesFromSameVendor(vendorId: ModelVendorId, services: DModelsService[]): DModelsService[] {
        let n = 0;
        return services.map((s: DModelsService): DModelsService =>
          (s.vId !== vendorId) ? s
            : { ...s, label: s.label.replace(/ #\d+$/, '') + (++n > 1 ? ` #${n}` : '') },
        );
      }

      const { sources: existingServices, confServiceId } = get();

      // create the service
      const newService: DModelsService = {
        id: _locallyUniqueServiceId(vendor.id, existingServices),
        label: vendor.name,
        vId: vendor.id,
        setup: vendor.initializeSetup?.() || {},
      };

      const newServices = _relabelServicesFromSameVendor(vendor.id, [...existingServices, newService]);

      set({
        sources: newServices,
        confServiceId: confServiceId ?? newService.id,
      });

      return newServices[newServices.length - 1];
    },

    removeService: (id: DModelsServiceId) =>
      set(state => {
        const llms = state.llms.filter(llm => llm.sId !== id);
        return {
          llms,
          sources: state.sources.filter(s => s.id !== id),
          modelAssignments: llmsHeuristicUpdateAssignments(llms, state.modelAssignments),
        };
      }),

    updateServiceSettings: <TServiceSettings>(id: DModelsServiceId, partialSettings: Partial<TServiceSettings>) =>
      set(state => ({
        sources: state.sources.map((s: DModelsService): DModelsService =>
          s.id === id
            ? { ...s, setup: { ...s.setup, ...partialSettings } }
            : s,
        ),
      })),

    setConfServiceId: (id: DModelsServiceId | null) =>
      set({ confServiceId: id }),

    setOpenRouterKey: (key: string) =>
      set(state => {
        const firstOpenRouterService = state.sources.find(s => s.vId === 'openrouter');
        return !firstOpenRouterService ? state : {
          sources: state.sources.map((s: DModelsService): DModelsService =>
            s.id === firstOpenRouterService.id
              ? { ...s, setup: { ...s.setup, oaiKey: key satisfies DOpenRouterServiceSettings['oaiKey'] } }
              : s,
          ),
        };
      }),

  }),
  {
    name: 'app-models',

    /* versioning:
     *  1: adds maxOutputTokens (default to half of contextTokens)
     *  2: large changes on all LLMs, and reset chat/fast/func LLMs
     *  3: big-AGI v2
     *  4: migrate .options to .initialParameters/.userParameters
     *  4B: we changed from .chatLLMId/.fastLLMId to modelAssignments: {}, without expicit migration (done on rehydrate, and for no particular reason)
     */
    version: 4,
    migrate: (_state: any, fromVersion: number): LlmsStore => {

      if (!_state) return _state;
      const state: LlmsStore = _state;

      // 0 -> 1: add 'maxOutputTokens' where missing
      if (fromVersion < 1)
        for (const llm of state.llms)
          if (llm.maxOutputTokens === undefined)
            llm.maxOutputTokens = llm.contextTokens ? Math.round(llm.contextTokens / 2) : null;

      // 1 -> 2: large changes
      if (fromVersion < 2) {
        for (const llm of state.llms) {
          delete (llm as any)['tags'];
          llm.interfaces = ['oai-chat' /* this is here like this to reduce dependencies */];
          // llm.inputTypes = { 'text': {} };
        }
      }

      // 2 -> 3: big-AGI v2: update all models for pricing info
      if (fromVersion < 3) {
        try {
          state.llms.forEach(portModelPricingV2toV3);
        } catch (error) {
          // ... if there's any error, ignore - shall be okay
        }
      }

      // 3 -> 4: migrate .options to .initialParameters/.userParameters
      if (fromVersion < 4) {
        try {
          state.llms.forEach(_port_V3Options_to_V4Parameters_inline);
        } catch (error) {
          // ... if there's any error, ignore - shall be okay
        }
      }

      return state;
    },

    // Pre-saving: omit the memory references from the persisted state
    // partialize: (state) => ({
    //   ...state,
    //   llms: state.llms.map((llm: DLLM): Omit<DLLM, 'itemToRemove'> => {
    //     const { itemToRemove, ...rest } = llm;
    //     return rest;
    //   }),
    // }),

    // Post-loading: ensure a valid starting state
    onRehydrateStorage: () => (state) => {
      if (!state) return;

      // [GC] remove models that do not refer to a valid service
      state.llms = state.llms.map((llm: DLLM): DLLM | null => {
        // finds the service that provides the model
        const service = state.sources.find(s => s.id === llm.sId);
        if (!service || !service.vId) return null;

        // ensure the vId link exists and is valid (this was a pre-TF update)
        return llm.vId ? llm : { ...llm, vId: service.vId };
      }).filter(llm => !!llm) as DLLM[];

      // Select the best LLMs automatically, if not set
      try {
        //  auto-detect assignments, or re-import them from the old format
        if (!state.modelAssignments || !Object.keys(state.modelAssignments).length) {

          // reimport the former chatLLMId and fastLLMId if set
          const prevState = state as { chatLLMId?: DLLMId, fastLLMId?: DLLMId };
          const existingAssignments: Partial<Record<DModelDomainId, DModelConfiguration>> = {};
          if (prevState.chatLLMId) {
            existingAssignments['primaryChat'] = createDModelConfiguration('primaryChat', prevState.chatLLMId);
            existingAssignments['codeApply'] = createDModelConfiguration('codeApply', prevState.chatLLMId);
            delete prevState.chatLLMId;
          }
          if (prevState.fastLLMId) {
            existingAssignments['fastUtil'] = createDModelConfiguration('fastUtil', prevState.fastLLMId);
            delete prevState.fastLLMId;
          }

          // auto-pick models
          state.modelAssignments = llmsHeuristicUpdateAssignments(state.llms, existingAssignments);
        }
      } catch (error) {
        console.error('Error in autoPickModels', error);
      }
    },

  },
));


export function findLLMOrThrow(llmId: DLLMId): DLLM {
  const llm: DLLM | undefined = llmsStoreState().llms.find(llm => llm.id === llmId);
  if (!llm)
    throw new Error(`Large Language Model ${llmId} not found`);
  return llm;
}

export function findModelsServiceOrNull<TServiceSettings extends object>(serviceId: DModelsServiceId): DModelsService<TServiceSettings> | null {
  return llmsStoreState().sources.find(s => s.id === serviceId) ?? null;
}

export function getChatLLMId(): DLLMId | null {
  return getDomainModelConfiguration('primaryChat', true, true)?.modelId ?? null;
}


export function getDomainModelIdOrThrow(tryDomains: DModelDomainId[], requireFunctionCallTools: boolean, requireImageInput: boolean, useCaseLabel: string): DLLMId {
  for (const domain of tryDomains) {
    const isLastTry = domain === tryDomains[tryDomains.length - 1];
    const llmId = getDomainModelConfiguration(domain, true, true)?.modelId;
    if (!llmId) continue;
    try {
      const llm = findLLMOrThrow(llmId);
      if (requireFunctionCallTools && !llm.interfaces.includes(LLM_IF_OAI_Fn)) {
        if (isLastTry) console.log(`[llm selection] Accepting ${llmId} for '${useCaseLabel}' despite missing function call tools.`);
        else continue;
      }
      if (requireImageInput && !llm.interfaces.includes(LLM_IF_OAI_Vision)) {
        if (isLastTry) console.log(`[llm selection] Accepting ${llmId} for '${useCaseLabel}' despite missing image input.`);
        else continue;
      }
      return llmId;
    } catch (error) {
      // Try next or fall back to the error
    }
  }
  throw new Error(`No model available for '${useCaseLabel}'. Pease select a '${tryDomains[0]}' model that supports${requireFunctionCallTools ? ' function calls' : ' text input'}${requireImageInput ? ' and image input' : ''} in App Preferences > Chat AI.`);
}


export function llmsStoreState(): LlmsRootState & LlmsAssignmentsState {
  return useModelsStore.getState();
}

export function llmsStoreActions(): LlmsRootActions & LlmsAssignmentsActions {
  return useModelsStore.getState();
}

export function getLLMsDebugInfo() {
  const { llms, sources, modelAssignments } = llmsStoreState();
  return { services: sources.length, llmsCount: llms.length, modelAssignments };
}

function _port_V3Options_to_V4Parameters_inline(llm: DLLM): void {

  // skip if already migrated
  if ('initialParameters' in (llm as object)) return;

  // initialize initialParameters and userParameters if they don't exist
  if (!llm.initialParameters) llm.initialParameters = {};
  if (!llm.userParameters) llm.userParameters = {};

  // migrate options to initialParameters/userParameters
  type DLLMV3_Options = DLLM & { options?: { llmRef: string, llmTemperature?: number, llmResponseTokens?: number } & Record<string, any> };
  const llmV3 = llm as DLLMV3_Options;
  if ('options' in llmV3 && typeof llmV3.options === 'object') {
    if ('llmRef' in llmV3.options)
      llm.initialParameters.llmRef = llmV3.options.llmRef;
    if ('llmTemperature' in llmV3.options && typeof llmV3.options.llmTemperature === 'number')
      llm.initialParameters.llmTemperature = Math.max(0, Math.min(1, llmV3.options.llmTemperature));
    if ('llmResponseTokens' in llmV3.options && typeof llmV3.options.llmResponseTokens === 'number')
      llm.initialParameters.llmResponseTokens = llmV3.options.llmResponseTokens;
    delete llmV3.options;
  }

}


================================================
FILE: src/common/stores/llms/hooks/useAllLLMs.ts
================================================
import type { DLLM } from '../llms.types';
import { useModelsStore } from '../store-llms';


export function useAllLLMs(): ReadonlyArray<DLLM> {
  return useModelsStore(state => state.llms);
}



================================================
FILE: src/common/stores/llms/hooks/useModelDomain.ts
================================================
import * as React from 'react';

import type { DLLMId } from '../llms.types';
import type { DModelConfiguration } from '../modelconfiguration.types';
import type { DModelDomainId } from '../model.domains.types';
import type { LlmsAssignmentsState } from '../store-llms-domains_slice';
import { LlmsRootState, useModelsStore } from '../store-llms';
import { ModelDomainsRegistry } from '../model.domains.registry';


/**
 * Getter for a single domain model configuration.
 * - Can optionally verify that the LLM exists.
 * - Can optionally use a fallback domain.
 */
export function getDomainModelConfiguration(modelDomainId: DModelDomainId, verifyLLMExists: boolean, autoDomainFallback: boolean): DModelConfiguration | undefined {
  return _getDomainModelConfigurationFromState(useModelsStore.getState(), modelDomainId, verifyLLMExists, autoDomainFallback);
}

function _getDomainModelConfigurationFromState({ llms, modelAssignments }: LlmsRootState & LlmsAssignmentsState, modelDomainId: DModelDomainId, verifyLLMExists: boolean, autoDomainFallback: boolean): DModelConfiguration | undefined {
  const modelConfiguration = modelAssignments?.[modelDomainId] ?? undefined;
  if (modelConfiguration) {
    if (!verifyLLMExists)
      return modelConfiguration;
    if (llms.find(llm => llm.id === modelConfiguration.modelId))
      return modelConfiguration;
  }

  // Try fallback domain
  if (!autoDomainFallback)
    return undefined;
  const fallbackDomain = ModelDomainsRegistry[modelDomainId]?.fallbackDomain ?? undefined;
  if (!fallbackDomain)
    return undefined;
  const fallbackModelConfiguration = modelAssignments?.[fallbackDomain] ?? undefined;
  if (fallbackModelConfiguration) {
    if (!verifyLLMExists)
      return fallbackModelConfiguration;
    if (llms.find(llm => llm.id === fallbackModelConfiguration.modelId))
      return fallbackModelConfiguration;
  }

  // couldn't find or verify domain or fallback domain
  return undefined;
}


/**
 * Single hooks to access per-domain LLM configurations.
 * - Since this is reactive, we assume we don't do 'automated domain fallback' here
 * - We also verify mandatory LLM existence
 */
export function useModelDomain(modelDomainId: DModelDomainId): {

  domainModelId: undefined | DLLMId | null;
  assignDomainModelId: (modelId: DLLMId | null) => void;

  domainModelConfiguration: DModelConfiguration | undefined;
  assignDomainModelConfiguration: (config: DModelConfiguration) => void;

} {

  const domainModelConfiguration = useModelsStore(state =>
    _getDomainModelConfigurationFromState(state, modelDomainId, true, false),
  );

  const assignDomainModelConfiguration = React.useCallback((modelConfiguration: DModelConfiguration) =>
    useModelsStore.getState().assignDomainModelConfiguration(modelConfiguration), []);

  const assignDomainModelId = React.useCallback((modelId: DLLMId | null) =>
    useModelsStore.getState().assignDomainModelId(modelDomainId, modelId), [modelDomainId]);

  return {

    // simple
    domainModelId: domainModelConfiguration?.modelId,
    assignDomainModelId,

    // full
    domainModelConfiguration,
    assignDomainModelConfiguration,

  };
}



================================================
FILE: src/common/stores/llms/hooks/useModelDomains.ts
================================================
import { useModelsStore } from '~/common/stores/llms/store-llms';

/**
 * Single hooks to access per-domain LLM configurations.
 */
export function useModelDomains() {
  return useModelsStore(state => state.modelAssignments);
}



================================================
FILE: src/common/stores/llms/hooks/useModelsZeroState.ts
================================================
import { useModelsStore } from '../store-llms';


export function useModelsZeroState(): boolean {
  return useModelsStore(state => !state.sources?.length);
}



================================================
FILE: src/common/stores/metrics/metrics.chatgenerate.ts
================================================
import { DPricingChatGenerate, getLlmCostForTokens, isModelPricingFree } from '~/common/stores/llms/llms.pricing';


// configuration
const METRICS_APPROXIMATE_DT_INNER_THRESHOLD = 200; // ms
const METRICS_APPROXIMATE_VT_TOKENS_THRESHOLD = 40; // tokens


/**
 * This is a stored type - IMPORTANT: do not break.
 * - stored by DMessage > DMessageGenerator
 */
export type DMetricsChatGenerate_Md =
  Omit<MetricsChatGenerateTokens, 'T'> &
  MetricsChatGenerateCost_Md &
  Pick<MetricsChatGenerateTime, 'dtAll' | 'dtStart' | 'vTOutInner'>; // 2025-02-27: added the inner velocity, which wasn't stored before

/**
 * In particular this is used 'as' AixWire_Particles.CGSelectMetrics
 */
export type DMetricsChatGenerate_Lg =
  MetricsChatGenerateTokens &
  MetricsChatGenerateTime &
  MetricsChatGenerateCost_Md;


type MetricsChatGenerateTokens = {
  // T = Tokens
  T?: number,
  TIn?: number,         // Portion of Input tokens which is new (not cached)
  TCacheRead?: number,
  TCacheWrite?: number,
  TOut?: number,
  TOutR?: number,       // Portion of TOut that was used for reasoning (e.g. not for output)
  // TOutA?: number,    // Portion of TOut that was used for Audio

  // If set, indicates unreliability or Stop Reason (sR)
  TsR?:
    | 'pending'         // still being generated (could be stuck in this state if data got corrupted)
    | 'aborted'         // aborted or failed (interrupted generation, out of tokens, connection error, etc)
}


type MetricsChatGenerateTime = {
  // dt = milliseconds
  dtStart?: number,
  dtInner?: number,
  dtAll?: number,

  // v = Tokens/s
  vTOutInner?: number,  // TOut / dtInner
  vTOutAll?: number,    // TOut / dtAll
}


export type MetricsChatGenerateCost_Md = {
  // $c = Cents of USD - NOTE: we chose to use cents to reduce floating point errors
  $c?: number,
  $cdCache?: number,
  $code?:
    | 'free'            // generated for free
    | 'partial-msg'     // partial message generated
    | 'partial-price'   // partial pricing available
    | 'no-pricing'      // model pricing not available
    | 'no-tokens'       // tokens are missing from the metrics
}


// ChatGenerate token metrics

export function metricsPendChatGenerateLg(metrics: DMetricsChatGenerate_Lg | undefined): void {
  if (metrics)
    metrics.TsR = 'pending';
}

export function metricsFinishChatGenerateLg(metrics: DMetricsChatGenerate_Lg | undefined, isAborted: boolean): void {
  if (!metrics) return;

  // remove the previous TsR if it was 'pending'
  delete metrics.TsR;
  if (isAborted)
    metrics.TsR = 'aborted';

  // sum up the Tokens
  if (!metrics.T)
    metrics.T = (metrics.TIn || 0) + (metrics.TOut || 0) + (metrics.TCacheRead || 0) + (metrics.TCacheWrite || 0);

  // calculate the Token velocities
  if (metrics.TOut !== undefined && metrics.dtAll !== undefined && metrics.dtAll > 0) {

    // inner time approximation (dtStart -> dtAll)
    if (!metrics.dtInner && metrics.dtStart !== undefined && metrics.dtStart > 0) {
      /**
       * Only use the approximate inner duration if it's greater than a threshold. this is to prevent
       * This is to prevent first -> last event timing (a poor substitute for the actual inner duration)
       * to be too short to be meaningful.
       */
      const dtInnerApprox = metrics.dtAll - metrics.dtStart;
      if (dtInnerApprox >= METRICS_APPROXIMATE_DT_INNER_THRESHOLD)
        metrics.dtInner = dtInnerApprox;
    }

    // inner velocity approximation (if not reported by the API, approximate to first -> last event)
    if (!metrics.vTOutInner && metrics.dtInner !== undefined && metrics.dtInner > 0) {

      // for OpenAI reasoning models, we needto remove the reasoning tokens from the total, as they were not counted
      const TOutReceived = metrics.TOut - (metrics.TOutR || 0);

      if (TOutReceived >= METRICS_APPROXIMATE_VT_TOKENS_THRESHOLD)
        metrics.vTOutInner = Math.round(100 * TOutReceived / (metrics.dtInner / 1000)) / 100;
    }

    // outer velocity (end-to-end)
    metrics.vTOutAll = Math.round(100 * metrics.TOut / (metrics.dtAll / 1000)) / 100;

  }
}


// ChatGenerate extraction for DMessage's smaller metrics

export function metricsChatGenerateLgToMd(metrics: DMetricsChatGenerate_Lg): DMetricsChatGenerate_Md {
  const allOptionalKeys: (keyof DMetricsChatGenerate_Md)[] = [
    '$c', '$cdCache', '$code', // select costs
    'TIn', 'TCacheRead', 'TCacheWrite', 'TOut', 'TOutR', // select token counts
    'dtAll', 'dtStart', 'vTOutInner', // select token timings/velocities
    'TsR', // stop reason
  ] as const;
  const extracted: DMetricsChatGenerate_Md = {};

  for (const key of allOptionalKeys) {

    // [OpenAI] we also ignore a TOutR of 0, as networks without reasoning return it. keeping it would be misleading as 'didn't reason but I could have', while it's 'can't reason'
    if (key === 'TOutR' && metrics.TOutR === 0)
      continue;

    // [OpenAI] we also ignore a TOutA of 0 (no audio in this output)
    // if (key === 'TOutA' && metrics.TOutA === 0)
    //   continue;

    if (metrics[key] !== undefined) {
      extracted[key] = metrics[key] as any;
    }
  }

  return extracted;
}


// ChatGenerate cost metrics

const USD_TO_CENTS = 100;

export function metricsComputeChatGenerateCostsMd(metrics?: Readonly<DMetricsChatGenerate_Md>, pricing?: DPricingChatGenerate | undefined, logLlmRefId?: string): MetricsChatGenerateCost_Md | undefined {
  if (!metrics)
    return undefined;

  // metrics: token presence
  const inNewTokens = metrics.TIn || 0;
  const inCacheReadTokens = metrics.TCacheRead || 0;
  const inCacheWriteTokens = metrics.TCacheWrite || 0;
  const sumInputTokens = inNewTokens + inCacheReadTokens + inCacheWriteTokens;
  const outTokens = metrics.TOut || 0;

  // usage: presence
  if (!sumInputTokens && !outTokens)
    return { $code: 'no-tokens' };

  // pricing: presence
  if (!pricing)
    return { $code: 'no-pricing' };

  // pricing: bail if free
  if (isModelPricingFree(pricing))
    return { $code: 'free' };


  // partial pricing
  const isPartialMessage = metrics.TsR === 'pending' || metrics.TsR === 'aborted';

  // Calculate costs
  const tierTokens = sumInputTokens;
  const $inNew = getLlmCostForTokens(tierTokens, inNewTokens, pricing.input);
  const $out = getLlmCostForTokens(tierTokens, outTokens, pricing.output);
  if ($inNew === undefined || $out === undefined) {
    // many llms don't have pricing information, so the cost computation ends here
    return { $code: 'partial-price' };
  }


  // Standard price
  const $noCacheRounded = Math.round(($inNew + $out) * USD_TO_CENTS * 10000) / 10000;
  if (!inCacheReadTokens && !inCacheWriteTokens)
    return { $c: $noCacheRounded, ...(isPartialMessage && { $code: 'partial-msg' }) };


  // Price with Caching
  const cachePricing = pricing.cache;
  if (!cachePricing) {
    console.log(`No cache pricing for ${logLlmRefId}`);
    return { $c: $noCacheRounded, $code: 'partial-price' };
  }

  // 2025-01-10: Now supporting tiered cache pricing
  // Note: We use the total input tokens (new + cache) as the tier discriminator for ALL pricing tiers.
  // This matches how providers like Google structure their pricing - the tier is based on the request size
  // (input context), and that tier's rates apply to all token types in that request.

  // compute the input cache read costs
  const $cacheRead = getLlmCostForTokens(tierTokens, inCacheReadTokens, cachePricing.read);
  if ($cacheRead === undefined) {
    console.log(`Missing cache read pricing for ${logLlmRefId}`);
    return { $c: $noCacheRounded, $code: 'partial-price' };
  }

  // compute the input cache write costs
  let $cacheWrite;
  switch (cachePricing.cType) {
    case 'ant-bp':
      $cacheWrite = getLlmCostForTokens(tierTokens, inCacheWriteTokens, cachePricing.write);
      break;
    case 'oai-ac':
      $cacheWrite = 0;
      break;
    default:
      throw new Error('computeChatGenerationCosts: Unknown cache type');
  }
  if ($cacheWrite === undefined) {
    console.log(`Missing cache write pricing for ${logLlmRefId}`);
    return { $c: $noCacheRounded, $code: 'partial-price' };
  }

  // compute the cost for this call
  const $c = Math.round(($inNew + $cacheRead + $cacheWrite + $out) * USD_TO_CENTS * 10000) / 10000;

  // compute the advantage from caching
  const $inAsIfNoCache = getLlmCostForTokens(tierTokens, sumInputTokens, pricing.input)!;
  const $cdCache = Math.round(($inAsIfNoCache - $inNew - $cacheRead - $cacheWrite) * USD_TO_CENTS * 10000) / 10000;

  // mark the costs as partial if the message was not completely received - i.e. the server did not tell us the final tokens count
  return {
    $c,
    $cdCache,
    ...(isPartialMessage && { $code: 'partial-msg' }),
  };
}



================================================
FILE: src/common/stores/metrics/metrics.modelservice.ts
================================================
import type { StateCreator } from 'zustand';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';

import type { MetricsChatGenerateCost_Md } from './metrics.chatgenerate';


interface ServiceMetricsAggregate {
  // accumulators
  totalCosts: number;
  totalSavings: number;
  totalInputTokens: number;
  totalOutputTokens: number;

  // Usage statistics
  usageCount: number;
  firstUsageDate: number; // Date.now()
  lastUsageDate: number; // Date.now()

  // counters
  freeUsages: number;
  noPricingUsages: number;
  noTokenUsages: number;
  partialMessageUsages: number;
  partialPriceUsages: number;
}

function createServiceMetricsAggregate(): ServiceMetricsAggregate {
  return {
    totalCosts: 0,
    totalSavings: 0,
    totalInputTokens: 0,
    totalOutputTokens: 0,
    usageCount: 0,
    firstUsageDate: 0,
    lastUsageDate: 0,
    freeUsages: 0,
    noPricingUsages: 0,
    noTokenUsages: 0,
    partialMessageUsages: 0,
    partialPriceUsages: 0,
  };
}

export const fallbackEmptyServiceMetricsAggregate = createServiceMetricsAggregate();


// Service Metrics Store Slice

interface ServiceMetricsState {

  // Service Metrics
  serviceMetrics: Record<DModelsServiceId, ServiceMetricsAggregate>;

}

interface ServiceMetricsActions {
  addChatGenerateCostEntry: (costs: MetricsChatGenerateCost_Md, inputTokens: number, outputTokens: number, serviceId: DModelsServiceId | null, debugCostSource: string) => void;
  getAggregateMetricsForService: (serviceId: DModelsServiceId) => ServiceMetricsAggregate | undefined;
}

export type ServiceMetricsSlice = ServiceMetricsState & ServiceMetricsActions;

export const createServiceMetricsSlice: StateCreator<ServiceMetricsSlice, [], [], ServiceMetricsSlice> = (set, get) => ({

  serviceMetrics: {},

  addChatGenerateCostEntry: (costs, inputTokens, outputTokens, serviceId: DModelsServiceId | null, debugCostSource: string) => set((state) => {
    if (!serviceId) return state;

    const currentMetrics = state.serviceMetrics[serviceId] || createServiceMetricsAggregate();
    const newMetrics = updateServiceMetrics(currentMetrics, costs, inputTokens, outputTokens, Date.now());

    return {
      serviceMetrics: {
        ...state.serviceMetrics,
        [serviceId]: newMetrics,
      },
    };
  }),

  getAggregateMetricsForService: (serviceId): ServiceMetricsAggregate | undefined => {
    return get().serviceMetrics[serviceId];
  },

});


/// Aggregation Functions

const CENTS_TO_DOLLARS = 0.01;

function updateServiceMetrics(currentMetrics: ServiceMetricsAggregate, costs: MetricsChatGenerateCost_Md, inputTokens: number, outputTokens: number, timestamp: number): ServiceMetricsAggregate {
  const newMetrics = { ...currentMetrics };

  // Update cost accumulators
  if (costs.$c !== undefined)
    newMetrics.totalCosts += costs.$c * CENTS_TO_DOLLARS;
  if (costs.$cdCache !== undefined)
    newMetrics.totalSavings += costs.$cdCache * CENTS_TO_DOLLARS;

  // Update accumulators
  newMetrics.totalInputTokens += inputTokens;
  newMetrics.totalOutputTokens += outputTokens;

  // Update usage statistics
  newMetrics.usageCount++;
  newMetrics.lastUsageDate = timestamp;
  if (!newMetrics.firstUsageDate)
    newMetrics.firstUsageDate = timestamp;

  // Update counters based on cost code
  if (costs.$code) {
    switch (costs.$code) {
      case 'free':
        newMetrics.freeUsages++;
        break;
      case 'no-pricing':
        newMetrics.noPricingUsages++;
        break;
      case 'no-tokens':
        newMetrics.noTokenUsages++;
        break;
      case 'partial-msg':
        newMetrics.partialMessageUsages++;
        break;
      case 'partial-price':
        newMetrics.partialPriceUsages++;
        break;
    }
  }

  return newMetrics;
}


================================================
FILE: src/common/stores/metrics/store-metrics.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import type { DLLM } from '~/common/stores/llms/llms.types';
import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';

import type { MetricsChatGenerateCost_Md } from './metrics.chatgenerate';
import { createServiceMetricsSlice, fallbackEmptyServiceMetricsAggregate, ServiceMetricsSlice } from './metrics.modelservice';


// Store: single per-app, using the slices pattern for aggregations

const useMetricsStore = create<ServiceMetricsSlice>()(persist((...a) => ({
  ...createServiceMetricsSlice(...a),
}), {
  name: 'app-metrics',
}));


export function metricsStoreAddChatGenerate(costs: MetricsChatGenerateCost_Md, inputTokens: number, outputTokens: number, llm: DLLM, debugCostSource: string) {
  useMetricsStore.getState().addChatGenerateCostEntry(costs, inputTokens, outputTokens, llm.sId || null, debugCostSource);
}

export function useCostMetricsForLLMService(serviceId?: DModelsServiceId) {
  return useMetricsStore((state) =>
    serviceId ? state.getAggregateMetricsForService(serviceId) ?? fallbackEmptyServiceMetricsAggregate
      : fallbackEmptyServiceMetricsAggregate,
  );
}



================================================
FILE: src/common/stores/workspace/store-client-workspace.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import type { DMessage } from '~/common/stores/chat/chat.message';
import type { LiveFileId } from '~/common/livefile/liveFile.types';
import { isAttachmentFragment } from '~/common/stores/chat/chat.fragments';
import { liveFileGetAllValidIDs } from '~/common/livefile/store-live-file';

import type { DWorkspaceId } from './workspace.types';


/**
 * A workspace must have only weak references to the contained information.
 * Strong resolution will be performed at the user levels, going by IDs.
 */
interface WorkspaceState {

  // Workspace associations (using arrays instead of Sets for serialization)
  liveFilesByWorkspace: Record<DWorkspaceId, LiveFileId[]>;

}

interface WorkspaceActions {

  // crud
  remove: (workspaceId: DWorkspaceId) => void;
  copyAssignments: (sourceWorkspaceId: DWorkspaceId, targetWorkspaceId: DWorkspaceId) => void;

  // operations
  liveFileAssign: (workspaceId: DWorkspaceId, fileId: LiveFileId) => void;
  liveFileUnassign: (workspaceId: DWorkspaceId, fileId: LiveFileId) => void;
  liveFileUnassignFromAll: (fileId: LiveFileId) => void;
  importAssignmentsFromMessages: (workspaceId: DWorkspaceId, messages: DMessage[]) => void;

}

export const useClientWorkspaceStore = create<WorkspaceState & WorkspaceActions>()(persist(
  (_set, _get) => ({

    // initial state, before any data is loaded
    liveFilesByWorkspace: {},


    // crud

    remove: (workspaceId: DWorkspaceId) =>
      _set((state) => {
        const { [workspaceId]: _, ...liveFilesByWorkspace } = state.liveFilesByWorkspace;
        return {
          liveFilesByWorkspace,
        };
      }),

    copyAssignments: (sourceWorkspaceId: DWorkspaceId, targetWorkspaceId: DWorkspaceId) =>
      _set((state) => {
        const sourceFiles = state.liveFilesByWorkspace[sourceWorkspaceId] || [];
        const targetFiles = state.liveFilesByWorkspace[targetWorkspaceId] || [];
        return {
          liveFilesByWorkspace: {
            ...state.liveFilesByWorkspace,
            // source files & target files, removing duplicates
            [targetWorkspaceId]: Array.from(new Set([...targetFiles, ...sourceFiles])),
          },
        };
      }),


    // operations

    liveFileAssign: (workspaceId: DWorkspaceId, fileId: LiveFileId) =>
      _set((state) => {
        // if alread included, do not do anything
        if (state.liveFilesByWorkspace[workspaceId]?.includes(fileId))
          return state;
        return {
          liveFilesByWorkspace: {
            ...state.liveFilesByWorkspace,
            [workspaceId]: Array.from(new Set([...(state.liveFilesByWorkspace[workspaceId] || []), fileId])),
          },
        };
      }),

    liveFileUnassign: (workspaceId: DWorkspaceId, fileId: LiveFileId) =>
      _set((state) => {
        if (!state.liveFilesByWorkspace[workspaceId]?.includes(fileId))
          return state;
        return {
          liveFilesByWorkspace: {
            ...state.liveFilesByWorkspace,
            [workspaceId]: (state.liveFilesByWorkspace[workspaceId] || []).filter(id => id !== fileId),
          },
        };
      }),

    liveFileUnassignFromAll: (fileId: LiveFileId) =>
      _set((state) => ({
        liveFilesByWorkspace: Object.fromEntries(
          Object.entries(state.liveFilesByWorkspace).map(([workspaceId, fileIds]) => [
            workspaceId,
            fileIds.filter(id => id !== fileId),
          ]),
        ),
      })),

    importAssignmentsFromMessages: (workspaceId: DWorkspaceId, messages: DMessage[]) =>
      _set((state) => {
        const existingFiles = state.liveFilesByWorkspace[workspaceId] || [];
        const newFileIds: LiveFileId[] = [];

        // Find all file IDs from conversation messages
        messages.forEach(message => {
          message.fragments.forEach(fragment => {
            if (isAttachmentFragment(fragment) && fragment.liveFileId)
              newFileIds.push(fragment.liveFileId);
          });
        });

        return {
          liveFilesByWorkspace: {
            ...state.liveFilesByWorkspace,
            // Combine existing files with new files, removing duplicates
            [workspaceId]: Array.from(new Set([...existingFiles, ...newFileIds])),
          },
        };
      }),

  }),
  {
    name: 'agi-client-workspace',

    onRehydrateStorage: () => (state) => {
      if (!state) return;

      // [GC][LiveFile] remove LiveFile references to invalid objects (also done in chats.conterters.ts)
      const validLiveFileIDs = liveFileGetAllValidIDs();
      state.liveFilesByWorkspace = Object.fromEntries(
        Object.entries(state.liveFilesByWorkspace)
          .map(([workspaceId, fileIds]) => [
            workspaceId,
            fileIds.filter(id => validLiveFileIDs.includes(id)),
          ])
          .filter(([_, fileIds]) => fileIds.length > 0),
      );
    },

  },
));

/**
 * Use this to get the workspace immediate actions (function calls)
 */
export function workspaceActions(): Readonly<WorkspaceActions> {
  return useClientWorkspaceStore.getState();
}



================================================
FILE: src/common/stores/workspace/useWorkspaceContentsMetadata.ts
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { LiveFile, LiveFileId, LiveFileMetadata } from '~/common/livefile/liveFile.types';
import { useLiveFileStore } from '~/common/livefile/store-live-file';

import type { DWorkspaceId } from './workspace.types';
import { useClientWorkspaceStore } from './store-client-workspace';


export interface WorkspaceContents {
  workspaceId: DWorkspaceId | null;
  liveFilesMetadata: LiveFileMetadata[];
}

export function useWorkspaceContentsMetadata(workspaceId: DWorkspaceId | null): WorkspaceContents {

  // stable reference to the LiveFileIds
  const workspaceLiveFileIds: LiveFileId[] | null = useClientWorkspaceStore(useShallow(state => {
    if (!workspaceId) return null;

    // as we only have LiveFiles, stop if we don't have any
    if (!state.liveFilesByWorkspace[workspaceId]?.length)
      return null;

    // re-renders if the array changes at all
    return state.liveFilesByWorkspace[workspaceId].toReversed();
  }));

  // reactive stable reference to the Workspace (only) LiveFiles
  // stability note: exposes on any liveFileStore change, but only re-renders if any Workspace LiveFile changes or is added/removed
  const workspaceLiveFiles: LiveFile[] | null = useLiveFileStore(useShallow(state => {
    if (!workspaceLiveFileIds?.length) return null;

    // re-render if any LiveFile changes, is added or removed
    return workspaceLiveFileIds.map(id => state.liveFiles[id]).filter(Boolean);
  }));

  // re-renders (returns a new object) every time a dependency changes
  return React.useMemo(() => {
    // NOTE: we could go further and stabilize individual LiveFileMetadata objects, to improve re-renders

    // creation of the workspace contents (stabilized thought the memo inputs)
    const { metadataGet } = useLiveFileStore.getState();
    const liveFilesMetadata = (workspaceLiveFiles || []).map(lf => metadataGet(lf.id)).filter(Boolean) as LiveFileMetadata[];
    return {
      workspaceId,
      liveFilesMetadata,
    };
  }, [workspaceId, workspaceLiveFiles]);
}



================================================
FILE: src/common/stores/workspace/workspace.types.ts
================================================
import type { DConversationId } from '~/common/stores/chat/chat.conversation';

/**
 * Not well defined for now, and mapping to DConversations, but we'll define this properly in the future
 * Makes searching for conversations easier
 */
export type DWorkspaceId = string;


/**
 * Make the V2 shortcut of having conversation=workspace evident and searachable.
 */
export function workspaceForConversationIdentity<T extends DConversationId | null>(conversationId: T): T {
  return conversationId;
}



================================================
FILE: src/common/stores/workspace/WorkspaceIdProvider.tsx
================================================
import * as React from 'react';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';

import { DWorkspaceId, workspaceForConversationIdentity } from './workspace.types';


// The Context and the data it will prop-drill
const WorkspaceContext = React.createContext(null as any as WorkspaceContextData);

interface WorkspaceContextData {
  workspaceId: DWorkspaceId | null;
}


/**
 * Provides the workspaceId for its children
 */
export function WorkspaceIdProvider(props: {
  conversationId: DConversationId | null,
  children?: React.ReactNode,
}) {

  // workspace data
  const workspaceData = React.useMemo(() => ({
    workspaceId: workspaceForConversationIdentity(props.conversationId),
  }), [props.conversationId]);

  return (
    <WorkspaceContext.Provider value={workspaceData}>
      {props.children}
    </WorkspaceContext.Provider>
  );
}

/**
 * Access the workspaceId from within a WorkspaceIdProvider subtree
 */
export function useContextWorkspaceId() {
  const value = React.useContext(WorkspaceContext);
  if (!value)
    throw new Error('Missing WorkspaceProvider');
  return value.workspaceId;
}



================================================
FILE: src/common/stores/workspace/WorkspaceLiveFilePicker.tsx
================================================
import * as React from 'react';

import { Box, Button, IconButton, ListDivider, ListItem, ListItemDecorator, MenuItem, SvgIcon, Typography } from '@mui/joy';
import ClearIcon from '@mui/icons-material/Clear';
import CodeIcon from '@mui/icons-material/Code';

import type { LiveFileId, LiveFileMetadata } from '~/common/livefile/liveFile.types';
import { CloseablePopup } from '~/common/components/CloseablePopup';
import { LiveFileChooseIcon, LiveFileIcon } from '~/common/livefile/liveFile.icons';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { getFirstFileSystemFileHandle } from '~/common/util/fileSystemUtils';
import { useDragDropDataTransfer } from '~/common/components/dnd-dt/useDragDropDataTransfer';

import type { DWorkspaceId } from './workspace.types';
import { useContextWorkspaceId } from './WorkspaceIdProvider';
import { useWorkspaceContentsMetadata } from './useWorkspaceContentsMetadata';


// configuration
const ENABLE_AUTO_WORKSPACE_PICK = false;


/**
 * Allows selection of LiveFiles in the current Workspace
 */
export function WorkspaceLiveFilePicker(props: {
  allowRemove?: boolean;
  autoSelectName: string | null;
  labelButton: string;
  labelTooltip?: string;
  liveFileId: LiveFileId | null;
  onSelectLiveFile: (id: LiveFileId | null) => Promise<void>;
  onSelectFileOpen: (workspaceId: DWorkspaceId | null) => Promise<void>;
  onSelectFileSystemFileHandle?: (workspaceId: DWorkspaceId | null, fsHandle: FileSystemFileHandle) => Promise<void>;
}) {

  // state for anchor
  const [menuAnchor, setMenuAnchor] = React.useState<null | HTMLElement>(null);

  // external state
  const workspaceId = useContextWorkspaceId();
  const { liveFilesMetadata: wLiveFiles } = useWorkspaceContentsMetadata(workspaceId);

  // set as disabled when empty
  const haveLiveFiles = wLiveFiles.length > 0;
  const { autoSelectName, liveFileId, onSelectLiveFile, onSelectFileOpen, onSelectFileSystemFileHandle } = props;


  // [effect] auto-select a LiveFileId
  React.useEffect(() => {
    if (!ENABLE_AUTO_WORKSPACE_PICK || !haveLiveFiles || !wLiveFiles.length)
      return;

    if (wLiveFiles.length === 1) {
      // auto-select the only LiveFile
      void onSelectLiveFile(wLiveFiles[0].id);
    } else {
      // auto-select by name
      const lfm = wLiveFiles.find(lfm => lfm.name === autoSelectName);
      if (lfm)
        void onSelectLiveFile(lfm.id);
    }
  }, [haveLiveFiles, wLiveFiles, autoSelectName, onSelectLiveFile]);


  // handlers

  const handleToggleMenu = React.useCallback((event: React.MouseEvent<HTMLElement>) => {
    event.preventDefault(); // added for the Right mouse click (to prevent the menu)
    setMenuAnchor(anchor => anchor ? null : event.currentTarget);
  }, []);

  const handleCloseMenu = React.useCallback(() => {
    setMenuAnchor(null);
  }, []);

  const handleSelectLiveFile = React.useCallback((id: LiveFileId | null) => {
    setMenuAnchor(null);
    void onSelectLiveFile(id);
  }, [onSelectLiveFile]);

  const handleSelectNewFile = React.useCallback(async () => {
    if (onSelectFileOpen) {
      setMenuAnchor(null);
      await onSelectFileOpen(workspaceId);
    }
  }, [onSelectFileOpen, workspaceId]);

  const handleDataTransferDrop = React.useCallback(async (dataTransfer: DataTransfer) => {
    if (onSelectFileSystemFileHandle) {
      const fsfHandle = await getFirstFileSystemFileHandle(dataTransfer);
      if (fsfHandle) {
        setMenuAnchor(null);
        await onSelectFileSystemFileHandle(workspaceId, fsfHandle);
      }
    }
  }, [onSelectFileSystemFileHandle, workspaceId]);

  const { dragContainerSx, dropComponent, handleContainerDragEnter, handleContainerDragStart } =
    useDragDropDataTransfer(true, 'Select', LiveFileChooseIcon as typeof SvgIcon, 'startDecorator', true, handleDataTransferDrop);

  // styles
  const containerSx = React.useMemo(() => ({
    ...dragContainerSx,
    display: 'flex',
    alignItems: 'center',
  }), [dragContainerSx]);


  const showRemove = !!liveFileId && props.allowRemove === true;

  return <>

    {/* Main Button, also a drop target */}
    <Box
      onDragEnter={handleContainerDragEnter}
      onDragStart={handleContainerDragStart}
      sx={containerSx}
    >
      {!liveFileId ? (
        <TooltipOutlined title={props.labelTooltip} placement='top-end'>
          <Button
            variant='plain'
            color='neutral'
            size='sm'
            onClick={handleToggleMenu}
            startDecorator={<LiveFileChooseIcon />}
            // endDecorator={<LiveFilePatchIcon color='success' />}
          >
            {props.labelButton}
          </Button>
        </TooltipOutlined>
      ) : (
        <IconButton
          size='sm'
          onClick={handleToggleMenu}
        >
          <LiveFileIcon />
          {/*<LiveFilePatchIcon color='success' />*/}
        </IconButton>
      )}

      {dropComponent}
    </Box>


    {/* Select/Upload file menu */}
    {!!menuAnchor && (
      <CloseablePopup
        menu anchorEl={menuAnchor} onClose={handleCloseMenu}
        placement='bottom-end'
        sx={{ '--ListItem-paddingRight': '1.5rem' }}
      >

        {/* Workspace Files (if any) */}
        <ListItem>
          <Typography level='body-sm'>Select Target:</Typography>
        </ListItem>

        {haveLiveFiles && wLiveFiles.map((lfm: LiveFileMetadata) => (
          <MenuItem
            key={lfm.id}
            selected={lfm.id === liveFileId}
            onClick={() => handleSelectLiveFile(lfm.id)}
            sx={{ border: 'none' }}
          >
            <ListItemDecorator><CodeIcon /></ListItemDecorator>
            {/*<Box>*/}
            {lfm.name}
            {/*<Box component='span' sx={{ fontSize: 'xs', display: 'block', color: 'text.tertiary' }}>*/}
            {/*  {lfm.size?.toLocaleString() || '(unknown)'} bytes {lfm.type ? `· ${lfm.type}` : ''}*/}
            {/*</Box>*/}
            {/*</Box>*/}
          </MenuItem>
        ))}

        {/* Pair a new file */}
        {haveLiveFiles && <ListDivider sx={{ my: 0 }} />}
        <MenuItem
          onClick={handleSelectNewFile}
          // sx={haveLiveFiles ? { minHeight: '3rem' } : undefined}
        >
          <ListItemDecorator>
            <LiveFileChooseIcon />
          </ListItemDecorator>
          Open File...
        </MenuItem>

        {/* Remove pairing */}
        {showRemove && (
          <MenuItem disabled={!liveFileId} onClick={() => handleSelectLiveFile(null)}>
            <ListItemDecorator><ClearIcon /></ListItemDecorator>
            Close
          </MenuItem>
        )}

      </CloseablePopup>
    )}

  </>;
}


================================================
FILE: src/common/styles/agi.effects.css
================================================
/* AGI processing - nice effects */
@property --rotate {
    syntax: "<angle>";
    initial-value: 132deg;
    inherits: false;
}

@keyframes rotation-loop {
    0% {
        --rotate: 0deg;
    }
    100% {
        --rotate: 360deg;
    }
}


/* Spinning effect, used while re-rendering images */

.agi-border-4 {
    /* config */
    --border-width: 4px;
    --border-radius: 2px;

    z-index: 0;
    position: relative;
    border-radius: var(--border-width);
}

.agi-border-4 > * {
    clip-path: inset(var(--border-width));
    border-radius: var(--border-radius);
    opacity: 0.94;
}

.agi-border-4::before {
    content: "";
    z-index: 0;
    position: absolute;
    inset: 0;
    border-radius: var(--border-radius);
    /*background-image: conic-gradient(*/
    /*        from var(--rotate),*/
    /*        #636B74, #0B6BCB, #1F7A1F*/
    /*);*/
    background-image: conic-gradient(
            from var(--rotate),
            violet, indigo, blue, green,
            yellow, orange, red, violet
    );
    animation: rotation-loop 2.5s linear infinite;
}


/* Simple highlight, used for <mark/> tags and ==highlighted== text  */
.agi-highlight {
    /*background-color: rgb(var(--agi-color-mark-highlight-channel));*/
    background: linear-gradient(
            104deg,
            rgba(var(--agi-color-mark-highlight-channel) / 0),
            rgba(var(--agi-color-mark-highlight-channel) / 1) 0.9%,
            rgba(var(--agi-color-mark-highlight-channel) / 1) 99.1%,
            rgba(var(--agi-color-mark-highlight-channel) / 0)
    );
    padding-block: 2px;
}

[data-joy-color-scheme="dark"] .agi-highlight {
    --agi-color-mark-highlight-channel: 118 108 0; /* 0 0 184; */
}

[data-joy-color-scheme="light"] .agi-highlight {
    --agi-color-mark-highlight-channel: 255 255 0;
}

/* Simple text content deletion */
.agi-content-delete {
    text-decoration: line-through;
    text-decoration-color: var(--color-danger-fg);
    /*text-decoration-thickness: 2px;*/
    font-style: italic;
}

/*.agi-highlight-yellow {*/
/*    background: linear-gradient(104deg, rgba(255,255,132,0) 0.9%, rgba(255,255,132,1) 2.4%, rgba(255,252,132,1) 50%, rgba(255,255,132,1) 97.6%, rgba(255,255,132,0) 99.1%);*/
/*    color: red;*/
/*}*/

/*.agi-border-4::after {*/
/*    content: "";*/
/*    z-index: -1;*/
/*    position: absolute;*/
/*    inset: 0;*/
/*    margin: 0 auto;*/
/*    transform: translate(0%, 20%) scale(0.8);*/
/*    filter: blur(48px);*/
/*    background-image: linear-gradient(var(--rotate), #5ddcff, #3c67e3 43%, #4e00c2);*/
/*    animation: rotation-loop 2.5s linear infinite;*/
/*}*/



================================================
FILE: src/common/styles/app.styles.css
================================================
:root {
    --AGI-Nav-width: 52px;
    /*noinspection CssInvalidFunction*/
    --AGI-Desktop-Drawer-width: round(clamp(260px, 18vw, 350px), 1px);
    /*noinspection CssInvalidFunction*/
    --AGI-Desktop-Panel-width: round(clamp(260px, 18vw, 350px), 1px);
    --AGI-Mobile-Drawer-width: 320px;
    --AGI-Mobile-Panel-width: 320px;
    --AGI-overlay-start-opacity: 0;
}

.agi-ellipsize {
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}

/* Prevents pull-to-refresh on mobile, so it's not triggered while scrolling the chat inadvertently */
body {
    overscroll-behavior-y: none;
}


================================================
FILE: src/common/styles/CodePrism.css
================================================
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
	/*color: black;*/
	/*background: none;*/
	/*text-shadow: 0 1px white;*/
	/*font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;*/
	/*font-size: 1em;*/
	/*text-align: left;*/
	/*white-space: pre;*/
	/*word-spacing: normal;*/
	/*word-break: normal;*/
	/*word-wrap: normal;*/
	/*line-height: 1.5;*/

	/*-moz-tab-size: 4;*/
	/*-o-tab-size: 4;*/
	/*tab-size: 4;*/

	/*-webkit-hyphens: none;*/
	/*-moz-hyphens: none;*/
	/*-ms-hyphens: none;*/
	/*hyphens: none;*/
}

/*pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,*/
/*code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {*/
/*	text-shadow: none;*/
/*	background: #b3d4fc;*/
/*}*/

/*pre[class*="language-"]::selection, pre[class*="language-"] ::selection,*/
/*code[class*="language-"]::selection, code[class*="language-"] ::selection {*/
/*	text-shadow: none;*/
/*	background: #b3d4fc;*/
/*}*/

@media print {
	code[class*="language-"],
	pre[class*="language-"] {
		text-shadow: none;
	}
}

/* Code blocks */
/*pre[class*="language-"] {*/
/*	padding: 1em;*/
/*	margin: .5em 0;*/
/*	overflow: auto;*/
/*}*/

/*:not(pre) > code[class*="language-"],*/
/*pre[class*="language-"] {*/
/*	background: #f5f2f0;*/
/*}*/

/*!* Inline code *!*/
/*:not(pre) > code[class*="language-"] {*/
/*	padding: .1em;*/
/*	border-radius: .3em;*/
/*	white-space: normal;*/
/*}*/

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: slategray;
}

.token.punctuation {
	color: #999;
}

.token.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
	color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
	color: #9a6e3a;
	/* This background color was intended by the author of this theme. */
	/*background: hsla(0, 0%, 100%, .5);*/
}

.token.atrule,
.token.attr-value,
.token.keyword {
	color: #07a;
}

.token.function,
.token.class-name {
	color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
	color: #e90;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}



================================================
FILE: src/common/styles/GithubMarkdown.css
================================================
/* NOTE: this CSS file has been forked from https://github.com/sindresorhus/github-markdown-css only to
 * enable programmatic switching between light and dark modes. The original file has a media query that
 * switches the theme based on the user's OS settings (but not the Joy UI theme). */

[data-joy-color-scheme="dark"] .markdown-body {
  color-scheme: dark;
  --color-prettylights-syntax-comment: #8b949e;
  --color-prettylights-syntax-constant: #79c0ff;
  --color-prettylights-syntax-entity: #d2a8ff;
  --color-prettylights-syntax-storage-modifier-import: #c9d1d9;
  --color-prettylights-syntax-entity-tag: #7ee787;
  --color-prettylights-syntax-keyword: #ff7b72;
  --color-prettylights-syntax-string: #a5d6ff;
  --color-prettylights-syntax-variable: #ffa657;
  --color-prettylights-syntax-brackethighlighter-unmatched: #f85149;
  --color-prettylights-syntax-invalid-illegal-text: #f0f6fc;
  --color-prettylights-syntax-invalid-illegal-bg: #8e1519;
  --color-prettylights-syntax-carriage-return-text: #f0f6fc;
  --color-prettylights-syntax-carriage-return-bg: #b62324;
  --color-prettylights-syntax-string-regexp: #7ee787;
  --color-prettylights-syntax-markup-list: #f2cc60;
  --color-prettylights-syntax-markup-heading: #1f6feb;
  --color-prettylights-syntax-markup-italic: #c9d1d9;
  --color-prettylights-syntax-markup-bold: #c9d1d9;
  --color-prettylights-syntax-markup-deleted-text: #ffdcd7;
  --color-prettylights-syntax-markup-deleted-bg: #67060c;
  --color-prettylights-syntax-markup-inserted-text: #aff5b4;
  --color-prettylights-syntax-markup-inserted-bg: #033a16;
  --color-prettylights-syntax-markup-changed-text: #ffdfb6;
  --color-prettylights-syntax-markup-changed-bg: #5a1e02;
  --color-prettylights-syntax-markup-ignored-text: #c9d1d9;
  --color-prettylights-syntax-markup-ignored-bg: #1158c7;
  --color-prettylights-syntax-meta-diff-range: #d2a8ff;
  --color-prettylights-syntax-brackethighlighter-angle: #8b949e;
  --color-prettylights-syntax-sublimelinter-gutter-mark: #484f58;
  --color-prettylights-syntax-constant-other-reference-link: #a5d6ff;
  --color-fg-default: #e6edf3;
  --color-fg-muted: #848d97;
  --color-fg-subtle: #6e7681;
  --color-canvas-default: #0d1117;
  --color-canvas-subtle: #161b22;
  --color-border-default: #30363d;
  --color-border-muted: #21262d;
  --color-neutral-muted: rgba(110,118,129,0.4);
  --color-accent-fg: #2f81f7;
  --color-accent-emphasis: #1f6feb;
  --color-success-fg: #3fb950;
  --color-success-emphasis: #238636;
  --color-attention-fg: #d29922;
  --color-attention-emphasis: #9e6a03;
  --color-attention-subtle: rgba(187,128,9,0.15);
  --color-danger-fg: #f85149;
  --color-danger-emphasis: #da3633;
  --color-done-fg: #a371f7;
  --color-done-emphasis: #8957e5;
}

[data-joy-color-scheme="light"] .markdown-body {
  color-scheme: light;
  --color-prettylights-syntax-comment: #57606a;
  --color-prettylights-syntax-constant: #0550ae;
  --color-prettylights-syntax-entity: #6639ba;
  --color-prettylights-syntax-storage-modifier-import: #24292f;
  --color-prettylights-syntax-entity-tag: #116329;
  --color-prettylights-syntax-keyword: #cf222e;
  --color-prettylights-syntax-string: #0a3069;
  --color-prettylights-syntax-variable: #953800;
  --color-prettylights-syntax-brackethighlighter-unmatched: #82071e;
  --color-prettylights-syntax-invalid-illegal-text: #f6f8fa;
  --color-prettylights-syntax-invalid-illegal-bg: #82071e;
  --color-prettylights-syntax-carriage-return-text: #f6f8fa;
  --color-prettylights-syntax-carriage-return-bg: #cf222e;
  --color-prettylights-syntax-string-regexp: #116329;
  --color-prettylights-syntax-markup-list: #3b2300;
  --color-prettylights-syntax-markup-heading: #0550ae;
  --color-prettylights-syntax-markup-italic: #24292f;
  --color-prettylights-syntax-markup-bold: #24292f;
  --color-prettylights-syntax-markup-deleted-text: #82071e;
  --color-prettylights-syntax-markup-deleted-bg: #ffebe9;
  --color-prettylights-syntax-markup-inserted-text: #116329;
  --color-prettylights-syntax-markup-inserted-bg: #dafbe1;
  --color-prettylights-syntax-markup-changed-text: #953800;
  --color-prettylights-syntax-markup-changed-bg: #ffd8b5;
  --color-prettylights-syntax-markup-ignored-text: #eaeef2;
  --color-prettylights-syntax-markup-ignored-bg: #0550ae;
  --color-prettylights-syntax-meta-diff-range: #8250df;
  --color-prettylights-syntax-brackethighlighter-angle: #57606a;
  --color-prettylights-syntax-sublimelinter-gutter-mark: #8c959f;
  --color-prettylights-syntax-constant-other-reference-link: #0a3069;
  --color-fg-default: #1F2328;
  --color-fg-muted: #656d76;
  --color-fg-subtle: #6e7781;
  --color-canvas-default: #ffffff;
  --color-canvas-subtle: #f6f8fa;
  --color-border-default: #d0d7de;
  --color-border-muted: hsla(210,18%,87%,1);
  --color-neutral-muted: rgba(175,184,193,0.2);
  --color-accent-fg: #0969da;
  --color-accent-emphasis: #0969da;
  --color-success-fg: #1a7f37;
  --color-success-emphasis: #1f883d;
  --color-attention-fg: #9a6700;
  --color-attention-emphasis: #9a6700;
  --color-attention-subtle: #fff8c5;
  --color-danger-fg: #d1242f;
  --color-danger-emphasis: #cf222e;
  --color-done-fg: #8250df;
  --color-done-emphasis: #8250df;
}



.markdown-body {
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  margin: 0;
  /* Big-AGI: Make sure a block is at least a rem tall */
  min-height: 1em;
  /* Big-AGI: Note: disabled because we have good CSS already */
  /*color: var(--color-fg-default);*/
  /*background-color: var(--color-canvas-default);*/
  /*font-family: -apple-system,BlinkMacSystemFont,"Segoe UI","Noto Sans",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji";*/
  /*font-size: 16px;*/
  /*line-height: 1.5;*/
  word-wrap: break-word;
}

.markdown-body .octicon {
  display: inline-block;
  fill: currentColor;
  vertical-align: text-bottom;
}

.markdown-body h1:hover .anchor .octicon-link:before,
.markdown-body h2:hover .anchor .octicon-link:before,
.markdown-body h3:hover .anchor .octicon-link:before,
.markdown-body h4:hover .anchor .octicon-link:before,
.markdown-body h5:hover .anchor .octicon-link:before,
.markdown-body h6:hover .anchor .octicon-link:before {
  width: 16px;
  height: 16px;
  content: ' ';
  display: inline-block;
  background-color: currentColor;
  -webkit-mask-image: url("data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' version='1.1' aria-hidden='true'><path fill-rule='evenodd' d='M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z'></path></svg>");
  mask-image: url("data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' version='1.1' aria-hidden='true'><path fill-rule='evenodd' d='M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z'></path></svg>");
}

.markdown-body details,
.markdown-body figcaption,
.markdown-body figure {
  display: block;
}

.markdown-body summary {
  display: list-item;
}

.markdown-body [hidden] {
  display: none !important;
}

.markdown-body a {
  background-color: transparent;
  color: var(--color-accent-fg);
  text-decoration: none;
}

.markdown-body abbr[title] {
  border-bottom: none;
  -webkit-text-decoration: underline dotted;
  text-decoration: underline dotted;
}

.markdown-body b,
.markdown-body strong {
  font-weight: 600;
}

.markdown-body dfn {
  font-style: italic;
}

.markdown-body h1 {
  margin: .67em 0;
  font-weight: 600;
  padding-bottom: .3em;
  font-size: 2em;
  border-bottom: 1px solid var(--color-border-muted);
}

.markdown-body mark {
  background-color: var(--color-attention-subtle);
  color: var(--color-fg-default);
}

.markdown-body small {
  font-size: 90%;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}

.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body sup {
  top: -0.5em;
}

.markdown-body img {
  border-style: none;
  max-width: 100%;
  box-sizing: content-box;
  background-color: var(--color-canvas-default);
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace;
  font-size: 1em;
}

.markdown-body figure {
  margin: 1em 40px;
}

.markdown-body hr {
  box-sizing: content-box;
  overflow: hidden;
  background: transparent;
  border-bottom: 1px solid var(--color-border-muted);
  height: .25em;
  padding: 0;
  /* big-AGI: was 24px -> 1.5em */
  margin: 1.5em 0;
  /*margin: 24px 0;*/
  background-color: var(--color-border-default);
  border: 0;
}

.markdown-body input {
  font: inherit;
  margin: 0;
  overflow: visible;
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}

.markdown-body [type=button],
.markdown-body [type=reset],
.markdown-body [type=submit] {
  -webkit-appearance: button;
}

.markdown-body [type=checkbox],
.markdown-body [type=radio] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body [type=number]::-webkit-inner-spin-button,
.markdown-body [type=number]::-webkit-outer-spin-button {
  height: auto;
}

.markdown-body [type=search]::-webkit-search-cancel-button,
.markdown-body [type=search]::-webkit-search-decoration {
  -webkit-appearance: none;
}

.markdown-body ::-webkit-input-placeholder {
  color: inherit;
  opacity: .54;
}

.markdown-body ::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

.markdown-body a:hover {
  text-decoration: underline;
}

.markdown-body ::placeholder {
  color: var(--color-fg-subtle);
  opacity: 1;
}

.markdown-body hr::before {
  display: table;
  content: "";
}

.markdown-body hr::after {
  display: table;
  clear: both;
  content: "";
}

.markdown-body table {
  border-spacing: 0;
  border-collapse: collapse;
  display: block;
  width: max-content;
  max-width: 100%;
  overflow: auto;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body details summary {
  cursor: pointer;
}

.markdown-body details:not([open])>*:not(summary) {
  display: none !important;
}

.markdown-body a:focus,
.markdown-body [role=button]:focus,
.markdown-body input[type=radio]:focus,
.markdown-body input[type=checkbox]:focus {
  outline: 2px solid var(--color-accent-fg);
  outline-offset: -2px;
  box-shadow: none;
}

.markdown-body a:focus:not(:focus-visible),
.markdown-body [role=button]:focus:not(:focus-visible),
.markdown-body input[type=radio]:focus:not(:focus-visible),
.markdown-body input[type=checkbox]:focus:not(:focus-visible) {
  outline: solid 1px transparent;
}

.markdown-body a:focus-visible,
.markdown-body [role=button]:focus-visible,
.markdown-body input[type=radio]:focus-visible,
.markdown-body input[type=checkbox]:focus-visible {
  outline: 2px solid var(--color-accent-fg);
  outline-offset: -2px;
  box-shadow: none;
}

.markdown-body a:not([class]):focus,
.markdown-body a:not([class]):focus-visible,
.markdown-body input[type=radio]:focus,
.markdown-body input[type=radio]:focus-visible,
.markdown-body input[type=checkbox]:focus,
.markdown-body input[type=checkbox]:focus-visible {
  outline-offset: 0;
}

.markdown-body kbd {
  display: inline-block;
  padding: 3px 5px;
  font: 11px ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;
  line-height: 10px;
  color: var(--color-fg-default);
  vertical-align: middle;
  background-color: var(--color-canvas-subtle);
  border: solid 1px var(--color-neutral-muted);
  border-bottom-color: var(--color-neutral-muted);
  border-radius: 6px;
  box-shadow: inset 0 -1px 0 var(--color-neutral-muted);
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  /* big-AGI: changed this to be more flexible with changing Block font size */
  margin-top: 1.2em;
  margin-bottom: 0.8em;
  /*margin-top: 24px;*/
  /*margin-bottom: 16px;*/
  font-weight: 600;
  line-height: 1.25;
}

.markdown-body h2 {
  font-weight: 600;
  padding-bottom: .3em;
  font-size: 1.5em;
  border-bottom: 1px solid var(--color-border-muted);
}

.markdown-body h3 {
  font-weight: 600;
  font-size: 1.25em;
}

.markdown-body h4 {
  font-weight: 600;
  font-size: 1em;
}

.markdown-body h5 {
  font-weight: 600;
  font-size: .875em;
}

.markdown-body h6 {
  font-weight: 600;
  font-size: .85em;
  color: var(--color-fg-muted);
}

.markdown-body p {
  margin-top: 0;
  margin-bottom: 10px;
}

.markdown-body blockquote {
  margin: 0;
  padding: 0 1em;
  color: var(--color-fg-muted);
  border-left: .25em solid var(--color-border-default);
}

.markdown-body ul,
.markdown-body ol {
  margin-top: 0;
  margin-bottom: 0;
  padding-left: 2em;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body tt,
.markdown-body code,
.markdown-body samp {
  /*font-family: ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;*/
  /*noinspection CssUnresolvedCustomProperty*/
  font-family: var(--joy-fontFamily-code),ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
  /*font-family: ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;*/
  /*noinspection CssUnresolvedCustomProperty*/
  font-family: var(--joy-fontFamily-code),ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;
  font-size: 12px;
  word-wrap: normal;
}

.markdown-body .octicon {
  display: inline-block;
  overflow: visible !important;
  vertical-align: text-bottom;
  fill: currentColor;
}

.markdown-body input::-webkit-outer-spin-button,
.markdown-body input::-webkit-inner-spin-button {
  margin: 0;
  -webkit-appearance: none;
  appearance: none;
}

.markdown-body::before {
  display: table;
  content: "";
}

.markdown-body::after {
  display: table;
  clear: both;
  content: "";
}

/* big-AGI: NOTE: we are doing this only on the <p> tags because otherwise
   this collapses the space between blocks */
.markdown-body>p:first-child {
  margin-top: 0 !important;
}

.markdown-body>p:last-child {
  margin-bottom: 0 !important;
}

/*.markdown-body>*:first-child {*/
/*  margin-top: 0 !important;*/
/*}*/

/*.markdown-body>*:last-child {*/
/*  margin-bottom: 0 !important;*/
/*}*/


.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body .absent {
  color: var(--color-danger-fg);
}

.markdown-body .anchor {
  float: left;
  padding-right: 4px;
  margin-left: -20px;
  line-height: 1;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body details {
  margin-top: 0;
  /* big-AGI: was 16px -> 1em*/
  margin-bottom: 1em;
  /*margin-bottom: 16px;*/
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

/* big-AGI: even the margins if there are no siblings */
.markdown-body ul:first-child:last-child,
.markdown-body ol:first-child:last-child {
  margin-top: 0.5em;
  margin-bottom: 0.5em;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: var(--color-fg-default);
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
  visibility: visible;
}

.markdown-body h1 tt,
.markdown-body h1 code,
.markdown-body h2 tt,
.markdown-body h2 code,
.markdown-body h3 tt,
.markdown-body h3 code,
.markdown-body h4 tt,
.markdown-body h4 code,
.markdown-body h5 tt,
.markdown-body h5 code,
.markdown-body h6 tt,
.markdown-body h6 code {
  padding: 0 .2em;
  font-size: inherit;
}

.markdown-body summary h1,
.markdown-body summary h2,
.markdown-body summary h3,
.markdown-body summary h4,
.markdown-body summary h5,
.markdown-body summary h6 {
  display: inline-block;
}

.markdown-body summary h1 .anchor,
.markdown-body summary h2 .anchor,
.markdown-body summary h3 .anchor,
.markdown-body summary h4 .anchor,
.markdown-body summary h5 .anchor,
.markdown-body summary h6 .anchor {
  margin-left: -40px;
}

.markdown-body summary h1,
.markdown-body summary h2 {
  padding-bottom: 0;
  border-bottom: 0;
}

.markdown-body ul.no-list,
.markdown-body ol.no-list {
  padding: 0;
  list-style-type: none;
}

.markdown-body ol[type="a s"] {
  list-style-type: lower-alpha;
}

.markdown-body ol[type="A s"] {
  list-style-type: upper-alpha;
}

.markdown-body ol[type="i s"] {
  list-style-type: lower-roman;
}

.markdown-body ol[type="I s"] {
  list-style-type: upper-roman;
}

.markdown-body ol[type="1"] {
  list-style-type: decimal;
}

.markdown-body div>ol:not([type]) {
  list-style-type: decimal;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body li+li {
  margin-top: .25em;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: 600;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body table th {
  font-weight: 600;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid var(--color-border-default);
}

.markdown-body table td>:last-child {
  margin-bottom: 0;
}

.markdown-body table tr {
  background-color: var(--color-canvas-default);
  border-top: 1px solid var(--color-border-muted);
}

.markdown-body table tr:nth-child(2n) {
  background-color: var(--color-canvas-subtle);
}

.markdown-body table img {
  background-color: transparent;
}

.markdown-body img[align=right] {
  padding-left: 20px;
}

.markdown-body img[align=left] {
  padding-right: 20px;
}

.markdown-body .emoji {
  max-width: none;
  vertical-align: text-top;
  background-color: transparent;
}

.markdown-body span.frame {
  display: block;
  overflow: hidden;
}

.markdown-body span.frame>span {
  display: block;
  float: left;
  width: auto;
  padding: 7px;
  margin: 13px 0 0;
  overflow: hidden;
  border: 1px solid var(--color-border-default);
}

.markdown-body span.frame span img {
  display: block;
  float: left;
}

.markdown-body span.frame span span {
  display: block;
  padding: 5px 0 0;
  clear: both;
  color: var(--color-fg-default);
}

.markdown-body span.align-center {
  display: block;
  overflow: hidden;
  clear: both;
}

.markdown-body span.align-center>span {
  display: block;
  margin: 13px auto 0;
  overflow: hidden;
  text-align: center;
}

.markdown-body span.align-center span img {
  margin: 0 auto;
  text-align: center;
}

.markdown-body span.align-right {
  display: block;
  overflow: hidden;
  clear: both;
}

.markdown-body span.align-right>span {
  display: block;
  margin: 13px 0 0;
  overflow: hidden;
  text-align: right;
}

.markdown-body span.align-right span img {
  margin: 0;
  text-align: right;
}

.markdown-body span.float-left {
  display: block;
  float: left;
  margin-right: 13px;
  overflow: hidden;
}

.markdown-body span.float-left span {
  margin: 13px 0 0;
}

.markdown-body span.float-right {
  display: block;
  float: right;
  margin-left: 13px;
  overflow: hidden;
}

.markdown-body span.float-right>span {
  display: block;
  margin: 13px auto 0;
  overflow: hidden;
  text-align: right;
}

.markdown-body code,
.markdown-body tt {
  padding: .2em .4em;
  margin: 0;
  font-size: 85%;
  white-space: break-spaces;
  background-color: var(--color-neutral-muted);
  border-radius: 6px;
}

.markdown-body code br,
.markdown-body tt br {
  display: none;
}

.markdown-body del code {
  text-decoration: inherit;
}

.markdown-body samp {
  font-size: 85%;
}

.markdown-body pre code {
  font-size: 100%;
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  color: var(--color-fg-default);
  background-color: var(--color-canvas-subtle);
  border-radius: 6px;
}

.markdown-body pre code,
.markdown-body pre tt {
  display: inline;
  /*max-width: auto;*/
  padding: 0;
  margin: 0;
  overflow: visible;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body .csv-data td,
.markdown-body .csv-data th {
  padding: 5px;
  overflow: hidden;
  font-size: 12px;
  line-height: 1;
  text-align: left;
  white-space: nowrap;
}

.markdown-body .csv-data .blob-num {
  padding: 10px 8px 9px;
  text-align: right;
  background: var(--color-canvas-default);
  border: 0;
}

.markdown-body .csv-data tr {
  border-top: 0;
}

.markdown-body .csv-data th {
  font-weight: 600;
  background: var(--color-canvas-subtle);
  border-top: 0;
}

.markdown-body [data-footnote-ref]::before {
  content: "[";
}

.markdown-body [data-footnote-ref]::after {
  content: "]";
}

.markdown-body .footnotes {
  font-size: 12px;
  color: var(--color-fg-muted);
  border-top: 1px solid var(--color-border-default);
}

.markdown-body .footnotes ol {
  padding-left: 16px;
}

.markdown-body .footnotes ol ul {
  display: inline-block;
  padding-left: 16px;
  margin-top: 16px;
}

.markdown-body .footnotes li {
  position: relative;
}

.markdown-body .footnotes li:target::before {
  position: absolute;
  top: -8px;
  right: -8px;
  bottom: -8px;
  left: -24px;
  pointer-events: none;
  content: "";
  border: 2px solid var(--color-accent-emphasis);
  border-radius: 6px;
}

.markdown-body .footnotes li:target {
  color: var(--color-fg-default);
}

.markdown-body .footnotes .data-footnote-backref g-emoji {
  font-family: monospace;
}

.markdown-body .pl-c {
  color: var(--color-prettylights-syntax-comment);
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
  color: var(--color-prettylights-syntax-constant);
}

.markdown-body .pl-e,
.markdown-body .pl-en {
  color: var(--color-prettylights-syntax-entity);
}

.markdown-body .pl-smi,
.markdown-body .pl-s .pl-s1 {
  color: var(--color-prettylights-syntax-storage-modifier-import);
}

.markdown-body .pl-ent {
  color: var(--color-prettylights-syntax-entity-tag);
}

.markdown-body .pl-k {
  color: var(--color-prettylights-syntax-keyword);
}

.markdown-body .pl-s,
.markdown-body .pl-pds,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sre,
.markdown-body .pl-sr .pl-sra {
  color: var(--color-prettylights-syntax-string);
}

.markdown-body .pl-v,
.markdown-body .pl-smw {
  color: var(--color-prettylights-syntax-variable);
}

.markdown-body .pl-bu {
  color: var(--color-prettylights-syntax-brackethighlighter-unmatched);
}

.markdown-body .pl-ii {
  color: var(--color-prettylights-syntax-invalid-illegal-text);
  background-color: var(--color-prettylights-syntax-invalid-illegal-bg);
}

.markdown-body .pl-c2 {
  color: var(--color-prettylights-syntax-carriage-return-text);
  background-color: var(--color-prettylights-syntax-carriage-return-bg);
}

.markdown-body .pl-sr .pl-cce {
  font-weight: bold;
  color: var(--color-prettylights-syntax-string-regexp);
}

.markdown-body .pl-ml {
  color: var(--color-prettylights-syntax-markup-list);
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
  font-weight: bold;
  color: var(--color-prettylights-syntax-markup-heading);
}

.markdown-body .pl-mi {
  font-style: italic;
  color: var(--color-prettylights-syntax-markup-italic);
}

.markdown-body .pl-mb {
  font-weight: bold;
  color: var(--color-prettylights-syntax-markup-bold);
}

.markdown-body .pl-md {
  color: var(--color-prettylights-syntax-markup-deleted-text);
  background-color: var(--color-prettylights-syntax-markup-deleted-bg);
}

.markdown-body .pl-mi1 {
  color: var(--color-prettylights-syntax-markup-inserted-text);
  background-color: var(--color-prettylights-syntax-markup-inserted-bg);
}

.markdown-body .pl-mc {
  color: var(--color-prettylights-syntax-markup-changed-text);
  background-color: var(--color-prettylights-syntax-markup-changed-bg);
}

.markdown-body .pl-mi2 {
  color: var(--color-prettylights-syntax-markup-ignored-text);
  background-color: var(--color-prettylights-syntax-markup-ignored-bg);
}

.markdown-body .pl-mdr {
  font-weight: bold;
  color: var(--color-prettylights-syntax-meta-diff-range);
}

.markdown-body .pl-ba {
  color: var(--color-prettylights-syntax-brackethighlighter-angle);
}

.markdown-body .pl-sg {
  color: var(--color-prettylights-syntax-sublimelinter-gutter-mark);
}

.markdown-body .pl-corl {
  text-decoration: underline;
  color: var(--color-prettylights-syntax-constant-other-reference-link);
}

.markdown-body g-emoji {
  display: inline-block;
  min-width: 1ch;
  font-family: "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", serif;
  font-size: 1em;
  font-style: normal !important;
  font-weight: 400;
  line-height: 1;
  vertical-align: -0.075em;
}

.markdown-body g-emoji img {
  width: 1em;
  height: 1em;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item label {
  font-weight: 400;
}

.markdown-body .task-list-item.enabled label {
  cursor: pointer;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 4px;
}

.markdown-body .task-list-item .handle {
  display: none;
}

.markdown-body .task-list-item-checkbox {
  margin: 0 .2em .25em -1.4em;
  vertical-align: middle;
}

.markdown-body .contains-task-list:dir(rtl) .task-list-item-checkbox {
  margin: 0 -1.6em .25em .2em;
}

.markdown-body .contains-task-list {
  position: relative;
}

.markdown-body .contains-task-list:hover .task-list-item-convert-container,
.markdown-body .contains-task-list:focus-within .task-list-item-convert-container {
  display: block;
  width: auto;
  height: 24px;
  overflow: visible;
  clip: auto;
}

.markdown-body ::-webkit-calendar-picker-indicator {
  filter: invert(50%);
}

.markdown-body .markdown-alert {
  /*padding: var(--base-size-8) var(--base-size-16);*/
  margin-bottom: 16px;
  color: inherit;
  border-left: .25em solid var(--color-border-default);
}

.markdown-body .markdown-alert>:first-child {
  margin-top: 0;
}

.markdown-body .markdown-alert>:last-child {
  margin-bottom: 0;
}

.markdown-body .markdown-alert .markdown-alert-title {
  display: flex;
  font-weight: 500;
  align-items: center;
  line-height: 1;
}

.markdown-body .markdown-alert.markdown-alert-note {
  border-left-color: var(--color-accent-emphasis);
}

.markdown-body .markdown-alert.markdown-alert-note .markdown-alert-title {
  color: var(--color-accent-fg);
}

.markdown-body .markdown-alert.markdown-alert-important {
  border-left-color: var(--color-done-emphasis);
}

.markdown-body .markdown-alert.markdown-alert-important .markdown-alert-title {
  color: var(--color-done-fg);
}

.markdown-body .markdown-alert.markdown-alert-warning {
  border-left-color: var(--color-attention-emphasis);
}

.markdown-body .markdown-alert.markdown-alert-warning .markdown-alert-title {
  color: var(--color-attention-fg);
}

.markdown-body .markdown-alert.markdown-alert-tip {
  border-left-color: var(--color-success-emphasis);
}

.markdown-body .markdown-alert.markdown-alert-tip .markdown-alert-title {
  color: var(--color-success-fg);
}

.markdown-body .markdown-alert.markdown-alert-caution {
  border-left-color: var(--color-danger-emphasis);
}

.markdown-body .markdown-alert.markdown-alert-caution .markdown-alert-title {
  color: var(--color-danger-fg);
}


================================================
FILE: src/common/styles/NProgress.css
================================================
/**
 * This is the Big-AGI customized nprogress.css file.
 * We only change the height and color of the bar.
 */

/* Make clicks pass-through */
#nprogress {
    --barColor: #32383E;
    --barHeight: 4px;
    pointer-events: none;
}

#nprogress .bar {
    background: var(--barColor);

    position: fixed;
    z-index: 1031;
    top: 0;
    left: 0;

    width: 100%;
    height: var(--barHeight);
}

/* Fancy blur effect */
#nprogress .peg {
    display: block;
    position: absolute;
    right: 0;
    width: 100px;
    height: 100%;
    box-shadow: 0 0 10px var(--barColor), 0 0 5px var(--barColor);
    opacity: 1.0;

    -ms-transform: rotate(3deg) translate(0px, -4px);
    transform: rotate(3deg) translate(0px, -4px);
}



================================================
FILE: src/common/tokens/tokens.image.ts
================================================
import type { DLLM } from '~/common/stores/llms/llms.types';


export function imageTokensForLLM(width: number | undefined, height: number | undefined, debugTitle: string | undefined, llm: DLLM) {
  // for the guidelines, see `attachment.pipeline.ts` (lists the latest URLs)
  // Note: we may resolve the service or use the access, for non-OpenAI services even if they're on the OpenAI protocol
  switch (llm.vId) {
    case 'openai':
      // missing values
      if (!width || !height) {
        console.log(`Missing width or height for openai image tokens calculation (${debugTitle || 'no title'})`);
        return 85;
      }
      // 'detail: low' mode, has an image of (or up to) 512x512 -> 85 tokens
      if (width <= 512 && height <= 512)
        return 85;
      // 'detail: high' mode, cover the image with 512x512 patches of 170 tokens, in addition to the 85
      const patchesX = Math.ceil(width / 512);
      const patchesY = Math.ceil(height / 512);
      return 85 + patchesX * patchesY * 170;

    case 'anthropic':
      // Recommended image sizes:
      // https://docs.anthropic.com/en/docs/build-with-claude/vision
      // - Max: 1568px on long edge
      // - Optimal: ≤1.15 megapixels (e.g., 1092x1092, 951x1268, 896x1344, 819x1456, 784x1568)
      // - Min: >200px on both edges

      // Max case as fallback
      if (!width || !height) {
        // console.log(`Missing width or height for Anthropic image tokens calculation (${debugTitle || 'no title'})`);
        return 1600;
      }

      // Calculate tokens based on image size
      const megapixels = (width * height) / 1000000;
      const tokens = Math.min(Math.round((width * height) / 750), 1600);

      // Max case for oversized images
      if (megapixels > 1.15) {
        // console.log(`Image exceeds recommended size for Anthropic (${debugTitle || 'no title'})`);
        return 1600;
      }
      // if (width < 200 || height < 200) {
      //   console.log(`Image may be too small for optimal Anthropic performance (${debugTitle || 'no title'})`);
      // }

      return tokens;

    case 'googleai':
      // Inferred from the Gemini Videos description, but not sure
      return 258;

    default:
      console.log(`[DEV] Unhandled token preview for image with llm: ${llm.vId}`);
      return 0;
  }
}



================================================
FILE: src/common/tokens/tokens.text.ts
================================================
import type { Tiktoken, TiktokenEncoding, TiktokenModel } from 'tiktoken';

import type { DLLM } from '~/common/stores/llms/llms.types';
import { getAllModelParameterValues } from '~/common/stores/llms/llms.parameters';


// Do not set this to true in production, it's very verbose
const DEBUG_TOKEN_COUNT = false;
const fallbackEncodingId: TiktokenEncoding = 'cl100k_base';


// Global symbols to dynamically load the Tiktoken library
let get_encoding: ((encoding: TiktokenEncoding) => Tiktoken) | null = null;
let encoding_for_model: ((model: TiktokenModel) => Tiktoken) | null = null;
let preloadPromise: Promise<void> | null = null;
let informTheUser = false;

/**
 * Preloads the Tiktoken library if not already loaded.
 * @returns {Promise<void>} A promise that resolves when the library is loaded.
 */
export function preloadTiktokenLibrary(): Promise<void> {
  if (!preloadPromise) {
    preloadPromise = import('tiktoken')
      .then(tiktoken => {
        get_encoding = tiktoken.get_encoding;
        encoding_for_model = tiktoken.encoding_for_model;
        if (informTheUser)
          console.warn('countModelTokens: Library loaded successfully');
      })
      .catch(error => {
        console.error('countModelTokens: Failed to load Tiktoken library:', error);
        preloadPromise = null; // Allow retrying if the import fails
        throw error; // Re-throw the error to inform the caller
      });
  }
  return preloadPromise;
}


/**
 * Wrapper around the Tiktoken library to keep tokenizers for all models and tokenizers in a cache.
 */
const tokenEncoders: { [modelId: string]: Tiktoken } = {};
const tokenizerCache: { [encodingId: string]: Tiktoken } = {};


/**
 * Counts the tokens in the given text for the specified model.
 * @param {string} text - The text to tokenize.
 * @param llm - The LLM to use for tokenization count.
 * @param {string} debugFrom - Debug information.
 * @returns {number | null} The token count or null if not ready.
 */
export function textTokensForLLM(text: string, llm: DLLM, debugFrom: string): number | null {
  // The library shall have been preloaded - if not, attempt to start its loading and return null to indicate we're not ready to count
  if (!encoding_for_model || !get_encoding) {
    if (!informTheUser) {
      console.warn('textTokensForLLM: Tiktoken library is not yet loaded, loading now...');
      informTheUser = true;
    }
    void preloadTiktokenLibrary(); // Attempt to preload without waiting.
    return null;
  }

  // Validate input
  const llmParameters = getAllModelParameterValues(llm.initialParameters, llm.userParameters);
  const openaiModel = llmParameters.llmRef;
  if (!openaiModel) {
    console.warn(`textTokensForLLM: LLM ${llm?.id} has no LLM reference id`);
    return null;
  }

  if (!(openaiModel in tokenEncoders)) {
    try {
      tokenEncoders[openaiModel] = encoding_for_model(openaiModel as TiktokenModel);
    } catch (e) {
      // Fallback to a known tokenizer if the model is not found
      if (!(fallbackEncodingId in tokenizerCache))
        tokenizerCache[fallbackEncodingId] = get_encoding(fallbackEncodingId);
      tokenEncoders[openaiModel] = tokenizerCache[fallbackEncodingId];
    }
  }

  // Note: the try/catch shouldn't be necessary, but there could be corner cases where the tiktoken library throws
  // https://github.com/enricoros/big-agi/issues/182
  let count = 0;
  try {
    count = tokenEncoders[openaiModel]?.encode(text, 'all', [])?.length || 0;
  } catch (e) {
    console.warn(`textTokensForLLM: Error tokenizing "${text.slice(0, 10)}..." with model '${openaiModel}': ${e}`);
  }
  if (DEBUG_TOKEN_COUNT)
    console.log(`textTokensForLLM: ${debugFrom}, ${llm?.id}, "${text.slice(0, 10)}": ${count}`);
  return count;
}


/**
 * Counts the tokens in the given text for the specified tokenizer.
 * @param {string} text - The text to tokenize.
 * @param {string} encodingId - The ID of the tokenizer.
 * @param {string} debugFrom - Debug information.
 * @returns {Array<{ token: number, bytes: string }> | null} The detailed token information or null if not ready.
 */
export function textTokensForEncodingId(text: string, encodingId: string, debugFrom: string): Array<UITokenChunk> | null {
  // The library shall have been preloaded - if not, attempt to start its loading and return null to indicate we're not ready to count
  if (!get_encoding) {
    if (!informTheUser) {
      console.warn('textTokensForEncodingId: Tiktoken library is not yet loaded, loading now...');
      informTheUser = true;
    }
    void preloadTiktokenLibrary(); // Attempt to preload without waiting.
    return null;
  }

  if (!(encodingId in tokenizerCache)) {
    try {
      tokenizerCache[encodingId] = get_encoding(encodingId as TiktokenEncoding);
    } catch (e) {
      console.error(`textTokensForEncodingId: Error initializing tokenizer "${encodingId}": ${e}`);
      return null;
    }
  }

  try {
    const tokens = tokenizerCache[encodingId]?.encode(text, 'all', []) || new Uint32Array();
    if (DEBUG_TOKEN_COUNT)
      console.log(`textTokensForEncodingId: ${debugFrom}, ${encodingId}, "${text.slice(0, 10)}": ${tokens.length}`);

    // for every token create an object {t:token, b: bytes}
    const tokenDetails: UITokenChunk[] = [];
    for (let i = 0; i < tokens.length; i++) {
      const bytesForToken = tokenizerCache[encodingId].decode_single_token_bytes(tokens[i]);
      const stringForToken = String.fromCharCode(...bytesForToken);
      tokenDetails.push({
        token: tokens[i],
        chunk: stringForToken,
        bytes: bytesForToken.join(', '),
      });
    }
    return tokenDetails;
  } catch (e) {
    console.error(`textTokensForEncodingId: Error tokenizing "${text.slice(0, 10)}..." with tokenizer '${encodingId}': ${e}`);
    return null;
  }
}

interface UITokenChunk {
  token: number;
  chunk: string;
  bytes: string;
}


================================================
FILE: src/common/tokens/useTokenizerSelect.tsx
================================================
import * as React from 'react';
import type { TiktokenEncoding } from 'tiktoken';

import type { SxProps } from '@mui/joy/styles/types';
import { FormControl, Option, Select } from '@mui/joy';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';


// Globals
interface TiktokenTokenizer {
  id: TiktokenEncoding;
  label: string;
  exampleNet?: string;
}

export const TiktokenTokenizers: TiktokenTokenizer[] = [
  { id: 'o200k_base', label: 'O200k Base', exampleNet: 'GPT-4o' },
  { id: 'cl100k_base', label: 'CL100k Base' },
  { id: 'p50k_edit', label: 'P50k Edit' },
  { id: 'p50k_base', label: 'P50k Base' },
  { id: 'r50k_base', label: 'R50k Base' },
  { id: 'gpt2', label: 'GPT-2' },
];


const tokenizerSelectSx: SxProps = {
  flex: 1,
  backgroundColor: 'background.popup',
};


/**
 * Select the Tokenizer
 *
 * @param initialTokenizerId (optional) the Tokenizer id
 * @param label label of the select, use '' to hide it
 * @param smaller if true, the select is smaller
 * @param disabled
 * @param placeholder placeholder of the select
 * @param isHorizontal if true, the select is horizontal (label - select)
 */
export function useTokenizerSelect(
  initialTokenizerId: TiktokenEncoding | null = null,
  label: string = 'Encoding',
  smaller: boolean = false,
  disabled: boolean = false,
  placeholder: string = 'Tokenizers …',
  isHorizontal: boolean = false,
): [string | null, string | null, React.JSX.Element | null] {

  // local state
  const [tokenizerId, setTokenizerId] = React.useState<string | null>(initialTokenizerId ? initialTokenizerId : TiktokenTokenizers[0].id);


  // derived state
  const selectedTokenizer = TiktokenTokenizers.find(t => t.id === tokenizerId);


  // callbacks
  const onSelectChange = React.useCallback((_event: unknown, value: string | null) => setTokenizerId(value), []);


  // memoed components
  const componentOptions = React.useMemo(() => {
    return TiktokenTokenizers.map(tokenizer => (
      <Option key={'tokenizer-' + tokenizer.id} value={tokenizer.id}>
        OpenAI · {tokenizer.label}
      </Option>
    ));
  }, []);

  const tokenizerSelectComponent = React.useMemo(() => (
    <FormControl orientation={isHorizontal ? 'horizontal' : undefined}>
      {!!label && <FormLabelStart title={label} />}
      <Select
        variant='outlined'
        value={tokenizerId}
        size={smaller ? 'sm' : undefined}
        disabled={disabled}
        onChange={onSelectChange}
        placeholder={placeholder}
        slotProps={{
          listbox: {
            sx: {
              '--ListItem-paddingLeft': '1rem',
              '--ListItem-minHeight': '2.5rem',
            },
          },
          button: {
            sx: {
              whiteSpace: 'inherit',
            },
          },
        }}
        sx={tokenizerSelectSx}
      >
        {componentOptions}
      </Select>
    </FormControl>
  ), [tokenizerId, componentOptions, disabled, isHorizontal, label, onSelectChange, placeholder, smaller]);

  return [tokenizerId, selectedTokenizer?.label || null, tokenizerSelectComponent];
}


================================================
FILE: src/common/types/immutable.types.ts
================================================
/**
 * Deep immutable type. Usage example: Immutable<DConversation[]>
 */
export type Immutable<T> =
  T extends (...args: any[]) => any ? T  // function types as-is
    : T extends Array<infer U> ? ReadonlyArray<Immutable<U>> // convert arrays into ReadonlyArray
      : T extends Map<infer K, infer V> ? ReadonlyMap<Immutable<K>, Immutable<V>>
        : T extends Set<infer M> ? ReadonlySet<Immutable<M>>
          : T extends object ? { readonly [K in keyof T]: Immutable<T[K]> }  // objects: recursively mark properties as readonly
            : T; // Primitives remain the same



================================================
FILE: src/common/types/next.page.d.ts
================================================
import type { ReactElement, ReactNode } from 'react';
import type { NextPage } from 'next';
import type { EmotionCache } from '@emotion/react';


export type NextPageWithLayout<P = {}, IP = P> = NextPage<P, IP> & {
  // definition of the per-page layout function, as per:
  // https://nextjs.org/docs/pages/building-your-application/routing/pages-and-layouts#per-page-layouts
  getLayout?: (page: ReactElement) => ReactNode;
}

// Extend the AppProps type with the custom page component type
declare module 'next/app' {
  import { AppProps } from 'next/app';

  type MyAppProps = AppProps & {
    Component: NextPageWithLayout
    emotionCache?: EmotionCache;
  };
}



================================================
FILE: src/common/types/useful.types.ts
================================================
// Useful types that are not specific to us

/**
 * Could be a value (or void) or a promise of it
 */
export type MaybePromise<T> = T | Promise<T>;

/**
 * In our app 'undefined' and 'null' must be different, so we don't use 'Maybe' type
 * - undefined: missing value, never read, etc.
 * - null: means 'force no value', 'force empty', etc.
 */
// export type Maybe<T> = T | null | undefined;



================================================
FILE: src/common/util/animUtils.ts
================================================
import { keyframes } from '@emotion/react';


// Color

export const animationColorBeamScatterINV = keyframes`
    100%, 0% {
        color: rgb(219, 255, 77);
    }
    25% {
        color: rgb(255, 255, 128);
    }
    50% {
        color: rgba(128, 255, 153);
    }
    75% {
        color: rgb(255, 204, 77);
    }`;

export const animationColorBeamScatter = keyframes`
    100%, 0% {
        color: rgb(85, 140, 47); // A rich, dark green
    }
    25% {
        color: rgb(75, 115, 35); // A slightly desaturated green for contrast
    }
    50% {
        color: rgba(65, 155, 55); // A brighter, more saturated green with slight transparency
    }
    75% {
        color: rgb(95, 130, 40); // A blend between the first and third colors for a smooth transition
    }`;

export const animationColorBeamGather = keyframes`
    100%, 0% {
        color: rgb(102, 0, 51);
    }
    25% {
        color: rgb(76, 0, 76);
    }
    50% {
        color: rgb(63, 0, 128);
    }
    75% {
        color: rgb(0, 0, 128);
    }`;

export const animationColorBlues = keyframes`
    0%, 100% {
        color: #636B74; /* Neutral main color (500) */
    }
    25% {
        color: #12467B; /* Primary darker shade (700) */
    }
    50% {
        color: #0B6BCB; /* Primary main color (500) */
    }
    75% {
        color: #083e75; /* Primary lighter shade (300) */
    }`;

export const animationColorRainbow = keyframes`
    100%, 0% {
        color: rgb(255, 0, 0);
    }
    8% {
        color: rgb(204, 102, 0);
    }
    16% {
        color: rgb(128, 128, 0);
    }
    25% {
        color: rgb(77, 153, 0);
    }
    33% {
        color: rgb(0, 179, 0);
    }
    41% {
        color: rgb(0, 153, 82);
    }
    50% {
        color: rgb(0, 128, 128);
    }
    58% {
        color: rgb(0, 102, 204);
    }
    66% {
        color: rgb(0, 0, 255);
    }
    75% {
        color: rgb(127, 0, 255);
    }
    83% {
        color: rgb(153, 0, 153);
    }
    91% {
        color: rgb(204, 0, 102);
    }`;

/*export const animationColorLimey = keyframes`
    100%, 0% {
        color: rgb(183, 255, 0);
    }
    25% {
        color: rgb(255, 251, 0);
    }
    50% {
        color: rgba(0, 255, 81);
    }
    75% {
        color: rgb(255, 153, 0);
    }`;
*/


// Background-Color

export const animationBackgroundBeamGather = keyframes`
    100%, 0% {
        background-color: rgb(102, 0, 51);
    }
    25% {
        background-color: rgb(76, 0, 76);
    }
    50% {
        background-color: rgb(63, 0, 128);
    }
    75% {
        background-color: rgb(0, 0, 128);
    }`;

export const animationBackgroundCameraFlash = keyframes`
    15% {
        background-color: rgba(0, 0, 0, 1);
    }
    35% {
        background-color: rgba(255, 255, 255, 0.9);
    }
    100% {
        background-color: transparent;
    }
`;

/*export const animationBackgroundDarkerRainbow = keyframes`
    100%, 0% {
        background-color: rgb(128, 0, 0);
    }
    8% {
        background-color: rgb(102, 51, 0);
    }
    16% {
        background-color: rgb(64, 64, 0);
    }
    25% {
        background-color: rgb(38, 76, 0);
    }
    33% {
        background-color: rgb(0, 89, 0);
    }
    41% {
        background-color: rgb(0, 76, 41);
    }
    50% {
        background-color: rgb(0, 64, 64);
    }
    58% {
        background-color: rgb(0, 51, 102);
    }
    66% {
        background-color: rgb(0, 0, 128);
    }
    75% {
        background-color: rgb(63, 0, 128);
    }
    83% {
        background-color: rgb(76, 0, 76);
    }
    91% {
        background-color: rgb(102, 0, 51);
    }`;*/


// Opactiy

export const animationOpacityFadeIn = keyframes`
    from {
        opacity: 0;
    }
    to {
        opacity: 1;
    }`;

// Transform

export const animationEnterBelow = keyframes`
    from {
        opacity: 0;
        transform: translateY(8px)
    }
    to {
        opacity: 1;
        transform: translateY(0)
    }
`;

export const animationEnterModal = keyframes`
    from, 50%, to {
        animation-timing-function: cubic-bezier(.215, .61, .355, 1) // ease-out
    }
    0% {
        opacity: .91;
        transform: scale3d(.98, .98, .98)
    }
    70% {
        opacity: 1;
        transform: scale3d(1.04, 1.04, 1.04)
    }
    to {
        transform: none;
    }
`;

export const animationOpacityPulse = keyframes`
    0% {
        opacity: 1;
    }
    50% {
        opacity: 0.7;
    }
    100% {
        opacity: 1;
    }`;

export const animationScalePulse = keyframes`
    0%, 100% {
        transform: scale(1);
    }
    50% {
        transform: scale(1.2);
    }`;

export const animationEnterScaleUp = keyframes`
    0% {
        //opacity: 0;
        //transform: translateY(8px);
        scale: 0.98;
        //rotate: -5deg;
    }
    100% {
        //opacity: 1;
        //transform: translateY(0);
        scale: 1;
        //rotate: 0;
    }`;


// Box/Text Shadow

export const animationShadowRingLimey = keyframes`
    100%, 0% {
        box-shadow: 1px 1px 0 white, 2px 2px 12px rgb(183, 255, 0);
    }
    25% {
        box-shadow: 1px 1px 0 white, 2px 2px 12px rgb(255, 251, 0);
        //scale: 1.2;
    }
    50% {
        box-shadow: 1px 1px 0 white, 2px 2px 12px rgba(0, 255, 81);
        //scale: 0.8;
    }
    75% {
        box-shadow: 1px 1px 0 white, 2px 2px 12px rgb(255, 153, 0);
    }`;

export const animationShadowBerry = keyframes`
    100%, 0% {
        box-shadow: 2px 2px 12px rgb(102, 0, 51);
    }
    25% {
        box-shadow: 2px 2px 12px rgb(76, 0, 76);
    }
    50% {
        box-shadow: 2px 2px 12px rgb(63, 0, 128);
    }
    75% {
        box-shadow: 2px 2px 12px rgb(0, 0, 128);
    }`;

export const animationShadowLimey = keyframes`
    100%, 0% {
        box-shadow: 2px 2px 12px -6px rgb(183, 255, 0);
    }
    25% {
        box-shadow: 2px 2px 12px -6px rgb(255, 251, 0);
    }
    50% {
        box-shadow: 2px 2px 12px -6px rgba(0, 255, 81);
    }
    75% {
        box-shadow: 2px 2px 12px -6px rgb(255, 153, 0);
    }`;

export const animationTextShadowLimey = keyframes`
    100%, 0% {
        text-shadow: 2px 2px 0 rgba(183, 255, 0, 0.5);
    }
    25% {
        text-shadow: 2px 2px 0 rgba(255, 251, 0, 0.5);
    }
    50% {
        text-shadow: 2px 2px 0 rgba(0, 255, 81, 0.5);
    }
    75% {
        text-shadow: 2px 2px 0 rgba(255, 153, 0, 0.5);
    }`;

// export const animationShadowBlueDarker = keyframes`
//     0%, 100% {
//         box-shadow: 3px 3px 0 rgb(135, 206, 235), /* Sky Blue */ 6px 6px 0 rgb(70, 130, 180), /* Steel Blue */ 9px 9px 0 rgb(0, 128, 128); /* Teal */
//     }
//     25% {
//         box-shadow: 3px 3px 0 rgb(116, 172, 223), /* Softer Sky Blue */ 6px 6px 0 rgb(60, 120, 170), /* Softer Steel Blue */ 9px 9px 0 rgb(0, 118, 118); /* Softer Teal */
//     }
//     50% {
//         box-shadow: 3px 3px 0 rgb(100, 149, 237), /* Cornflower Blue */ 6px 6px 0 rgb(30, 144, 255), /* Dodger Blue */ 9px 9px 0 rgb(0, 206, 209); /* Dark Turquoise */
//     }
//     75% {
//         box-shadow: 3px 3px 0 rgb(65, 105, 225), /* Royal Blue */ 6px 6px 0 rgb(0, 0, 255), /* Blue */ 9px 9px 0 rgb(0, 139, 139); /* Dark Cyan */
//     }
// `;
//
// export const animationShadowLimeyDarker = keyframes`
//     0%, 100% {
//         box-shadow: 3px 3px 0 rgb(50, 205, 50), /* Lime Green */ 6px 6px 0 rgb(60, 179, 113), /* Medium Sea Green */ 9px 9px 0 rgb(34, 139, 34); /* Forest Green */
//     }
//     25% {
//         box-shadow: 3px 3px 0 rgb(124, 252, 0), /* Lawn Green */ 6px 6px 0 rgb(107, 142, 35), /* Olive Drab */ 9px 9px 0 rgb(85, 107, 47); /* Dark Olive Green */
//     }
//     50% {
//         box-shadow: 3px 3px 0 rgb(173, 255, 47), /* Green Yellow */ 6px 6px 0 rgb(154, 205, 50), /* Yellow Green */ 9px 9px 0 rgb(0, 100, 0); /* Dark Green */
//     }
//     75% {
//         box-shadow: 3px 3px 0 rgb(0, 255, 0), /* Lime */ 6px 6px 0 rgb(50, 205, 50), /* Lime Green */ 9px 9px 0 rgb(0, 128, 0); /* Green */
//     }
// `;
//
// export const blobMorph = keyframes`
//     0%, 100% {
//         border-radius: 30% 70% 70% 30% / 30% 30% 70% 70%;
//     }
//     25% {
//         border-radius: 50% 50% 50% 50% / 50% 50% 50% 50%;
//     }
//     50% {
//         border-radius: 30% 30% 70% 70% / 70% 70% 30% 30%;
//     }
//     75% {
//         border-radius: 50% 50% 50% 50% / 50% 50% 50% 50%;
//     }
// `;
//
// export const bouncyBoxShadow = keyframes`
//     0% {
//         box-shadow: 0 8px 8px 0 rgba(11, 107, 203, 0.2);
//     }
//     20% {
//         box-shadow: 12px 20px 24px 0 rgba(11, 107, 203, 0.2);
//     }
//     40% {
//         box-shadow: -12px 32px 24px 0 rgba(11, 107, 203, 0.2);
//     }
//     60% {
//         box-shadow: 24px -4px 24px 0 rgba(11, 107, 203, 0.2);
//     }
//     80% {
//         box-shadow: -24px 14px 24px 0 rgba(11, 107, 203, 0.2);
//     }
//     100% {
//         box-shadow: 0 8px 8px 0 rgba(11, 107, 203, 0.2);
//     }
// `;


================================================
FILE: src/common/util/blobUtils.ts
================================================
import { Release } from '~/common/app.release';


/// --- Base64 -> X --- ///

// Convert a base64 string to a Uint8Array (byte array).
export function convert_Base64_To_UInt8Array(base64: string, debugCaller: string): Uint8Array<ArrayBuffer> {
  try {
    // Remove data URL prefix if present - shall NOT happen
    let base64Data = base64;
    if (base64Data.startsWith('data:')) {
      Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64_To_UInt8Array: Detected data URL format in (${debugCaller}). Consider passing pure base64 instead.`);
      base64Data = base64Data.replace(/^data:[^;]+;base64,/, '');
    }

    // NOTE: we don't check for an empty string as it's valid and can convert

    // Decode base64 to binary string
    let binaryString: string;
    try {
      binaryString = atob(base64Data);
    } catch (errorD1) {
      Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64_To_UInt8Array: Failed to decode base64 in (${debugCaller}), attempting cleanup:`, errorD1);

      // Attempt to clean and fix the base64 string
      const cleanedBase64 = base64Data.replace(/[^A-Za-z0-9+/]/g, '');
      const paddingNeeded = (4 - (cleanedBase64.length % 4)) % 4;
      const paddedBase64 = cleanedBase64 + '='.repeat(paddingNeeded);
      binaryString = atob(paddedBase64);
    }

    // Convert binary string to Uint8Array - MODERNIZED from:
    // const bytes = new Uint8Array(binaryString.length);
    // for (let i = 0; i < binaryString.length; i++)
    //   bytes[i] = binaryString.charCodeAt(i);
    return Uint8Array.from(binaryString, char => char.charCodeAt(0));

  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64_To_UInt8Array: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Base64 decode failed (${debugCaller})`);
  }
}

/**
 * Convert a base64 string + its mimetype to a Blob.
 * @param base64 Base64 encoded string - the function will warn if this is a data URL instead.
 * @param blobMimeType MIME type of the resulting Blob, e.g. 'image/png', 'audio/wav', etc.
 * @param debugCaller User-visible label for debugging purposes, e.g. 'Voice Recorder'
 */
export async function convert_Base64WithMimeType_To_Blob(base64: string, blobMimeType: string, debugCaller: string): Promise<Blob> {
  try {
    // First attempt: Use our UInt8Array conversion
    try {
      // Validate base64 string - allow empty strings as they are valid
      if (base64 == null) {
        // noinspection ExceptionCaughtLocallyJS
        throw new Error('Invalid base64 data');
      }

      // Convert base64 to byte array
      const bytes = convert_Base64_To_UInt8Array(base64, debugCaller);

      // Convert byte array to blob (note, not reusing the dedicated function because it doesn't accept empty byte arrays)
      return new Blob([bytes], { type: blobMimeType });

    } catch (primaryError) {
      // Approach 2: Fallback using fetch with data URL
      Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64_To_Blob: Primary method failed in (${debugCaller}), trying fallback:`, primaryError);

      try {
        // Extract base64 data and handle data URL prefix
        let base64Data = base64;
        if (base64Data.startsWith('data:'))
          base64Data = base64Data.replace(/^data:[^;]+;base64,/, '');

        const dataUrl = `data:${blobMimeType};base64,${base64Data}`;
        const response = await fetch(dataUrl);
        if (!response.ok) {
          // noinspection ExceptionCaughtLocallyJS
          throw new Error(`Fetch Blob failed (${response.status})`);
        }

        // Empty blob from successful fetch is valid - represents empty content
        return await response.blob();
      } catch (fallbackError) {
        Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64_To_Blob: Both methods failed in (${debugCaller}):`, { primaryError, fallbackError });
        // noinspection ExceptionCaughtLocallyJS
        throw primaryError; // Rethrow original error for consistency
      }
    }

  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64_To_Blob: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Base64 to Blob failed (${debugCaller})`);
  }
}

// Convert (encode) separate base64 data and MIME type to a base64 data URL.
export function convert_Base64WithMimeType_To_Base64DataURL(base64Data: string, mimeType: string, debugCaller: string): string {
  try {
    if (base64Data == null) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid base64 data');
    }

    if (typeof (mimeType as unknown) !== 'string' || !mimeType.trim()) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid MIME type');
    }

    // Ensure base64Data doesn't already have data URL prefix
    if (base64Data.startsWith('data:')) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error(`Already a data URL`);
    }

    // Construct the data URL
    return `data:${mimeType};base64,${base64Data}`;

  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64WithMimeType_To_Base64DataURL: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Data URL creation failed (${debugCaller})`);
  }
}


/// --- Base64 Data URL <-> X --- ///

// Convert a base64 data URL (e.g. 'data:image/png;base64,iVBOUgAA...') to separate base64 data and MIME type.
export function convert_Base64DataURL_To_Base64WithMimeType(dataUrl: string, debugCaller: string): { base64Data: string, mimeType: string } {
  try {
    if (typeof (dataUrl as unknown) !== 'string') {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid data URL');
    }

    if (!dataUrl.startsWith('data:')) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Not a data URL');
    }

    // Parse the data URL format: data:[<mediatype>][;base64],<data>
    const commaIndex = dataUrl.indexOf(',');
    if (commaIndex === -1) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid data URL format');
    }

    const header = dataUrl.substring(5, commaIndex); // Skip "data:" prefix
    const base64Data = dataUrl.substring(commaIndex + 1);

    // Parse the header to extract MIME type
    let mimeType = '';
    if (header.includes(';base64')) {
      // Format: data:image/png;base64,
      mimeType = header.replace(';base64', '');
    } else {
      // Format without explicit base64 encoding (assume it's base64 anyway)
      Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64DataURL_To_Base64WithMimeType: Data URL in (${debugCaller}) doesn't specify base64 encoding, assuming base64`);
      mimeType = header;
    }

    // Default MIME type if empty
    if (!mimeType.trim()) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error(`Missing MIME type`);
    }

    return { base64Data, mimeType };
  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_Base64DataURL_To_Base64WithMimeType: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Data URL parse failed (${debugCaller})`);
  }
}


/// --- Blob -> X --- ///

// Convert a Blob to a base64 string (without data URL prefix).
export async function convert_Blob_To_Base64(blob: Blob, debugCaller: string): Promise<string> {
  try {
    const base64DataURL = await convert_Blob_To_Base64DataURL(blob, debugCaller);
    // Extract base64 part from data URL
    const commaIndex = base64DataURL.indexOf(',');
    if (commaIndex === -1) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Malformed data URL');
    }
    // Empty base64 result from empty blob is valid - represents empty content
    return base64DataURL.substring(commaIndex + 1);
  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_Blob_To_Base64: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Blob to base64 failed (${debugCaller})`);
  }
}

// Convert a Blob to a base64 data URL string. [Fast] uses the FileReader API
async function convert_Blob_To_Base64DataURL(blob: Blob, debugCaller: string): Promise<string> {
  try {
    if (!((blob as unknown) instanceof Blob)) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid blob');
    }

    return new Promise<string>((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        if (typeof reader.result === 'string')
          resolve(reader.result);
        else
          reject(new Error('FileReader error'));
      };
      reader.onerror = () => reject(new Error(`FileReader failed`));
      reader.onabort = () => reject(new Error('FileReader aborted'));
      reader.readAsDataURL(blob);
    });

  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_Blob_To_Base64DataURL: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Blob read failed (${debugCaller})`);
  }
}

// Convert a Blob to a Uint8Array (byte array)
export async function convert_Blob_To_UInt8Array(blob: Blob, debugCaller: string): Promise<Uint8Array> {
  try {
    if (!((blob as unknown) instanceof Blob)) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid blob');
    }

    const arrayBuffer = await blob.arrayBuffer();
    return new Uint8Array(arrayBuffer);

  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_Blob_To_UInt8Array: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Blob to bytes failed (${debugCaller})`);
  }
}


/// --- UInt8Array -> X --- ///

// Convert a Uint8Array (byte array) to a Blob
export function convert_UInt8ArrayWithMimeType_To_Blob(bytes: Uint8Array, blobMimeType: string, debugCaller: string): Blob {
  try {
    if (!((bytes as unknown) instanceof Uint8Array)) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid byte array');
    }

    return new Blob([bytes], { type: blobMimeType });

  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_UInt8Array_To_Blob: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Bytes to Blob failed (${debugCaller})`);
  }
}

// Convert a Uint8Array (byte array) to a base64 string - SLOW? - minimize usage
export function convert_UInt8Array_To_Base64(bytes: Uint8Array, debugCaller: string): string {
  try {
    if (!((bytes as unknown) instanceof Uint8Array)) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('Invalid byte array');
    }

    // Handle empty array case
    if (bytes.length === 0)
      return '';

    // Method 1: Using Buffer (if available in Node.js environment)
    if (typeof Buffer !== 'undefined')
      return Buffer.from(bytes).toString('base64');

    // Method 2: Current implementation with apply fix
    let binaryString = '';
    const chunkSize = 0x8000; // 32KB chunks
    for (let i = 0; i < bytes.length; i += chunkSize) {
      const chunk = bytes.subarray(i, i + chunkSize); // subarray is more efficient than slice
      binaryString += String.fromCharCode.apply(null, Array.from(chunk));
    }
    return btoa(binaryString); // binary string to base64
  } catch (error) {
    Release.IsNodeDevBuild && console.warn(`[DEV] convert_UInt8Array_To_Base64: Conversion failed in (${debugCaller}):`, error);
    throw new Error(`Bytes to base64 failed (${debugCaller})`);
  }
}



================================================
FILE: src/common/util/canvasUtils.ts
================================================
/**
 * Converts a canvas to a data URL and extracts the MIME type and Base64 data
 * @param canvas The canvas element to convert
 * @param requestedMimeType The desired MIME type for the image
 * @param imageQuality A number between 0 and 1 indicating image quality for lossy formats
 * @param userLogLabel A label to use in console warnings
 */
export function canvasToDataURLAndMimeType(
  canvas: HTMLCanvasElement,
  requestedMimeType: string,
  imageQuality: number | undefined,
  userLogLabel: string,
): { mimeType: string; base64Data: string } {

  // Extract the actual MIME type and Base64 data efficiently
  const dataUrl = canvas.toDataURL(requestedMimeType, imageQuality);

  const colonIndex = dataUrl.indexOf(':');
  const semicolonIndex = dataUrl.indexOf(';', colonIndex);
  if (colonIndex === -1 || semicolonIndex === -1)
    throw new Error('canvasToDataURLAndMimeType: Invalid data URL format.');
  const actualMimeType = dataUrl.slice(colonIndex + 1, semicolonIndex);

  const commaIndex = dataUrl.indexOf(',');
  if (commaIndex === -1)
    throw new Error('canvasToDataURLAndMimeType: Invalid data URL comma.');
  const base64Data = dataUrl.slice(commaIndex + 1);

  // Warn if the actual MIME type differs from the requested one
  if (actualMimeType !== requestedMimeType)
    console.warn(`${userLogLabel}: requested MIME type "${requestedMimeType}" was not used. Actual MIME type is "${actualMimeType}".`);

  return { mimeType: actualMimeType, base64Data };
}

/**
 * Creates a Blob object representing the image contained in the canvas, with format validation and fallback
 * @param canvas The canvas element to convert
 * @param requestedMimeType Desired MIME type - browsers are required to support image/png; many will support additional formats including image/jpeg and some may support image/webp.
 * @param imageQuality Quality for lossy formats (0-1) (image/jpeg or image/webp)
 * @param debugLabel Label for debugging
 */
export async function asyncCanvasToBlobWithValidation(
  canvas: HTMLCanvasElement,
  requestedMimeType: string,
  imageQuality: undefined | number,
  debugLabel?: string,
): Promise<{ blob: Blob; actualMimeType: string }> {
  return new Promise((resolve, reject) => {
    canvas.toBlob((blob) => {
      if (!blob)
        return reject(new Error(`Failed to convert canvas to blob with format '${requestedMimeType}'`));

      // Warn if the actual MIME type differs from the requested one
      if (debugLabel && blob.type !== requestedMimeType)
        console.warn(`[DEV] ${debugLabel}: requested MIME type "${requestedMimeType}" was not used. Actual MIME type is "${blob.type}".`);

      resolve({ blob, actualMimeType: blob.type });
    }, requestedMimeType, imageQuality);
  });
}


export function renderVideoFrameToNewCanvas(videoElement: HTMLVideoElement): HTMLCanvasElement {
  // paint the video on a canvas, to save it
  const canvas = document.createElement('canvas');
  canvas.width = videoElement.videoWidth || 640;
  canvas.height = videoElement.videoHeight || 480;
  const ctx = canvas.getContext('2d');
  ctx?.drawImage(videoElement, 0, 0);
  return canvas;
}



================================================
FILE: src/common/util/clientFetchers.ts
================================================
export const frontendSideFetch = fetch;


================================================
FILE: src/common/util/clipboardUtils.ts
================================================
import { addSnackbar } from '../components/snackbar/useSnackbarsStore';
import { Is, isBrowser } from './pwaUtils';

export function copyToClipboard(text: string, typeLabel: string) {
  if (!isBrowser)
    return;
  if (!window.navigator.clipboard?.writeText) {
    alert('Clipboard access is blocked. Please enable it in your browser settings.');
    return;
  }
  window.navigator.clipboard.writeText(text)
    .then(() => {
      addSnackbar({
        key: 'copy-to-clipboard',
        message: `${typeLabel} copied to clipboard`,
        type: 'success',
        closeButton: false,
        overrides: {
          autoHideDuration: 2000,
        },
      });
    })
    .catch((err) => {
      alert(`Failed to message to clipboard${err?.name ? ' (' + err.name + ')' : ''}.\n\n${err?.message || 'Unknown error, likely a permission issue.'}`);
    });
}

export function copyBlobPromiseToClipboard(mimeType: string, blobPromise: Promise<Blob>, typeLabel: string) {
  if (!isBrowser)
    return;
  if (!navigator.clipboard || !navigator.clipboard.write) {
    alert('Clipboard access is blocked or not supported in this browser.');
    return;
  }
  // Create a ClipboardItem with the Blob
  const clipboardItem = new ClipboardItem({ [mimeType]: blobPromise });

  // Write the ClipboardItem to the clipboard
  navigator.clipboard.write([clipboardItem])
    .then(() => {
      addSnackbar({
        key: 'copy-blob-to-clipboard',
        message: `${typeLabel} copied to clipboard`,
        type: 'success',
        closeButton: false,
        overrides: {
          autoHideDuration: 2000,
        },
      });
    })
    .catch((err) => {
      const [media, type] = mimeType.split('/');
      alert(`Failed to copy ${type?.toUpperCase()} ${media} to clipboard${err?.name ? ' (' + err.name + ')' : ''}.\n\n${err?.message || 'Unknown error, likely a permission issue.'}`);
    });
}

export function supportsClipboardRead() {
  return !Is.Browser.Firefox;
}

export async function getClipboardItems(): Promise<ClipboardItem[] | null> {
  if (!isBrowser || !window.navigator.clipboard?.read)
    return [];
  try {
    return await window.navigator.clipboard.read();
  } catch (error: any) {
    console.warn('Failed to read clipboard: ', error);
    return null;
  }
}


================================================
FILE: src/common/util/costUtils.ts
================================================
export function formatModelsCost(cost: number) {
  return cost < 1
    ? `${(cost * 100).toFixed(cost < 0.010 ? 2 : 2)} ¢`
    : `$ ${cost.toFixed(2)}`;
}


================================================
FILE: src/common/util/dMessageUtils.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import type { SxProps } from '@mui/joy/styles/types';
import { Avatar, Box } from '@mui/joy';
import Face6Icon from '@mui/icons-material/Face6';
import NotificationsActiveIcon from '@mui/icons-material/NotificationsActiveOutlined';
import SettingsSuggestIcon from '@mui/icons-material/SettingsSuggest';
import SmartToyOutlinedIcon from '@mui/icons-material/SmartToyOutlined';
import VisibilityOffOutlinedIcon from '@mui/icons-material/VisibilityOffOutlined';

import { SystemPurposeId, SystemPurposes } from '../../data';

import { llmsGetVendorIcon } from '~/modules/llms/components/LLMVendorIcon';

import type { MetricsChatGenerateCost_Md } from '~/common/stores/metrics/metrics.chatgenerate';
import type { DMessage, DMessageGenerator, DMessageRole } from '~/common/stores/chat/chat.message';
import type { UIComplexityMode } from '~/common/app.theme';
import { PhPaintBrush } from '~/common/components/icons/phosphor/PhPaintBrush';
import { animationColorRainbow } from '~/common/util/animUtils';
import { formatModelsCost } from '~/common/util/costUtils';


// configuration
export const ANIM_BUSY_TYPING = 'https://i.giphy.com/media/jJxaUysjzO9ri/giphy.webp';
const ANIM_BUSY_DOWNLOADING = 'https://i.giphy.com/26u6dIwIphLj8h10A.webp'; // hourglass: https://i.giphy.com/TFSxpAIYz5inJGuY8f.webp, small-lq: https://i.giphy.com/131tNuGktpXGhy.webp, floppy: https://i.giphy.com/RxR1KghIie2iI.webp
const ANIM_BUSY_PAINTING = 'https://i.giphy.com/media/5t9ujj9cMisyVjUZ0m/giphy.webp';
const ANIM_BUSY_THINKING = 'https://i.giphy.com/media/l44QzsOLXxcrigdgI/giphy.webp';


export const avatarIconSx = {
  borderRadius: 'sm',
  height: 36,
  width: 36,
} as const;

const largerAvatarIconsSx = {
  borderRadius: 'sm',
  width: 48,
  height: 48,
};

const aixSkipBoxSx = {
  height: 36,
  width: 36,
  display: 'flex',
  alignItems: 'center',
  justifyContent: 'center',
};

const aixSkipIconSx = {
  color: 'neutral.solidBg',
};

const tooltipSx: SxProps = {
  fontSize: 'sm',
  p: 1,
  display: 'grid',
  gap: 1,
};

const tooltipIconContainerSx: SxProps = {
  display: 'flex',
  alignItems: 'center',
  gap: 1,
};

const tooltipCreationTimeSx: SxProps = {
  fontSize: 'xs',
  color: 'text.tertiary',
};

const tooltipMetricsGridSx: SxProps = {
  // grid of 2 columns, the first fits the labels, the other expends with the values
  display: 'grid',
  gridTemplateColumns: 'auto 1fr',
  columnGap: 1,
  rowGap: 0.5,
};


/** Whole message background color, based on the message role and state */
export function messageBackground(messageRole: DMessageRole | string, userCommand: 'draw' | 'react' | false, wasEdited: boolean, isAssistantIssue: boolean): string {
  switch (messageRole) {
    case 'user':
      return userCommand === 'draw' ? 'warning.softActiveBg'
        : userCommand === 'react' ? 'success.softHoverBg'
          : 'primary.plainHoverBg'; // was .background.level1
    case 'assistant':
      return isAssistantIssue ? 'danger.softBg' : 'background.surface';
    case 'system':
      return wasEdited ? 'warning.softHoverBg' : 'neutral.softBg';
    default:
      return '#ff0000';
  }
}


/** Message avatar icon, based on the message role and state (e.g. notification pending, is generating, etc.) */
export function makeMessageAvatarIcon(
  uiComplexityMode: UIComplexityMode,
  messageRole: DMessageRole | string,
  messageGeneratorName: string | undefined,
  messagePurposeId: SystemPurposeId | string | undefined,
  messageIncomplete: boolean,
  messageFlagAixSkip: boolean,
  messageFlaxNotifyComplete: boolean,
  larger: boolean,
): React.JSX.Element {

  const nameOfRole =
    messageRole === 'user' ? 'You'
      : messageRole === 'assistant' ? 'Assistant'
        : 'System';

  // if skipped, just return the skip symbol
  if (messageFlagAixSkip)
    return <Box sx={aixSkipBoxSx}><VisibilityOffOutlinedIcon sx={aixSkipIconSx} /></Box>;

  // if pending a notification, return the busy icon
  if (messageFlaxNotifyComplete)
    return <Box sx={aixSkipBoxSx}><NotificationsActiveIcon sx={aixSkipIconSx} /></Box>;

  switch (messageRole) {
    case 'system':
      return <SettingsSuggestIcon sx={avatarIconSx} />;  // https://em-content.zobj.net/thumbs/120/apple/325/robot_1f916.png

    case 'user':
      return <Face6Icon sx={avatarIconSx} />;            // https://www.svgrepo.com/show/306500/openai.svg

    case 'assistant':
      const isDownload = messageGeneratorName === 'web';
      const isTextToImage =
        messageGeneratorName?.startsWith('GPT Image') // sync this with t2i.client.ts
        || messageGeneratorName?.startsWith('DALL·E')
        || messageGeneratorName === 'Prodia';
      const isReact = messageGeneratorName?.startsWith('react-');

      // Extra appearance
      if (uiComplexityMode === 'extra') {

        // Pending animations (larger too)
        if (messageIncomplete)
          return <Avatar
            variant='plain'
            alt={nameOfRole}
            src={isDownload ? ANIM_BUSY_DOWNLOADING
              : isTextToImage ? ANIM_BUSY_PAINTING
                : isReact ? ANIM_BUSY_THINKING
                  : ANIM_BUSY_TYPING}
            sx={larger ? largerAvatarIconsSx : avatarIconSx}
          />;

        // Purpose image (if present)
        const purposeImage = SystemPurposes[messagePurposeId as SystemPurposeId]?.imageUri ?? undefined;
        if (purposeImage)
          return <Avatar
            variant='plain'
            alt={nameOfRole}
            src={purposeImage}
            sx={avatarIconSx}
          />;

      }

      // mode: text-to-image
      if (isTextToImage)
        return <PhPaintBrush sx={!messageIncomplete ? avatarIconSx : {
          ...avatarIconSx,
          animation: `${animationColorRainbow} 1s linear infinite`,
        }} />;

      // TODO: llm symbol (if messageIncomplete)
      // if (messageIncomplete)

      // purpose symbol (if present)
      const symbol = SystemPurposes[messagePurposeId as SystemPurposeId]?.symbol;
      if (symbol)
        return <Box sx={{
          fontSize: '24px',
          textAlign: 'center',
          width: '100%',
          minWidth: `${avatarIconSx.width}px`,
          lineHeight: `${avatarIconSx.height}px`,
        }}>
          {symbol}
        </Box>;

      // default assistant avatar
      return <SmartToyOutlinedIcon sx={avatarIconSx} />; // https://mui.com/static/images/avatar/2.jpg
  }
  return <Avatar alt={nameOfRole} />;
}


/** Message avatar label and tooltip, based on the message generator and state */
export function useMessageAvatarLabel(
  messageParts: Pick<DMessage, 'generator' | 'pendingIncomplete' | 'created' | 'updated'> | undefined,
  complexity: UIComplexityMode,
): { label: React.ReactNode; tooltip: React.ReactNode } {

  // we do this for performance reasons, to only limit re-renders to these parts of the message
  const { generator, pendingIncomplete, created, updated } = messageParts || {};

  // OPTIMIZATION - THIS COULD BACKFIRE - THE ICON MAY NOT BE UPDATED AS OFTEN AS WE NEED
  // -> we will only trigger updates on: updated, pendingIncomplete changes, name changes
  // generator will change at every step (due to some structuredClone in AIX); we choose to 'lag' behind it and
  // refresh this when other variables change
  const laggedGeneratorRef = React.useRef<DMessageGenerator | undefined>(undefined);
  laggedGeneratorRef.current = generator;
  const generatorName = generator?.name ?? '';

  return React.useMemo(() => {
    if (created === undefined) {
      return {
        label: 'unk-msg',
        tooltip: null,
      };
    }
    const generator = laggedGeneratorRef.current;
    if (!generator) {
      return {
        label: 'unk-model',
        tooltip: null,
      };
    }

    // incomplete: just the name
    const prettyName = prettyShortChatModelName(generatorName);
    if (pendingIncomplete)
      return {
        label: prettyName,
        tooltip: (!created || complexity === 'minimal') ? null : (
          <Box sx={tooltipSx}>
            <TimeAgo date={created} formatter={(value: number, unit: string, _suffix: string) => `Thinking for ${value} ${unit}${value > 1 ? 's' : ''}...`} />
          </Box>
        ),
      };

    // named generator: nothing else to do there
    if (generator.mgt === 'named')
      return {
        label: prettyName,
        tooltip: prettyName !== generator.name ? generator.name : null,
      };

    // aix generator: details galore
    const modelId = generator.aix?.mId ?? null;
    const vendorId = generator.aix?.vId ?? null;
    const VendorIcon = (vendorId && complexity !== 'minimal') ? llmsGetVendorIcon(vendorId) : null;
    const metrics = generator.metrics ? _prettyMetrics(generator.metrics, complexity) : null;
    const stopReason = generator.tokenStopReason ? _prettyTokenStopReason(generator.tokenStopReason, complexity) : null;

    // aix tooltip: more details
    return {
      label: (stopReason && complexity !== 'minimal') ? <>{prettyName} <small>({stopReason})</small></> : prettyName,
      tooltip: complexity === 'minimal' ? null : (
        <Box sx={tooltipSx}>
          {VendorIcon ? <Box sx={tooltipIconContainerSx}><VendorIcon />{generator.name}</Box> : <div>{generator.name}</div>}
          {(modelId && complexity === 'extra') && <div>{modelId}</div>}
          {metrics && <div>{metrics}</div>}
          {stopReason && <div>{stopReason}</div>}
          {complexity === 'extra' && !!created && <Box sx={tooltipCreationTimeSx}>{updated ? 'Updated' : 'Created'} <TimeAgo date={updated || created} />.</Box>}
        </Box>
      ),
    };
  }, [complexity, created, generatorName, pendingIncomplete, updated]);
}

function _prettyMetrics(metrics: DMessageGenerator['metrics'], uiComplexityMode: UIComplexityMode): React.ReactNode {
  if (!metrics) return null;

  const showWaitingTime = metrics?.dtStart !== undefined && (uiComplexityMode === 'extra' || metrics.dtStart >= 10000);
  const showSpeedSection = uiComplexityMode !== 'minimal' && (showWaitingTime || metrics?.vTOutInner !== undefined);
  const showTimeSection = showSpeedSection && !!metrics?.dtAll;

  const costCode = metrics.$code ? _prettyCostCode(metrics.$code) : null;

  return <Box sx={tooltipMetricsGridSx}>

    {/* Tokens */}
    {metrics?.TIn !== undefined && <div>Tokens:</div>}
    {metrics?.TIn !== undefined && <div>
      {' '}<b>{metrics.TIn?.toLocaleString() || ''}</b> in
      {metrics.TCacheRead !== undefined && <>{' · '}<b>{metrics.TCacheRead?.toLocaleString() || ''}</b> read</>}
      {metrics.TCacheWrite !== undefined && <>{' · '}<b>{metrics.TCacheWrite?.toLocaleString() || ''}</b> wrote</>}
      {', '}<b>{metrics.TOut?.toLocaleString() || ''}</b> out
      {metrics.TOutR !== undefined && <> (<b>{metrics.TOutR?.toLocaleString() || ''}</b> for reasoning)</>}
      {/*{metrics.TOutA !== undefined && <> (<b>{metrics.TOutA?.toLocaleString() || ''}</b> for audio)</>}*/}
    </div>}

    {/* Timings */}
    {showSpeedSection && <div>Speed:</div>}
    {showSpeedSection && <div>
      {!!metrics.vTOutInner && <>~<b>{(Math.round(metrics.vTOutInner * 10) / 10).toLocaleString() || ''}</b> tok/s</>}
      {showWaitingTime && (<span style={{ opacity: 0.5 }}>
        {metrics.vTOutInner !== undefined && ' · '}
        <span>{(Math.round(metrics.dtStart! / 100) / 10).toLocaleString() || ''}</span>s wait
      </span>)}
    </div>}

    {/* Costs */}
    {metrics?.$c !== undefined && <div>Costs:</div>}
    {metrics?.$c !== undefined && <div>
      <b>{formatModelsCost(metrics.$c / 100)}</b>
      {metrics.$cdCache !== undefined && <>
        {' '}<small>(
        {metrics.$cdCache > 0
          ? <>cache savings: <b>{formatModelsCost(metrics.$cdCache / 100)}</b></>
          : <>cache costs: <b>{formatModelsCost(-metrics.$cdCache / 100)}</b></>
        })</small>
      </>}
    </div>}
    {costCode && <div>{metrics?.$c !== undefined ? 'Costs:' : ''}</div>}
    {costCode && <div><em>{costCode}</em></div>}

    {/* Time */}
    {showTimeSection && <div>Time:</div>}
    {showTimeSection && <div><b>{(Math.round(metrics.dtAll! / 100) / 10).toLocaleString()}</b> s</div>}
  </Box>;
}

function _prettyCostCode(code: MetricsChatGenerateCost_Md['$code']): string | null {
  if (!code) return null;
  switch (code) {
    case 'free':
      return 'Free';
    case 'no-tokens':
      return 'Missing tokens for pricing';
    case 'no-pricing':
      return 'Model pricing not available';
    case 'partial-msg':
      return 'Incomplete Message - Partial Cost';
    case 'partial-price':
      return 'Model pricing is incomplete';
  }
}

function _prettyTokenStopReason(reason: DMessageGenerator['tokenStopReason'], complexity: UIComplexityMode): string | null {
  if (!reason) return null;
  switch (reason) {
    case 'client-abort':
      return complexity !== 'minimal' ? 'Stopped' : '';
    case 'filter':
      return 'Filtered';
    case 'issue':
      return complexity === 'extra' ? 'Error' : '';
    case 'out-of-tokens':
      return 'Out of Tokens';
  }
}


const oaiORegex = /gpt-[345](?:o|\.\d+)?-|o[1345]-|chatgpt-4o|computer-use-/;
const geminiRegex = /gemini-|gemma-|learnlm-/;


/** Pretty name for a chat model ID - VERY HARDCODED - shall use the Avatar Label-style code instead */
export function prettyShortChatModelName(model: string | undefined): string {
  if (!model) return '';

  // TODO: fully reform this function to be using information from the DLLM, rather than this manual mapping

  // [OpenAI]
  let prefixIndex = model.search(oaiORegex);
  if (prefixIndex !== -1) {
    let cutModel = prefixIndex === -1 ? model : model.slice(prefixIndex);
    // remove version: cut before the '-202..' if present
    const versionIndex = cutModel.search(/-20\d{2}/);
    if (versionIndex !== -1) cutModel = cutModel.slice(0, versionIndex);
    return cutModel
      .replace('chatgpt-', 'ChatGPT_')
      .replace('gpt-', 'GPT_')
      // feature variants
      .replace('-audio', ' Audio')
      .replace('-realtime-preview', ' Realtime')
      .replace('-realtime', ' Realtime')
      .replace('-search-preview', ' Search')
      .replace('-search', ' Search')
      .replace('-tts', ' TTS')
      .replace('-turbo', ' Turbo')
      // price variants
      .replace('-pro', ' Pro')
      .replace('-preview', ' (preview)')
      // .replace('-latest', ' latest') // covered by catch-all
      // size (covered by catch-all)
      // .replace('-mini', ' mini')
      // .replace('-micro', ' micro')
      // .replace('-nano', ' nano')
      // catch-all
      .replaceAll('-', ' ')
      .replaceAll('_', '-');
  }
  // [LocalAI?]
  if (model.endsWith('.bin')) return model.slice(0, -4);
  // [Alibaba]
  if (model.startsWith('alibaba-qwen-') || model.startsWith('qwen-')) {
    return model
      .replace('alibaba-', ' ')
      .replace('qwen', 'Qwen')
      .replace('max', 'Max')
      .replace('plus', 'Plus')
      .replace('turbo', 'Turbo')
      .replaceAll('-', ' ');
  }
  // [Anthropic]
  const prettyAnthropic = _prettyAnthropicModelName(model);
  if (prettyAnthropic) return prettyAnthropic;
  // [Gemini]
  prefixIndex = model.search(geminiRegex);
  if (prefixIndex !== -1) {
    let cutModel = prefixIndex === -1 ? model : model.slice(prefixIndex);
    // Check for -NN-NN at the end (e.g., -05-15)
    let datePattern = '';
    const dateMatch = cutModel.match(/-(\d{2}-\d{2})$/);
    if (dateMatch) {
      datePattern = ' ' + dateMatch[1]; // extract '05-15'
      cutModel = cutModel.slice(0, cutModel.length - dateMatch[0].length); // remove '-05-15'
    }
    const geminiName = cutModel
      .replace('non-thinking', '') // NOTE: this is our variant, injected in gemini.models.ts
      .replaceAll('-', ' ')
      // products
      .replace('gemini', 'Gemini')
      .replace('gemma', 'Gemma')
      .replace('learnlm', 'LearnLM')
      // price variants
      .replace('pro', 'Pro')
      .replace('flash', 'Flash')
      // feature variants
      .replace('generation', 'Gen')
      .replace('image', 'Image')
      .replace('thinking', 'Thinking')
      .replace('preview', '')
      .replace('experimental', 'exp')
      .replace('exp', '(exp)');
    return geminiName + datePattern;
  }
  // [Deepseek]
  if (model.includes('deepseek-')) {
    // start past the last /, if any
    const lastSlashIndex = model.lastIndexOf('/');
    const modelName = lastSlashIndex === -1 ? model : model.slice(lastSlashIndex + 1);
    return modelName.replace('deepseek-', ' Deepseek ')
      .replace('reasoner', 'R1').replace('r1', 'R1')
      .replaceAll('-', ' ')
      .trim();
  }
  // [LM Studio]
  if (model.startsWith('C:\\') || model.startsWith('D:\\'))
    return _prettyLMStudioFileModelName(model).replace('.gguf', '');
  // [Mistral]
  if (model.includes('mistral-large')) return 'Mistral Large';
  // [Ollama]
  if (model.includes(':'))
    return model.replace(':latest', '').replaceAll(':', ' ');
  // [Perplexity]
  if (model.includes('sonar-')) {
    // capitalize each component of the name, e.g. 'sonar-pro' -> 'Sonar Pro'
    return model.split('-').map(s => s.charAt(0).toUpperCase() + s.slice(1)).join(' ');
  }
  // [xAI]
  if (model.includes('grok-')) {
    if (model.includes('grok-3') || model.includes('grok-2')) {
      return model
        .replace('xai-', '')
        .replace('-beta', '')
        .split('-').map(s => s.charAt(0).toUpperCase() + s.slice(1)).join(' ');
    }
    if (model.includes('grok-beta')) return 'Grok Beta';
    if (model.includes('grok-vision-beta')) return 'Grok Vision Beta';
  }
  // [FireworksAI]
  if (model.includes('accounts/')) {
    const index = model.indexOf('accounts/');
    const subStr = model.slice(index + 9);
    return subStr.replaceAll('/models/', ' · ').replaceAll(/[_-]/g, ' ');
  }
  return model;
}

function _prettyAnthropicModelName(modelId: string): string | null {
  if (modelId.indexOf('claude-') === -1) return null; // not a Claude model

  // must match any known prefix
  let claudeIndex = -1;
  const claudePrefixes = ['claude-opus-4', 'claude-sonnet-4', 'claude-haiku-4', 'claude-3', 'claude-2'];
  for (const prefix of claudePrefixes) {
    const index = modelId.indexOf(prefix);
    if (index !== -1) {
      claudeIndex = index;
      break;
    }
  }

  const subStr = modelId.slice(claudeIndex);
  const version =
    subStr.includes('-5') ? '5'
      : subStr.includes('-4') ? '4'
        : subStr.includes('-3-7') ? '3.7'
          : subStr.includes('-3-5') ? '3.5'
            : subStr.includes('-3') ? '3'
              : '?';

  if (subStr.includes(`-opus`)) return `Claude ${version} Opus`;
  if (subStr.includes(`-sonnet`)) return `Claude ${version} Sonnet`;
  if (subStr.includes(`-haiku`)) return `Claude ${version} Haiku`;

  return `Claude ${version}`;
}

function _prettyLMStudioFileModelName(filePath: string): string {
  const normalizedPath = filePath.replace(/\\/g, '/');
  return normalizedPath.split('/').pop() || '';
}



================================================
FILE: src/common/util/downloadUtils.ts
================================================
/**
 * Triggers a file download given a URL and filename.
 * @param url - The URL of the file to download:
 * @param filename - The desired filename for the downloaded file.
 */
export function downloadToFile(url: string, filename: string): void {
  const anchor = document.createElement('a');
  anchor.href = url;
  anchor.download = filename || 'download';
  document.body.appendChild(anchor); // Ensure visibility in the DOM for Firefox
  anchor.click();
  document.body.removeChild(anchor); // Clean up
}

/**
 * Downloads a file from a Blob object.
 * @param blob - The Blob object containing the file data.
 * @param filename - The desired filename for the downloaded file.
 */
export function downloadBlob(blob: Blob, filename: string): void {
  const url = URL.createObjectURL(blob);
  downloadToFile(url, filename);
  URL.revokeObjectURL(url); // Clean up the Blob URL
}

//
// /**
//  * Downloads text content as a file.
//  * @param content - The text content to download.
//  * @param filename - The desired filename for the downloaded file.
//  */
// export function downloadText(content: string, filename: string): void {
//   const blob = new Blob([content], { type: 'text/plain' });
//   downloadBlob(blob, filename);
// }
//
// /**
//  * Downloads a JSON object as a file.
//  * @param data - The JSON object to download.
//  * @param filename - The desired filename for the downloaded file.
//  */
// export function downloadJSON(data: any, filename: string): void {
//   const jsonStr = JSON.stringify(data, null, 2);
//   const blob = new Blob([jsonStr], { type: 'application/json' });
//   downloadBlob(blob, filename);
// }
//



================================================
FILE: src/common/util/errorUtils.ts
================================================
import { Release } from '~/common/app.release';

/**
 * Present an error to the user in a human-readable format.
 * Be exhaustive and not repetitive. Ignore the stack trace.
 */
export function presentErrorToHumans(error: any, mdBold: boolean = false, devWarnError: boolean = false): string {
  if (devWarnError)
    console.error('presentErrorToDevelopers', { error });

  // Handle Error objects
  if (error instanceof Error) {
    let message = error.name ? `[${error.name}] ` : '';
    message += error.message;
    if (mdBold)
      message = `**${message}**`;

    if (error.cause) {
      // shallow print of the message only
      if (error.cause instanceof Error)
        message += ` · cause: ${error.cause.message}.`;
      // to print it fully (not recommended), use the following:
      // message += ` · cause: ${presentErrorToHumans(error.cause)}`;
    }

    return message;
  }

  // Handle DOMException
  if (error instanceof DOMException)
    return `[DOMException] ${error.name}: ${error.message}`;

  // Handle string errors
  if (typeof error === 'string')
    return error;

  // Handle objects
  if (typeof error === 'object' && error !== null)
    return safeObjectToString(error);

  // Handle other types
  return `Unknown Error: ${String(error)}`;
}

function safeObjectToString(obj: object): string {
  const pairs: string[] = [];
  for (const [key, value] of Object.entries(obj)) {
    let valueStr: string;
    if (typeof value === 'object' && value !== null) {
      valueStr = '[Object]';
    } else if (typeof value === 'function') {
      valueStr = '[Function]';
    } else {
      valueStr = String(value);
    }
    pairs.push(`${key}: ${valueStr}`);
  }
  return `{ ${pairs.join(', ')} }`;
}


/**
 * Serialize an error object to a plain object for storage or transmission.
 */
export function serializeError(value: any): any {
  // handle Error objects
  if (value instanceof Error) {
    return {
      _isError: true,  // Mark as serialized error for identification
      name: value.name ?? 'SError',
      message: value.message ?? 'No SMessage',
      ...(value.stack !== undefined && { stack: value.stack }), // Include stack if available
      ...(value.cause !== undefined && { cause: serializeError(value.cause) }), // Recursively serialize cause
      // Capture other properties
      ...Object.fromEntries(
        Object.entries(value).filter(([k]) => !['name', 'message', 'stack', 'cause'].includes(k)),
      ),
    };
  }

  // handle objects that might contain errors
  if (value && typeof value === 'object') {
    if (Array.isArray(value)) {
      return value.map(serializeError);
    }

    const result: Record<string, any> = {};
    for (const [key, val] of Object.entries(value)) {
      result[key] = serializeError(val);
    }
    return result;
  }

  // Return primitives as-is
  return value;
}

/**
 * Conditionally triggers the debugger
 */
export function maybeDebuggerBreak(): void {

  const isBreakEnabled = process.env.NEXT_PUBLIC_DEBUG_BREAKS === 'true';

  if (Release.IsNodeDevBuild && isBreakEnabled) {
    // eslint-disable-next-line no-debugger
    debugger; // This line will be hit only if DevTools are open.
    // Build tools often remove debugger statements in production.
  }
}



================================================
FILE: src/common/util/eventUtils.ts
================================================
// /**
//  * Generates helper functions for dispatching and listening to custom Browser events with typed details.
//  *
//  * @param eventName The base name of the event. The actual event type will be `${eventName}Event`.
//  * @returns A tuple containing two functions:
//  * 1. `dispatchEvent(target: EventTarget, detail: TDetail) => void` - Dispatches the custom event on the specified target with the provided detail.
//  * 2. `installListener(target: EventTarget, listener: (detail: TDetail) => void) => () => void` - Installs an event listener on the specified target that listens for the custom event and executes the provided callback with the event detail. Returns a function to remove the installed event listener.
//  * @template TDetail The type of the detail object that will be passed with the event.
//  */
// export function customEventHelpers<TDetail>(eventName: string): [dispatchEvent: (target: EventTarget, detail: TDetail) => void, installListener: (state: TDetail, target: EventTarget, listener: (detail: TDetail) => void) => () => void] {
//   const eventType = `${eventName}Event`;
//
//   const createEvent = (detail: TDetail): CustomEvent<TDetail> => new CustomEvent<TDetail>(eventType, { detail: detail });
//
//   const dispatchEvent = (target: EventTarget, detail: TDetail) => target.dispatchEvent(createEvent(detail));
//
//   const installListener = (currentState: TDetail, target: EventTarget, detailListener: (detail: TDetail) => void) => {
//     const listener = (event: Event) => detailListener((event as CustomEvent<TDetail>).detail);
//     detailListener(currentState);
//     target.addEventListener(eventType, listener);
//     return () => target.removeEventListener(eventType, listener);
//   };
//
//   return [dispatchEvent, installListener];
// }



================================================
FILE: src/common/util/fileSystemUtils.ts
================================================
import type { FileWithHandle } from 'browser-fs-access';


/**
 * Extending the `FileSystemDirectoryHandle` with a `values` method to iterate over the directory contents.
 * This is as defined in https://fs.spec.whatwg.org/#filesystemdirectoryhandle (File System Standard, Last Updated 28 June 2024).
 */
interface ExplorableFileSystemDirectoryHandle extends FileSystemDirectoryHandle {
  values?: () => AsyncIterable<FileSystemFileHandle | FileSystemDirectoryHandle | null>;
}

interface FileWithHandleAndPath {
  fileWithHandle: FileWithHandle;
  relativeName: string;
}

/**
 * Recursively get all files from a directory, returning an array of `FileWithHandleAndPath` objects,
 * where the handles are all FileSystemFileHandle objects (allows for LiveFile support).
 */
export async function getAllFilesFromDirectoryRecursively(directoryHandle: FileSystemDirectoryHandle): Promise<FileWithHandleAndPath[]> {
  const list: FileWithHandleAndPath[] = [];
  const separator = '/';

  async function traverseDirectory(dirHandle: ExplorableFileSystemDirectoryHandle, path: string = '') {
    if ('values' in dirHandle && typeof dirHandle.values === 'function') {
      for await (const handle of dirHandle.values()) {
        if (!handle) continue;
        const relativePath = path ? `${path}${separator}${handle.name}` : handle.name;

        if (handle.kind === 'file') {
          const fileWithHandle = await handle.getFile() as FileWithHandle;
          fileWithHandle.handle = handle;
          list.push({
            fileWithHandle: fileWithHandle,
            relativeName: relativePath,
          });
        } else if (handle.kind === 'directory') {
          await traverseDirectory(handle, relativePath);
        }
      }
    }
  }

  await traverseDirectory(directoryHandle);
  return list;
}


/// Helpers for handling DataTransfer items that contain File System Handles, and we need to pre-get all the promises to files/handles upfront.

/*
 * Note: was File | Promise<Handles | null>, but we added and extra File fallback in the promise
 * to handle cases where the handle is null (e.g. Chrome screen captures), which would break the
 * downstream logic.
 */
type FileOrFileHandlePromise = Promise<FileSystemFileHandle | FileSystemDirectoryHandle | File | null> | File;

/**
 * Extracts file system handles or files from a list of data transfer items.
 * Note: the main purpose of this function is to get all the files/handles **upfront** in a
 * datatransfer, as those objects expire with async operations.
 */
export function getDataTransferFilesOrPromises(items: DataTransferItemList, fallbackAsFiles: boolean): FileOrFileHandlePromise[] {
  const results: FileOrFileHandlePromise[] = [];

  for (let i = 0; i < items.length; i++) {
    const item = items[i];
    if (item.kind !== 'file')
      continue;

    // Try to get file system handle if available and not forced to use file
    if ('getAsFileSystemHandle' in item && typeof item.getAsFileSystemHandle === 'function') {
      try {
        const fsHandle = item.getAsFileSystemHandle() as Promise<FileSystemFileHandle | FileSystemDirectoryHandle | null>;
        if (fsHandle)
          results.push(fsHandle.then(handleOrNull => {
            // if null, return a File instead - note that this is a fallback, as we prefer to get the handle
            // but when pasing screen captures from Chrome, the handle will be null, while the file shall
            // still be retrievable.
            return handleOrNull || item.getAsFile();
          }));
        continue;
      } catch (error) {
        console.error('Error getting file system handle:', error);
      }
    }

    // Fallback to getAsFile
    if (fallbackAsFiles) {
      const file = item.getAsFile();
      if (file)
        results.push(file);
    }
  }

  return results;
}


/**
 * Utility function to get the first file system handle from a DataTransfer object.
 * Note that a DataTransfer object can contain multiple files, but we assume the first is the one.
 */
export async function getFirstFileSystemFileHandle(dataTransfer: DataTransfer): Promise<FileSystemFileHandle | null> {

  // get FileSystemFileHandle objects from the DataTransfer
  const fileOrFSHandlePromises = getDataTransferFilesOrPromises(dataTransfer.items, false);
  if (!fileOrFSHandlePromises.length)
    return null;

  // resolve the promises to get the actual files/handles
  const filesOrHandles = await Promise.all(fileOrFSHandlePromises);
  for (let filesOrHandle of filesOrHandles)
    if (!(filesOrHandle instanceof File) && filesOrHandle?.kind === 'file' && filesOrHandle)
      return filesOrHandle;

  // no file system handle found
  return null;
}



================================================
FILE: src/common/util/htmlTableToMarkdown.ts
================================================
/**
 * @fileoverview Utility functions for Markdown.
 */

import { isBrowser } from '~/common/util/pwaUtils';

/**
 * Quick and dirty conversion of HTML tables to Markdown tables.
 * Big plus: doesn't require any dependencies.
 */
export function htmlTableToMarkdown(html: string, includeInvisible: boolean): string {
  const parser = new DOMParser();
  const doc = parser.parseFromString(html, 'text/html');
  const table = doc.querySelector('table');
  if (!table) return '';

  const markdownRows: string[] = [];
  const headerCells = table.querySelectorAll('thead th');
  if (headerCells.length > 0) {
    const headerRow = '| ' + Array.from(headerCells)
      .map(cell => getTextWithSpaces(cell, includeInvisible).trim())
      .join(' | ') + ' |';
    markdownRows.push(headerRow);
    markdownRows.push('|:' + Array(headerCells.length).fill('---').join('|:') + '|');
  }

  const bodyRows = table.querySelectorAll('tbody tr');
  for (const row of Array.from(bodyRows)) {
    const rowCells = row.querySelectorAll('td');
    const markdownRow = '| ' + Array.from(rowCells)
      .map(cell => getTextWithSpaces(cell, includeInvisible).trim())
      .join(' | ') + ' |';
    markdownRows.push(markdownRow);
  }

  return markdownRows.join('\n');
}

// Helper function to get text with spaces, ignoring hidden elements
function getTextWithSpaces(node: Node, includeInvisible: boolean): string {
  let text = '';
  node.childNodes.forEach(child => {
    if (child.nodeType === Node.TEXT_NODE)
      text += child.textContent;
    else if (child.nodeType === Node.ELEMENT_NODE)
      if (includeInvisible || isVisible(child as Element))
        text += ' ' + getTextWithSpaces(child, includeInvisible) + ' ';
  });
  return text;
}

// Helper function to determine if an element is visible
function isVisible(element: Element): boolean {
  if (!isBrowser) return true;

  // if the cell is hidden, don't include it
  const style = window.getComputedStyle(element);
  if (style.display === 'none' || style.visibility === 'hidden')
    return false;

  // Check for common classes used to hide content or indicate tooltip/popover content.
  // You may need to add more classes here based on your actual HTML/CSS.
  const ignoredClasses = ['hidden', 'group-hover', 'tooltip', 'pointer-events-none', 'opacity-0'];
  for (const ignoredClass of ignoredClasses)
    if (element.classList.contains(ignoredClass))
      return false;

  // Otherwise, the element is considered visible
  return true;
}


================================================
FILE: src/common/util/idbUtils.ts
================================================
/**
 * Copyright (c) 2024 Enrico Ros
 *
 * Faster Zustand storage backend serializing objects just before write.
 * Moreover uses a deadline-based scheduler to batch writes, with an aggregation window.
 */

import type { PersistStorage, StorageValue } from 'zustand/middleware';
import { get as idbGet, set as idbSet } from 'idb-keyval';


// [DEV] configuration
const DEBUG_SCHEDULER = false;
const IDB_MERGE_WINDOW = 321;   // not a magic number, just a random value
const IDB_DEADLINE = 1234;      // breaks the pace


type SetKey = string;

type SetOperation = {
  queueDeadline: number | null;
  scheduledTimerId: ReturnType<typeof setTimeout> | null;
  lastState: null | StorageValue<any>;
  needsWrite: boolean;
  isWriting: boolean; // [r: all, w: performWrite]
};


const _warn = (...args: any[]) => console.warn('IndexedDB:', ...args);
const _devWarn = (...args: any[]) => console.warn('[DEV] IndexedDB:', ...args);


class IndexedDBWriteScheduler {

  private writeOperations: Record<SetKey, SetOperation> = {};

  constructor(readonly mergeWindow: number, readonly deadline: number) {
  }


  async getItem<S>(key: SetKey): Promise<StorageValue<S> | null> {
    // in-mem recycle: unexpected, but implemented
    const operation = this.writeOperations[key];
    if (operation && operation.lastState !== null) {
      _devWarn(`unexpected in-mem recycle of '${key}'`);
      return operation.lastState;
    }

    // fetch from IDB
    const jsonState = await this.#idbReadString(key);
    if (jsonState === null) return null; // first time is null (not found in storage)

    // deserialize
    try {
      return JSON.parse(jsonState) as StorageValue<S>;
    } catch (error: any) {
      _warn(`GET: reading error for '${key}':`, error);
      return null;
    }
  }

  setItem<S>(key: SetKey, newValue: StorageValue<S>): void {

    // do not serialize now, just store the object in the work order
    const operation = this.writeOperations[key];
    if (!operation) {
      if (DEBUG_SCHEDULER) _devWarn(`SET.${key} new operation`);
      this.writeOperations[key] = {
        queueDeadline: Date.now() + this.deadline,
        scheduledTimerId: null,
        lastState: newValue,
        needsWrite: true,
        isWriting: false,
      };
    } else {
      if (DEBUG_SCHEDULER) _devWarn(`SET.${key} updating operation`);
      if (!operation.queueDeadline)
        operation.queueDeadline = Date.now() + this.deadline;
      operation.lastState = newValue;
      operation.needsWrite = true;
    }

    // schedule the write
    this.#scheduleWrite(key);
  }

  async setItemDirect<S>(key: SetKey, newValue: StorageValue<S>): Promise<void> {
    return this.#idbWriteString(key, JSON.stringify(newValue));
  }


  // scheduling

  #scheduleWrite(key: SetKey): void {
    const operation = this.writeOperations[key];
    if (!operation) return;

    if (!operation.needsWrite) return;
    if (operation.isWriting) return;

    const now = Date.now();

    const timeUntilMerge = this.mergeWindow;
    const timeUntilDeadline = operation.queueDeadline ? operation.queueDeadline - now : 0; // 0 should not be an option, as state is set correctly
    const delay = Math.max(Math.min(timeUntilMerge, timeUntilDeadline), 0);

    if (delay > 0) {

      // schedule/reshedule the write

      if (DEBUG_SCHEDULER) _devWarn(` - schedule ${key}: ${operation.scheduledTimerId ? 'reschedule' : 'schedule'} in ${delay} ms`);
      if (operation.scheduledTimerId)
        clearTimeout(operation.scheduledTimerId);
      operation.scheduledTimerId = setTimeout(() => {
        void this.#performWrite(key);
      }, delay);

    } else {

      // we are past the deadline

      if (DEBUG_SCHEDULER) _devWarn(` - schedule ${key}: ${operation.scheduledTimerId ? 'just wait (already pending)' : 'schedule 0-delay'}`);
      if (operation.scheduledTimerId) {
        // there's already a timer scheduled, so we don't need to do anything
        return;
      }

      operation.scheduledTimerId = setTimeout(() => {
        void this.#performWrite(key);
      }, 0);
    }
  }

  async #performWrite(key: SetKey): Promise<void> {
    const operation = this.writeOperations[key];
    if (!operation) return;

    // set the state for the scheduling operations to come
    const state = operation.lastState;
    operation.queueDeadline = null;
    if (operation.scheduledTimerId) {
      clearTimeout(operation.scheduledTimerId);
      operation.scheduledTimerId = null;
    }
    operation.lastState = null;
    operation.needsWrite = false;
    operation.isWriting = true;

    try {

      // serialize
      const dateStart = Date.now();
      const serialized = JSON.stringify(state);
      if (DEBUG_SCHEDULER) _devWarn(`SET '${key}': serialized ${serialized?.length?.toLocaleString()} bytes in ${Date.now() - dateStart} ms`);

      // Optimization - ? unsure, needs testing
      // (globalThis as any)?.scheduler?.yield?.();

      // write to IDB
      await this.#idbWriteString(key, serialized);

    } catch (error: any) {
      _warn(`SET '${key}': serialization error:`, error);
    }

    // done
    operation.isWriting = false;

    // schedule the next write
    this.#scheduleWrite(key);

  }


  // with strings

  async #idbReadString(key: SetKey): Promise<string | null> {
    const now = Date.now();
    const counter = ++this.#readOpCounter;
    try {
      if (DEBUG_SCHEDULER) _devWarn(`GET ${key}(${counter})`);
      const jsonState = await idbGet(key) ?? null;
      if (DEBUG_SCHEDULER) _devWarn(jsonState === null ? `GET ${key}(${counter}) -> missing` : `GET ${key}(${counter}) -> read ${jsonState?.length?.toLocaleString()} bytes in ${Date.now() - now} ms`);
      return jsonState;
    } catch (error: any) {
      _warn(`GET '${key}(${counter})': read error:`, error);
      return null;
    }
  }

  async #idbWriteString(key: SetKey, jsonState: string): Promise<void> {
    const now = Date.now();
    const counter = ++this.#writeOpCounter;
    try {
      if (DEBUG_SCHEDULER) _devWarn(`SET ${key}(${counter})`);
      await idbSet(key, jsonState);
      if (DEBUG_SCHEDULER) _devWarn(`SET ${key}(${counter}) -> wrote ${jsonState?.length?.toLocaleString()} bytes in ${Date.now() - now} ms`);
    } catch (error: any) {
      _warn(`SET '${key}(${counter})': write error:`, error);
    }
  }


  // private fields
  #readOpCounter = 0;
  #writeOpCounter = 0;

}


const _idbScheduler = new IndexedDBWriteScheduler(IDB_MERGE_WINDOW, IDB_DEADLINE);

/**
 * Thin adapter to use the new scheduler with Zustand.
 */
export function createIDBPersistStorage<S>(): PersistStorage<S> | undefined {

  // server-side or no IDB support
  if (typeof window === 'undefined')
    return undefined;
  if (!('indexedDB' in window)) {
    _warn('[FATAL] IndexedDB is not supported in this browser.');
    return undefined;
  }

  return {
    getItem: async (name: string): Promise<StorageValue<S> | null> => _idbScheduler.getItem(name),
    setItem: (name: string, newValue: StorageValue<S>): void => _idbScheduler.setItem(name, newValue),
    removeItem: async (_name: string): Promise<void> => {
      // We do NOT remove! We don't intend to implement this, on purpose
    },
  };
}


export async function backupIdbV3(keyFrom: string, keyTo: string): Promise<boolean> {
  try {
    const existingItem = await _idbScheduler.getItem(keyFrom);
    if (existingItem === null) {
      _warn(`idbUtils: backupIdbV3: item not found: '${keyFrom}'`);
      return false;
    }
    await _idbScheduler.setItemDirect(keyTo, existingItem);
    return true;
  } catch (error) {
    _warn(`idbUtils: backupIdbV3: Error backing up from '${keyFrom}' to '${keyTo}':`, error);
    return false;
  }
}

/// Maintenance

/* Sets a single key-value in a given IndexedDB key-value store.

function setValue(dbName, key, value) {
  return new Promise((resolve, reject) => {
    const request = indexedDB.open(dbName);
    request.onerror = event => reject(new Error('Error opening database: ' + event.target.error));
    request.onsuccess = event => {
      const db = event.target.result;
      const transaction = db.transaction('keyval', 'readwrite');
      const store = transaction.objectStore('keyval');

      const updateRequest = store.put(value, key);
      updateRequest.onerror = event => reject(new Error('Error updating JSON string: ' + event.target.error));
      updateRequest.onsuccess = () => resolve('Successfully updated JSON string.');
    };
  });
}

function copyValue(dbName, sourceKey, targetKey) {
  return new Promise((resolve, reject) => {
    const request = indexedDB.open(dbName);
    request.onerror = event => reject(new Error('Error opening database: ' + event.target.error));
    request.onsuccess = event => {
      const db = event.target.result;
      const transaction = db.transaction('keyval', 'readwrite');
      const store = transaction.objectStore('keyval');

      const getRequest = store.get(sourceKey);
      getRequest.onerror = event => reject(new Error('Error retrieving value: ' + event.target.error));
      getRequest.onsuccess = () => {
        const value = getRequest.result;

        if (value === undefined) {
          reject(new Error(`No value found for key: ${sourceKey}`));
          return;
        }

        const putRequest = store.put(value, targetKey);
        putRequest.onsuccess = () => resolve(`Successfully copied value from ${sourceKey} to ${targetKey}.`);
        putRequest.onerror = event => reject(new Error('Error copying value: ' + event.target.error));
      };
    };
  });
}

function deleteValue(dbName, key) {
  return new Promise((resolve, reject) => {
    const request = indexedDB.open(dbName);
    request.onerror = event => reject(new Error('Error opening database: ' + event.target.error));
    request.onsuccess = event => {
      const db = event.target.result;
      const transaction = db.transaction('keyval', 'readwrite');
      const store = transaction.objectStore('keyval');

      const deleteRequest = store.delete(key);
      deleteRequest.onerror = event => reject(new Error('Error deleting value: ' + event.target.error));
      deleteRequest.onsuccess = () => resolve(`Successfully deleted value for key: ${key}.`);
    };
  });
}

// Example usage:
const myNewJsonString = '{"your": "new json string"}'; // Replace with your desired JSON string
await setValue('keyval-store', 'app-chats', myNewJsonString);
await copyValue('keyval-store', 'app-chats-copy', 'app-chats');
await deleteValue('keyval-store', 'app-chats-prev');

*/



================================================
FILE: src/common/util/idUtils.ts
================================================
import { nanoid } from 'nanoid';

// This is here to index all the UUIDs in the application
type UidScope =
  | 'attachment-draft'
  | 'beam-fusion'
  | 'beam-preset-config'
  | 'beam-ray'
  | 'chat-block'
  | 'chat-dconversation'
  | 'chat-dmessage'
  | 'chat-dfragment'
  | 'chat-ephemerals-item'
  | 'chat-folders-item'
  | 'chat-pane'
  | 'clip-history'
  | 'dblob-asset'
  | 'draw-prompt'
  | 'event-id'
  | 'livefile-item'
  | 'logger'
  | 'persona-creator-chain'
  | 'persona-simple'
  | 'processing-queue-task'
  | 'server-storage-deletion-key'
  | 'server-storage-id'
  | 'server-storage-owner'
  | 'snackbar-item'
  | 'variform-variable'
  | 'vector-device-id10'
  ;

/**
 * Application-wide unique identifier generator
 * @param _scope Does not influence the ID generation, but is used to index all the IDs in the application
 */
export function agiUuid(_scope: Exclude<UidScope, 'chat-dfragment'>) {
  return nanoid();
}

/*
 * Smaller version of the above, without claims of uniqueness
 */
export function agiId(scope: Extract<UidScope, 'chat-dfragment' | 'chat-block' | 'vector-device-id10'>) {
  switch (scope) {
    case 'chat-block':
      return nanoid(16);
    case 'chat-dfragment':
      return nanoid(8);
    case 'vector-device-id10':
      return nanoid(10);
  }
}

/*
 * Seldomly used
 */
export function agiCustomId(digits: number) {
  return nanoid(digits);
}


// UUID v4 generation - because in DBs the lookup is faster, although it takes more bytes as a string

type UuidV4Scope =
  | 'conversation-2'
  | 'persona-2'
  ;


/**
 * Generates a UUID v4 using the Web Crypto API
 * @returns A standard UUID v4 string (e.g., '123e4567-e89b-12d3-a456-426614174000')
 */
export function agiUuidV4(_scope: UuidV4Scope): string {
  // for modern browsers and Node.js
  if (typeof crypto !== 'undefined' && crypto.randomUUID)
    return crypto.randomUUID();

  // fallback for missing crypto.randomUUID
  const randomValues = new Uint8Array(16);
  crypto.getRandomValues(randomValues);

  // Set version (4) and variant (RFC4122)
  randomValues[6] = (randomValues[6] & 0x0f) | 0x40;
  randomValues[8] = (randomValues[8] & 0x3f) | 0x80;

  // Convert to hex string and format as UUID
  const hex = Array.from(randomValues)
    .map(b => b.toString(16).padStart(2, '0'))
    .join('');

  return `${hex.slice(0, 8)}-${hex.slice(8, 12)}-${hex.slice(12, 16)}-${hex.slice(16, 20)}-${hex.slice(20)}`;
}

/**
 * Converts a nanoid to a UUID v4 format string. The conversion is:
 * - Deterministic (same nanoid always produces the same UUID)
 * - Maintains randomness properties
 * - Produces valid UUID v4 format (8-4-4-4-12 characters)
 */
export function nanoidToUuidV4(nanoid: string, _scope: 'convert-stored-chat-v1'): string {
  // 1. Create a consistent hash from the nanoid
  const hash = new Uint8Array(16);
  for (let i = 0; i < nanoid.length; i++) {
    // Simple but consistent hash function
    hash[i % 16] ^= nanoid.charCodeAt(i);
  }

  // 2. Ensure UUID v4 format requirements
  // Version 4 UUID has these requirements:
  // - bit 6-7 of clock_seq_hi_and_reserved to 0b10 (RFC 4122)
  // - bit 12-15 of time_hi_and_version to 0b0100 (version 4)
  hash[6] = (hash[6] & 0x0f) | 0x40;  // Version 4
  hash[8] = (hash[8] & 0x3f) | 0x80;  // RFC 4122 variant

  // 3. Convert to hex string
  const hexArray = Array.from(hash).map(b => b.toString(16).padStart(2, '0'));

  // 4. Format as UUID (8-4-4-4-12)
  return [
    hexArray.slice(0, 4).join(''),
    hexArray.slice(4, 6).join(''),
    hexArray.slice(6, 8).join(''),
    hexArray.slice(8, 10).join(''),
    hexArray.slice(10, 16).join(''),
  ].join('-');
}


/*
// Similar to the above but makes sure there's no collision with the given list of IDs
export function agiUuidUncollided(scope: Extract<UidScope, 'chat-dfragment'>, existingIds: string[]) {
  const characters = scope === 'chat-dfragment' ? 8 : 21;
  let id: string;
  do {
    id = nanoid(characters);
  } while (existingIds.includes(id));
  return id;
}
*/

/*
import { v4 as uuidv4 } from 'uuid';

export function createBase64UuidV4(): string {
  return uuidToBase64(uuidv4());
}

function uuidToBase64(uuid: string): string {
  // Remove hyphens from the UUID
  const cleanUuid = uuid.replaceAll('-', '');

  // Convert the cleaned UUID to a byte array
  const uuidBytes = new Uint8Array(16);
  for (let i = 0; i < 32; i += 2)
    uuidBytes[i / 2] = parseInt(cleanUuid.substring(i, i + 2), 16);

  // Convert byte array to a Base64 string
  const base64 = btoa(String.fromCharCode.apply(null, uuidBytes as any));

  // Remove '=' end padding
  return base64.replace(/=+$/, '');
}
 */


================================================
FILE: src/common/util/imageUtils.ts
================================================
/**
 * Copyright (c) 2024-2025 Enrico Ros
 *
 * Functions to deal with images from the frontend.
 * Also see videoUtils.ts for more image-related functions.
 */

import { DEFAULT_ADRAFT_IMAGE_MIMETYPE, DEFAULT_ADRAFT_IMAGE_QUALITY } from '../attachment-drafts/attachment.pipeline';

import { asyncCanvasToBlobWithValidation } from './canvasUtils';

// configuration
const IMAGE_DIMENSIONS = {
  ANTHROPIC_MAX_SIDE: 1568,
  GOOGLE_MAX_SIDE: 3072,
  OPENAI_HIGH_RES_MAX_SIDE: 2048,
  OPENAI_HIGH_RES_MIN_SIDE: 768,
  OPENAI_LOW_RES_SIDE: 512,
  THUMBNAIL_128: 128,
  THUMBNAIL_256: 256,
} as const;


export type CommonImageMimeTypes = 'image/png' | 'image/jpeg' | 'image/webp';
export type LLMImageResizeMode = 'openai-low-res' | 'openai-high-res' | 'google' | 'anthropic' | 'thumbnail-128' | 'thumbnail-256';


/**
 * Converts an SVG string to a PNG Blob via an intermediate canvas.
 */
export async function renderSVGToPNGBlob(svgCode: string, transparentBackground: boolean, renderScale: number = 2.0): Promise<Blob | null> {
  if (!svgCode) return null;

  // Create a Blob URL for the SVG
  const svgBlob = new Blob([svgCode], { type: 'image/svg+xml;charset=utf-8' });
  const url = URL.createObjectURL(svgBlob);

  // Load the SVG image
  const img = new Image();
  img.crossOrigin = 'anonymous';
  img.src = url;
  await new Promise<void>((resolve, reject) => {
    img.onload = () => resolve();
    img.onerror = (e) => {
      console.error('Error loading SVG image:', e);
      reject(e);
    };
  });

  // Prepare canvas @[Scale]x, e.g. @2x
  const canvasWidth = img.width * renderScale;
  const canvasHeight = img.height * renderScale;
  const canvas = document.createElement('canvas');
  canvas.width = canvasWidth;
  canvas.height = canvasHeight;
  const ctx = canvas.getContext('2d');
  if (!ctx) {
    URL.revokeObjectURL(url);
    return null;
  }

  // Handle background
  if (!transparentBackground) {
    // TODO: make it responsive, such as with:
    // document.querySelector('html')?.getAttribute('data-joy-color-scheme') === 'dark'
    // ctx.fillStyle = '#FFFFFF';
    // ctx.fillRect(0, 0, canvasWidth, canvasHeight);
  } else {
    // clear the canvas to ensure transparency
    ctx.clearRect(0, 0, canvasWidth, canvasHeight);
  }

  // Draw the SVG image @2x
  ctx.drawImage(img, 0, 0, canvasWidth, canvasHeight);

  // Convert canvas to PNG Blob, and we're done
  try {
    const { blob } = await asyncCanvasToBlobWithValidation(canvas, 'image/png', undefined, 'renderSVGToPNGBlob');
    return blob;
  } finally {
    URL.revokeObjectURL(url);
  }
}


// ===== BLOB-BASED IMAGE UTILITIES =====

interface ImageTransformOptions {
  /** Resize mode for the image, if specified. */
  resizeMode?: LLMImageResizeMode,
  /** If unspecified, we'll use the DEFAULT_ADRAFT_IMAGE_MIMETYPE (webp for chrome/firefox, jpeg for safari which doesn't encode webp) */
  convertToMimeType?: 'image/png' | 'image/jpeg' | 'image/webp',
  /** If specified, we'll use the DEFAULT_ADRAFT_IMAGE_QUALITY */
  convertToLossyQuality?: number, // 0-1, only used if convertToMimeType is lossy (jpeg or webp)
  /** If true, resize errors (image decode, canvas drawImage) will throw (default: false) Note that if the image does not need to be resized, this will not throw. */
  throwOnResizeError?: boolean,
  /** If true, type conversion errors (image type conversion) will throw (default: false) */
  throwOnTypeConversionError?: boolean,
  /** If set, prints conversion stats (if converted) to the console */
  debugConversionLabel?: string,
}

interface ImageTransformOperationResult extends ImageOperationResult {
  hasResized: boolean;
  hasTypeConverted: boolean;
  initialSize: number;
  initialType: string;
  // finalSize: number;
  // sizeRatio: number; // percentage difference in size compared to the initial size
}

interface ImageOperationResult {
  blob: Blob;
  // if either width or height is 0, the dimension could not be determined
  width: 0 | number;
  height: 0 | number;
}


/**
 * Transform/resize/convert an image Blob based on the provided options.
 * By default this function does not throw on errors, at worst returning the same input Blob without dimension information.
 * @throws error if resizing or type conversion fails and the respective options are set to throwOnResizeError or throwOnTypeConversionError.
 */
export async function imageBlobTransform(inputImage: Blob, options: ImageTransformOptions): Promise<ImageTransformOperationResult> {

  // remember the initial state, for stats
  const initialSize: number = inputImage.size;
  const initialType: string = inputImage.type;

  // working state - for pipeline-like processing
  let workingBlob: Blob = inputImage;
  let workingWidth: number = 0;
  let workingHeight: number = 0;


  // 1. Resize & Format-convert image if requested
  let hasResized = false;
  let hasTypeConverted = false;
  const toMimeType = options.convertToMimeType || DEFAULT_ADRAFT_IMAGE_MIMETYPE;
  const toLossyQuality = options.convertToLossyQuality ?? DEFAULT_ADRAFT_IMAGE_QUALITY;
  if (options.resizeMode) {

    // if null, resizing was not needed or possible (size could not be a fit)
    // this will throw an error if the resizeMode is not supported
    try {
      const resized = await imageBlobResizeIfNeeded(
        workingBlob,
        options.resizeMode,
        toMimeType,
        toLossyQuality,
      );
      if (resized) {
        hasResized = true;
        hasTypeConverted = (resized.blob.type !== workingBlob.type);
        workingBlob = resized.blob;
        workingWidth = resized.width;
        workingHeight = resized.height;
      }
    } catch (resizeError) {
      console.warn('[DEV] transformImageBlob: Error resizing image:', { resizeError });
      if (options.throwOnResizeError)
        throw new Error(`Failed to resize image: ${resizeError instanceof Error ? resizeError.message : String(resizeError)}`);
    }
  }

  // 2. Convert to a target mimetype if requested
  if (options.convertToMimeType && workingBlob.type !== options.convertToMimeType) {
    try {
      const converted = await imageBlobConvertType(
        workingBlob,
        options.convertToMimeType,
        toLossyQuality,
      );
      hasTypeConverted = true;
      workingBlob = converted.blob;
      workingWidth = converted.width || workingWidth;
      workingHeight = converted.height || workingHeight;
    } catch (typeConversionError) {
      console.warn('[DEV] transformImageBlob: Error converting image type:', { typeConversionError });
      if (options.throwOnTypeConversionError)
        throw new Error(`Failed to convert image type: ${typeConversionError instanceof Error ? typeConversionError.message : String(typeConversionError)}`);
    }
  }

  // 3. Find out the image dimensions if not available (frontend)
  if (!workingWidth || !workingHeight) {
    try {
      const dimensions = await imageBlobGetDimensions(workingBlob);
      workingWidth = dimensions.width || 0;
      workingHeight = dimensions.height || 0;
    } catch (dimError) {
      // sizing failed, but this is not fatal
      console.log('[DEV] Failed to get image dimensions from Blob:', { dimError });
    }
  }

  // return the result
  if (options.debugConversionLabel && (hasResized || hasTypeConverted)) {
    const finalSize = workingBlob.size;
    const sizeRatio = (initialSize && finalSize) ? Math.round(((finalSize - initialSize) / initialSize) * 100) : 1;
    console.log(`[${options.debugConversionLabel}] stored generated ${initialType} -> ${workingBlob.type} (quality:${toLossyQuality}, ${sizeRatio}% reduction, ${initialSize?.toLocaleString()} -> ${finalSize?.toLocaleString()})`);
  }

  return {
    blob: workingBlob,
    width: workingWidth,
    height: workingHeight,
    hasResized: hasResized,
    hasTypeConverted: hasTypeConverted,
    initialType: initialType,
    initialSize: initialSize,
  };
}


/**
 * Asynchronously gets the dimensions of a Blob image.
 */
export async function imageBlobGetDimensions(imageBlob: Blob): Promise<{ width: number, height: number }> {
  return new Promise((resolve, reject) => {
    const image = new Image();
    image.crossOrigin = 'Anonymous';
    image.onload = () => {
      URL.revokeObjectURL(image.src);
      resolve({ width: image.width, height: image.height });
    };
    image.onerror = (error: string | Event) => {
      URL.revokeObjectURL(image.src);
      console.warn('Failed to load image blob for dimension extraction.', { error });
      reject(new Error('Failed to load image blob for dimension extraction.'));
    };
    image.src = URL.createObjectURL(imageBlob);
  });
}


/**
 * Converts an image Blob to a different format and returns the new Blob with dimensions.
 * @throws error if the conversion fails.
 */
export async function imageBlobConvertType(imageBlob: Blob, toMimeType: CommonImageMimeTypes, toLossyQuality: number): Promise<ImageOperationResult> {
  return new Promise((resolve, reject) => {
    const image = new Image();
    image.crossOrigin = 'Anonymous';
    image.onload = () => {
      URL.revokeObjectURL(image.src);

      const canvas = document.createElement('canvas');
      canvas.width = image.width;
      canvas.height = image.height;
      const ctx = canvas.getContext('2d');
      if (!ctx)
        return reject(new Error('Failed to get canvas context for conversion'));
      ctx.drawImage(image, 0, 0);

      // Convert canvas to Blob with validation
      asyncCanvasToBlobWithValidation(canvas, toMimeType, toLossyQuality, 'imageBlobConvertType')
        .then(({ blob }) => resolve({ blob, width: image.width, height: image.height }))
        .catch((reason) => reject(new Error(`Failed to convert image blob to '${toMimeType}': ${reason instanceof Error ? reason.message : String(reason)}`)));
    };
    image.onerror = (error: string | Event) => {
      URL.revokeObjectURL(image.src);
      console.warn('Failed to load image blob for conversion.', { error });
      reject(new Error('Failed to load image blob for type conversion.'));
    };
    image.src = URL.createObjectURL(imageBlob);
  });
}


/**
 * Resizes an image Blob if needed based on the specified resize mode.
 * Does not throw if resize if not needed, only returns null (and does not adapt the mime).
 * @throws error if the resize mode is unsupported or if resizing fails.
 */
export async function imageBlobResizeIfNeeded(imageBlob: Blob, resizeMode: LLMImageResizeMode, toMimeType: CommonImageMimeTypes, toLossyQuality: number): Promise<null | ImageOperationResult> {
  const image = new Image();
  image.crossOrigin = 'Anonymous';

  return new Promise((resolve, reject) => {
    image.onload = () => {
      URL.revokeObjectURL(image.src);

      const originalWidth = image.width;
      const originalHeight = image.height;

      let newWidth: number = originalWidth;
      let newHeight: number = originalHeight;
      let shouldResize = false;

      switch (resizeMode) {
        case 'anthropic':
          // Resize to fit within 1568px on the long edge
          const maxSideAnthropic = IMAGE_DIMENSIONS.ANTHROPIC_MAX_SIDE;
          if (originalWidth > maxSideAnthropic || originalHeight > maxSideAnthropic) {
            shouldResize = true;
            if (originalWidth > originalHeight) {
              newWidth = maxSideAnthropic;
              newHeight = Math.round((originalHeight / originalWidth) * maxSideAnthropic);
            } else {
              newHeight = maxSideAnthropic;
              newWidth = Math.round((originalWidth / originalHeight) * maxSideAnthropic);
            }
          }
          break;

        case 'google':
          // Google: Resize to fit within 3072x3072
          const maxSideGoogle = IMAGE_DIMENSIONS.GOOGLE_MAX_SIDE;
          if (originalWidth > maxSideGoogle || originalHeight > maxSideGoogle) {
            shouldResize = true;
            if (originalWidth > originalHeight) {
              newWidth = maxSideGoogle;
              newHeight = Math.round((originalHeight / originalWidth) * maxSideGoogle);
            } else {
              newHeight = maxSideGoogle;
              newWidth = Math.round((originalWidth / originalHeight) * maxSideGoogle);
            }
          }
          break;

        case 'openai-high-res':
          // OpenAI:
          // 1. Scale down to fit within 2048x2048
          const maxSideOpenAI = IMAGE_DIMENSIONS.OPENAI_HIGH_RES_MAX_SIDE;
          if (originalWidth > maxSideOpenAI || originalHeight > maxSideOpenAI) {
            shouldResize = true;
            if (originalWidth > originalHeight) {
              newWidth = maxSideOpenAI;
              newHeight = Math.round((originalHeight / originalWidth) * maxSideOpenAI);
            } else {
              newHeight = maxSideOpenAI;
              newWidth = Math.round((originalWidth / originalHeight) * maxSideOpenAI);
            }
          }

          // 2. Scale down to 768px on the shortest side (if larger) - maintain aspect ratio
          const minSideOpenAI = IMAGE_DIMENSIONS.OPENAI_HIGH_RES_MIN_SIDE;
          if (newWidth > newHeight && newHeight > minSideOpenAI) {
            shouldResize = true;
            newWidth = Math.round((newWidth / newHeight) * minSideOpenAI);
            newHeight = minSideOpenAI;
          } else if (newWidth < newHeight && newWidth > minSideOpenAI) {
            shouldResize = true;
            newHeight = Math.round((newHeight / newWidth) * minSideOpenAI);
            newWidth = minSideOpenAI;
          }
          break;

        case 'openai-low-res':
          // Resize to 512x512 if any side is larger
          if (originalWidth <= IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE && originalHeight <= IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE) {
            resolve(null);
            return;
          }

          const lrScaleMode = 'keep-aspect-ratio' as ('stretch' | 'keep-aspect-ratio');
          switch (lrScaleMode) {
            case 'stretch':
              newWidth = IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE;
              newHeight = IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE;
              shouldResize = true;
              break;

            case 'keep-aspect-ratio':
              if (originalWidth > originalHeight) {
                newWidth = IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE;
                newHeight = Math.round((originalHeight / originalWidth) * IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE);
              } else {
                newHeight = IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE;
                newWidth = Math.round((originalWidth / originalHeight) * IMAGE_DIMENSIONS.OPENAI_LOW_RES_SIDE);
              }
              shouldResize = true;
              break;
          }
          break;

        case 'thumbnail-128':
        case 'thumbnail-256':
          shouldResize = true;
          const maxSideThumbnail = resizeMode === 'thumbnail-128' ? IMAGE_DIMENSIONS.THUMBNAIL_128 : IMAGE_DIMENSIONS.THUMBNAIL_256;
          if (originalWidth > maxSideThumbnail || originalHeight > maxSideThumbnail) {
            if (originalWidth > originalHeight) {
              newWidth = maxSideThumbnail;
              newHeight = Math.round((originalHeight / originalWidth) * maxSideThumbnail);
            } else {
              newHeight = maxSideThumbnail;
              newWidth = Math.round((originalWidth / originalHeight) * maxSideThumbnail);
            }
          }
          break;

        default:
          reject(new Error('Unsupported resize mode'));
          return;
      }

      if (!shouldResize) {
        resolve(null);
        return;
      }

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      if (!ctx)
        return reject(new Error('Failed to get canvas context for resizing'));

      canvas.width = newWidth;
      canvas.height = newHeight;
      ctx.drawImage(image, 0, 0, newWidth, newHeight);

      // Convert canvas to Blob with validation
      asyncCanvasToBlobWithValidation(canvas, toMimeType, toLossyQuality, 'imageBlobResizeIfNeeded')
        .then(({ blob }) => resolve({ blob, width: newWidth, height: newHeight }))
        .catch((reason) => reject(new Error(`Failed to resize image to '${resizeMode}' as '${toMimeType}': ${reason instanceof Error ? reason.message : String(reason)}`)));
    };

    image.onerror = (error: string | Event) => {
      URL.revokeObjectURL(image.src);
      console.warn('[DEV] Failed to load image blob for resizing.', { error });
      reject(new Error('Failed to load image blob for resizing.'));
    };

    // this starts the decoding
    image.src = URL.createObjectURL(imageBlob);
  });
}


================================================
FILE: src/common/util/jsonUtils.ts
================================================
import * as z from 'zod/v4';

import { maybeDebuggerBreak } from '~/common/util/errorUtils';


// configuration
const ENABLE_NON_STANDARD = false; // if true, it will enable 'undefined' as a valid value in JSON objects


//
// JSON validation - used before saving to DB/sync transmission - to ensure valid structure
//

const literalSchema = z.union([
  z.string(),
  z.number(),
  z.boolean(),
  z.null(),
  // NON-STANDARD, but adding this because we do have 'undefined' in in-mem objects
  ...(ENABLE_NON_STANDARD ? [z.undefined()] : []),
]);

type Literal = z.infer<typeof literalSchema>;
type Json = Literal | Json[] | { [key: string]: Json };

const jsonSchema: z.ZodType<Json> = z.lazy(() =>
  z.union([
    literalSchema,
    z.array(jsonSchema),
    z.record(z.string(), jsonSchema),
  ]),
);

/**
 * Checks if the given value is a valid JSON object, which will be serialized
 * without errors for storage or transmission.
 */
export function isValidJson(value: unknown, debugLocation: string): value is Json {
  const result = jsonSchema.safeParse(value);
  if (result.success)
    return true;

  console.log(`[DEV] ${debugLocation}: Invalid JSON:`, { error: result.error });
  maybeDebuggerBreak();
  return result.success;
}



================================================
FILE: src/common/util/pdfUtils.ts
================================================
import { canvasToDataURLAndMimeType } from './canvasUtils';

// configuration
const SKIP_LOADING_IN_DEV = false;

/**
 * Extracts text from a PDF file
 *
 * Uses the Next.js dynamic import feature to import the 'pdfjs-dist' library
 * only when this function is called. This allows the 'pdfjs-dist' library to
 * be bundled into a separate chunk, which is only loaded when this function
 * is called. This is useful because the 'pdfjs-dist' library is quite large,
 * and we don't want to load it unless we need to. [Faster startup time!]
 *
 * @param pdfBuffer The content of a PDF file
 * @param onProgress A callback function to report the progress of the text extraction
 */
export async function pdfToText(pdfBuffer: ArrayBuffer, onProgress: (progress: number) => void): Promise<string> {
  const { getDocument } = await dynamicImportPdfJs();
  if (!getDocument) {
    console.log('pdfToText: [dev] pdfjs-dist loading skipped');
    return '';
  }
  const pdf = await getDocument({ data: pdfBuffer }).promise;
  const textPages: string[] = []; // Initialize an array to hold text from all pages
  onProgress(0);

  for (let i = 1; i <= pdf.numPages; i++) {

    const page = await pdf.getPage(i);
    onProgress(i / pdf.numPages);

    const content = await page.getTextContent();
    const strings = content.items
      .filter(isTextItem) // Use the type guard to filter out items with the 'str' property
      .map((item) => (item as { str: string }).str); // Use type assertion to ensure that the item has the 'str' property
    onProgress((i * 3 + 1) / (pdf.numPages * 3));

    // textPages.push(strings.join(' ')); // Add the joined strings to the array
    // New way: join the strings to form a page text. treat empty lines as newlines, otherwise join with a space (or not if the line is just 1 space)
    textPages.push(strings.reduce((acc, str) => {
      // empty line -> newline
      if (str === '')
        return acc + '\n';

      // single space
      if (str === ' ')
        return acc + str;

      // trick: de-hyphenation of consecutive lines
      if (/\w-$/.test(acc) && /^\w/.test(str))
        return acc.slice(0, -1) + str;

      // add a space if the last char is not a space or return (regex)
      if (/\S$/.test(acc))
        return acc + ' ' + str;

      // otherwise just concatenate
      return acc + str;
    }, ''));
    onProgress((i * 3 + 2) / (pdf.numPages * 3));
  }

  onProgress(1);
  return textPages.join('\n\n'); // Join all the page texts at the end
}


interface PdfPageImage {
  mimeType: string;
  base64Data: string;
  scale: number;
  width: number;
  height: number;
}

/**
 * Renders all pages of a PDF to images
 *
 * @param pdfBuffer The content of a PDF file
 * @param imageMimeType The MIME type of the image to render (default 'image/jpeg')
 * @param imageQuality The quality of the image (default 0.95 for moderate quality)
 * @param scale The scale factor for the image resolution (default 1.5 for moderate quality)
 * @param onProgress A callback function to report the progress of the image rendering
 */
export async function pdfToImageDataURLs(pdfBuffer: ArrayBuffer, imageMimeType: string, imageQuality: number /* = 0.95 */, scale: number /*= 1.5*/, onProgress: (progress: number) => void): Promise<PdfPageImage[]> {
  const { getDocument } = await dynamicImportPdfJs();
  if (!getDocument) {
    console.log('pdfToImageDataURLs: [dev] pdfjs-dist loading skipped');
    return [];
  }
  const pdf = await getDocument({ data: pdfBuffer }).promise;
  const images: PdfPageImage[] = [];

  for (let i = 1; i <= pdf.numPages; i++) {

    const page = await pdf.getPage(i);
    onProgress(i / pdf.numPages);

    const viewport = page.getViewport({ scale });
    const canvas = document.createElement('canvas');
    const context = canvas.getContext('2d')!;
    canvas.height = viewport.height;
    canvas.width = viewport.width;
    onProgress((i * 3 + 1) / (pdf.numPages * 3));

    await page.render({
      canvasContext: context,
      viewport,
    }).promise;

    // Convert canvas image to a DataURL string
    try {
      const { mimeType: actualMimeType, base64Data } = canvasToDataURLAndMimeType(canvas, imageMimeType, imageQuality, 'pdf-to-image');
      images.push({
        mimeType: actualMimeType,
        base64Data,
        scale,
        width: viewport.width,
        height: viewport.height,
      });
    } catch (error) {
      console.warn(`pdfToImageDataURLs: failed to convert image to ${imageMimeType}.`, { error });
    }
    onProgress((i * 3 + 2) / (pdf.numPages * 3));
  }

  onProgress(1);
  return images;
}


// Dynamically import the 'pdfjs-dist' library
async function dynamicImportPdfJs() {
  // https://github.com/vercel/turbo/issues/4795#issuecomment-2153074851
  // Disable loading 'pdfjs-dist' during development to make --turbo work
  if (SKIP_LOADING_IN_DEV && process.env.NODE_ENV === 'development') {
    return { getDocument: null };
  } else {
    // Dynamically import the 'pdfjs-dist' library [nextjs]
    const { getDocument, GlobalWorkerOptions } = await import('pdfjs-dist');

    // Set the worker script path
    GlobalWorkerOptions.workerSrc = '/workers/pdf.worker.min.mjs';

    return { getDocument };
  }
}

// Type guard to check if an item has a 'str' property
function isTextItem(item: any): item is { str: string } {
  return 'str' in item && typeof item.str === 'string';
}


================================================
FILE: src/common/util/perfUtils.ts
================================================
type StopMeasureInterval = () => void;

export function perfMeasureInterval(measureName: string): StopMeasureInterval {
  performance.mark?.(measureName + '-start');
  return () => {
    performance.mark?.(measureName + '-end');
    performance.measure?.(measureName, measureName + '-start', measureName + '-end');
  };
}


================================================
FILE: src/common/util/promptUtils.ts
================================================
/**
 * This function performs expansion of variables and evaluates ternary expressions.
 * Recursion occurs only within the trueBranch and falseBranch of ternary expressions.
 *
 * Simple variable replacement:
 * - {{varName}} -> replaced with variables[varName]
 *
 * Ternary expressions:
 * - {{varCondition ? 'true string' : 'false string'}} -> if variables[varCondition] is truthy, replace with 'true string', else replace with 'false string'
 *
 * Combined Ternary:
 * - {{varCondition ? 'string with {{innerVar}}' : 'string with {{anotherVar}}'}} -- this should work really well, but it's only been used once
 *
 */
export function processPromptTemplate(
  template: string,
  variables: Record<string, string | boolean>,
  templateName: string
): string {

  // match ternary expressions and simple variables
  const regex = /{{\s*(\w+)\s*\?\s*'(.*?)'\s*:\s*'(.*?)'\s*}}|{{\s*(\w+)\s*}}/g;

  // keep track of missing variables
  const missingVariables = new Set<string>();

  // Replace variables and evaluate ternary expressions
  const replacedStr = template.replace(
    regex,
    (match, key1, trueValue, falseValue, key2) => {
      const key = key1 || key2; // key can be in either group
      const value = variables[key];

      // Variable is missing
      if (value === undefined) {
        missingVariables.add(key);
        return '';
      }

      // Ternary conditional
      if (trueValue !== undefined && falseValue !== undefined) {
        const branch = value ? trueValue as string : falseValue as string;

        // Replace variables within the selected branch
        return branch.replace(/{{\s*(\w+)\s*}}/g, (m, varName) => {
          const varValue = variables[varName];
          if (varValue === undefined || typeof varValue !== 'string') {
            missingVariables.add(varName);
            return '';
          }
          return varValue;
        });
      } else {
        // Simple variable replacement
        if (typeof value !== 'string') {
          missingVariables.add(key);
          return '';
        }
        return value;
      }
    }
  );

  // [DEV] Warn for every variable that is not replaced
  if (process.env.NODE_ENV === 'development' && missingVariables.size > 0)
    console.warn(`[DEV] Missing variables in template "${templateName}" (or wrong types):`, Array.from(missingVariables));

  return replacedStr;
}



================================================
FILE: src/common/util/pwaUtils.ts
================================================
import { Brand } from '../app.config';

// True if run in the browser
export const isBrowser = typeof window !== 'undefined';

// Safe (brittle) lower case user agent string - brittle, but we mostly use it for optional features
const _safeUA = isBrowser ? window.navigator?.userAgent.toLowerCase() || '' : '';


// Frontend Environment Classification
export const Is = {
  Desktop: !/mobile|android|iphone|ipad|ipod/.test(_safeUA),
  Browser: {
    Chrome: _safeUA.includes('chrome') || _safeUA.includes('crios'),
    get Safari() {
      return _safeUA.includes('safari') && !this.Chrome && !_safeUA.includes('chromium');
    },
    Firefox: _safeUA.includes('firefox') || _safeUA.includes('fxios'),
    Edge: _safeUA.includes('edg'),
    Opera: _safeUA.includes('opr') || _safeUA.includes('opera'),
  },
  OS: {
    iOS: /ip(hone|od|ad)/.test(_safeUA),
    Android: _safeUA.includes('android'),
    MacOS: /macintosh|macintel|macppc|mac68k/.test(_safeUA),
    Windows: _safeUA.includes('windows'),
    Linux: _safeUA.includes('linux'),
  },
  Deployment: {
    Localhost: clientHostName().includes('localhost:300'),
    VercelFromBackendOrSSR: !!process.env.VERCEL_ENV,
    VercelFromFrontend: !!process.env.NEXT_PUBLIC_VERCEL_URL,
  },
} as const;


// Frontend Language
export const BrowserLang = {
  get orUS() {
    return (isBrowser ? window.navigator.language : '') || 'en-US';
  },
  get notUS() {
    return this.orUS !== 'en-US';
  },
} as const;


/**
 * Returns 'true' if the application is being executed as a 'PWA' (e.g., installed, stand-alone)
 */
export function isPwa(): boolean {
  return isBrowser ? window.matchMedia('(display-mode: standalone)').matches : false;
}

/**
 * Generates a human-readable device name with improved accuracy.
 * Handles browser precedence correctly, considers PWA status.
 *
 * Examples: "Windows Edge", "iPhone Safari", "Android Chrome (App)"
 */
export function generateDeviceName(): string {
  if (!isBrowser) return 'Server';

  // Get platform information
  let platform: string;

  // Check specific mobile devices first
  if (Is.OS.iOS) {
    if (_safeUA.includes('ipad')) platform = 'iPad';
    else if (_safeUA.includes('ipod')) platform = 'iPod';
    else platform = 'iPhone';
  }
  // Then check for Android
  else if (Is.OS.Android) {
    platform = 'Android';
  }
  // Then desktop OSes
  else if (Is.OS.Windows) {
    platform = 'Windows';
  } else if (Is.OS.MacOS) {
    platform = 'Mac';
  } else if (Is.OS.Linux) {
    platform = 'Linux';
  }
  // Fallback to form factor if OS detection fails
  else {
    platform = Is.Desktop ? 'Desktop' : 'Mobile';
  }

  // Get browser with correct precedence (order matters!)
  let browser: string;
  if (Is.Browser.Edge) browser = 'Edge';
  else if (Is.Browser.Opera) browser = 'Opera';
  else if (Is.Browser.Firefox) browser = 'Firefox';
  else if (Is.Browser.Chrome) browser = 'Chrome';
  else if (Is.Browser.Safari) browser = 'Safari';
  else browser = 'Browser';

  // Check for PWA status
  const isPwaInstalled = isPwa();
  const pwaIndicator = isPwaInstalled ? ' (App)' : '';

  // Format the name based on platform and browser
  return `${platform} ${browser}${pwaIndicator}`;
}

/// Web Share ///

export function webSharePresent(): boolean {
  return isBrowser && !!navigator.share;
}

export function webShare(title: string, text: string, url: string, onShared?: () => void): void {
  if (isBrowser && navigator.share)
    navigator
      .share({ title, text, url })
      .then(() => onShared?.())
      .catch((error) => {
        console.error('Error sharing', error);
        alert('Sharing failed. This browser may not support sharing.');
      });
}


/// Client Host Names ///

export function clientHostName(): string {
  return isBrowser ? window.location.host : '';
}

export function clientUtmSource(campaign?: string): string {
  const host = clientHostName();
  if (!host) return '';
  return '?utm_source=' + host + '&utm_medium=' + Brand.Title.Base.toLowerCase() + (campaign ? `&utm_campaign=${campaign}` : '');
}


/// Delayed Idle Runner ///

/**
 * Schedules a callback to be executed during the browser's idle periods or after a specified timeout.
 *
 * @param callback - The callback function to execute.
 * @param timeout - The maximum time to wait before executing the callback, in milliseconds.
 * @returns A cleanup function that can be used to cancel the scheduled callback (e.g., on an unmount).
 */
export function runWhenIdle(callback: () => void, timeout: number): () => void {
  if (!isBrowser) {
    console.warn('runWhenIdle is only supported in browser environments.');
    // Return a no-op function for non-browser environments
    return () => {
    };
  }

  // Schedule the callback using either requestIdleCallback or setTimeout
  const usingIdleCallback = 'requestIdleCallback' in window;
  let handle = usingIdleCallback
    ? window.requestIdleCallback(callback, { timeout })
    : setTimeout(callback, timeout);

  // Return a cleanup function
  return () => {
    if (usingIdleCallback)
      window.cancelIdleCallback(handle as number);
    else
      clearTimeout(handle);
  };
}



================================================
FILE: src/common/util/screenCaptureUtils.ts
================================================
import { Is, isBrowser } from './pwaUtils';
import { renderVideoFrameAsFile } from '~/common/util/videoUtils';


// Check if the browser supports screen capture
export const supportsScreenCapture = isBrowser && !!navigator.mediaDevices?.getDisplayMedia;


export async function takeScreenCapture(): Promise<File | null> {
  if (!supportsScreenCapture) return null;

  // detect a browser issue
  const startTime = Date.now();

  // open a media stream to capture the screen, which shows the user a dialog to select the screen to capture
  let mediaStream: MediaStream;
  try {
    mediaStream = await navigator.mediaDevices.getDisplayMedia({ video: true });
  } catch (error: any) {
    // User did not grant permission to capture screen
    if (error.name === 'NotAllowedError') {

      // Safari on macOS has a known issue where canceling the window selection causes a 60-second delay
      // before throwing the permission error. We detect this case and provide a user-friendly message.
      if (Is.Browser.Safari && Is.OS.MacOS && (Date.now() - startTime) > 50000)
        throw new Error('Safari took about a minute to detect that the user canceled window selection. It is faster to select any window and then delete the attachment rather than canceling.');

      return null;
    }
    // else, rethrow
    throw error;
  }

  // connect a video element to the media stream, to capture a frame
  const video: HTMLVideoElement = document.createElement('video');
  video.srcObject = mediaStream;

  // wait for the video to load
  const metadataLoaded = new Promise((resolve) => {
    video.onloadedmetadata = () => resolve(null);
  });
  await video.play();
  await metadataLoaded;

  // short timeout to ensure the video frame is ready
  await new Promise((resolve) => setTimeout(resolve, 200));

  // capture a frame (or throw)
  try {
    const file = await renderVideoFrameAsFile(video, 'capture', 'image/png');
    _stopScreenCaptureStream(mediaStream, video);
    return file;
  } catch (error) {
    _stopScreenCaptureStream(mediaStream, video);
    throw error;
  }
}

function _stopScreenCaptureStream(mediaStream: MediaStream, videoElement: HTMLVideoElement) {
  try {
    mediaStream.getTracks().forEach(track => track.stop());
  } catch (error) {
    // ...
  }

  // [stop] close the video element
  try {
    videoElement.pause();
    videoElement.srcObject = null;
    videoElement.onloadedmetadata = null;
    videoElement.remove();
  } catch (error) {
    // ...
  }
}


================================================
FILE: src/common/util/stateUtils.tsx
================================================
// import * as React from 'react';
// import { StoreApi } from 'zustand';
//
//
// // https://x.com/mattpocockuk/status/1780865485325979685?s=46&t=cmQVCdpY7_bVoOftn8NIcg
// const createZustandContext = <TInitial, TStore extends StoreApi<any>, >(getStore: (initial: TInitial) => TStore) => {
//   const Context = React.createContext(
//     null as any as TStore,
//   );
//
//   const Provider = (props: {
//     children?: React.ReactNode;
//     initialValue: TInitial;
//   }) => {
//     const [store] = React.useState(() =>
//       getStore(props.initialValue),
//     );
//
//     return (
//       <Context.Provider value={store}>
//         {props.children}
//       </Context.Provider>
//     );
//   };
//
//   return {
//     useContext: () => React.useContext(Context),
//     Context,
//     Provider,
//   };
// };


================================================
FILE: src/common/util/storageUtils.ts
================================================
import { isBrowser } from '~/common/util/pwaUtils';

// enable debugging of the persistent storage
const DEBUG_PERSISTENCE = false;

// track if persistent storage has been granted already
let _alreadyGranted = false;

/**
 * Request persistent storage for the current origin, so that indexedDB's content is not evicted.
 */
export async function requestPersistentStorageSafe(): Promise<boolean> {
  // if already granted in this session, return true immediately
  if (_alreadyGranted)
    return true;

  try {
    if (isBrowser && navigator.storage && navigator.storage.persist) {
      const isPersisted = await navigator.storage.persisted();
      if (isPersisted) {
        if (DEBUG_PERSISTENCE)
          console.log('Storage is already persisted', await estimatePersistentStorageOrThrow());
        _alreadyGranted = true;
        return true;
      }

      const isGranted = await navigator.storage.persist();
      if (DEBUG_PERSISTENCE || !isGranted) {
        // await navigator.storage.getDirectory()
        const estimate = await estimatePersistentStorageOrThrow();
        console.log('Persistent storage granted:', isGranted, 'usageMB:', estimate?.usageMB, 'quotaMB:', estimate?.quotaMB);
      }
      if (isGranted)
        _alreadyGranted = true;
      return isGranted;
    }
  } catch (error) {
    console.error('Error requesting persistent storage', error);
    return false;
  }

  console.warn('Persistent storage is not supported by this browser');
  return false;
}

export async function estimatePersistentStorageOrThrow(): Promise<{ usageMB: number, quotaMB: number } | null> {
  if (isBrowser && navigator.storage && navigator.storage.estimate) {
    const estimate = await navigator.storage.estimate();
    return {
      // convert to MBs (with 3 decimal places)
      usageMB: Math.round((estimate.usage || 0) / 1024 / 1024 * 1000) / 1000,
      quotaMB: Math.round((estimate.quota || 0) / 1024 / 1024),
    };
  }

  console.warn('Storage estimate is not supported by this browser');
  return null;
}



================================================
FILE: src/common/util/textUtils.ts
================================================
export function capitalizeFirstLetter(string: string) {
  return string?.length ? (string.charAt(0).toUpperCase() + string.slice(1)) : string;
}


export function countWords(text: string) {
  const trimmedText = text.trim();
  if (!trimmedText) return 0;
  return trimmedText.split(/\s+/).length;
}

export function countLines(text?: string) {
  if (!text) return 0;
  return text.split('\n').length;
}

/**
 * Convert a string (e.g., a web URL or file name) to a human-readable hyphenated format.
 * This function:
 * - Optionally removes URL schemas (http://, https://, ftp://, etc.)
 * - Handles query parameters by replacing '=' with '-' and '&' with '--'
 * - Replaces non-alphanumeric characters with hyphens
 * - Removes redundant hyphens
 * - Trims leading and trailing hyphens
 * - Converts the result to lowercase
 */
export function humanReadableHyphenated(text: string, removeSchema: boolean = false): string {
  // Trim the input and optionally remove URL schema
  let processed = text.trim();
  if (removeSchema)
    processed = processed.replace(/^(https?|file):\/\//, '');

  // Handle query parameters
  processed = processed.replace(/\?/g, '-')  // Replace '?' with '-'
    .replace(/=/g, '-')   // Replace '=' with '-'
    .replace(/&/g, '--'); // Replace '&' with '--'

  return processed
    .replace(/[^a-zA-Z0-9]+/g, '-') // Replace non-alphanumeric characters (including spaces) with hyphens
    .replace(/-{2,}/g, '-') // Remove redundant hyphens
    .replace(/^-+|-+$/g, '') // Remove leading and trailing hyphens
    .toLowerCase();
}

export function humanReadableBytes(bytes: number): string {
  if (bytes < 0) return 'N/A';
  if (bytes === 0) return '0 Bytes';
  const k = 1024;
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  return `${parseFloat((bytes / Math.pow(k, i)).toFixed(1))} ${sizes[i]}`;
}

export function ellipsizeFront(text: string, maxLength: number) {
  if (text.length <= maxLength)
    return text;
  return '…' + text.slice(-(maxLength - 1));
}

export function ellipsizeMiddle(text: string, maxLength: number, ellipsis: string = '…'): string {
  if (text.length <= maxLength)
    return text;
  if (maxLength <= ellipsis.length)
    return ellipsis.slice(0, maxLength);

  const sideLength = (maxLength - ellipsis.length) / 2;
  const frontLength = Math.ceil(sideLength);
  const backLength = Math.floor(sideLength);

  return text.slice(0, frontLength) + ellipsis + text.slice(-backLength);
}

export function ellipsizeEnd(text: string, maxLength: number, maxLines?: number) {
  let wasTruncated = false;

  // Handle maxLines if specified
  if (maxLines !== undefined && maxLines > 0) {
    const lines = text.split('\n');
    if (lines.length > maxLines) {
      text = lines.slice(0, maxLines).join('\n');
      wasTruncated = true;
    }
  }

  // Check if text exceeds maxLength and truncate if necessary
  if (text.length > maxLength) {
    text = text.slice(0, maxLength - 1) + '…';
    // wasTruncated = true; // not useful here
  } else if (wasTruncated) {
    // If text was truncated by lines but not by length, add ellipsis if possible
    if (text.length + 1 <= maxLength) {
      text += '…';
    } else if (maxLength > 0) {
      // Truncate one character to add ellipsis without exceeding maxLength
      text = text.slice(0, maxLength - 1) + '…';
    }
  }

  return text;
}


export function textEscapeHtml(text: string): string {
  return text
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&#039;');
}


export function textIsSingleEmoji(text: string): boolean {
  if (!Intl.Segmenter)
    throw new Error('Intl.Segmenter is not supported');

  // create segmenter instance with default locale
  const segmenter = new Intl.Segmenter(undefined, { granularity: 'grapheme' });
  const segments = Array.from(segmenter.segment(text));
  return segments.length === 1;
}


/**
 * Simple hash generation for a string - used in the Frontend! For backend see `sdbmHash` in `backend.router.ts`.
 */
export function frontendHashString(str: string): string {
  let hash = 0;
  for (let i = 0; i < str.length; i++) {
    const char = str.charCodeAt(i);
    hash = ((hash << 5) - hash) + char;
    hash = hash & hash; // Convert to 32bit integer
  }
  return 'h-' + hash.toString(16);
}



================================================
FILE: src/common/util/timeUtils.ts
================================================
export function prettyTimestampForFilenames(useSeconds: boolean = true) {
  const now = new Date();
  const year = now.getFullYear();
  const month = String(now.getMonth() + 1).padStart(2, '0'); // JavaScript months are 0-based.
  const day = String(now.getDate()).padStart(2, '0');
  const hour = String(now.getHours()).padStart(2, '0');
  const minute = String(now.getMinutes()).padStart(2, '0');
  const second = String(now.getSeconds()).padStart(2, '0');
  return `${year}-${month}-${day}-${hour}${minute}${useSeconds ? second : ''}`; // YYYY-MM-DD_HHMM[SS] format
}

export function getLocalMidnightInUTCTimestamp(): number {
  const midnight = new Date();
  // midnight.setDate(midnight.getDate() - 1);
  midnight.setHours(24, 0, 0, 0);
  return midnight.getTime();
}

export function getTimeBucketEn(itemTimeStamp: number, midnightTimestamp: number): string {
  const oneHour = 60 * 60 * 1000;
  const oneDay = oneHour * 24;
  const oneWeek = oneDay * 7;
  const oneMonth = oneDay * 30; // approximation

  // relative time
  const relDiff = Date.now() - itemTimeStamp;
  if (relDiff < oneHour)
    return 'Last Hour';

  // midnight-relative time
  const diff = midnightTimestamp - itemTimeStamp;
  if (diff < oneDay) {
    // if (diff > oneDay / 2)
    //   return 'This morning';
    // else if (diff > oneDay / 4)
    //   return 'This afternoon';
    // else
    //   return 'This evening';
    return 'Today';
  } else if (diff < oneDay * 2) {
    return 'Yesterday';
  } else if (diff < oneDay * 3) {
    return 'Two Days Ago';
  } else if (diff < oneWeek) {
    return 'This Week';
  } else if (diff < oneWeek * 2) {
    return 'Last Week';
  } else if (diff < oneMonth) {
    return 'This Month';
  } else if (diff < oneMonth * 2) {
    return 'Last Month';
  } else {
    return 'Older';
  }
}


================================================
FILE: src/common/util/trpc.client.ts
================================================
// noinspection JSUnresolvedReference

/**
 * This is the client-side entrypoint for your tRPC API. It is used to create the `api` object which
 * contains the Next.js App-wrapper, as well as your type-safe React Query hooks.
 *
 * We also create a few inference helpers for input and output types.
 */
import { createTRPCClient, httpBatchStreamLink, httpLink, loggerLink } from '@trpc/client';
import { createTRPCNext } from '@trpc/next';

import type { AppRouterEdge } from '~/server/trpc/trpc.router-edge';
import type { AppRouterCloud } from '~/server/trpc/trpc.router-cloud';
import { transformer } from '~/server/trpc/trpc.transformer';

import { getBaseUrl } from './urlUtils';
import { reactQueryClientSingleton } from '../app.queryclient';


// configuration
const VERCEL_WORKAROUND_EDGE_1MB_PAYLOAD_LIMIT = true;


const enableLoggerLink = (opts: any) => {
  return process.env.NODE_ENV === 'development' ||
    (opts.direction === 'down' && opts.result instanceof Error);
};


/// Edge APIs: async, query, and stream

/** Typesafe async/await hooks for the the Edge-Runtime API */
export const apiAsync = createTRPCClient<AppRouterEdge>({
  links: [
    loggerLink({ enabled: enableLoggerLink }),
    httpLink({
      url: `${getBaseUrl()}/api/edge`,
      transformer: transformer,
    }),
  ],
});

/** Typesafe React Query hooks for the tRPC Edge-Runtime API */
export const apiQuery = createTRPCNext<AppRouterEdge>({
  config() {
    return {
      /**
       * We set the queryClient to a singleton App-wide instance, to use the same client for
       * both React Query and tRPC. As `withTRPC` in _app.tsx, it will create a QueryClientProvider
       * component, so we can catch 2 birds with one stone and only create 1 provider, over 1
       * instance, and reuse the same configuration for both traditional React Query and tRPC.
       */
      queryClient: reactQueryClientSingleton(),
      links: [
        loggerLink({ enabled: enableLoggerLink }),
        httpLink({
          url: `${getBaseUrl()}/api/edge`,
          transformer: transformer,
          // You can pass any HTTP headers you wish here
          // async headers() {
          //   return {
          //     // authorization: getAuthCookie(),
          //   };
          // },
        }),
      ],
    };
  },
  /**
   * Whether tRPC should await queries when server rendering pages.
   * @see https://trpc.io/docs/client/nextjs/ssr
   */
  ssr: false,
  /**
   * Transformer used for data de-serialization from the server.
   * @see https://trpc.io/docs/server/data-transformers
   */
  transformer: transformer,
});

/** Stream API: uses tRPC streaming to transfer partial updates to the client */
export const apiStream = createTRPCClient<AppRouterEdge>({
  links: [
    loggerLink({ enabled: enableLoggerLink }),
    httpBatchStreamLink({
      url: `${getBaseUrl()}/api/edge`,
      transformer: transformer,
      /**
       * WORKAROUND:
       * Due to the fact that we are sending large payloads with images, and having a 1MB max payload size
       * limit on Vercel, we need to limit the number of items in the stream to 1, to err on the side of
       * safety.
       */
      ...(VERCEL_WORKAROUND_EDGE_1MB_PAYLOAD_LIMIT && { maxItems: 1 }),
    }),
  ],
});


/// Node.js runtime APIs

/** Node/Immediate API: Typesafe async/await hooks for the the Node functions API */
export const apiAsyncNode = createTRPCClient<AppRouterCloud>({
  links: [
    loggerLink({ enabled: enableLoggerLink }),
    httpLink({
      url: `${getBaseUrl()}/api/cloud`,
      transformer: transformer,
    }),
  ],
});

/** Node/Streaming API: typesafe async generator hooks */
export const apiStreamNode = createTRPCClient<AppRouterCloud>({
  links: [
    loggerLink({ enabled: enableLoggerLink }),
    httpBatchStreamLink({
      url: `${getBaseUrl()}/api/cloud`,
      transformer: transformer,
      maxItems: 1, // to not wait for the last connection to close
    }),
  ],
});


================================================
FILE: src/common/util/urlUtils.ts
================================================
// noinspection JSUnresolvedReference

import { Is, isBrowser } from './pwaUtils';

/**
 * Return the base URL for the current environment.
 *  - browser: '' (relative url)
 *  - SSR: vercel url
 *  - dev SSR: localhost
 */
export function getBaseUrl(): string {
  if (isBrowser) return ''; // browser should use relative url
  if (Is.Deployment.VercelFromBackendOrSSR) return `https://${process.env.VERCEL_URL}`; // SSR should use vercel url
  // NOTE: untested with https://localhost:3000
  return `http://localhost:${process.env.PORT ?? 3000}`; // dev SSR should use localhost
}

/**
 * Return the origin for the current environment.
 *  - http/https://...
 */
export function getOriginUrl(): string {
  if (isBrowser) return window.location.origin;
  if (Is.Deployment.VercelFromBackendOrSSR) return `https://${process.env.VERCEL_URL}`;
  // NOTE: untested with https://localhost:3000
  return `http://localhost:${process.env.PORT ?? 3000}`;
}


/**
 * Returns the domain of a website
 * */
export function urlExtractDomain(url: string): string {
  try {
    return new URL(url).hostname;
  } catch {
    return url;
  }
}

/**
 * Simplifies a URL to its origin and path (removes query and hash)
 */
export function urlPrettyHref(href: string, removeHttps: boolean, removeTrailingSlash: boolean): string {
  try {
    const url = new URL(href);
    let cleaner = decodeURIComponent(url.origin + url.pathname);
    if (removeHttps) cleaner = cleaner.replace(/^https?:\/\//, '');
    if (removeTrailingSlash) cleaner = cleaner.replace(/\/$/, '');
    return cleaner;
  } catch {
    return href;
  }
}


/**
 * If the string is a valid URL, return it. Otherwise, return null.
 */
export function asValidURL(textString: string | null, relaxProtocol: boolean = false /*, strictMode: boolean = false*/): string | null {

  // basic input validation
  if (!textString) return null;
  const trimmed = textString.trim();
  if (!trimmed) return null;

  try {
    // relax protocol to https if missing
    let urlString = trimmed;
    if (relaxProtocol && !/^https?:\/\//i.test(trimmed) && trimmed.includes('.'))
      urlString = 'https://' + trimmed;

    // throw if URL is invalid
    const url = new URL(urlString);

    // protocol must be http(s)
    if (!['http:', 'https:'].includes(url.protocol))
      return null;

    // strict mode: extra validations
    /*if (strictMode) {

      // no IP addresses in strict mode
      if (!/^([a-z0-9]([a-z0-9-]*[a-z0-9])?\.)+[a-z]{2,}$/i.test(url.hostname))
        return null;

      // no credentials in strict mode
      if (url.username || url.password)
        return null;
    }*/

    // Return the normalized URL
    return url.toString();

  } catch (e) {
    return null;
  }
}

/**
 * Extracts URLs from a text string.
 */
export function extractUrlsFromText(text: string): string[] {
  const urlRegex = /(https?:\/\/\S+)/g;
  return text.match(urlRegex) || [];
}



// added for future in-app routing
// export namespace SearchParams {
//
//   /** Checks if a search parameter exists */
//   export function hasParam(key: string): boolean {
//     return _parse().has(key);
//   }
//
//   /** Gets a search parameter by key */
//   export function getParam(key: string, defaultValue = ''): string {
//     const value = _parse().get(key);
//     return value !== null ? value : defaultValue;
//   }
//
//   /** Updates or adds a search parameter */
//   export function updateParam(key: string, value: string): void {
//     const searchParams = _parse();
//     searchParams.set(key, value);
//     _update(searchParams);
//   }
//
//   /** Removes a search parameter */
//   export function removeParam(key: string): void {
//     const searchParams = _parse();
//     searchParams.delete(key);
//     _update(searchParams);
//   }
//
//
//   function _parse(): URLSearchParams {
//     if (!isBrowser) return new URLSearchParams();
//
//     try {
//       return new URL(window.location.href).searchParams;
//     } catch (error) {
//       console.error('[DEV] SearchParams: error parsing URL:', error);
//       return new URLSearchParams();
//     }
//   }
//
//   /** Updates the URL with the provided search parameters */
//   function _update(searchParams: URLSearchParams): void {
//     if (!isBrowser) return;
//
//     try {
//       window.history.replaceState(
//         {},
//         '',
//         `${window.location.pathname}?${searchParams.toString()}`,
//       );
//     } catch (error) {
//       console.error('[DEV] SearchParams: error updating URL:', error);
//     }
//   }
// }



================================================
FILE: src/common/util/videoUtils.ts
================================================
/**
 * Copyright (c) 2024 Enrico Ros
 *
 * Functions to deal with HTML5Video elements.
 * Also see imageUtils.ts for more image-related functions.
 */

import { asyncCanvasToBlobWithValidation, renderVideoFrameToNewCanvas } from './canvasUtils';
import { downloadBlob } from './downloadUtils';
import { prettyTimestampForFilenames } from './timeUtils';


type AllowedFormats = 'image/png' | 'image/jpeg';


/**
 * Take the current frame of a video element and downloads it as a named PNG file.
 * Video -> Canvas -> Blob -> (download)
 */
export async function downloadVideoFrame(videoElement: HTMLVideoElement, prefixName: string, imageFormat: AllowedFormats, imageQuality?: number) {
  // Video -> Canvas -> Blob
  const renderedFrame: HTMLCanvasElement = renderVideoFrameToNewCanvas(videoElement);
  try {
    const { blob } = await asyncCanvasToBlobWithValidation(renderedFrame, imageFormat, imageQuality, 'downloadVideoFrame');
    // Blob -> download
    downloadBlob(blob, _videoPrettyFileName(prefixName, renderedFrame, imageFormat));
  } catch (error) {
    throw new Error(`Failed to download video frame: ${error instanceof Error ? error.message : String(error)}`);
  }
}

/**
 * Take the current frame of a video element and returns it as a File.
 */
export async function renderVideoFrameAsFile(videoElement: HTMLVideoElement, prefixName: string, imageFormat: AllowedFormats, imageQuality?: number): Promise<File> {
  // Video -> Canvas -> Blob
  const renderedFrame: HTMLCanvasElement = renderVideoFrameToNewCanvas(videoElement);
  try {
    const { blob, actualMimeType } = await asyncCanvasToBlobWithValidation(renderedFrame, imageFormat, imageQuality, 'renderVideoFrameAsFile');
    // Blob -> File
    return new File([blob], _videoPrettyFileName(prefixName, renderedFrame, actualMimeType), { type: actualMimeType });
  } catch (error) {
    throw new Error(`Failed to render video frame: ${error instanceof Error ? error.message : String(error)}`);
  }
}


function _videoPrettyFileName(prefixName: string, renderedFrame: HTMLCanvasElement, imageFormat: AllowedFormats | string /* allowing for the actual mime type to be different */): string {
  const prettyResolution = `${renderedFrame.width}x${renderedFrame.height}`;
  const extensions: { [mime: string]: string } = {
    'image/png': 'png',
    'image/jpeg': 'jpg',
    'image/webp': 'webp',
    'image/gif': 'gif',
  };
  const extension = extensions[imageFormat] || 'jpg'; // Fallback to jpg if format is not recognized
  return `${prefixName}_${prettyTimestampForFilenames()}_${prettyResolution}.${extension}`;
}



================================================
FILE: src/common/util/viewTransitionUtils.ts
================================================
// import { flushSync } from 'react-dom';
//
//
// // Provide the missing definition for this novel API
//
// // Extend the global Document interface
// declare global {
//   interface Document {
//     startViewTransition(updateCallback: UpdateCallback): ViewTransition;
//   }
// }
//
// type UpdateCallback = () => Promise<any>;
//
// interface ViewTransition {
//   readonly updateCallbackDone: Promise<undefined>;
//   readonly ready: Promise<undefined>;
//   readonly finished: Promise<undefined>;
//
//   skipTransition(): undefined;
// }
//
//
// // Perform a view transition, if supported by the browser
// export async function performViewTransition<T>(callback: () => T) {
//
//   // If the browser does not support view transitions, just call the callback
//   if (!('startViewTransition' in document))
//     return callback();
//
//   // Transition to the new view
//   const viewTransition = document.startViewTransition(async () => {
//     if (typeof flushSync !== 'function')
//       return callback();
//     return flushSync(() => callback());
//   });
//
//   // Wait for the transition to be ready
//   // await viewTransition.ready;
// }



================================================
FILE: src/common/util/webGeolocationUtils.ts
================================================
import { Release } from '../app.release';

import { frontendSideFetch } from './clientFetchers';
import { isBrowser } from './pwaUtils';


export const isWebGeolocationSupported = isBrowser && !!navigator.geolocation;


export interface WebGeolocation {

  // approximate geolocation
  city?: string;
  region?: string;
  country?: string;
  timezone: string;

  // other geolocation data, for future use
  coords?: {
    latitude: number;
    longitude: number;
    accuracy?: number;
  };

  // when it was measured
  timestamp: number;
}


// in-mem cache
let _cache: WebGeolocation | undefined = undefined;


/**
 * Gets cached geolocation data without requesting permissions
 */
export function webGeolocationCached(): WebGeolocation | undefined {
  return _cache;
}


/**
 * Get current geolocation permission state
 */
export async function webGeolocationPermissionState(): Promise<
  | 'granted' | 'denied' | 'prompt' // from the API
  | 'unsupported' // if there's no API
> {
  if (!isWebGeolocationSupported) return 'unsupported';

  if (navigator.permissions) {
    try {
      const permissionStatus = await navigator.permissions.query({ name: 'geolocation' as PermissionName });
      return permissionStatus.state;
    } catch (e) {
      console.warn('Failed to query geolocation permission:', e);
    }
  }

  // if we have cached data, we had permission at some point
  return _cache ? 'granted' : 'prompt';
}


/**
 * Request geolocation permission and retrieve location data
 */
export async function webGeolocationRequest(): Promise<WebGeolocation | null> {

  // return cached data if available and recent (last 60 minutes)
  if (_cache && (Date.now() - _cache.timestamp < 60 * 60 * 1000))
    return _cache;

  if (!isWebGeolocationSupported) {
    console.warn('Geolocation is not supported in this environment');
    return null;
  }

  try {

    // request position with a reasonable timeout
    const position = await _getCurrentPositionAsync({
      // don't need high accuracy for this
      enableHighAccuracy: false,
      timeout: 5000,
      maximumAge: 10 * 60 * 1000, // Accept a position up to 10 minutes old
    });

    // create basic geolocation data
    const data: WebGeolocation = {
      timezone: Intl.DateTimeFormat().resolvedOptions().timeZone,
      coords: {
        latitude: position.coords.latitude,
        longitude: position.coords.longitude,
        accuracy: position.coords.accuracy,
      },
      timestamp: Date.now(),
    };

    // try to enhance with reverse geocoding (for city, region, country)
    try {
      return _cache = await _enhanceWithLocationData(data);
    } catch (error) {
      // if reverse geocoding fails, still return and cache basic data
      _cache = data;
      return data;
    }
  } catch (error) {
    console.log('[DEV] Geolocation request failed:', error);
    return null;
  }
}


// Private helper functions

function _getCurrentPositionAsync(options: PositionOptions): Promise<GeolocationPosition> {
  return new Promise((resolve, reject) => {
    navigator.geolocation.getCurrentPosition(resolve, reject, options);
  });
}

async function _enhanceWithLocationData(data: WebGeolocation): Promise<WebGeolocation> {
  if (!data.coords) return data;

  try {
    const { latitude, longitude } = data.coords;

    // For now, use Nominatim (OpenStreetMap) for reverse geocoding
    // TODO: use a robust geocoding service
    const response = await frontendSideFetch(`https://nominatim.openstreetmap.org/reverse?format=json&lat=${latitude}&lon=${longitude}&zoom=10&accept-language=${navigator.language || 'en'}`, {
      headers: {
        // required by Nominatim
        'User-Agent': `Big-AGI/${Release.App.versionCode}`,
      },
    });

    if (!response.ok) {
      console.warn('Reverse geocoding failed:', response.statusText);
      return data; // Return the original data without enhancement
    }

    const result = await response.json();
    if (result.address) {
      // Format data according to OpenAI expectations
      return {
        ...data,
        city: result.address.city || result.address.town || result.address.village || undefined,
        region: result.address.state || result.address.county || undefined,
        country: result.address.country_code?.toUpperCase(),
      };
    }

    return data;
  } catch (error) {
    console.warn('Reverse geocoding failed:', error);
    return data; // Return the original data without enhancement
  }
}



================================================
FILE: src/common/util/windowUtils.tsx
================================================
import { isBrowser } from './pwaUtils';

export class WindowFocusObserver {
  private static instance: WindowFocusObserver | null = null;
  private listeners: Set<(isWindowFocused: boolean) => void> = new Set();
  private isWindowFocused: boolean = true;
  private refCount: number = 0;

  // singleton

  public static getInstance(): WindowFocusObserver {
    if (!WindowFocusObserver.instance)
      WindowFocusObserver.instance = new WindowFocusObserver();
    return WindowFocusObserver.instance;
  }

  private constructor() {
    if (!isBrowser) return;
    this.isWindowFocused = document.hasFocus();
    window.addEventListener('focus', this._handleWindowFocus);
    window.addEventListener('blur', this._handleWindowBlur);
  }

  // clients

  get windowFocusState(): boolean {
    return this.isWindowFocused;
  }

  public subscribe(listener: (isWindowFocused: boolean) => void): () => void {
    this.listeners.add(listener);
    this.refCount++;
    return () => {
      this.listeners.delete(listener);
      this.refCount--;
      if (this.refCount === 0) {
        this._cleanup();
      }
    };
  }

  // private methods

  private _cleanup(): void {
    if (!isBrowser) return;
    window.removeEventListener('focus', this._handleWindowFocus);
    window.removeEventListener('blur', this._handleWindowBlur);
    this.listeners.clear();
    WindowFocusObserver.instance = null;
  }

  private _handleWindowFocus = (): void => {
    this._updateWindowFocusState(true);
  };

  private _handleWindowBlur = (): void => {
    this._updateWindowFocusState(false);
  };

  private _updateWindowFocusState(newState: boolean): void {
    if (this.isWindowFocused !== newState) {
      this.isWindowFocused = newState;
      this.listeners.forEach(listener => listener(this.isWindowFocused));
    }
  }
}

/* // Uncomment to have a great debugging tool for focus issues, tracking every movement within the document. Use LLMs to explain.

export function useDocumentFocusDebugger() {
  const previousFocusRef = React.useRef<Element | null>(null);

  React.useEffect(() => {
    // Check if we're in a browser environment
    if (typeof window === 'undefined') return;

    const handleFocusChange = (event: FocusEvent) => {
      const currentFocus = event.target as Element;

      if (currentFocus !== previousFocusRef.current) {
        const prevInfo = _getElementInfo(previousFocusRef.current);
        const currentInfo = _getElementInfo(currentFocus);

        console.group('Focus Change');
        console.log(`Time: ${new Date().toISOString()}`);
        console.log(`Event: ${event.type}`);
        console.log('Previous focus:', prevInfo);
        console.log('Current focus:', currentInfo);
        console.log('Stack trace:', new Error().stack);
        console.groupEnd();

        previousFocusRef.current = currentFocus;
      }
    };

    document.addEventListener('focus', handleFocusChange, true);
    document.addEventListener('blur', handleFocusChange, true);

    return () => {
      document.removeEventListener('focus', handleFocusChange, true);
      document.removeEventListener('blur', handleFocusChange, true);
    };
  }, []);
}

function _getElementInfo(element: Element | null) {
  if (!element) return 'None';

  return {
    tagName: element.tagName,
    id: element.id,
    className: element.className,
    textContent: element.textContent?.slice(0, 50) ?? '',
    componentName: _getReactComponentName(element),
  };
}

function _getReactComponentName(element: Element): string {
  const reactKey = Object.keys(element).find(key => key.startsWith('__reactFiber$'));
  if (reactKey) {
    const fiber = (element as any)[reactKey];
    if (fiber && fiber.return && fiber.return.type) {
      return fiber.return.type.name || 'Unknown';
    }
  }
  return 'Unknown';
}
*/



================================================
FILE: src/common/util/audio/AudioGenerator.ts
================================================
// noinspection JSUnusedGlobalSymbols

import { isBrowser } from '~/common/util/pwaUtils';

export namespace AudioGenerator {

  interface SoundOptions {
    volume?: number;
    roomSize?: 'small' | 'large';
  }

  // Advanced Sounds (with room acoustics)
  export function mouseClick(): void {
    const ctx = singleContext();
    if (!ctx) return;

    const clickOsc = ctx.createOscillator();
    const resonanceOsc = ctx.createOscillator();
    const clickGain = ctx.createGain();
    const resonanceGain = ctx.createGain();

    clickOsc.type = 'sine';
    clickOsc.frequency.setValueAtTime(2000, ctx.currentTime);
    clickOsc.frequency.exponentialRampToValueAtTime(20, ctx.currentTime + 0.02);

    resonanceOsc.type = 'sine';
    resonanceOsc.frequency.setValueAtTime(800, ctx.currentTime);

    // Use fixed gain values to match original
    clickGain.gain.setValueAtTime(1, ctx.currentTime);
    createEnvelope(ctx, clickGain.gain, 0.001, 0.02, 0, 0.01);

    resonanceGain.gain.setValueAtTime(0.2, ctx.currentTime);
    createEnvelope(ctx, resonanceGain.gain, 0.002, 0.05, 0, 0.03);

    const merger = ctx.createChannelMerger(2);
    clickOsc.connect(clickGain).connect(merger, 0, 0);
    resonanceOsc.connect(resonanceGain).connect(merger, 0, 0);

    applyRoomAcoustics(ctx, merger, 'small');

    clickOsc.start();
    resonanceOsc.start();
    clickOsc.stop(ctx.currentTime + 0.1);
    resonanceOsc.stop(ctx.currentTime + 0.1);
  }

  export function typewriterKeystroke(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;

    const strikeNoise = createNoise(ctx, 0.02);
    const inkNoise = createNoise(ctx, 0.05);
    const mechanismOsc = ctx.createOscillator();

    const strikeFilter = ctx.createBiquadFilter();
    const inkFilter = ctx.createBiquadFilter();
    const strikeGain = ctx.createGain();
    const inkGain = ctx.createGain();
    const mechanismGain = ctx.createGain();

    strikeFilter.type = 'highpass';
    strikeFilter.frequency.setValueAtTime(3000, ctx.currentTime);
    strikeFilter.Q.setValueAtTime(10, ctx.currentTime);

    inkFilter.type = 'lowpass';
    inkFilter.frequency.setValueAtTime(500, ctx.currentTime);

    mechanismOsc.type = 'triangle';
    mechanismOsc.frequency.setValueAtTime(400, ctx.currentTime);
    mechanismOsc.frequency.linearRampToValueAtTime(200, ctx.currentTime + 0.05);

    createEnvelope(ctx, strikeGain.gain, 0.001, 0.01, 0, 0.01);
    createEnvelope(ctx, inkGain.gain, 0.01, 0.03, 0.1, 0.02);
    createEnvelope(ctx, mechanismGain.gain, 0.001, 0.03, 0, 0.02);

    strikeGain.gain.setValueAtTime(options.volume || 0.3, ctx.currentTime);
    inkGain.gain.setValueAtTime((options.volume || 0.3) * 0.5, ctx.currentTime);
    mechanismGain.gain.setValueAtTime((options.volume || 0.3) * 0.2, ctx.currentTime);

    const merger = ctx.createChannelMerger(2);
    strikeNoise.connect(strikeFilter).connect(strikeGain).connect(merger, 0, 0);
    inkNoise.connect(inkFilter).connect(inkGain).connect(merger, 0, 0);
    mechanismOsc.connect(mechanismGain).connect(merger, 0, 0);

    applyRoomAcoustics(ctx, merger, options.roomSize || 'small');

    strikeNoise.start();
    inkNoise.start(ctx.currentTime + 0.01);
    mechanismOsc.start();
    mechanismOsc.stop(ctx.currentTime + 0.1);
  }

  export function smallFirework(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;

    const launchNoise = createNoise(ctx, 0.5);
    const explosionNoise = createNoise(ctx, 0.2);
    const boomOsc = ctx.createOscillator();

    const launchFilter = ctx.createBiquadFilter();
    const explosionFilter = ctx.createBiquadFilter();
    const launchGain = ctx.createGain();
    const explosionGain = ctx.createGain();
    const boomGain = ctx.createGain();

    launchFilter.type = 'bandpass';
    launchFilter.frequency.setValueAtTime(1000, ctx.currentTime);
    launchFilter.frequency.exponentialRampToValueAtTime(3000, ctx.currentTime + 0.5);

    explosionFilter.type = 'lowpass';
    explosionFilter.frequency.setValueAtTime(10000, ctx.currentTime + 0.5);
    explosionFilter.frequency.exponentialRampToValueAtTime(500, ctx.currentTime + 0.7);

    boomOsc.type = 'sine';
    boomOsc.frequency.setValueAtTime(100, ctx.currentTime + 0.5);
    boomOsc.frequency.exponentialRampToValueAtTime(20, ctx.currentTime + 0.7);

    createEnvelope(ctx, launchGain.gain, 0.01, 0.1, 0.5, 0.39);
    explosionGain.gain.setValueAtTime(0, ctx.currentTime);
    explosionGain.gain.setValueAtTime(options.volume || 0.3, ctx.currentTime + 0.5);
    createEnvelope(ctx, explosionGain.gain, 0.001, 0.1, 0.3, 0.1);
    boomGain.gain.setValueAtTime(0, ctx.currentTime);
    boomGain.gain.setValueAtTime((options.volume || 0.3) * 0.5, ctx.currentTime + 0.5);
    createEnvelope(ctx, boomGain.gain, 0.001, 0.1, 0.3, 0.2);

    const merger = ctx.createChannelMerger(2);
    launchNoise.connect(launchFilter).connect(launchGain).connect(merger, 0, 0);
    explosionNoise.connect(explosionFilter).connect(explosionGain).connect(merger, 0, 0);
    boomOsc.connect(boomGain).connect(merger, 0, 0);

    // Add crackle sounds
    for (let i = 0; i < 20; i++) {
      const crackleNoise = createNoise(ctx, 0.05);
      const crackleFilter = ctx.createBiquadFilter();
      const crackleGain = ctx.createGain();

      crackleFilter.type = 'bandpass';
      crackleFilter.frequency.setValueAtTime(2000 + Math.random() * 3000, ctx.currentTime);

      const startTime = ctx.currentTime + 0.55 + Math.random() * 0.4;
      crackleGain.gain.setValueAtTime(0, startTime);
      createEnvelope(ctx, crackleGain.gain, 0.001, 0.02, 0, 0.03);

      crackleNoise.connect(crackleFilter).connect(crackleGain).connect(merger, 0, 0);
      crackleNoise.start(startTime);
    }

    applyRoomAcoustics(ctx, merger, options.roomSize || 'large');

    launchNoise.start();
    explosionNoise.start(ctx.currentTime + 0.5);
    boomOsc.start(ctx.currentTime + 0.5);
    boomOsc.stop(ctx.currentTime + 1);
  }


  // Basic Sounds

  // export function basicSound(options: SoundOptions = {}): void {
  //   const ctx = singleContext();
  //   if (!ctx) return;
  //   const o = ctx.createOscillator();
  //   const g = ctx.createGain();
  //
  //   o.type = 'sine';
  //   o.frequency.setValueAtTime(440, ctx.currentTime);
  //
  //   g.gain.setValueAtTime(options.volume || 0.3, ctx.currentTime);
  //   g.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + 0.5);
  //
  //   o.connect(g).connect(ctx.destination);
  //   o.start();
  //   o.stop(ctx.currentTime + 0.5);
  // }

  export function basicNote(note: string = 'C4', duration: number = 1, options: SoundOptions = {}) {
    const ctx = singleContext();
    if (!ctx) return;

    const now = ctx.currentTime;
    const o = ctx.createOscillator();
    const g = ctx.createGain();

    o.type = 'sine';
    o.frequency.setValueAtTime(noteToFrequency(note), now);

    g.gain.setValueAtTime(0, now);
    g.gain.linearRampToValueAtTime(options.volume || 0.3, now + 0.1);
    g.gain.exponentialRampToValueAtTime(0.001, now + duration);

    o.connect(g);
    g.connect(agMasterGain);
    // applyRoomAcoustics(ctx, g, options.roomSize || 'small');

    o.start(now);
    o.stop(now + duration);
  }

  export function basicRandomSound(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;
    const types: OscillatorType[] = ['sine', 'square', 'sawtooth', 'triangle'];
    const o = ctx.createOscillator();
    const g = ctx.createGain();

    o.type = types[Math.floor(Math.random() * types.length)];
    o.frequency.setValueAtTime(200 + Math.random() * 500, ctx.currentTime);

    const duration = 0.1 + Math.random() * 0.5;
    g.gain.setValueAtTime(options.volume || 0.3, ctx.currentTime);
    g.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + duration);

    o.connect(g).connect(ctx.destination);
    o.start();
    o.stop(ctx.currentTime + duration);
  }

  export function basicBubblingLava(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;
    const noise = createNoise(ctx, 1);
    const filter = ctx.createBiquadFilter();
    const g = ctx.createGain();

    filter.type = 'lowpass';
    filter.frequency.setValueAtTime(100, ctx.currentTime);
    filter.frequency.linearRampToValueAtTime(1000, ctx.currentTime + 0.5);

    g.gain.setValueAtTime(options.volume || 0.15, ctx.currentTime);
    g.gain.linearRampToValueAtTime(0, ctx.currentTime + 1);

    noise.connect(filter).connect(g).connect(ctx.destination);
    noise.start();
    noise.stop(ctx.currentTime + 1);
  }

  export function basicRetroGlitch(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;
    const o = ctx.createOscillator();
    const g = ctx.createGain();

    o.type = 'sawtooth';
    o.frequency.setValueAtTime(110, ctx.currentTime);

    g.gain.setValueAtTime(options.volume || 0.15, ctx.currentTime);
    g.gain.linearRampToValueAtTime(0, ctx.currentTime + 0.5);

    for (let i = 0; i < 10; i++) {
      o.frequency.exponentialRampToValueAtTime(
        110 * Math.pow(2, Math.random() * 3),
        ctx.currentTime + i * 0.05,
      );
    }

    o.connect(g).connect(ctx.destination);
    o.start();
    o.stop(ctx.currentTime + 0.5);
  }

  export function basicZenChimes(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;
    const frequencies = [523.25, 587.33, 659.25, 698.46, 783.99];
    frequencies.forEach((freq, i) => {
      setTimeout(() => {
        const o = ctx.createOscillator();
        const g = ctx.createGain();

        o.type = 'sine';
        o.frequency.setValueAtTime(freq, ctx.currentTime);

        g.gain.setValueAtTime(options.volume || 0.15, ctx.currentTime);
        g.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + 1);

        o.connect(g).connect(ctx.destination);
        o.start();
        o.stop(ctx.currentTime + 1);
      }, i * 200);
    });
  }

  export function basicAstralChimes(options: SoundOptions = {}, start: number = 0, count: number = 20, stepMs: number = 150): void {
    const ctx = singleContext();
    if (!ctx) return;
    const frequencies = [261.63, 293.66, 329.63, 349.23, 392.00, 440.00, 493.88];
    for (let i = 0; i < count; i++) {
      setTimeout(() => {
        const o = ctx.createOscillator();
        const g = ctx.createGain();

        o.type = 'sine';
        o.frequency.setValueAtTime(frequencies[Math.floor((start + i) % frequencies.length)], ctx.currentTime);

        g.gain.setValueAtTime(0, ctx.currentTime);
        g.gain.linearRampToValueAtTime(options.volume || 0.05, ctx.currentTime + 0.01);
        g.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + 2);

        o.connect(g).connect(ctx.destination);
        // applyRoomAcoustics(ctx, g, 'small');
        o.start();
        o.stop(ctx.currentTime + 2);
      }, i * stepMs);
    }
  }

  export function basicWhisperGarden(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;
    const noise = createNoise(ctx, 3);
    const filter = ctx.createBiquadFilter();
    const g = ctx.createGain();

    filter.type = 'lowpass';
    filter.frequency.setValueAtTime(1000, ctx.currentTime);

    g.gain.setValueAtTime(0, ctx.currentTime);
    g.gain.linearRampToValueAtTime(options.volume || 0.1, ctx.currentTime + 0.5);
    g.gain.linearRampToValueAtTime(0, ctx.currentTime + 3);

    noise.connect(filter).connect(g).connect(ctx.destination);
    noise.start();
    noise.stop(ctx.currentTime + 3);
  }

  export function basicWarmHearthEmbrace(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;
    const noise = createNoise(ctx, 4);
    const filter = ctx.createBiquadFilter();
    const g = ctx.createGain();

    filter.type = 'bandpass';
    filter.frequency.setValueAtTime(300, ctx.currentTime);
    filter.Q.setValueAtTime(10, ctx.currentTime);

    g.gain.setValueAtTime(0, ctx.currentTime);
    g.gain.linearRampToValueAtTime(options.volume || 0.2, ctx.currentTime + 0.5);
    g.gain.linearRampToValueAtTime(options.volume ? options.volume / 2 : 0.1, ctx.currentTime + 3.5);
    g.gain.linearRampToValueAtTime(0, ctx.currentTime + 4);

    noise.connect(filter).connect(g).connect(ctx.destination);
    noise.start();
    noise.stop(ctx.currentTime + 4);
  }


  // Big-AGI Sounds

  export function chatAutoSend(options: SoundOptions = {}) {
    const ctx = singleContext();
    if (!ctx) return;
    const o = ctx.createOscillator();
    const g = ctx.createGain();

    o.type = 'sine';
    o.frequency.setValueAtTime(440, ctx.currentTime);
    o.frequency.exponentialRampToValueAtTime(40, ctx.currentTime + 0.4);

    // o.frequency.exponentialRampToValueAtTime(100, ctx.currentTime + 0.5);
    // o.frequency.exponentialRampToValueAtTime(20, ctx.currentTime + 0.5);
    // o.frequency.exponentialRampToValueAtTime(2000, ctx.currentTime + 1.0);

    g.gain.setValueAtTime(options.volume || 0.3, ctx.currentTime);
    g.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + 0.4);

    o.connect(g).connect(agMasterGain);
    // applyRoomAcoustics(ctx, o.connect(g), options.roomSize || 'small');

    o.start();
    o.stop(ctx.currentTime + 0.4);
  }

  /** Play a gentle notification sound when the assistant's response is ready */
  export function chatNotifyResponse(options: SoundOptions = {}): void {
    const ctx = singleContext();
    if (!ctx) return;

    const now = ctx.currentTime;
    const volume = options.volume ?? 0.2;
    const noteDuration = 0.12;

    // const frequencies = [523.25, 783.99]; // C5, G5
    const frequencies = [392.00, 466.16]; // G4, A#4 // Low and nice
    // const frequencies = [880.00, 1108.73]; // A5, C#6 // High and more alert
    // const frequencies = [783.99, 659.25, 523.25]; // G5, E5, C5

    frequencies.forEach((freq, index) => {
      const oscillator = ctx.createOscillator();
      const gainNode = ctx.createGain();

      oscillator.type = 'sine';
      oscillator.frequency.setValueAtTime(freq, now + index * noteDuration);

      gainNode.gain.setValueAtTime(0, now + index * noteDuration);
      gainNode.gain.linearRampToValueAtTime(volume, now + index * noteDuration + 0.05);
      gainNode.gain.exponentialRampToValueAtTime(0.001, now + (index + 1) * noteDuration);

      oscillator.connect(gainNode); // .connect(agMasterGain);
      applyRoomAcoustics(ctx, gainNode, options.roomSize || 'small');
      oscillator.start(now + index * noteDuration);
      oscillator.stop(now + (index + 2) * noteDuration);
    });
  }

}


// export namespace TR909 {
//   interface TR909Options {
//     volume?: number;
//     pitch?: number;
//     decay?: number;
//     tone?: number;
//     noiseType?: 'white' | 'pink';
//   }
//
//   export function kick(options: TR909Options = {}): void {
//     const ctx = singleContext();
//     if (!ctx) return;
//
//     const now = ctx.currentTime;
//     const { pitch = 80, decay = 0.35, tone = 0.40, noiseType = 'white' } = options;
//
//     // oscillator
//     const o = ctx.createOscillator();
//     o.type = 'sine';
//     o.frequency.setValueAtTime(pitch, now);
//     o.frequency.exponentialRampToValueAtTime(pitch * 0.5, now + 0.15);
//
//     const og = ctx.createGain();
//     createEnvelope(ctx, og.gain, 0.001, decay, 0.1, 0.1);
//     o.connect(og);
//
//     // noise
//     const n = createNoise(ctx, decay + 0.1, noiseType);
//
//     const ng = ctx.createGain();
//     createEnvelope(ctx, ng.gain, 0.001, 0.05, 0.1, 0.05);
//     n.connect(ng);
//
//     // filter
//     const oToneFilter = ctx.createBiquadFilter();
//     oToneFilter.type = 'lowpass';
//     oToneFilter.frequency.setValueAtTime(1000 * tone, now);
//     og.connect(oToneFilter);
//     ng.connect(oToneFilter);
//
//     const compressor = ctx.createDynamicsCompressor();
//     oToneFilter.connect(compressor);
//     compressor.connect(agMasterGain);
//
//     o.start(now);
//     n.start(now);
//     o.stop(now + decay + 0.2);
//     n.stop(now + decay + 0.1);
//   }
//
//   export function snare(options: TR909Options = {}): void {
//     const ctx = singleContext();
//     if (!ctx) return;
//
//     const now = ctx.currentTime;
//     const { pitch = 150, decay = 0.2, tone = 1, noiseType = 'white' } = options;
//
//     // Oscillator
//     const o = ctx.createOscillator();
//     o.type = 'triangle';
//     o.frequency.setValueAtTime(pitch, now);
//
//     const oscGain = ctx.createGain();
//     createEnvelope(ctx, oscGain.gain, 0.001, 0.06, 0, 0.1);
//     o.connect(oscGain);
//
//     const oToneFilter = ctx.createBiquadFilter();
//     oToneFilter.type = 'bandpass';
//     oToneFilter.frequency.setValueAtTime(400 * tone, now);
//     oToneFilter.Q.setValueAtTime(1, now);
//     oscGain.connect(oToneFilter);
//
//     // Noise
//     const n = createNoise(ctx, decay + 0.1, noiseType);
//
//     const ng = ctx.createGain();
//     createEnvelope(ctx, ng.gain, 0.001, decay, 0, 0.01, 0.2);
//     n.connect(ng);
//
//     const nHighpassFilter = ctx.createBiquadFilter();
//     nHighpassFilter.type = 'highpass';
//     nHighpassFilter.frequency.setValueAtTime(2000, now);
//     ng.connect(nHighpassFilter);
//
//
//     // Compressor
//     const compressor = ctx.createDynamicsCompressor();
//     oToneFilter.connect(compressor);
//     nHighpassFilter.connect(compressor);
//     compressor.connect(agMasterGain);
//
//     n.start(now);
//     o.start(now);
//     n.stop(now + decay + 0.2);
//     o.stop(now + decay + 0.2);
//   }
//
//   export function hihat(options: TR909Options = {}): void {
//     const ctx = singleContext();
//     if (!ctx) return;
//
//     const now = ctx.currentTime;
//     const { decay = 0.08, tone = 1.5, noiseType = 'white' } = options;
//
//     // noise
//     const noise = createNoise(ctx, decay + 0.05, noiseType);
//     const noiseGain = ctx.createGain();
//     createEnvelope(ctx, noiseGain.gain, 0.001, decay, 0.1, 0.05);
//     noise.connect(noiseGain);
//
//     // noise filter
//     const nHighpassFilter = ctx.createBiquadFilter();
//     nHighpassFilter.type = 'highpass';
//     nHighpassFilter.frequency.setValueAtTime(7000 * tone, now);
//     noiseGain.connect(nHighpassFilter);
//
//     // compressor
//     const compressor = ctx.createDynamicsCompressor();
//     nHighpassFilter.connect(compressor);
//     compressor.connect(agMasterGain);
//
//     noise.start(now);
//     noise.stop(now + decay + 0.05);
//   }
//
//   export function clap(options: TR909Options = {}): void {
//     const ctx = singleContext();
//     if (!ctx) return;
//
//     const now = ctx.currentTime;
//     const { decay = 0.2, tone = 1, noiseType = 'white' } = options;
//
//     // noise 1
//     const n1 = createNoise(ctx, 0.05, noiseType);
//     const n1gain = ctx.createGain();
//     createEnvelope(ctx, n1gain.gain, 0.001, 0.03, 0, 0.02);
//     n1.connect(n1gain);
//
//     // noise 2
//     const n2 = createNoise(ctx, decay, noiseType);
//     const n2gain = ctx.createGain();
//     createEnvelope(ctx, n2gain.gain, 0.02, decay - 0.02, 0.1, 0.05);
//     n2.connect(n2gain);
//
//     // n1 + n2 filter
//     const bandpassFilter = ctx.createBiquadFilter();
//     bandpassFilter.type = 'bandpass';
//     bandpassFilter.frequency.setValueAtTime(1000 * tone, now);
//     bandpassFilter.Q.setValueAtTime(1.6, now);
//     n1gain.connect(bandpassFilter);
//     n2gain.connect(bandpassFilter);
//
//     // compressor
//     const compressor = ctx.createDynamicsCompressor();
//     bandpassFilter.connect(compressor);
//     compressor.connect(agMasterGain);
//
//     n1.start(now);
//     n2.start(now + 0.02);
//     n1.stop(now + 0.05);
//     n2.stop(now + decay);
//   }
// }


/// Utility Functions ///

function applyRoomAcoustics(ctx: AudioContext, source: AudioNode, roomSize: 'small' | 'large' = 'small'): void {
  const convolver = ctx.createConvolver();
  const reverbTime = roomSize === 'large' ? 2 : 0.5;
  const decayRate = roomSize === 'large' ? 0.5 : 2;

  const rate = ctx.sampleRate;
  const length = rate * reverbTime;
  const impulse = ctx.createBuffer(2, length, rate);
  for (let channel = 0; channel < 2; channel++) {
    const impulseData = impulse.getChannelData(channel);
    for (let i = 0; i < length; i++) {
      impulseData[i] = (Math.random() * 2 - 1) * Math.pow(1 - i / length, decayRate);
    }
  }
  convolver.buffer = impulse;

  const reverbGain = ctx.createGain();
  reverbGain.gain.setValueAtTime(0.2, ctx.currentTime);

  source.connect(convolver);
  convolver.connect(reverbGain);
  reverbGain.connect(agMasterGain);
  source.connect(agMasterGain);
}

function createEnvelope(ctx: AudioContext, param: AudioParam, attackTime: number, decayTime: number, sustainLevel: number, releaseTime: number, amplitude?: number): void {
  const now = ctx.currentTime;
  param.setValueAtTime(0, now);
  param.linearRampToValueAtTime(amplitude !== undefined ? amplitude : 1, now + attackTime);
  param.linearRampToValueAtTime(sustainLevel, now + attackTime + decayTime);
  param.linearRampToValueAtTime(0, now + attackTime + decayTime + releaseTime);
}

function createNoise(ctx: AudioContext, duration: number, type: 'white' | 'pink' = 'white') {
  const bufferSize = ctx.sampleRate * duration;
  const buffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate);
  const data = buffer.getChannelData(0);

  switch (type) {
    case 'white':
      for (let i = 0; i < bufferSize; i++) {
        data[i] = Math.random() * 2 - 1;
      }
      break;

    case 'pink':
      let b0 = 0, b1 = 0, b2 = 0, b3 = 0, b4 = 0, b5 = 0, b6 = 0;
      for (let i = 0; i < bufferSize; i++) {
        const white = Math.random() * 2 - 1;
        b0 = 0.99886 * b0 + white * 0.0555179;
        b1 = 0.99332 * b1 + white * 0.0750759;
        b2 = 0.96900 * b2 + white * 0.1538520;
        b3 = 0.86650 * b3 + white * 0.3104856;
        b4 = 0.55000 * b4 + white * 0.5329522;
        b5 = -0.7616 * b5 - white * 0.0168980;
        data[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;
        data[i] *= 0.11;
        b6 = white * 0.115926;
      }
      break;
  }

  const noiseSource = ctx.createBufferSource();
  noiseSource.buffer = buffer;
  return noiseSource;
}

function noteToFrequency(note: string /* = 'C4' */): number {
  const notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
  const octave = parseInt(note.slice(-1));
  const keyNumber = notes.indexOf(note.slice(0, -1));

  if (keyNumber === -1) throw new Error('Invalid note');

  // A4 is 440 Hz
  const a4 = 440;

  // Calculate half steps from A4
  const halfStepsFromA4 = (octave - 4) * 12 + keyNumber - 9;

  // Formula: f = 440 * (2^(1/12))^n
  // Where n is the number of half steps from A4
  return a4 * Math.pow(2, halfStepsFromA4 / 12);
}


// (Single) Global Audio Generation Context
let agCtx: AudioContext;
let agMasterGain: GainNode;

function singleContext() {
  if (!isBrowser) return null;
  if (!agCtx) {
    agCtx = new (window.AudioContext || (window as any).webkitAudioContext)();
    agMasterGain = agCtx.createGain();
    agMasterGain.connect(agCtx.destination);
  }
  if (agCtx.state === 'suspended') {
    // fire/forget
    void agCtx.resume();
  }
  return agCtx;
}



================================================
FILE: src/common/util/audio/AudioLivePlayer.ts
================================================
export class AudioLivePlayer {
  private readonly mimeType: string = 'audio/mpeg';

  private readonly audioContext: AudioContext;
  private readonly audioElement: HTMLAudioElement;
  private readonly mediaSource: MediaSource;
  private sourceBuffer: SourceBuffer | null = null;

  private chunkQueue: ArrayBuffer[] = [];
  private isSourceBufferUpdating: boolean = false;
  private isMediaSourceEnded: boolean = false;
  private isMediaSourceOpen: boolean = false;


  constructor() {
    this.audioContext = new AudioContext();
    this.audioElement = new Audio();
    this.mediaSource = new MediaSource();
    this.audioElement.src = URL.createObjectURL(this.mediaSource);
    this.audioElement.autoplay = true;

    // Connect the audio element to the audio context
    const sourceNode = this.audioContext.createMediaElementSource(this.audioElement);
    sourceNode.connect(this.audioContext.destination);

    // Set up MediaSource events
    this.mediaSource.addEventListener('sourceopen', this.onMediaSourceOpen);
    this.mediaSource.addEventListener('error', this.onMediaSourceError);
    this.mediaSource.addEventListener('sourceended', this.onMediaSourceEnded);
    this.mediaSource.addEventListener('sourceclose', this.onMediaSourceClosed);
  }

  private onMediaSourceOpen = () => {
    this.isMediaSourceOpen = true;
    this.sourceBuffer = this.mediaSource.addSourceBuffer(this.mimeType);
    this.sourceBuffer.mode = 'sequence'; // Ensure data is appended in order
    this.sourceBuffer.addEventListener('updateend', this.onSourceBufferUpdateEnd);
    this.sourceBuffer.addEventListener('error', this.onSourceBufferError);

    // Start appending data if any is queued
    this.appendNextChunk();
  };

  private onMediaSourceError = (e: Event) => {
    console.error('MediaSource error:', e);
  };

  private onMediaSourceEnded = () => {
    console.log('MediaSource ended');
  };

  private onMediaSourceClosed = () => {
    console.log('MediaSource closed');
  };

  private onSourceBufferError = (e: Event) => {
    console.error('SourceBuffer error:', e);
  };

  private onSourceBufferUpdateEnd = () => {
    this.isSourceBufferUpdating = false;

    // Continue appending if there's more data
    if (!this.isMediaSourceEnded) {
      this.appendNextChunk();
    } else {
      // End the stream if all data has been appended
      if (this.sourceBuffer && !this.sourceBuffer.updating && this.chunkQueue.length === 0) {
        this.mediaSource.endOfStream();
      }
    }
  };

  private appendNextChunk() {
    if (!this.sourceBuffer || this.isSourceBufferUpdating || !this.isMediaSourceOpen) return;

    if (this.chunkQueue.length > 0) {
      const chunk = this.chunkQueue.shift();
      if (chunk) {
        try {
          this.isSourceBufferUpdating = true;
          this.sourceBuffer.appendBuffer(chunk);
        } catch (e) {
          console.error('Error appending buffer:', e);
          this.isSourceBufferUpdating = false;
        }
      }
    } else if (this.isMediaSourceEnded) {
      if (this.sourceBuffer && !this.sourceBuffer.updating) {
        this.mediaSource.endOfStream();
      }
    }
  }

  /**
   * Enqueue an ArrayBuffer chunk to be played
   */
  public enqueueChunk(chunk: ArrayBuffer) {
    this.chunkQueue.push(chunk);
    this.appendNextChunk();
  }

  /**
   * Signal that no more chunks will be enqueued
   */
  public endPlayback() {
    this.isMediaSourceEnded = true;
    // If the sourceBuffer is not updating, we can end the stream
    if (this.sourceBuffer && !this.sourceBuffer.updating && this.chunkQueue.length === 0) {
      this.mediaSource.endOfStream();
    }
  }

  /**
   * Stop playback and clean up resources
   */
  public async stop() {
    this.audioElement.pause();
    this.chunkQueue = [];
    this.isMediaSourceEnded = true;

    if (this.sourceBuffer) {
      try {
        if (this.mediaSource.readyState === 'open') {
          this.mediaSource.endOfStream();
        }
        this.sourceBuffer.abort();
      } catch (e) {
        console.warn('Error stopping playback:', e);
      }
    }

    void this.audioContext.close(); // fire/forget
    this.audioElement.src = '';
  }
}



================================================
FILE: src/common/util/audio/AudioPlayer.ts
================================================
export namespace AudioPlayer {

  /**
   * Plays an audio file from a URL (e.g. an MP3 file).
   */
  export async function playUrl(url: string): Promise<void> {
    return new Promise((resolve, reject) => {
      const audio = new Audio(url);
      audio.onended = () => resolve();
      audio.onerror = (e) => reject(new Error(`Error playing audio: ${e}`));
      audio.play().catch(reject);
    });
  }

  /**
   * Plays an audio buffer (e.g. from an ArrayBuffer).
   */
  export async function playBuffer(audioBuffer: ArrayBuffer): Promise<void> {
    const audioContext = new AudioContext();
    const bufferSource = audioContext.createBufferSource();
    bufferSource.buffer = await audioContext.decodeAudioData(audioBuffer);
    bufferSource.connect(audioContext.destination);
    bufferSource.start();
    return new Promise((resolve) => {
      bufferSource.onended = () => resolve();
    });
  }

}



================================================
FILE: src/common/util/audio/usePlayUrl.ts
================================================
import * as React from 'react';
import { AudioPlayer } from '~/common/util/audio/AudioPlayer';


/**
 * Plays a sound from a URL, and optionally repeats it after a delay.
 * @param url The URL of the sound to play.
 * @param firstDelay The delay before the first play, in milliseconds.
 * @param repeatMs The delay between each repeat, in milliseconds. If 0, the sound will only play once.
 */
export function usePlayUrl(url: string | null, firstDelay: number = 0, repeatMs: number = 0) {
  React.useEffect(() => {
    if (!url) return;

    let timer2: any = null;

    const playFirstTime = () => {
      const playAudio = () => AudioPlayer.playUrl(url);
      void playAudio();
      timer2 = repeatMs > 0 ? setInterval(playAudio, repeatMs) : null;
    };

    const timer1 = setTimeout(playFirstTime, firstDelay);

    return () => {
      clearTimeout(timer1);
      if (timer2)
        clearInterval(timer2);
    };
  }, [firstDelay, repeatMs, url]);
}

/*export function useAudioPlayer() {
const [isPlaying, setIsPlaying] = React.useState(false);
const [currentUrl, setCurrentUrl] = React.useState<string | null>(null);

const play = React.useCallback(async (url: string) => {
  setCurrentUrl(url);
  setIsPlaying(true);
  try {
    await playUrl(url);
  } catch (error) {
    console.error('Error playing audio:', error);
  } finally {
    setIsPlaying(false);
  }
}, []);

const stop = React.useCallback(() => {
  setIsPlaying(false);
  setCurrentUrl(null);
}, []);

return { play, stop, isPlaying, currentUrl };
}*/



================================================
FILE: src/common/util/hooks/useAsyncCallBusy.ts
================================================
import * as React from 'react';

interface AsyncState<TData> {
  isLoading: boolean;
  error: Error | null;
  lastSuccessfulData: TData | null;
}

type AsyncFunction<TArgs extends any[], TResult> = (...args: TArgs) => Promise<TResult>;

type AsyncCallResult<TArgs extends any[], TResult> = [
  isLoading: boolean,
  execute: (...args: TArgs) => Promise<TResult>,
  error: Error | null,
  data: TResult | null
];


/**
 * Simplifies calls to `async` operations in React components.
 *
 * Ideal for standardizing async patterns in React applications, particularly
 * for API calls, data fetching, and other asynchronous tasks:
 *
 * - react to state: LOADING (the main reason for this), error, and data being set
 * - type safe: maintain typescript types throughout
 * - misc: prevent stale closures, memory leaks (on unmount - NOTE: REMOVED!), boilerplate
 */
export function useAsyncCallBusy<TArgs extends any[], TResult>(asyncFunction: AsyncFunction<TArgs, TResult>): AsyncCallResult<TArgs, TResult> {

  // least amount of state - updated pre, post, and in case of error
  const [state, setState] = React.useState<AsyncState<TResult>>({
    isLoading: false,
    error: null,
    lastSuccessfulData: null,
  });

  const latestAsyncFunction = React.useRef(asyncFunction);

  React.useEffect(() => {
    latestAsyncFunction.current = asyncFunction;
  }, [asyncFunction]);

  const execute = React.useCallback(async (...args: TArgs): Promise<TResult> => {
    setState(prev => ({
      ...prev,
      isLoading: true,
      error: null,
    }));

    try {
      const result = await latestAsyncFunction.current(...args);
      setState({
        isLoading: false,
        error: null,
        lastSuccessfulData: result,
      });
      return result;
    } catch (err) {
      const error = err instanceof Error ? err : new Error('An error occurred');
      setState(prev => ({
        ...prev,
        isLoading: false,
        error,
      }));
      throw error;
    }
  }, []);

  return [state.isLoading, execute, state.error, state.lastSuccessfulData];
}


================================================
FILE: src/common/util/hooks/useDeep.ts
================================================
/*
 * Custom implementation of deep equality check for objects and arrays.
 * Note that some libs provide it, but we don't want another dependency and this
 * is just right for us.
 */
export function isDeepEqual<T>(a: T, b: T): boolean {
  // Check if both are the same reference or both are null/undefined
  if (a === b) return true;

  // Check if either is null/undefined (but not both, as that case is handled above)
  if (a == null || b == null) return false;

  // If objects don't have the same constructor, they are not equal
  if (a.constructor !== b.constructor) return false;

  // Specific handling for arrays
  if (Array.isArray(a) && Array.isArray(b)) {
    if (a.length !== b.length) return false;
    for (let i = 0; i < a.length; i++)
      if (!isDeepEqual(a[i], b[i])) return false;
    return true;
  }

  // Handle generic objects
  if (typeof a === 'object') {
    const aKeys = Object.keys(a);
    const bKeys = Object.keys(b);

    // Check if objects have different number of keys
    if (aKeys.length !== bKeys.length) return false;

    // Check if objects have different keys or different values for the same keys
    for (const key of aKeys)
      if (!bKeys.includes(key) || !isDeepEqual((a as any)[key], (b as any)[key])) return false;

    return true;
  }

  // If none of the complex object checks apply or if they fail, the objects are not deeply equal
  return false;
}


/*export function useDeep<S, U>(selector: (state: S) => U): (state: S) => U {
  const prev = React.useRef<U>(undefined); // NOTE: not sure we're handling the initial value correctly in this function
  return (state) => {
    const next = selector(state);
    return isDeepEqual(prev.current, next)
      ? (prev.current as U)
      : (prev.current = next);
  };
}*/


================================================
FILE: src/common/util/hooks/useShallowObject.ts
================================================
import * as React from 'react';

/**
 * Shallow compare two objects for equality.
 * Returns true if the objects have the same properties and values.
 */
export function shallowEquals<T>(objA: T, objB: T) {

  // like '===' but handles two corner cases differently:
  // - +0 and -0 are different
  // - NaN and NaN are the same
  if (Object.is(objA, objB))
    return true;

  if (typeof objA !== 'object' || objA === null || typeof objB !== 'object' || objB === null)
    return false;

  // Map: special case
  if (objA instanceof Map && objB instanceof Map) {
    if (objA.size !== objB.size)
      return false;
    for (const [key, value] of objA)
      if (!Object.is(value, objB.get(key)))
        return false;
    return true;
  }

  // Set: special case
  if (objA instanceof Set && objB instanceof Set) {
    if (objA.size !== objB.size)
      return false;
    for (const value of objA)
      if (!objB.has(value))
        return false;
    return true;
  }

  // Array: shallow compare
  if (Array.isArray(objA)) {
    if (!Array.isArray(objB) || objA.length !== objB.length)
      return false;
    for (let i = 0; i < objA.length; i++)
      if (!Object.is(objA[i], objB[i]))
        return false;
    return true;
  }

  // Object  shallow compare (key and value equality)
  const keysA = Object.keys(objA) as (keyof T)[];
  if (keysA.length !== Object.keys(objB).length)
    return false;
  for (const keyA of keysA)
    if (!Object.hasOwn(objB, keyA as string) || !Object.is(objA[keyA], objB[keyA]))
      return false;
  return true;
}


/**
 * Returns a stable object reference when the value has not 'shallow' changed.
 * Useful to avoid unnecessary re-renders when the object reference changes but
 * the internal properties are the same.
 *
 * In case of b = { ...a }, b will be the same object reference as a when
 * the properties are the same.
 */
export function useShallowStable<T>(value: T): StableType<T> {
  /*
   * Ref to store the last value, so we can compare it with the new value, and
   * return the same object reference when the properties are 'shallow' equal.
   */
  const ref = React.useRef<T>(value);

  return React.useMemo(() => {
    if (!shallowEquals<T>(ref.current, value))
      ref.current = value;
    return ref.current;
  }, [value]) as StableType<T>;
}

type StableType<T> = T extends any[] ? T : T extends object ? T : never;


/**
 * Returns a `function` that will stabilize the object reference
 * when the value has not 'shallow' changed.
 *
 * Example:
 *   ...
 *   const stabilizePrinter = useShallowStabilizer<PrinterObjectType>();
 *   ...
 *   const printer = stabilizePrinter({...printerValue});
 *   ...
 */
export function useShallowStabilizer<T>(): (value: T) => T {
  const ref = React.useRef<T | null>(null);

  return React.useCallback((value: T) => {
    if (ref.current === null || !shallowEquals<T>(ref.current, value))
      ref.current = value;
    return ref.current;
  }, []);
}


================================================
FILE: src/common/util/hooks/useToggleableBoolean.ts
================================================
import * as React from 'react';

// in-memory map to remember the last state
const toggleStates = new Map<string, boolean>();

export function useToggleableBoolean(initialValue: boolean = false, key?: string) {

  // Retrieve the initial value from memory if a key is provided and exists in the map
  const memoryValue = key ? toggleStates.get(key) : undefined;

  // state
  const [value, setValue] = React.useState<boolean>(memoryValue ?? initialValue);

  // Define the toggle function
  const toggle = React.useCallback(() => {
    setValue(state => {
      const newValue = !state;
      // If a key is provided, update the value in the map
      if (key)
        toggleStates.set(key, newValue);
      return newValue;
    });
  }, [key]);

  return { on: value, toggle };
}

export type ToggleableBoolean = ReturnType<typeof useToggleableBoolean>;


================================================
FILE: src/common/util/mediasession/MediaSessionManager.ts
================================================
// type MediaSessionAction = 'play' | 'pause' | 'stop' | 'seekbackward' | 'seekforward' | 'previoustrack' | 'nexttrack';
// export type MediaSessionCallbacks = Partial<Record<MediaSessionAction, () => void>>;
//
//
// export class MediaSessionManager {
//
//   private static instance: MediaSessionManager;
//
//   private handlers: Record<MediaSessionAction, Set<() => void>> = {
//     play: new Set(),
//     pause: new Set(),
//     stop: new Set(),
//     seekbackward: new Set(),
//     seekforward: new Set(),
//     previoustrack: new Set(),
//     nexttrack: new Set(),
//   };
//
//   private constructor() {
//     if (!('mediaSession' in navigator)) {
//       console.warn('Media Session API is not supported in this browser.');
//     }
//   }
//
//   public static getInstance(): MediaSessionManager {
//     if (!MediaSessionManager.instance) {
//       MediaSessionManager.instance = new MediaSessionManager();
//     }
//     return MediaSessionManager.instance;
//   }
//
//   public registerComponent(handlers: MediaSessionCallbacks): void {
//     Object.entries(handlers).forEach(([action, handler]) => {
//       if (handler) {
//         this.handlers[action as MediaSessionAction].add(handler);
//       }
//     });
//     this.applyHandlers();
//   }
//
//   public unregisterComponent(handlers: MediaSessionCallbacks): void {
//     Object.entries(handlers).forEach(([action, handler]) => {
//       if (handler) {
//         this.handlers[action as MediaSessionAction].delete(handler);
//       }
//     });
//     this.applyHandlers();
//   }
//
//   private applyHandlers(): void {
//     if (!('mediaSession' in navigator)) return;
//
//     // check if we have any callbacks to set
//     const isEmpty = Object.values(this.handlers).every(handlers => handlers.size === 0);
//
//     // set Metadata, so that the world is notified of the presence of this global shortcut
//     if (isEmpty) {
//       if (navigator.mediaSession.metadata)
//         navigator.mediaSession.metadata = null;
//     } else {
//       if (!navigator.mediaSession.metadata)
//         navigator.mediaSession.metadata = new MediaMetadata({
//           title: ProductName...
//           artist: ProductName...
//           album: ProductName...
//         });
//     }
//
//     // add callbacks (even cascading ones for multiple registrations)
//     (Object.keys(this.handlers) as MediaSessionAction[]).forEach(action => {
//       const handlers = this.handlers[action];
//       if (handlers.size > 0) {
//         navigator.mediaSession.setActionHandler(action, () => {
//           handlers.forEach(handler => handler());
//         });
//       } else {
//         navigator.mediaSession.setActionHandler(action, null);
//       }
//     });
//   }
//
// }


================================================
FILE: src/common/util/mediasession/useMediaSessionCallbacks.ts
================================================
// import * as React from 'react';
//
// import { useShallowStable } from '../hooks/useShallowObject';
//
// import { MediaSessionCallbacks, MediaSessionManager } from './MediaSessionManager';
//
//
// // noinspection JSUnusedGlobalSymbols
// /**
//  * Note: this does not seem to be working as of now.
//  * The reason is possibly related to us not having an <audio> element in the DOM.
//  * @param handlers an object containing zero or more handlers for diverse media session actions
//  */
// export function useMediaSessionCallbacks(handlers: MediaSessionCallbacks) {
//
//   const stableHandlers = useShallowStable(handlers);
//
//   React.useEffect(() => {
//     MediaSessionManager.getInstance().registerComponent(stableHandlers);
//     return () => MediaSessionManager.getInstance().unregisterComponent(stableHandlers);
//   }, [stableHandlers]);
//
// }


================================================
FILE: src/modules/3rdparty/THIRD_PARTY_NOTICES.md
================================================
# Third-Party Notices

This project includes third-party software components that are subject to separate license terms. These components are located in the `src/modules/3rdparty/` directory. Below is a list of the third-party components and their respective licensing information.

---

## Aider

**Locations:**

- `src/modules/3rdparty/aider/coderPrompts.ts`
- `src/modules/3rdparty/aider/editBlockPrompts.ts`
- `src/modules/3rdparty/aider/wholeFilePrompts.ts`

**Original Repository:** [Aider](https://github.com/paul-gauthier/aider)

**License:** Apache License 2.0

**License File:** [AIDER-LICENSE.txt](aider/AIDER-LICENSE.txt)

### Description

Portions of this project are derived from **Aider**, specifically:

- Base prompts and variables for code editing functionality.
- Prompt templates for code editing and whole file modifications.
- The prompts have been translated from Python to JavaScript and adapted for use in the Big-AGI project.

### Modifications

- Translated from Python to JavaScript.
- Adjusted prompts to fit the context and functionality of the Big-AGI project.
- Organized the derived code within the `src/modules/3rdparty/aider/` directory for modularity.

**Note:** The inclusion of Aider code in this project is solely for enhancing the code-diff functionality. All obligations under the Apache License 2.0 are acknowledged and fulfilled. Users are advised to review the license terms provided.

---

## t3-env

**Locations:**
- `src/modules/3rdparty/t3-env/index.ts`
- `src/modules/3rdparty/t3-env/env-core.ts`
- `src/modules/3rdparty/t3-env/standard.ts`

**Original Repository:** [t3-oss/t3-env](https://github.com/t3-oss/t3-env/tree/main)

**License:** [MIT](https://github.com/t3-oss/t3-env/tree/main?tab=MIT-1-ov-file#readme)

### Description

The folder contains source code from the @t3-oss/t3-env package, a library for managing environment variables.
The original code includes:

- Presets for various environments (which we didn't use)
- Support for standard schema parsers (we only use Zod)

### Purpose

- To reduce dependency on an external library
- To initially migrate to Zod4 without waiting for this library to be updated

### Source Files

- [index.ts](https://github.com/t3-oss/t3-env/blob/main/packages/nextjs/src/index.ts) (commit b13d46b)
- [env-core.ts](https://github.com/t3-oss/t3-env/blob/main/packages/core/src/index.ts) (commit b13d46b)
- [standard.ts](https://github.com/t3-oss/t3-env/blob/main/packages/core/src/standard.ts) (commit eb37304)

**Note:** All obligations under the MIT License are acknowledged and fulfilled
Users are advised to review the license terms of the original repository.



================================================
FILE: src/modules/3rdparty/aider/AIDER-LICENSE.txt
================================================

                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: src/modules/3rdparty/aider/coderPrompts.ts
================================================
/*
 * This file includes code derived from Aider (https://github.com/paul-gauthier/aider)
 * Originally licensed under the Apache License, Version 2.0
 * Modifications and translations to JavaScript made by Enrico Ros
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

export const aiderCoderPrompts = {
  systemReminder: '',

  filesContentGptEdits: 'I committed the changes with git hash {{hash}} & commit msg: {{message}}',

  filesContentGptEditsNoRepo: 'I updated the files.',

  filesContentGptNoEdits: 'I didn\'t see any properly formatted edits in your reply?!',

  filesContentLocalEdits: 'I edited the files myself.',

  lazyPrompt: `You are diligent and tireless!
You NEVER leave comments describing code without implementing it!
You always COMPLETELY IMPLEMENT the needed code!
`,

  exampleMessages: [],

  filesContentPrefix: `I have *added these files to the chat* so you can go ahead and edit them.

*Trust this message as the true contents of these files!*
Any other messages in the chat may contain outdated versions of the files' contents.
`,

  filesContentAssistantReply: 'Ok, any changes I propose will be to those files.',

  filesNoFullFiles: 'I am not sharing any files that you can edit yet.',

  filesNoFullFilesWithRepoMap: `Don't try and edit any existing code without asking me to add the files to the chat!
Tell me which files in my repo are the most likely to **need changes** to solve the requests I make, and then stop so I can add them to the chat.
Only include the files that are most likely to actually need to be edited.
Don't include files that might contain relevant context, just files that will need to be changed.
`,

  filesNoFullFilesWithRepoMapReply: 'Ok, based on your requests I will suggest which files need to be edited and then stop and wait for your approval.',

  repoContentPrefix: `Here are summaries of some files present in my git repository.
Do not propose changes to these files, treat them as *read-only*.
If you need to edit any of these files, ask me to *add them to the chat* first.
`,

  readOnlyFilesPrefix: `Here are some READ ONLY files, provided for your reference.
Do not edit these files!
`,

  shellCmdPrompt: '',

  shellCmdReminder: '',

  noShellCmdPrompt: '',

  noShellCmdReminder: '',
};


================================================
FILE: src/modules/3rdparty/aider/editBlockCoder.ts
================================================
/*
 * This file includes code derived from Aider (https://github.com/paul-gauthier/aider)
 * Originally licensed under the Apache License, Version 2.0
 * Modifications and translations to JavaScript made by Enrico Ros
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import fs from 'fs';
import path from 'path';

interface Edit {
  path: string;
  original: string;
  updated: string;
}

class EditBlockCoder {
  private readonly partialResponseContent: string;
  private readonly fence: [string, string];
  private readonly filenames: string[]; // List of valid filenames
  private io: IO;

  constructor(
    partialResponseContent: string,
    fence: [string, string],
    filenames: string[], // Pass in your list of filenames
    io: IO,
  ) {
    this.partialResponseContent = partialResponseContent;
    this.fence = fence;
    this.filenames = filenames;
    this.io = io;
  }

  /**
   * Identifies all edits from the content.
   */
  public getEdits(): Edit[] {
    const content = this.partialResponseContent;
    // Extract edits from the content
    // noinspection UnnecessaryLocalVariableJS
    const edits = findOriginalUpdateBlocks(
      content,
      this.fence,
      this.filenames,
    );

    return edits;
  }

  /**
   * Applies all edits to the respective files.
   */
  public applyEdits(edits: Edit[]): void {
    const failed: Edit[] = [];
    const passed: Edit[] = [];

    for (const edit of edits) {
      const { path: relativePath, original, updated } = edit;
      let fullPath = this.absRootPath(relativePath);

      if (!fs.existsSync(fullPath)) {
        console.warn(`File ${relativePath} does not exist. Skipping edit.`);
        failed.push(edit);
        continue;
      }

      let content = this.io.readText(fullPath);
      let newContent = doReplace(fullPath, content, original, updated, this.fence);

      if (newContent) {
        this.io.writeText(fullPath, newContent);
        passed.push(edit);
      } else {
        failed.push(edit);
      }
    }

    if (failed.length > 0) {
      this.handleFailedEdits(failed, passed);
    }
  }

  /**
   * Handles edits that failed to apply.
   */
  private handleFailedEdits(failed: Edit[], passed: Edit[]): void {
    const blocks = failed.length === 1 ? 'block' : 'blocks';
    let message = `# ${failed.length} SEARCH/REPLACE ${blocks} failed to match!\n`;

    for (const edit of failed) {
      const { path, original, updated } = edit;

      const fullPath = this.absRootPath(path);
      const content = this.io.readText(fullPath);

      message += `
## SearchReplaceNoExactMatch: This SEARCH block failed to exactly match lines in ${path}
<<<<<<< SEARCH
${original}=======
${updated}>>>>>>> REPLACE

`;
      const suggestion = findSimilarLines(original, content);
      if (suggestion) {
        message += `Did you mean to match some of these actual lines from ${path}?

${this.fence[0]}
${suggestion}
${this.fence[1]}

`;
      }

      if (updated && content.includes(updated)) {
        message += `Are you sure you need this SEARCH/REPLACE block?
The REPLACE lines are already in ${path}!

`;
      }
    }

    message += `The SEARCH section must exactly match an existing block of lines including all whitespace, comments, indentation, docstrings, etc.\n`;

    if (passed.length > 0) {
      const pblocks = passed.length === 1 ? 'block' : 'blocks';
      message += `
# The other ${passed.length} SEARCH/REPLACE ${pblocks} were applied successfully.
Don't re-send them.
Just reply with fixed versions of the ${blocks} above that failed to match.
`;
    }

    throw new Error(message);
  }

  /**
   * Resolves a relative path to an absolute path.
   */
  private absRootPath(relPath: string): string {
    // Replace with your application's root directory logic if needed
    return path.resolve(process.cwd(), relPath);
  }
}

// Helper classes and functions

/**
 * IO class for reading and writing files.
 */
class IO {
  public readText(filePath: string): string {
    return fs.readFileSync(filePath, 'utf8');
  }

  public writeText(filePath: string, content: string): void {
    fs.writeFileSync(filePath, content, 'utf8');
  }
}

/**
 * Parses the content to find original and updated blocks.
 */
function findOriginalUpdateBlocks(
  content: string,
  fence: [string, string],
  validFnames: string[] = [],
): Edit[] {
  const edits: Edit[] = [];
  const lines = content.split('\n');
  let i = 0;
  let currentFilename: string | null = null;

  const headPattern = /^<{5,9} SEARCH/;
  const dividerPattern = /^={5,9}$/;
  const updatedPattern = /^>{5,9} REPLACE/;

  while (i < lines.length) {
    let line = lines[i];

    // Handle SEARCH/REPLACE blocks
    if (headPattern.test(line.trim())) {
      let filename = findFilename(lines.slice(Math.max(0, i - 3), i), fence, validFnames);
      filename = filename || currentFilename;
      if (!filename) {
        throw new Error(`Bad/missing filename before the fence ${fence[0]}`);
      }
      currentFilename = filename;

      const originalText: string[] = [];
      i += 1;
      while (i < lines.length && !dividerPattern.test(lines[i].trim())) {
        originalText.push(lines[i]);
        i += 1;
      }
      if (i >= lines.length || !dividerPattern.test(lines[i].trim())) {
        throw new Error(`Expected '======='`);
      }

      const updatedText: string[] = [];
      i += 1;
      while (i < lines.length && !updatedPattern.test(lines[i].trim()) && !dividerPattern.test(lines[i].trim())) {
        updatedText.push(lines[i]);
        i += 1;
      }
      if (i >= lines.length || (!updatedPattern.test(lines[i].trim()) && !dividerPattern.test(lines[i].trim()))) {
        throw new Error(`Expected '>>>>>>> REPLACE' or '======='`);
      }

      edits.push({
        path: filename,
        original: originalText.join('\n'),
        updated: updatedText.join('\n'),
      });
    }
    i += 1;
  }

  return edits;
}

/**
 * Tries to find the filename from previous lines.
 */
function findFilename(
  lines: string[],
  fence: [string, string],
  validFnames: string[],
): string | null {
  const reversedLines = [...lines].reverse();
  const filenames: string[] = [];

  for (const line of reversedLines.slice(0, 3)) {
    const filename = stripFilename(line, fence);
    if (filename) filenames.push(filename);
    if (!line.startsWith(fence[0])) break;
  }

  if (filenames.length === 0) return null;

  // Check for exact match
  for (const fname of filenames) {
    if (validFnames.includes(fname)) return fname;
  }

  // Check for basename match
  for (const fname of filenames) {
    for (const vfname of validFnames) {
      if (fname === path.basename(vfname)) return vfname;
    }
  }

  // Return the first filename with an extension
  return filenames.find(fname => fname.includes('.')) || filenames[0];
}

/**
 * Strips wrapping characters from the filename.
 */
function stripFilename(filename: string, fence: [string, string]): string | null {
  filename = filename.trim();

  if (filename === '...') return null;

  if (filename.startsWith(fence[0])) return null;

  filename = filename.replace(/[:#`*]/g, '').trim();
  return filename || null;
}

/**
 * Performs the replacement in the file content.
 */
function doReplace(
  fname: string,
  content: string,
  beforeText: string,
  afterText: string,
  fence: [string, string],
): string | null {
  beforeText = stripQuotedWrapping(beforeText, fname, fence);
  afterText = stripQuotedWrapping(afterText, fname, fence);

  // Handle new file creation
  if (!fs.existsSync(fname) && !beforeText.trim()) {
    fs.writeFileSync(fname, '', 'utf8');
    content = '';
  }

  if (!content) return null;

  if (!beforeText.trim()) {
    // Append to existing file
    return content + afterText;
  } else {
    const newContent = replaceMostSimilarChunk(content, beforeText, afterText);
    return newContent || null;
  }
}

/**
 * Strips quoted wrapping from the text.
 */
function stripQuotedWrapping(
  text: string,
  fname: string | undefined,
  fence: [string, string],
): string {
  if (!text) return text;

  let lines = text.split('\n');

  if (fname && lines[0].trim().endsWith(path.basename(fname))) {
    lines.shift();
  }

  if (lines[0].startsWith(fence[0]) && lines[lines.length - 1].startsWith(fence[1])) {
    lines = lines.slice(1, -1);
  }

  let result = lines.join('\n');
  if (result && !result.endsWith('\n')) result += '\n';

  return result;
}

/**
 * Attempts to replace the most similar chunk in the content.
 */
function replaceMostSimilarChunk(
  whole: string,
  part: string,
  replace: string,
): string | null {
  const wholeLines = whole.endsWith('\n') ? whole : whole + '\n';
  const partLines = part.endsWith('\n') ? part : part + '\n';
  const replaceLines = replace.endsWith('\n') ? replace : replace + '\n';

  const wholeArray = wholeLines.split('\n');
  const partArray = partLines.split('\n');
  const replaceArray = replaceLines.split('\n');

  // Try for an exact match
  const result = perfectReplace(wholeArray, partArray, replaceArray);

  if (result) return result.join('\n');

  // Try matching while ignoring leading whitespace
  const whitespaceResult = replaceIgnoringLeadingWhitespace(wholeArray, partArray, replaceArray);

  if (whitespaceResult) return whitespaceResult.join('\n');

  return null;
}

/**
 * Performs a perfect replacement if an exact match is found.
 */
function perfectReplace(
  whole: string[],
  part: string[],
  replace: string[],
): string[] | null {
  const partStr = part.join('\n');
  for (let i = 0; i <= whole.length - part.length; i++) {
    const slice = whole.slice(i, i + part.length).join('\n');
    if (slice === partStr) {
      return [...whole.slice(0, i), ...replace, ...whole.slice(i + part.length)];
    }
  }
  return null;
}

/**
 * Replaces content while ignoring leading whitespace differences.
 */
function replaceIgnoringLeadingWhitespace(
  whole: string[],
  part: string[],
  replace: string[],
): string[] | null {
  for (let i = 0; i <= whole.length - part.length; i++) {
    const slice = whole.slice(i, i + part.length);
    const match = slice.every((line, idx) => line.trimStart() === part[idx].trimStart());
    if (match) {
      // Adjust leading whitespace based on the existing content
      const leadingWhitespace = slice[0].match(/^\s*/)?.[0] || '';
      const adjustedReplace = replace.map(line => leadingWhitespace + line.trimStart());
      return [...whole.slice(0, i), ...adjustedReplace, ...whole.slice(i + part.length)];
    }
  }
  return null;
}

/**
 * Finds similar lines in the content to provide suggestions.
 */
function findSimilarLines(
  searchLines: string,
  contentLines: string,
  threshold: number = 0.6,
): string {
  const searchArray = searchLines.split('\n');
  const contentArray = contentLines.split('\n');

  let bestRatio = 0;
  let bestMatch: string[] | null = null;
  let bestMatchIndex = -1;

  for (let i = 0; i <= contentArray.length - searchArray.length; i++) {
    const chunk = contentArray.slice(i, i + searchArray.length);
    const ratio = stringSimilarity(searchArray.join('\n'), chunk.join('\n'));
    if (ratio > bestRatio) {
      bestRatio = ratio;
      bestMatch = chunk;
      bestMatchIndex = i;
    }
  }

  if (bestRatio < threshold || !bestMatch) return '';

  // Show context around the best match
  const N = 5;
  const start = Math.max(0, bestMatchIndex - N);
  const end = Math.min(contentArray.length, bestMatchIndex + searchArray.length + N);

  return contentArray.slice(start, end).join('\n');
}

/**
 * Calculates the similarity between two strings.
 */
function stringSimilarity(str1: string, str2: string): number {
  let longer = str1;
  let shorter = str2;
  if (str1.length < str2.length) {
    longer = str2;
    shorter = str1;
  }
  const longerLength = longer.length;
  if (longerLength === 0) {
    return 1.0;
  }
  return (longerLength - editDistance(longer, shorter)) / longerLength;
}

/**
 * Computes the edit distance between two strings.
 */
function editDistance(s1: string, s2: string): number {
  s1 = s1.toLowerCase();
  s2 = s2.toLowerCase();

  const costs: number[] = [];
  for (let i = 0; i <= s1.length; i++) {
    let lastValue = i;
    for (let j = 0; j <= s2.length; j++) {
      if (i === 0)
        costs[j] = j;
      else {
        if (j > 0) {
          let newValue = costs[j - 1];
          if (s1.charAt(i - 1) !== s2.charAt(j - 1))
            newValue = Math.min(Math.min(newValue, lastValue), costs[j]) + 1;
          costs[j - 1] = lastValue;
          lastValue = newValue;
        }
      }
    }
    if (i > 0)
      costs[s2.length] = lastValue;
  }
  return costs[s2.length];
}


================================================
FILE: src/modules/3rdparty/aider/editBlockPrompts.ts
================================================
/*
 * This file includes code derived from Aider (https://github.com/paul-gauthier/aider)
 * Originally licensed under the Apache License, Version 2.0
 * Modifications and translations to JavaScript made by Enrico Ros
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { processPromptTemplate } from '~/common/util/promptUtils';

import { aiderCoderPrompts } from './coderPrompts';

export function getMainSystemPrompt(lazyPrompt: string, shellCmdPrompt: string) {
  const template = `Act as an expert software developer.
Always use best practices when coding.
Respect and use existing conventions, libraries, etc that are already present in the code base.
{{lazy_prompt}}
Take requests for changes to the supplied code.
If the request is ambiguous, ask questions.

Always reply to the user in the same language they are using.

Once you understand the request you MUST:

1. Decide if you need to propose *SEARCH/REPLACE* edits to any files that haven't been added to the chat. You can create new files without asking!

But if you need to propose edits to existing files not already added to the chat, you *MUST* tell the user their full path names and ask them to *add the files to the chat*.
End your reply and wait for their approval.
You can keep asking if you then decide you need to edit more files.

2. Think step-by-step and explain the needed changes in a few short sentences.

3. Describe each change with a *SEARCH/REPLACE block* per the examples below.

All changes to files must use this *SEARCH/REPLACE block* format.
ONLY EVER RETURN CODE IN A *SEARCH/REPLACE BLOCK*!
{{shell_cmd_prompt}}
`;
  return processPromptTemplate(template, {
    lazy_prompt: lazyPrompt,
    shell_cmd_prompt: shellCmdPrompt,
  }, 'editBlockMainSystemPrompt');
}

export function getShellCmdPrompt(platform: string) {
  const template = `
4. *Concisely* suggest any shell commands the user might want to run in \`\`\`bash blocks.

Just suggest shell commands this way, not example code.
Only suggest complete shell commands that are ready to execute, without placeholders.
Only suggest at most a few shell commands at a time, not more than 1-3.

Use the appropriate shell based on the user's system info:
{{platform}}
Examples of when to suggest shell commands:

- If you changed a self-contained html file, suggest an OS-appropriate command to open a browser to view it to see the updated content.
- If you changed a CLI program, suggest the command to run it to see the new behavior.
- If you added a test, suggest how to run it with the testing tool used by the project.
- Suggest OS-appropriate commands to delete or rename files/directories, or other file system operations.
- If your code changes add new dependencies, suggest the command to install them.
- Etc.
`;
  return processPromptTemplate(template, {
    platform,
  }, 'shellCmdPrompt');
}

export function getNoShellCmdPrompt(platform: string) {
  const template = `
Keep in mind these details about the user's platform and environment:
{{platform}}
`;
  return processPromptTemplate(template, {
    platform,
  }, 'noShellCmdPrompt');
}

export const exampleMessages = [
  {
    role: 'user',
    content: 'Change get_factorial() to use math.factorial',
  },
  {
    role: 'assistant',
    content: `To make this change we need to modify \`mathweb/flask/app.py\` to:

1. Import the math package.
2. Remove the existing factorial() function.
3. Update get_factorial() to call math.factorial instead.

Here are the *SEARCH/REPLACE* blocks:

mathweb/flask/app.py
{{fence}}python
<<<<<<< SEARCH
from flask import Flask
=======
import math
from flask import Flask
>>>>>>> REPLACE
{{fence}}

mathweb/flask/app.py
{{fence}}python
<<<<<<< SEARCH
def factorial(n):
    "compute factorial"

    if n == 0:
        return 1
    else:
        return n * factorial(n-1)

=======
>>>>>>> REPLACE
{{fence}}

mathweb/flask/app.py
{{fence}}python
<<<<<<< SEARCH
    return str(factorial(n))
=======
    return str(math.factorial(n))
>>>>>>> REPLACE
{{fence}}
`,
  },
  {
    role: 'user',
    content: 'Refactor hello() into its own file.',
  },
  {
    role: 'assistant',
    content: `To make this change we need to modify \`main.py\` and make a new file \`hello.py\`:

1. Make a new hello.py file with hello() in it.
2. Remove hello() from main.py and replace it with an import.

Here are the *SEARCH/REPLACE* blocks:

hello.py
{{fence}}python
<<<<<<< SEARCH
=======
def hello():
    "print a greeting"

    print("hello")
>>>>>>> REPLACE
{{fence}}

main.py
{{fence}}python
<<<<<<< SEARCH
def hello():
    "print a greeting"

    print("hello")
=======
from hello import hello
>>>>>>> REPLACE
{{fence}}
`,
  },
];

export function getSystemReminder(lazyPrompt: string, shellCmdReminder: string) {
  const template = `# *SEARCH/REPLACE block* Rules:

Every *SEARCH/REPLACE block* must use this format:
1. The *FULL* file path alone on a line, verbatim. No bold asterisks, no quotes around it, no escaping of characters, etc.
2. The opening fence and code language, eg: {{fence}}python
3. The start of search block: <<<<<<< SEARCH
4. A contiguous chunk of lines to search for in the existing source code
5. The dividing line: =======
6. The lines to replace into the source code
7. The end of the replace block: >>>>>>> REPLACE
8. The closing fence: {{fence}}

Use the *FULL* file path, as shown to you by the user.

Every *SEARCH* section must *EXACTLY MATCH* the existing file content, character for character, including all comments, docstrings, etc.
If the file contains code or other data wrapped/escaped in json/xml/quotes or other containers, you need to propose edits to the literal contents of the file, including the container markup.

*SEARCH/REPLACE* blocks will replace *all* matching occurrences.
Include enough lines to make the SEARCH blocks uniquely match the lines to change.

Keep *SEARCH/REPLACE* blocks concise.
Break large *SEARCH/REPLACE* blocks into a series of smaller blocks that each change a small portion of the file.
Include just the changing lines, and a few surrounding lines if needed for uniqueness.
Do not include long runs of unchanging lines in *SEARCH/REPLACE* blocks.

Only create *SEARCH/REPLACE* blocks for files that the user has added to the chat!

To move code within a file, use 2 *SEARCH/REPLACE* blocks: 1 to delete it from its current location, 1 to insert it in the new location.

Pay attention to which filenames the user wants you to edit, especially if they are asking you to create a new file.

If you want to put code in a new file, use a *SEARCH/REPLACE block* with:
- A new file path, including dir name if needed
- An empty \`SEARCH\` section
- The new file's contents in the \`REPLACE\` section

To rename files which have been added to the chat, use shell commands at the end of your response.

{{lazy_prompt}}
ONLY EVER RETURN CODE IN A *SEARCH/REPLACE BLOCK*!
{{shell_cmd_reminder}}
`;
  return processPromptTemplate(template, {
    lazy_prompt: lazyPrompt,
    shell_cmd_reminder: shellCmdReminder,
    fence: '```',
  }, 'editBlockSystemReminder');
}

export const shellCmdReminder = aiderCoderPrompts.shellCmdReminder || `
Examples of when to suggest shell commands:

- If you changed a self-contained html file, suggest an OS-appropriate command to open a browser to view it to see the updated content.
- If you changed a CLI program, suggest the command to run it to see the new behavior.
- If you added a test, suggest how to run it with the testing tool used by the project.
- Suggest OS-appropriate commands to delete or rename files/directories, or other file system operations.
- If your code changes add new dependencies, suggest the command to install them.
- Etc.
`;


================================================
FILE: src/modules/3rdparty/aider/glue.ts
================================================
/*
 * This file includes code derived from Aider (https://github.com/paul-gauthier/aider)
 * Originally licensed under the Apache License, Version 2.0
 * Modifications and translations to JavaScript made by Enrico Ros
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { aiderCoderPrompts } from './coderPrompts';
import { exampleMessages, getMainSystemPrompt, getNoShellCmdPrompt, getSystemReminder } from './editBlockPrompts';

type ChatMessage = {
  role: 'user' | 'assistant' | 'system';
  text: string;
}

/**
 * Builds a EditBlock-style prompt.
 *
 * @param userMessage The request from the user.
 * @param platformMessage example: 'The user will apply the edits automatically without further review.'
 * @param isModelLazy False for powerful models.
 * @param useSystemPrompt True to put the main system prompt as a system message.
 */
export function getEditBlockDiffPrompt(userMessage: string, platformMessage: string, isModelLazy: boolean, useSystemPrompt: boolean): ChatMessage[] {
  const history: ChatMessage[] = [];

  // 1. main system prompt
  const lazyPrompt = isModelLazy ? aiderCoderPrompts.lazyPrompt : '';
  const noShellPrompt = getNoShellCmdPrompt(platformMessage);
  let mainSysPrompt = getMainSystemPrompt(lazyPrompt, noShellPrompt);
  if (exampleMessages.length > 0) {
    mainSysPrompt += '\n# Example conversations:\n\n';
    for (const example of exampleMessages)
      mainSysPrompt += `## ${example.role.toUpperCase()}: ${example.content}\n\n`;
  }
  // mainSysPrompt = mainSysPrompt.trim();
  const mainSysReminder = getSystemReminder(lazyPrompt, '');
  mainSysPrompt += '\n' + mainSysReminder;

  if (useSystemPrompt)
    history.push({
      role: 'system', text: mainSysPrompt,
    });
  else
    history.push({
      role: 'user', text: mainSysPrompt,
    }, {
      role: 'assistant', text: 'Ok.',
    });

  // [...] examples, readonly_files, repo, done, **chat_files**, **cur**, **reminder**

  // 6. chat_files
  history.push({
    role: 'user', text: aiderCoderPrompts.filesNoFullFilesWithRepoMap,
  }, {
    role: 'assistant', text: aiderCoderPrompts.filesNoFullFilesWithRepoMapReply,
  });

  // 7. cur + reminder
  userMessage = userMessage + '\n' + getSystemReminder(lazyPrompt, '');
  history.push({
    role: 'user', text: userMessage,
  });

  return history;
}


================================================
FILE: src/modules/3rdparty/aider/wholeFilePrompts.ts
================================================
/*
 * This file includes code derived from Aider (https://github.com/paul-gauthier/aider)
 * Originally licensed under the Apache License, Version 2.0
 * Modifications and translations to JavaScript made by Enrico Ros
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { processPromptTemplate } from '~/common/util/promptUtils';


export function getMainSystemPrompt(lazyPrompt: string) {
  const template = `Act as an expert software developer.
Take requests for changes to the supplied code.
If the request is ambiguous, ask questions.

Always reply to the user in the same language they are using.

{{lazy_prompt}}
Once you understand the request you MUST:
1. Determine if any code changes are needed.
2. Explain any needed changes.
3. If changes are needed, output a copy of each file that needs changes.
`;
  return processPromptTemplate(template, {
    lazy_prompt: lazyPrompt,
  }, 'wholeFileMainSystemPrompt');
}

export const exampleMessages = [
  {
    role: 'user',
    content: 'Change the greeting to be more casual',
  },
  {
    role: 'assistant',
    content: `Ok, I will:

1. Switch the greeting text from "Hello" to "Hey".

show_greeting.py
{{fence}}
import sys

def greeting(name):
    print(f"Hey {{name}}")

if __name__ == '__main__':
    greeting(sys.argv[1])
{{fence}}
`,
  },
];

export function getSystemReminder(lazyPrompt: string) {
  const template = `To suggest changes to a file you MUST return the entire content of the updated file.
You MUST use this *file listing* format:

path/to/filename.js
{{fence}}
// entire file content ...
// ... goes in between
{{fence}}

Every *file listing* MUST use this format:
- First line: the filename with any originally provided path
- Second line: opening {{fence}}
- ... entire content of the file ...
- Final line: closing {{fence}}

To suggest changes to a file you MUST return a *file listing* that contains the entire content of the file.
*NEVER* skip, omit or elide content from a *file listing* using "..." or by adding comments like "... rest of code..."!
Create a new file you MUST return a *file listing* which includes an appropriate filename, including any appropriate path.

{{lazy_prompt}}
`;
  return processPromptTemplate(template, {
    lazy_prompt: lazyPrompt,
    fence: '```',
  }, 'wholeFileSystemReminder');
}

export const redactedEditMessage = 'No changes are needed.';



================================================
FILE: src/modules/3rdparty/t3-env/env-core.ts
================================================
import type { StandardSchemaDictionary, StandardSchemaV1 } from "./standard";
import { parseWithDictionary } from "./standard";

export type { StandardSchemaV1, StandardSchemaDictionary };

export type ErrorMessage<T extends string> = T;
export type Simplify<T> = {
  [P in keyof T]: T[P];
} & {};

// biome-ignore lint/suspicious/noExplicitAny: <explanation>
type Impossible<T extends Record<string, any>> = Partial<
  Record<keyof T, never>
>;

type UnReadonlyObject<T> = T extends Readonly<infer U> ? U : T;

type Reduce<
  TArr extends Array<Record<string, unknown>>,
  TAcc = {},
> = TArr extends []
  ? TAcc
  : TArr extends [infer Head, ...infer Tail]
    ? Tail extends Array<Record<string, unknown>>
      ? Head & Reduce<Tail, TAcc>
      : never
    : never;

export interface BaseOptions<
  TShared extends Record<string, StandardSchemaV1>,
  TExtends extends Array<Record<string, unknown>>,
> {
  /**
   * How to determine whether the app is running on the server or the client.
   * @default typeof window === "undefined"
   */
  isServer?: boolean;

  /**
   * Shared variables, often those that are provided by build tools and is available to both client and server,
   * but isn't prefixed and doesn't require to be manually supplied. For example `NODE_ENV`, `VERCEL_URL` etc.
   */
  shared?: TShared;

  /**
   * Extend presets
   */
  extends?: TExtends;

  /**
   * Called when validation fails. By default the error is logged,
   * and an error is thrown telling what environment variables are invalid.
   */
  onValidationError?: (issues: readonly StandardSchemaV1.Issue[]) => never;

  /**
   * Called when a server-side environment variable is accessed on the client.
   * By default an error is thrown.
   */
  onInvalidAccess?: (variable: string) => never;

  /**
   * Whether to skip validation of environment variables.
   * @default false
   */
  skipValidation?: boolean;

  /**
   * By default, this library will feed the environment variables directly to
   * the Zod validator.
   *
   * This means that if you have an empty string for a value that is supposed
   * to be a number (e.g. `PORT=` in a ".env" file), Zod will incorrectly flag
   * it as a type mismatch violation. Additionally, if you have an empty string
   * for a value that is supposed to be a string with a default value (e.g.
   * `DOMAIN=` in an ".env" file), the default value will never be applied.
   *
   * In order to solve these issues, we recommend that all new projects
   * explicitly specify this option as true.
   */
  emptyStringAsUndefined?: boolean;
}

export interface LooseOptions<
  TShared extends Record<string, StandardSchemaV1>,
  TExtends extends Array<Record<string, unknown>>,
> extends BaseOptions<TShared, TExtends> {
  runtimeEnvStrict?: never;

  /**
   * What object holds the environment variables at runtime. This is usually
   * `process.env` or `import.meta.env`.
   */
  // Unlike `runtimeEnvStrict`, this doesn't enforce that all environment variables are set.
  runtimeEnv: Record<string, string | boolean | number | undefined>;
}

export interface StrictOptions<
  TPrefix extends string | undefined,
  TServer extends Record<string, StandardSchemaV1>,
  TClient extends Record<string, StandardSchemaV1>,
  TShared extends Record<string, StandardSchemaV1>,
  TExtends extends Array<Record<string, unknown>>,
> extends BaseOptions<TShared, TExtends> {
  /**
   * Runtime Environment variables to use for validation - `process.env`, `import.meta.env` or similar.
   * Enforces all environment variables to be set. Required in for example Next.js Edge and Client runtimes.
   */
  runtimeEnvStrict: Record<
    | {
    [TKey in keyof TClient]: TPrefix extends undefined
      ? never
      : TKey extends `${TPrefix}${string}`
        ? TKey
        : never;
  }[keyof TClient]
    | {
    [TKey in keyof TServer]: TPrefix extends undefined
      ? TKey
      : TKey extends `${TPrefix}${string}`
        ? never
        : TKey;
  }[keyof TServer]
    | {
    [TKey in keyof TShared]: TKey extends string ? TKey : never;
  }[keyof TShared],
    string | boolean | number | undefined
  >;
  runtimeEnv?: never;
}

export interface ClientOptions<
  TPrefix extends string | undefined,
  TClient extends Record<string, StandardSchemaV1>,
> {
  /**
   * The prefix that client-side variables must have. This is enforced both at
   * a type-level and at runtime.
   */
  clientPrefix: TPrefix;

  /**
   * Specify your client-side environment variables schema here. This way you can ensure the app isn't
   * built with invalid env vars.
   */
  client: Partial<{
    [TKey in keyof TClient]: TKey extends `${TPrefix}${string}`
      ? TClient[TKey]
      : ErrorMessage<`${TKey extends string
        ? TKey
        : never} is not prefixed with ${TPrefix}.`>;
  }>;
}

export interface ServerOptions<
  TPrefix extends string | undefined,
  TServer extends Record<string, StandardSchemaV1>,
> {
  /**
   * Specify your server-side environment variables schema here. This way you can ensure the app isn't
   * built with invalid env vars.
   */
  server: Partial<{
    [TKey in keyof TServer]: TPrefix extends undefined
      ? TServer[TKey]
      : TPrefix extends ""
        ? TServer[TKey]
        : TKey extends `${TPrefix}${string}`
          ? ErrorMessage<`${TKey extends `${TPrefix}${string}`
            ? TKey
            : never} should not prefixed with ${TPrefix}.`>
          : TServer[TKey];
  }>;
}

export type ServerClientOptions<
  TPrefix extends string | undefined,
  TServer extends Record<string, StandardSchemaV1>,
  TClient extends Record<string, StandardSchemaV1>,
> =
  | (ClientOptions<TPrefix, TClient> & ServerOptions<TPrefix, TServer>)
  | (ServerOptions<TPrefix, TServer> & Impossible<ClientOptions<never, never>>)
  | (ClientOptions<TPrefix, TClient> & Impossible<ServerOptions<never, never>>);

export type EnvOptions<
  TPrefix extends string | undefined,
  TServer extends Record<string, StandardSchemaV1>,
  TClient extends Record<string, StandardSchemaV1>,
  TShared extends Record<string, StandardSchemaV1>,
  TExtends extends Array<Record<string, unknown>>,
> =
  | (LooseOptions<TShared, TExtends> &
  ServerClientOptions<TPrefix, TServer, TClient>)
  | (StrictOptions<TPrefix, TServer, TClient, TShared, TExtends> &
  ServerClientOptions<TPrefix, TServer, TClient>);

type TPrefixFormat = string | undefined;
type TServerFormat = Record<string, StandardSchemaV1>;
type TClientFormat = Record<string, StandardSchemaV1>;
type TSharedFormat = Record<string, StandardSchemaV1>;
type TExtendsFormat = Array<Record<string, unknown>>;

export type CreateEnv<
  TServer extends TServerFormat,
  TClient extends TClientFormat,
  TShared extends TSharedFormat,
  TExtends extends TExtendsFormat,
> = Readonly<
  Simplify<
    StandardSchemaDictionary.InferOutput<TServer> &
    StandardSchemaDictionary.InferOutput<TClient> &
    StandardSchemaDictionary.InferOutput<TShared> &
    UnReadonlyObject<Reduce<TExtends>>
  >
>;

export function createEnv<
  TPrefix extends TPrefixFormat,
  TServer extends TServerFormat = NonNullable<unknown>,
  TClient extends TClientFormat = NonNullable<unknown>,
  TShared extends TSharedFormat = NonNullable<unknown>,
  const TExtends extends TExtendsFormat = [],
>(
  opts: EnvOptions<TPrefix, TServer, TClient, TShared, TExtends>,
): CreateEnv<TServer, TClient, TShared, TExtends> {
  const runtimeEnv = opts.runtimeEnvStrict ?? opts.runtimeEnv ?? process.env;

  const emptyStringAsUndefined = opts.emptyStringAsUndefined ?? false;
  if (emptyStringAsUndefined) {
    for (const [key, value] of Object.entries(runtimeEnv)) {
      if (value === "") {
        delete runtimeEnv[key];
      }
    }
  }

  const skip = !!opts.skipValidation;
  // biome-ignore lint/suspicious/noExplicitAny: <explanation>
  if (skip) return runtimeEnv as any;

  const _client = typeof opts.client === "object" ? opts.client : {};
  const _server = typeof opts.server === "object" ? opts.server : {};
  const _shared = typeof opts.shared === "object" ? opts.shared : {};
  const isServer =
    opts.isServer ?? (typeof window === "undefined" || "Deno" in window);

  const finalSchema = isServer
    ? {
      ..._server,
      ..._shared,
      ..._client,
    }
    : {
      ..._client,
      ..._shared,
    };

  const parsed = parseWithDictionary(finalSchema, runtimeEnv);

  const onValidationError =
    opts.onValidationError ??
    ((issues) => {
      console.error("❌ Invalid environment variables:", issues);
      throw new Error("Invalid environment variables");
    });

  const onInvalidAccess =
    opts.onInvalidAccess ??
    (() => {
      throw new Error(
        "❌ Attempted to access a server-side environment variable on the client",
      );
    });

  if (parsed.issues) {
    return onValidationError(parsed.issues);
  }

  const isServerAccess = (prop: string) => {
    if (!opts.clientPrefix) return true;
    return !prop.startsWith(opts.clientPrefix) && !(prop in _shared);
  };
  const isValidServerAccess = (prop: string) => {
    return isServer || !isServerAccess(prop);
  };
  const ignoreProp = (prop: string) => {
    return prop === "__esModule" || prop === "$$typeof";
  };

  const extendedObj = (opts.extends ?? []).reduce((acc, curr) => {
    return Object.assign(acc, curr);
  }, {});
  const fullObj = Object.assign(parsed.value, extendedObj);

  const env = new Proxy(fullObj, {
    get(target, prop) {
      if (typeof prop !== "string") return undefined;
      if (ignoreProp(prop)) return undefined;
      if (!isValidServerAccess(prop)) return onInvalidAccess(prop);
      return Reflect.get(target, prop);
    },
    // Maybe reconsider this in the future:
    // https://github.com/t3-oss/t3-env/pull/111#issuecomment-1682931526
    // set(_target, prop) {
    //   // Readonly - this is the error message you get from assigning to a frozen object
    //   throw new Error(
    //     typeof prop === "string"
    //       ? `Cannot assign to read only property ${prop} of object #<Object>`
    //       : `Cannot assign to read only property of object #<Object>`
    //   );
    // },
  });

  // biome-ignore lint/suspicious/noExplicitAny: <explanation>
  return env as any;
}


================================================
FILE: src/modules/3rdparty/t3-env/index.ts
================================================
import type {
  CreateEnv,
  ServerClientOptions,
  StandardSchemaV1,
  StrictOptions,
} from "./env-core";
import { createEnv as createEnvCore } from "./env-core";

const CLIENT_PREFIX = "NEXT_PUBLIC_" as const;
type ClientPrefix = typeof CLIENT_PREFIX;

type Options<
  TServer extends Record<string, StandardSchemaV1>,
  TClient extends Record<`${ClientPrefix}${string}`, StandardSchemaV1>,
  TShared extends Record<string, StandardSchemaV1>,
  TExtends extends Array<Record<string, unknown>>,
> = Omit<
  StrictOptions<ClientPrefix, TServer, TClient, TShared, TExtends> &
  ServerClientOptions<ClientPrefix, TServer, TClient>,
  "runtimeEnvStrict" | "runtimeEnv" | "clientPrefix"
> &
  (
    | {
    /**
     * Manual destruction of `process.env`. Required for Next.js < 13.4.4.
     */
    runtimeEnv: StrictOptions<
      ClientPrefix,
      TServer,
      TClient,
      TShared,
      TExtends
    >["runtimeEnvStrict"];
    experimental__runtimeEnv?: never;
  }
    | {
    runtimeEnv?: never;
    /**
     * Can be used for Next.js ^13.4.4 since they stopped static analysis of server side `process.env`.
     * Only client side `process.env` is statically analyzed and needs to be manually destructured.
     */
    experimental__runtimeEnv: Record<
      | {
      [TKey in keyof TClient]: TKey extends `${ClientPrefix}${string}`
        ? TKey
        : never;
    }[keyof TClient]
      | {
      [TKey in keyof TShared]: TKey extends string ? TKey : never;
    }[keyof TShared],
      string | boolean | number | undefined
    >;
  }
    );

export function createEnv<
  TServer extends Record<string, StandardSchemaV1> = NonNullable<unknown>,
  TClient extends Record<
    `${ClientPrefix}${string}`,
    StandardSchemaV1
  > = NonNullable<unknown>,
  TShared extends Record<string, StandardSchemaV1> = NonNullable<unknown>,
  const TExtends extends Array<Record<string, unknown>> = [],
>(
  opts: Options<TServer, TClient, TShared, TExtends>,
): CreateEnv<TServer, TClient, TShared, TExtends> {
  const client = typeof opts.client === "object" ? opts.client : {};
  const server = typeof opts.server === "object" ? opts.server : {};
  const shared = opts.shared;

  const runtimeEnv = opts.runtimeEnv
    ? opts.runtimeEnv
    : {
      ...process.env,
      ...opts.experimental__runtimeEnv,
    };

  return createEnvCore<ClientPrefix, TServer, TClient, TShared, TExtends>({
    ...opts,
    shared,
    client,
    server,
    clientPrefix: CLIENT_PREFIX,
    runtimeEnv,
  });
}


================================================
FILE: src/modules/3rdparty/t3-env/standard.ts
================================================
/** The Standard Schema interface. */
export interface StandardSchemaV1<Input = unknown, Output = Input> {
  /** The Standard Schema properties. */
  readonly "~standard": StandardSchemaV1.Props<Input, Output>;
}

export declare namespace StandardSchemaV1 {
  /** The Standard Schema properties interface. */
  export interface Props<Input = unknown, Output = Input> {
    /** The version number of the standard. */
    readonly version: 1;
    /** The vendor name of the schema library. */
    readonly vendor: string;
    /** Validates unknown input values. */
    readonly validate: (
      value: unknown,
    ) => Result<Output> | Promise<Result<Output>>;
    /** Inferred types associated with the schema. */
    readonly types?: Types<Input, Output> | undefined;
  }

  /** The result interface of the validate function. */
  export type Result<Output> = SuccessResult<Output> | FailureResult;

  /** The result interface if validation succeeds. */
  export interface SuccessResult<Output> {
    /** The typed output value. */
    readonly value: Output;
    /** The non-existent issues. */
    readonly issues?: undefined;
  }

  /** The result interface if validation fails. */
  export interface FailureResult {
    /** The issues of failed validation. */
    readonly issues: ReadonlyArray<Issue>;
  }

  /** The issue interface of the failure output. */
  export interface Issue {
    /** The error message of the issue. */
    readonly message: string;
    /** The path of the issue, if any. */
    readonly path?: ReadonlyArray<PropertyKey | PathSegment> | undefined;
  }

  /** The path segment interface of the issue. */
  export interface PathSegment {
    /** The key representing a path segment. */
    readonly key: PropertyKey;
  }

  /** The Standard Schema types interface. */
  export interface Types<Input = unknown, Output = Input> {
    /** The input type of the schema. */
    readonly input: Input;
    /** The output type of the schema. */
    readonly output: Output;
  }

  /** Infers the input type of a Standard Schema. */
  export type InferInput<Schema extends StandardSchemaV1> = NonNullable<
    Schema["~standard"]["types"]
  >["input"];

  /** Infers the output type of a Standard Schema. */
  export type InferOutput<Schema extends StandardSchemaV1> = NonNullable<
    Schema["~standard"]["types"]
  >["output"];
}

export type StandardSchemaDictionary = Record<string, StandardSchemaV1>;
export namespace StandardSchemaDictionary {
  /**
   * A dictionary of Standard Schemas that match the input and output types.
   */
  export type Matching<
    Input,
    Output extends Record<keyof Input, unknown> = Input,
  > = {
    [K in keyof Input]-?: StandardSchemaV1<Input[K], Output[K]>;
  };
  export type InferInput<T extends StandardSchemaDictionary> = {
    [K in keyof T]: StandardSchemaV1.InferInput<T[K]>;
  };
  export type InferOutput<T extends StandardSchemaDictionary> = {
    [K in keyof T]: StandardSchemaV1.InferOutput<T[K]>;
  };
}

export function parseWithDictionary<TDict extends StandardSchemaDictionary>(
  dictionary: TDict,
  value: Record<string, unknown>,
): StandardSchemaV1.Result<StandardSchemaDictionary.InferOutput<TDict>> {
  const result: Record<string, unknown> = {};
  const issues: StandardSchemaV1.Issue[] = [];
  for (const key in dictionary) {
    const schema = dictionary[key];
    const prop = value[key];
    const propResult = schema["~standard"].validate(prop);
    if (propResult instanceof Promise) {
      throw new Error(
        `Validation must be synchronous, but ${key} returned a Promise.`,
      );
    }
    if (propResult.issues) {
      issues.push(
        ...propResult.issues.map((issue) => ({
          ...issue,
          path: [key, ...(issue.path ?? [])],
        })),
      );
      continue;
    }
    result[key] = propResult.value;
  }
  if (issues.length) {
    return { issues };
  }
  return { value: result as never };
}


================================================
FILE: src/modules/aifn/useLLMChain.ts
================================================
import * as React from 'react';

import type { AixAPI_Context_ChatGenerate } from '~/modules/aix/server/api/aix.wiretypes';
import type { AixChatGenerate_TextMessages } from '~/modules/aix/client/aix.client.chatGenerateRequest';
import { aixChatGenerateText_Simple } from '~/modules/aix/client/aix.client';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { ellipsizeMiddle } from '~/common/util/textUtils';
import { findLLMOrThrow } from '~/common/stores/llms/store-llms';


// set to true to log to the console
const DEBUG_CHAIN = false;


export interface LLMChainStep {
  name: string;
  setSystem?: string;
  addUserChainInput?: boolean;
  addModelPrevOutput?: boolean;
  addUserText?: string;
}


/**
 * React hook to manage a chain of LLM transformations.
 */
export function useLLMChain(
  steps: LLMChainStep[],
  llmId: DLLMId | undefined,
  chainInput: string | undefined,
  aixContextName: AixAPI_Context_ChatGenerate['name'],
  aixContextRef: AixAPI_Context_ChatGenerate['ref'],
  onSuccess?: (output: string, input: string) => void,
) {

  // state
  const [chain, setChain] = React.useState<ChainState | null>(null);
  const [errorMessage, setErrorMessage] = React.useState<string | null>(null);
  const [chainStepInterimText, setChainStepInterimText] = React.useState<string | null>(null);
  const chainAbortController = React.useRef(new AbortController());


  // abort an ongoing chain, if any
  const abortChain = React.useCallback((reason: string) => {
    DEBUG_CHAIN && console.log('chain: abort (' + reason + ')');
    chainAbortController.current.abort(reason);
    chainAbortController.current = new AbortController();
  }, []);

  const userCancelChain = React.useCallback(() => {
    abortChain('user canceled');
    setErrorMessage('Canceled');
  }, [abortChain]);

  // starts a chain with the given inputs
  const startChain = React.useCallback((inputText: string | undefined, llmId: DLLMId | undefined, steps: LLMChainStep[]) => {
    DEBUG_CHAIN && console.log('chain: restart', { textLen: inputText?.length, llmId, stepsCount: steps.length });

    // abort any former running chain
    abortChain('restart');

    // init state
    setErrorMessage(!llmId ? 'LLM not provided' : null);
    setChain((inputText && llmId)
      ? _initChainState(llmId, inputText, steps)
      : null,
    );
    setChainStepInterimText(null);

  }, [abortChain]);

  // restarts this chain
  const restartChain = React.useCallback(() => {
    startChain(chainInput, llmId, steps);
  }, [chainInput, llmId, startChain, steps]);


  // [effect] Start on inputs change + Abort on unmounts
  React.useEffect(() => {
    restartChain();
    return () => abortChain('unmount');
  }, [restartChain, abortChain]);


  // stepper: perform Step on Chain updates
  React.useEffect(() => {

    // skip step if the chain has been aborted
    const _chainAbortController = chainAbortController.current;
    if (_chainAbortController.signal.aborted) return;

    // skip if there is no chain
    if (!chain || !llmId) return;

    // skip if no next unprocessed step
    const nextStepIdx = chain.stepStates.findIndex((step) => !step.isComplete);
    if (nextStepIdx === -1) return;

    // safety check (re-processing the same step shall never happen)
    const nextStepState = chain.stepStates[nextStepIdx];
    if (nextStepState.output)
      return console.log('WARNING - Output overlap - FIXME', nextStepState);
    const nextStep = nextStepState.def;


    // execute step instructions

    const stepSystemInstruction = nextStep.setSystem || chain.lastSystemInstruction || '';

    const stepChatHistory: AixChatGenerate_TextMessages = [...chain.lastChatHistory];

    if (nextStep.addUserChainInput)
      stepChatHistory.push({
        role: 'user',
        text: !chain.safeInputLength ? chain.chainInputText : ellipsizeMiddle(chain.chainInputText, chain.safeInputLength, '\n...\n'),
      });

    if (nextStep.addModelPrevOutput && nextStepIdx > 0)
      stepChatHistory.push({
        role: 'model',
        text: chain.safeInputLength
          ? ellipsizeMiddle(chain.stepStates[nextStepIdx - 1].output!, chain.safeInputLength, '\n...\n')
          : (chain.stepStates[nextStepIdx - 1].output || ''),
      });

    if (nextStep.addUserText)
      stepChatHistory.push({
        role: 'user',
        text: nextStep.addUserText,
      });

    // monitor for cleanup before the result
    let stepDone = false;
    const stepAbortController = new AbortController();
    const globalToStepListener = () => stepAbortController.abort('chain aborted');
    _chainAbortController.signal.addEventListener('abort', globalToStepListener);

    // interim text
    setChainStepInterimText(null);

    // LLM call (streaming, cancelable)
    aixChatGenerateText_Simple(
      llmId,
      stepSystemInstruction,
      stepChatHistory,
      aixContextName,
      aixContextRef,
      { abortSignal: stepAbortController.signal },
      setChainStepInterimText,
    )
      .then((stepOutputText) => {
        if (stepAbortController.signal.aborted)
          return;
        const chainState = _updateChainState_pure(chain, nextStepIdx, stepSystemInstruction, stepChatHistory, stepOutputText);
        if (chainState.outputText && onSuccess)
          onSuccess(chainState.outputText, chainState.chainInputText);
        setChain(chainState);
      })
      .catch((err) => {
        if (!stepAbortController.signal.aborted)
          setErrorMessage(`Transformation error: ${err?.message || err?.toString() || err || 'unknown'}`);
      })
      .finally(() => {
        stepDone = true;
        setChainStepInterimText(null);
      });

    // abort if unmounted before the LLM call ends, or if the full chain has been aborted
    return () => {
      if (!stepDone)
        stepAbortController.abort('step aborted');
      _chainAbortController.signal.removeEventListener('abort', globalToStepListener);
    };
  }, [aixContextName, aixContextRef, chain, llmId, onSuccess]);

  return {
    isFinished: !!chain?.outputText,
    isTransforming: !!chain?.stepStates?.length && !chain?.outputText && !errorMessage,
    chainOutputText: chain?.outputText ?? null,
    chainProgress: chain?.progress ?? 0,
    chainStepName: chain?.stepStates?.find((step) => !step.isComplete)?.def.name ?? null,
    chainStepInterimChars: chainStepInterimText?.length ?? null,
    chainIntermediates: chain?.stepStates
      ?.map((step) => ({ name: step.def.name, output: step.output ?? null }))
      .filter(i => !!i.output) ?? [],
    chainErrorMessage: errorMessage,
    userCancelChain,
    restartChain,
  };
}


interface ChainState {
  chainInputText: string;
  overrideResponseTokens: number | null;
  safeInputLength: number | null;

  stepStates: StepState[];

  lastSystemInstruction: string | null;
  lastChatHistory: AixChatGenerate_TextMessages;

  progress: number;
  outputText: string | null;
}

interface StepState {
  def: LLMChainStep;
  isLast: boolean;
  isComplete: boolean;
  output?: string;
}

function _initChainState(llmId: DLLMId, input: string, steps: LLMChainStep[]): ChainState {
  // max token allocation fo the job
  const llm = findLLMOrThrow(llmId);

  const overrideResponseTokens = llm.maxOutputTokens;
  const safeInputLength = (llm.contextTokens && overrideResponseTokens)
    ? Math.floor((llm.contextTokens - overrideResponseTokens) * 2)
    : null;

  return {
    // consts
    chainInputText: input,
    overrideResponseTokens,
    safeInputLength,

    // each step state
    stepStates: steps.map((step, i) => ({
      def: step,
      isLast: i === steps.length - 1,
      isComplete: false,
      output: undefined,
    })),

    // variables updated by the state machinery
    lastSystemInstruction: null,
    lastChatHistory: [],

    // input/output
    progress: 0,
    outputText: null,
  };
}

function _updateChainState_pure(chain: ChainState, stepIdx: number, stepSystemInstruction: string, stepChatHistory: AixChatGenerate_TextMessages, stepOutputText: string): ChainState {
  const stepsCount = chain.stepStates.length;
  return {
    ...chain,
    stepStates: chain.stepStates.map((step, i) =>
      (i === stepIdx) ? {
        ...step,
        // def // do not change
        // isLast // do not change
        isComplete: true,
        output: stepOutputText,
      } : step),
    lastSystemInstruction: stepSystemInstruction,
    lastChatHistory: stepChatHistory,
    progress: Math.round(100 * (stepIdx + 1) / stepsCount) / 100,
    outputText: (stepIdx === stepsCount - 1) ? stepOutputText : null,
  };
}



================================================
FILE: src/modules/aifn/useStreamChatText.ts
================================================
import * as React from 'react';

import type { AixAPI_Context_ChatGenerate } from '~/modules/aix/server/api/aix.wiretypes';
import type { AixChatGenerate_TextMessages } from '~/modules/aix/client/aix.client.chatGenerateRequest';
import { aixChatGenerateText_Simple } from '~/modules/aix/client/aix.client';

import type { DLLMId } from '~/common/stores/llms/llms.types';


/**
 * NOTE: we shall rename this to useAgiStreamChatText or similar, but let's not conclict already.
 */
export function useStreamChatText() {

  // state
  const [text, setText] = React.useState<string | null>(null);
  const [partialText, setPartialText] = React.useState<string | null>(null);
  const [streamError, setStreamError] = React.useState<string | null>(null);
  const abortControllerRef = React.useRef<AbortController | null>(null);


  const startStreaming = React.useCallback(async (llmId: DLLMId, systemInstructionText: string, aixChatGenerate_TextMessages: AixChatGenerate_TextMessages, aixContextName: AixAPI_Context_ChatGenerate['name'], aixContextRef: AixAPI_Context_ChatGenerate['ref']) => {
    setStreamError(null);
    setPartialText(null);
    setText(null);

    // Cancel any existing stream before starting a new one
    abortControllerRef.current?.abort();
    abortControllerRef.current = new AbortController();

    try {

      const finalText = await aixChatGenerateText_Simple(
        llmId,
        systemInstructionText,
        aixChatGenerate_TextMessages,
        aixContextName,
        aixContextRef,
        { abortSignal: abortControllerRef.current.signal },
        setPartialText,
      );

      // since streamChat has finished, we can assume the stream is complete
      setText(finalText);

    } catch (error: any) {
      setStreamError(error?.name !== 'AbortError'
        ? error?.message || error?.toString() || JSON.stringify(error) || 'Unknown error'
        : 'Interrupted.',
      );
    } finally {
      abortControllerRef.current = null;
    }
  }, []);

  const stopStreaming = React.useCallback(() => {
    abortControllerRef.current?.abort();
    abortControllerRef.current = null;
  }, []);

  const resetText = React.useCallback(() => {
    setText(null);
    setPartialText(null);
    setStreamError(null);
  }, []);


  // Clean up the abort controller when the component unmounts
  React.useEffect(() => {
    return () => stopStreaming();
  }, [stopStreaming]);


  return {
    // properties
    isStreaming: !!abortControllerRef.current,
    text,
    partialText,
    streamError,
    // methods
    startStreaming,
    stopStreaming,
    setText,
    resetText,
  };
}


================================================
FILE: src/modules/aifn/agiattachmentprompts/agiAttachmentPrompts.ts
================================================
import * as z from 'zod/v4';

import type { AixAPIChatGenerate_Request } from '~/modules/aix/server/api/aix.wiretypes';
import { aixCGR_ChatSequence_FromDMessagesOrThrow, aixCGR_SystemMessageText } from '~/modules/aix/client/aix.client.chatGenerateRequest';
import { aixChatGenerateContent_DMessage, aixCreateChatGenerateContext } from '~/modules/aix/client/aix.client';
import { aixFunctionCallTool, aixRequireSingleFunctionCallInvocation } from '~/modules/aix/client/aix.client.fromSimpleFunction';

import { createTextContentFragment, DMessageAttachmentFragment, isImageRefPart } from '~/common/stores/chat/chat.fragments';
import { getDomainModelIdOrThrow } from '~/common/stores/llms/store-llms';


export async function agiAttachmentPrompts(attachmentFragments: DMessageAttachmentFragment[], abortSignal: AbortSignal) {

  // precondition
  // const docParts = attachmentFragments.filter(f => f.part.pt === 'doc').map(f => f.part) as DMessageDocPart[];
  // const docs_count = docParts.length;
  const docs_count = attachmentFragments.length;
  if (docs_count < 1)
    return [];

  // require llm
  const requireVision = attachmentFragments.some(f => isImageRefPart(f.part));
  const llmId = getDomainModelIdOrThrow(['fastUtil', 'primaryChat'], true, requireVision, 'guess-attachments-prompts');

  const num_suggestions = 3;

  const inputSchema = z.object({ // zod-4
    attachments_analysis: z.array(
      z.object({
        name: z.string().describe('Identifier of the file.'),
        type: z.string().describe('Type or format of the file.'),
        summary: z.string().describe('Brief summary of the file\'s content, structure, commonalities and uniqueness. Be specific.'),
      }),
    ).describe(`Analysis of the ${docs_count} attachments.`),
    relationships: z.string().describe('Identified patterns, relationships, dependencies and differences between the attachments.'),
    top_orthogonal_user_actions: z.array(
      z.string().describe('Proposed action that relates to all the content, written as a authentic 5-15 words instruction coming from the user, each starting with an action verb.'),
    ).describe(`Top${num_suggestions} orthogonal inferred actions, deeply tied to patterns between the content, each action relating to all attachments.`),
    most_valuable_action: z.string().describe(`The most valuable option to take, considering the nature of all attachments. Suggested something at the intersection of the ${docs_count} attachments.`).optional(),
  });

  const aixChatGenerate: AixAPIChatGenerate_Request = {
    systemMessage: aixCGR_SystemMessageText(
      `You are an AI assistant skilled in content analysis and task inference within a chat application. 
Your function is to examine the attachments provided by the user, understand their nature and potential relationships, guess the user intention, and suggest the most likely and valuable actions the user intends to perform.
Respond only by calling the propose_user_actions_for_attachments function.`),
    chatSequence: await aixCGR_ChatSequence_FromDMessagesOrThrow([{
      role: 'user',
      fragments: [createTextContentFragment(`The user wants to perform an action for which is attaching ${docs_count} related pieces of content.
Analyze the provided content to determine its nature, identify any relationships between the pieces, and infer the most probable high-value task or action the user wants to perform.`)],
    }, {
      role: 'user',
      fragments: attachmentFragments,
    }, {
      role: 'user',
      fragments: [createTextContentFragment(`Call the function once, filling in order the attachments, the relationships between them, the top ${num_suggestions} orthogonal actions you inferred and the single most valuable action.`)],
    }]),
    tools: [
      aixFunctionCallTool({
        name: 'propose_user_actions_for_attachments',
        description: `Proposes ${num_suggestions} user actions from content analysis of ${docs_count} contents.`,
        inputSchema,
      }),
    ],
    toolsPolicy: { type: 'any' },
  } as const;

  const { fragments } = await aixChatGenerateContent_DMessage(
    llmId,
    aixChatGenerate,
    aixCreateChatGenerateContext('chat-attachment-prompts', attachmentFragments[0].fId),
    false,
    { abortSignal },
  );

  // extract the function call
  const { argsObject } = aixRequireSingleFunctionCallInvocation(fragments, 'propose_user_actions_for_attachments', false, 'agiAttachmentPrompts');

  const args = inputSchema.parse(argsObject);
  if (!args.top_orthogonal_user_actions?.length)
    throw new Error('AIX: Missing output');

  // prepend the top action to the list
  let topActions = args.top_orthogonal_user_actions;
  if (args.most_valuable_action) {
    topActions = topActions.filter(a => a !== args.most_valuable_action);
    topActions.unshift(args.most_valuable_action);
  }
  // return top 3
  return (topActions || []).slice(0, 3);
}



================================================
FILE: src/modules/aifn/agiattachmentprompts/useAgiAttachmentPrompts.tsx
================================================
import * as React from 'react';
import { useQuery } from '@tanstack/react-query';

import type { AttachmentDraft } from '~/common/attachment-drafts/attachment.types';
import { useShallowStable } from '~/common/util/hooks/useShallowObject';

import { agiAttachmentPrompts } from './agiAttachmentPrompts';


// interface

export interface AgiAttachmentPromptsData {
  isVisible: boolean;
  hasData: boolean;
  prompts: string[];
  error: Error | null;
  isFetching: boolean;
  isPending: boolean;
  refetch: () => Promise<any>;
  clear: () => void;
}

const noPrompts: string[] = [];

export function useAgiAttachmentPrompts(canAutoTrigger: boolean, attachmentDrafts: AttachmentDraft[]): AgiAttachmentPromptsData {

  // state
  const [isCleared, setIsCleared] = React.useState(false);
  const [alreadyRan, setAlreadyRan] = React.useState(false);

  // derived
  const fragments = attachmentDrafts.flatMap(draft => draft.outputFragments);
  const hasNoInput = fragments.length === 0;
  const hasEnoughInput = fragments.length >= 2;

  // async operation state
  const { data, error, isPending, isFetching, refetch } = useQuery({
    enabled: canAutoTrigger && hasEnoughInput && !alreadyRan,
    queryKey: ['aifn-prompts-attachments', ...fragments.map(f => f.fId).sort()],
    queryFn: async ({ signal }) => {
      const data = await agiAttachmentPrompts(fragments, signal);
      setIsCleared(false);
      return data;
    },
    staleTime: 1000 * 60 * 10, // 10 minutes
    // placeholderData: inputCount ? keepPreviousData : undefined,
  });

  const clear = React.useCallback(() => {
    setIsCleared(true);
  }, []);

  // derived state
  const isVisible = hasEnoughInput;
  const hasData = !!data && data.length > 0;

  // [effect] set/reset alreadyRan
  React.useEffect(() => {
    if (hasNoInput && alreadyRan)
      setAlreadyRan(false);
    else if (hasData && !alreadyRan)
      setAlreadyRan(true);
  }, [hasNoInput, hasData, alreadyRan]);

  return useShallowStable({
    isVisible,
    hasData: hasData && !isCleared,
    prompts: isCleared ? noPrompts : data || noPrompts,
    error,
    isFetching,
    isPending,
    refetch,
    clear,
  });
}



================================================
FILE: src/modules/aifn/agicodefixup/agiFixupCode.ts
================================================
import * as z from 'zod/v4';

import type { AixAPIChatGenerate_Request } from '~/modules/aix/server/api/aix.wiretypes';
import { aixChatGenerateContent_DMessage, aixCreateChatGenerateContext } from '~/modules/aix/client/aix.client';
import { aixCGR_FromSimpleText } from '~/modules/aix/client/aix.client.chatGenerateRequest';
import { aixFunctionCallTool, aixRequireSingleFunctionCallInvocation } from '~/modules/aix/client/aix.client.fromSimpleFunction';

import { getDomainModelIdOrThrow } from '~/common/stores/llms/store-llms';
import { processPromptTemplate } from '~/common/util/promptUtils';


export type CodeFixType = keyof typeof CodeFixes;

interface CodeFix {
  description: string;
  systemMessage: string;
  userInstructionTemplate: string; // Template with placeholders for `codeToFix` and `errorString`
  functionName: string;
  functionPolicy: 'invoke' | 'think-then-invoke';
  outputSchema: z.ZodObject<{
    corrected_code: z.ZodString;
  }>;
}

const CodeFixes: Record<string, CodeFix> = {};


/**
 *
 */
export async function agiFixupCode(issueType: CodeFixType, codeToFix: string, errorString: string | null, abortSignal: AbortSignal): Promise<string> {

  // Validate the issue type
  const config = CodeFixes[issueType];
  if (!config) throw new Error('Invalid issue type.');

  // Require the Chat LLM (for a change) - as this is a small but important call
  const llmId = getDomainModelIdOrThrow(['codeApply'], true, false, 'autofix-code');

  // Construct the AI chat generate request
  const templateVariables = {
    codeToFix: codeToFix,
    errorMessageSection: errorString?.trim() ? `The error message was:\n${errorString}\n\n` : '',
    functionName: config.functionName,
  };

  const aixRequest: AixAPIChatGenerate_Request = {
    ...aixCGR_FromSimpleText(
      processPromptTemplate(config.systemMessage, templateVariables, issueType),
      [{ role: 'user', text: processPromptTemplate(config.userInstructionTemplate, templateVariables, issueType) }],
    ),
    tools: [
      aixFunctionCallTool({
        name: config.functionName,
        description: config.description,
        inputSchema: config.outputSchema,
      }),
    ],
    toolsPolicy:
      config.functionPolicy === 'invoke' ? { type: 'function_call', function_call: { name: config.functionName } }
        : config.functionPolicy === 'think-then-invoke' ? { type: 'auto' } : undefined,
  };

  // Invoke the AI model
  const { fragments } = await aixChatGenerateContent_DMessage(
    llmId,
    aixRequest,
    aixCreateChatGenerateContext('fixup-code', '_DEV_'),
    false,
    { abortSignal, llmOptionsOverride: { llmTemperature: 0 /* chill the model for fixing code, we need valid json, not creativity */ } },
  );

  // Validate and parse the AI's response
  const { argsObject } = aixRequireSingleFunctionCallInvocation(fragments, config.functionName, config.functionPolicy === 'think-then-invoke', issueType);
  const argsZod = config.outputSchema.parse(argsObject);

  // Return the corrected code
  return argsZod.corrected_code;
}



================================================
FILE: src/modules/aifn/agicodefixup/useAgiFixupCode.tsx
================================================
import { type QueryObserverResult, useQuery } from '@tanstack/react-query';

import { agiFixupCode, CodeFixType } from './agiFixupCode';


export interface AgiFixCodeBlockData {
  correctedCode: string | null;
  error: Error | null;
  isFetching: boolean;
  isPending: boolean;
  refetch: () => Promise<QueryObserverResult<string, Error>>;
}

export function useAgiFixupCode(codeFixType: CodeFixType, canAutoTrigger: boolean, codeToFix: string, errorString: string | null): AgiFixCodeBlockData {

  // Async operation state using React Query
  const { data, error, isFetching, isPending, refetch } = useQuery<string, Error>({
    enabled: canAutoTrigger,
    queryKey: ['aifn-agi-fix-code', codeToFix, errorString],
    queryFn: async ({ signal }) => {
      return await agiFixupCode(codeFixType, codeToFix, errorString, signal);
    },
    staleTime: 1000 * 60 * 10, // 10 minutes
  });

  return {
    correctedCode: data || null,
    error,
    isFetching,
    isPending,
    refetch,
  };
}


================================================
FILE: src/modules/aifn/auto-chat-follow-ups/autoChatFollowUps.ts
================================================
import * as z from 'zod/v4';

import type { AixAPIChatGenerate_Request } from '~/modules/aix/server/api/aix.wiretypes';
import { AixClientFunctionCallToolDefinition, aixFunctionCallTool, aixRequireSingleFunctionCallInvocation } from '~/modules/aix/client/aix.client.fromSimpleFunction';
import { aixCGR_ChatSequence_FromDMessagesOrThrow, aixCGR_SystemMessageText } from '~/modules/aix/client/aix.client.chatGenerateRequest';
import { aixChatGenerateContent_DMessage, aixCreateChatGenerateContext } from '~/modules/aix/client/aix.client';

import { ConversationsManager } from '~/common/chat-overlay/ConversationsManager';
import { createDMessageTextContent, messageFragmentsReduceText } from '~/common/stores/chat/chat.message';
import { createErrorContentFragment, createPlaceholderVoidFragment, createTextContentFragment } from '~/common/stores/chat/chat.fragments';
import { getDomainModelIdOrThrow } from '~/common/stores/llms/store-llms';
import { marshallWrapText } from '~/common/stores/chat/chat.tokens';
import { processPromptTemplate } from '~/common/util/promptUtils';
import { useChatStore } from '~/common/stores/chat/store-chats';


/*const suggestUserFollowUpFn: VChatFunctionIn = {
  name: 'suggest_user_prompt',
  description: 'Surprises the user with a thought-provoking question/prompt/contrarian idea',
  parameters: {
    type: 'object',
    properties: {
      question_as_user: {
        type: 'string',
        description: 'The concise and insightful question that we propose the user should ask, designed to provoke deep thought and stimulate conversation',
      },
      title: {
        type: 'string',
        description: 'Very brief title, e.g., Meaning of Life',
      },
    },
    required: ['question_as_user', 'title'],
  },
};*/


// NOTE: also see the definition of the fixups in `src/modules/aifn/agicodefixup/agiFixupCode.ts`
interface DumbToolTBD {
  sys: string;
  usr: string;
  fun: AixClientFunctionCallToolDefinition,
}


function _getSystemMessage(tool: DumbToolTBD, variables: Record<string, string>, templateName: string): AixAPIChatGenerate_Request['systemMessage'] {
  return aixCGR_SystemMessageText(processPromptTemplate(tool.sys, { ...variables, functionName: tool.fun.name }, templateName));
}


// Auto-Diagram

const diagramsTool = {
  // variables: personaSystemPrompt, functionName
  sys: `You are an expert AI assistant skilled in creating diagrams. Analyze the conversation and user persona below to determine if a PlantUML diagram would complement or enhance the user's understanding.

Rate the diagram's usefulness (1-5): 1: Misleading, unnecessary or duplicate, 2: Not a fit or trivial, 3: Potentially useful to the user, 4: Very useful, 5: Essential.

Only if the rating is 4 or 5, include the diagram code, otherwise leave it empty and STOP.

---

# Assistant personality type:
{{personaSystemPrompt}}

---

# Instructions
Analyze the following short exchange and call the function {{functionName}} with the results of your analysis including code only if the score is 4 or 5.`,
  usr: 'Analyze the conversation and call {{functionName}} to assess diagram relevance and generate PlantUML if highly relevant.',
  fun: {
    name: 'draw_plantuml_diagram',
    description: 'Generates a PlantUML diagram or mindmap from the last message, if applicable, very useful to the user, and no other diagrams are present.',
    inputSchema: z.object({ // zod-4
      rating_short_reason: z.string().describe('A 4-10 words reason on whether the diagram would be desired by the user or not.'),
      rating_number: z.number().describe('The relevance of the diagram to the conversation, on a scale of 1 to 5 . If lower than 4, STOP.'),
      type: z.string().describe('The most suitable PlantUML diagram type: sequence, usecase, class, activity, component, state, object, deployment, timing, network, wireframe, gantt, wbs or mindmap.').optional(),
      code: z.string().describe('A valid PlantUML string (@startuml...@enduml) to be rendered as a diagram or mindmap (@startmindmap...@endmindmap), or empty. No external references allowed. Use one or more asterisks to indent and separate with spaces.').optional(),
    }),
  },
} satisfies DumbToolTBD;


// Auto-HTML-UI

const suggestUIFunctionName = 'generate_web_ui';

export const autoFollowUpUIMixin = `Do not generate code, unless via the \`${suggestUIFunctionName}\` function call, IF DEFINED`;

// noinspection HtmlRequiredTitleElement
const uiTool = {
  sys: `You are a helpful AI assistant skilled in creating user interfaces. Analyze the conversation and user persona below to determine if an HTML user interface would complement or enhance the user's understanding.

**Rating System**
Rate the UI's usefulness (1-5): 1. Misleading, unnecessary, or duplicate, 2. Not a fit or trivial, 3. Potentially useful or thought-provoking to the user, 4. Very useful, 5. Essential

Only if the rating is 3, 4, or 5, generate the HTML code. Ensure the generated UI is visual, interactive, resilient, and engaging.

**Assistant Personality Type**
{{personaSystemPrompt}}

**Instructions**
Analyze the following short exchange and call the function {{functionName}} with the HTML code only if the score is 3, 4, or 5.

Please follow closely the following requirements:
- **Generate Web UIs** such as interactive games, blueprints, mockups, data visualizations, dashboards, and tutorials.
- **Code Quality and Resilience:** The single-file HTML, CSS, and JavaScript code must be correct and resilient, as there will be no opportunity to modify it after.
- **Include HTML Comments:** After the DOCTYPE, explain your brief concept choices and short implementation guidelines.
- **Frontend-Only Architecture:** The code should be self-contained, using HTML, CSS, and JavaScript only. External images are allowed. Must not require backend or environment setup.
- **Include Tailwind CSS:** Add \`<script src='https://cdn.tailwindcss.com/3.4.3'></script>\` in the \`<head>\` section.
- **Incorporate Trends:** Selectively use abstract gradients, color clashing, vintage minimalism, geometric shapes, or 3D bubble text where they enhance the UI's purpose and user experience.
- **Functional Requirements:** The UI must solve the user's problem, demonstrate a complete feature or concept, be visually impressive, and renderable in isolation.`,
  usr: 'Analyze the conversation and call {{functionName}} to evaluate UI relevance and generate HTML code if sufficiently useful.',
  fun: {
    name: suggestUIFunctionName,
    description: 'Renders a web UI when provided with a single concise HTML5 string (can include CSS and JS), if applicable and relevant.',
    inputSchema: z.object({ // zod-4
      possible_ui_requirements: z.string().describe('Brief (10 words) to medium length (40 words) requirements for the UI. Include main features, looks, and layout.'),
      rating_short_reason: z.string().describe('A 4-10 word reason on whether the UI would be desired by the user or not.'),
      rating_number: z.number().describe('The relevance of the UI to the conversation, on a scale of 1 (does not add much value), 2 (superfluous), 3 (helps a lot in understanding), 4 (essential) to 5 (fundamental to the understanding). If 1 or 2, do not proceed and STOP.'),
      html: z.string().describe('A valid HTML string containing the user interface code. The code should be complete, with no dependencies, lower case, and include minimal inline CSS if needed. The UI should be visual and interactive.').optional(),
      file_name: z.string().describe('Short letters-and-dashes file name of the HTML without the .html extension.').optional(),
    }),
  },
} satisfies DumbToolTBD;


/**
 * Formulates proposals (based on 2 messages, at least) for:
 * - Diagrams: will process the message and append diagrams
 * - HTML UI: automatically append a HTML UI, if valuable
 * - [missing] follow-up questions
 * - [missing] prompts
 * - [missing] counterpoints
 */
export async function autoChatFollowUps(conversationId: string, assistantMessageId: string, suggestDiagrams: boolean, suggestHTMLUI: boolean, suggestQuestions: boolean) {

  // skip invalid or short conversations
  const { conversations } = useChatStore.getState();
  const conversation = conversations.find(c => c.id === conversationId) ?? null;
  if (!conversation || conversation.messages.length < 2) return;

  // require a valid fast model (only)
  let codeLlmId;
  try {
    codeLlmId = getDomainModelIdOrThrow(['codeApply'], true, false, 'chat-followups');
  } catch (error) {
    return console.log(`autoSuggestions: ${error}`);
  }

  // find the index of the assistant message
  const assistantMessageIndex = conversation.messages.findIndex(m => m.id === assistantMessageId);
  if (assistantMessageIndex < 2) return;

  const systemMessage = conversation.messages[0];
  const userMessage = conversation.messages[assistantMessageIndex - 1];
  const assistantMessage = conversation.messages[assistantMessageIndex];

  // verify the roles of the last messages
  if (!(systemMessage?.role === 'system') || !(userMessage?.role === 'user') || !(assistantMessage?.role === 'assistant')) return;

  // Execute the following follow-ups in parallel
  // const assistantMessageId = assistantMessage.id;

  const personaSystemPrompt = messageFragmentsReduceText(systemMessage.fragments);
  const assistantMessageText = messageFragmentsReduceText(assistantMessage.fragments);

  const cHandler = ConversationsManager.getHandler(conversationId);

  // Follow-up: Question
  if (suggestQuestions) {
    // ... TODO ...
  }

  // Follow-up: Auto-Diagrams if the assistant text does not contain @startuml / @startmindmap already
  if (suggestDiagrams && !['@startuml', '@startmindmap', '```plantuml', '```mermaid'].some(s => assistantMessageText.includes(s))) {

    // Placeholder for the diagram
    const placeholderFragment = createPlaceholderVoidFragment('Auto-Diagram ...');
    cHandler.messageFragmentAppend(assistantMessageId, placeholderFragment, false, false);

    // Instructions
    const systemMessage = _getSystemMessage(diagramsTool, { personaSystemPrompt }, 'chat-followup-diagram_system');
    const chatSequence = await aixCGR_ChatSequence_FromDMessagesOrThrow([
      userMessage,
      assistantMessage,
      createDMessageTextContent('user', processPromptTemplate(diagramsTool.usr, { functionName: diagramsTool.fun.name }, 'chat-followup-diagram_reminder')),
    ]);

    // Strict call to a function
    aixChatGenerateContent_DMessage(
      codeLlmId,
      { systemMessage, chatSequence, tools: [aixFunctionCallTool(diagramsTool.fun)], toolsPolicy: { type: 'any' } },
      aixCreateChatGenerateContext('chat-followup-diagram', conversationId),
      false,
      { abortSignal: 'NON_ABORTABLE' },
    ).then(({ fragments }) => {

      // extract the function call
      const { argsObject } = aixRequireSingleFunctionCallInvocation(fragments, diagramsTool.fun.name, false, 'chat-followup-diagram');
      const { code, type } = diagramsTool.fun.inputSchema.parse(argsObject);
      if (code && type) {

        // validate the code
        const plantUML = code.trim();
        if (!plantUML.startsWith('@start') || !(plantUML.endsWith('@enduml') || plantUML.endsWith('@endmindmap'))) {
          console.log(`autoSuggestions: invalid generated PlantUML: ${plantUML.slice(0, 20)}...`);
          throw new Error('Invalid PlantUML');
        }

        // PlantUML Text Content to replace the placeholder
        const fileName = `${type}.diagram`;
        const codeBlock = marshallWrapText(plantUML, /*'[Auto Diagram] ' +*/ fileName, 'markdown-code');
        const fragment = createTextContentFragment(codeBlock);
        cHandler.messageFragmentReplace(assistantMessageId, placeholderFragment.fId, fragment, false);
        return;
      }

      // no diagram generated
      cHandler.messageFragmentDelete(assistantMessageId, placeholderFragment.fId, false, false);
    }).catch(error => {
      cHandler.messageFragmentReplace(assistantMessageId, placeholderFragment.fId, createErrorContentFragment(`Auto-Diagram generation issue: ${error?.message || error}`), false);
    });
  }

  // Follow-up: Auto-HTML-UI if the assistant text does not contain <html> already
  if (suggestHTMLUI && !['<html', '<HTML', '<Html'].some(s => assistantMessageText.includes(s))) {

    // Placeholder for the UI
    const placeholderFragment = createPlaceholderVoidFragment('Auto-UI ...');
    cHandler.messageFragmentAppend(assistantMessageId, placeholderFragment, false, false);

    // Instructions
    const systemMessage = _getSystemMessage(uiTool, { personaSystemPrompt }, 'chat-followup-htmlui_system');
    const chatSequence = await aixCGR_ChatSequence_FromDMessagesOrThrow([
      userMessage,
      assistantMessage,
      createDMessageTextContent('user', processPromptTemplate(uiTool.usr, { functionName: uiTool.fun.name }, 'chat-followup-htmlui_reminder')),
    ]);

    // Strict call to a function
    aixChatGenerateContent_DMessage(
      codeLlmId,
      { systemMessage, chatSequence, tools: [aixFunctionCallTool(uiTool.fun)], toolsPolicy: { type: 'any' } },
      aixCreateChatGenerateContext('chat-followup-htmlui', conversationId),
      false,
      { abortSignal: 'NON_ABORTABLE' },
    ).then(({ fragments }) => {

      // extract the function call
      const { argsObject } = aixRequireSingleFunctionCallInvocation(fragments, uiTool.fun.name, false, 'chat-followup-diagram');
      const { html, file_name } = uiTool.fun.inputSchema.parse(argsObject);
      if (html && file_name) {

        // validate the code
        const htmlUI = html.trim();
        if (!['<!DOCTYPE', '<!doctype', '<html', '<HTML', '<Html'].some(s => htmlUI.includes(s))) {
          console.log(`autoSuggestions: invalid generated HTML: ${htmlUI.slice(0, 20)}...`);
          throw new Error('Invalid HTML');
        }

        // HTML UI Text Content to replace the placeholder
        const fileName = (file_name || 'ui').trim().replace(/[^a-zA-Z0-9-]/g, '') + '.html';
        const codeBlock = marshallWrapText(htmlUI, /*'[Generative UI] ' +*/ fileName, 'markdown-code');
        const fragment = createTextContentFragment(codeBlock); // `Example of Generative User Interface ("Auto UI" setting):\n${codeBlock}`
        cHandler.messageFragmentReplace(assistantMessageId, placeholderFragment.fId, fragment, false);
        return;
      }

      // no UI generated
      cHandler.messageFragmentDelete(assistantMessageId, placeholderFragment.fId, false, false);
    }).catch(error => {
      cHandler.messageFragmentReplace(assistantMessageId, placeholderFragment.fId, createErrorContentFragment(`Auto-UI generation issue: ${error?.message || error}`), false);
    });
  }

}


================================================
FILE: src/modules/aifn/autotitle/autoTitle.ts
================================================
import { aixChatGenerateText_Simple } from '~/modules/aix/client/aix.client';

import { excludeSystemMessages } from '~/common/stores/chat/chat.conversation';
import { getConversation, useChatStore } from '~/common/stores/chat/store-chats';
import { getDomainModelIdOrThrow } from '~/common/stores/llms/store-llms';
import { messageFragmentsReduceText } from '~/common/stores/chat/chat.message';


/**
 * Creates the AI titles for conversations, by taking the last 5 first-lines and asking AI what's that about
 * @returns true if the title was actually replaced (for instance, it may not be needed)
 */
export async function autoConversationTitle(conversationId: string, forceReplace: boolean): Promise<boolean> {

  // use valid fast model
  let autoTitleLlmId;
  try {
    autoTitleLlmId = getDomainModelIdOrThrow(['fastUtil'], false, false, 'conversation-titler');
  } catch (error) {
    console.log(`autoConversationTitle: ${error}`);
    return false;
  }

  // only operate on valid conversations, without any title
  const conversation = getConversation(conversationId);
  if (!conversation || (!forceReplace && (conversation.autoTitle || conversation.userTitle)))
    return false;

  const { setAutoTitle, setUserTitle } = useChatStore.getState();
  if (forceReplace) {
    setUserTitle(conversationId, '');
    setAutoTitle(conversationId, '✏️...');
  }

  // first line of the last 5 messages
  const historyLines: string[] = excludeSystemMessages(conversation.messages).slice(-5).map(m => {
    const messageText = messageFragmentsReduceText(m.fragments);
    let text = messageText.split('\n')[0];
    text = text.length > 100 ? text.substring(0, 100) + '...' : text;
    text = `${m.role === 'user' ? 'You' : 'Assistant'}: ${text}`;
    return `- ${text}`;
  });


  try {

    // LLM chat-generate call
    let title = await aixChatGenerateText_Simple(
      autoTitleLlmId,
      'You are an AI conversation titles assistant who specializes in creating expressive yet few-words chat titles.',
      `Analyze the given short conversation (every line is truncated) and extract a concise chat title that summarizes the conversation in as little as a couple of words.
Only respond with the lowercase short title and nothing else.

\`\`\`
${historyLines.join('\n')}
\`\`\``,
      'chat-ai-title', conversationId,
    );

    // parse title
    title = title
      ?.trim()
      ?.replaceAll('"', '')
      ?.replace('Title: ', '')
      ?.replace('title: ', '');

    // data write
    if (title) {
      setAutoTitle(conversationId, title);
      return true;
    }

  } catch (error: any) {
    // not critical at all
    console.log('Failed to auto-title conversation', conversationId, { error });
    if (forceReplace)
      setAutoTitle(conversationId, '');
  }

  return false;
}


================================================
FILE: src/modules/aifn/digrams/diagrams.data.ts
================================================
import type { AixChatGenerate_TextMessages } from '~/modules/aix/client/aix.client.chatGenerateRequest';

import type { FormRadioOption } from '~/common/components/forms/FormRadioControl';


export type DiagramType = 'auto' | 'mind';
export type DiagramLanguage = 'mermaid' | 'plantuml';


// NOTE: keep these global, or it will trigger re-renders
export const diagramTypes: FormRadioOption<DiagramType>[] = [
  { label: 'Automatic', value: 'auto' },
  { label: 'Mindmap', value: 'mind' },
];

export const diagramLanguages: FormRadioOption<DiagramLanguage>[] = [
  { label: 'PlantUML', value: 'plantuml' },
  { label: 'Mermaid (mindmaps)', value: 'mermaid' },
];

const mermaidMindmapExample = `For example:
\`\`\`mermaid
mindmap
  root((mindmap))
    Origins
      Long history
      ::icon(fa fa-book)
      Popularisation
        British popular psychology author Tony Buzan
    Research
      On effectiveness<br/>and features
      On Automatic creation
        Uses
            Creative techniques
    Tools
      Pen and paper
      Mermaid
\`\`\`
`;

function plantumlDiagramPrompt(diagramType: DiagramType): { sys: string, usr: string } {
  switch (diagramType) {
    case 'auto':
      return {
        sys: 'Generate a valid PlantUML diagram markdown (```plantuml\\n@startuml\\n...@enduml\\n```), ready for rendering. No external references allowed and all strings must be escaped correctly (each in a single line). Choose the most suitable PlantUML diagram type: sequence, class, use case, activity, component, state, object, deployment, wireframe, mindmap, gantt, or flowchart.',
        usr: 'Generate the PlantUML code for a suitable diagram that best captures the essence of the preceding message.',
      };
    case 'mind':
      return {
        sys: 'Generate a valid PlantUML mindmap markdown (```plantuml\\n@startmindmap\\n...@endmindmap\\n\`\`\`), ready for rendering. No external references allowed. Use one or more asterisks to indent and separate with spaces.',
        usr: 'Generate a PlantUML mindmap that effectively summarizes the key points from the preceding message.',
      };
  }
}

function mermaidDiagramPrompt(diagramType: DiagramType): { sys: string, usr: string } {
  let promptDetails = diagramType === 'auto'
    ? 'Generate a valid Mermaid diagram markdown (```mermaid\\n...```), ready for rendering. The code should have no external references and all names must be properly escaped. Select the most appropriate Mermaid diagram type: flowchart, sequence, class, state, erd, gantt, pie, or git.'
    : 'Generate a valid Mermaid mindmap markdown (```mermaid\\n...```), ready for rendering. The code should have no external references and all names must be properly escaped. ' + mermaidMindmapExample;
  return {
    sys: `Your task is to generate accurate and well-structured Mermaid code from the given text. ${promptDetails}`,
    usr: `Generate the Mermaid code for a ${diagramType === 'auto' ? 'suitable diagram' : 'mind map'} that ${diagramType === 'auto' ? 'best captures the essence' : 'effectively summarizes the key points'} of the preceding message.`,
  };
}

const sysSuffixPM = 'The next three messages will outline: 1. your personality, 2. the data you\'ll work with, and 3. a clear restatement of the instructions.';
const usrSuffixCoT = 'Please think step by step, then generate valid diagram code in a markdown block as instructed, and stop your response.';

export function bigDiagramPrompt(
  diagramType: DiagramType,
  diagramLanguage: DiagramLanguage,
  chatSystemPrompt: string,
  subject: string,
  customInstruction: string,
): { systemInstruction: string, messages: AixChatGenerate_TextMessages } {
  const { sys, usr } = diagramLanguage === 'mermaid' ? mermaidDiagramPrompt(diagramType) : plantumlDiagramPrompt(diagramType);
  return {
    systemInstruction: sys + '\n' + sysSuffixPM,
    messages: [
      { role: 'user', text: chatSystemPrompt },
      { role: 'model', text: subject },
      { role: 'user', text: (!customInstruction?.trim() ? usr : `${usr} Also consider the following instructions: ${customInstruction.trim()}`) + '\n' + usrSuffixCoT },
    ],
  };
}


================================================
FILE: src/modules/aifn/digrams/DiagramsModal.tsx
================================================
import * as React from 'react';

import { Box, Button, ButtonGroup, CircularProgress, Divider, FormControl, FormLabel, Grid, Input } from '@mui/joy';
import AccountTreeTwoToneIcon from '@mui/icons-material/AccountTreeTwoTone';
import ReplayIcon from '@mui/icons-material/Replay';
import StopOutlinedIcon from '@mui/icons-material/StopOutlined';
import TelegramIcon from '@mui/icons-material/Telegram';

import { AutoBlocksRenderer } from '~/modules/blocks/AutoBlocksRenderer';
import { aixChatGenerateText_Simple } from '~/modules/aix/client/aix.client';

import { AppBreadcrumbs } from '~/common/components/AppBreadcrumbs';
import { ChipToggleButton } from '~/common/components/ChipToggleButton';
import { ConversationsManager } from '~/common/chat-overlay/ConversationsManager';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { InlineError } from '~/common/components/InlineError';
import { adjustContentScaling } from '~/common/app.theme';
import { createDMessageTextContent, messageFragmentsReduceText } from '~/common/stores/chat/chat.message';
import { splitSystemMessageFromHistory } from '~/common/stores/chat/chat.conversation';
import { useFormRadio } from '~/common/components/forms/useFormRadio';
import { useFormRadioLlmType } from '~/common/components/forms/useFormRadioLlmType';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useModelDomain } from '~/common/stores/llms/hooks/useModelDomain';
import { useUIContentScaling } from '~/common/stores/store-ui';

import { bigDiagramPrompt, DiagramLanguage, diagramLanguages, DiagramType, diagramTypes } from './diagrams.data';


// configuration
const DIAGRAM_ACTOR_PREFIX = 'diagram';


// Used by the callers to setup the diagram session
export interface DiagramConfig {
  conversationId: string;
  messageId: string;
  text: string;
}


// This method fixes issues in the generation output. Very heuristic.
function hotFixDiagramCode(llmCode: string): string {
  // put the code in markdown, if missing
  if (llmCode.startsWith('@start'))
    llmCode = '```\n' + llmCode + '\n```';
  // fix generation mistakes
  return llmCode
    .replaceAll('@startumd', '@startuml') // haiku
    .replaceAll('@endutml', '@enduml') // haiku
    .replaceAll('@endmindmap\n@enduml', '@endmindmap') // gpt-3.5
    .replaceAll('@endmindmap\n@end', '@endmindmap') // gpt-3.5
    .replaceAll('```\n```', '```');
}


export function DiagramsModal(props: { config: DiagramConfig, onClose: () => void; }) {

  // state
  const [showOptions, setShowOptions] = React.useState(true);
  const [diagramCode, setDiagramCode] = React.useState<string | null>(null);
  const [diagramType, diagramComponent] = useFormRadio<DiagramType>('mind', diagramTypes, 'Diagram');
  const [diagramLanguage, languageComponent, setDiagramLanguage] = useFormRadio<DiagramLanguage>('mermaid', diagramLanguages, 'Syntax');
  const [customInstruction, setCustomInstruction] = React.useState<string>('');
  const [errorMessage, setErrorMessage] = React.useState<string | null>(null);
  const [abortController, setAbortController] = React.useState<AbortController | null>(null);

  // external state
  const isMobile = useIsMobile();
  const contentScaling = useUIContentScaling();
  const { domainModelId: runModelId } = useModelDomain('primaryChat');
  const [diagramLlm, llmComponent] = useFormRadioLlmType('Generator', runModelId ?? null, 'run');

  // derived state
  const { messageId, text: subject } = props.config;
  const diagramLlmId = diagramLlm?.id;

  // conversation handler (to view history and eventually append the message)
  const cHandler = ConversationsManager.getHandler(props.config.conversationId);

  /**
   * Core Diagram Generation function, with Streaming, custom prompt, etc.
   */
  const handleGenerateNew = React.useCallback(async () => {
    if (abortController)
      return;

    if (!diagramType || !diagramLanguage || !diagramLlm)
      return setErrorMessage(`Invalid diagram Type, Language, or Model (${diagramLlm}).`);

    setErrorMessage(null);

    let diagramCode: string = 'Loading...';
    setDiagramCode(diagramCode);

    const stepAbortController = new AbortController();
    setAbortController(stepAbortController);
    // cHandler.setAbortController(stepAbortController);

    const reChatHistory = cHandler.historyViewHeadOrThrow('diagrams-modal');
    const { chatSystemInstruction } = splitSystemMessageFromHistory(reChatHistory);
    if (!chatSystemInstruction)
      return setErrorMessage('No System instruction in this conversation');

    try {
      const { systemInstruction, messages } = bigDiagramPrompt(
        diagramType,
        diagramLanguage,
        messageFragmentsReduceText(chatSystemInstruction.fragments),
        subject,
        customInstruction,
      );
      await aixChatGenerateText_Simple(
        diagramLlm.id,
        systemInstruction,
        messages,
        'ai-diagram', messageId,
        { abortSignal: stepAbortController.signal },
        (text) => {
          !!text && setDiagramCode(diagramCode = text.trim());
        },
      );
    } catch (error: any) {
      setDiagramCode(null);
      setErrorMessage(error?.name !== 'AbortError' ? error?.message : 'Interrupted.');
    } finally {
      setDiagramCode(hotFixDiagramCode(diagramCode));
      setAbortController(null);
    }

  }, [abortController, cHandler, customInstruction, diagramLanguage, diagramLlm, diagramType, messageId, subject]);

  // [Effect] Auto-abort on unmount
  React.useEffect(() => {
    return () => {
      if (abortController) {
        abortController.abort();
        // cHandler.setAbortController(null);
        setAbortController(null);
      }
    };
  }, [abortController, cHandler]);


  // custom instruction

  const handleCustomInstructionKeyDown = React.useCallback((event: React.KeyboardEvent<HTMLInputElement>) => {
    if (event.key === 'Enter') {
      event.preventDefault();
      void handleGenerateNew();
    }
  }, [handleGenerateNew]);

  const handleCustomInstructionChange = React.useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    setCustomInstruction(event.target.value);
  }, []);


  // done

  const handleAppendMessageAndClose = React.useCallback(() => {
    if (!diagramCode)
      return setErrorMessage('Nothing to add to the conversation.');

    const diagramMessage = createDMessageTextContent('assistant', diagramCode); // [chat] append assistant:diagram
    // diagramMessage.purposeId = conversation.systemPurposeId;
    diagramMessage.generator = { mgt: 'named', name: DIAGRAM_ACTOR_PREFIX + (diagramLlmId ? `-${diagramLlmId}` : '') };

    cHandler.messageAppend(diagramMessage);
    props.onClose();
  }, [cHandler, diagramCode, diagramLlmId, props]);


  // [effect] Auto-switch language to match diagram type
  React.useEffect(() => {
    setDiagramLanguage(diagramType === 'mind' ? 'mermaid' : 'plantuml');
  }, [diagramType, setDiagramLanguage]);


  return (
    <GoodModal
      // titleStartDecorator={<AutoFixHighIcon sx={{ fontSize: 'md', mr: 1 }} />}
      title={<Box sx={{ flex: 1, display: 'flex', alignItems: 'center' }}>
        <AppBreadcrumbs size='md' rootTitle='Create'>
          <AppBreadcrumbs.Leaf><b>Diagram</b></AppBreadcrumbs.Leaf>
        </AppBreadcrumbs>
        <Box sx={{ ml: 1.25 }}>
          <ChipToggleButton
            text={showOptions ? 'show less' : 'show more'}
            onClick={() => setShowOptions(options => !options)}
          />
        </Box>
        {/*<IconButton*/}
        {/*  aria-label={showOptions ? 'Hide Options' : 'Show Options'}*/}
        {/*  size='sm'*/}
        {/*  onClick={() => setShowOptions(options => !options)}*/}
        {/*  sx={{ ml: 1, my: -0.5 }}*/}
        {/*>*/}
        {/*  {showOptions ? <ExpandMoreIcon /> : <ExpandLessIcon />}*/}
        {/*</IconButton>*/}
      </Box>}
      hideBottomClose
      open onClose={props.onClose}
      sx={{ maxWidth: { xs: '100vw', md: '95vw', lg: '88vw' } }}
    >

      {showOptions && (
        <Grid container spacing={2}>
          <Grid xs={12} md={6}>
            {diagramComponent}
          </Grid>
          {languageComponent && (
            <Grid xs={12} md={6}>
              {languageComponent}
            </Grid>
          )}
          <Grid xs={12} md={6}>
            {llmComponent}
          </Grid>
          <Grid xs={12} md={6}>
            <FormControl>
              <FormLabel>Customize</FormLabel>
              <Input
                title='Custom Instruction'
                placeholder='e.g. visualize as state'
                value={customInstruction}
                onKeyDown={handleCustomInstructionKeyDown}
                onChange={handleCustomInstructionChange}
                endDecorator={(abortController && customInstruction) ? <CircularProgress size='sm' /> : undefined}
              />
            </FormControl>
          </Grid>
        </Grid>
      )}

      {errorMessage && <InlineError error={errorMessage} />}

      {!showOptions && !!abortController && <Box sx={{ display: 'flex', justifyContent: 'center' }}>
        <CircularProgress size='lg' />
      </Box>}

      {!!diagramCode && (!abortController || showOptions) && (
        <Box sx={{
          backgroundColor: 'background.level2',
          marginX: 'calc(-1 * var(--Card-padding))',
          minHeight: 96,
          p: { xs: 1, md: 2 },
          overflow: 'hidden',
        }}>
          <AutoBlocksRenderer
            text={diagramCode}
            fromRole='assistant'
            contentScaling={adjustContentScaling(contentScaling, -1)}
            fitScreen={isMobile}
            isMobile={isMobile}
            blocksProcessor='diagram'
            codeRenderVariant='plain'
            textRenderVariant='text'
            // Edit is moved from the BlocksRenderer to the ContentPartText
            // onMessageEdit={(text) => setMessage({ ...message, text })}
          />
        </Box>
      )}

      {!diagramCode && <Divider />}

      {/* End */}
      <Box sx={{ mt: 'auto', display: 'flex', flexWrap: 'wrap', justifyContent: 'space-between' }}>

        {/* Add Message to Chat (once complete) */}
        <Button variant='soft' color='success' disabled={!diagramCode || !!abortController} endDecorator={<TelegramIcon />} onClick={handleAppendMessageAndClose}>
          Add To Chat
        </Button>

        {/* Button Group to toggle controls visibility - NOT enabled at the moment */}
        <ButtonGroup variant='solid' color='primary' sx={{ ml: 'auto' }}>
          {/*<IconButton*/}
          {/*  aria-label={showOptions ? 'Hide Options' : 'Show Options'}*/}
          {/*  onClick={() => setShowOptions(options => !options)}*/}
          {/*>*/}
          {/*  {showOptions ? <ExpandLessIcon /> : <ExpandMoreIcon />}*/}
          {/*</IconButton>*/}
          <Button
            variant={abortController ? 'soft' : 'solid'} color='primary'
            disabled={!diagramLlm}
            onClick={abortController ? () => {
              abortController.abort();
              // cHandler.setAbortController(null);
              setAbortController(null);
            } : handleGenerateNew}
            endDecorator={abortController ? <StopOutlinedIcon /> : diagramCode ? <ReplayIcon /> : <AccountTreeTwoToneIcon />}
            sx={{ minWidth: isMobile ? 160 : 220 }}
          >
            {abortController ? 'Stop' : diagramCode ? 'Regenerate' : 'Generate'}
          </Button>
        </ButtonGroup>

      </Box>

    </GoodModal>
  );
}


================================================
FILE: src/modules/aifn/flatten/flatten.data.ts
================================================
export type FlattenStyleType = 'brief' | 'deep' | 'exploration' | 'action';

interface FlattenProfile {
  type: FlattenStyleType;
  name: string;
  description: string;
  emoji: string;
  systemPrompt: string;
  userPrompt: string;
}

const systemPromptSuffix = 'Ensure the summary is impersonal and easy to read, write clear and separated paragraphs and use bullet points when possible.';

export const FLATTEN_PROFILES: FlattenProfile[] = [
  {
    type: 'brief',
    name: 'Brief',
    description: 'Concise overview with main points and actions',
    emoji: '⚡',
    systemPrompt: 'Create a brief and concise summary of the given conversation thread, focusing on the most important points, recent developments, and key actionable insights. Maintain enough context for future reference and exclude any references to the user or the assistant. ' + systemPromptSuffix,
    userPrompt: 'Please create a brief and concise summary for the conversation below, focusing on the most important points, recent developments, and key actionable insights, while maintaining enough context for future reference:',
  },
  {
    type: 'deep',
    name: 'Detailed',
    description: 'Detailed summary with synthesized ideas',
    emoji: '🔎',
    systemPrompt: 'Provide a comprehensive and detailed summary of the given conversation thread, capturing context and background, all recent and relevant points, preserving context, and synthesizing related ideas. Highlight actionable insights and stakeholder considerations, while excluding references to the user or the assistant. ' + systemPromptSuffix,
    userPrompt: 'Please provide a detailed summary of the conversation below, capturing context and background, all recent and relevant points, preserving context, synthesizing related ideas, highlighting actionable insights, and including any stakeholder considerations:',
  },
  {
    type: 'exploration',
    name: 'Open-ended',
    description: 'Open-ended summary for further discussion',
    emoji: '🌱',
    systemPrompt: 'Summarize the given conversation thread in a way that invites further exploration, encourages the addition of new perspectives, and identifies knowledge gaps or unanswered questions. Foster continued discussion on the topic while excluding references to the user or the assistant. ' + systemPromptSuffix,
    userPrompt: 'Please summarize the conversation below in a way that invites further exploration, encourages the addition of new perspectives, identifies knowledge gaps or unanswered questions, and fosters continued discussion on the topic:',
  },
  {
    type: 'action',
    name: 'Actionable',
    description: 'Summary with decisions, actions, and context',
    emoji: '📌',
    systemPrompt: 'Generate a summary of the given conversation thread that emphasizes decisions made, agreed-upon next steps, and action items from the discussion. Capture the context, key points, and any potential challenges or opportunities, while excluding references to the user or the assistant. ' + systemPromptSuffix,
    userPrompt: 'Please generate a summary of the conversation below that emphasizes decisions made, agreed-upon next steps, and action items from the discussion, while also capturing the context, key points, and any potential challenges or opportunities:',
  },
];


================================================
FILE: src/modules/aifn/flatten/FlattenerModal.tsx
================================================
import * as React from 'react';

import { Alert, Box, Button, CircularProgress, Divider, FormControl, FormLabel, IconButton, List, ListDivider, ListItem, ListItemButton, ListItemContent, ListItemDecorator, Typography } from '@mui/joy';
import ForkRightIcon from '@mui/icons-material/ForkRight';
import ReplayIcon from '@mui/icons-material/Replay';

import { useStreamChatText } from '~/modules/aifn/useStreamChatText';

import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { ConversationsManager } from '~/common/chat-overlay/ConversationsManager';
import { DConversationId } from '~/common/stores/chat/chat.conversation';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { InlineTextarea } from '~/common/components/InlineTextarea';
import { createDMessageTextContent, DMessage, messageFragmentsReduceText } from '~/common/stores/chat/chat.message';
import { useFormRadioLlmType } from '~/common/components/forms/useFormRadioLlmType';

import { FLATTEN_PROFILES, FlattenStyleType } from './flatten.data';
import { useModelDomain } from '~/common/stores/llms/hooks/useModelDomain';


function StylesList(props: { selectedStyle: FlattenStyleType | null, onSelectedStyle: (type: FlattenStyleType) => void }) {
  const readonly = !!props.selectedStyle;
  const items = FLATTEN_PROFILES.filter(style => !readonly || style.type === props.selectedStyle);
  return (
    <List sx={{ p: 0 }}>
      {items.map((style, idx) => (
        <React.Fragment key={style.type}>
          <ListItem>
            <ListItemButton onClick={() => !readonly && props.onSelectedStyle(style.type)}>
              <ListItemDecorator sx={{ fontSize: '16pt' }}>
                {style.emoji}
              </ListItemDecorator>
              <ListItemContent>
                <Typography>
                  {style.name}
                </Typography>
                <Typography level='body-sm'>
                  {style.description}
                </Typography>
              </ListItemContent>
            </ListItemButton>
          </ListItem>
          {idx < items.length - 1 && <ListDivider key={'div-' + style.type} inset='startContent' />}
        </React.Fragment>
      ))}
    </List>
  );
}

function FlatteningProgress(props: { llmLabel: string, partialText: string | null }) {
  return (
    <Box sx={{ mx: 'auto', display: 'flex', flexDirection: 'column', alignItems: 'center', gap: 2 }}>
      <CircularProgress />
      <Typography>
        {props.partialText?.length ? `${props.partialText.length} characters` : 'Compacting'}...
      </Typography>
      <Typography level='body-sm'>
        This may take up to a minute.
      </Typography>
      <Typography level='body-xs'>
        Using: {props.llmLabel}
      </Typography>
    </Box>
  );
}


function encodeConversationAsUserMessage(userPrompt: string, messages: Readonly<DMessage[]>): string {
  let encodedMessages = '';

  for (const message of messages) {
    if (message.role === 'system') continue;
    const author = message.role === 'user' ? 'User' : 'Assistant';
    const messageText = messageFragmentsReduceText(message.fragments);
    const text = messageText.replace(/\n/g, '\n\n');
    encodedMessages += `---${author}---\n${text}\n\n`;
  }

  return userPrompt ? userPrompt + '\n\n' + encodedMessages.trim() : encodedMessages.trim();
}


export function FlattenerModal(props: {
  conversationId: string | null,
  onConversationBranch: (conversationId: DConversationId, messageId: string | null, addSplitPane: boolean) => DConversationId | null,
  onClose: () => void,
}) {

  // state
  const [selectedStyle, setSelectedStyle] = React.useState<FlattenStyleType | null>(null);
  const [selectedLLMLabel, setSelectedLLMLabel] = React.useState<string | null>(null);
  const [confirmOverwrite, setConfirmOverwrite] = React.useState(false);
  const [errorMessage, setErrorMessage] = React.useState<string | null>(null);

  // external state
  const { domainModelId: runModelId } = useModelDomain('primaryChat');
  const [llm, llmComponent] = useFormRadioLlmType('Model', runModelId ?? null, 'util');
  const {
    isStreaming, text: flattenedText, partialText, streamError,
    startStreaming, setText, resetText,
  } = useStreamChatText();


  const handlePerformFlattening = React.useCallback(async (flattenStyle: FlattenStyleType) => {

    // validate config (or set error)
    if (!props.conversationId)
      return setErrorMessage('No conversation selected');
    const cHandler = ConversationsManager.getHandler(props.conversationId);
    const messages = !cHandler.isValid() ? [] : cHandler.historyViewHeadOrThrow('flattener-modal');
    if (!messages.length)
      return setErrorMessage('No messages in conversation');
    if (!llm)
      return setErrorMessage('No model selected');
    const flattenProfile = FLATTEN_PROFILES.find(s => s.type === flattenStyle);
    if (!flattenProfile)
      return setErrorMessage('No style selected');

    setSelectedStyle(flattenStyle);
    setSelectedLLMLabel(llm.label);
    setErrorMessage(null);

    // start (auto-abort previous and at unmount)
    await startStreaming(
      llm.id,
      flattenProfile.systemPrompt,
      [{ role: 'user', text: encodeConversationAsUserMessage(flattenProfile.userPrompt, messages) }],
      'ai-flattener',
      messages[0].id,
    );

  }, [llm, props.conversationId, startStreaming]);


  const handleErrorRetry = () => {
    setSelectedStyle(null);
    setErrorMessage(null);
    resetText();
  };


  const handleReplaceConversation = (branch: boolean) => {
    if (!props.conversationId || !selectedStyle || !flattenedText) return;
    let newConversationId: string | null = props.conversationId;
    if (branch)
      newConversationId = props.onConversationBranch(props.conversationId, null, false /* no pane from Flatter new */);
    if (newConversationId) {
      const ncHandler = ConversationsManager.getHandler(newConversationId);
      const newRootMessage = createDMessageTextContent('user', flattenedText);// [new chat] user:former chat summary
      ncHandler.historyClear();
      ncHandler.messageAppend(newRootMessage);
    }
    props.onClose();
  };

  const isSuccess = !!flattenedText;
  const isError = !!errorMessage || !!streamError;

  return (
    <GoodModal
      open={!!props.conversationId} dividers
      title={!selectedStyle ? 'Compact' : 'Compacting...'}
      onClose={props.onClose}
    >

      {/* Style selector */}
      <FormControl>
        <FormLabel>Style</FormLabel>
        <StylesList selectedStyle={selectedStyle} onSelectedStyle={handlePerformFlattening} />
      </FormControl>

      {/* Progress indicator */}
      {isStreaming && !!selectedLLMLabel && (
        <FlatteningProgress llmLabel={selectedLLMLabel} partialText={partialText} />
      )}

      {/* Group post-execution */}
      {(isSuccess || isError) && <Box sx={{ display: 'flex', flexDirection: 'column', gap: 2, flexGrow: 1 }}>

        {/* Possible Error */}
        {isError && <Box sx={{ display: 'flex', flexDirection: 'row', gap: 1, alignItems: 'center' }}>
          <Alert variant='soft' color='danger' sx={{ my: 1, flexGrow: 1 }}>
            {!!errorMessage && <Typography>{errorMessage}</Typography>}
            {!!streamError && <Typography>LLM issue: {streamError}</Typography>}
          </Alert>
          <IconButton variant='solid' color='danger' onClick={handleErrorRetry}>
            <ReplayIcon />
          </IconButton>
        </Box>}

        {/* Proceed*/}
        {isSuccess && !isError && (
          <Box sx={{ display: 'flex', flexDirection: 'row', gap: 1, alignItems: 'center' }}>
            <IconButton
              variant={isError ? 'solid' : 'plain'} color={isError ? 'danger' : 'primary'}
              onClick={handleErrorRetry}
            >
              <ReplayIcon />
            </IconButton>

            <Button variant='outlined' onClick={() => setConfirmOverwrite(true)} sx={{ ml: 'auto' }}>
              Replace Chat
            </Button>
            <Button variant='solid' onClick={() => handleReplaceConversation(true)} startDecorator={<ForkRightIcon />}>
              Branch
            </Button>
          </Box>
        )}

        {/* Review or Edit Text */}
        {isSuccess && <InlineTextarea initialText={flattenedText} selectAllOnFocus={false} onEdit={setText} />}

      </Box>}

      {!isSuccess && !isStreaming && !!llmComponent && <Divider />}

      {!isSuccess && !isStreaming && llmComponent}


      {/* [confirmation] Overwrite Conversation */}
      {confirmOverwrite && <ConfirmationModal
        open onClose={() => setConfirmOverwrite(false)} onPositive={() => handleReplaceConversation(false)}
        confirmationText='Are you sure you want to overwrite the conversation with the compacted text?'
        positiveActionText='Replace conversation'
      />}

    </GoodModal>
  );
}


================================================
FILE: src/modules/aifn/imagine/imaginePromptFromText.ts
================================================
import { aixChatGenerateText_Simple } from '~/modules/aix/client/aix.client';

import { getDomainModelIdOrThrow } from '~/common/stores/llms/store-llms';


const simpleImagineSystemPrompt =
  `As an AI image generation prompt writer, create precise, clear and simple prompts using adjectives, nouns, and artistic references.
Craft creative, coherent and descriptive captions to guide the text-to-image AI in generating articulate and surprising artwork.
Follow best practices such as beginning with 'A [photo of, drawing of, ...] {subject} ...', using objective words that are unambiguous to visualize.
Write a minimum of 20-30 words prompt and up to the size of the input.
Provide output a single image generation prompt and nothing else.`;

/**
 * Creates a caption for a drawing or photo given some description - used to elevate the quality of the imaging
 */
export async function imaginePromptFromTextOrThrow(messageText: string, contextRef: string): Promise<string> {

  // we used the fast LLM, but let's just converge to the chat LLM here
  const llmId = getDomainModelIdOrThrow(['fastUtil'], false, false, 'imagine-prompt-from-text');

  // truncate the messageText to full words and up to 1000 characters
  if (messageText.length > 1000) {
    const truncated = messageText.slice(0, 1000);
    const lastSpace = truncated.lastIndexOf(' ');
    if (lastSpace > 0) {
      messageText = truncated.slice(0, lastSpace);
    } else {
      messageText = truncated;
    }
  }

  // ensure we end with a punctuation
  if (!/[.!?]$/.test(messageText))
    messageText += '.';

  return (await aixChatGenerateText_Simple(
    llmId,
    simpleImagineSystemPrompt,
    'Write a minimum of 20-30 words prompt and up to the size of the input, based on the INPUT below.\n\nINPUT:\n' + messageText,
    'draw-expand-prompt', contextRef,
  )).trim();
}

// https://www.youtube.com/watch?v=XLG-qtZwxIw
/*const promptNext =
  'I want you to act as a prompt engineer. You will help me write prompts for an ai art generator.\n' +
  '\n' +
  'I will provide you with short content ideas and your job is to elaborate these into full, detailed, coherent prompts.\n' +
  '\n' +
  'Prompts involve describing the content and style of images in concise accurate language. It is useful to be explicit and use references to popular culture, artists and mediums. Your focus needs to be on nouns and adjectives. I will give you some example prompts for your reference. Please define the exact camera that should be used\n' +
  '\n' +
  'Here is a formula for you to use(content insert nouns here)(medium: insert artistic medium here)(style: insert references to genres, artists and popular culture here)(lighting, reference the lighting here)(colours reference color styles and palettes here)(composition: reference cameras, specific lenses, shot types and positional elements here)\n' +
  '\n' +
  'when giving a prompt remove the brackets, speak in natural language and be more specific, use precise, articulate language.';
*/


================================================
FILE: src/modules/aifn/react/react.ts
================================================
/*
 * porting of implementation from here: https://til.simonwillison.net/llms/python-react-pattern
 */

import { aixChatGenerateText_Simple } from '~/modules/aix/client/aix.client';
import { bareBonesPromptMixer } from '~/modules/persona/pmix/pmix';
import { callApiSearchGoogle } from '~/modules/google/search.client';
import { callBrowseFetchPageOrThrow } from '~/modules/browse/browse.client';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { frontendSideFetch } from '~/common/util/clientFetchers';


// prompt to implement the ReAct paradigm: https://arxiv.org/abs/2210.03629
const reActPrompt = (enableBrowse: boolean): string =>
  `You are a Question Answering AI with reasoning ability.
You will receive a Question from the User.
In order to answer any Question, you run in a loop of Thought, Action, PAUSE, Observation.
If from the Thought or Observation you can derive the answer to the Question, you MUST also output an "Answer: ", followed by the answer and the answer ONLY, without explanation of the steps used to arrive at the answer.
You will use "Thought: " to describe your thoughts about the question being asked.
You will use "Action: " to run one of the actions available to you - then return PAUSE. NEVER continue generating "Observation: " or "Answer: " in the same response that contains PAUSE.
"Observation" will be presented to you as the result of previous "Action".
If the "Observation" you received is not related to the question asked, or you cannot derive the answer from the observation, change the Action to be performed and try again.

ALWAYS assume today as {{Today}} when dealing with questions regarding dates.
Never mention your knowledge cutoff date

Your available "Actions" are:

google:
e.g. google: Django
Returns google custom search results
ALWAYS look up on google when the question is related to live events or factual information, such as sports, news, or weather.

` + (enableBrowse ? `loadUrl:
e.g. loadUrl: https://arxiv.org/abs/1706.03762
Opens the given URL and displays it

` : '') + /*`calculate:
e.g. calculate: 4 * 7 / 3
Runs a simple javascript calculation and returns the number, the input must be javascript 

` + */ `wikipedia:
e.g. wikipedia: Django
Returns a summary from searching Wikipedia

ONLY look things up on Wikipedia when explicitly asked to do so.

Example session:

Question: What is the capital of France?
Thought: I should look up France on Wikipedia
Action: wikipedia: France

You will be called again with the following, along with all previous messages between the User and You:

Observation: France is a country. The capital is Paris.

You then output:
Answer: The capital of France is Paris
`;


const actionRe = /^Action: (\w+): (.*)$/;


/**
 * State - Abstraction used for serialization, save/restore, inspection, debugging, rendering, etc.
 *
 * Keep this as minimal and flat as possible
 *   - initialize(): will create the state with initial values
 *   - loop() is a function that will update the state (in place)
 */
interface State {
  instruction: string;
  llm: string;
  messages: { role: 'user' | 'model', text: string }[];
  nextPrompt: string;
  lastObservation: string;
  result: string | undefined;
}

export class Agent {

  constructor(readonly contextRef: string, readonly abortSignal: AbortSignal) {
    // this is here only to memo `contextRef` for later use
  }

  // NOTE: this is here for demo, but the whole loop could be moved to the caller's event loop
  async reAct(question: string, llmId: DLLMId, maxTurns = 5, enableBrowse = false,
              appendLog: (...data: any[]) => void = console.log,
              showState: (state: object) => void): Promise<string> {
    let i = 0;
    // TODO: to initialize with previous chat messages to provide context.
    const S: State = this.initialize(`Question: ${question}`, llmId, enableBrowse, appendLog);
    showState(S);
    while (i < maxTurns && S.result === undefined) {
      i++;
      appendLog(`\n## Turn ${i}`);
      await this.step(S, llmId, appendLog);
      showState(S);
    }
    // return only the 'Answer: ' part of the result
    if (S.result) {
      const idx = S.result.indexOf('Answer: ');
      if (idx !== -1)
        return S.result.slice(idx + 8);
    }
    return S.result || 'No result';
  }

  initialize(question: string, assistantLLMId: DLLMId, enableBrowse: boolean, log: (...data: any[]) => void = console.log): State {
    const systemPrompt = bareBonesPromptMixer(reActPrompt(enableBrowse), assistantLLMId);
    log('## Prepare Buffer');
    log('→ instruction [' + 1 + ']: "' + systemPrompt.slice(0, 86).replaceAll('\n', ' ') + ' ..."');
    return {
      instruction: systemPrompt,
      messages: [],
      nextPrompt: question,
      lastObservation: '',
      result: undefined,
      llm: assistantLLMId,
    };
  }

  truncateStringAfterPause(input: string): string {
    const pauseKeyword = 'PAUSE';
    const pauseIndex = input.indexOf(pauseKeyword);

    if (pauseIndex === -1) {
      return input;
    }

    const endIndex = pauseIndex + pauseKeyword.length;
    return input.slice(0, endIndex);
  }

  async llmChat(S: State, prompt: string, llmId: DLLMId): Promise<string> {
    S.messages.push({ role: 'user', text: prompt });
    let response = await aixChatGenerateText_Simple(llmId, S.instruction, S.messages, 'chat-react-turn', this.contextRef, { abortSignal: this.abortSignal });
    // process response, strip out potential hallucinated response after PAUSE is detected
    response = this.truncateStringAfterPause(response);
    S.messages.push({ role: 'model', text: response });
    return response;
  }

  async step(S: State, llmId: DLLMId, log: (...data: any[]) => void = console.log) {
    log('→ ' + (S.lastObservation ? 'action' : 'user') + ' [' + (S.messages.length + 1) + ']: "' + S.nextPrompt + '"');
    const result = await this.llmChat(S, S.nextPrompt, llmId);
    log('← reAct [' + (S.messages.length) + ']: "' + result + '"');
    const actions = result
      .split('\n')
      .map((a: string) => actionRe.exec(a))
      .filter((a: RegExpExecArray | null) => a !== null) as RegExpExecArray[];
    if (actions.length > 0) {
      const action = actions[0][1];
      const actionInput = actions[0][2];
      if (!(action in knownActions)) {
        throw new Error(`Unknown action: ${action}: ${actionInput}`);
      }
      log(`⚡ __${action}__("${actionInput}") → Observation`);
      S.lastObservation = await knownActions[action](actionInput);
      S.nextPrompt = `Observation: ${S.lastObservation}`;
      // will be displayed in the next step
      // log('=>' + S.nextPrompt);
    } else {
      log('↙ done');
      // already displayed (← react)
      // log(`Result: ${result}`);
      S.result = result;
    }
  }
}


type ActionFunction = (input: string) => Promise<string>;

async function wikipedia(q: string): Promise<string> {
  const response = await frontendSideFetch(
    `https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch=${encodeURIComponent(q)}&format=json&origin=*`,
  );
  const data = await response.json();
  return data.query.search[0].snippet;
}

async function search(query: string): Promise<string> {
  try {
    const data = await callApiSearchGoogle(query, 10);
    return JSON.stringify(data);
  } catch (error: any) {
    console.error('Error fetching search results:', error);
    return 'An error occurred while searching the internet. Missing Google API Key? Google error: ' + (error?.message || error?.toString() || 'Unknown error');
  }
}

async function browse(url: string): Promise<string> {
  try {
    const page = await callBrowseFetchPageOrThrow(url);
    if (!page.content)
      return page.file ? 'A file download was requested, but we only support web pages: ' + page.url : 'No content received';
    const pageContent = page.content.markdown || page.content.text || page.content.html || '';
    return JSON.stringify(pageContent ? { text: pageContent } : { error: 'Issue reading the page' });
  } catch (error) {
    console.error('Error browsing:', (error as Error).message);
    return 'An error occurred while browsing to the URL. Missing WSS Key?';
  }
}

// Disable, as it allows for arbitrary code execution
// async function calculate(what: string): Promise<string> {
//   return String(eval(what));
// }

const knownActions: { [key: string]: ActionFunction } = {
  wikipedia: wikipedia,
  google: search,
  loadUrl: browse,
  // calculate: calculate, // DISABLED: security
};


================================================
FILE: src/modules/aifn/summarize/ContentReducer.tsx
================================================
// import * as React from 'react';
//
// import { Alert, Box, Button, CircularProgress, Divider, FormControl, Option, Select, Slider, Stack, Textarea, Typography } from '@mui/joy';
//
// import type { DLLM, DLLMId } from '~/common/stores/llms/llms.types';
//
// import { TokenBadgeMemo } from '../../../apps/chat/components/composer/tokens/TokenBadge';
//
// import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
// import { GoodModal } from '~/common/components/modals/GoodModal';
// import { Section } from '~/common/components/Section';
// import { lineHeightTextareaMd } from '~/common/app.theme';
// import { useDefaultLLMIDs, useNonHiddenLLMs } from '~/common/stores/llms/llms.hooks';
//
// import { summerizeToFitContextBudget } from './summerize';
//
//
// function TokenUsageAlert({ usedTokens, tokenLimit }: { usedTokens: number, tokenLimit: number }) {
//   const remainingTokens = tokenLimit - usedTokens;
//
//   const message = remainingTokens >= 1
//     ? `${usedTokens.toLocaleString()} reduced tokens and ${remainingTokens.toLocaleString()} tokens remaining.`
//     : `⚠️ These ${usedTokens.toLocaleString()} tokens go over budget by ${(-remainingTokens).toLocaleString()} tokens.`;
//
//   return <Alert variant='soft' color={remainingTokens >= 1 ? 'primary' : 'danger'} sx={{ mt: 1 }}>{message}</Alert>;
// }
//
//
// /**
//  * Dialog to compress a PDF
//  */
// export function ContentReducer(props: {
//   initialText: string,
//   initialTokens: number,
//   tokenLimit: number,
//   onClose: () => void,
//   onReducedText: (text: string) => void,
// }) {
//
//   // external state
//   const llms = useNonHiddenLLMs();
//   const { fastLLMId } = useDefaultLLMIDs();
//
//   // state
//   const [reducerModelId, setReducerModelId] = React.useState<DLLMId | null>(fastLLMId);
//   const [compressionLevel, setCompressionLevel] = React.useState(3);
//   const [reducedText, setReducedText] = React.useState('');
//   const [processing, setProcessing] = React.useState(false);
//
//   // derived state
//   // const reducedTokens = reducerModelId ? estimateTextTokens(reducedText, reducerModel, 'content reducer reduce') ?? 0 : 0;
//   const reducedTokens = 0; // DISABLED the line above, not ported to estimateTextTokens yet
//   const remainingTokens = props.tokenLimit - reducedTokens;
//
//
//   const handleReducerModelChange = (_event: any, value: DLLMId | null) => value && setReducerModelId(value);
//
//   const handleCompressionLevelChange = (_event: Event, newValue: number | number[]) => setCompressionLevel(newValue as number);
//
//   const handlePreviewClicked = async () => {
//     setProcessing(true);
//     if (reducerModelId) {
//       const reducedText = await summerizeToFitContextBudget(props.initialText, props.tokenLimit, reducerModelId);
//       setReducedText(reducedText);
//     }
//     setProcessing(false);
//   };
//
//   const handleUseReducedTextClicked = () => props.onReducedText(reducedText);
//
//   // DISABLED: user shall select the model and compression level first
//   // upon load, click the preview button
//   // React.useEffect(() => {
//   //   // noinspection JSIgnoredPromiseFromCall
//   //   handlePreviewClicked();
//   // }, [handlePreviewClicked]);
//
//   return (
//     <GoodModal
//       open title='Content Reducer (preview)'
//       onClose={props.onClose}
//       startButton={
//         <Button variant='solid' color={remainingTokens >= 1 ? 'primary' : 'danger'} disabled={!reducedText} onClick={handleUseReducedTextClicked}>
//           Use Reduced Text
//         </Button>
//       }>
//
//       <Divider />
//
//       {/* Settings */}
//       <Section>
//         <Stack direction='column' sx={{ gap: 2 }}>
//
//           <Typography level='body-sm'>
//             Input: <b>{props.initialTokens.toLocaleString()}</b> tokens · Limit: <b>{props.tokenLimit.toLocaleString()}</b> tokens
//             <br />
//             compression needed ≥ <b>{props.tokenLimit ? Math.round(100 * props.initialTokens / props.tokenLimit) : 0}</b> %
//           </Typography>
//
//           <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
//             <FormLabelStart title='Reducer model'
//                             description={llms.find(llm => llm.id === reducerModelId)?.description?.slice(0, 10) ?? '[select]'} />
//             {reducerModelId && <Select value={reducerModelId} onChange={handleReducerModelChange} sx={{ minWidth: 140 }}>
//               {llms.map((llm: DLLM) => (
//                 <Option key={llm.id} value={llm.id}>
//                   {llm.label} {llm.id === fastLLMId && '*'}
//                 </Option>
//               ))}
//             </Select>}
//           </FormControl>
//
//           <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
//             <FormLabelStart title='Compression'
//                             description={compressionLevel < 2 ? 'Low' : compressionLevel > 4 ? 'High' : 'Medium'} />
//             <Slider
//               color='neutral' disabled
//               min={1} max={5} defaultValue={3}
//               value={compressionLevel} onChange={handleCompressionLevelChange}
//               valueLabelDisplay='auto'
//               sx={{ py: 1, mt: 1.1 }}
//             />
//           </FormControl>
//
//           <Box sx={{ display: 'flex', justifyContent: 'flex-end' }}>
//             <Button variant='solid' color='primary' onClick={handlePreviewClicked} disabled={processing}>
//               Preview
//             </Button>
//           </Box>
//
//         </Stack>
//       </Section>
//
//
//       {/* Outputs */}
//       <Section title='Compressed content'>
//
//         {/* Readonly output and token counter */}
//         <Box sx={{ flexGrow: 1, position: 'relative', minWidth: '30vw' }}>
//
//           <Textarea
//             readOnly
//             variant='soft' autoFocus
//             minRows={4} maxRows={8}
//             value={reducedText}
//             sx={{
//               lineHeight: lineHeightTextareaMd,
//             }} />
//
//           <TokenBadgeMemo direct={reducedTokens} limit={props.tokenLimit} absoluteBottomRight />
//
//           {/* indicator we're processing */}
//           {processing && (
//             <Box sx={{ position: 'absolute', top: 0, left: 0, right: 0, bottom: 0, display: 'flex', alignItems: 'center', justifyContent: 'center', flexDirection: 'column' }}>
//               <CircularProgress />
//               <Typography level='body-sm' sx={{ mt: 1 }}>Reduction in progress.</Typography>
//               <Typography level='body-xs'>This can take a few minutes</Typography>
//             </Box>
//           )}
//
//         </Box>
//
//         {!!reducedTokens && <TokenUsageAlert usedTokens={reducedTokens} tokenLimit={props.tokenLimit} />}
//
//       </Section>
//
//     </GoodModal>
//   );
// }


================================================
FILE: src/modules/aifn/summarize/summerize.ts
================================================
// import { aixChatGenerateText_Simple } from '~/modules/aix/client/aix.client';
//
// import type { DLLMId } from '~/common/stores/llms/llms.types';
// import { findLLMOrThrow } from '~/common/stores/llms/store-llms';
//
//
// // prompt to be tried when doing recursive summerization.
// //const summerizationPrompt: string = `You are a semantic text compressor AI, with a low compression rate, but with high fidelity of the content, designed to efficiently process scientific and research papers extracted from PDF format by recognizing patterns, understanding context, and focusing on meaning. Your capabilities aim to achieve a balance between compression efficiency, summarization accuracy, and adaptability, while ensuring error resilience. Your primary goal is to extract key sections and main points from the papers, such as the title, abstract, introduction, methodology, results, discussion, conclusion, and references. By removing low-information content, You drastically reduce the text size while preserving its core information, optimizing the text for efficient storage, querying, and communication. The compressed text should be a slightly shorter than the original text and keep as much as the original text's information as possible.`;
//
// const cleanupPrompt: string = `Please remove any non-sensical portions and complete references from the following text extracts while preserving the original meaning and semantics of the text as much as possible. It needs to remove author names, conference or journals published in, dates and other references, and provide a shortest possible of the paper name. For instance, It needs to remove the text that looks like below, which are references to academic papers:
//
// [52] Alice Johnson, Bob Smith, Charlie Brown, David Lee, Emily Adams, Frank Williams, Grace Thompson, Harry Jackson, Irene Taylor, Jack Wilson, et al. ConvoAI: Conversational models for interactive applications. arXiv preprint arXiv:1234.56789 , 2022. [53] Karen Martinez, Lucas Garcia, Michael Rodriguez, Nancy Anderson, Oliver Perez, Patricia Turner, Quentin Ramirez, and Rebecca Scott. Contextual Transformers: Learning through adaptive gradients. arXiv preprint arXiv:2345.67890 , 2022.
//
// If the text contains no sensible information, such as file name, or complete gibberish text such as layout and table data, just return an empty string.
// `;
//
//
// function breakDownChunk(chunk: string, targetWordCount: number): string[] {
//   const words = chunk.split(' ');
//   const subChunks = [];
//
//   for (let i = 0; i < words.length; i += targetWordCount) {
//     subChunks.push(words.slice(i, i + targetWordCount).join(' '));
//   }
//
//   return subChunks;
// }
//
// export async function summerizeToFitContextBudget(text: string, targetWordCount: number, llmId: DLLMId): Promise<string> {
//   if (targetWordCount < 0) {
//     throw new Error('Target word count must be a non-negative number.');
//   }
//
//   // 1) Split the input text into chunks by new lines
//   const chunks = text.split('\n').filter(chunk => chunk.trim() !== '');
//
//   // 1.1) Break down chunks longer than targetWordCount into sub-chunks
//   const subChunks = chunks.flatMap(chunk => {
//     if (chunk.split(' ').length > targetWordCount) {
//       return breakDownChunk(chunk, targetWordCount);
//     } else {
//       return [chunk];
//     }
//   });
//
//   // 2) Remove non-sensical contents from each chunk
//   // using OpenAI API to remove non-sensical contents
//   const cleanedChunks = await Promise.all(subChunks.map(async chunk => {
//     // being conservative, as long as targetWordCount is not reached, we will keep calling the API
//     // print out the length of the chunk to be cleaned up
//     return await cleanUpContent(chunk, llmId, targetWordCount);
//   }));
//
//   console.log('************Finished cleaning up the chunks************');
//
//   // return if the targetWordCount already reached after step 2
//   if (cleanedChunks.reduce((acc, chunk) => acc + chunk.split(' ').length, 0) <= targetWordCount) {
//     console.log('enough content is removed, return the cleaned chunks');
//     return cleanedChunks.join('\n');
//   }
//
//   console.log('Simply removing non-sensical contents is not enough, proceed with recursive summerization');
//
//   // 3) Reduce the length of each chunk proportionally based on the text's length over the total length
//   const totalLength = cleanedChunks.reduce((acc, chunk) => acc + chunk.split(' ').length, 0);
//   const summarizedChunks = await Promise.all(cleanedChunks.map(async chunk => {
//     const chunkLength = chunk.split(' ').length;
//     const chunkTargetWordCount = Math.floor(targetWordCount * (chunkLength / totalLength));
//     return await recursiveSummerize(chunk, llmId, chunkTargetWordCount, 0); // Add the initial depth value
//   }));
//
//   // 4) Combine the summarized chunks and return
//   return summarizedChunks.join('\n');
// }
//
// async function cleanUpContent(chunk: string, llmId: DLLMId, _ignored_was_targetWordCount: number): Promise<string> {
//
//   // auto-adjust the tokens assuming the output would be half the size of the input (a bit dangerous,
//   // but at this stage we are not guaranteed the input nor output would fit)
//   const outputTokenShare = 1 / 3;
//   const { contextTokens } = findLLMOrThrow(llmId);
//   const autoResponseTokensSize = contextTokens ? Math.floor(contextTokens * outputTokenShare) : null;
//
//   return await aixChatGenerateText_Simple(
//     llmId,
//     cleanupPrompt,
//     chunk,
//     'chat-ai-summarize', 'DEV',
//   ).catch(() => '').then((response: string) => response.trim());
// }
//
// async function recursiveSummerize(text: string, llmId: DLLMId, targetWordCount: number, depth: number = 0): Promise<string> {
//   const words = text.split(' ');
//
//   if (words.length <= targetWordCount || words.length <= 1 || depth >= 2) {
//     return text;
//   }
//
//   const shortenedWords = await cleanUpContent(text, llmId, targetWordCount);
//
//   return await recursiveSummerize(shortenedWords, llmId, targetWordCount, depth + 1);
// }


================================================
FILE: src/modules/aix/AIX.README.md
================================================
[Binary file]


================================================
FILE: src/modules/aix/client/aix.client.chatGenerateRequest.ts
================================================
import { getImageAsset } from '~/common/stores/blob/dblobs-portability';

import { DLLM, LLM_IF_HOTFIX_NoStream, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_StripSys0, LLM_IF_HOTFIX_Sys0ToUsr0 } from '~/common/stores/llms/llms.types';
import { DMessage, DMessageRole, DMetaReferenceItem, MESSAGE_FLAG_AIX_SKIP, MESSAGE_FLAG_VND_ANT_CACHE_AUTO, MESSAGE_FLAG_VND_ANT_CACHE_USER, messageHasUserFlag } from '~/common/stores/chat/chat.message';
import { DMessageFragment, DMessageImageRefPart, isAttachmentFragment, isContentOrAttachmentFragment, isDocPart, isTextContentFragment, isToolResponseFunctionCallPart, isVoidThinkingFragment } from '~/common/stores/chat/chat.fragments';
import { Is } from '~/common/util/pwaUtils';
import { convert_Base64WithMimeType_To_Blob, convert_Blob_To_Base64 } from '~/common/util/blobUtils';
import { imageBlobResizeIfNeeded, LLMImageResizeMode } from '~/common/util/imageUtils';

// NOTE: pay particular attention to the "import type", as this is importing from the server-side Zod definitions
import type { AixAPIChatGenerate_Request, AixMessages_ModelMessage, AixMessages_ToolMessage, AixMessages_UserMessage, AixParts_InlineImagePart, AixParts_MetaCacheControl, AixParts_MetaInReferenceToPart, AixParts_ModelAuxPart } from '../server/api/aix.wiretypes';

// TODO: remove console messages to zero, or replace with throws or something


// configuration
const MODEL_IMAGE_RESCALE_MIMETYPE = !Is.Browser.Safari ? 'image/webp' : 'image/jpeg';
const MODEL_IMAGE_RESCALE_QUALITY = 0.90;
const IGNORE_CGR_NO_IMAGE_DEREFERENCE = true; // set to false to raise an exception, otherwise the CGR will continue skipping the part


// AIX <> Simple Text API helpers

/**
 * The simplest text-only inputs for aixChatGenerateContent_DMessage.
 */
export type AixChatGenerate_TextMessages = {
  role: 'user' | 'model';
  text: string;
}[];

export function aixCGR_FromSimpleText(systemInstruction: null | string, messages: AixChatGenerate_TextMessages): AixAPIChatGenerate_Request {
  return {
    systemMessage: systemInstruction === null ? null : aixCGR_SystemMessageText(systemInstruction),
    chatSequence: messages.map(m => {
      switch (m.role) {
        case 'user':
          return aixCGR_UserMessageText(m.text);
        case 'model':
          return aixCGR_ModelMessageText(m.text);
      }
    }),
  };
}

export function aixCGR_SystemMessageText(text: string) {
  return { parts: [aixCGRTextPart(text)] };
}

export function aixCGR_UserMessageText(text: string): AixMessages_UserMessage {
  return { role: 'user', parts: [aixCGRTextPart(text)] };
}

function aixCGR_ModelMessageText(text: string): AixMessages_ModelMessage {
  return { role: 'model', parts: [aixCGRTextPart(text)] };
}

function aixCGRTextPart(text: string) {
  return { pt: 'text' as const, text };
}


//
// AIX <> Chat Messages API helpers
//


export async function aixCGR_SystemMessage_FromDMessageOrThrow(
  systemInstruction: null | Pick<DMessage, 'fragments' | 'metadata' | 'userFlags'>,
): Promise<AixAPIChatGenerate_Request['systemMessage']> {

  // quick bypass for no message
  if (!systemInstruction)
    return null;

  // create the system instruction
  const sm: AixAPIChatGenerate_Request['systemMessage'] = {
    parts: [],
  };

  // process fragments of the system instruction
  for (const fragment of systemInstruction.fragments) {
    if (isTextContentFragment(fragment)) {
      sm.parts.push(fragment.part);
    } else if (isAttachmentFragment(fragment) && isDocPart(fragment.part)) {
      sm.parts.push(fragment.part);
    } else {
      if (process.env.NODE_ENV === 'development')
        throw new Error('[DEV] aixCGR_systemMessageFromInstruction: unexpected system fragment');
      console.warn('[DEV] aixCGR_systemMessageFromInstruction: unexpected system fragment:', fragment);
    }
  }

  // (on System message) handle the ant-cache-prompt user/auto flags
  const mHasAntCacheFlag = messageHasUserFlag(systemInstruction, MESSAGE_FLAG_VND_ANT_CACHE_AUTO) || messageHasUserFlag(systemInstruction, MESSAGE_FLAG_VND_ANT_CACHE_USER);
  if (mHasAntCacheFlag
    && sm.parts.length > 0 // added this to avoid settings a cache control on an empty system message
  )
    sm.parts.push(_clientCreateAixMetaCacheControlPart('anthropic-ephemeral'));

  return sm;
}


export async function aixCGR_ChatSequence_FromDMessagesOrThrow(
  messageSequenceWithoutSystem: Readonly<Pick<DMessage, 'role' | 'fragments' | 'metadata' | 'userFlags'>[]>, // Note: adding the "Pick" to show the low requirement from the DMessage type, as we'll move to simpler APIs soon
  // _assemblyMode: 'complete' = 'complete',
): Promise<AixAPIChatGenerate_Request['chatSequence']> {

  // if the user has marked messages for exclusion, we skip them
  messageSequenceWithoutSystem = messageSequenceWithoutSystem.filter(m => !messageHasUserFlag(m, MESSAGE_FLAG_AIX_SKIP));

  const lastAssistantMessageIndex = messageSequenceWithoutSystem.findLastIndex(m => m.role === 'assistant');

  // reduce history
  // NOTE: we used to have a "systemMessage" here, but we're moving to a more strict API with separate processing of it;
  //       - as such we now 'throw' if a system message is found (on dev mode, and just warn in production).
  //       - still, we keep the full reducer as a 'AixCGR_FromDmessages' type, in case we need more complex reductions in the future
  const cgr = await messageSequenceWithoutSystem.reduce(async (accPromise, m, _index): Promise<AixAPIChatGenerate_Request> => {
    const acc = await accPromise;

    // (on any User/Assistant messages) check the ant-cache-prompt user/auto flags
    const mHasAntCacheFlag = messageHasUserFlag(m, MESSAGE_FLAG_VND_ANT_CACHE_AUTO) || messageHasUserFlag(m, MESSAGE_FLAG_VND_ANT_CACHE_USER);

    // in the new version we handle all parts and only expect User and Assistant DMessages - as the System has been handled separately
    const dMessageRole: DMessageRole = m.role;
    if (dMessageRole === 'user') {

      const dMessageUserFragments = m.fragments;
      const aixChatMessageUser = await dMessageUserFragments.reduce(async (uMsgPromise, uFragment: DMessageFragment) => {

        const uMsg = await uMsgPromise;
        if (!isContentOrAttachmentFragment(uFragment) || uFragment.part.pt === '_pt_sentinel')
          return uMsg;

        switch (uFragment.part.pt) {
          case 'text':
            uMsg.parts.push(uFragment.part);
            break;

          case 'image_ref':
            // note, we don't resize, as the user image is resized following the user's preferences
            try {
              uMsg.parts.push(await aixConvertImageRefToInlineImageOrThrow(uFragment.part, false));
            } catch (error: any) {
              if (IGNORE_CGR_NO_IMAGE_DEREFERENCE) console.warn(`Image from the user missing in the chat generation request because: ${error?.message || error?.toString() || 'Unknown error'} - continuing without`);
              else throw error;
            }
            break;

          case 'doc':
            uMsg.parts.push(uFragment.part);
            break;

          // skipped (non-user)
          case 'error':
          case 'tool_invocation':
          case 'tool_response':
            console.warn('aixCGR_FromDMessages: unexpected Non-User fragment part type', (uFragment.part as any).pt);
            break;

          default:
            const _exhaustiveCheck: never = uFragment.part;
            console.warn('aixCGR_FromDMessages: unexpected User fragment part type', (uFragment.part as any).pt);
        }
        return uMsg;
      }, Promise.resolve({ role: 'user', parts: [] } as AixMessages_UserMessage));

      // handle in-reference-to metadata, adding a part right after the user text (or at the beginning)
      if (m.metadata?.inReferenceTo?.length) {
        // find the index of the last text part
        const lastTextPartIndex = aixChatMessageUser.parts.findLastIndex(p => p.pt === 'text');
        // insert the meta part after the last text part (and before the first attachment)
        aixChatMessageUser.parts.splice(lastTextPartIndex + 1, 0, _clientCreateAixMetaInReferenceToPart(m.metadata.inReferenceTo));
      }

      // (on User messages) handle the ant-cache-prompt user/auto flags
      if (mHasAntCacheFlag)
        aixChatMessageUser.parts.push(_clientCreateAixMetaCacheControlPart('anthropic-ephemeral'));

      acc.chatSequence.push(aixChatMessageUser);

    } else if (dMessageRole === 'assistant') {

      // Note: even tool invocations and responses were interleaved, we will bucket them in 1 model message and 1 tool message
      // FIXME: assumption that this is the right way of handling it, rather than interleaving many messages
      const modelMessage: AixMessages_ModelMessage = { role: 'model', parts: [] };
      const toolMessage: AixMessages_ToolMessage = { role: 'tool', parts: [] };

      for (const aFragment of m.fragments) {

        if ((!isContentOrAttachmentFragment(aFragment) && !isVoidThinkingFragment(aFragment)) || aFragment.part.pt === '_pt_sentinel')
          continue;

        switch (aFragment.part.pt) {

          case 'text':
          case 'tool_invocation':
            // Key place where the Aix Zod inferred types are compared to the Typescript defined DMessagePart* types
            // - in case of error, check that the types in `chat.fragments.ts` and `aix.wiretypes.ts` are in sync
            modelMessage.parts.push(aFragment.part);
            break;

          case 'ma':
            // https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#why-thinking-blocks-must-be-preserved
            // [Anthropic] special case: despite being Void, we send the DVoidModelAuxPart which has signed Thinking blocks and Redacted data,
            //             which may be instrumental for the model to execute tools-result follow-up actions/text.
            const isAntModelAux = aFragment.part.textSignature || aFragment.part.redactedData?.length;
            if (isAntModelAux)
              modelMessage.parts.push(aFragment.part as AixParts_ModelAuxPart /* NOTE: this is a forced cast from readonly string[] to string[], but not a big deal here*/);
            break;

          case 'doc':
            // TODO
            console.warn('aixCGR_FromDMessages: doc part from Assistant not implemented yet');
            // mMsg.parts.push(aFragment.part);
            break;

          case 'error':
            // Note: the llm will receive the extra '[ERROR]' text; this could be optimized to handle errors better
            modelMessage.parts.push({ pt: 'text', text: `[ERROR] ${aFragment.part.error}` });
            break;

          case 'image_ref':
            // TODO: rescale shall be dependent on the LLM here - and be careful with the high-res options, as they can
            //  be really space consuming. how to choose between high and low? global option?
            /**
             * FIXME for GEMINI IMAGE GENERATION
             * For now we upload ONLY THE LAST IMAGE as full quality, while all others are resized before transmission.
             */
            const isLastAssistantMessage = _index === lastAssistantMessageIndex;
            const resizeMode = isLastAssistantMessage ? false : 'openai-low-res';
            try {
              modelMessage.parts.push(await aixConvertImageRefToInlineImageOrThrow(aFragment.part, resizeMode));
            } catch (error: any) {
              if (IGNORE_CGR_NO_IMAGE_DEREFERENCE) console.warn(`Image from the assistant missing in the chat generation request because: ${error?.message || error?.toString() || 'Unknown error'} - continuing without`);
              else throw error;
            }
            break;

          case 'tool_response':
            // Valiation of DMessageToolResponsePart of response.type: 'function_call'
            // - NOTE: for now we make the large assumption that responses are JSON objects, not arrays, not strings
            // - This was done for Gemini as the response needs to be an object; however we will need to decide:
            // TODO: decide the responses policy: do we allow only objects? if not, then what's the rule to convert objects to Gemini's inputs?
            if (isToolResponseFunctionCallPart(aFragment.part)) {
              let resultObject: any;
              try {
                resultObject = JSON.parse(aFragment.part.response.result);
              } catch (error: any) {
                throw new Error('[AIX validation] expecting `tool_response` to be parseable');
              }
              if (!resultObject || typeof resultObject !== 'object')
                throw new Error('[AIX validation] expecting `tool_response` to be a JSON object');
              if (Array.isArray(resultObject))
                throw new Error('[AIX validation for Gemini] expecting `tool_response` to not be an array');
            }
            toolMessage.parts.push(aFragment.part);
            break;

          default:
            const _exhaustiveCheck: never = aFragment.part;
            console.warn('aixCGR_FromDMessages: unexpected Assistant fragment part', aFragment.part);
            break;
        }
      }

      const assistantMessages: (AixMessages_ModelMessage | AixMessages_ToolMessage)[] = [];
      if (modelMessage.parts.length > 0)
        assistantMessages.push(modelMessage);
      if (toolMessage.parts.length > 0)
        assistantMessages.push(toolMessage);

      // (on Assistant messages) handle the ant-cache-prompt user/auto flags, on the very last message
      if (mHasAntCacheFlag && assistantMessages.length > 0)
        assistantMessages[assistantMessages.length - 1].parts.push(_clientCreateAixMetaCacheControlPart('anthropic-ephemeral'));

      // Add the assistant messages to the chatSequence
      acc.chatSequence.push(...assistantMessages);

    } else {

      // DEV MODE: THROW ERROR, to aid the porting efforts
      if (process.env.NODE_ENV === 'development')
        throw new Error(`[DEV] aixCGR_FromDMessages: unexpected message role ${m.role}. Please PORT the caller to the systemIntruction API change.`);

      // TODO: implement mid-chat system messages if needed
      // NOTE: the API should just disallow 'system' messages in the middle of the chat
      console.warn('[DEV] aixCGR_FromDMessages: unexpected message role', m.role);

    }

    return acc;
  }, Promise.resolve({
    systemMessage: null,
    chatSequence: [],
  } as Pick<AixAPIChatGenerate_Request, 'systemMessage' | 'chatSequence'>) /* this is the key to the new version of this function which doesn't extract system messages anymore */);

  // as promised we only return this as we only built this, and not the full CGR.
  return cgr.chatSequence;
}


/// Parts that differ from DMessage*Part to AIX

export async function aixConvertImageRefToInlineImageOrThrow(imageRefPart: DMessageImageRefPart, resizeMode: LLMImageResizeMode | false): Promise<AixParts_InlineImagePart> {

  // validate
  const { dataRef } = imageRefPart;
  if (dataRef.reftype !== 'dblob' || !('dblobAssetId' in dataRef)) {
    console.warn('Image reference is not supported', imageRefPart);
    throw new Error('Image reference is not supported');
  }

  // get image asset
  const imageAsset = await getImageAsset(dataRef.dblobAssetId);
  if (!imageAsset) {
    console.warn('Image asset not found', imageRefPart);
    throw new Error('Image asset not found');
  }

  // base64 -> blob conversion
  let { mimeType, base64: base64Data } = imageAsset.data;

  // convert if requested (with intermediate Blob transformation)
  if (resizeMode) {
    try {
      // convert base64 -> Blob
      const imageBlob = await convert_Base64WithMimeType_To_Blob(base64Data, mimeType, 'aixConvertImageRefToInlineImage');
      // resize Blob
      const resizedOp = await imageBlobResizeIfNeeded(imageBlob, resizeMode, MODEL_IMAGE_RESCALE_MIMETYPE, MODEL_IMAGE_RESCALE_QUALITY);
      if (resizedOp) {
        // if resized, convert resized Blob back to base64
        base64Data = await convert_Blob_To_Base64(resizedOp.blob, 'aixConvertImageRefToInlineImage');
        mimeType = resizedOp.blob.type as any;
      }
    } catch (resizeError) {
      console.warn('[DEV] aixConvertImageRefToInlineImageOrThrow: Error resizing image:', resizeError);
      // continue without resizing, as this is not critical
    }
  }

  return _clientCreateAixInlineImagePart(base64Data, mimeType || dataRef.mimeType);
}

function _clientCreateAixInlineImagePart(base64: string, mimeType: string): AixParts_InlineImagePart {
  return { pt: 'inline_image', mimeType: (mimeType || 'image/png') as AixParts_InlineImagePart['mimeType'], base64 };
}

function _clientCreateAixMetaCacheControlPart(control: AixParts_MetaCacheControl['control']): AixParts_MetaCacheControl {
  return { pt: 'meta_cache_control', control: control };
}

function _clientCreateAixMetaInReferenceToPart(items: DMetaReferenceItem[]): AixParts_MetaInReferenceToPart {
  return { pt: 'meta_in_reference_to', referTo: items };
}


/// Client-side hotfixes


export function clientHotFixGenerateRequest_ApplyAll(llmInterfaces: DLLM['interfaces'], aixChatGenerate: AixAPIChatGenerate_Request, modelName: string): {
  shallDisableStreaming: boolean;
  workaroundsCount: number;
} {

  let workaroundsCount = 0;

  // Apply the remove-sys0 hot fix - at the time of doing it, Gemini Image Generation does not use the system instructions
  if (llmInterfaces.includes(LLM_IF_HOTFIX_StripSys0))
    workaroundsCount += clientHotFixGenerateRequest_StripSys0(aixChatGenerate);

  // Apply the cast-sys0-to-usr0 hot fix (e.g. o1-preview); however this is a late-stage emergency hotfix as we expect the caller to be aware of this logic
  if (llmInterfaces.includes(LLM_IF_HOTFIX_Sys0ToUsr0))
    workaroundsCount += clientHotFixGenerateRequest_Sys0ToUsr0(aixChatGenerate);

  // Apply the strip-images hot fix (e.g. o1-preview); however this is a late-stage emergency hotfix as we expect the caller to be aware of this logic
  if (llmInterfaces.includes(LLM_IF_HOTFIX_StripImages))
    workaroundsCount += clientHotFixGenerateRequest_StripImages(aixChatGenerate);

  // Disable streaming for select chat models that don't support it (e.g. o1-preview (old) and o1-2024-12-17)
  const shallDisableStreaming = llmInterfaces.includes(LLM_IF_HOTFIX_NoStream);

  if (workaroundsCount > 0)
    console.warn(`[DEV] Working around '${modelName}' model limitations: client-side applied ${workaroundsCount} workarounds`);

  return { shallDisableStreaming, workaroundsCount };

}


/**
 * Hot fix for models that don't support vision input and we need to perform the fix ahead of AIX send.
 *
 * Notes for the o1-2024-12-17 model:
 * - we don't strip inline images, as o1 supports them
 */
function clientHotFixGenerateRequest_StripImages(aixChatGenerate: AixAPIChatGenerate_Request): number {

  let workaroundsCount = 0;

  // Note: other conversions that would translate to system inside the AIX Dispatch will be handled there, as we have a
  // higher level representation here, where the roles are 'user', 'model', and 'tool'.

  // Remove any inline images from the entire chat sequence
  for (let i = 0; i < aixChatGenerate.chatSequence.length; i++) {
    const message = aixChatGenerate.chatSequence[i];

    // Iterate over message parts and remove inline images
    for (let j = message.parts.length - 1; j >= 0; j--) {
      if (message.parts[j].pt === 'inline_image') {
        workaroundsCount++;
        message.parts.splice(j, 1);
      }
    }
  }

  // Log the number of workarounds applied
  return workaroundsCount;

}

/**
 * Hot fix for models that don't want the system message - e.g. Gemini Image Generation (although this may change)
 */
function clientHotFixGenerateRequest_StripSys0(aixChatGenerate: AixAPIChatGenerate_Request): number {

  const workaroundsCount = aixChatGenerate.systemMessage?.parts?.length ? 1 : 0;
  aixChatGenerate.systemMessage = null;
  return workaroundsCount;

}


/**
 * Hot fix for handling system messages in models that do not support them, such as `o1-preview`.
 * -> Converts System to User messages for compatibility.
 *
 * Notes for the o1-2024-12-17 model:
 * - we don't cast the system to user, as the aix dispatcher is casting the 'system' message to 'developer'
 */
function clientHotFixGenerateRequest_Sys0ToUsr0(aixChatGenerate: AixAPIChatGenerate_Request): number {

  // Convert the main system message if it exists
  if (!aixChatGenerate.systemMessage)
    return 0;

  // Convert system message to user message
  const systemAsUser: AixMessages_UserMessage = {
    role: 'user',
    parts: aixChatGenerate.systemMessage.parts,
  };

  // Insert the converted system message at the beginning of the chat sequence (recreating the array to not alter the original)
  aixChatGenerate.chatSequence = [...aixChatGenerate.chatSequence];
  aixChatGenerate.chatSequence.unshift(systemAsUser);

  // Remove the original system message
  aixChatGenerate.systemMessage = null;

  // Log the workaround applied
  return 1;

}


================================================
FILE: src/modules/aix/client/aix.client.fromSimpleFunction.ts
================================================
import * as z from 'zod/v4';

import type { AixTools_FunctionCallDefinition } from '../server/api/aix.wiretypes';
import { DMessageContentFragment, DMessageToolInvocationPart, DMessageVoidFragment, isContentFragment } from '~/common/stores/chat/chat.fragments';


// configuration
const AIX_DEBUG_CLIENT_TOOLS = process.env.NODE_ENV === 'development';


export type AixClientFunctionCallToolDefinition = {
  name: string;
  description: string;
  /**
   * The input schema for the function call.
   * We only accept objects, not arrays - as downstream APIs have spotty implementation for non-object.
   * If the function does not take any inputs, use `Zod.object({})` or Zod.void().
   */
  inputSchema: z.ZodObject; // zod-4 object
}


/**
 * Create an Aix FunctionCall Tool Definition from a simple function definition.
 * @param functionCall
 */
export function aixFunctionCallTool(functionCall: AixClientFunctionCallToolDefinition): AixTools_FunctionCallDefinition {

  // convert a Zod schema to JSON Schema
  const { properties, required } = z.toJSONSchema(functionCall.inputSchema, {
    // config
    io: 'input', // avoids AdditionalProperties by looking at the Zod schema from the input perspective
    target: 'draft-2020-12', // (default) newest standard
    reused: 'inline', // (default) inline reused schemas

    // [DEV] makes sure we specify good tool definitions
    cycles: 'throw',
    unrepresentable: 'throw',
  });

  const takesNoInputs = !Object.keys(properties || {}).length;
  return {
    type: 'function_call',
    function_call: {
      name: functionCall.name,
      description: functionCall.description,
      ...(!takesNoInputs && {
        input_schema: {
          properties: properties as any, // FIXME: remove the 'as any' after the full migration to zod-4
          ...(!!required?.length && {
            required: required,
          }),
        },
      }),
    },
  };
}


/** Extract the function name from the Aix FunctionCall Tool Definition */
export function aixRequireSingleFunctionCallInvocation(fragments: (DMessageContentFragment | DMessageVoidFragment)[], expectedFunctionName: string, allowThinkPart: boolean, debugLabel: string): {
  invocation: Extract<DMessageToolInvocationPart['invocation'], { type: 'function_call' }>;
  argsObject: object;
} {

  if (!Array.isArray(fragments) || !(fragments.length >= 1)) {
    if (AIX_DEBUG_CLIENT_TOOLS)
      console.error(`[DEV] single-function-call (${debugLabel}): invalid fragments:`, { fragments });
    throw new Error('AIX: Unexpected response.');
  }

  const toolIdx = allowThinkPart ? fragments.length - 1 : 0;
  if (!isContentFragment(fragments[toolIdx]) || fragments[toolIdx].part.pt !== 'tool_invocation') {
    if (AIX_DEBUG_CLIENT_TOOLS)
      console.error(`[DEV] single-function-call (${debugLabel}): invalid fragment part:`, { part: fragments[toolIdx].part });

    // special case, if we have an error part, rethrow that message instead (better error message)
    if (fragments[toolIdx].part.pt === 'error')
      throw new Error('AIX: Error invoking function: ' + fragments[toolIdx].part.error);

    throw new Error('AIX: Missing function invocation.');
  }

  const { invocation } = fragments[toolIdx].part;

  if (invocation.type !== 'function_call' || invocation.name !== expectedFunctionName) {
    if (AIX_DEBUG_CLIENT_TOOLS)
      console.error(`[DEV] single-function-call (${debugLabel}): invalid invocation:`, { invocation });
    throw new Error('AIX: Expected a function call.');
  }

  if (!invocation.args) {
    if (AIX_DEBUG_CLIENT_TOOLS)
      console.error(`[DEV] single-function-call (${debugLabel}): missing invocation args:`, { invocation });
    throw new Error('AIX: Missing function arguments.');
  }

  try {
    return {
      invocation,
      argsObject: JSON.parse(invocation.args),
    };
  } catch (e) {
    if (process.env.NODE_ENV === 'development')
      console.error('[DEV] single-function-call: invalid invocation args:', invocation, 'for', debugLabel);
    throw new Error('AIX: Invalid function arguments.');
  }
}



================================================
FILE: src/modules/aix/client/aix.client.test.ts
================================================
// Future Testing Code
//
// const sampleFC: boolean = false; // aixModel.id.indexOf('models/gemini') === -1;
// const sampleCE: boolean = false; // aixModel.id.indexOf('models/gemini') !== -1;
// if (sampleFC) {
//   aixChatGenerate.tools = [
//     {
//       type: 'function_call',
//       function_call: {
//         name: 'get_capybara_info_given_name_and_color',
//         description: 'Get the info about capybaras. Call one each per name.',
//         input_schema: {
//           properties: {
//             'name': {
//               type: 'string',
//               description: 'The name of the capybara',
//               enum: ['enrico', 'coolio'],
//             },
//             'color': {
//               type: 'string',
//               description: 'The color of the capybara. Mandatory!!',
//             },
//             // 'story': {
//             //   type: 'string',
//             //   description: 'A fantastic story about the capybara. Please 10 characters maximum.',
//             // },
//           },
//           required: ['name'],
//         },
//       },
//     },
//   ];
// }
// if (sampleCE) {
//   aixChatGenerate.tools = [
//     {
//       type: 'code_execution',
//       variant: 'gemini_auto_inline',
//     },
//   ];
// }

/**
 * OpenAI-specific moderation check. This is a separate function, as it's not part of the
 * streaming chat generation, but it's a pre-check before we even start the streaming.
 *
 * @returns null if the message is safe, or a string with the user message if it's not safe
 */
/* NOTE: NOT PORTED TO AIX YET, this was the former "LLMS" implementation
async function _openAIModerationCheck(access: OpenAIAccessSchema, lastMessage: ... | null): Promise<string | null> {
  if (!lastMessage || lastMessage.role !== 'user')
    return null;

  try {
    const moderationResult = await apiAsync.llmOpenAI.moderation.mutate({
      access, text: lastMessage.content,
    });
    const issues = moderationResult.results.reduce((acc, result) => {
      if (result.flagged) {
        Object
          .entries(result.categories)
          .filter(([_, value]) => value)
          .forEach(([key, _]) => acc.add(key));
      }
      return acc;
    }, new Set<string>());

    // if there's any perceived violation, we stop here
    if (issues.size) {
      const categoriesText = [...issues].map(c => `\`${c}\``).join(', ');
      // do not proceed with the streaming request
      return `[Moderation] I an unable to provide a response to your query as it violated the following categories of the OpenAI usage policies: ${categoriesText}.\nFor further explanation please visit https://platform.openai.com/docs/guides/moderation/moderation`;
    }
  } catch (error: any) {
    // as the moderation check was requested, we cannot proceed in case of error
    return '[Issue] There was an error while checking for harmful content. ' + error?.toString();
  }

  // moderation check was successful
  return null;
}
*/


================================================
FILE: src/modules/aix/client/aix.client.ts
================================================
import { findServiceAccessOrThrow } from '~/modules/llms/vendors/vendor.helpers';

import type { DMessage, DMessageGenerator } from '~/common/stores/chat/chat.message';
import type { MaybePromise } from '~/common/types/useful.types';
import { DLLM, DLLMId, LLM_IF_HOTFIX_NoTemperature, LLM_IF_OAI_Responses, LLM_IF_Outputs_Audio, LLM_IF_Outputs_Image, LLM_IF_Outputs_NoText } from '~/common/stores/llms/llms.types';
import { apiStream } from '~/common/util/trpc.client';
import { DMetricsChatGenerate_Lg, metricsChatGenerateLgToMd, metricsComputeChatGenerateCostsMd } from '~/common/stores/metrics/metrics.chatgenerate';
import { DModelParameterValues, getAllModelParameterValues } from '~/common/stores/llms/llms.parameters';
import { createErrorContentFragment, DMessageContentFragment, DMessageErrorPart, DMessageVoidFragment, isContentFragment, isErrorPart } from '~/common/stores/chat/chat.fragments';
import { findLLMOrThrow } from '~/common/stores/llms/store-llms';
import { getLabsDevMode, getLabsDevNoStreaming } from '~/common/stores/store-ux-labs';
import { metricsStoreAddChatGenerate } from '~/common/stores/metrics/store-metrics';
import { presentErrorToHumans } from '~/common/util/errorUtils';
import { webGeolocationCached } from '~/common/util/webGeolocationUtils';

// NOTE: pay particular attention to the "import type", as this is importing from the server-side Zod definitions
import type { AixAPI_Access, AixAPI_Context_ChatGenerate, AixAPI_Model, AixAPIChatGenerate_Request } from '../server/api/aix.wiretypes';

import { aixCGR_ChatSequence_FromDMessagesOrThrow, aixCGR_FromSimpleText, aixCGR_SystemMessage_FromDMessageOrThrow, AixChatGenerate_TextMessages, clientHotFixGenerateRequest_ApplyAll } from './aix.client.chatGenerateRequest';
import { ContentReassembler } from './ContentReassembler';
import { withDecimator } from './withDecimator';


// configuration
export const DEBUG_PARTICLES = false;
const AIX_CLIENT_DEV_ASSERTS = process.env.NODE_ENV === 'development';


export function aixCreateChatGenerateContext(name: AixAPI_Context_ChatGenerate['name'], ref: string | '_DEV_'): AixAPI_Context_ChatGenerate {
  return { method: 'chat-generate', name, ref };
}

export function aixCreateModelFromLLMOptions(
  llmInterfaces: DLLM['interfaces'],
  llmOptions: DModelParameterValues,
  _llmOptionsOverride: Omit<DModelParameterValues, 'llmRef'> | undefined,
  debugLlmId: string,
): AixAPI_Model {

  // make sure llmRef is removed, if present in the override - excess of caution here
  const llmOptionsOverride = _llmOptionsOverride ? { ..._llmOptionsOverride } : undefined;
  if (llmOptionsOverride)
    delete (llmOptionsOverride as { llmRef?: any }).llmRef;

  // destructure input with the overrides
  const {
    llmRef, llmTemperature, llmResponseTokens, llmTopP, llmForceNoStream,
    llmVndAntThinkingBudget,
    llmVndGeminiShowThoughts, llmVndGeminiThinkingBudget,
    llmVndOaiReasoningEffort, llmVndOaiRestoreMarkdown, llmVndOaiWebSearchContext, llmVndOaiWebSearchGeolocation,
    llmVndPerplexityDateFilter, llmVndPerplexitySearchMode,
    llmVndXaiSearchMode, llmVndXaiSearchSources, llmVndXaiSearchDateFilter,
  } = {
    ...llmOptions,
    ...llmOptionsOverride,
  };

  // llmRef is absolutely required
  if (!llmRef)
    throw new Error(`AIX: Error in configuration for model ${debugLlmId} (missing ref, temperature): ${JSON.stringify(llmOptions)}`);

  // llmTemperature is highly recommended, so we display a note if it's missing
  if (llmTemperature === undefined)
    console.warn(`[DEV] AIX: Missing temperature for model ${debugLlmId}, using default.`);

  // Output modalities
  const acceptsOutputs: AixAPI_Model['acceptsOutputs'] = [];
  if (!llmInterfaces.includes(LLM_IF_Outputs_NoText)) acceptsOutputs.push('text');
  if (llmInterfaces.includes(LLM_IF_Outputs_Audio)) acceptsOutputs.push('audio');
  if (llmInterfaces.includes(LLM_IF_Outputs_Image)) acceptsOutputs.push('image');

  // Output APIs
  const llmVndOaiResponsesAPI = llmInterfaces.includes(LLM_IF_OAI_Responses);

  // Client-side late stage model HotFixes
  const hotfixOmitTemperature = llmInterfaces.includes(LLM_IF_HOTFIX_NoTemperature);

  // User Geolocation
  let userGeolocation: AixAPI_Model['userGeolocation'] | undefined;
  if (llmVndOaiWebSearchGeolocation) {
    const webGeolocation = webGeolocationCached();
    if (webGeolocation) {
      userGeolocation = {
        ...(webGeolocation.city ? { city: webGeolocation.city } : {}),
        ...(webGeolocation.country ? { country: webGeolocation.country } : {}),
        ...(webGeolocation.region ? { region: webGeolocation.region } : {}),
        timezone: webGeolocation.timezone,
      };
    } else
      console.log(`[DEV] AIX: Geolocation is requested for model ${debugLlmId}, but it's not available.`);
  }

  return {
    id: llmRef,
    acceptsOutputs: acceptsOutputs,
    ...(hotfixOmitTemperature ? { temperature: null } : llmTemperature !== undefined ? { temperature: llmTemperature } : {}),
    ...(llmResponseTokens /* null: similar to undefined, will omit the value */ ? { maxTokens: llmResponseTokens } : {}),
    ...(llmTopP !== undefined ? { topP: llmTopP } : {}),
    ...(llmForceNoStream ? { forceNoStream: llmForceNoStream } : {}),
    ...(llmVndAntThinkingBudget !== undefined ? { vndAntThinkingBudget: llmVndAntThinkingBudget } : {}),
    ...(llmVndGeminiShowThoughts ? { vndGeminiShowThoughts: llmVndGeminiShowThoughts } : {}),
    ...(llmVndGeminiThinkingBudget !== undefined ? { vndGeminiThinkingBudget: llmVndGeminiThinkingBudget } : {}),
    ...(llmVndOaiResponsesAPI ? { vndOaiResponsesAPI: true } : {}),
    ...(llmVndOaiReasoningEffort ? { vndOaiReasoningEffort: llmVndOaiReasoningEffort } : {}),
    ...(llmVndOaiRestoreMarkdown ? { vndOaiRestoreMarkdown: llmVndOaiRestoreMarkdown } : {}),
    ...(llmVndOaiWebSearchContext ? { vndOaiWebSearchContext: llmVndOaiWebSearchContext } : {}),
    ...(llmVndPerplexityDateFilter ? { vndPerplexityDateFilter: llmVndPerplexityDateFilter } : {}),
    ...(llmVndPerplexitySearchMode ? { vndPerplexitySearchMode: llmVndPerplexitySearchMode } : {}),
    ...(userGeolocation ? { userGeolocation } : {}),
    ...(llmVndXaiSearchMode ? { vndXaiSearchMode: llmVndXaiSearchMode } : {}),
    ...(llmVndXaiSearchSources ? { vndXaiSearchSources: llmVndXaiSearchSources } : {}),
    ...(llmVndXaiSearchDateFilter ? { vndXaiSearchDateFilter: llmVndXaiSearchDateFilter } : {}),
  };
}


/**
 * Accumulator for ChatGenerate output data, as it is being streamed.
 * The object is modified in-place from the lower layers and passed to the callback for efficiency.
 */
export interface AixChatGenerateContent_DMessage extends Pick<DMessage, 'fragments' | 'generator' | 'pendingIncomplete'> {
  fragments: (DMessageContentFragment | DMessageVoidFragment)[];
  generator: DMessageGenerator; // Extract<DMessageGenerator, { mgt: 'aix' }>;
  pendingIncomplete: boolean;
}

type StreamMessageStatus = {
  outcome: 'success' | 'aborted' | 'errored',
  lastDMessage: AixChatGenerateContent_DMessage,
  errorMessage?: string
};


interface AixClientOptions {
  abortSignal: AbortSignal | 'NON_ABORTABLE'; // 'NON_ABORTABLE' is a special case for non-abortable operations
  throttleParallelThreads?: number; // 0: disable, 1: default throttle (12Hz), 2+ reduce frequency with the square root
  llmOptionsOverride?: Omit<DModelParameterValues, 'llmRef'>; // overrides for the LLM options
}


/**
 * Level 3 Generation from an LLM Id + Chat History.
 */
export async function aixChatGenerateContent_DMessage_FromConversation(
  // chat-inputs -> Partial<DMessage> outputs
  llmId: DLLMId,
  chatSystemInstruction: null | Pick<DMessage, 'fragments' | 'metadata' | 'userFlags'>,
  chatHistoryWithoutSystemMessages: Readonly<DMessage[]>,
  // aix inputs
  aixContextName: AixAPI_Context_ChatGenerate['name'],
  aixContextRef: AixAPI_Context_ChatGenerate['ref'],
  // others
  clientOptions: AixClientOptions,
  onStreamingUpdate: (update: AixChatGenerateContent_DMessage, isDone: boolean) => MaybePromise<void>,
): Promise<StreamMessageStatus> {

  let errorMessage: string | undefined;

  let lastDMessage: AixChatGenerateContent_DMessage = {
    fragments: [],
    generator: {
      mgt: 'named',
      name: llmId as any,
    },
    pendingIncomplete: true,
  };

  try {

    // Aix ChatGenerate Request
    const aixChatContentGenerateRequest: AixAPIChatGenerate_Request = {
      systemMessage: await aixCGR_SystemMessage_FromDMessageOrThrow(chatSystemInstruction),
      chatSequence: await aixCGR_ChatSequence_FromDMessagesOrThrow(chatHistoryWithoutSystemMessages),
    };

    await aixChatGenerateContent_DMessage(
      llmId,
      aixChatContentGenerateRequest,
      aixCreateChatGenerateContext(aixContextName, aixContextRef),
      true,
      clientOptions,
      async (update: AixChatGenerateContent_DMessage, isDone: boolean) => {
        lastDMessage = update;
        await onStreamingUpdate(lastDMessage, isDone);
      },
    );

  } catch (error: any) {

    // this can only be a large, user-visible error, such as LLM not found
    console.warn('[DEV] aixChatGenerateContentStreaming error:', { error });

    errorMessage = error.message || (typeof error === 'string' ? error : 'Chat stopped.');
    lastDMessage.fragments.push(createErrorContentFragment(`Issue: ${errorMessage}`));
    lastDMessage.generator = {
      ...lastDMessage.generator,
      tokenStopReason: 'issue',
    };
    lastDMessage.pendingIncomplete = false;
  }

  // TODO: check something beyond this return status (as exceptions almost never happen here)
  // - e.g. the generator.aix may have error/token stop codes

  return {
    outcome: errorMessage ? 'errored' : lastDMessage.generator?.tokenStopReason === 'client-abort' ? 'aborted' : 'success',
    lastDMessage: lastDMessage,
    errorMessage: errorMessage || undefined,
  };
}


/**
 * Accumulator for the simple text-only API
 */
interface AixChatGenerateText_Simple {
  text: string | null;
  generator: DMessageGenerator;
  isDone: boolean;
}

/**
 * Level 2 - Simpler facade to text-only inputs and text-only outputs - and nothing else. Old-school V1-like API.
 *
 * NOTE: this is a simplified version of the `aixChatGenerateContent_DMessage` function, with text-only inputs and outputs.
 * NOTE: it's missing throttling; there's the chance we could abstract and consolidate the two functions, because they are
 * NOTE: very similar in structure, just the inputs/outputs (and verifiers and transformations) are different.
 *
 * Contract - expects ONLY text/text in/out (e.g. no Tools, no upstream Error messages, no Empty messages):
 * - User aborts are thrown as AbortError
 * - Other issues are thrown as Error
 * - Aix issues (network, model, etc.) that became error fragments are re-thrown as Error
 *
 * @throws AbortError if the user aborts the operation
 * @throws Error if there are issues with the LLM Output, the Upstream AI service, the Aix API
 */
export async function aixChatGenerateText_Simple(
  // [V1-like text-only API] text inputs -> string output
  llmId: DLLMId,
  systemInstruction: null | string,
  aixTextMessages: AixChatGenerate_TextMessages | string, // if string, it's a single user message - maximum simplicity
  // aix inputs
  aixContextName: AixAPI_Context_ChatGenerate['name'],
  aixContextRef: AixAPI_Context_ChatGenerate['ref'],
  // optional options
  clientOptions?: Partial<AixClientOptions>, // this makes the abortController optional
  // optional callback for streaming
  onTextStreamUpdate?: (text: string, isDone: boolean, generator: DMessageGenerator) => MaybePromise<void>,
): Promise<string> {

  // Aix Access
  const llm = findLLMOrThrow(llmId);
  const { transportAccess: aixAccess, vendor: llmVendor, serviceSettings: llmServiceSettings } = findServiceAccessOrThrow<object, AixAPI_Access>(llm.sId);

  // Aix Model
  const llmParameters = getAllModelParameterValues(llm.initialParameters, llm.userParameters);
  const aixModel = aixCreateModelFromLLMOptions(llm.interfaces, llmParameters, clientOptions?.llmOptionsOverride, llmId);

  // Aix ChatGenerate Request
  const aixChatGenerate = aixCGR_FromSimpleText(
    systemInstruction,
    typeof aixTextMessages === 'string' ? [{ role: 'user', text: aixTextMessages }] : aixTextMessages,
  );

  // Aix Context
  const aixContext = aixCreateChatGenerateContext(aixContextName, aixContextRef);

  // Aix Streaming - implicit if the callback is provided
  let aixStreaming = !!onTextStreamUpdate;


  // Client-side late stage model HotFixes
  const { shallDisableStreaming } = clientHotFixGenerateRequest_ApplyAll(llm.interfaces, aixChatGenerate, llmParameters.llmRef || llm.id);
  if (shallDisableStreaming)
    aixStreaming = false;


  // Variable to store the final text
  const state: AixChatGenerateText_Simple = {
    text: null,
    generator: {
      mgt: 'aix',
      name: llmId,
      aix: {
        vId: llm.vId,
        mId: llm.id,
      },
    },
    isDone: false,
  };

  // NO streaming initial notification - only notified past the first real characters
  // await onTextStreamUpdate?.(dText.text, false);

  // apply any vendor-specific rate limit
  await llmVendor.rateLimitChatGenerate?.(llm, llmServiceSettings);


  // Abort: if no signal is provided, we will create a dummy signal
  const abortSignal = (clientOptions?.abortSignal && clientOptions.abortSignal !== 'NON_ABORTABLE') ? clientOptions?.abortSignal
    : new AbortController().signal; // since this is a 'simple' low-stakes API, we can 'ignore' the abort signal and not enforce it with the caller


  // Aix Low-Level Chat Generation - does not throw, but may return an error in the final text
  const ll = await _aixChatGenerateContent_LL(
    aixAccess,
    aixModel,
    aixChatGenerate,
    aixContext,
    aixStreaming,
    abortSignal,
    clientOptions?.throttleParallelThreads ?? 0,
    !aixStreaming ? undefined : async (ll: AixChatGenerateContent_LL, _isDone: boolean /* we want to issue this, in case the next action is an exception */) => {
      _llToText(ll, state);
      if (onTextStreamUpdate && state.text !== null)
        await onTextStreamUpdate(state.text, false, state.generator);
    },
  );

  // Mark as complete
  state.isDone = true;

  // LLM Cost computation & Aggregations
  _llToText(ll, state);
  _updateGeneratorCostsInPlace(state.generator, llm, `aix_chatgenerate_text-${aixContextName}`);


  // re-throw the user-initiated abort, as the former function catches it
  if (abortSignal.aborted)
    throw new DOMException('Stopped.', 'AbortError');

  // throw if there was no text generated
  if (state.text === null)
    throw new Error('AIX: Empty text response.');

  // throw if there are error fragments
  const errorMessage = ll.fragments
    .filter(f => isContentFragment(f) && isErrorPart(f.part))
    .map(f => (f.part as DMessageErrorPart).error).join('\n');
  if (errorMessage)
    throw new Error('AIX: Error in response: ' + errorMessage);

  // final update
  await onTextStreamUpdate?.(state.text, true, state.generator);

  return state.text;
}

/**
 * Down-casts the LL to plain text, and updates the destination object.
 * - text -> text
 * - error -> inline error text: DO NOT THROW HERE, as the LL will catch it and add another error part with the same text
 * - tool -> throw: the LL will catch it and add the error text. However when done outside the LL (secondary usage) this will throw freely
 */
function _llToText(src: AixChatGenerateContent_LL, dest: AixChatGenerateText_Simple) {
  // copy over Generator's
  if (src.genMetricsLg)
    dest.generator.metrics = metricsChatGenerateLgToMd(src.genMetricsLg); // reduce the size to store in DMessage
  if (src.genModelName)
    dest.generator.name = src.genModelName;
  if (src.genTokenStopReason)
    dest.generator.tokenStopReason = src.genTokenStopReason;

  // transform the fragments to plain text
  if (src.fragments.length) {
    dest.text = '';
    for (let fragment of src.fragments) {
      switch (fragment.part.pt) {
        case 'text':
          dest.text += fragment.part.text;
          break;
        case 'error':
          dest.text += (dest.text ? '\n' : '') + fragment.part.error;
          break;
        case 'tool_invocation':
          throw new Error(`AIX: Unexpected tool invocation ${fragment.part.invocation?.type === 'function_call' ? fragment.part.invocation.name : fragment.part.id} in the Text response.`);
        case 'image_ref': // impossible
        case 'tool_response': // impossible - stopped at the invocation alrady
        case '_pt_sentinel': // impossible
          break;
      }
    }
  }
}


/**
 * Level 1 - Generates chat content using a specified LLM and ChatGenerateRequest (incl. Tools) and returns a DMessage-compatible object.
 *
 * Contract:
 * - empty fragments means no content yet, and no error
 * - pendingIncomplete is true until the final update & final object (or unless this throws)
 * - errors become Error fragments, and they can be dialect-sent, dispatch-excepts, client-read issues or even user aborts
 * @throws Error if the LLM is not found or other misconfigurations, but handles most other errors internally.
 *
 * Features:
 * - Throttling if requrested (decimates the requests based on the square root of the number parllel hints)
 * - computes the costs and metrics for the chat generation
 * - vendor-specific rate limit
 * - 'pendingIncomplete' logic
 * - 'o1-preview' hotfix for OpenAI models
 * - [NOT PORTED YET: checks for harmful content with the free 'moderation' API (OpenAI-only)]
 *
 * @param llmId - ID of the Language Model to use
 * @param aixChatGenerate - Multi-modal chat generation request specifics, including Tools and high-level metadata
 * @param aixContext - Information about how this chat generation is being used
 * @param aixStreaming - Whether to use streaming for generation
 * @param clientOptions - Client options for the operation
 * @param onStreamingUpdate - Optional callback for streaming updates
 *
 * @returns Promise<AixChatGenerateContent_DMessage> - The final DMessage-compatible object
 */
export async function aixChatGenerateContent_DMessage<TServiceSettings extends object = {}, TAccess extends AixAPI_Access = AixAPI_Access>(
  // llm Id input -> access & model
  llmId: DLLMId,
  // aix inputs
  aixChatGenerate: AixAPIChatGenerate_Request,
  aixContext: AixAPI_Context_ChatGenerate,
  aixStreaming: boolean,
  // others
  clientOptions: AixClientOptions,
  onStreamingUpdate?: (update: AixChatGenerateContent_DMessage, isDone: boolean) => MaybePromise<void>,
): Promise<AixChatGenerateContent_DMessage> {

  // Aix Access
  const llm = findLLMOrThrow(llmId);
  const { transportAccess: aixAccess, vendor: llmVendor, serviceSettings: llmServiceSettings } = findServiceAccessOrThrow<TServiceSettings, TAccess>(llm.sId);

  // Aix Model
  const llmParameters = getAllModelParameterValues(llm.initialParameters, llm.userParameters);
  const aixModel = aixCreateModelFromLLMOptions(llm.interfaces, llmParameters, clientOptions?.llmOptionsOverride, llmId);

  // Client-side late stage model HotFixes
  const { shallDisableStreaming } = clientHotFixGenerateRequest_ApplyAll(llm.interfaces, aixChatGenerate, llmParameters.llmRef || llm.id);
  if (shallDisableStreaming)
    aixStreaming = false;


  // [OpenAI-only] check for harmful content with the free 'moderation' API, if the user requests so
  // if (aixAccess.dialect === 'openai' && aixAccess.moderationCheck) {
  //   const moderationUpdate = await _openAIModerationCheck(aixAccess, messages.at(-1) ?? null);
  //   if (moderationUpdate)
  //     return onUpdate({ textSoFar: moderationUpdate, typing: false }, true);
  // }

  // Aix Low-Level Chat Generation
  const dMessage: AixChatGenerateContent_DMessage = {
    fragments: [],
    generator: {
      mgt: 'aix',
      name: llmId,
      aix: {
        vId: llm.vId,
        mId: llm.id, // NOTE: using llm.id instead of aixModel.id (the ref) so we can re-select them in the UI (Beam)
      },
      // metrics: undefined,
      // tokenStopReason: undefined,
    },
    pendingIncomplete: true,
  };

  // streaming initial notification, for UI updates
  await onStreamingUpdate?.(dMessage, false);

  // apply any vendor-specific rate limit
  await llmVendor.rateLimitChatGenerate?.(llm, llmServiceSettings);

  // Abort: if the operation is non-abortable, we can't use the AbortSignal
  if (clientOptions.abortSignal === 'NON_ABORTABLE') {
    // [DEV] UGLY: here we have non-abortable operations -- we silence the warning, but something may be done in the future
    // console.log('[DEV] Aix non-abortable operation:', { aixContext, llmId });
    clientOptions.abortSignal = new AbortController().signal;
  }

  // Aix Low-Level Chat Generation
  const llAccumulator = await _aixChatGenerateContent_LL(aixAccess, aixModel, aixChatGenerate, aixContext, aixStreaming, clientOptions.abortSignal, clientOptions.throttleParallelThreads ?? 0,
    async (ll: AixChatGenerateContent_LL, isDone: boolean) => {
      if (isDone) return; // optimization, as there aren't branches between here and the final update below
      if (onStreamingUpdate) {
        _llToDMessage(ll, dMessage);
        await onStreamingUpdate(dMessage, false);
      }
    },
  );

  // Mark as complete
  dMessage.pendingIncomplete = false;

  // LLM Cost computation & Aggregations
  _llToDMessage(llAccumulator, dMessage);
  _updateGeneratorCostsInPlace(dMessage.generator, llm, `aix_chatgenerate_content-${aixContext.name}`);

  // final update (could ignore and take the dMessage)
  await onStreamingUpdate?.(dMessage, true);

  return dMessage;
}

function _llToDMessage(src: AixChatGenerateContent_LL, dest: AixChatGenerateContent_DMessage) {
  if (src.fragments.length)
    dest.fragments = src.fragments; // Note: this gets replaced once, and then it's the same from that point on
  if (src.genMetricsLg)
    dest.generator.metrics = metricsChatGenerateLgToMd(src.genMetricsLg); // reduce the size to store in DMessage
  if (src.genModelName)
    dest.generator.name = src.genModelName;
  if (src.genTokenStopReason)
    dest.generator.tokenStopReason = src.genTokenStopReason;
}

function _updateGeneratorCostsInPlace(generator: DMessageGenerator, llm: DLLM, debugCostSource: string) {
  // Compute costs
  const llmParameters = getAllModelParameterValues(llm.initialParameters, llm.userParameters);
  const costs = metricsComputeChatGenerateCostsMd(generator.metrics, llm.pricing?.chat, llmParameters.llmRef || llm.id);
  if (!costs) {
    // FIXME: we shall warn that the costs are missing, as the only way to get pricing is through surfacing missing prices
    return;
  }

  // Add the costs to the generator.metrics object
  if (generator.metrics)
    Object.assign(generator.metrics, costs);

  // Run aggregations
  const m = generator.metrics;
  const inputTokens = (m?.TIn || 0) + (m?.TCacheRead || 0) + (m?.TCacheWrite || 0);
  const outputTokens = (m?.TOut || 0) /* + (m?.TOutR || 0) THIS IS A BREAKDOWN, IT'S ALREADY IN */;
  metricsStoreAddChatGenerate(costs, inputTokens, outputTokens, llm, debugCostSource);
}


/**
 * Accumulator for Lower Level ChatGenerate output data, as it is being streamed.
 * The object is modified in-place and passed to the callback for efficiency.
 */
export interface AixChatGenerateContent_LL {
  // source of truth for any caller
  // - empty array means no content yet, and no error
  fragments: (DMessageContentFragment | DMessageVoidFragment)[];

  // pieces of generator
  genMetricsLg?: DMetricsChatGenerate_Lg;
  genModelName?: string;
  genTokenStopReason?: DMessageGenerator['tokenStopReason'];
}

/**
 * Low-level-0 client-side ChatGenerateContent, with optional streaming.
 *
 * Contract:
 * - empty fragments means no content yet, and no error
 * - aixStreaming hints the source, but can be respected or not
 *   - onReassemblyUpdate is optional, you can ignore the updates and await the final result
 * - errors become Error fragments, and they can be dialect-sent, dispatch-excepts, client-read issues or even user aborts
 *   - DOES NOT THROW, but the final accumulator may contain error fragments
 * - empty fragments:
 *   - in the interim updates, means no content yet
 *   - in the final update, means there was no content received at all
 * - the output (accumulator) is always a complete object with all fragments
 *   - of the reasons, 'client-abort' and 'out-of-tokens' are the only ones that can be set without any fragments
 *
 * Inputs are all Aix_* objects:
 *
 * @param aixAccess abstracts the provider-specific configuration
 * @param aixModel selects and provides the model-specific configuration
 * @param aixChatGenerate the chat generation request specifics, which includes system instructions and various tools use:
 *    - tools include Function Declaration (for function calling), Gemini Code Execution, etc.
 *    - special parts include 'In Reference To' (a decorator of messages)
 *    - other special parts include the Anthropic Caching hints, on select message
 * @param aixContext specifies the scope of the caller, such as what's the high level objective of this call
 * @param aixStreaming requests the source to provide incremental updates
 * @param abortSignal allows the caller to stop the operation
 * @param throttleParallelThreads allows the caller to limit the number of parallel threads
 *
 * The output is an accumulator object with the fragments, and the generator
 * pieces (metrics, model name, token stop reason)
 *
 * @param onGenerateContentUpdate updated with the same accumulator at every step, and at the end (with isDone=true)
 * @returns the final accumulator object
 *
 */
async function _aixChatGenerateContent_LL(
  // aix inputs
  aixAccess: AixAPI_Access,
  aixModel: AixAPI_Model,
  aixChatGenerate: AixAPIChatGenerate_Request,
  aixContext: AixAPI_Context_ChatGenerate,
  aixStreaming: boolean,
  // others
  abortSignal: AbortSignal,
  throttleParallelThreads: number | undefined,
  // optional streaming callback: not fired until the first piece of content
  onGenerateContentUpdate?: (accumulator: AixChatGenerateContent_LL, isDone: boolean) => MaybePromise<void>,
): Promise<AixChatGenerateContent_LL> {

  // Aix Low-Level Chat Generation Accumulator
  const accumulator_LL: AixChatGenerateContent_LL = {
    fragments: [],
    /* rest start as undefined (missing in reality) */
  };

  const sendContentUpdate = !onGenerateContentUpdate ? undefined : withDecimator(throttleParallelThreads ?? 0, async () => {
    /**
     * We want the first update to have actual content.
     * However note that we won't be sending out the model name very fast this way,
     * but it's probably what we want because of the ParticleIndicators (VFX!)
     */
    if (!accumulator_LL.fragments.length)
      return;

    await onGenerateContentUpdate(accumulator_LL, false);
  });

  /**
   * DEBUG note: early we were filtering (aixContext.name === 'conversation'), but with the new debugger we don't
   * - 'sudo' mode is enabled by the UX Labs, and activates debug
   * - every request thereafter both sends back the Aix server-side dispatch packet, and appends all the particles received by the client side
   */
  const requestServerDebugging = getLabsDevMode();
  const debugContext = !requestServerDebugging ? undefined : { contextName: aixContext.name, contextRef: aixContext.ref };

  /**
   * Particles Reassembler.
   * - uses this accumulator
   * - calls a partial update callback with built-in decimation
   * - optional. forwards particles to the debugger
   * - abort will interrupt the fetch, and also the reassembly (for pieces coming still down the wire)
   */
  const reassembler = new ContentReassembler(
    accumulator_LL,
    sendContentUpdate,
    debugContext,
    abortSignal,
  );

  try {

    // tRPC Aix Chat Generation (streaming) API - inside the try block for deployment path errors
    const particles = await apiStream.aix.chatGenerateContent.mutate({
      access: aixAccess,
      model: aixModel,
      chatGenerate: aixChatGenerate,
      context: aixContext,
      streaming: getLabsDevNoStreaming() ? false : aixStreaming, // [DEV] disable streaming if set in the UX (testing)
      /**
       * Debugging/Profiling is only active when the "Debug Mode" is on.
       */
      ...(requestServerDebugging && {
        connectionOptions: {
          /**
           * Request a round-trip of the upstream AIX dispatch request.
           * Note: the server-side will only send the Body of the call on production builds, while headers will be shown on "Dev Builds".
           */
          debugDispatchRequest: true,
          /**
           * Request profiling data for a successful call (only streaming for now).
           * Note: the server-side won't enable profiling on non-production builds.
           */
          debugProfilePerformance: true,
        },
      }),
    }, {
      signal: abortSignal,
    });

    /**
     * Reassemble the particles by enqueueing them as they come in.
     * Processing is done asynchronously and in batches.
     *
     * Workaround: we cannot use Asyncs insie the 'for...await' loop, as we'd get
     * a 'closed connection' exception thrown when looping and a slow operation.
     */
    for await (const particle of particles)
      reassembler.enqueueWireParticle(particle);

    // synchronize any pending async tasks
    await reassembler.waitForWireComplete();

  } catch (error: any) {

    // something else broke, likely a User Abort, or an Aix server error (e.g. tRPC)
    const isUserAbort = abortSignal.aborted;
    const isErrorAbort = (error instanceof Error) && (error.name === 'AbortError' || (error.cause instanceof DOMException && error.cause.name === 'AbortError'));
    if (isUserAbort || isErrorAbort) {
      if (isUserAbort !== isErrorAbort)
        if (AIX_CLIENT_DEV_ASSERTS)
          console.error(`[DEV] Aix streaming AbortError mismatch (${isUserAbort}, ${isErrorAbort})`, { error: error });
      await reassembler.setClientAborted().catch(console.error /* never */);
    } else {
      // NOTE: this code path has also been almost replicated on `ContentReassembler.#processWireBacklog.catch() {...}`
      if (AIX_CLIENT_DEV_ASSERTS)
        console.error('[DEV] Aix streaming Error:', error);
      const showAsBold = !!accumulator_LL.fragments.length;
      const errorText = (presentErrorToHumans(error, showAsBold, true) || 'Unknown error').replace('[TRPCClientError]', '');
      await reassembler.setClientExcepted(`An unexpected error occurred: ${errorText} Please retry.`).catch(console.error /* never */);
    }

  }

  // and we're done
  reassembler.finalizeAccumulator();

  // final update (could ignore and take the final accumulator)
  await onGenerateContentUpdate?.(accumulator_LL, true /* Last message, done */);

  // return the final accumulated message
  return accumulator_LL;
}



================================================
FILE: src/modules/aix/client/ContentReassembler.ts
================================================
import { addDBImageAsset } from '~/common/stores/blob/dblobs-portability';

import type { MaybePromise } from '~/common/types/useful.types';
import { DEFAULT_ADRAFT_IMAGE_MIMETYPE } from '~/common/attachment-drafts/attachment.pipeline';
import { convert_Base64WithMimeType_To_Blob } from '~/common/util/blobUtils';
import { create_CodeExecutionInvocation_ContentFragment, create_CodeExecutionResponse_ContentFragment, create_FunctionCallInvocation_ContentFragment, createAnnotationsVoidFragment, createDMessageDataRefDBlob, createDVoidWebCitation, createErrorContentFragment, createImageContentFragment, createModelAuxVoidFragment, createTextContentFragment, DVoidModelAuxPart, isContentFragment, isModelAuxPart, isTextContentFragment, isVoidAnnotationsFragment, isVoidFragment } from '~/common/stores/chat/chat.fragments';
import { ellipsizeMiddle } from '~/common/util/textUtils';
import { imageBlobTransform } from '~/common/util/imageUtils';
import { metricsFinishChatGenerateLg, metricsPendChatGenerateLg } from '~/common/stores/metrics/metrics.chatgenerate';
import { presentErrorToHumans } from '~/common/util/errorUtils';

import type { AixWire_Particles } from '../server/api/aix.wiretypes';

import type { AixClientDebugger, AixFrameId } from './debugger/memstore-aix-client-debugger';
import { aixClientDebugger_completeFrame, aixClientDebugger_init, aixClientDebugger_recordParticleReceived, aixClientDebugger_setProfilerMeasurements, aixClientDebugger_setRequest } from './debugger/reassembler-debug';

import { AixChatGenerateContent_LL, DEBUG_PARTICLES } from './aix.client';


// configuration
const GENERATED_IMAGES_CONVERT_TO_COMPRESSED = true; // converts PNG to WebP or JPEG to save IndexedDB space
const GENERATED_IMAGES_COMPRESSION_QUALITY = 0.98;
const ELLIPSIZE_DEV_ISSUE_MESSAGES = 4096;
const MERGE_ISSUES_INTO_TEXT_PART_IF_OPEN = true;
const DEBUG_LOG_PROFILER_ON_CLIENT = false; // print Profiling particles when they come in, otherwise ignore them


/**
 * Reassembles the content fragments and more information from the Aix ChatGenerate Particles.
 */
export class ContentReassembler {

  // constructor
  private readonly debuggerFrameId: AixFrameId | null;

  // processing mechanics
  private readonly wireParticlesBacklog: AixWire_Particles.ChatGenerateOp[] = [];
  private isProcessing = false;
  private processingPromise = Promise.resolve();
  private hadErrorInWireReassembly = false;

  // reassembly state (plus the ext. accumulator)
  private currentTextFragmentIndex: number | null = null;


  constructor(
    private readonly accumulator: AixChatGenerateContent_LL,
    private readonly onAccumulatorUpdated?: () => MaybePromise<void>,
    enableDebugContext?: AixClientDebugger.Context,
    private readonly wireAbortSignal?: AbortSignal,
  ) {

    // [SUDO] Debugging the request, last-write-wins for the global (displayed in the UI)
    this.debuggerFrameId = !enableDebugContext ? null : aixClientDebugger_init(enableDebugContext);

  }


  // PUBLIC: wire queueing and processing

  enqueueWireParticle(op: AixWire_Particles.ChatGenerateOp): void {
    if (this.#wireIsAborted) {
      // console.log('Dropped particle due to abort:', op);
      return;
    }

    this.wireParticlesBacklog.push(op);

    // -> debugger, if active (ans skip the header particle)
    if (this.debuggerFrameId && !('cg' in op && op.cg === '_debugDispatchRequest'))
      aixClientDebugger_recordParticleReceived(this.debuggerFrameId, op, this.#wireIsAborted);

    this.#continueWireBacklogProcessing();
  }

  async waitForWireComplete(): Promise<void> {
    return this.processingPromise;
  }


  finalizeAccumulator(): void {

    // Perform all the latest operations
    const hasAborted = !!this.accumulator.genTokenStopReason;
    metricsFinishChatGenerateLg(this.accumulator.genMetricsLg, hasAborted);

    // [SUDO] Debugging, finalize the frame
    if (this.debuggerFrameId)
      aixClientDebugger_completeFrame(this.debuggerFrameId);

  }


  async setClientAborted(): Promise<void> {
    if (DEBUG_PARTICLES)
      console.log('-> aix.p: abort-client');

    // NOTE: this doens't go to the debugger anymore - as we only publish external particles to the debugger
    await this.#reassembleParticle({ cg: 'end', reason: 'abort-client', tokenStopReason: 'client-abort-signal' });
  }

  async setClientExcepted(errorAsText: string): Promise<void> {
    if (DEBUG_PARTICLES)
      console.log('-> aix.p: issue:', errorAsText);

    this.onCGIssue({ cg: 'issue', issueId: 'client-read', issueText: errorAsText });

    // NOTE: this doens't go to the debugger anymore - as we only publish external particles to the debugger
    await this.#reassembleParticle({ cg: 'end', reason: 'issue-rpc', tokenStopReason: 'cg-issue' });
  }


  // processing - internal

  #continueWireBacklogProcessing(): void {
    // require work
    if (this.isProcessing || !this.#hasBacklog) return;
    // require not external abort
    if (this.#wireIsAborted) return;
    // require not former processing errors
    if (this.hadErrorInWireReassembly) return;

    this.isProcessing = true;

    // schedule processing as a promise chain
    // Key insight: the .then modifies the processingPromise in place, so we can chain it
    this.processingPromise = this.processingPromise.then(() => this.#processWireBacklog());

    // NOTE: we let errors propagate to the caller, as here we're too down deep to handle them
    // .catch((error) => console.error('ContentReassembler: processing error', error));
  }

  async #processWireBacklog(): Promise<void> {
    // try...finally does not stop the error propagation (grat because we handle errors in the caller)
    // but allows this to continue processing the backlog
    try {

      while (this.#hasBacklog && !this.#wireIsAborted) {

        // worker function, may be sync or async
        const particle = this.wireParticlesBacklog.shift()!;
        await this.#reassembleParticle(particle);

        // signal all updates
        await this.onAccumulatorUpdated?.();

      }

    } catch (error) {

      // ERROR CATCHING - LIKE the _aixChatGenerateContent_LL which doesn't intercept this somehow
      // NEW METHOD: shows Error Fragments on both Reassembly and Callbacks errors
      //
      // - we don't stop processing anymore, as the source may still be pumping particles
      // - we insert an error fragment showing what happened - akin to how _aixChatGenerateContent_LL would do it
      //
      const showAsBold = !!this.accumulator.fragments.length;
      const errorText = (presentErrorToHumans(error, showAsBold, true) || 'Unknown error');
      this._appendReassemblyDevError(`An unexpected issue occurred: ${errorText} Please retry.`, true);
      await this.onAccumulatorUpdated?.()?.catch(console.error);

      // FORMER METHOD - the THROW wasn't caught by the caller

      // mark that we've encountered an error to prevent further scheduling
      // this.hadErrorInWireReassembly = true;
      // this.wireParticlesBacklog.length = 0; // empty the backlog

      // te-throw to propagate to outer catch blocks
      // throw error;

    } finally {

      // continue processing in case there's more to do
      this.isProcessing = false;
      this.#continueWireBacklogProcessing();

    }
  }

  get #hasBacklog(): boolean {
    return this.wireParticlesBacklog.length > 0;
  }

  get #wireIsAborted(): boolean {
    return !!this.wireAbortSignal?.aborted;
  }


  /// Particle Reassembly ///

  async #reassembleParticle(op: AixWire_Particles.ChatGenerateOp): Promise<void> {
    switch (true) {

      // TextParticleOp
      case 't' in op:
        this.onAppendText(op);
        break;

      // PartParticleOp
      case 'p' in op:
        switch (op.p) {
          case '❤':
            // ignore the heartbeats
            break;
          case 'tr_':
            this.onAppendReasoningText(op);
            break;
          case 'trs':
            this.onSetReasoningSignature(op);
            break;
          case 'trr_':
            this.onAddRedactedDataParcel(op);
            break;
          case 'fci':
            this.onStartFunctionCallInvocation(op);
            break;
          case '_fci':
            this.onAppendFunctionCallInvocationArgs(op);
            break;
          case 'cei':
            this.onAddCodeExecutionInvocation(op);
            break;
          case 'cer':
            this.onAddCodeExecutionResponse(op);
            break;
          case 'ia':
            await this.onAppendInlineAudio(op);
            break;
          case 'ii':
            await this.onAppendInlineImage(op);
            break;
          case 'urlc':
            this.onAddUrlCitation(op);
            break;
          default:
            // noinspection JSUnusedLocalSymbols
            const _exhaustiveCheck: never = op;
            this._appendReassemblyDevError(`unexpected PartParticleOp: ${JSON.stringify(op)}`);
        }
        break;

      // ChatControlOp
      case 'cg' in op:
        switch (op.cg) {
          case '_debugDispatchRequest':
            if (this.debuggerFrameId)
              aixClientDebugger_setRequest(this.debuggerFrameId, op.dispatchRequest);
            break;
          case '_debugProfiler':
            if (this.debuggerFrameId)
              aixClientDebugger_setProfilerMeasurements(this.debuggerFrameId, op.measurements);
            // Profiling particles will come in if the app is in "Debug Mode" + it's a Development build!
            // Additionally to show them on the console (rather than just in the debugger) set the
            // constant to `true`.
            if (DEBUG_LOG_PROFILER_ON_CLIENT) {
              console.warn('[AIX] chatGenerate profiler measurements:');
              console.table(op.measurements);
            }
            break;
          case 'end':
            this.onCGEnd(op);
            break;
          case 'issue':
            this.onCGIssue(op);
            break;
          case 'set-metrics':
            this.onMetrics(op);
            break;
          case 'set-model':
            this.onModelName(op);
            break;
          default:
            // noinspection JSUnusedLocalSymbols
            const _exhaustiveCheck: never = op;
            this._appendReassemblyDevError(`unexpected ChatGenerateOp: ${JSON.stringify(op)}`);
        }
        break;

      default:
        // noinspection JSUnusedLocalSymbols
        const _exhaustiveCheck: never = op;
        this._appendReassemblyDevError(`unexpected particle: ${JSON.stringify(op)}`);
    }
  }


  /// Fragments Reassembly ///

  // Appends the text to the open text part, or creates a new one if none is open
  private onAppendText(particle: AixWire_Particles.TextParticleOp): void {

    // add to existing TextContentFragment
    const currentTextFragment = this.currentTextFragmentIndex !== null ? this.accumulator.fragments[this.currentTextFragmentIndex] : null;
    if (currentTextFragment && isTextContentFragment(currentTextFragment)) {
      currentTextFragment.part.text += particle.t;
      return;
    }

    // new TextContentFragment
    const newTextFragment = createTextContentFragment(particle.t);
    this.accumulator.fragments.push(newTextFragment);
    this.currentTextFragmentIndex = this.accumulator.fragments.length - 1;

  }

  private onAppendReasoningText({ _t /*, weak*/ }: Extract<AixWire_Particles.PartParticleOp, { p: 'tr_' }>): void {
    // Break text accumulation
    this.currentTextFragmentIndex = null;

    // append to existing ModelAuxVoidFragment if possible
    const currentFragment = this.accumulator.fragments[this.accumulator.fragments.length - 1];
    if (currentFragment && isVoidFragment(currentFragment) && isModelAuxPart(currentFragment.part)) {
      const appendedPart = { ...currentFragment.part, aText: (currentFragment.part.aText || '') + _t } satisfies DVoidModelAuxPart;
      this.accumulator.fragments[this.accumulator.fragments.length - 1] = { ...currentFragment, part: appendedPart };
      return;
    }

    // new ModelAuxVoidFragment
    const fragment = createModelAuxVoidFragment('reasoning', _t);
    this.accumulator.fragments.push(fragment);
  }

  private onSetReasoningSignature({ signature }: Extract<AixWire_Particles.PartParticleOp, { p: 'trs' }>): void {

    // set to existing ModelAuxVoidFragment if possible
    const currentFragment = this.accumulator.fragments[this.accumulator.fragments.length - 1];
    if (currentFragment && isVoidFragment(currentFragment) && isModelAuxPart(currentFragment.part)) {
      const setPart = { ...currentFragment.part, textSignature: signature } satisfies DVoidModelAuxPart;
      this.accumulator.fragments[this.accumulator.fragments.length - 1] = { ...currentFragment, part: setPart };
      return;
    }

    // if for some reason there's no ModelAuxVoidFragment, create one
    const fragment = createModelAuxVoidFragment('reasoning', '', signature);
    this.accumulator.fragments.push(fragment);
  }

  private onAddRedactedDataParcel({ _data }: Extract<AixWire_Particles.PartParticleOp, { p: 'trr_' }>): void {

    // add to existing ModelAuxVoidFragment if possible
    const currentFragment = this.accumulator.fragments[this.accumulator.fragments.length - 1];
    if (currentFragment && isVoidFragment(currentFragment) && isModelAuxPart(currentFragment.part)) {
      const appendedPart = { ...currentFragment.part, redactedData: [...(currentFragment.part.redactedData || []), _data] } satisfies DVoidModelAuxPart;
      this.accumulator.fragments[this.accumulator.fragments.length - 1] = { ...currentFragment, part: appendedPart };
      return;
    }

    // create a new ModelAuxVoidFragment for redacted thinking
    const fragment = createModelAuxVoidFragment('reasoning', '', undefined, [_data]);
    this.accumulator.fragments.push(fragment);
  }


  private onStartFunctionCallInvocation(fci: Extract<AixWire_Particles.PartParticleOp, { p: 'fci' }>): void {
    // Break text accumulation
    this.currentTextFragmentIndex = null;
    // Start FC accumulation
    const fragment = create_FunctionCallInvocation_ContentFragment(
      fci.id,
      fci.name,
      fci.i_args || '', // if i_args is undefined, use an empty string, which means 'no args' in DParticle/AixTools (for now at least)
    );
    // TODO: add _description from the Spec
    // TODO: add _args_schema from the Spec
    this.accumulator.fragments.push(fragment);
  }

  private onAppendFunctionCallInvocationArgs(_fci: Extract<AixWire_Particles.PartParticleOp, { p: '_fci' }>): void {
    const fragment = this.accumulator.fragments[this.accumulator.fragments.length - 1];
    if (fragment && isContentFragment(fragment) && fragment.part.pt === 'tool_invocation' && fragment.part.invocation.type === 'function_call') {
      const updatedPart = {
        ...fragment.part,
        invocation: {
          ...fragment.part.invocation,
          args: (fragment.part.invocation.args || '') + _fci._args,
        },
      };
      this.accumulator.fragments[this.accumulator.fragments.length - 1] = { ...fragment, part: updatedPart };
    } else
      this._appendReassemblyDevError('unexpected _fc particle without a preceding function-call');
  }

  private onAddCodeExecutionInvocation(cei: Extract<AixWire_Particles.PartParticleOp, { p: 'cei' }>): void {
    this.accumulator.fragments.push(create_CodeExecutionInvocation_ContentFragment(cei.id, cei.language, cei.code, cei.author));
    this.currentTextFragmentIndex = null;
  }

  private onAddCodeExecutionResponse(cer: Extract<AixWire_Particles.PartParticleOp, { p: 'cer' }>): void {
    this.accumulator.fragments.push(create_CodeExecutionResponse_ContentFragment(cer.id, cer.error, cer.result, cer.executor, cer.environment));
    this.currentTextFragmentIndex = null;
  }

  private async onAppendInlineAudio(particle: Extract<AixWire_Particles.PartParticleOp, { p: 'ia' }>): Promise<void> {

    // Break text accumulation, as we have a full audio part in the middle
    this.currentTextFragmentIndex = null;

    const { mimeType, a_b64: base64Data, label, generator, durationMs } = particle;
    const safeLabel = label || 'Generated Audio';

    try {

      // create blob and play audio - this will throw on malformed data
      const audioBlob = await convert_Base64WithMimeType_To_Blob(base64Data, mimeType, 'ContentReassembler.onAppendInlineAudio');
      const audioUrl = URL.createObjectURL(audioBlob);

      // Play the audio
      const audio = new Audio(audioUrl);

      // Clean up when audio ends or errors
      const cleanup = () => {
        URL.revokeObjectURL(audioUrl);
        audio.removeEventListener('ended', cleanup);
        audio.removeEventListener('error', cleanup);
        audio.src = ''; // Release audio element reference
      };
      audio.addEventListener('ended', cleanup);
      audio.addEventListener('error', cleanup);

      // Play and handle immediate errors
      audio.play().catch(error => {
        console.warn('[Audio] Failed to play generated audio:', error);
        cleanup();
      });

      // TEMP: show a label instead of adding the model part
      this.accumulator.fragments.push(createTextContentFragment(`Playing ${safeLabel}${durationMs ? ` (${Math.round(durationMs / 10) / 100}s)` : ''}`));

      // Add the audio to the DBlobs DB
      // const dblobAssetId = await addDBAudioAsset('global', 'app-chat', {
      //   label: safeLabel,
      //   data: {
      //     mimeType: mimeType as any,
      //     base64: base64Data,
      //   },
      //   origin: {
      //     ot: 'generated',
      //     source: 'ai-text-to-speech',
      //     generatorName: generator ?? '',
      //     prompt: '', // Audio doesn't have a prompt in this context
      //     parameters: {},
      //     generatedAt: new Date().toISOString(),
      //   },
      //   metadata: {
      //     durationMs: durationMs || 0,
      //     // Other audio metadata could be added here
      //   },
      // });

      // Create DMessage data reference for the audio
      // const bytesSizeApprox = Math.ceil((base64Data.length * 3) / 4);
      // const audioAssetDataRef = createDMessageDataRefDBlob(
      //   dblobAssetId,
      //   particle.mimeType,
      //   bytesSizeApprox,
      // );

      // Create the DMessageContentFragment for audio
      // const audioContentFragment = createAudioContentFragment(
      //   audioAssetDataRef,
      //   safeLabel,
      //   durationMs,
      // );

      // this.accumulator.fragments.push(audioContentFragment);

    } catch (error: any) {
      console.warn('[DEV] Failed to add inline audio to DBlobs:', { label: safeLabel, error, mimeType, size: base64Data.length });
      // Add an error fragment instead
      this.accumulator.fragments.push(createErrorContentFragment(`Failed to process audio: ${error?.message || 'Unknown error'}`));
    }
  }

  private async onAppendInlineImage(particle: Extract<AixWire_Particles.PartParticleOp, { p: 'ii' }>): Promise<void> {

    // Break text accumulation, as we have a full image part in the middle
    this.currentTextFragmentIndex = null;

    let { i_b64: inputBase64, mimeType: inputType, label, generator, prompt } = particle;
    const safeLabel = label || 'Generated Image';

    try {

      // base64 -> blob conversion
      let inputImage = await convert_Base64WithMimeType_To_Blob(inputBase64, inputType, 'ContentReassembler.onAppendInlineImage');

      // perform resize/type conversion if desired, and find the image dimensions
      const shallConvert = GENERATED_IMAGES_CONVERT_TO_COMPRESSED && inputType === 'image/png';
      const { blob: imageBlob, height: imageHeight, width: imageWidth } = await imageBlobTransform(inputImage, {
        convertToMimeType: shallConvert ? DEFAULT_ADRAFT_IMAGE_MIMETYPE : undefined,
        convertToLossyQuality: GENERATED_IMAGES_COMPRESSION_QUALITY,
        throwOnTypeConversionError: true,
        debugConversionLabel: `ContentReassembler(ii)`,
      });

      // add the image to the DBlobs DB
      const dblobAssetId = await addDBImageAsset('app-chat', imageBlob, {
        label: safeLabel,
        metadata: {
          width: imageWidth,
          height: imageHeight,
          // description: '',
        },
        origin: { // Generation originated
          ot: 'generated',
          source: 'ai-text-to-image',
          generatorName: generator ?? '',
          prompt: prompt ?? '',
          parameters: {}, // ?
          generatedAt: new Date().toISOString(),
        },
      });

      // create the DMessage _Content_ Fragment (not attachment), as this comes from the assistant
      // so this is akin to the t2i-generated images
      const imageContentFragment = createImageContentFragment(
        createDMessageDataRefDBlob( // Data Reference {} for the image
          dblobAssetId,
          imageBlob.type,
          imageBlob.size,
        ),
        safeLabel,
        imageWidth || undefined,
        imageHeight || undefined,
      );

      this.accumulator.fragments.push(imageContentFragment);
    } catch (error: any) {
      console.warn('[DEV] Failed to add inline image to DBlobs:', { label, error, inputType, base64Length: inputBase64.length });
    }
  }

  private onAddUrlCitation(urlc: Extract<AixWire_Particles.PartParticleOp, { p: 'urlc' }>): void {

    const { title, url, num: refNumber, from: startIndex, to: endIndex, text: textSnippet, pubTs } = urlc;

    // reuse existing annotations - single fragment per message
    const existingFragment = this.accumulator.fragments.find(isVoidAnnotationsFragment);
    if (existingFragment) {

      // coalesce ranges if there are citations at the same URL
      const sameUrlCitation = existingFragment.part.annotations.find(({ type, url: existingUrl }) => type === 'citation' && url === existingUrl);
      if (!sameUrlCitation) {
        existingFragment.part.annotations = [
          ...existingFragment.part.annotations,
          createDVoidWebCitation(url, title, refNumber, startIndex, endIndex, textSnippet, pubTs),
        ];
      } else {
        if (startIndex !== undefined && endIndex !== undefined) {
          sameUrlCitation.ranges = [
            ...sameUrlCitation.ranges,
            { startIndex, endIndex, ...(textSnippet ? { textSnippet } : {}) },
          ];
        }
      }

    } else {

      // create the *only* annotations fragment in the message
      const newCitation = createDVoidWebCitation(url, title, refNumber, startIndex, endIndex, textSnippet, pubTs);
      this.accumulator.fragments.push(createAnnotationsVoidFragment([newCitation]));

    }

    // Important: Don't reset currentTextFragmentIndex to allow text to continue
    // This ensures we don't interrupt the text flow
  }


  /// Rest of the data ///

  private onCGEnd({ reason: _reason /* Redundant: no information */, tokenStopReason }: Extract<AixWire_Particles.ChatGenerateOp, { cg: 'end' }>): void {

    // NOTE: no new info in particle.reason
    // - abort-client: user abort (already captured in the stop reason)
    // - done-*: normal termination (no info)
    // - issue-*: issue (already captured in the 'issue' particle, and stop reason is 'cg-issue')

    // handle the token stop reason
    switch (tokenStopReason) {
      // normal stop
      case 'ok':                    // content
      case 'ok-tool_invocations':   // content + tool invocation
        break;

      case 'client-abort-signal':
        this.accumulator.genTokenStopReason = 'client-abort';
        break;

      case 'out-of-tokens':
        this.accumulator.genTokenStopReason = 'out-of-tokens';
        break;

      case 'cg-issue':              // error fragment already added before
        this.accumulator.genTokenStopReason = 'issue';
        break;

      case 'filter-content':        // inline text message shall have been added
      case 'filter-recitation':     // inline text message shall have been added
        this.accumulator.genTokenStopReason = 'filter';
        break;

      // unexpected
      default:
        // noinspection JSUnusedLocalSymbols
        const _exhaustiveCheck: never = tokenStopReason;
        this._appendReassemblyDevError(`Unexpected token stop reason: ${tokenStopReason}`);
        break;
    }
  }

  private onCGIssue({ issueId: _issueId /* Redundant as we add an Error Fragment already */, issueText }: Extract<AixWire_Particles.ChatGenerateOp, { cg: 'issue' }>): void {
    // NOTE: not sure I like the flow at all here
    // there seem to be some bad conditions when issues are raised while the active part is not text
    if (MERGE_ISSUES_INTO_TEXT_PART_IF_OPEN) {
      const currentTextFragment = this.currentTextFragmentIndex === null ? null
        : this.accumulator.fragments[this.currentTextFragmentIndex];
      if (currentTextFragment && isTextContentFragment(currentTextFragment)) {
        currentTextFragment.part.text += ' ' + issueText;
        return;
      }
    }
    this.accumulator.fragments.push(createErrorContentFragment(issueText));
    this.currentTextFragmentIndex = null;
  }

  private onMetrics({ metrics }: Extract<AixWire_Particles.ChatGenerateOp, { cg: 'set-metrics' }>): void {
    // type check point for AixWire_Particles.CGSelectMetrics -> DMetricsChatGenerate_Lg
    this.accumulator.genMetricsLg = metrics;
    metricsPendChatGenerateLg(this.accumulator.genMetricsLg);
  }

  private onModelName({ name }: Extract<AixWire_Particles.ChatGenerateOp, { cg: 'set-model' }>): void {
    this.accumulator.genModelName = name;
  }


  // utility

  private _appendReassemblyDevError(errorText: string, omitPrefix?: boolean): void {
    if (ELLIPSIZE_DEV_ISSUE_MESSAGES) {
      const excess = errorText.length - ELLIPSIZE_DEV_ISSUE_MESSAGES;
      const truncationMessage = `\n\n ... (truncated ${excess?.toLocaleString()} characters) ... \n\n`;
      if (excess > 0)
        errorText = ellipsizeMiddle(errorText, ELLIPSIZE_DEV_ISSUE_MESSAGES - truncationMessage.length, truncationMessage);
    }
    this.accumulator.fragments.push(createErrorContentFragment((omitPrefix ? '' : 'AIX Content Reassembler: ') + errorText));
    this.currentTextFragmentIndex = null;
  }

}


================================================
FILE: src/modules/aix/client/withDecimator.ts
================================================
import type { MaybePromise } from '~/common/types/useful.types';

// configuration
// 12 messages per second works well for 60Hz displays (single chat has 1 message every 5 frames, and 24 in 4 chats, see the square root below)
const DECIMATOR_BASE_FPS = 12;
// we keep a space of at least 20ms between calls, to avoid blocking the UI; hopefully this is good for older systems too
const DECIMATOR_MIN_IDLE_MS = 20;
// minimum number of un-decimated calls -- IN ADDITION TO THE FIRST ONE (!)
const DECIMATOR_MIN_FREE_PASSES = 1;
// enable console logging
const DEBUG_DECIMATOR = false;


/**
 * Higher-order function that applies decimation to the provided callback.
 * Preserves the same signature as the input function.
 *
 * @param throttleUnits 0: disable, 1: default throttle (12Hz), 2+ reduce frequency with the square root
 * @param fn The function to be decimated
 * @returns A new function with the same signature that applies decimation
 */
export function withDecimator<T extends (...args: any[]) => MaybePromise<void>>(throttleUnits: number, fn: T): T {

  // pass though
  if (!throttleUnits) return fn;

  // 12 messages per second works well for 60Hz displays (single chat, and 24 in 4 chats, see the square root below)
  const unitDelayMs = 1000 / DECIMATOR_BASE_FPS;
  const intervalMs = !throttleUnits ? 0
    : throttleUnits > 1 ? Math.round(unitDelayMs * Math.sqrt(throttleUnits))
      : unitDelayMs;

  // state
  let creationTime = Date.now();
  let nextDeadline = creationTime - 1;
  let freePasses = DECIMATOR_MIN_FREE_PASSES;

  return (async (...args: Parameters<T>): Promise<void> => {

    const tStart = Date.now();

    // skip if early & out of free passes
    if (tStart < nextDeadline) {
      // skip
      if (freePasses <= 0) {
        if (DEBUG_DECIMATOR)
          console.log(` - ~decimate: SKIP, ${nextDeadline - tStart} left`);
        return;
      }

      // consume free pass
      freePasses--;
      if (DEBUG_DECIMATOR)
        console.log(` -  decimate: FREE PASS, ${freePasses} remaining`);
    }

    // run
    if (DEBUG_DECIMATOR)
      console.log(` - !decimate: CALL, ${tStart - nextDeadline} overtime, at ${tStart - creationTime}ms`);
    const retVal: void = await fn(...args);

    // schedule the next deadline
    const tStop = Date.now();
    const tElapsed = tStop - tStart;
    if (DEBUG_DECIMATOR)
      if (tElapsed > intervalMs)
        console.log(` - !decimate: WARNING, ${tElapsed - intervalMs}ms late (${tElapsed} > ${intervalMs})`);
    nextDeadline = Math.round(tStop + Math.max(intervalMs - tElapsed, DECIMATOR_MIN_IDLE_MS));

    return retVal;

  }) as T;

}



================================================
FILE: src/modules/aix/client/debugger/AixDebuggerDialog.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Box, Button, Divider, FormControl, FormLabel, Option, Select, Typography } from '@mui/joy';
import ClearAllIcon from '@mui/icons-material/ClearAll';

import { GoodModal } from '~/common/components/modals/GoodModal';

import { AixDebuggerFrame } from './AixDebuggerFrame';
import { aixClientDebuggerActions, useAixClientDebuggerStore } from './memstore-aix-client-debugger';


export function AixDebuggerDialog(props: {
  onClose: () => void;
}) {

  // external state - we subscribe to Any update - it's a temp debugger anyway
  const { frames, activeFrameId, maxFrames } = useAixClientDebuggerStore(useShallow((state) => ({
    frames: state.frames,
    activeFrameId: state.activeFrameId,
    maxFrames: state.maxFrames,
  })));

  // derived state
  const activeFrame = frames.find(f => f.id === activeFrameId) ?? null;


  // handlers

  const handleSetMaxFrames = React.useCallback((value: number) => {
    aixClientDebuggerActions().setMaxFrames(value);
  }, []);

  const handleSetActiveFrame = React.useCallback((value: number | null) => {
    aixClientDebuggerActions().setActiveFrame(value);
  }, []);


  return (
    <GoodModal
      open
      onClose={props.onClose}
      title='AIX API Debugger'
      sx={{ maxWidth: undefined }}
    >

      <Box sx={{ display: 'flex', flexDirection: { xs: 'column', md: 'row' }, gap: 2 }}>

        {/* Request Switcher */}
        <FormControl sx={{ flex: 1, minWidth: 0 }}>
          <FormLabel>Select Request</FormLabel>
          <Select
            size='sm'
            variant='outlined'
            value={activeFrameId}
            onChange={(_, value) => handleSetActiveFrame(value)}
            placeholder='No requests available'
            disabled={!frames.length}
            sx={{ backgroundColor: 'background.popup' }}
          >
            {frames.map((frame) => {
              const label = `Request #${frame.id} - ${frame.context.contextName}`;
              return (
                <Option key={frame.id} value={frame.id} label={label + (frame.isComplete ? ` (${frame.particles.length})` : ' (Running)')}>
                  <div>{label} - {frame.particles.length} pts.</div>
                  <Box component='span' sx={{ marginLeft: 'auto', fontSize: 'xs' }}>{new Date(frame.timestamp).toLocaleTimeString()}</Box>
                </Option>
              );
            })}
          </Select>
        </FormControl>

        {/* History Size Preferenes */}
        <Box sx={{ display: 'flex', alignItems: 'flex-end', gap: 2 }}>
          <FormControl>
            <FormLabel>History Size</FormLabel>
            <Select
              size='sm'
              value={maxFrames}
              onChange={(_, value) => value !== null && handleSetMaxFrames(value)}
              sx={{ backgroundColor: 'background.popup' }}
            >
              <Option value={5}>Keep 5 requests</Option>
              <Option value={10}>Keep 10 requests</Option>
              <Option value={20}>Keep 20 requests</Option>
              <Option value={50}>Keep 50 requests</Option>
            </Select>
          </FormControl>

          {/* Clear History */}
          <Button
            size='sm'
            color='danger'
            onClick={aixClientDebuggerActions().clearHistory}
            startDecorator={<ClearAllIcon />}
            disabled={frames.length === 0}
          >
            Clear History
          </Button>
        </Box>
      </Box>

      <Divider />

      {/* Zero State */}
      {(!frames.length || !activeFrame) && (
        <Box sx={{ display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center', minHeight: '200px' }}>
          {!frames.length && <>
            <Typography level='title-lg'>
              No AIX API requests recorded yet
            </Typography>
            <Typography level='body-sm' sx={{ mt: 2, maxWidth: 468 }}>
              Ensure AIX debugging is active (Settings -&gt; Labs -&gt; Developer Mode)
              and you are running your own localhost:3000 installation.
            </Typography>
          </>}
          {!activeFrame && !!frames.length && (
            <Typography level='body-sm'>
              Select a request to view details
            </Typography>
          )}
        </Box>
      )}

      {/* Frame viewer */}
      {!!activeFrame && (
        <Box sx={{ overflow: 'hidden' }}>
          <AixDebuggerFrame frame={activeFrame} />
        </Box>
      )}

    </GoodModal>
  );
}



================================================
FILE: src/modules/aix/client/debugger/AixDebuggerFrame.tsx
================================================
import * as React from 'react';

import { Box, Card, Chip, Divider, Typography } from '@mui/joy';

import { ChipToggleButton } from '~/common/components/ChipToggleButton';
import TimelapseIcon from '@mui/icons-material/Timelapse';

import type { AixClientDebugger } from './memstore-aix-client-debugger';
import { AixDebuggerMeasurementsTable } from './AixDebuggerMeasurementsTable';


const _styles = {

  requestCard: {
    overflow: 'auto',
    boxShadow: 'inset 2px 0 4px -2px rgba(0, 0, 0, 0.2)',
    fontFamily: 'code',
    fontSize: 'xs',
    p: 1.5,
    gap: 1,
  } as const,

  requestCardText: {
    whiteSpace: 'pre',
  } as const,

  particleNorminal: {
    display: 'flex',
    justifyContent: 'space-between',
    alignItems: 'center',
  } as const,

  particleAborted: {
    // ..._styles.particleNorminal,
    display: 'flex',
    justifyContent: 'space-between',
    alignItems: 'center',
    // change look
    backgroundColor: '#f9f9f9',
    borderLeft: '3px solid orange',
  } as const,

  pTime: {
    pl: 2,
    fontSize: 'xs',
    whiteSpace: 'nowrap',
  } as const,

} as const;


export function AixDebuggerFrame(props: {
  frame: AixClientDebugger.Frame;
}) {

  // state
  const [showParticles, setShowParticles] = React.useState(false); // hide by default (heavy)

  const handleToggleShowParticles = React.useCallback(() => {
    setShowParticles(on => !on);
  }, []);

  const { frame } = props;

  return (
    <Box sx={{ display: 'flex', flexDirection: 'column', gap: 3 }}>

      {/* Frame Header */}
      <Box sx={{ fontSize: 'sm', display: 'grid', gridTemplateColumns: { xs: 'auto 1fr', md: 'auto 1fr auto 1fr' }, gap: 1, alignItems: 'center' }}>
        <Typography fontWeight='bold'>Request </Typography>
        <Typography fontWeight='bold'>{frame.id}</Typography>
        <div>Status:</div>
        <Chip variant='soft' color={frame.isComplete ? 'success' : 'warning'}>{frame.isComplete ? 'Complete' : 'In Progress'}</Chip>
        <div>Date</div>
        <div>{new Date(frame.timestamp).toLocaleString()}</div>
        <div>-&gt; URL:</div>
        <Chip>{frame.url || 'No URL data available'}</Chip>
        <div>Context:</div>
        <Chip>{frame.context.contextName}</Chip>
        <div>Reference:</div>
        <Chip>{frame.context.contextRef}</Chip>
      </Box>

      {/* Headers */}
      <Card variant='soft' color='warning' sx={_styles.requestCard}>
        <Typography color='warning' variant='soft' level='title-sm'>
          -&gt; Headers
        </Typography>
        <Divider />
        <Box sx={_styles.requestCardText}>
          {frame.headers || 'No headers data available'}
        </Box>
      </Card>

      {/* Body */}
      <Card variant='soft' color='primary' sx={_styles.requestCard}>
        <Typography color='primary' variant='soft' level='title-sm'>
          -&gt; Body
        </Typography>
        <Divider />
        <Box sx={_styles.requestCardText}>
          {frame.body || 'No headers data available'}
        </Box>
      </Card>

      {/* Performance Profiler */}
      <Card variant='soft' color='success' sx={_styles.requestCard}>
        <Typography color='success' variant='soft' level='title-sm' startDecorator={<TimelapseIcon />}>
          Internal Profiler:
        </Typography>
        {!!frame.profilerMeasurements?.length ? (
          <AixDebuggerMeasurementsTable measurements={frame.profilerMeasurements} />
        ) : (
          'No profiler measurements available. Note: profiling is not available in production.'
        )}
      </Card>

      {/* Particles List */}
      <Box mb={showParticles ? -2 : undefined} sx={_styles.particleNorminal}>
        <Typography level='title-sm'>
          Particles {frame.particles.length > 0 && `(${frame.particles.length})`}
          {!frame.isComplete && ' • Streaming...'}
        </Typography>
        <ChipToggleButton
          text='show particles'
          active={showParticles}
          onClick={handleToggleShowParticles}
        />
      </Box>
      {showParticles && <Card variant='soft' sx={_styles.requestCard}>

        {/* Zero state */}
        {!frame.particles.length && (
          <Typography>
            No particles received yet
          </Typography>
        )}

        {/* List of particles */}
        {frame.particles.map((particle, idx) => {

          // truncated preview of particle content
          let jsonPreview = '';
          try {
            const content = particle.content;
            jsonPreview = JSON.stringify(content).substring(0, 1024);
            if (jsonPreview.length >= 1024) jsonPreview += '...';
          } catch (e) {
            jsonPreview = 'Error parsing content';
          }

          return (
            <Box key={idx} sx={particle.isAborted ? _styles.particleAborted : _styles.particleNorminal}>
              <Box className='agi-ellipsize'>
                <span style={{ opacity: 0.5 }}>{idx + 1}:</span> {particle.isAborted ? ' (Aborted)' : ''} {jsonPreview}
              </Box>
              <Box sx={_styles.pTime}>
                {new Date(particle.timestamp).toLocaleTimeString()}
              </Box>
            </Box>
          );
        })}

      </Card>}
    </Box>
  );
}



================================================
FILE: src/modules/aix/client/debugger/AixDebuggerMeasurementsTable.tsx
================================================
import * as React from 'react';

import { Table, Typography } from '@mui/joy';

import type { AixClientDebugger } from './memstore-aix-client-debugger';


export function AixDebuggerMeasurementsTable(props: {
  measurements: AixClientDebugger.Measurements
}) {

  // empty placeholder
  if (!props.measurements?.length)
    return (
      <Typography level='body-sm' fontStyle='italic'>
        No performance measurements available
      </Typography>
    );

  // assume the keys of the first measurement are uniform across all measurements
  const headers = Object.keys(props.measurements[0]);

  return (
    <Table
      size='sm'
      variant='outlined'
      sx={{

        backgroundColor: 'background.surface',
        '& th': { fontWeight: 'bold', whiteSpace: 'nowrap', p: 1 },
        '& td': { fontFamily: 'code', p: 1 },
      }}
    >
      <thead>
      <tr>
        {headers.map(header => (
          <th key={header}>{header}</th>
        ))}
      </tr>
      </thead>
      <tbody>
      {props.measurements.map((measurement, index) => (
        <tr key={index}>
          {headers.map(header => {
            const value = measurement[header];
            // Format percentages with 1 decimal place
            const displayValue = header === 'percent' && typeof value === 'number'
              ? `${value.toFixed(1)}%`
              : value;
            return <td key={header}>{displayValue}</td>;
          })}
        </tr>
      ))}
      </tbody>
    </Table>
  );
}


================================================
FILE: src/modules/aix/client/debugger/memstore-aix-client-debugger.ts
================================================
import { create } from 'zustand';

//
// NOTE: this file is supposed to be lightweight and to be kept in memory. Particles are used by reference and
// not cloned or modified. Visualization is a Reactive stringification of the referred objects pretty much.
//

const DEFAULT_FRAMES_COUNT = 10;


/// Types ///

export namespace AixClientDebugger {

  export interface Frame {
    // frame information
    id: AixFrameId;
    timestamp: number;
    // calling purpose
    context: Context;
    // upstream request
    url: string;
    headers: string;
    body: string;
    isComplete: boolean;
    // upstream profiler measurements
    profilerMeasurements?: Measurements;
    // NOTE: in the future we could debug the raw SSE streams.. not now
    // aix response particles
    particles: Particle[];
  }

  export type Measurements = Record<string, string | number>[];

  export interface Particle {
    timestamp: number;
    content: Record<string, any>;
    isAborted?: boolean;
  }

  export interface Context {
    contextName: string;
    contextRef: string;
  }

}

export type AixFrameId = number;

let _lastInMemoryFrameId = 1;

function _createAixClientDebuggerFrame(frameContext: AixClientDebugger.Context): AixClientDebugger.Frame {
  return {
    id: ++_lastInMemoryFrameId,
    timestamp: Date.now(),
    url: '',
    headers: '',
    body: '',
    particles: [],
    isComplete: false,
    context: {
      contextName: frameContext.contextName || '_contextName',
      contextRef: frameContext.contextRef || '_contextRef',
    },
  };
}


/// Store ///

interface AixClientDebuggerState {
  frames: AixClientDebugger.Frame[];
  activeFrameId: AixFrameId | null;
  maxFrames: number;
}

interface AixClientDebuggerActions {
  // frames
  createFrame: (initialContext: AixClientDebugger.Context) => AixFrameId;
  setRequest: (fId: AixFrameId, updates: Pick<AixClientDebugger.Frame, 'url' | 'headers' | 'body'>) => void;
  setProfilerMeasurements: (fId: AixFrameId, measurements: AixClientDebugger.Measurements) => void;
  addParticle: (fId: AixFrameId, particle: AixClientDebugger.Particle, isAborted?: boolean) => void;
  completeFrame: (fId: AixFrameId) => void;

  // client view
  setActiveFrame: (activeFrameId: AixFrameId | null) => void;
  setMaxFrames: (count: number) => void;
  clearHistory: () => void;
}

type AixClientDebuggerStore = AixClientDebuggerState & AixClientDebuggerActions;


export const useAixClientDebuggerStore = create<AixClientDebuggerStore>((_set) => ({

  // initial state
  frames: [],
  activeFrameId: null,
  maxFrames: DEFAULT_FRAMES_COUNT,


  // Frame actions

  createFrame: (initialContext) => {
    const newFrame = _createAixClientDebuggerFrame(initialContext);

    _set((state) => ({
      frames: [newFrame, ...state.frames].slice(0, state.maxFrames),
      activeFrameId: newFrame.id,
    }));

    return newFrame.id;
  },

  setRequest: (fId, requestData) =>
    _set(state => ({
      frames: state.frames.map(frame => frame.id !== fId ? frame : {
        ...frame,
        ...requestData,
      }),
    })),

  setProfilerMeasurements: (fId, measurements) =>
    _set(state => ({
      frames: state.frames.map(frame => frame.id !== fId ? frame : {
        ...frame,
        profilerMeasurements: measurements,
      }),
    })),

  addParticle: (fId, particle, isAborted = false) =>
    _set(state => ({
      frames: state.frames.map(frame => frame.id !== fId ? frame : {
        ...frame,
        particles: [...frame.particles, particle],
      }),
    })),

  completeFrame: (fId) =>
    _set(state => ({
      frames: state.frames.map(frame => frame.id !== fId ? frame : {
        ...frame,
        isComplete: true,
      }),
    })),


  // Client View actions

  setActiveFrame: (activeFrameId) => _set({
    activeFrameId,
  }),

  setMaxFrames: (count) => _set(state => ({
    maxFrames: count,
    frames: state.frames.slice(0, count),
  })),

  clearHistory: () => _set({
    frames: [],
    activeFrameId: null,
  }),

}));


export function aixClientDebuggerActions() {
  return useAixClientDebuggerStore.getState() as AixClientDebuggerActions;
}



================================================
FILE: src/modules/aix/client/debugger/reassembler-debug.ts
================================================
import { AixClientDebugger, AixFrameId, useAixClientDebuggerStore } from './memstore-aix-client-debugger';


export function aixClientDebugger_init(contextInfo: AixClientDebugger.Context): AixFrameId {
  return useAixClientDebuggerStore.getState().createFrame(contextInfo);
}

export function aixClientDebugger_setRequest(
  frameId: AixFrameId,
  request: { url: string, headers: string, body: string },
): void {
  useAixClientDebuggerStore.getState().setRequest(frameId, {
    url: request.url,
    headers: request.headers,
    body: request.body,
  });
}

export function aixClientDebugger_setProfilerMeasurements(
  frameId: AixFrameId,
  measurements: AixClientDebugger.Measurements,
): void {
  useAixClientDebuggerStore.getState().setProfilerMeasurements(frameId, measurements);
}

export function aixClientDebugger_recordParticleReceived(frameId: AixFrameId, particleContent: Record<string, any>, isAborted = false): void {
  useAixClientDebuggerStore.getState().addParticle(frameId, {
    timestamp: Date.now(),
    content: particleContent,
    ...(isAborted && { isAborted }),
  });
}

export function aixClientDebugger_completeFrame(frameId: number): void {
  useAixClientDebuggerStore.getState().completeFrame(frameId);
}



================================================
FILE: src/modules/aix/server/api/aix.router.ts
================================================
import * as z from 'zod/v4';

import { createEmptyReadableStream, createServerDebugWireEvents, safeErrorString, serverCapitalizeFirstLetter } from '~/server/wire';
import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { fetchResponseOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { AixDemuxers } from '../dispatch/stream.demuxers';
import { AixWire_API, AixWire_API_ChatContentGenerate, AixWire_Particles } from './aix.wiretypes';
import { ChatGenerateTransmitter } from '../dispatch/chatGenerate/ChatGenerateTransmitter';
import { PerformanceProfiler } from '../dispatch/PerformanceProfiler';
import { createChatGenerateDispatch } from '../dispatch/chatGenerate/chatGenerate.dispatch';
import { heartbeatsWhileAwaiting } from '../dispatch/heartbeatsWhileAwaiting';


/**
 * Security - only allow certain operations in development builds (i.e. not in any production builds by default):
 *  1. dispatch Headers: hide sensitive data such as keys
 *  2. Performance profiling: visible in the AIX debugger when requested on development builds
 *  3. 'DEV_URL: ...' in error messages to show the problematic upstream URL
 *  4. onComment on SSE streams
 */
export const AIX_SECURITY_ONLY_IN_DEV_BUILDS = process.env.NODE_ENV === 'development';


export const aixRouter = createTRPCRouter({

  /**
   * Chat content generation, streaming, multipart.
   * Architecture: Client <-- (intake) --> Server <-- (dispatch) --> AI Service
   */
  chatGenerateContent: publicProcedure
    .input(z.object({
      access: AixWire_API.Access_schema,
      model: AixWire_API.Model_schema,
      chatGenerate: AixWire_API_ChatContentGenerate.Request_schema,
      context: AixWire_API.ContextChatGenerate_schema,
      streaming: z.boolean(),
      connectionOptions: AixWire_API.ConnectionOptions_schema.optional(),
    }))
    .mutation(async function* ({ input, ctx }): AsyncGenerator<AixWire_Particles.ChatGenerateOp> {


      // Intake derived state
      const intakeAbortSignal = ctx.reqSignal;
      const { access, model, chatGenerate, streaming: aixStreaming, connectionOptions } = input;
      const accessDialect = access.dialect;
      const prettyDialect = serverCapitalizeFirstLetter(accessDialect);

      // Applies per-model streaming suppression; added for o3 without verification
      const streaming = model.forceNoStream ? false : aixStreaming;


      // Intake Transmitters
      const chatGenerateTx = new ChatGenerateTransmitter(prettyDialect, connectionOptions?.throttlePartTransmitter);


      // Profiler, if requested by the caller
      const _profiler = (input.connectionOptions?.debugProfilePerformance && AIX_SECURITY_ONLY_IN_DEV_BUILDS)
        ? new PerformanceProfiler() : null;

      const _profilerCompleted = !_profiler ? null : () => {
        // append to the response, if requested by the client
        if (input.connectionOptions?.debugProfilePerformance)
          chatGenerateTx.addDebugProfilererData(_profiler?.getResultsData());

        // [DEV] uncomment this line to see the profiler table in the server-side console
        // performanceProfilerLog('AIX Router Performance', _profiler?.getResultsData());

        // clear the profiler for the next call, for resident lambdas (the profiling framework is global)
        _profiler?.clearMeasurements();
      };


      // Prepare the dispatch requests
      let dispatch: ReturnType<typeof createChatGenerateDispatch>;
      try {
        dispatch = createChatGenerateDispatch(access, model, chatGenerate, streaming);
      } catch (error: any) {
        chatGenerateTx.setRpcTerminatingIssue('dispatch-prepare', `**[AIX Configuration Issue] ${prettyDialect}**: ${safeErrorString(error) || 'Unknown service preparation error'}`, false);
        yield* chatGenerateTx.flushParticles();
        return; // exit
      }

      // Connect to the dispatch
      let dispatchResponse: Response;
      try {

        // [DEV] Debugging the request without requiring a server restart
        if (input.connectionOptions?.debugDispatchRequest) {
          chatGenerateTx.addDebugRequestInDev(dispatch.request.url, dispatch.request.headers, dispatch.request.body);
          yield* chatGenerateTx.emitParticles();
        }

        // Blocking fetch with heartbeats - combats timeouts, for instance with long Anthriopic requests (>25s on Vercel)
        _profiler?.measureStart('connect');
        dispatchResponse = yield* heartbeatsWhileAwaiting(fetchResponseOrTRPCThrow({
          url: dispatch.request.url,
          method: 'POST',
          headers: dispatch.request.headers,
          body: dispatch.request.body,
          signal: intakeAbortSignal,
          name: `Aix.${prettyDialect}`,
          throwWithoutName: true,
        }));
        _profiler?.measureEnd('connect');

      } catch (error: any) {
        // Handle expected dispatch abortion while the first fetch hasn't even completed
        if (error && error?.name === 'TRPCError' && intakeAbortSignal.aborted) {
          chatGenerateTx.setEnded('done-dispatch-aborted');
          yield* chatGenerateTx.flushParticles();
          return; // exit
        }

        // Handle AI Service connection error
        const dispatchFetchError = safeErrorString(error) + (error?.cause ? ' · ' + JSON.stringify(error.cause) : '');
        const extraDevMessage = AIX_SECURITY_ONLY_IN_DEV_BUILDS ? ` - [DEV_URL: ${dispatch.request.url}]` : '';

        const showOnConsoleForNonCustomServers = access.dialect !== 'openai' || !access.oaiHost;
        chatGenerateTx.setRpcTerminatingIssue('dispatch-fetch', `**[Service Issue] ${prettyDialect}**: ${dispatchFetchError}${extraDevMessage}`, showOnConsoleForNonCustomServers);
        yield* chatGenerateTx.flushParticles();
        return; // exit
      }


      // [NON-STREAMING] Read the full response and send operations down the intake
      const serverDebugIncomingPackets = createServerDebugWireEvents();
      if (!streaming) {
        let dispatchBody: string | undefined = undefined;
        try {
          // Read the full response body with heartbeats
          _profiler?.measureStart('read-full');
          dispatchBody = yield* heartbeatsWhileAwaiting(dispatchResponse.text());
          _profiler?.measureEnd('read-full');
          serverDebugIncomingPackets?.onMessage(dispatchBody);

          // Parse the response in full
          dispatch.chatGenerateParse(chatGenerateTx, dispatchBody);
          chatGenerateTx.setEnded('done-dispatch-closed');

        } catch (error: any) {
          if (dispatchBody === undefined)
            chatGenerateTx.setRpcTerminatingIssue('dispatch-read', `**[Reading Issue] ${prettyDialect}**: ${safeErrorString(error) || 'Unknown stream reading error'}`, true);
          else
            chatGenerateTx.setRpcTerminatingIssue('dispatch-parse', ` **[Parsing Issue] ${prettyDialect}**: ${safeErrorString(error) || 'Unknown stream parsing error'}.\nInput data: ${dispatchBody}.\nPlease open a support ticket on GitHub.`, true);
        }
        _profilerCompleted?.();
        yield* chatGenerateTx.flushParticles();
        return; // exit
      }


      // STREAM the response to the client
      const dispatchReader = (dispatchResponse.body || createEmptyReadableStream()).getReader();
      const dispatchDecoder = new TextDecoder('utf-8', { fatal: false /* malformed data -> “ ” (U+FFFD) */ });
      const dispatchDemuxer = AixDemuxers.createStreamDemuxer(dispatch.demuxerFormat);
      const dispatchParser = dispatch.chatGenerateParse;

      // Data pump: AI Service -- (dispatch) --> Server -- (intake) --> Client
      do {

        // Read AI Service chunk
        let dispatchChunk: string;
        try {
          _profiler?.measureStart('read');
          const { done, value } = yield* heartbeatsWhileAwaiting(dispatchReader.read());
          _profiler?.measureEnd('read');

          // Handle normal dispatch stream closure (no more data, AI Service closed the stream)
          if (done) {
            chatGenerateTx.setEnded('done-dispatch-closed');
            break; // outer do {}
          }

          // Decode the chunk - does Not throw (see the constructor for why)
          _profiler?.measureStart('decode');
          dispatchChunk = dispatchDecoder.decode(value, { stream: true });
          _profiler?.measureEnd('decode');
        } catch (error: any) {
          // Handle expected dispatch stream abortion - nothing to do, as the intake is already closed
          if (error && error?.name === 'ResponseAborted') {
            chatGenerateTx.setEnded('done-dispatch-aborted');
            break; // outer do {}
          }

          // Handle abnormal stream termination
          chatGenerateTx.setRpcTerminatingIssue('dispatch-read', `**[Streaming Issue] ${prettyDialect}**: ${safeErrorString(error) || 'Unknown stream reading error'}`, true);
          break; // outer do {}
        }


        // Demux the chunk into 0 or more events
        _profiler?.measureStart('demux');
        const demuxedEvents = dispatchDemuxer.demux(dispatchChunk);
        _profiler?.measureEnd('demux');

        for (const demuxedItem of demuxedEvents) {
          serverDebugIncomingPackets?.onMessage(demuxedItem);

          // ignore events post termination
          if (chatGenerateTx.isEnded) {
            // DEV-only message to fix dispatch protocol parsing -- warning on, because this is important and a sign of a bug
            console.warn('[chatGenerateContent] Received event after termination:', demuxedItem);
            break; // inner for {}
          }

          // ignore superfluos stream events
          if (demuxedItem.type !== 'event')
            continue; // inner for {}

          // [OpenAI] Special: stream termination marker
          if (demuxedItem.data === '[DONE]') {
            chatGenerateTx.setEnded('done-dialect');
            break; // inner for {}, then outer do
          }

          try {
            _profiler?.measureStart('parse');
            dispatchParser(chatGenerateTx, demuxedItem.data, demuxedItem.name);
            _profiler?.measureEnd('parse');
            if (!chatGenerateTx.isEnded)
              yield* chatGenerateTx.emitParticles();
          } catch (error: any) {
            // Handle parsing issue (likely a schema break); print it to the console as well
            chatGenerateTx.setRpcTerminatingIssue('dispatch-parse', ` **[Service Parsing Issue] ${prettyDialect}**: ${safeErrorString(error) || 'Unknown stream parsing error'}.\nInput data: ${demuxedItem.data}.\nPlease open a support ticket on GitHub.`, false);
            break; // inner for {}, then outer do
          }
        }

      } while (!chatGenerateTx.isEnded);

      _profilerCompleted?.();

      // Flush everything that's left; if we're here we have encountered a clean end condition,
      // or an error that has already been queued up for this last flush
      yield* chatGenerateTx.flushParticles();

    }),

});



================================================
FILE: src/modules/aix/server/api/aix.wiretypes.ts
================================================
import * as z from 'zod/v4';

// Used to align Particles to the Typescript definitions from the frontend-side, on 'chat.fragments.ts'
import type { DMessageToolResponsePart } from '~/common/stores/chat/chat.fragments';

import { anthropicAccessSchema } from '~/modules/llms/server/anthropic/anthropic.router';
import { geminiAccessSchema } from '~/modules/llms/server/gemini/gemini.router';
import { ollamaAccessSchema } from '~/modules/llms/server/ollama/ollama.router';
import { openAIAccessSchema } from '~/modules/llms/server/openai/openai.router';


//
// Design notes:
// - [Client -> AIX API calls] This encodes the structure sent to the AIX server API calls
// - Parts: mirror the Typescript definitions from the frontend-side, on 'chat.fragments.ts'
//


// Export types
export type AixParts_DocPart = z.infer<typeof AixWire_Parts.DocPart_schema>;
export type AixParts_InlineAudioPart = z.infer<typeof AixWire_Parts.InlineAudioPart_schema>;
export type AixParts_InlineImagePart = z.infer<typeof AixWire_Parts.InlineImagePart_schema>;
export type AixParts_ModelAuxPart = z.infer<typeof AixWire_Parts.ModelAuxPart_schema>;
export type AixParts_MetaCacheControl = z.infer<typeof AixWire_Parts.MetaCacheControl_schema>;
export type AixParts_MetaInReferenceToPart = z.infer<typeof AixWire_Parts.MetaInReferenceToPart_schema>;

export type AixMessages_SystemMessage = z.infer<typeof AixWire_Content.SystemInstruction_schema>;
export type AixMessages_ModelMessage = z.infer<typeof AixWire_Content.ModelMessage_schema>;
export type AixMessages_ToolMessage = z.infer<typeof AixWire_Content.ToolMessage_schema>;
export type AixMessages_UserMessage = z.infer<typeof AixWire_Content.UserMessage_schema>;
export type AixMessages_ChatMessage = z.infer<typeof AixWire_Content.ChatMessage_schema>;

export type AixTools_ToolDefinition = z.infer<typeof AixWire_Tooling.Tool_schema>;
export type AixTools_FunctionCallDefinition = Extract<z.infer<typeof AixWire_Tooling.Tool_schema>, { type: 'function_call' }>;
export type AixTools_ToolsPolicy = z.infer<typeof AixWire_Tooling.ToolsPolicy_schema>;

export type AixAPI_Access = z.infer<typeof AixWire_API.Access_schema>;
export type AixAPI_Context_ChatGenerate = z.infer<typeof AixWire_API.ContextChatGenerate_schema>;
export type AixAPI_Model = z.infer<typeof AixWire_API.Model_schema>;
export type AixAPIChatGenerate_Request = z.infer<typeof AixWire_API_ChatContentGenerate.Request_schema>;


/// Input Types to AIX

export namespace OpenAPI_Schema {

  /**
   * The zod definition of an "OpenAPI 3.0.3" "Schema Object".
   * https://spec.openapis.org/oas/v3.0.3#schema-object
   *
   * 1. this is an OpenAPI Schema Object, and not a standard JSON Schema, which is
   *    ("application/schema+json", a JSON object that describes the structure of JSON data).
   * 2. this is actually a subset of the OpenAPI Schema Object, as we only need a subset
   *    of the properties for our function calling use case.
   */
  export const Object_schema = z.object({
    // allowed data types - https://ai.google.dev/api/rest/v1beta/cachedContents#Type
    type: z.enum(['string', 'number', 'integer', 'boolean', 'array', 'object']),

    // (recommended) brief description of the parameter - can contain examples - can be markdown
    description: z.string().optional(),

    // the value may be null
    nullable: z.boolean().optional(),

    // [string] possible values
    enum: z.array(z.any()).optional(),

    // [number] float, double - [integer]: int32, int64
    format: z.string().optional(),

    // [object] properties (recursively)
    properties: z.record(z.string(), z.any() /* could refer to self using z.lazy().... */).optional(),
    // [object] required properties
    required: z.array(z.string()).optional(),

    // [array] schema of the items
    items: z.any().optional(), // could refer to self using z.lazy()....

    // ignore but possibly useful properties..
    // minimum: z.number().optional(),
    // maximum: z.number().optional(),
    // minLength: z.number().int().nonnegative().optional(),
    // maxLength: z.number().int().nonnegative().optional(),
    // pattern: z.string().optional(),
    // default: z.any().optional(),
    // additionalProperties: z.union([z.boolean(), jsonSchema]).optional(),
  });

}

export namespace AixWire_Parts {

  // User Input Parts

  export const TextPart_schema = z.object({
    pt: z.literal('text'),
    text: z.string(),
  });

  export const InlineAudioPart_schema = z.object({
    pt: z.literal('inline_audio'),
    /**
     * Minimal audio format support for browser compatibility:
     * - audio/wav: Most compatible, converted from Gemini PCM
     * - audio/mp3: Widely supported, efficient
     * - audio/ogg: Open format, good compression
     */
    mimeType: z.enum(['audio/wav', 'audio/mp3']), // was (['audio/wav', 'audio/mp3', 'audio/aiff', 'audio/aac', 'audio/ogg', 'audio/flac'])
    base64: z.string(),
    // sampleRate: z.number().optional(), // for PCM formats
    // channels: z.number().optional(),   // for PCM formats
    // durationMs: z.number().optional(),
  });

  // NOTE: different from DMessageImageRefPart, in that the image data is inlined rather than being referred to
  export const InlineImagePart_schema = z.object({
    pt: z.literal('inline_image'),
    /**
     * The MIME type of the image.
     * Only using the types supported by all, while the following are supported only by a subset:
     * - image/gif: Anthropic, OpenAI
     * - image/heic, image/heif: Gemini
     */
    mimeType: z.enum(['image/jpeg', 'image/png', 'image/webp']),
    base64: z.string(),
  });

  // The reason of existence of a doc part, is to be encoded differently depending on
  // the target llm (e.g. xml for anthropic, markdown titled block for others, ...)
  export const DocPart_schema = z.object({
    pt: z.literal('doc'),

    // Doc Type, not to be confused the underlying data type
    // TODO: have more precise types here, probably all VND.AGI.* ?
    vdt: z.enum([
      'application/vnd.agi.code',
      'application/vnd.agi.ocr',
      'text/plain',
    ]),

    // identifier of the document, to be known to the model, as unique as possible, for the purpose of versioning
    ref: z.string(),

    // optional title of the document
    l1Title: z.string().optional(),

    // version of the document - optional because it's not guaranteed, but strongly suggested
    version: z.number().optional(),

    // inlined for now as it's only used here; in the TypeScript definition this is DMessageDataInline
    data: z.object({
      idt: z.literal('text'),
      text: z.string(),
      mimeType: z.string().optional(), // underlying data type (e.g. text/plain, or blank)
    }),

    // meta: ignored...
  });

  // Tool Call

  const _FunctionCallInvocation_schema = z.object({
    type: z.literal('function_call'),
    name: z.string(),
    args: z.string(), //.nullable(), // 2024-11-03: disabled .nullable(), as we'll use '' for no args (which some APIs weirdly don't support so we'll mock downstream as '{}')
    // _description: z.string().optional(),
    // _args_schema: z.object({}).optional(),
  });

  const _CodeExecutionInvocation_schema = z.object({
    type: z.literal('code_execution'),
    variant: z.literal('gemini_auto_inline').optional(),
    language: z.string().optional(),
    code: z.string(),
  });

  export const ToolInvocationPart_schema = z.object({
    pt: z.literal('tool_invocation'),
    id: z.string(),
    invocation: z.discriminatedUnion('type', [
      _FunctionCallInvocation_schema,
      _CodeExecutionInvocation_schema,
    ]),
  });

  // Tool Response

  const _FunctionCallResponse_schema = z.object({
    type: z.literal('function_call'),
    result: z.string(),
    _name: z.string().optional(),
  });

  const _CodeExecutionResponse_schema = z.object({
    type: z.literal('code_execution'),
    result: z.string(),
    // _variant: z.literal('gemini_auto_inline').optional(),
  });

  export const ToolResponsePart_schema = z.object({
    pt: z.literal('tool_response'),
    id: z.string(),
    response: z.discriminatedUnion('type', [
      _FunctionCallResponse_schema,
      _CodeExecutionResponse_schema,
    ]),
    error: z.string().or(z.boolean()).optional(),
    // _environment: z.enum(['upstream', 'server', 'client']).optional(),
  });

  // Model Auxiliary Part (for thinking blocks)

  export const ModelAuxPart_schema = z.object({
    pt: z.literal('ma'),
    aType: z.literal('reasoning'),
    aText: z.string(),
    textSignature: z.string().optional(),
    redactedData: z.array(z.string()).optional(),
  });

  // Metas

  export const MetaCacheControl_schema = z.object({
    pt: z.literal('meta_cache_control'),
    control: z.literal('anthropic-ephemeral'),
  });

  export const MetaInReferenceToPart_schema = z.object({
    pt: z.literal('meta_in_reference_to'),
    referTo: z.array(z.object({
      mrt: z.literal('dmsg'),
      mText: z.string(),
      mRole: z.string(),
    })),
  });

}

export namespace AixWire_Content {

  /// System Message

  export const SystemInstruction_schema = z.object({
    parts: z.array(z.discriminatedUnion('pt', [
      AixWire_Parts.TextPart_schema,
      AixWire_Parts.DocPart_schema, // Jan 10, 2025: added support for Docs in AIX system
      AixWire_Parts.MetaCacheControl_schema,
    ])),
  });

  /// Chat Message

  export const UserMessage_schema = z.object({
    role: z.literal('user'),
    parts: z.array(z.discriminatedUnion('pt', [
      AixWire_Parts.TextPart_schema,
      // AixWire_Parts.InlineAudioPart_schema,
      AixWire_Parts.InlineImagePart_schema,
      AixWire_Parts.DocPart_schema,
      AixWire_Parts.MetaCacheControl_schema,
      AixWire_Parts.MetaInReferenceToPart_schema,
    ])),
  });

  export const ModelMessage_schema = z.object({
    role: z.literal('model'),
    parts: z.array(z.discriminatedUnion('pt', [
      AixWire_Parts.TextPart_schema,
      AixWire_Parts.InlineAudioPart_schema,
      AixWire_Parts.InlineImagePart_schema,
      AixWire_Parts.ToolInvocationPart_schema,
      AixWire_Parts.ModelAuxPart_schema,
      AixWire_Parts.MetaCacheControl_schema,
    ])),
  });

  export const ToolMessage_schema = z.object({
    role: z.literal('tool'),
    parts: z.array(z.discriminatedUnion('pt', [
      AixWire_Parts.ToolResponsePart_schema,
      AixWire_Parts.MetaCacheControl_schema,
    ])),
  });

  export const ChatMessage_schema = z.discriminatedUnion('role', [
    UserMessage_schema,
    ModelMessage_schema,
    ToolMessage_schema,
  ]);

}

export namespace AixWire_Tooling {

  /// Function Call Tool Definition

  const _FunctionCall_schema = z.object({
    /**
     * The name of the function to call. Up to 64 characters long, and can only contain letters, numbers, underscores, and hyphens.
     */
    name: z.string().regex(/^[a-zA-Z0-9_-]{1,64}$/, {
      message: 'Function name must be 1-64 characters long and contain only letters, numbers, underscores, and hyphens',
    }),
    /**
     * 3-4 sentences. Detailed description of what the tool does, when it should be used (and when not), what each parameter means, caveats and limitations.
     * - Good: "Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company."
     * - Poor: "Gets the stock price for a ticker."
     */
    description: z.string(),
    /**
     *  A JSON Schema object defining the expected parameters for the function call.
     *  - Optional. If not provided, it means the Function Tool does not require any input and will be invoked without any arguments.
     *  (OpenAI + Google: parameters, Anthropic: input_schema)
     */
    input_schema: z.object({
      // type: z.literal('object'), // Note: every protocol adapter adds this in the structure, here's we're just opting to not add it
      properties: z.record(z.string(), OpenAPI_Schema.Object_schema),
      required: z.array(z.string()).optional(),
    }).optional(),
  });

  const _FunctionCallTool_schema = z.object({
    type: z.literal('function_call'),
    function_call: _FunctionCall_schema,
    // domain: z.enum(['server', 'client']).optional(),
  });

  /// Code Execution Tool

  const _CodeExecutionTool_schema = z.object({
    type: z.literal('code_execution'),
    /**
     * For now we are supporting a single provider:
     * - gemini_auto_inline: Google Gemini, auto-invoked, and inline (runs the code and goes back to the model to continue the generation)
     */
    variant: z.enum(['gemini_auto_inline']),
  });

  /// Tool Definition

  /**
   * Describe 'Tools' available to the model.
   *   API for developers, this data does not get stored[1].
   *   Tools are items that require an input description and will produce an output.
   *
   * __Function Call Tools__
   * The model decides to invoke a function creates a JSON object to fill-in the
   * arguments of the function according to a developer-provided schema.
   * - [1] Note that the schema could be stored to the data as rest as part
   *       of DMessageToolCallPart messages.
   *
   * __Code Execution Tools__
   * Models of the Gemini family will emit a code exeuction Tool Call, then execute
   * the code into a sandboxed code interpreter, then emit a Tool Response with the
   * generated code and then resume execution of the code, inline.
   *
   * @example
   * [
   *  { type: 'function_call', function_call: { name: 'get_stock_price', description: 'Retrieves the current stock price for a given ticker symbol.', input_schema: { type: 'object', properties: { ticker: { type: 'string', description: 'The ticker symbol of the stock to get the price for.' } }, required: ['ticker'] } } },
   *  { type: 'code_execution', provider: 'gemini' },
   * ]
   * */
  export const Tool_schema = z.discriminatedUnion('type', [
    _FunctionCallTool_schema,
    _CodeExecutionTool_schema,
  ]);

  /// Tools Policy

  /**
   * Policy for tools that the model can use:
   * - auto: can use a tool or not (default, same as not specifying a policy)
   * - any: must use one tool at least
   * - function_call: must use a specific Function Tool
   * - none: same as not giving the model any tool [REMOVED - just give no tools]
   */
  export const ToolsPolicy_schema = z.discriminatedUnion('type', [
    z.object({ type: z.literal('auto') }),
    z.object({ type: z.literal('any') /*, parallel: z.boolean()*/ }),
    z.object({ type: z.literal('function_call'), function_call: z.object({ name: z.string() }) }),
  ]);

}

export namespace AixWire_API {

  /// Access

  export const Access_schema = z.discriminatedUnion('dialect', [
    anthropicAccessSchema,
    geminiAccessSchema,
    ollamaAccessSchema,
    openAIAccessSchema,
  ]);

  /// Model

  export const Model_schema = z.object({
    id: z.string(),
    acceptsOutputs: z.array(z.enum(['text', 'image', 'audio'])),
    temperature: z.number().min(0).max(2).optional()
      .nullable(), // [Deepseek, 2025-01-20] temperature unsupported, so we use 'null' to omit it from the request
    maxTokens: z.number().min(1).optional(),
    topP: z.number().min(0).max(1).optional(),
    forceNoStream: z.boolean().optional(),
    vndAntThinkingBudget: z.number().nullable().optional(),
    vndGeminiShowThoughts: z.boolean().optional(),
    vndGeminiThinkingBudget: z.number().optional(),
    vndOaiResponsesAPI: z.boolean().optional(),
    vndOaiReasoningEffort: z.enum(['low', 'medium', 'high']).optional(),
    vndOaiRestoreMarkdown: z.boolean().optional(),
    vndOaiWebSearchContext: z.enum(['low', 'medium', 'high']).optional(),
    vndPerplexityDateFilter: z.enum(['unfiltered', '1m', '3m', '6m', '1y']).optional(),
    vndPerplexitySearchMode: z.enum(['default', 'academic']).optional(),
    vndXaiSearchMode: z.enum(['auto', 'on', 'off']).optional(),
    vndXaiSearchSources: z.string().optional(),
    vndXaiSearchDateFilter: z.enum(['unfiltered', '1d', '1w', '1m', '6m', '1y']).optional(),
    /**
     * [OpenAI, 2025-03-11] This is the generic version of the `web_search_options.user_location` field
     * This AIX field mimics on purpose: https://platform.openai.com/docs/api-reference/chat/create
     */
    userGeolocation: z.object({
      city: z.string().optional(),      // free text input for the city of the user, e.g. San Francisco.
      country: z.string().optional(),   // two-letter ISO country code of the user, e.g. US
      region: z.string().optional(),    // free text input for the reg. of the user the user, e.g. California
      timezone: z.string().optional(),  // IANA timezone of the user, e.g. America/Los_Angeles
    }).optional(),
  });

  /// Context

  export const ContextChatGenerate_schema = z.object({
    method: z.literal('chat-generate'),
    name: z.enum([

      // non-streaming AI operations
      'chat-ai-summarize',
      'chat-ai-title',
      'chat-attachment-prompts',  // - id of the first fragment
      'chat-followup-diagram',
      'chat-followup-htmlui',
      'chat-react-turn',
      'draw-expand-prompt',
      'fixup-code',

      // streaming AI operations
      'ai-diagram',               // making a diagram - messageId
      'ai-flattener',             // flattening a thread - messageId of the first message
      'beam-gather',              // fusing beam rays - fusionId
      'beam-scatter',             // scattering beam rays - rayId
      'call',                     // having a phone conversation - messageId of the first message
      'conversation',             // chatting with a persona - conversationId
      'persona-extract',          // extracting a persona from texts - chainId

      // temporary (nothing is more permanent than a temporary fix that works well)
      '_DEV_',

    ]),
    ref: z.string(),
  });

  // For future use
  // export const Context_schema = z.discriminatedUnion('method', [
  //   ContextChatGenerate_schema,
  // ]);

  /// Connection options

  export const ConnectionOptions_schema = z.object({
    debugDispatchRequest: z.boolean().optional(),
    debugProfilePerformance: z.boolean().optional(),
    throttlePartTransmitter: z.number().optional(), // in ms
    // retry: z.number().optional(),
    // retryDelay: z.number().optional(),
  });

}

export namespace AixWire_API_ChatContentGenerate {

  /// Request

  export const Request_schema = z.object({
    systemMessage: AixWire_Content.SystemInstruction_schema.nullable(),
    chatSequence: z.array(AixWire_Content.ChatMessage_schema),
    tools: z.array(AixWire_Tooling.Tool_schema).optional(),
    toolsPolicy: AixWire_Tooling.ToolsPolicy_schema.optional(),
  });

  /// Response - Events Stream

  // const AixEventProto_schema = z.union([
  //   z.object({ t: z.string() }),
  //   z.object({ set: z.object({ model: z.string().optional() }) }),
  // ]);
  //
  // const AixControlProto_schema = z.object({
  //   type: z.enum(['start', 'done']),
  // });
  //
  // const AixErrorProto_schema = z.object({
  //   issueId: z.enum(['dispatch-prepare', 'dispatch-fetch', 'dispatch-read', 'dispatch-parse']),
  //   issueText: z.string(),
  // });

}


///  Output Types from AIX

/**
 * This is the protocol for both the control objects sent by the tRPC streaming procedures,
 * and the thePartTransmitter/PartReassembler.
 *
 * VITAL: when transmitting anything that's "undefined", leave it out of the
 * object rather than setting it as 'undefined' as 'superjson' will mess it up
 * and tRPC decoding will be broken (very important!)
 */
export namespace AixWire_Particles {

  /** Unified particle representation for outputs of chatGenerate */
  export type ChatGenerateOp =
    | ChatControlOp
    | TextParticleOp
    | PartParticleOp;


  // ChatControl

  type ChatControlOp =
  // | { cg: 'start' } // not really used for now
    | { cg: 'end', reason: CGEndReason, tokenStopReason: GCTokenStopReason }
    | { cg: 'issue', issueId: CGIssueId, issueText: string }
    | { cg: 'set-metrics', metrics: CGSelectMetrics }
    | { cg: 'set-model', name: string }
    | { cg: '_debugDispatchRequest', security: 'dev-env', dispatchRequest: { url: string, headers: string, body: string } } // may generalize this in the future
    | { cg: '_debugProfiler', measurements: Record<string, number | string>[] };

  export type CGEndReason =     // the reason for the end of the chat generation
    | 'abort-client'            // user aborted before the end of stream
    | 'done-dialect'            // OpenAI signals the '[DONE]' event, or Anthropic sensds the 'message_stop' event
    | 'done-dispatch-aborted'   // this shall never see the light of day, as it was a reaction to the intake being aborted first
    | 'done-dispatch-closed'    // dispatch connection closed
    | 'issue-dialect'           // [1] ended because a dispatch encountered an issue, such as out-of-tokens, recitation, etc.
    | 'issue-rpc';              // [2] ended because of an issue

  export type CGIssueId =
    | 'dialect-issue'           // [1] when end reason = 'issue-dialect'
    | 'dispatch-prepare'        // [2] when end reason = 'issue-rpc', 4 phases of GC dispatch
    | 'dispatch-fetch'          // [2] "
    | 'dispatch-read'           // [2] "
    | 'dispatch-parse'          // [2] "
    | 'client-read';            // the aix client encountered an unexpected error (e.g. tRPC)

  export type GCTokenStopReason =
    | 'ok'                      // clean, including reaching 'stop sequences'
    | 'ok-tool_invocations'     // clean & tool invocations
    // premature:
    | 'cg-issue'                // [1][2] chat-generation issue (see CGIssueId)
    | 'client-abort-signal'     // the client aborted - likely a user/auto initiation
    | 'filter-content'          // content filter (e.g. profanity)
    | 'filter-recitation'       // recitation filter (e.g. recitation)
    | 'out-of-tokens';          // got out of tokens

  /**
   * NOTE: break compatbility with this D-stored-type only when we'll
   * start to need backwards-incompatible Particle->Reassembler flexibility,
   * which can't be just extended in the D-stored-type.
   *
   * We are now duplicating this, to force the type checker to reveal any discrepancies.
   */
  export type CGSelectMetrics = {
    // T = milliseconds
    TIn?: number,         // Portion of Input tokens which is new (not cached)
    TCacheRead?: number,
    TCacheWrite?: number,
    TOut?: number,
    TOutR?: number,       // Portion of TOut that was used for reasoning (e.g. not for output)
    // TOutA?: number,    // Portion of TOut that was used for Audio

    // dt = milliseconds
    dtStart?: number,
    dtInner?: number,
    dtAll?: number,

    // v = Tokens/s
    vTOutInner?: number,  // TOut / dtInner
  };

  // TextParticle / PartParticle - keep in line with the DMessage*Part counterparts

  export type TextParticleOp =
    | { t: string }; // special: incremental text, but with a more optimized/succinct representation compared to { p: 't_', i_t: string }

  export type PartParticleOp =
    | { p: '❤' } // heart beat
    | { p: 'tr_', _t: string, weak?: 'tag' } // reasoning text, incremental; could be a 'weak' detection, e.g. heuristic from '<think>' rather than API-provided
    | { p: 'trs', signature: string } // reasoning signature
    | { p: 'trr_', _data: string } // reasoning raw (or redacted) data
    // | { p: 'ii', mimeType: string, i_b64?: string /* never undefined */ }
    // | { p: '_ii', i_b64: string }
    // | { p: 'di', type: string, ref: string, l1Title: string, i_text?: string /* never undefined */ }
    // | { p: '_di', i_text: string }
    | { p: 'fci', id: string, name: string, i_args?: string /* never undefined */ }
    | { p: '_fci', _args: string }
    | { p: 'cei', id: string, language: string, code: string, author: 'gemini_auto_inline' }
    | { p: 'cer', id: string, error: DMessageToolResponsePart['error'], result: string, executor: 'gemini_auto_inline', environment: DMessageToolResponsePart['environment'] }
    | { p: 'ia', mimeType: string, a_b64: string, label?: string, generator?: string, durationMs?: number } // inline audio, complete
    | { p: 'ii', mimeType: string, i_b64: string, label?: string, generator?: string, prompt?: string } // inline image, complete
    | { p: 'urlc', title: string, url: string, num?: number, from?: number, to?: number, text?: string, pubTs?: number }; // url citation - pubTs: publication timestamp

}



================================================
FILE: src/modules/aix/server/dispatch/heartbeatsWhileAwaiting.ts
================================================
// configuration
const DEFAULT_TIMEOUT_MS = 10_000;


/**
 * Awaits a promise while sending ❤
 *
 * Maintains connection liveliness during long-running operations such as
 * long fetches (e.g. Anthropic on large context) or long reads (e.g.
 * image generation by Gemini Image).
 *
 * @param operationPromise Promise to await with heartbeat protection
 * @param timeoutMs Time in ms between heartbeats (if 0, no heartbeats)
 * @returns The same result as awaiting the promise
 */
export async function* heartbeatsWhileAwaiting<TOut>(operationPromise: Promise<TOut>, timeoutMs: number = DEFAULT_TIMEOUT_MS) {
  if (!timeoutMs) return await operationPromise;

  // holds the outcome in either state
  const operationWrapper = operationPromise
    .then(result => ({ type: 'resolved' as const, result }))
    .catch(error => ({ type: 'rejected' as const, error }));

  while (true) {

    // setup next ❤ timeout
    const heartbeatPromise = new Promise<'❤'>(resolve => {
      setTimeout(() => resolve('❤'), timeoutMs);
    });

    // race ❤|operation
    const winner = await Promise.race([
      operationWrapper,
      heartbeatPromise,
    ]);

    // if the operation won, great, we're done
    if (winner !== '❤')
      break;

    // otherwise send the ❤
    yield { p: '❤' as const };
  }

  // return the actual result (or throw if rejected)
  const wrappedResult = await operationWrapper;
  if (wrappedResult.type === 'rejected')
    throw wrappedResult.error;

  return wrappedResult.result;
}



================================================
FILE: src/modules/aix/server/dispatch/PerformanceProfiler.ts
================================================
// Types

type PerformanceMeasurements = PerformanceMeasurement[];

interface PerformanceMeasurement extends Record<string, number | string> {
  operation: string;
  totalMs: number;
  percent: number;
  count: number;
  avgMs: number;
  minMs: number;
  maxMs: number;
}


/**
 * Lightweight 'performance'-like API for Edge runtimes.
 *
 * Note (Enrico): on Edge runtimes the Date.now() function could be a bit coarse,
 * to prevent timing attacks. Still should be indicative enough for statistical
 * profiling in our use cases.
 */
class _EdgePerformanceFallback {

  private marks = new Map<string, number>();
  private measures = new Map<string, { duration: number }[]>();

  mark(name: string): void {
    this.marks.set(name, Date.now());
  }

  measure(name: string, startMark: string, endMark: string): void {
    const startTime = this.marks.get(startMark);
    const endTime = this.marks.get(endMark);

    if (startTime && endTime) {
      if (!this.measures.has(name))
        this.measures.set(name, []);
      this.measures.get(name)?.push({ duration: endTime - startTime });
    }
  }

  clearMarks(name: string): void {
    if (name)
      this.marks.delete(name);
    else
      this.marks.clear();
  }

  clearMeasures(name: string): void {
    if (name)
      this.measures.delete(name);
    else
      this.measures.clear();
  }

  getEntriesByName(name: string, type: string): Array<{ duration: number }> {
    if (type === 'measure')
      return this.measures.get(name) || [];
    return [];
  }
}


/**
 * Retuns the performance API, or a lightweight fallback when it's not available.
 */
function _getPerformanceAPI(): typeof performance | _EdgePerformanceFallback {

  // FIXME: we are forcing the fallback for now, as the performance API would conflict with Beam
  //        as 'marks' are global and would conflict between chats.
  // if (typeof performance !== 'undefined' && typeof performance.mark === 'function' && typeof performance.measure === 'function')
  //   return performance;

  return new _EdgePerformanceFallback();
}


export function performanceProfilerLog(label: string, measurements?: PerformanceMeasurements): void {
  console.log(`\n---- ${label} ----`);
  console.log('Operation        | Total ms   | % of Total | Count | Avg ms   | Min ms   | Max ms   ');
  console.log('-----------------|------------|------------|-------|----------|----------|----------');
  if (measurements?.length) {
    for (const result of measurements) {
      // Format the percentage with one decimal place
      const percentageFormatted = result.percent.toFixed(1) + '%';
      console.log(
        `${result.operation.padEnd(16)} | ` +
        `${String(result.totalMs).padEnd(10)} | ` +
        `${percentageFormatted.padEnd(10)} | ` +
        `${String(result.count).padEnd(5)} | ` +
        `${String(result.avgMs).padEnd(8)} | ` +
        `${String(result.minMs).padEnd(8)} | ` +
        `${String(result.maxMs).padEnd(8)}`,
      );
    }
  }
  console.log('-'.repeat(label.length + 10));
}


/**
 * High-precision performance profiler - utility class. Compatible with Edge runtimes.
 */
export class PerformanceProfiler {

  private readonly perf = _getPerformanceAPI();
  private readonly measurements = new Map<string, number>();

  /** Start measuring an operation */
  measureStart(name: string): void {
    this.perf.mark(`${name}:start`);
  }

  /** End measuring an operation */
  measureEnd(name: string): void {
    this.perf.mark(`${name}:end`);
    this.perf.measure(name, `${name}:start`, `${name}:end`);
    this.measurements.set(name, (this.measurements.get(name) || 0) + 1);
  }

  /** Call this between sessions, as the runtime will otherwise keep accumulating */
  clearMeasurements(): void {
    for (const name of this.measurements.keys()) {
      this.perf.clearMarks(`${name}:start`);
      this.perf.clearMarks(`${name}:end`);
      this.perf.clearMeasures(name);
    }
    this.measurements.clear();
  }

  /** Get performance results, JSON-friendly */
  getResultsData(): PerformanceMeasurements {
    const results: PerformanceMeasurements = [];
    let grandTotalMs = 0;

    for (const name of this.measurements.keys()) {
      const entries = this.perf.getEntriesByName(name, 'measure');
      const count = entries.length;
      const totalMs = entries.reduce((sum, entry) => sum + entry.duration, 0);
      grandTotalMs += totalMs;
      const avgMs = totalMs / count;
      const minMs = Math.min(...entries.map(e => e.duration));
      const maxMs = Math.max(...entries.map(e => e.duration));

      results.push({
        operation: name,
        totalMs: Number(totalMs.toFixed(2)),
        percent: 0,
        count: count,
        avgMs: Number(avgMs.toFixed(2)),
        minMs: Number(minMs.toFixed(2)),
        maxMs: Number(maxMs.toFixed(2)),
      });
    }

    for (let result of results)
      result.percent = grandTotalMs > 0 ? Number((result.totalMs / grandTotalMs * 100).toFixed(1)) : 0;

    return results.sort((a, b) => b.totalMs - a.totalMs);
  }

}


================================================
FILE: src/modules/aix/server/dispatch/stream.demuxer.fastsse.ts
================================================
import type { AixDemuxers } from './stream.demuxers';
import { AIX_SECURITY_ONLY_IN_DEV_BUILDS } from '../api/aix.router';


/**
 * High-performance hand-roller parser for EventSource streams.
 *
 * Acknowledgements: thanks to the great `eventsource-parser` library for the inspiration and code [2].
 *
 * NOTE: we follow the spec for parsing, but not for event dispatching, which happens in our format. Breaks from spec:
 * - Non-Standard output format
 * - Retry (reconnect timeout): parsed but not used (applies to the whole stream, not individual events)
 * - Last Event Handling: not really implemented
 *
 * SSE information [1]:
 * - UTF-8 encoded, may start with a BOM (U+FEFF)
 * - default event type is 'message'
 * - mime is text/event-stream'
 *
 * [1]: https://html.spec.whatwg.org/multipage/server-sent-events.html
 * [2]: https://github.com/rexxars/eventsource-parser
 */
export function createFastEventSourceDemuxer(): AixDemuxers.StreamDemuxer {

  // accumulator
  let buffer = '';
  let checkForBom = true;
  let eolSearchIndex = 0;

  // parsed stream fields
  let streamLastEventId: string | undefined = undefined; // unused
  let streamReconnectTime: number | undefined = undefined;

  // parsed event block fields. [1]: They must be initialized to the empty string.
  let eventData: string = '';
  let eventId: string = '';
  let eventType: string = '';

  return {
    demux: (chunk: string): AixDemuxers.DemuxedEvent[] => {

      // fast-out
      if (!chunk) return [];

      /**
       * Strip the BOM if present in the very first packet.
       * NOTE: this assumes a String, UTF-8 encoded (obtained from new TextDecoder('utf-8').decode(...)), not
       * a Uint8Array, which would have 3 bytes (0xEF,0xBB,0xBF) at the start and would require a .slice(3) instead.
       *
       */
      if (checkForBom) {
        if (chunk.startsWith('\uFEFF'))
          chunk = chunk.slice(1);
        checkForBom = false;
      }

      // concatenate the new chunk to the buffer
      buffer += chunk;


      /// Fast Line Splitting

      /**
       * Fast-split the buffer into lines (hand optimized)
       *
       * From the spec:
       *   The stream must then be parsed by reading everything line by line, with:
       * - a U+000D CARRIAGE RETURN U+000A LINE FEED (CRLF) character pair
       * - a single U+000A LINE FEED (LF) character not preceded by a U+000D CARRIAGE RETURN (CR) character
       * - a single U+000D CARRIAGE RETURN (CR) character not followed by a U+000A LINE FEED (LF) character
       * being the ways in which a line can end.
       */
      const lines = [];
      do {
        let lfIndex = buffer.indexOf('\n', eolSearchIndex);
        if (lfIndex !== -1) {
          // we have a LF, let's check if it's a standalone LF or a CRLF
          if (lfIndex === 0) // ^LF
            lines.push('');
          else if (buffer[lfIndex - 1] === '\r') // CRLF
            lines.push(buffer.slice(eolSearchIndex, lfIndex - 1));
          else // LF
            lines.push(buffer.slice(eolSearchIndex, lfIndex));
          eolSearchIndex = lfIndex + 1;
        } else {
          // no LF found, let's check for a CR
          let crIndex = buffer.indexOf('\r', eolSearchIndex);
          if (crIndex !== -1) {
            // we have a CR, and it is not followed by a LF in the chunk
            // NOTE: we make the assumption that the CR *WILL NOT* be followed by a LF in the next chunk (same as eventsource-parser)
            //       however even if it is, worst case we'll get 2 empty lines, which will be de-duped later
            lines.push(buffer.slice(eolSearchIndex, crIndex));
            eolSearchIndex = crIndex + 1;
          } else {
            // no EOL found, we're done with this chunk
            break;
          }
        }
      } while (eolSearchIndex < buffer.length);

      // nothing found
      if (!lines.length) return [];

      // update the buffer - note that we could even avoid this and the algo would work, however we are reducing memory size but increasing memory thrashing here
      buffer = eolSearchIndex === buffer.length ? '' : buffer.slice(eolSearchIndex);
      eolSearchIndex = 0;


      /// Line-by-Line Processing

      const events: AixDemuxers.DemuxedEvent[] = [];

      for (const line of lines) {

        // blank line: Dispatch
        if (line === '') {
          // set the event source Last Event Id to the event Id (unused)
          streamLastEventId = eventId || streamLastEventId;

          if (eventData) {
            // **NOTE**: this is our unified 'DemuxEvent' format, which is different from the spec.
            //           As we build this for speed, we are already adopting the destination format rather than
            //           the event dispatch format of [1] ({ id: eventId, event: eventType || undefined, data: eventData.endsWith() ? ... }).
            events.push({
              type: 'event',
              name: eventType || undefined,
              data: eventData.endsWith('\n') ? eventData.slice(0, -1) : eventData, // [2] thanks
              // eventId: eventId || undefined, // unused
            });
          }

          // Reset for the next event
          eventId = '';
          eventData = '';
          eventType = '';

          continue; // Dispatch queued
        }

        // non-blank line: Parse
        // if the line starts with a colon, ignore
        const colonIndex = line.indexOf(':');
        if (colonIndex === 0) {
          if (AIX_SECURITY_ONLY_IN_DEV_BUILDS)
            console.log('[DEV] fast-sse-demuxer: SSE Comment (may ignore):', line.slice(line.startsWith(': ') ? 2 : 1));
          continue;
        }

        // Process the line as a (field, value) pair
        let field, value;
        if (colonIndex > 0) {
          // if the line contains a colon, parse the field
          field = line.slice(0, colonIndex);
          value = line.slice(colonIndex + (line[colonIndex + 1] === ' ' ? 2 : 1));
        } else {
          // use the whole line as the field name, and an empty string as the field value
          field = line;
          value = '';
        }

        // Process the field
        switch (field) {
          case 'event':
            eventType = value;
            break;

          case 'data':
            eventData += value + '\n';
            break;

          case 'id':
            if (!value.includes('\0'))
              eventId = value;
            break;

          case 'retry':
            if (/^\d+$/.test(value))
              streamReconnectTime = parseInt(value, 10);
            else if (AIX_SECURITY_ONLY_IN_DEV_BUILDS)
              console.warn('[DEV] fast-sse-demuxer: Invalid `retry` value:', value, line);
            break;

          default:
            // [1] Otherwise the field is ignored
            if (AIX_SECURITY_ONLY_IN_DEV_BUILDS)
              console.warn('[DEV] fast-sse-demuxer: Ignoring unknown field:', field, value, line);
            break;
        }
      }

      return events;
    },

    remaining: () => buffer,

    reconnectInterval: () => streamReconnectTime,
    lastEventId: () => streamLastEventId,
  };
}



================================================
FILE: src/modules/aix/server/dispatch/stream.demuxer.sse.ts
================================================
// import { createParser as createEventsourceParser, type EventSourceMessage, ParseError } from 'eventsource-parser';
//
// import { AIX_SECURITY_ONLY_IN_DEV_BUILDS } from '../api/aix.router';
//
// import type { AixDemuxers } from './stream.demuxers';
//
//
// /**
//  * NOTE: this uses the `eventsource-parser` library, which is compliant, but not fast.
//  * When possible, use the _createFastEventSourceDemuxer
//  *
//  * Creates a parser for an EventSource stream (e.g. OpenAI's format).
//  * Uses the renowned `eventsource-parser` library.
//  *
//  * Note that we only use the 'feed' function and not 'reset', as we recreate the object per-call.
//  */
// export function createEventSourceDemuxer(): AixDemuxers.StreamDemuxer {
//   let buffer: AixDemuxers.DemuxedEvent[] = [];
//   const parser = createEventsourceParser({
//     onEvent: (event: EventSourceMessage) => {
//       buffer.push({ type: 'event', name: event.event || undefined, data: event.data });
//     },
//     onRetry: (interval: number) => {
//       buffer.push({ type: 'reconnect-interval', data: '' + interval });
//     },
//     onError: (error: ParseError) => {
//       console.warn(`stream.demuxers: parser error (${error.type}):`, error.field, error.value, error.line);
//     },
//     onComment: (comment: string) => {
//       if (AIX_SECURITY_ONLY_IN_DEV_BUILDS)
//         console.log('[DEV] stream.demuxers: parser comment (safe to ignore):', comment);
//     },
//   });
//
//   return {
//     demux: (chunk: string) => {
//       parser.feed(chunk);
//       const bufferCopy = buffer;
//       buffer = [];
//       return bufferCopy;
//     },
//     remaining: () => '',
//   };
// }



================================================
FILE: src/modules/aix/server/dispatch/stream.demuxers.ts
================================================
import { createFastEventSourceDemuxer } from './stream.demuxer.fastsse';


export namespace AixDemuxers {

  /**
   * The format of the stream: 'sse' or 'json-nl'
   * - 'fast-sse' is our own parser, optimized for performance. to be preferred when possible over 'sse' (check for full compatibility with the upstream)
   * - 'json-nl' is used by Ollama
   */
  export type StreamDemuxerFormat = 'fast-sse' | 'json-nl' | null;


  /**
   * Creates a demuxer for a stream of events.
   * The demuxer is stateful and accumulates data until a full event is available.
   */
  export function createStreamDemuxer(format: StreamDemuxerFormat): StreamDemuxer {
    switch (format) {
      case 'fast-sse':
        return createFastEventSourceDemuxer();
      case 'json-nl':
        return _createJsonNlDemuxer();
      case null:
        return _nullStreamDemuxerWarn;
    }
  }


  export type DemuxedEvent = {
    type: 'event' | 'reconnect-interval';
    name?: string;
    data: string; // in case of 'reconnect-interval' this is the string representation of the number (in milliseconds)
    // eventId?: string; // unused
  };

  export type StreamDemuxer = {
    demux: (chunk: string) => DemuxedEvent[];
    remaining: () => string;

    // unused, but may be provided by some demuxers
    lastEventId?: () => string | undefined; // not used for now - SSE defines it for the stream
    reconnectInterval?: () => number | undefined; // not used for now - SSE announces it
  };

}


/**
 * Creates a parser for a 'JSON\n' non-event stream, to be swapped with an EventSource parser.
 * Ollama is the only vendor that uses this format.
 */
function _createJsonNlDemuxer(): AixDemuxers.StreamDemuxer {
  let buffer = '';

  return {
    demux: (chunk: string): AixDemuxers.DemuxedEvent[] => {
      buffer += chunk;
      if (!buffer.endsWith('\n')) return [];

      const jsonFullLines = buffer.split('\n').filter(line => !!line);
      buffer = '';

      return jsonFullLines.map(jsonString => ({
        type: 'event',
        data: jsonString,
      }));
    },

    remaining: () => buffer,
  };
}


const _nullStreamDemuxerWarn: AixDemuxers.StreamDemuxer = {
  demux: () => {
    console.warn('Null demuxer called - shall not happen, as it is only created in non-streaming');
    return [];
  },
  remaining: () => '',
};



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/chatGenerate.dispatch.ts
================================================
import { anthropicAccess } from '~/modules/llms/server/anthropic/anthropic.router';
import { geminiAccess } from '~/modules/llms/server/gemini/gemini.router';
import { ollamaAccess } from '~/modules/llms/server/ollama/ollama.router';
import { openAIAccess } from '~/modules/llms/server/openai/openai.router';

import type { AixAPI_Access, AixAPI_Model, AixAPIChatGenerate_Request } from '../../api/aix.wiretypes';
import type { AixDemuxers } from '../stream.demuxers';

import { GeminiWire_API_Generate_Content } from '../wiretypes/gemini.wiretypes';

import { aixToAnthropicMessageCreate } from './adapters/anthropic.messageCreate';
import { aixToGeminiGenerateContent } from './adapters/gemini.generateContent';
import { aixToOpenAIChatCompletions } from './adapters/openai.chatCompletions';
import { aixToOpenAIResponses } from './adapters/openai.responsesCreate';

import type { IParticleTransmitter } from './IParticleTransmitter';
import { createAnthropicMessageParser, createAnthropicMessageParserNS } from './parsers/anthropic.parser';
import { createGeminiGenerateContentResponseParser } from './parsers/gemini.parser';
import { createOpenAIChatCompletionsChunkParser, createOpenAIChatCompletionsParserNS } from './parsers/openai.parser';
import { createOpenAIResponsesEventParser, createOpenAIResponseParserNS, } from './parsers/openai.responses.parser';


/**
 * Interface for the vendor parsers to implement
 */
export type ChatGenerateParseFunction = (partTransmitter: IParticleTransmitter, eventData: string, eventName?: string) => void;


/**
 * Specializes to the correct vendor a request for chat generation
 */
export function createChatGenerateDispatch(access: AixAPI_Access, model: AixAPI_Model, chatGenerate: AixAPIChatGenerate_Request, streaming: boolean): {
  request: { url: string, headers: HeadersInit, body: object },
  demuxerFormat: AixDemuxers.StreamDemuxerFormat;
  chatGenerateParse: ChatGenerateParseFunction;
} {

  switch (access.dialect) {
    case 'anthropic':
      return {
        request: {
          ...anthropicAccess(access, model.id, '/v1/messages'),
          body: aixToAnthropicMessageCreate(model, chatGenerate, streaming),
        },
        demuxerFormat: streaming ? 'fast-sse' : null,
        chatGenerateParse: streaming ? createAnthropicMessageParser() : createAnthropicMessageParserNS(),
      };

    case 'gemini':
      /**
       * [Gemini, 2025-04-17] For newer thinking parameters, use v1alpha (we only see statistically better results)
       */
      const useV1Alpha = !!model.vndGeminiShowThoughts || model.vndGeminiThinkingBudget !== undefined;
      return {
        request: {
          ...geminiAccess(access, model.id, streaming ? GeminiWire_API_Generate_Content.streamingPostPath : GeminiWire_API_Generate_Content.postPath, useV1Alpha),
          body: aixToGeminiGenerateContent(model, chatGenerate, access.minSafetyLevel, false, streaming),
        },
        // we verified that 'fast-sse' works well with Gemini
        demuxerFormat: streaming ? 'fast-sse' : null,
        chatGenerateParse: createGeminiGenerateContentResponseParser(model.id.replace('models/', ''), streaming),
      };

    /**
     * Ollama has now an OpenAI compability layer for `chatGenerate` API, but still its own protocol for models listing.
     * - as such, we 'cast' here to the dispatch to an OpenAI dispatch, while using Ollama access
     * - we still use the ollama.router for the models listing and aministration APIs
     *
     * For reference we show the old code for body/demuxerFormat/chatGenerateParse also below
     */
    case 'ollama':
      return {
        request: {
          ...ollamaAccess(access, '/v1/chat/completions'), // use the OpenAI-compatible endpoint
          // body: ollamaChatCompletionPayload(model, _hist, access.ollamaJson, streaming),
          body: aixToOpenAIChatCompletions('openai', model, chatGenerate, access.ollamaJson, streaming),
        },
        // demuxerFormat: streaming ? 'json-nl' : null,
        demuxerFormat: streaming ? 'fast-sse' : null,
        // chatGenerateParse: createDispatchParserOllama(),
        chatGenerateParse: streaming ? createOpenAIChatCompletionsChunkParser() : createOpenAIChatCompletionsParserNS(),
      };

    case 'alibaba':
    case 'azure':
    case 'deepseek':
    case 'groq':
    case 'lmstudio':
    case 'localai':
    case 'mistral':
    case 'openai':
    case 'openpipe':
    case 'openrouter':
    case 'perplexity':
    case 'togetherai':
    case 'xai':

      // switch to the Responses API if the model supports it
      const isResponsesAPI = !!model.vndOaiResponsesAPI;
      if (isResponsesAPI) {
        return {
          request: {
            ...openAIAccess(access, model.id, '/v1/responses'),
            body: aixToOpenAIResponses(model, chatGenerate, false, streaming),
          },
          demuxerFormat: streaming ? 'fast-sse' : null,
          chatGenerateParse: streaming ? createOpenAIResponsesEventParser() : createOpenAIResponseParserNS(),
        };
      }

      return {
        request: {
          ...openAIAccess(access, model.id, '/v1/chat/completions'),
          body: aixToOpenAIChatCompletions(access.dialect, model, chatGenerate, false, streaming),
        },
        demuxerFormat: streaming ? 'fast-sse' : null,
        chatGenerateParse: streaming ? createOpenAIChatCompletionsChunkParser() : createOpenAIChatCompletionsParserNS(),
      };
  }
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/ChatGenerateTransmitter.ts
================================================
import { SERVER_DEBUG_WIRE } from '~/server/wire';
import { serverSideId } from '~/server/trpc/trpc.nanoid';

import type { AixWire_Particles } from '../../api/aix.wiretypes';
import { AIX_SECURITY_ONLY_IN_DEV_BUILDS } from '../../api/aix.router';

import type { IParticleTransmitter } from './IParticleTransmitter';


// configuration
const ENABLE_EXTRA_DEV_MESSAGES = true;
/**
 * This is enabled by default because probabilistically unlikely -- however there will be false positives/negatives.
 *
 * To activate, one needs a text message with the full `<think>` tag at the beginning of the session. It's likely to
 * happen if the tokenizer has been trained for it, but for general tokenizers (and for now) this escapes.
 */
const LLM_HOTFIX_TRANSFORM_THINKING = true;
export const IssueSymbols = {
  Generic: '❌',
  PromptBlocked: '🚫',
  Recitation: '🦜',
  Language: '🌐',
};


/**
 * Queues up and emits small messages (particles) to the client, for the purpose of a stateful
 * full reconstruction of the AixWire_Parts[] objects.
 *
 * Called by:
 * - The current dispatch chatGenerate parser, for transmitting multi-modal and multi-part messages to the client
 * - The aix.router.ts for chatGenerate operations (if called, it's mainly to queue errors)
 *
 * Error handling:
 * - Dialect issues: transmitted by the service (such as OpenAI's .error json fields, or gemini RECITATION) -- [dialect-issue]
 * - RPC issues: the issue is catched in the Aix router at various stages -- [dispatch-prepare, dispatch-fetch, dispatch-read, dispatch-parse]
 *  - Throwing in the IPartTrasmitter portion will be caught by the caller and be re-injected as a [dispatch-parse] issue
 */
export class ChatGenerateTransmitter implements IParticleTransmitter {

  // Particle queue
  private currentText: AixWire_Particles.TextParticleOp | null = null;
  private currentPart: AixWire_Particles.PartParticleOp | null = null;
  private transmissionQueue: AixWire_Particles.ChatGenerateOp[] = [];

  // State machinery
  private lastFunctionCallParticle: Extract<AixWire_Particles.PartParticleOp, { p: 'fci' }> | null = null;
  private isThinkingText: boolean | undefined = !LLM_HOTFIX_TRANSFORM_THINKING ? false : undefined;

  // Termination
  private terminationReason: AixWire_Particles.CGEndReason | null /* if reset (not impl.) */ | undefined = undefined;

  // Token stop reason
  private tokenStopReason: AixWire_Particles.GCTokenStopReason | undefined = undefined;

  // Metrics
  private accMetrics: AixWire_Particles.CGSelectMetrics | undefined = undefined;
  private sentMetrics: boolean = false;
  private freshMetrics: boolean = false;


  constructor(private readonly prettyDialect: string, _throttleTimeMs: number | undefined) {
    // TODO: implement throttling on a particle basis

    // Not really used for now
    // this.transmissionQueue.push({
    //   cg: 'start',
    // });
  }

  private _queueParticleS() {
    if (this.currentText) {
      this.transmissionQueue.push(this.currentText);
      this.currentText = null;
    }
    if (this.currentPart) {
      this.transmissionQueue.push(this.currentPart);
      this.currentPart = null;
    }
  }


  /// aix.router.ts

  * emitParticles(): Generator<AixWire_Particles.ChatGenerateOp> {
    // Metrics: emit at the beginning and the end -- if there's data to transmit
    if (!this.sentMetrics && this.freshMetrics && this.accMetrics) {
      this.sentMetrics = true;
      this.freshMetrics = false;
      this.transmissionQueue.push({
        cg: 'set-metrics',
        metrics: this.accMetrics,
      });
    }

    // Termination
    if (this.terminationReason) {
      const dispatchOrDialectIssue = this.terminationReason === 'issue-dialect' || this.terminationReason === 'issue-rpc';
      this.transmissionQueue.push({
        cg: 'end',
        reason: this.terminationReason,
        tokenStopReason: this.tokenStopReason || (dispatchOrDialectIssue ? 'cg-issue' : 'ok'),
      });
      // Keep this in a terminated state, so that every subsequent call will yield errors (not implemented)
      // this.terminationReason = null;
    }

    // Emit queued particles
    for (const op of this.transmissionQueue)
      yield op;
    this.transmissionQueue = [];
  }

  * flushParticles(): Generator<AixWire_Particles.ChatGenerateOp> {
    this._queueParticleS();
    this.sentMetrics = false; // enable sending metrics again
    return yield* this.emitParticles();
  }

  get isEnded() {
    return !!this.terminationReason;
  }

  setRpcTerminatingIssue(issueId: AixWire_Particles.CGIssueId, issueText: string, forceLogWarn: boolean) {
    this._addIssue(issueId, issueText, forceLogWarn);
    this.setEnded('issue-rpc');
  }

  addDebugRequestInDev(url: string, headers: HeadersInit, body: object) {
    this.transmissionQueue.push({
      cg: '_debugDispatchRequest',
      security: 'dev-env',
      dispatchRequest: {
        url: url,
        headers: !AIX_SECURITY_ONLY_IN_DEV_BUILDS ? '(hidden sensitive data)' : JSON.stringify(headers, null, 2),
        body: JSON.stringify(body, null, 2),
      },
    });
  }

  addDebugProfilererData(measurements: Record<string, string | number>[]) {
    this.transmissionQueue.push({
      cg: '_debugProfiler',
      measurements,
    });
  }


  /// IPartTransmitter

  /** Set the end reason (NOTE: more comprehensive than just the IPartTransmitter.setEnded['reason'])*/
  setEnded(reason: AixWire_Particles.CGEndReason) {
    if (SERVER_DEBUG_WIRE)
      console.log('|terminate|', reason, this.terminationReason ? `(WARNING: already terminated ${this.terminationReason})` : '');
    this.terminationReason = reason;
  }

  setTokenStopReason(reason: AixWire_Particles.GCTokenStopReason) {
    if (SERVER_DEBUG_WIRE)
      console.log('|token-stop|', reason);
    this.tokenStopReason = reason;
  }

  /** End the current part and flush it */
  setDialectTerminatingIssue(dialectText: string, symbol: string | null) {
    this._addIssue('dialect-issue', ` ${symbol || ''} **[${this.prettyDialect} Issue]:** ${dialectText}`, false);
    this.setEnded('issue-dialect');
  }

  /** Closes the current part, also flushing it out */
  endMessagePart() {
    // signals that the part has ended and should be transmitted
    this._queueParticleS();
    // the following are set above
    // this.currentText = null;
    // this.currentPart = null;
    this.lastFunctionCallParticle = null;
    // Note: should set some sending flag or something
  }

  /** Appends text, creating a part if missing [throttled] */
  appendText(textChunk: string) {
    // if there was another Part in the making, queue it
    if (this.currentPart)
      this.endMessagePart();
    this.currentText = {
      t: textChunk,
    };
    // [throttle] send it immediately for now
    this._queueParticleS();
  }

  /** Appends reasoning text, which is its own kind of content */
  appendReasoningText(textChunk: string, weak?: Extract<AixWire_Particles.PartParticleOp, { p: 'tr_' }>['weak']) {
    // NOTE: don't skip on empty chunks, as we want to transition states
    // if there was another Part in the making, queue it
    if (this.currentPart)
      this.endMessagePart();
    this.currentPart = {
      p: 'tr_',
      _t: textChunk,
      ...(weak ? { weak } : {}),
    };
    // [throttle] send it immediately for now
    this._queueParticleS();
  }

  /** Sets a reasoning signature, associated with the current reasoning text */
  setReasoningSignature(signature: string): void {
    this.endMessagePart();
    this.currentPart = {
      p: 'trs',
      signature,
    };
    this._queueParticleS();
  }

  /** Adds a raw (redacted) reasoning data parcel */
  addReasoningRedactedData(data: string): void {
    this.endMessagePart();
    this.currentPart = {
      p: 'trr_',
      _data: data,
    };
    this._queueParticleS();
  }

  /**
   * Support function to extract potential reasoning text in between <think> and </think> tags,
   * if and only if it's the very first text in the whole session.
   */
  appendAutoText_weak(textChunk: string) {
    // fast-path
    if (this.isThinkingText === false) {
      this.appendText(textChunk);
      return;
    }

    // inspect only at the very beginning
    let remaining = textChunk;
    if (this.isThinkingText === undefined) {
      const trimmed = remaining.trimStart();
      if (trimmed.startsWith('<think>')) {
        this.isThinkingText = true;
        remaining = trimmed.substring('<think>'.length);
      } else
        this.isThinkingText = false;  // or never use thinking extraction
    }

    while (remaining.length > 0) {
      if (this.isThinkingText) {
        const closingIdx = remaining.indexOf('</think>');
        if (closingIdx >= 0) {
          const reasoningText = remaining.substring(0, closingIdx);
          this.appendReasoningText(reasoningText, 'tag');
          this.isThinkingText = false;
          remaining = remaining.substring(closingIdx + '</think>'.length);
          // this is the only branch that can still loop
        } else {
          this.appendReasoningText(remaining, 'tag');
          return;
        }
      } else {
        this.appendText(remaining);
        return;
      }
    }
  }


  /** Appends an audio file generated by the model */
  appendAudioInline(mimeType: string, base64Data: string, label: string, generator: string, durationMs: number): void {
    // audio is a breaking content part
    this.endMessagePart();

    // enqueue and send right away as it's a large part
    this.transmissionQueue.push({
      p: 'ia',  // inline audio
      mimeType,
      a_b64: base64Data,
      ...(label ? { label } : {}),
      ...(generator ? { generator } : {}),
      ...(durationMs ? { durationMs } : {}),
    });
    this._queueParticleS();
  }

  /** Appends an image generated by the model */
  appendImageInline(mimeType: string, base64Data: string, label: string, generator: string, prompt: string): void {
    // images are a breaking content part
    this.endMessagePart();

    // enqueue and send right away as it's a large part
    this.transmissionQueue.push({
      p: 'ii',  // inline image
      mimeType,
      i_b64: base64Data,
      ...(label ? { label } : {}),
      ...(generator ? { generator } : {}),
      ...(prompt ? { prompt } : {}),
    });
    this._queueParticleS();
  }


  /** Undocumented, internal, as the IPartTransmitter callers will call setDialectTerminatingIssue instead */
  private _addIssue(issueId: AixWire_Particles.CGIssueId, issueText: string, forceLogWarn: boolean) {
    if (forceLogWarn || ENABLE_EXTRA_DEV_MESSAGES || SERVER_DEBUG_WIRE)
      console.warn(`Aix.${this.prettyDialect} (${issueId}): ${issueText}`);

    // queue the issue
    this.endMessagePart();
    this.transmissionQueue.push({
      cg: 'issue',
      issueId,
      issueText,
    });
  }

  /**
   * Creates a FC part, flushing the previous one if needed, and starts adding data to it
   * @param id if null [Gemini], a new id will be generated to keep it linked to future tool responses
   * @param functionName required.
   * @param expectedArgsFmt 'incr_str' | 'json_object' - 'incr_str' for incremental string, 'json_object' for JSON object
   * @param args must be undefined, or match the expected Args Format
   */
  startFunctionCallInvocation(id: string | null, functionName: string, expectedArgsFmt: 'incr_str' | 'json_object', args: string | object | null) {
    // validate state
    if (this.currentPart?.p === 'fci')
      throw new Error('Cannot start a new function call while the previous one is still open [parser-logic]');

    this.endMessagePart();
    this.currentPart = {
      p: 'fci',
      id: id ?? serverSideId('aix-tool-call-id'),
      name: functionName,
    };
    if (args) {
      if ((typeof args === 'string' && expectedArgsFmt !== 'incr_str') || (typeof args === 'object' && expectedArgsFmt !== 'json_object'))
        throw new Error(`unexpected argument format: got '${typeof args}' instead of '${expectedArgsFmt}'`);
      this.currentPart.i_args = typeof args === 'string' ? args : JSON.stringify(args);
    }
    this.lastFunctionCallParticle = this.currentPart;
    this._queueParticleS();
  }

  /** Appends data to a FC part [throttled] */
  appendFunctionCallInvocationArgs(id: string | null, argsJsonChunk: string) {
    // we expect the last function call to be open
    if (this.lastFunctionCallParticle?.p !== 'fci')
      throw new Error('function-call-tool: cannot append arguments to a non-existing function call');

    // we expect the id to match, if provided
    if (id && id !== this.lastFunctionCallParticle.id)
      throw new Error('function-call-tool: arguments id mismatch');

    // transmit the arguments
    // [throttle] this is where we could operate to accumulate the arguments
    this._queueParticleS();
    this.currentPart = {
      p: '_fci',
      _args: argsJsonChunk,
    };
    this._queueParticleS();
  }

  /** Creates a CE request part, flushing the previous one if needed, and completes it */
  addCodeExecutionInvocation(id: string | null, language: string, code: string, author: 'gemini_auto_inline') {
    this.endMessagePart();
    this.transmissionQueue.push({
      p: 'cei',
      id: id ?? serverSideId('aix-tool-call-id'),
      language,
      code,
      author,
    });
  }

  /** Creates a CE result part, flushing the previous one if needed, and completes it */
  addCodeExecutionResponse(id: string | null, error: boolean | string, result: string, executor: 'gemini_auto_inline', environment: 'upstream') {
    this.endMessagePart();
    this.transmissionQueue.push({
      p: 'cer',
      id: id ?? serverSideId('aix-tool-response-id'),
      error,
      result,
      executor,
      environment,
    });
  }

  /** Creates a CE result part, flushing the previous one if needed, and completes it */
  appendUrlCitation(title: string, url: string, citationNumber?: number, startIndex?: number, endIndex?: number, textSnippet?: string, pubTs?: number) {
    this.endMessagePart();
    this.transmissionQueue.push({
      p: 'urlc',
      title,
      url,
      ...(citationNumber !== undefined ? { num: citationNumber } : {}),
      ...(startIndex !== undefined ? { from: startIndex } : {}),
      ...(endIndex !== undefined ? { to: endIndex } : {}),
      ...(textSnippet ? { text: textSnippet } : {}),
      ...(pubTs !== undefined ? { pubTs } : {}),
    } satisfies Extract<AixWire_Particles.PartParticleOp, { p: 'urlc' }>);
  }

  /** Communicates the model name to the client */
  setModelName(modelName: string) {
    this.transmissionQueue.push({
      cg: 'set-model',
      name: modelName,
    });
    // send it right away if there's no other content (this may be the first particle)
    if (this.currentPart === null && this.currentText === null)
      this._queueParticleS();
  }

  /** Update the metrics, sent twice (after the first call, and then at the end of the transmission) */
  updateMetrics(update: Partial<AixWire_Particles.CGSelectMetrics>) {
    if (!this.accMetrics)
      this.accMetrics = {};

    // similar to Object.assign, but takes care of removing the "undefined" entries
    for (const key in update) {
      const value = (update as any)[key] as number | undefined;
      if (value !== undefined)
        (this.accMetrics as any)[key] = value;
    }

    this.freshMetrics = true;
  }

}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/IParticleTransmitter.ts
================================================
import type { AixWire_Particles } from '~/modules/aix/server/api/aix.wiretypes';


export interface IParticleTransmitter {

  // Parser-initiated Control //

  /** Set the end reason - only use for 'done-dialect' to signal a dialect-close */
  setEnded(reason: Extract<AixWire_Particles.CGEndReason, 'done-dialect' | 'issue-dialect'>): void;

  /** End the current part and flush it */
  setDialectTerminatingIssue(dialectText: string, symbol: string | null): void;


  // Parts data //

  /** Closes the current part, also flushing it out */
  endMessagePart(): void;

  /** Appends text, creating a part if missing [throttled] */
  appendText(textChunk: string): void;

  /** Appends reasoning text, creating a part if missing [throttled] */
  appendReasoningText(textChunk: string, weak?: 'tag'): void;

  /** Sets a reasoning signature, associated with the current reasoning text */
  setReasoningSignature(signature: string): void;

  /** Adds a raw (redacted) reasoning data parcel */
  addReasoningRedactedData(data: string): void;

  /** Appends test, with automatic heuristics for Particle splitting [throttled] */
  appendAutoText_weak(textChunk: string): void;

  /** Appends an audio file generated by the model */
  appendAudioInline(mimeType: string, base64Data: string, label: string, generator: string, durationMs: number): void;

  /** Appends an image generated by the model */
  appendImageInline(mimeType: string, base64Data: string, label: string, generator: string, prompt: string): void;

  /**
   * Creates a FC part, flushing the previous one if needed, and starts adding data to it
   * @param id if null [Gemini], a new id will be generated to keep it linked to future tool responses
   * @param functionName required.
   * @param expectedArgsFmt 'incr_str' | 'json_object' - 'incr_str' for incremental string, 'json_object' for JSON object
   * @param args must be undefined, or match the expected Args Format
   */
  startFunctionCallInvocation(id: string | null, functionName: string, expectedArgsFmt: 'incr_str' | 'json_object', args: string | object | null): void;

  /** Appends data to a FC part [throttled] */
  appendFunctionCallInvocationArgs(id: string | null, argsJsonChunk: string): void;

  /** Creates a CE request part, flushing the previous one if needed, and completes it */
  addCodeExecutionInvocation(id: string | null, language: string, code: string, author: 'gemini_auto_inline'): void;

  /** Creates a CE result part, flushing the previous one if needed, and completes it */
  addCodeExecutionResponse(id: string | null, error: boolean | string, result: string, executor: 'gemini_auto_inline', environment: 'upstream'): void;

  /** Adds a URL citation part */
  appendUrlCitation(title: string, url: string, citationNumber?: number, startIndex?: number, endIndex?: number, textSnippet?: string, pubTs?: number): void;

  // Non-parts data //

  /** Communicates the model name to the client */
  setModelName(modelName: string): void;

  /** Communicates the finish reason to the client */
  setTokenStopReason(reason: AixWire_Particles.GCTokenStopReason): void;

  /** Update the metrics, sent twice (after the first call, and then at the end of the transmission) */
  updateMetrics(update: Partial<AixWire_Particles.CGSelectMetrics>): void;

}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/adapters/anthropic.messageCreate.ts
================================================
import { escapeXml } from '~/server/wire';

import type { AixAPI_Model, AixAPIChatGenerate_Request, AixMessages_ChatMessage, AixParts_DocPart, AixParts_MetaInReferenceToPart, AixTools_ToolDefinition, AixTools_ToolsPolicy } from '../../../api/aix.wiretypes';
import { AnthropicWire_API_Message_Create, AnthropicWire_Blocks } from '../../wiretypes/anthropic.wiretypes';


// configuration
const hotFixImagePartsFirst = true;
const hotFixMapModelImagesToUser = true;

// former fixes, now removed
// const hackyHotFixStartWithUser = false; // 2024-10-22: no longer required


type TRequest = AnthropicWire_API_Message_Create.Request;

export function aixToAnthropicMessageCreate(model: AixAPI_Model, chatGenerate: AixAPIChatGenerate_Request, streaming: boolean): TRequest {

  // Convert the system message
  let systemMessage: TRequest['system'] = undefined;
  if (chatGenerate.systemMessage?.parts.length) {
    systemMessage = chatGenerate.systemMessage.parts.reduce((acc, part) => {
      switch (part.pt) {

        case 'text':
          acc.push(AnthropicWire_Blocks.TextBlock(part.text));
          break;

        case 'doc':
          acc.push(AnthropicWire_Blocks.TextBlock(approxDocPart_To_String(part)));
          break;

        case 'meta_cache_control':
          if (!acc.length)
            console.warn('Anthropic: cache_control without a message to attach to');
          else if (part.control !== 'anthropic-ephemeral')
            console.warn('Anthropic: cache_control with an unsupported value:', part.control);
          else
            AnthropicWire_Blocks.blockSetCacheControl(acc[acc.length - 1], 'ephemeral');
          break;

        default:
          throw new Error(`Unsupported part type in System message: ${(part as any).pt}`);
      }
      return acc;
    }, [] as Exclude<TRequest['system'], undefined>);

    // unset system message if empty
    if (!systemMessage.length)
      systemMessage = undefined;
  }

  // Transform the chat messages into Anthropic's format
  const chatMessages: TRequest['messages'] = [];
  let currentMessage: TRequest['messages'][number] | null = null;
  for (const aixMessage of chatGenerate.chatSequence) {
    for (const antPart of _generateAnthropicMessagesContentBlocks(aixMessage)) {
      // apply cache_control to the current head block of the current message
      if ('set_cache_control' in antPart) {
        if (currentMessage && currentMessage.content.length) {
          const lastBlock = currentMessage.content[currentMessage.content.length - 1];
          if (lastBlock.type !== 'thinking' && lastBlock.type !== 'redacted_thinking')
            AnthropicWire_Blocks.blockSetCacheControl(lastBlock, 'ephemeral');
          else
            console.warn('Anthropic: cache_control on a thinking block - not allowed');
        } else
          console.warn('Anthropic: cache_control without a message to attach to');
        continue;
      }
      // create a new message if the role changes, otherwise append as a new content block
      const { role, content } = antPart;
      if (!currentMessage || currentMessage.role !== role) {
        if (currentMessage)
          chatMessages.push(currentMessage);
        currentMessage = { role, content: [] };
      }
      currentMessage.content.push(content);
    }
  }
  if (currentMessage)
    chatMessages.push(currentMessage);

  // If the first (user) message is missing, copy the first line of the system message
  // [Anthropic] October 8th, 2024 release notes: "...we no longer require the first input message to be a user message."
  // if (hackyHotFixStartWithUser && chatMessages.length && chatMessages[0].role !== 'user' && systemMessage?.length) {
  //   const hackSystemMessageFirstLine = (systemMessage[0]?.text || '').split('\n')[0];
  //   chatMessages.unshift({ role: 'user', content: [AnthropicWire_Blocks.TextBlock(hackSystemMessageFirstLine)] });
  //   console.log(`Anthropic: hotFixStartWithUser (${chatMessages.length} messages) - ${hackSystemMessageFirstLine}`);
  // }

  // Construct the request payload
  const payload: TRequest = {
    max_tokens: model.maxTokens !== undefined ? model.maxTokens : 8192,
    model: model.id,
    system: systemMessage,
    messages: chatMessages,
    tools: chatGenerate.tools && _toAnthropicTools(chatGenerate.tools),
    tool_choice: chatGenerate.toolsPolicy && _toAnthropicToolChoice(chatGenerate.toolsPolicy),
    // metadata: { user_id: ... }
    // stop_sequences: undefined,
    stream: streaming,
    ...(model.temperature !== null ? { temperature: model.temperature !== undefined ? model.temperature : undefined } : {}),
    // top_k: undefined,
    // top_p: undefined,
  };

  // Top-P instead of temperature
  if (model.topP !== undefined) {
    payload.top_p = model.topP;
    delete payload.temperature;
  }

  // [Anthropic] Thinking Budget
  if (model.vndAntThinkingBudget !== undefined) {
    payload.thinking = model.vndAntThinkingBudget !== null ? {
      type: 'enabled',
      budget_tokens: model.vndAntThinkingBudget < payload.max_tokens ? model.vndAntThinkingBudget : payload.max_tokens - 1,
    } : {
      type: 'disabled',
    };
    delete payload.temperature;
  }

  // Preemptive error detection with server-side payload validation before sending it upstream
  const validated = AnthropicWire_API_Message_Create.Request_schema.safeParse(payload);
  if (!validated.success) {
    console.error('Anthropic: invalid messageCreate payload. Error:', validated.error.message);
    throw new Error(`Invalid sequence for Anthropic models: ${validated.error.issues?.[0]?.message || validated.error.message || validated.error}.`);
  }

  return validated.data;
}


function* _generateAnthropicMessagesContentBlocks({ parts, role }: AixMessages_ChatMessage): Generator<{
  role: 'user' | 'assistant',
  content: TRequest['messages'][number]['content'][number]
} | {
  set_cache_control: 'anthropic-ephemeral'
}> {
  if (parts.length < 1) return; // skip empty messages

  if (hotFixImagePartsFirst) {
    parts.sort((a, b) => {
      if (a.pt === 'inline_image' && b.pt !== 'inline_image') return -1;
      if (a.pt !== 'inline_image' && b.pt === 'inline_image') return 1;
      return 0;
    });
  }

  switch (role) {

    case 'user':
      for (const part of parts) {
        switch (part.pt) {

          case 'text':
            yield { role: 'user', content: AnthropicWire_Blocks.TextBlock(part.text) };
            break;

          case 'inline_image':
            yield { role: 'user', content: AnthropicWire_Blocks.ImageBlock(part.mimeType, part.base64) };
            break;

          case 'doc':
            yield { role: 'user', content: AnthropicWire_Blocks.TextBlock(approxDocPart_To_String(part)) };
            break;

          case 'meta_in_reference_to':
            const irtXMLString = approxInReferenceTo_To_XMLString(part);
            if (irtXMLString)
              yield { role: 'user', content: AnthropicWire_Blocks.TextBlock(irtXMLString) };
            break;

          case 'meta_cache_control':
            yield { set_cache_control: part.control };
            break;

          default:
            throw new Error(`Unsupported part type in User message: ${(part as any).pt}`);
        }
      }
      break;

    case 'model':
      for (const part of parts) {
        switch (part.pt) {

          case 'text':
            yield { role: 'assistant', content: AnthropicWire_Blocks.TextBlock(part.text) };
            break;

          case 'inline_audio':
            // Anthropic does not support inline audio, if we got to this point, we should throw an error
            throw new Error('Model-generated inline audio is not supported by Anthropic yet');

          case 'inline_image':
            // Example of mapping a model-generated image (even from other vendors, not just Anthropic) to a user message
            if (hotFixMapModelImagesToUser) {
              yield { role: 'user', content: AnthropicWire_Blocks.ImageBlock(part.mimeType, part.base64) };
            } else
              throw new Error('Model-generated images are not supported by Anthropic yet');
            break;

          case 'tool_invocation':
            let toolUseBlock;
            switch (part.invocation.type) {
              case 'function_call':
                toolUseBlock = AnthropicWire_Blocks.ToolUseBlock(part.id, part.invocation.name, part.invocation.args);
                break;
              case 'code_execution':
                toolUseBlock = AnthropicWire_Blocks.ToolUseBlock(part.id, 'execute_code' /* suboptimal */, part.invocation.code);
                break;
              default:
                const _exhaustiveCheck: never = part.invocation;
                throw new Error(`Unsupported tool call type in Model message: ${(part.invocation as any).type}`);
            }
            yield { role: 'assistant', content: toolUseBlock };
            break;

          case 'ma':
            if (!part.aText && !part.textSignature && !part.redactedData)
              throw new Error('Extended Thinking data is missing');
            if (part.aText && part.textSignature)
              yield { role: 'assistant', content: AnthropicWire_Blocks.ThinkingBlock(part.aText, part.textSignature) };
            for (const redactedData of part.redactedData || [])
              yield { role: 'assistant', content: AnthropicWire_Blocks.RedactedThinkingBlock(redactedData) };
            break;

          case 'meta_cache_control':
            yield { set_cache_control: part.control };
            break;

          default:
            const _exhaustiveCheck: never = part;
            throw new Error(`Unsupported part type in Model message: ${(part as any).pt}`);
        }
      }
      break;

    case 'tool':
      for (const part of parts) {
        switch (part.pt) {

          case 'tool_response':
            const toolErrorPrefix = part.error ? (typeof part.error === 'string' ? `[ERROR] ${part.error} - ` : '[ERROR] ') : '';
            switch (part.response.type) {
              case 'function_call':
                const fcTextParts = [AnthropicWire_Blocks.TextBlock(toolErrorPrefix + part.response.result)];
                yield { role: 'user', content: AnthropicWire_Blocks.ToolResultBlock(part.id, fcTextParts, part.error ? true : undefined) };
                break;
              case 'code_execution':
                const ceTextParts = [AnthropicWire_Blocks.TextBlock(toolErrorPrefix + part.response.result)];
                yield { role: 'user', content: AnthropicWire_Blocks.ToolResultBlock(part.id, ceTextParts, part.error ? true : undefined) };
                break;
              default:
                throw new Error(`Unsupported tool response type in Tool message: ${(part as any).pt}`);
            }
            break;

          case 'meta_cache_control':
            // ignored in tools
            break;

          default:
            const _exhaustiveCheck: never = part;
            throw new Error(`Unsupported part type in Tool message: ${(part as any).pt}`);
        }
      }
      break;
  }
}

function _toAnthropicTools(itds: AixTools_ToolDefinition[]): NonNullable<TRequest['tools']> {
  return itds.map(itd => {
    switch (itd.type) {

      case 'function_call':
        const { name, description, input_schema } = itd.function_call;
        return {
          type: 'custom', // we could not set it, but it helps our typesystem with discrimination
          name,
          description,
          input_schema: {
            type: 'object',
            properties: input_schema?.properties || null, // Anthropic valid values for input_schema.properties are 'object' or 'null' (null is used to declare functions with no inputs)
            required: input_schema?.required,
          },
        };

      case 'code_execution':
        throw new Error('Gemini code interpreter is not supported');

    }
  });
}

function _toAnthropicToolChoice(itp: AixTools_ToolsPolicy): NonNullable<TRequest['tool_choice']> {
  switch (itp.type) {
    case 'auto':
      return { type: 'auto' as const };
    case 'any':
      return { type: 'any' as const };
    case 'function_call':
      return { type: 'tool' as const, name: itp.function_call.name };
  }
}


// Approximate conversions - alternative approaches should be tried until we find the best one

export function approxDocPart_To_String({ ref, data }: AixParts_DocPart /*, wrapFormat?: 'markdown-code'*/): string {
  // NOTE: Consider a better representation here
  //
  // We use the 'legacy' markdown encoding, but we may consider:
  //  - '<doc id='ref' title='title' version='version'>\n...\n</doc>'
  //  - ```doc id='ref' title='title' version='version'\n...\n```
  //  - # Title [id='ref' version='version']\n...\n
  //  - ...more ideas...
  //
  return '```' + (ref || '') + '\n' + data.text + '\n```\n';
}

export function approxInReferenceTo_To_XMLString(irt: AixParts_MetaInReferenceToPart): string | null {
  const refs = irt.referTo.map(r => escapeXml(r.mText));
  if (!refs.length)
    return null; // `<context>User provides no specific references</context>`;
  return refs.length === 1
    ? `<context>User refers to this in particular:<ref>${refs[0]}</ref></context>`
    : `<context>User refers to ${refs.length} items:<ref>${refs.join('</ref><ref>')}</ref></context>`;
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/adapters/gemini.generateContent.ts
================================================
import type { AixAPI_Model, AixAPIChatGenerate_Request, AixMessages_ChatMessage, AixParts_DocPart, AixTools_ToolDefinition, AixTools_ToolsPolicy } from '../../../api/aix.wiretypes';
import { GeminiWire_API_Generate_Content, GeminiWire_ContentParts, GeminiWire_Messages, GeminiWire_Safety, GeminiWire_ToolDeclarations } from '../../wiretypes/gemini.wiretypes';

import { approxDocPart_To_String, approxInReferenceTo_To_XMLString } from './anthropic.messageCreate';


// configuration
const hotFixImagePartsFirst = true;
const hotFixReplaceEmptyMessagesWithEmptyTextPart = true;


export function aixToGeminiGenerateContent(model: AixAPI_Model, chatGenerate: AixAPIChatGenerate_Request, geminiSafetyThreshold: GeminiWire_Safety.HarmBlockThreshold, jsonOutput: boolean, _streaming: boolean): TRequest {

  // Note: the streaming setting is ignored as it only belongs in the path

  // System Instructions
  let systemInstruction: TRequest['systemInstruction'] = undefined;
  if (chatGenerate.systemMessage?.parts.length) {
    systemInstruction = chatGenerate.systemMessage.parts.reduce((acc, part) => {
      switch (part.pt) {

        case 'text':
          acc.parts.push(GeminiWire_ContentParts.TextPart(part.text));
          break;

        case 'doc':
          acc.parts.push(GeminiWire_ContentParts.TextPart(approxDocPart_To_String(part)));
          break;

        case 'meta_cache_control':
          // ignore this breakpoint hint - Anthropic only
          break;

        default:
          const _exhaustiveCheck: never = part;
          throw new Error(`Unsupported part type in System message: ${(part as any).pt}`);
      }
      return acc;
    }, { parts: [] } as Exclude<TRequest['systemInstruction'], undefined>);

    // unset system instruction if empty
    if (!systemInstruction.parts.length)
      systemInstruction = undefined;
  }

  // Chat Messages
  const contents: TRequest['contents'] = _toGeminiContents(chatGenerate.chatSequence);

  // Construct the request payload
  const payload: TRequest = {
    contents,
    tools: chatGenerate.tools && _toGeminiTools(chatGenerate.tools),
    toolConfig: chatGenerate.toolsPolicy && _toGeminiToolConfig(chatGenerate.toolsPolicy),
    safetySettings: _toGeminiSafetySettings(geminiSafetyThreshold),
    systemInstruction,
    generationConfig: {
      stopSequences: undefined, // (default, optional)
      responseMimeType: jsonOutput ? 'application/json' : undefined,
      responseSchema: undefined, // (default, optional) NOTE: for JSON output, we'd take the schema here
      candidateCount: undefined, // (default, optional)
      maxOutputTokens: model.maxTokens !== undefined ? model.maxTokens : undefined,
      ...(model.temperature !== null ? { temperature: model.temperature !== undefined ? model.temperature : undefined } : {}),
      topP: undefined, // (default, optional)
      topK: undefined, // (default, optional)
    },
  };

  // Top-P instead of temperature
  if (model.topP !== undefined) {
    delete payload.generationConfig!.temperature;
    payload.generationConfig!.topP = model.topP;
  }

  // Thinking models: thinking budget and show thoughts
  if (model.vndGeminiShowThoughts === true || model.vndGeminiThinkingBudget !== undefined) {
    const thinkingConfig: Exclude<TRequest['generationConfig'], undefined>['thinkingConfig'] = {};

    // This seems deprecated keep it in case Gemini turns it on again
    if (model.vndGeminiShowThoughts)
      thinkingConfig.includeThoughts = true;

    // 0 disables thinking explicitly
    if (model.vndGeminiThinkingBudget !== undefined) {
      if (model.vndGeminiThinkingBudget > 0)
        thinkingConfig.includeThoughts = true;
      thinkingConfig.thinkingBudget = model.vndGeminiThinkingBudget;
    }

    payload.generationConfig!.thinkingConfig = thinkingConfig;
  }

  // [Gemini, 2025-05-20] Experimental Audio generation (TTS - audio only, no text): Request
  const noTextOutput = !model.acceptsOutputs.includes('text');
  if (model.acceptsOutputs.includes('audio')) {

    // (undocumented) Adapt the request
    delete payload.systemInstruction;
    delete payload.generationConfig!.maxOutputTokens; // maxOutputTokens is not supported for audio-only output
    payload.generationConfig!.temperature = 1;

    // activate audio (/only) output
    payload.generationConfig!.responseModalities = noTextOutput ? ['AUDIO'] : ['TEXT', 'AUDIO'];

    // default voice config - list here: https://ai.google.dev/gemini-api/docs/speech-generation#voices
    payload.generationConfig!.speechConfig = {
      voiceConfig: {
        prebuiltVoiceConfig: {
          voiceName: 'Zephyr',
        },
      },
    };
  }
  // [Gemini, 2025-03-14] Experimental Image generation: Request
  else if (model.acceptsOutputs.includes('image')) {
    payload.generationConfig!.responseModalities = noTextOutput ? ['IMAGE'] : ['TEXT', 'IMAGE'];
    // 2025-03-14: both APIs v1alpha and v1beta do not support specifying the resolution
    // payload.generationConfig!.mediaResolution = 'MEDIA_RESOLUTION_HIGH';
  }

  // TODO: Google Search Grounding: for the models that support it, it shall be declared and runtime toggleable
  // it then becomes just a metter of:
  // - payload.tools = [...payload.tools, { googleSearch: {} }]; -- for most models
  // - emitting the missing particles, parsing, rendering
  // - working around the limitations and idiosyncrasies of the Search API

  // Preemptive error detection with server-side payload validation before sending it upstream
  const validated = GeminiWire_API_Generate_Content.Request_schema.safeParse(payload);
  if (!validated.success) {
    console.warn('Gemini: invalid generateContent payload. Error:', validated.error.message);
    throw new Error(`Invalid sequence for Gemini models: ${validated.error.issues?.[0]?.message || validated.error.message || validated.error}.`);
  }

  return validated.data;
}

type TRequest = GeminiWire_API_Generate_Content.Request;


function _toGeminiContents(chatSequence: AixMessages_ChatMessage[]): GeminiWire_Messages.Content[] {

  // Remove messages that are made of empty parts
  // if (hotFixRemoveEmptyMessages)
  //   chatSequence = chatSequence.filter(message => message.parts.length > 0);


  return chatSequence.map(message => {
    const parts: GeminiWire_ContentParts.ContentPart[] = [];

    if (hotFixImagePartsFirst) {
      message.parts.sort((a, b) => {
        if (a.pt === 'inline_image' && b.pt !== 'inline_image') return -1;
        if (a.pt !== 'inline_image' && b.pt === 'inline_image') return 1;
        return 0;
      });
    }

    /* Semantically we want to preserve an empty assistant response, but Gemini requires
     * at least one part for a `Content` object, so the empty message becomes a "" instead.
     * E.g. { role: 'rolename', parts: [{text: ''}] }
     */
    if (hotFixReplaceEmptyMessagesWithEmptyTextPart && message.parts.length === 0) {
      parts.push(GeminiWire_ContentParts.TextPart(''));
    }

    for (const part of message.parts) {
      switch (part.pt) {

        case 'text':
          parts.push(GeminiWire_ContentParts.TextPart(part.text));
          break;

        case 'inline_audio':
        case 'inline_image':
          parts.push(GeminiWire_ContentParts.InlineDataPart(part.mimeType, part.base64));
          break;

        case 'doc':
          parts.push(_toApproximateGeminiDocPart(part));
          break;

        case 'ma':
          // ignore this thinking block - Anthropic only
          break;

        case 'meta_cache_control':
          // ignore this breakpoint hint - Anthropic only
          break;

        case 'meta_in_reference_to':
          const irtXMLString = approxInReferenceTo_To_XMLString(part);
          if (irtXMLString)
            parts.push(GeminiWire_ContentParts.TextPart(irtXMLString));
          break;

        case 'tool_invocation':
          const invocation = part.invocation;
          switch (invocation.type) {
            case 'function_call':
              let functionCallArgs: Record<string, any> | undefined;
              if (invocation.args) {
                // TODO: migrate to JSON | objects across all providers
                // noinspection SuspiciousTypeOfGuard - reason: above
                if (typeof invocation.args === 'string') {
                  try {
                    functionCallArgs = JSON.parse(invocation.args);
                  } catch (e) {
                    console.warn('Gemini: failed to parse (string -> JSON) function call arguments', e);
                    functionCallArgs = { output: invocation.args };
                  }
                } else {
                  functionCallArgs = invocation.args;
                }
              }
              parts.push(GeminiWire_ContentParts.FunctionCallPart(invocation.name, functionCallArgs));
              break;
            case 'code_execution':
              if (invocation.language?.toLowerCase() !== 'python')
                console.warn('Gemini only supports Python code execution, but got:', invocation.language);
              parts.push(GeminiWire_ContentParts.ExecutableCodePart('PYTHON', invocation.code));
              break;
            default:
              const _exhaustiveCheck: never = invocation;
              throw new Error(`Unsupported tool call type in message: ${(part as any).call.type}`);
          }
          break;

        case 'tool_response':
          const toolErrorPrefix = part.error ? (typeof part.error === 'string' ? `[ERROR] ${part.error} - ` : '[ERROR] ') : '';
          switch (part.response.type) {
            case 'function_call':
              let functionResponseResponse: Record<string, any> | undefined;
              if (part.response.result) {
                // TODO: migrate function call results to JSON | objects across all providers
                // noinspection SuspiciousTypeOfGuard
                if (typeof part.response.result === 'string') {
                  try {
                    functionResponseResponse = JSON.parse(part.response.result);
                  } catch (e) {
                    console.warn('Gemini: failed to parse (string -> JSON) function response result', e);
                    functionResponseResponse = { output: toolErrorPrefix + part.response.result };
                  }
                  if (Array.isArray(functionResponseResponse)) {
                    console.warn('toGeminiContents: Gemini requires results of function calls to be objects', { result: functionResponseResponse });
                    throw new Error('Gemini: unexpected array as function response');
                  }
                } else {
                  functionResponseResponse = part.response.result;
                }
              }
              parts.push(GeminiWire_ContentParts.FunctionResponsePart(part.response._name || part.id, functionResponseResponse));
              break;
            case 'code_execution':
              parts.push(GeminiWire_ContentParts.CodeExecutionResultPart(!part.error ? 'OUTCOME_OK' : 'OUTCOME_FAILED', toolErrorPrefix + part.response.result));
              break;
            default:
              const _exhaustiveCheck: never = part.response;
              throw new Error(`Unsupported tool response type in message: ${(part as any).response.type}`);
          }
          break;

        default:
          const _exhaustiveCheck: never = part;
          throw new Error(`Unsupported part type in Chat message: ${(part as any).pt}`);
      }
    }

    return {
      role: message.role === 'model' ? 'model' : 'user',
      parts,
    };
  });
}

function _toGeminiTools(itds: AixTools_ToolDefinition[]): NonNullable<TRequest['tools']> {
  const tools: TRequest['tools'] = [];

  itds.forEach(itd => {
    switch (itd.type) {

      // Note: we add each function call as a separate tool, however it could be possible to add
      // a single tool with multiple function calls - which one to choose?
      case 'function_call':
        const { name, description, input_schema } = itd.function_call;

        // create the function declaration
        const functionDeclaration: GeminiWire_ToolDeclarations.FunctionDeclaration = {
          name,
          description,
        };

        // handle no-params function call definitions for Gemini (no input_schema, or empty properties)
        if (input_schema?.properties && Object.keys(input_schema.properties).length) {
          functionDeclaration.parameters = {
            type: 'object',
            properties: input_schema?.properties,
            required: input_schema?.required,
          };
        }

        // coalesce the function declaration into the last tool, if of the right type
        const lastTool = tools[tools.length - 1];
        if (lastTool && 'functionDeclarations' in lastTool && lastTool.functionDeclarations?.length) {
          lastTool.functionDeclarations.push(functionDeclaration);
          break;
        }

        // create a new tool with the function declaration
        tools.push({
          functionDeclarations: [functionDeclaration],
        });
        break;

      case 'code_execution':
        if (itd.variant !== 'gemini_auto_inline')
          throw new Error('Gemini only supports inline code execution');

        // throw if code execution is present more than once
        if (tools.some(tool => tool.codeExecution))
          throw new Error('Gemini code interpreter already defined');

        tools.push({
          codeExecution: {
            // the official docs have no parameters yet...
            // https://ai.google.dev/api/caching#tool
          },
        });
        break;

    }
  });

  return tools;
}

function _toGeminiToolConfig(itp: AixTools_ToolsPolicy): NonNullable<TRequest['toolConfig']> {
  switch (itp.type) {
    case 'auto':
      return { functionCallingConfig: { mode: 'AUTO' } };
    case 'any':
      return { functionCallingConfig: { mode: 'ANY' } };
    case 'function_call':
      return {
        functionCallingConfig: {
          mode: 'ANY',
          allowedFunctionNames: [itp.function_call.name],
        },
      };
  }
}

function _toGeminiSafetySettings(threshold: GeminiWire_Safety.HarmBlockThreshold): TRequest['safetySettings'] {
  return threshold === 'HARM_BLOCK_THRESHOLD_UNSPECIFIED' ? undefined : [
    { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: threshold },
    { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: threshold },
    { category: 'HARM_CATEGORY_HARASSMENT', threshold: threshold },
    { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: threshold },
    { category: 'HARM_CATEGORY_CIVIC_INTEGRITY', threshold: threshold },
  ];
}


// Approximate conversions - alternative approaches should be tried until we find the best one

function _toApproximateGeminiDocPart(aixPartsDocPart: AixParts_DocPart): GeminiWire_ContentParts.ContentPart {
  // NOTE: we keep this function because we could use Gemini's different way to represent documents in the future...
  return GeminiWire_ContentParts.TextPart(approxDocPart_To_String(aixPartsDocPart));
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/adapters/openai.chatCompletions.ts
================================================
import type { OpenAIDialects } from '~/modules/llms/server/openai/openai.router';

import { AixAPI_Model, AixAPIChatGenerate_Request, AixMessages_ChatMessage, AixMessages_SystemMessage, AixParts_DocPart, AixParts_InlineAudioPart, AixParts_MetaInReferenceToPart, AixTools_ToolDefinition, AixTools_ToolsPolicy } from '../../../api/aix.wiretypes';
import { OpenAIWire_API_Chat_Completions, OpenAIWire_ContentParts, OpenAIWire_Messages } from '../../wiretypes/openai.wiretypes';

import { approxDocPart_To_String } from './anthropic.messageCreate';


//
// OpenAI API - Chat Adapter - Implementation Notes
//
// - only supports N=1, mainly because the whole ecosystem downstream only supports N=1
// - not implemented: top_p, parallel_tool_calls, seed, stop, user
// - fully ignored at the moment: frequency_penalty, presence_penalty, logit_bias, logprobs, top_logprobs, service_tier
// - impedence mismatch: see the notes in the message conversion function for additional decisions, including:
//   - doc parts embedded as markdown text
//   - image parts embedded as base64 data URLs
//   - all tool calls embedded as function calls, and multiple will be batched together
//

// configuration
const hotFixOnlySupportN1 = true;
const hotFixPreferArrayUserContent = true;
const hotFixForceImageContentPartOpenAIDetail: 'auto' | 'low' | 'high' = 'high';
const hotFixSquashTextSeparator = '\n\n\n---\n\n\n';
const approxSystemMessageJoiner = '\n\n---\n\n';


type TRequest = OpenAIWire_API_Chat_Completions.Request;
type TRequestMessages = TRequest['messages'];

export function aixToOpenAIChatCompletions(openAIDialect: OpenAIDialects, model: AixAPI_Model, chatGenerate: AixAPIChatGenerate_Request, jsonOutput: boolean, streaming: boolean): TRequest {

  // Dialect incompatibilities -> Hotfixes
  const hotFixAlternateUserAssistantRoles = openAIDialect === 'deepseek' || openAIDialect === 'perplexity';
  const hotFixRemoveEmptyMessages = openAIDialect === 'perplexity';
  const hotFixRemoveStreamOptions = openAIDialect === 'azure' || openAIDialect === 'mistral';
  const hotFixSquashMultiPartText = openAIDialect === 'deepseek';
  const hotFixThrowCannotFC = openAIDialect === 'openrouter' /* OpenRouter FC support is not good (as of 2024-07-15) */ || openAIDialect === 'perplexity';
  const hotFixVndORIncludeReasoning = openAIDialect === 'openrouter'; // [OpenRouter, 2025-01-24] has a special `include_reasoning` field to show the chain of thought

  // Model incompatibilities -> Hotfixes

  // [OpenAI] - o1 models
  // - o1 models don't support system messages, we could hotfix this here once and for all, but we want to transfer the responsibility to the UI for better messaging to the user
  // - o1 models also use the new 'max_completion_tokens' rather than 'max_tokens', breaking API compatibility, so we have to address it here
  const hotFixOpenAIOFamily = (openAIDialect === 'openai' || openAIDialect === 'azure') && (
    model.id === 'o1' || model.id.startsWith('o1-') ||
    model.id === 'o3' || model.id.startsWith('o3-') ||
    model.id === 'o4' || model.id.startsWith('o4-') ||
    model.id === 'o5' || model.id.startsWith('o5-')
  );

  // Throw if function support is needed but missing
  if (chatGenerate.tools?.length && hotFixThrowCannotFC)
    throw new Error('This service does not support function calls');

  // Convert the chat messages to the OpenAI 4-Messages format
  let chatMessages = _toOpenAIMessages(chatGenerate.systemMessage, chatGenerate.chatSequence, hotFixOpenAIOFamily);

  // Apply hotfixes
  if (hotFixSquashMultiPartText)
    chatMessages = _fixSquashMultiPartText(chatMessages);

  if (hotFixRemoveEmptyMessages)
    chatMessages = _fixRemoveEmptyMessages(chatMessages);

  if (hotFixAlternateUserAssistantRoles)
    chatMessages = _fixAlternateUserAssistantRoles(chatMessages);


  // Construct the request payload
  let payload: TRequest = {
    model: model.id,
    messages: chatMessages,
    tools: chatGenerate.tools && _toOpenAITools(chatGenerate.tools),
    tool_choice: chatGenerate.toolsPolicy && _toOpenAIToolChoice(openAIDialect, chatGenerate.toolsPolicy),
    parallel_tool_calls: undefined,
    max_tokens: model.maxTokens !== undefined ? model.maxTokens : undefined,
    ...(model.temperature !== null ? { temperature: model.temperature !== undefined ? model.temperature : undefined } : {}),
    top_p: undefined,
    n: hotFixOnlySupportN1 ? undefined : 0, // NOTE: we choose to not support this at the API level - most downstram ecosystem supports 1 only, which is the default
    stream: streaming,
    stream_options: streaming ? { include_usage: true } : undefined,
    response_format: jsonOutput ? { type: 'json_object' } : undefined,
    seed: undefined,
    stop: undefined,
    user: undefined,
  };

  // [OpenRouter, 2025-01-24]
  if (hotFixVndORIncludeReasoning)
    payload.include_reasoning = true;

  // Top-P instead of temperature
  if (model.topP !== undefined) {
    delete payload.temperature;
    payload.top_p = model.topP;
  }

  // [OpenAI] Vendor-specific reasoning effort, for o1 models only as of 2024-12-24
  if (model.vndOaiReasoningEffort) {
    payload.reasoning_effort = model.vndOaiReasoningEffort;
  }
  // [OpenAI] Vendor-specific restore markdown, for newer o1 models
  if (model.vndOaiRestoreMarkdown) {
    _fixVndOaiRestoreMarkdown_Inline(payload);
  }
  // [OpenAI] Vendor-specific web search context and/or geolocation
  if (model.vndOaiWebSearchContext || model.userGeolocation) {
    payload.web_search_options = {};
    if (model.vndOaiWebSearchContext)
      payload.web_search_options.search_context_size = model.vndOaiWebSearchContext;
    if (model.userGeolocation)
      payload.web_search_options.user_location = {
        type: 'approximate',
        approximate: {
          ...model.userGeolocation,
        },
      };
  }

  // [xAI] Vendor-specific extensions for Live Search
  if (openAIDialect === 'xai' && model.vndXaiSearchMode && model.vndXaiSearchMode !== 'off') {
    const search_parameters: any = {
      return_citations: true,
    };

    // mode defaults to 'auto' if not specified, so only include if not 'auto'
    if (model.vndXaiSearchMode && model.vndXaiSearchMode !== 'auto')
      search_parameters.mode = model.vndXaiSearchMode;

    if (model.vndXaiSearchSources) {
      const sources = model.vndXaiSearchSources
        .split(',')
        .map(s => s.trim())
        .filter(s => !!s);
      
      // only omit sources if it's the default ('web' and 'x')
      const isDefaultSources = sources.length === 2 && sources.includes('web') && sources.includes('x');
      if (!isDefaultSources)
        search_parameters.sources = sources.map(s => ({ type: s }));
    }

    if (model.vndXaiSearchDateFilter && model.vndXaiSearchDateFilter !== 'unfiltered') {
      const fromDate = _convertSimpleDateFilterToISO(model.vndXaiSearchDateFilter);
      if (fromDate)
        search_parameters.from_date = fromDate;
    }

    payload.search_parameters = search_parameters;
  }

  // [Perplexity] Vendor-specific extensions for search models
  if (openAIDialect === 'perplexity') {
    // Reasoning effort (reuses OpenAI parameter)
    if (model.vndOaiReasoningEffort) {
      payload.reasoning_effort = model.vndOaiReasoningEffort;
    }

    // Search mode (academic filter)
    if (model.vndPerplexitySearchMode && model.vndPerplexitySearchMode !== 'default') {
      payload.search_mode = model.vndPerplexitySearchMode;
    }

    // Date range filter
    if (model.vndPerplexityDateFilter && model.vndPerplexityDateFilter !== 'unfiltered') {
      const filter = _convertPerplexityDateFilter(model.vndPerplexityDateFilter);
      if (filter) payload.search_after_date_filter = filter;
    }
  }

  // [OpenRouter] -> [Anthropic] via OpenAI API - https://openrouter.ai/docs/use-cases/reasoning-tokens
  if (openAIDialect === 'openrouter' && model.vndAntThinkingBudget !== undefined) {

    // vndAntThinkingBudget's presence indicates a user preference:
    // - [x] a number, which is the budget in tokens
    // - [ ] null: shall disable thinking, but openrouter does not support this?
    if (model.vndAntThinkingBudget === null) {
      // simply not setting the reasoning field downgrades this to a non-thinking model
      // console.warn('OpenRouter does not support disabling thinking of Anthropic models. Using default.');
    } else {
      payload.reasoning = {
        max_tokens: model.vndAntThinkingBudget || 1024,
      };
    }
  }

  if (hotFixOpenAIOFamily)
    payload = _fixRequestForOpenAIO1_maxCompletionTokens(payload);

  if (hotFixRemoveStreamOptions)
    payload = _fixRemoveStreamOptions(payload);

  // Preemptive error detection with server-side payload validation before sending it upstream
  const validated = OpenAIWire_API_Chat_Completions.Request_schema.safeParse(payload);
  if (!validated.success) {
    console.warn('OpenAI: invalid chatCompletions payload. Error:', validated.error);
    throw new Error(`Invalid sequence for OpenAI models: ${validated.error.issues?.[0]?.message || validated.error.message || validated.error}.`);
  }

  // if (hotFixUseDeprecatedFunctionCalls)
  //   validated.data = _fixUseDeprecatedFunctionCalls(validated.data);

  return validated.data;
}


function _fixAlternateUserAssistantRoles(chatMessages: TRequestMessages): TRequestMessages {

  // [Perplexity, 2025-06-23] HotFix: if there's only 1 message from the system, treat it as a user message
  if (chatMessages.length === 1 && chatMessages[0].role === 'system')
    return [{ ...chatMessages[0], role: 'user' }];

  // [Perplexity, 2025-06-23] HotFix: if an assistant message comes before the first user message, we prepend an empty user message
  const firstUserIndex = chatMessages.findIndex(message => message.role === 'user');
  const firstAssistantIndex = chatMessages.findIndex(message => message.role === 'assistant');
  if (firstAssistantIndex !== -1 && firstAssistantIndex < firstUserIndex)
    chatMessages.splice(firstAssistantIndex, 0, { role: 'user', content: [{ type: 'text', text: '' }] });

  return chatMessages.reduce((acc, historyItem) => {

    // treat intermediate system messages as user messages
    if (acc.length > 0 && historyItem.role === 'system') {
      historyItem = {
        ...historyItem,
        role: 'user',
      };
    }

    // if the current item has the same role as the last item, concatenate their content
    if (acc.length > 0) {
      const lastItem = acc[acc.length - 1];
      if (lastItem.role === historyItem.role) {
        if (lastItem.role === 'assistant') {
          lastItem.content += hotFixSquashTextSeparator + historyItem.content;
        } else if (lastItem.role === 'user') {
          lastItem.content = [
            ...(Array.isArray(lastItem.content) ? lastItem.content : [OpenAIWire_ContentParts.TextContentPart(lastItem.content)]),
            ...(Array.isArray(historyItem.content) ? historyItem.content : historyItem.content ? [OpenAIWire_ContentParts.TextContentPart(historyItem.content)] : []),
          ];
        }
        return acc;
      }
    }

    // if it's not a case for concatenation, just push the current item to the accumulator
    acc.push(historyItem);
    return acc;
  }, [] as TRequestMessages);
}

function _fixRemoveEmptyMessages(chatMessages: TRequestMessages): TRequestMessages {
  return chatMessages.filter(message => message.content !== null && message.content !== '');
}

function _fixRequestForOpenAIO1_maxCompletionTokens(payload: TRequest): TRequest {

  // Remove temperature and top_p controls
  const { max_tokens, temperature: _removeTemperature, top_p: _removeTopP, ...rest } = payload;

  // Change max_tokens to max_completion_tokens:
  // - pre-o1: max_tokens is the output amount
  // - o1: max_completion_tokens is the output amount + reasoning amount
  if (max_tokens)
    rest.max_completion_tokens = max_tokens;

  return rest;
}

function _fixRemoveStreamOptions(payload: TRequest): TRequest {
  const { stream_options, parallel_tool_calls, ...rest } = payload;
  return rest;
}

function _fixSquashMultiPartText(chatMessages: TRequestMessages): TRequestMessages {
  // Convert multi-part text messages to single strings for older OpenAI dialects
  return chatMessages.reduce((acc, message) => {
    if (message.role === 'user' && Array.isArray(message.content))
      acc.push({ role: message.role, content: message.content.filter(part => part.type === 'text').map(textPart => textPart.text).filter(text => !!text).join(hotFixSquashTextSeparator) });
    else
      acc.push(message);
    return acc;
  }, [] as TRequestMessages);
}

function _fixVndOaiRestoreMarkdown_Inline(payload: TRequest) {

  // OpenAI - https://platform.openai.com/docs/guides/reasoning/advice-on-prompting#advice-on-prompting
  //
  // As of 2025-01-12, OpenAI states: << Markdown formatting: Starting with o1-2024-12-17,
  // o1 models in the API will avoid generating responses with markdown formatting.
  // To signal to the model when you do want markdown formatting in the response,
  // include the string Formatting re-enabled on the first line of your developer message. >>
  //
  // This function prepends "Formatting re-enabled" to the first user message, if not already present
  if (payload.messages?.length) {
    const firstMessage = payload.messages[0];
    const isDevOrSystem = firstMessage.role === 'developer' || firstMessage.role === 'system';

    // update the text of the developer message
    if (isDevOrSystem && firstMessage.content && !firstMessage.content.split('\n')[0].includes('Formatting re-enabled')) {
      firstMessage.content = 'Formatting re-enabled\n' + firstMessage.content;
    }
    // if the developer message is missing, add it altogether
    else if (!isDevOrSystem) {
      // prepend to the first user message
      payload.messages.unshift({ role: 'developer', content: 'Formatting re-enabled' });
    }
  }

}

/*function _fixUseDeprecatedFunctionCalls(payload: OpenaiWire_ChatCompletionRequest): OpenaiWire_ChatCompletionRequest {
  // Hack the request to rename the parameters - without checking or anything - real hack
  const { tools, tool_choice, ...rest } = payload;
  if (tools?.length)
    (rest as any).functions = tools.map(tool => {
      if (tool.type !== 'function')
        throw new Error('Unsupported tool type');
      return { ...tool.function };
    });
  if (tool_choice)
    (rest as any).function_call = tool_choice === 'none' ? 'none' : typeof tool_choice === 'object' ? { name: tool_choice.function.name } : 'auto';
  console.log('HACKED:', rest, tools, tool_choice);
  return rest;
}*/


function _toOpenAIMessages(systemMessage: AixMessages_SystemMessage | null, chatSequence: AixMessages_ChatMessage[], hotFixOpenAIo1Family: boolean): TRequestMessages {

  // Transform the chat messages into OpenAI's format (an array of 'system', 'user', 'assistant', and 'tool' messages)
  const chatMessages: TRequestMessages = [];

  // Convert the system message - single-part stay as-is and multi-part (text or doc) are flattened to a string
  const msg0TextParts: OpenAIWire_ContentParts.TextContentPart[] = [];
  systemMessage?.parts.forEach((part) => {
    switch (part.pt) {
      case 'text':
        msg0TextParts.push(OpenAIWire_ContentParts.TextContentPart(part.text));
        break;

      case 'doc':
        msg0TextParts.push(aixDocPart_to_OpenAITextContent(part));
        break;

      case 'meta_cache_control':
        // ignore this breakpoint hint - Anthropic only
        break;

      default:
        const _exhaustiveCheck: never = part;
        throw new Error(`Unsupported part type in System message: ${(part as any).pt}`);
    }
  });

  // Add the system message
  if (msg0TextParts.length)
    chatMessages.push({
      /**
       * Notes:
       * o1Family in this case is not o1-preview as it's sporting the Sys0ToUsr0 hotfix
       * o3-mini accepts both system and developer roles, and they seem to have the same effects
       */
      role: !hotFixOpenAIo1Family ? 'system' : 'developer',
      content: aixTexts_to_OpenAIInstructionText(msg0TextParts.map(text => text.text)),
    });


  // Convert the messages
  for (const { parts, role } of chatSequence) {
    switch (role) {

      case 'user':
        for (const part of parts) {
          const currentMessage = chatMessages[chatMessages.length - 1];
          switch (part.pt) {

            case 'text':
              const textContentPart = OpenAIWire_ContentParts.TextContentPart(part.text);

              // Append to existing content[], or new message
              if (currentMessage?.role === 'user' && Array.isArray(currentMessage.content))
                currentMessage.content.push(textContentPart);
              else
                chatMessages.push({ role: 'user', content: hotFixPreferArrayUserContent ? [textContentPart] : textContentPart.text });
              break;

            case 'doc':
              const docContentPart = aixDocPart_to_OpenAITextContent(part);

              // Append to existing content[], or new message
              if (currentMessage?.role === 'user' && Array.isArray(currentMessage.content))
                currentMessage.content.push(docContentPart);
              else
                chatMessages.push({ role: 'user', content: hotFixPreferArrayUserContent ? [docContentPart] : docContentPart.text });
              break;

            case 'inline_image':
              // create a new OpenAIWire_ImageContentPart
              const { mimeType, base64 } = part;
              const base64DataUrl = `data:${mimeType};base64,${base64}`;
              const imageContentPart = OpenAIWire_ContentParts.ImageContentPart(base64DataUrl, hotFixForceImageContentPartOpenAIDetail);

              // Append to existing content[], or new message
              if (currentMessage?.role === 'user' && Array.isArray(currentMessage.content))
                currentMessage.content.push(imageContentPart);
              else
                chatMessages.push({ role: 'user', content: [imageContentPart] });
              break;

            case 'meta_cache_control':
              // ignore this breakpoint hint - Anthropic only
              break;

            case 'meta_in_reference_to':
              chatMessages.push({
                role: !hotFixOpenAIo1Family ? 'system' : 'user', // NOTE: o1Family does not support system messages for this, we downcast to 'user'
                content: aixMetaRef_to_OpenAIText(part),
              });
              break;

            default:
              const _exhaustiveCheck: never = part;
              throw new Error(`Unsupported part type in User message: ${(part as any).pt}`);
          }
        }
        break;

      case 'model':
        for (const part of parts) {
          const currentMessage = chatMessages[chatMessages.length - 1];
          switch (part.pt) {

            case 'text':
              // create a new OpenAIWire_AssistantMessage
              chatMessages.push({ role: 'assistant', content: part.text });
              break;

            case 'inline_audio':
              // Implementation notes
              // - audio parts are not supported on the assistant side, but on the user side, so we
              //   create a user part instead

              // create a new OpenAI_AudioContentPart of type User
              const audioFormat = aixAudioPart_to_OpenAIAudioFormat(part);
              const audioBase64DataUrl = `data:${part.mimeType};base64,${part.base64}`;
              const audioContentPart = OpenAIWire_ContentParts.OpenAI_AudioContentPart(audioBase64DataUrl, audioFormat);

              // Append to existing content[], or new message
              if (currentMessage?.role === 'user' && Array.isArray(currentMessage.content))
                currentMessage.content.push(audioContentPart);
              else
                chatMessages.push({ role: 'user', content: [audioContentPart] });
              break;

            case 'inline_image':
              // Implementation notes
              // - image parts are not supported on the assistant side, but on the user side, so we
              //   create a user part instead
              // - we use the 'high' detail level for the image content part (how to expose to the user?)

              // create a new OpenAIWire_ImageContentPart of type User
              const imageBase64DataUrl = `data:${part.mimeType};base64,${part.base64}`;
              const imageContentPart = OpenAIWire_ContentParts.ImageContentPart(imageBase64DataUrl, hotFixForceImageContentPartOpenAIDetail);

              // Append to existing content[], or new message
              if (currentMessage?.role === 'user' && Array.isArray(currentMessage.content))
                currentMessage.content.push(imageContentPart);
              else
                chatMessages.push({ role: 'user', content: [imageContentPart] });
              break;

            case 'tool_invocation':
              // Implementation notes
              // - the assistant called the tool (this is the invocation params) without text beforehand
              // - we will append to an existing assistant message, if there's space for a tool invocation
              // - otherwise we'll add an assistant message with null message

              // create a new OpenAIWire_ToolCall (specialized to function)
              const invocation = part.invocation;
              let toolCallPart;
              switch (invocation.type) {
                case 'function_call':
                  toolCallPart = OpenAIWire_ContentParts.PredictedFunctionCall(part.id, invocation.name, invocation.args || '');
                  break;
                case 'code_execution':
                  toolCallPart = OpenAIWire_ContentParts.PredictedFunctionCall(part.id, 'execute_code' /* suboptimal */, invocation.code || '');
                  break;
                default:
                  const _exhaustiveCheck: never = invocation;
                  throw new Error(`Unsupported tool call type in Model message: ${(part as any).pt}`);
              }

              // Append to existing content[], or new message
              if (currentMessage?.role === 'assistant') {
                if (!Array.isArray(currentMessage.tool_calls))
                  currentMessage.tool_calls = [toolCallPart];
                else
                  currentMessage.tool_calls.push(toolCallPart);
              } else
                chatMessages.push({ role: 'assistant', content: null, tool_calls: [toolCallPart] });
              break;

            case 'ma':
              // ignore this thinking block - Anthropic only
              break;

            case 'meta_cache_control':
              // ignore this breakpoint hint - Anthropic only
              break;

            default:
              const _exhaustiveCheck: never = part;
              throw new Error(`Unsupported part type in Model message: ${(part as any).pt}`);
          }

        }
        break;

      case 'tool':
        for (const part of parts) {
          switch (part.pt) {

            case 'tool_response':
              const toolErrorPrefix = part.error ? (typeof part.error === 'string' ? `[ERROR] ${part.error} - ` : '[ERROR] ') : '';
              if (part.response.type === 'function_call' || part.response.type === 'code_execution')
                chatMessages.push(OpenAIWire_Messages.ToolMessage(part.id, toolErrorPrefix + part.response.result));
              else
                throw new Error(`Unsupported tool response type in Tool message: ${(part as any).pt}`);
              break;

            case 'meta_cache_control':
              // ignore this breakpoint hint - Anthropic only
              break;

            default:
              const _exhaustiveCheck: never = part;
              throw new Error(`Unsupported part type in Tool message: ${(part as any).pt}`);
          }
        }
        break;
    }
  }

  return chatMessages;
}

function _toOpenAITools(itds: AixTools_ToolDefinition[]): NonNullable<TRequest['tools']> {
  return itds.map(itd => {
    const itdType = itd.type;
    switch (itdType) {

      case 'function_call':
        const { name, description, input_schema } = itd.function_call;
        return {
          type: 'function',
          function: {
            name: name,
            description: description,
            parameters: {
              type: 'object',
              properties: input_schema?.properties ?? {},
              required: input_schema?.required,
            },
          },
        };

      case 'code_execution':
        throw new Error('Gemini code interpreter is not supported');

      default:
        // const _exhaustiveCheck: never = itdType;
        throw new Error(`OpenAI (classic API) unsupported tool: ${itdType}`);

    }
  });
}

function _toOpenAIToolChoice(openAIDialect: OpenAIDialects, itp: AixTools_ToolsPolicy): NonNullable<TRequest['tool_choice']> {
  // [Mistral] - supports 'auto', 'none', 'any'
  if (openAIDialect === 'mistral' && itp.type !== 'auto') {
    // Note: we tried adding the 'any' model, but don't feel comfortable with altering our good parsers
    // to allow for Mistral's deviation from the de-facto norm set by the OpenAI protocol.
    throw new Error('We only support automatic tool selection for Mistral models');
  }

  // NOTE: OpenAI has an additional policy 'none', which we don't have as it behaves like passing no tools at all.
  //       Passing no tools is mandated instead of 'none'.
  switch (itp.type) {
    case 'auto':
      return 'auto';
    case 'any':
      return 'required';
    case 'function_call':
      return { type: 'function' as const, function: { name: itp.function_call.name } };
  }
}


// Approximate conversions

export function aixAudioPart_to_OpenAIAudioFormat(part: AixParts_InlineAudioPart) {
  const audioMimeType = part.mimeType;
  switch (audioMimeType) {
    case 'audio/wav':
      return 'wav';
    case 'audio/mp3':
      return 'mp3';
    default:
      const _exhaustiveCheck: never = audioMimeType;
      throw new Error(`Unsupported inline audio format: ${audioMimeType}`);
  }
}

export function aixMetaRef_to_OpenAIText(irt: AixParts_MetaInReferenceToPart): string {
  // Get the item texts without roles
  const items = irt.referTo.map(r => r.mText);
  if (items.length === 0)
    return 'CONTEXT: The user provides no specific references.';

  const isShortItem = (text: string): boolean =>
    text.split('\n').length <= 3 && text.length <= 200;

  const formatItem = (text: string, index?: number): string => {
    if (isShortItem(text)) {
      const formatted = text.replace(/\n/g, ' ').replace(/\s+/g, ' ');
      return index !== undefined ? `${index + 1}. "${formatted}"` : `"${formatted}"`;
    }
    return `${index !== undefined ? `ITEM ${index + 1}:\n` : ''}---\n${text}\n---`;
  };

  // Formerly: `The user is referring to this in particular:\n{{ReplyToText}}`.replace('{{ReplyToText}}', part.replyTo);
  if (items.length === 1)
    return `CONTEXT: The user is referring to this in particular:\n${formatItem(items[0])}`;

  const allShort = items.every(isShortItem);
  return `CONTEXT: The user is referring to these ${items.length} in particular:\n\n${
    items.map((text, index) => formatItem(text, index)).join(allShort ? '\n' : '\n\n')}`;
}

export function aixDocPart_to_OpenAITextContent(part: AixParts_DocPart): OpenAIWire_ContentParts.TextContentPart {

  // Corner case, low probability: if the content is already enclosed in triple-backticks, return it as-is
  if (part.data.text.startsWith('```'))
    return OpenAIWire_ContentParts.TextContentPart(part.data.text);

  return OpenAIWire_ContentParts.TextContentPart(approxDocPart_To_String(part));
}

export function aixTexts_to_OpenAIInstructionText(texts: string[]): string {
  return texts.join(approxSystemMessageJoiner);
}


// Vendor specific extensions

function _convertPerplexityDateFilter(filter: string): string {
  const now = new Date();
  switch (filter) {
    case '1m':
      return new Date(now.getFullYear(), now.getMonth() - 1, now.getDate()).toLocaleDateString('en-US');
    case '3m':
      return new Date(now.getFullYear(), now.getMonth() - 3, now.getDate()).toLocaleDateString('en-US');
    case '6m':
      return new Date(now.getFullYear(), now.getMonth() - 6, now.getDate()).toLocaleDateString('en-US');
    case '1y':
      return new Date(now.getFullYear() - 1, now.getMonth(), now.getDate()).toLocaleDateString('en-US');
    default:
      console.warn('[DEV] Perplexity date filter not recognized:', filter);
      return '';
  }
}

function _convertSimpleDateFilterToISO(filter: '1d' | '1w' | '1m' | '6m' | '1y'): string {
  const now = new Date();
  switch (filter) {
    case '1d':
      now.setDate(now.getDate() - 1);
      break;
    case '1w':
      now.setDate(now.getDate() - 7);
      break;
    case '1m':
      now.setMonth(now.getMonth() - 1);
      break;
    case '6m':
      now.setMonth(now.getMonth() - 6);
      break;
    case '1y':
      now.setFullYear(now.getFullYear() - 1);
      break;
  }
  return now.toISOString().split('T')[0];
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/adapters/openai.responsesCreate.ts
================================================
import { AixAPI_Model, AixAPIChatGenerate_Request, AixMessages_ChatMessage, AixMessages_SystemMessage, AixTools_ToolDefinition, AixTools_ToolsPolicy } from '../../../api/aix.wiretypes';
import { OpenAIWire_API_Responses, OpenAIWire_Responses_Items, OpenAIWire_Responses_Tools } from '../../wiretypes/openai.wiretypes';

import { approxDocPart_To_String } from './anthropic.messageCreate';
import { aixDocPart_to_OpenAITextContent, aixMetaRef_to_OpenAIText, aixTexts_to_OpenAIInstructionText } from '~/modules/aix/server/dispatch/chatGenerate/adapters/openai.chatCompletions';


// configuration
const OPENAI_RESPONSES_DEFAULT_TRUNCATION: TRequest['truncation'] = undefined;


type TRequest = OpenAIWire_API_Responses.Request;
type TRequestInput = OpenAIWire_Responses_Items.InputItem;
type TRequestTool = OpenAIWire_Responses_Tools.Tool;


/**
 * OpenAI Responses request adapter
 *
 * Implementation notes:
 * - much side functionality is not implemented yet
 * - testing with o3-pro only for now
 */
export function aixToOpenAIResponses(model: AixAPI_Model, chatGenerate: AixAPIChatGenerate_Request, jsonOutput: boolean, streaming: boolean): TRequest {

  // [OpenAI] Vendor-specific model checks
  const isOpenAIOFamily = ['o1', 'o3', 'o4', 'o5'].some(m => model.id === m || model.id.startsWith(m + '-'));
  const isOpenAIComputerUse = model.id.includes('computer-use');
  const isOpenAIO1Pro = model.id === 'o1-pro' || model.id.startsWith('o1-pro-');
  const isOpenAIDeepResearch = model.id.includes('-deep-research');

  const hotFixNoTemperature = isOpenAIOFamily;
  const hotFixNoTruncateAuto = isOpenAIComputerUse;
  const hotFixForceSearchTool = isOpenAIDeepResearch;

  // ---
  // construct the request payload
  // NOTE: the zod parsing will remove the undefined values from the upstream request, enabling an easier construction
  // ---

  const { requestInput, requestInstructions } = _toOpenAIResponsesRequestInput(chatGenerate.systemMessage, chatGenerate.chatSequence);
  const payload: TRequest = {

    // Model configuration
    model: model.id,
    max_output_tokens: model.maxTokens ?? undefined, // response if unset: null
    temperature: !hotFixNoTemperature ? model.temperature ?? undefined : undefined,
    // top_p: ... below (alternative to temperature)

    // Input
    instructions: requestInstructions,
    input: requestInput,

    // Tools
    tools: chatGenerate.tools && _toOpenAIResponsesTools(chatGenerate.tools),
    tool_choice: chatGenerate.toolsPolicy && _toOpenAIResponsesToolChoice(chatGenerate.toolsPolicy),
    // parallel_tool_calls: undefined, // response if unset: true

    // Operations Config
    reasoning: !model.vndOaiReasoningEffort ? undefined : {
      effort: model.vndOaiReasoningEffort,
      summary: !isOpenAIO1Pro ? 'detailed' : 'auto', // elevated from 'auto' (o1-pro still at 'auto')
    },

    // Output Config
    // text: ... below

    // API state management
    store: false, // default would be 'true'
    // previous_response_id: undefined,

    // API options
    stream: streaming,
    // background: false, // response if unset: false
    truncation: !hotFixNoTruncateAuto ? OPENAI_RESPONSES_DEFAULT_TRUNCATION : 'auto',
    // user: undefined,

  };

  // "top-p": if present, use instead of temperature
  if (model.topP !== undefined) {
    delete payload.temperature;
    payload.top_p = model.topP;
  }

  // JSON output: not implemented yet - will need a schema definition (similar to the tool args definition)
  if (jsonOutput) {
    console.warn('[DEV] notImplemented: responses: jsonOutput');
    // payload.text = {
    //   format: {
    //     type: 'json_schema',
    //   },
    // };
  }

  // Tool: Search: for search models, and deep research models
  if (hotFixForceSearchTool || model.vndOaiWebSearchContext || model.userGeolocation) {
    if (!payload.tools?.length)
      payload.tools = [];
    const webSearchTool: TRequestTool = {
      type: 'web_search_preview',
      search_context_size: model.vndOaiWebSearchContext ?? undefined,
      user_location: model.userGeolocation && {
        type: 'approximate',
        ...model.userGeolocation, // .city, .country, .region, .timezone
      },
    };
    payload.tools.push(webSearchTool);
  }


  // Preemptive error detection with server-side payload validation before sending it upstream
  // this includes stripping 'undefined' fields
  const validated = OpenAIWire_API_Responses.Request_schema.safeParse(payload);
  if (!validated.success) {
    console.warn('[DEV] OpenAI: invalid Responses request payload. Error:', { error: validated.error });
    throw new Error(`Invalid sequence for OpenAI models: ${validated.error.issues?.[0]?.message || validated.error.message || validated.error}.`);
  }

  return validated.data;
}


function _toOpenAIResponsesRequestInput(systemMessage: AixMessages_SystemMessage | null, chatSequence: AixMessages_ChatMessage[]): { requestInput: TRequestInput[], requestInstructions: TRequest['instructions'] } {

  /**
   * Instructions to the model
   *
   * Single-part texts stay as-is, while multi-part texts or docs are flattened to a string.
   */
  const instructionsParts: string[] = [];
  systemMessage?.parts.forEach((part) => {
    switch (part.pt) {
      case 'text':
        instructionsParts.push(part.text);
        break;

      case 'doc':
        instructionsParts.push(aixDocPart_to_OpenAITextContent(part).text);
        break;

      case 'meta_cache_control':
        // ignore this breakpoint hint - Anthropic only
        break;

      default:
        const _exhaustiveCheck: never = part;
        throw new Error(`Unsupported part type in System message: ${(part as any).pt}`);
    }
  });
  const requestInstructions: TRequest['instructions'] = instructionsParts.length ? aixTexts_to_OpenAIInstructionText(instructionsParts) : undefined;


  // We decide to adopt these schemas for the conversion (API gives us a few choices)
  const chatMessages: (UserMessage | ModelMessage | FunctionCallMessage | FunctionCallOutputMessage)[] = [];
  type UserMessage = Omit<OpenAIWire_Responses_Items.UserItemMessage, 'role'> & { role: 'user' };
  type ModelMessage = Extract<OpenAIWire_Responses_Items.InputMessage_Compat, { role: 'assistant' }>;
  type FunctionCallMessage = OpenAIWire_Responses_Items.OutputFunctionCallItem;
  type FunctionCallOutputMessage = OpenAIWire_Responses_Items.FunctionToolCallOutput;

  function userMessage() {
    // Ensure the last message is a user message, or create a new one
    let lastMessage = chatMessages.length ? chatMessages[chatMessages.length - 1] : undefined;
    if (lastMessage && lastMessage.type === 'message' && lastMessage.role === 'user')
      return lastMessage;
    const newMessage: UserMessage = {
      type: 'message',
      role: 'user',
      content: [],
    };
    chatMessages.push(newMessage);
    return newMessage;
  }

  function modelMessage() {
    // Ensure the last message is a model message, or create a new one
    let lastMessage = chatMessages.length ? chatMessages[chatMessages.length - 1] : undefined;
    if (lastMessage && lastMessage.type === 'message' && lastMessage.role === 'assistant')
      return lastMessage;
    const newMessage: ModelMessage = {
      type: 'message',
      role: 'assistant',
      content: [],
    };
    chatMessages.push(newMessage);
    return newMessage;
  }

  function newFunctionCallMessage(callId: string, functionName: string, functionArguments: string) {
    const newMessage: FunctionCallMessage = {
      type: 'function_call',
      call_id: callId,
      name: functionName,
      arguments: functionArguments,
    };
    chatMessages.push(newMessage);
    return newMessage;
  }

  function newFunctionCallOutputMessage(callId: string, functionOutputJson: string) {
    const newMessage: FunctionCallOutputMessage = {
      type: 'function_call_output',
      call_id: callId,
      output: functionOutputJson,
    };
    chatMessages.push(newMessage);
    return newMessage;
  }

  /**
   * Input Messages
   *
   * Conversion from the AIX input format to the OpenAI Responses Input format is straightforward.
   *
   * - user messages will be converted to the new Input Item format (which doesn't need IDs)
   * - assistant messages to the old Input Message format (which doesn't need IDs)
   *
   */
  for (const { role: messageRole, parts: messageParts } of chatSequence) {

    switch (messageRole) {
      case 'user':
        for (const userPart of messageParts) {
          const uPt = userPart.pt;
          switch (uPt) {

            case 'text':
              userMessage().content.push({
                type: 'input_text',
                text: userPart.text,
              });
              break;

            case 'doc':
              const docText = userPart.data.text.startsWith('```') ? userPart.data.text : approxDocPart_To_String(userPart);
              userMessage().content.push({
                type: 'input_text',
                text: docText,
              });
              break;

            case 'inline_image':
              // create a new OpenAIWire_ImageContentPart
              const { mimeType, base64 } = userPart;
              const base64DataUrl = `data:${mimeType};base64,${base64}`;
              userMessage().content.push({
                type: 'input_image',
                detail: 'high', // TODO: check if user images shall always be 'high' detail
                image_url: base64DataUrl,
              });
              break;

            case 'meta_in_reference_to':
              userMessage().content.push({
                type: 'input_text',
                text: aixMetaRef_to_OpenAIText(userPart),
              });
              break;

            case 'meta_cache_control':
              // ignored - Anthropic only
              break;

            default:
              const _exhaustiveCheck: never = uPt;
              throw new Error(`Unsupported part type in User message: ${uPt}`);
          }
        }
        break;

      case 'model':
        for (const modelPart of messageParts) {
          const mPt = modelPart.pt;
          switch (mPt) {

            case 'text':
              modelMessage().content.push({
                type: 'output_text',
                text: modelPart.text,
              });
              break;

            case 'inline_audio':
              // Workaround for OpenAI Responses API: - TODO: verify if this is still needed
              // - audio (file) parts are not supported on the assistant side, but on the user side, so we upload as user

              // create a new OpenAI_AudioContentPart of type User
              // const audioFormat = _toOpenAIAudioFormat(modelPart);
              const audioBase64DataUrl = `data:${modelPart.mimeType};base64,${modelPart.base64}`;
              userMessage().content.push({
                type: 'input_file',
                file_data: audioBase64DataUrl,
              });
              break;

            case 'inline_image':
              // Workaround: as User part - TODO: verify if this is still needed
              const { mimeType, base64 } = modelPart;
              const base64DataUrl = `data:${mimeType};base64,${base64}`;
              userMessage().content.push({
                type: 'input_image',
                detail: 'high', // TODO: check if model images shall always be 'high' detail
                image_url: base64DataUrl,
              });
              break;

            case 'tool_invocation':
              const invocation = modelPart.invocation;
              const invocationType = invocation.type;
              switch (invocationType) {
                case 'function_call':
                  newFunctionCallMessage(modelPart.id, invocation.name, invocation.args || '');
                  break;
                case 'code_execution':
                  console.warn('[DEV] notImplemented: OpenAI Responses: code execution tool calls');
                  newFunctionCallMessage(modelPart.id, 'execute_code', invocation.code || '');
                  break;
                default:
                  const _exhaustiveCheck: never = invocation;
                  throw new Error(`Unsupported tool call type in Model message: ${mPt}`);
              }
              break;

            case 'ma':
              // TODO: support this in the future - may contain the encrypted reasoning data, although we don't parse this yet
              break;

            case 'meta_cache_control':
              // ignored - Anthropic only
              break;

            default:
              const _exhaustiveCheck: never = mPt;
              throw new Error(`Unsupported part type in Model message: ${mPt}`);
          }
        }
        break;

      case 'tool':
        for (const toolPart of messageParts) {
          const tPt = toolPart.pt;
          switch (tPt) {

            case 'tool_response':
              const toolResponseType = toolPart.response.type;
              switch (toolResponseType) {
                case 'function_call':
                  const { result: functionCallOutput } = toolPart.response;
                  newFunctionCallOutputMessage(toolPart.id, functionCallOutput);
                  break;
                case 'code_execution':
                  const { result: codeExecutionOutput } = toolPart.response;
                  newFunctionCallOutputMessage(toolPart.id, codeExecutionOutput);
                  break;
                default:
                  const _exhaustiveCheck: never = toolResponseType;
                  throw new Error(`Unsupported tool response type in Tool message: ${tPt}/${toolResponseType}`);
              }
              break;

            case 'meta_cache_control':
              // ignored - Anthropic only
              break;

            default:
              const _exhaustiveCheck: never = tPt;
              throw new Error(`Unsupported part type in Tool message: ${tPt}`);
          }
        }
        break;

      default:
        const _exhaustiveCheck: never = messageRole;
        break;
    }
  }

  // return the instruction and input sequence
  return {
    requestInstructions,
    requestInput: chatMessages,
  };
}

function _toOpenAIResponsesTools(itds: AixTools_ToolDefinition[]): NonNullable<TRequestTool[]> {
  return itds.map(itd => {
    const itdType = itd.type;
    switch (itdType) {

      case 'function_call':
        const { name, description, input_schema } = itd.function_call;
        return {
          type: 'function',
          name: name,
          description: description,
          parameters: {
            type: 'object',
            properties: input_schema?.properties ?? {},
            required: input_schema?.required,
          },
        };

      case 'code_execution':
        throw new Error('Gemini code interpreter is not supported');

      default:
        // const _exhaustiveCheck: never = itdType;
        throw new Error(`OpenAI (Responses API) unsupported tool: ${itdType}`);

    }
  });
}

function _toOpenAIResponsesToolChoice(itp: AixTools_ToolsPolicy): NonNullable<TRequest['tool_choice']> {
  // NOTE: we don't support forcing hosted tools yet
  const itpType = itp.type;
  switch (itpType) {
    case 'auto':
      return 'auto';
    case 'any':
      return 'required';
    case 'function_call':
      return { type: 'function' as const, name: itp.function_call.name };
    default:
      const _exhaustiveCheck: never = itpType;
      throw new Error(`Unsupported tools policy type: ${itpType}`);
  }
}




================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/parsers/anthropic.parser.ts
================================================
import { safeErrorString } from '~/server/wire';

import type { AixWire_Particles } from '../../../api/aix.wiretypes';
import type { ChatGenerateParseFunction } from '../chatGenerate.dispatch';
import type { IParticleTransmitter } from '../IParticleTransmitter';
import { IssueSymbols } from '../ChatGenerateTransmitter';

import { AnthropicWire_API_Message_Create } from '../../wiretypes/anthropic.wiretypes';


/**
 * Anthropic Streaming Completions - Messages Architecture
 *
 * Anthropic uses a events-based, chunk-based streaming protocol for its chat completions:
 * 1. 'message_start': Initializes a new message with metadata (id, model, usage) and empty content.
 * 2. 'content_block_start': Begins a new content block (text or tool_use).
 * 3. 'content_block_delta': Streams incremental updates to the current content block.
 * 4. 'content_block_stop': Signals the end of the current content block.
 * 5. 'message_delta': Provides updates to message-level information (e.g., stop_reason, usage).
 * 6. 'message_stop': Indicates the end of the entire message.
 * 7. 'ping': Keepalive event that may occur at any time during the stream.
 * 8. 'error': Communicates errors (e.g., overloaded_error) during streaming.
 *
 * Delta Types:
 * - 'text_delta': Incremental text updates for text blocks.
 * - 'input_json_delta': Partial JSON strings for tool_use inputs.
 *
 * Assumptions:
 * - Content blocks are indexed and streamed sequentially, with no gaps, 'index' is 0-based and reliable.
 * - 'text' parts are incremental and meant to be concatenated via 'text_delta'
 * - 'tool_use' parts are only function calls, and meant to have arguments as an incremental string via 'input_json_delta'
 * - There could be multiple messages, but we only handle 1 at this time, with multiple parts.
 * - Message Deltas will provide a 'stop reason' on the message
 * - Begin/End are explicit
 */
export function createAnthropicMessageParser(): ChatGenerateParseFunction {
  const parserCreationTimestamp = Date.now();
  let responseMessage: AnthropicWire_API_Message_Create.Response;
  let hasErrored = false;
  let timeToFirstEvent: number;
  let messageStartTime: number | undefined = undefined;
  let chatInTokens: number | undefined = undefined;

  return function(pt: IParticleTransmitter, eventData: string, eventName?: string): void {

    // Time to first event
    if (timeToFirstEvent === undefined)
      timeToFirstEvent = Date.now() - parserCreationTimestamp;

    // if we've errored, we should not be receiving more data
    if (hasErrored)
      console.log('Anthropic stream has errored already, but received more data:', eventData);

    switch (eventName) {
      // Ignore pings
      case 'ping':
        break;

      // M1. Initialize the message content for a new message
      case 'message_start':
        messageStartTime = Date.now();
        const isFirstMessage = !responseMessage;
        if (!isFirstMessage)
          throw new Error('Unexpected second message - we only support 1 Antrhopic message at a time');

        // Throws on malformed event data, or even role != 'assistant'
        responseMessage = AnthropicWire_API_Message_Create.event_MessageStart_schema.parse(JSON.parse(eventData)).message;

        // state validation
        if (responseMessage.content.length)
          throw new Error('Unexpected content blocks at message start');
        if (responseMessage.role !== 'assistant')
          throw new Error(`Unexpected role at message start: ${responseMessage.role}`);
        if (!responseMessage.model)
          throw new Error('Model name missing at message start');

        // -> Model
        if (isFirstMessage)
          pt.setModelName(responseMessage.model);
        if (responseMessage.usage) {
          chatInTokens = responseMessage.usage.input_tokens;
          const metricsUpdate: AixWire_Particles.CGSelectMetrics = {
            TIn: chatInTokens,
            TOut: responseMessage.usage.output_tokens,
            dtStart: timeToFirstEvent,
          };
          if (responseMessage.usage.cache_read_input_tokens || responseMessage.usage.cache_creation_input_tokens) {
            if (responseMessage.usage.cache_read_input_tokens !== undefined)
              metricsUpdate.TCacheRead = responseMessage.usage.cache_read_input_tokens;
            if (responseMessage.usage.cache_creation_input_tokens !== undefined)
              metricsUpdate.TCacheWrite = responseMessage.usage.cache_creation_input_tokens;
          }
          pt.updateMetrics(metricsUpdate);
        }
        break;

      // M2. Initialize content block if needed
      case 'content_block_start':
        if (responseMessage) {
          const { index, content_block } = AnthropicWire_API_Message_Create.event_ContentBlockStart_schema.parse(JSON.parse(eventData));
          if (responseMessage.content[index] !== undefined)
            throw new Error(`Unexpected content block start location (${index})`);
          responseMessage.content[index] = content_block;

          switch (content_block.type) {
            case 'text':
              pt.appendText(content_block.text);
              break;

            case 'tool_use':
              // [Anthropic] Note: .input={} and is parsed as an object - if that's the case, we zap it to ''
              if (content_block && typeof content_block.input === 'object' && Object.keys(content_block.input).length === 0)
                content_block.input = null;
              pt.startFunctionCallInvocation(content_block.id, content_block.name, 'incr_str', content_block.input! ?? null);
              break;

            case 'thinking':
              pt.appendReasoningText(content_block.thinking);
              pt.setReasoningSignature(content_block.signature);
              break;

            case 'redacted_thinking':
              pt.addReasoningRedactedData(content_block.data);
              break;

            default:
              const _exhaustiveCheck: never = content_block;
              throw new Error(`Unexpected content block type: ${(content_block as any).type}`);
          }
        } else
          throw new Error('Unexpected content_block_start');
        break;

      // M3+. Append delta text to the current message content
      case 'content_block_delta':
        if (responseMessage) {
          const { index, delta } = AnthropicWire_API_Message_Create.event_ContentBlockDelta_schema.parse(JSON.parse(eventData));
          if (responseMessage.content[index] === undefined)
            throw new Error(`Unexpected content block delta location (${index})`);

          switch (delta.type) {
            case 'text_delta':
              if (responseMessage.content[index].type === 'text') {
                responseMessage.content[index].text += delta.text;
                pt.appendText(delta.text);
              } else
                throw new Error('Unexpected text delta');
              break;

            case 'input_json_delta':
              if (responseMessage.content[index].type === 'tool_use') {
                responseMessage.content[index].input += delta.partial_json;
                pt.appendFunctionCallInvocationArgs(responseMessage.content[index].id, delta.partial_json);
              } else
                throw new Error('Unexpected input_json_delta');
              break;

            case 'thinking_delta':
              if (responseMessage.content[index].type === 'thinking') {
                responseMessage.content[index].thinking += delta.thinking;
                pt.appendReasoningText(delta.thinking);
              } else
                throw new Error('Unexpected thinking delta');
              break;

            case 'signature_delta':
              if (responseMessage.content[index].type === 'thinking') {
                responseMessage.content[index].signature = delta.signature;
                pt.setReasoningSignature(delta.signature);
              } else
                throw new Error('Unexpected signature delta');
              break;

            // note: redacted_thinking doesn't have deltas, only start (with payload) and stop

            default:
              const _exhaustiveCheck: never = delta;
              throw new Error(`Unexpected content block delta type: ${(delta as any).type}`);
          }
        } else
          throw new Error('Unexpected content_block_delta');
        break;

      // Finalize content block if needed.
      case 'content_block_stop':
        if (responseMessage) {
          const { index } = AnthropicWire_API_Message_Create.event_ContentBlockStop_schema.parse(JSON.parse(eventData));
          if (responseMessage.content[index] === undefined)
            throw new Error(`Unexpected content block stop location (${index})`);

          // Signal that the tool is ready? (if it is...)
          pt.endMessagePart();
        } else
          throw new Error('Unexpected content_block_stop');
        break;

      // Optionally handle top-level message changes. Example: updating stop_reason
      case 'message_delta':
        if (responseMessage) {
          const { delta, usage } = AnthropicWire_API_Message_Create.event_MessageDelta_schema.parse(JSON.parse(eventData));

          Object.assign(responseMessage, delta);

          // -> Token Stop Reason
          const tokenStopReason = _fromAnthropicStopReason(delta.stop_reason);
          if (tokenStopReason !== null)
            pt.setTokenStopReason(tokenStopReason);

          if (usage?.output_tokens && messageStartTime) {
            const elapsedTimeMilliseconds = Date.now() - messageStartTime;
            const elapsedTimeSeconds = elapsedTimeMilliseconds / 1000;
            const chatOutRate = elapsedTimeSeconds > 0 ? usage.output_tokens / elapsedTimeSeconds : 0;
            pt.updateMetrics({
              TIn: chatInTokens !== undefined ? chatInTokens : -1,
              TOut: usage.output_tokens,
              vTOutInner: Math.round(chatOutRate * 100) / 100, // Round to 2 decimal places
              dtStart: timeToFirstEvent,
              dtInner: elapsedTimeMilliseconds,
              dtAll: Date.now() - parserCreationTimestamp,
            });
          }
        } else
          throw new Error('Unexpected message_delta');
        break;

      // We can now close the message
      case 'message_stop':
        AnthropicWire_API_Message_Create.event_MessageStop_schema.parse(JSON.parse(eventData));
        return pt.setEnded('done-dialect');

      // UNDOCUMENTED - Occasionaly, the server will send errors, such as {"type": "error", "error": {"type": "overloaded_error", "message": "Overloaded"}}
      case 'error':
        hasErrored = true;
        const { error } = JSON.parse(eventData);
        const errorText = (error.type && error.message) ? `${error.type}: ${error.message}` : safeErrorString(error);
        return pt.setDialectTerminatingIssue(errorText || 'unknown server issue.', IssueSymbols.Generic);

      default:
        throw new Error(`Unexpected event name: ${eventName}`);
    }
  };
}


export function createAnthropicMessageParserNS(): ChatGenerateParseFunction {
  const parserCreationTimestamp = Date.now();

  return function(pt: IParticleTransmitter, fullData: string): void {

    // parse with validation (e.g. type: 'message' && role: 'assistant')
    const {
      model,
      content,
      stop_reason,
      usage,
    } = AnthropicWire_API_Message_Create.Response_schema.parse(JSON.parse(fullData));

    // -> Model
    if (model)
      pt.setModelName(model);

    // -> Content Blocks - Non-Streaming
    for (let i = 0; i < content.length; i++) {
      const contentBlock = content[i];
      const isLastBlock = i === content.length - 1;
      switch (contentBlock.type) {
        case 'thinking':
          pt.appendReasoningText(contentBlock.thinking);
          contentBlock.signature && pt.setReasoningSignature(contentBlock.signature);
          break;

        case 'redacted_thinking':
          pt.addReasoningRedactedData(contentBlock.data);
          break;

        case 'text':
          pt.appendText(contentBlock.text);
          break;

        case 'tool_use':
          // NOTE: this gets parsed as an object, not string deltas of a json!
          pt.startFunctionCallInvocation(contentBlock.id, contentBlock.name, 'json_object', (contentBlock.input as object) || null);
          pt.endMessagePart();
          break;

        default:
          const _exhaustiveCheck: never = contentBlock;
          throw new Error(`Unexpected content block type: ${(contentBlock as any).type}`);
      }
    }

    // -> Token Stop Reason
    const tokenStopReason = _fromAnthropicStopReason(stop_reason);
    if (tokenStopReason !== null)
      pt.setTokenStopReason(tokenStopReason);

    // -> Stats
    if (usage) {
      const elapsedTimeMilliseconds = Date.now() - parserCreationTimestamp;
      // const elapsedTimeSeconds = elapsedTimeMilliseconds / 1000;
      // const chatOutRate = elapsedTimeSeconds > 0 ? usage.output_tokens / elapsedTimeSeconds : 0;
      const metricsUpdate: AixWire_Particles.CGSelectMetrics = {
        TIn: usage.input_tokens,
        TOut: usage.output_tokens,
        // vTOutInner: Math.round(chatOutRate * 100) / 100, // Round to 2 decimal places
        // dtStart: // we don't know
        // dtInner: // we don't know
        dtAll: elapsedTimeMilliseconds,
      };
      if (usage.cache_read_input_tokens || usage.cache_creation_input_tokens) {
        if (usage.cache_read_input_tokens !== undefined)
          metricsUpdate.TCacheRead = usage.cache_read_input_tokens;
        if (usage.cache_creation_input_tokens !== undefined)
          metricsUpdate.TCacheWrite = usage.cache_creation_input_tokens;
      }
      pt.updateMetrics(metricsUpdate);
    }
  };
}


function _fromAnthropicStopReason(stopReason: AnthropicWire_API_Message_Create.Response['stop_reason']) {
  switch (stopReason) {

    case 'end_turn':
    case 'stop_sequence':
      return 'ok';

    case 'tool_use':
      return 'ok-tool_invocations';

    case 'max_tokens':
      return 'out-of-tokens';

    default:
      console.warn(`_fromAnthropicStopReason: unknown stop reason: ${stopReason}`);
      return null;
  }
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/parsers/gemini.audioutils.ts
================================================
interface AudioFormat {
  channels: number;
  sampleRate: number;
  bitsPerSample: number;
}

interface ConvertedAudio {
  mimeType: string;
  base64Data: string;
  durationMs: number;
}


/** Convert Gemini PCM audio to WAV format */
export function geminiConvertPCM2WAV(mimeType: string, base64PCMData: string): ConvertedAudio {
  const format = parseGeminiAudioMimeType(mimeType);
  const pcmBuffer = Buffer.from(base64PCMData, 'base64');

  const wavBuffer = createWAVFromPCM(pcmBuffer, format);
  const durationMs = calculateDurationMs(pcmBuffer.length, format);

  return {
    mimeType: 'audio/wav',
    base64Data: wavBuffer.toString('base64'),
    durationMs,
  };
}


/**
 * Parse Gemini audio MIME type to extract format parameters
 * Example: "audio/L16;codec=pcm;rate=24000" -> { channels: 1, sampleRate: 24000, bitsPerSample: 16 }
 */
function parseGeminiAudioMimeType(mimeType: string): AudioFormat {

  const [baseType, ...params] = mimeType.split(';').map(s => s.trim());

  // Initialize default format
  const format: AudioFormat = {
    channels: 1, // Default to mono
    sampleRate: 24000, // Default for Gemini
    bitsPerSample: 16, // Default
  };

  // Parse format from base type (e.g., "L16" -> 16 bits)
  const [, formatPart] = baseType.split('/');
  if (formatPart?.startsWith('L')) {
    const bits = parseInt(formatPart.slice(1), 10);
    if (!isNaN(bits))
      format.bitsPerSample = bits;
  }

  // Parse parameters
  for (const param of params) {
    const [key, value] = param.split('=').map(s => s.trim());
    switch (key) {
      case 'codec':
        if (value !== 'pcm')
          throw new Error('Unsupported codec: PCM. Gemini audio should be in PCM format.');
        break;
      case 'rate':
        const rate = parseInt(value, 10);
        if (!isNaN(rate)) format.sampleRate = rate;
        break;
      case 'channels':
        const channels = parseInt(value, 10);
        if (!isNaN(channels)) format.channels = channels;
        break;
      default:
        console.warn(`[DEV] geminiConvertPCM2WAV: unknown audio parameter: ${key}=${value}`);
        break;
    }
  }

  return format;
}

/**
 * Create WAV file from raw PCM data
 */
function createWAVFromPCM(pcmData: Buffer, format: AudioFormat): Buffer {
  const { channels, sampleRate, bitsPerSample } = format;

  const byteRate = sampleRate * channels * bitsPerSample / 8;
  const blockAlign = channels * bitsPerSample / 8;
  const dataSize = pcmData.length;
  const fileSize = 36 + dataSize;

  const header = Buffer.alloc(44);

  // RIFF header
  header.write('RIFF', 0);
  header.writeUInt32LE(fileSize, 4);
  header.write('WAVE', 8);

  // fmt chunk
  header.write('fmt ', 12);
  header.writeUInt32LE(16, 16);           // PCM chunk size
  header.writeUInt16LE(1, 20);            // Audio format (1 = PCM)
  header.writeUInt16LE(channels, 22);     // Number of channels
  header.writeUInt32LE(sampleRate, 24);   // Sample rate
  header.writeUInt32LE(byteRate, 28);     // Byte rate
  header.writeUInt16LE(blockAlign, 32);   // Block align
  header.writeUInt16LE(bitsPerSample, 34); // Bits per sample

  // data chunk
  header.write('data', 36);
  header.writeUInt32LE(dataSize, 40);

  return Buffer.concat([header, pcmData]);
}

/** Calculate audio duration in milliseconds */
function calculateDurationMs(dataSize: number, format: AudioFormat): number {
  const { channels, sampleRate, bitsPerSample } = format;
  const bytesPerSample = bitsPerSample / 8;
  const totalSamples = dataSize / (channels * bytesPerSample);
  return Math.round((totalSamples / sampleRate) * 1000);
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/parsers/gemini.parser.ts
================================================
import type { AixWire_Particles } from '../../../api/aix.wiretypes';
import type { ChatGenerateParseFunction } from '../chatGenerate.dispatch';
import type { IParticleTransmitter } from '../IParticleTransmitter';
import { IssueSymbols } from '../ChatGenerateTransmitter';

import { GeminiWire_API_Generate_Content, GeminiWire_Safety } from '../../wiretypes/gemini.wiretypes';

import { geminiConvertPCM2WAV } from './gemini.audioutils';


// configuration
const ENABLE_RECITATIONS_AS_CITATIONS = false;


/**
 * Gemini Completions -  Messages Architecture
 *
 * Will send a single candidate (the API does not support more than 1), which will contain the content parts.
 * There is just a single Part per Candidate, unless the chunk contains parallel function calls, in which case they're in parts.
 *
 * Beginning and End are implicit and follow the natural switching of parts in a progressive order; Gemini may for instance
 * send incremental text parts, then call functions, then send more text parts, which we'll translate to multi parts.
 *
 * Parts assumptions:
 *  - 'text' parts are incremental, and meant to be concatenated
 *  - 'functionCall' are whole
 *  - 'executableCode' are whole
 *  - 'codeExecutionResult' are whole *
 *
 *  Note that non-streaming calls will contain a complete sequence of complete parts.
 */
export function createGeminiGenerateContentResponseParser(requestedModelName: string, isStreaming: boolean): ChatGenerateParseFunction {
  const parserCreationTimestamp = Date.now();
  let sentRequestedModelName = false;
  let sentActualModelName = false;
  let timeToFirstEvent: number;
  let skipComputingTotalsOnce = isStreaming;
  let groundingIndexNumber = 0;

  // this can throw, it's caught by the caller
  return function(pt: IParticleTransmitter, eventData: string): void {

    // Time to first event
    if (timeToFirstEvent === undefined)
      timeToFirstEvent = Date.now() - parserCreationTimestamp;

    // Throws on malformed event data
    const generationChunk = GeminiWire_API_Generate_Content.Response_schema.parse(JSON.parse(eventData));

    // -> Model
    if (generationChunk.modelVersion && !sentActualModelName) {
      pt.setModelName(generationChunk.modelVersion);
      sentActualModelName = true;
    }
    if (!sentActualModelName && !sentRequestedModelName) {
      pt.setModelName(requestedModelName);
      sentRequestedModelName = true;
    }

    // -> Prompt Safety Blocking
    if (generationChunk.promptFeedback?.blockReason) {
      const { blockReason, safetyRatings } = generationChunk.promptFeedback;
      return pt.setDialectTerminatingIssue(`Input not allowed: ${blockReason}: ${_explainGeminiSafetyIssues(safetyRatings)}`, IssueSymbols.PromptBlocked);
    }

    // candidates may be an optional field (started happening on 2024-09-27)
    if (generationChunk.candidates) {

      // expect: single completion
      if (generationChunk.candidates.length !== 1)
        throw new Error(`expected 1 completion, got ${generationChunk.candidates?.length}`);
      const candidate0 = generationChunk.candidates[0];
      if (candidate0.index !== undefined && candidate0.index !== 0)
        throw new Error(`expected completion index 0, got ${candidate0.index}`);

      // -> Candidates[0] -> Content
      for (const mPart of (candidate0.content?.parts || [])) {
        switch (true) {

          // <- TextPart
          case 'text' in mPart:
            // [Gemini, 2025-01-23] CoT support
            if (mPart.thought)
              pt.appendReasoningText(mPart.text || '');
            else
              pt.appendText(mPart.text || '');
            break;

          // <- InlineDataPart
          case 'inlineData' in mPart:
            // [Gemini, 2025-03-14] Experimental Image generation: Response
            if (mPart.inlineData.mimeType.startsWith('image/')) {
              pt.appendImageInline(
                mPart.inlineData.mimeType,
                mPart.inlineData.data,
                'Gemini Generated Image',
                'Gemini',
                '',
              );
            } else if (mPart.inlineData.mimeType.startsWith('audio/')) {
              try {
                // Convert the API response from PCM to WAV: {
                //   "mimeType": "audio/L16;codec=pcm;rate=24000",
                //   "data": "7P/z/wQACg...==" (57,024 bytes)
                // }
                const convertedAudio = geminiConvertPCM2WAV(mPart.inlineData.mimeType, mPart.inlineData.data);
                pt.appendAudioInline(
                  convertedAudio.mimeType,
                  convertedAudio.base64Data,
                  'Gemini Generated Audio',
                  'Gemini',
                  convertedAudio.durationMs,
                );
              } catch (error) {
                console.warn('[Gemini] Failed to convert audio:', error);
                pt.setDialectTerminatingIssue(`Failed to process audio: ${error}`, null);
              }
            } else
              pt.setDialectTerminatingIssue(`Unsupported inline data type: ${mPart.inlineData.mimeType}`, null);
            break;

          // <- FunctionCallPart
          case 'functionCall' in mPart:
            let { id: fcId, name: fcName, args: fcArgs } = mPart.functionCall;
            // Validate the function call arguments - we expect a JSON object, not just any JSON value
            if (!fcArgs || typeof fcArgs !== 'object')
              console.warn(`[Gemini] Invalid function call arguments: ${JSON.stringify(fcArgs)} for ${fcName}`);
            else
              pt.startFunctionCallInvocation(fcId ?? null, fcName, 'json_object', fcArgs);
            pt.endMessagePart();
            break;

          // <- ExecutableCodePart
          case 'executableCode' in mPart:
            pt.addCodeExecutionInvocation(null, mPart.executableCode.language || '', mPart.executableCode.code || '', 'gemini_auto_inline');
            break;

          // <- CodeExecutionResultPart
          case 'codeExecutionResult' in mPart:
            switch (mPart.codeExecutionResult.outcome) {
              case 'OUTCOME_OK':
                pt.addCodeExecutionResponse(null, false, mPart.codeExecutionResult.output || '', 'gemini_auto_inline', 'upstream');
                break;
              case 'OUTCOME_FAILED':
                pt.addCodeExecutionResponse(null, true, mPart.codeExecutionResult.output || '', 'gemini_auto_inline', 'upstream');
                break;
              case 'OUTCOME_DEADLINE_EXCEEDED':
                const deadlineError = 'Code execution deadline exceeded' + (mPart.codeExecutionResult.output ? `: ${mPart.codeExecutionResult.output}` : '');
                pt.addCodeExecutionResponse(null, deadlineError, '', 'gemini_auto_inline', 'upstream');
                break;
              default:
                throw new Error(`unexpected code execution outcome: ${mPart.codeExecutionResult.outcome}`);
            }
            break;

          default:
            // noinspection JSUnusedLocalSymbols
            const _exhaustiveCheck: never = mPart;
            throw new Error(`unexpected content part: ${JSON.stringify(mPart)}`);
        }
      }

      // -> Candidates[0] -> Safety Ratings
      // only parsed when the finish reason is 'SAFETY'

      // -> Candidates[0] -> Citation Metadata
      // this is automated recitation detection by the API, not explicit grounding - very weak signal - as websites appear to be poor quality
      if (ENABLE_RECITATIONS_AS_CITATIONS && candidate0.citationMetadata?.citationSources?.length) {
        for (let { startIndex, endIndex, uri /*, license*/ } of candidate0.citationMetadata.citationSources) {
          // TODO: have a particle/part flag to state the purpose of a citation? (e.g. 'recitation' is weaker than 'grounding')
          pt.appendUrlCitation('', uri || '', undefined, startIndex, endIndex, undefined, undefined);
        }
      }

      // -> Candidates[0] -> Grounding Metadata
      if (candidate0.groundingMetadata?.groundingChunks?.length) {
        /**
         * TODO: improve parsing of grounding metadata, including:
         * - annotations and ranges .groundingSupports
         * - sort chunks by their overal confidence in the .groundingSupports?
         * - follow up Google Search queries (.webSearchQueries)
         * - include the 'renderedContent' from .searchEntryPoint
         */
        for (const { web } of candidate0.groundingMetadata.groundingChunks) {
          pt.appendUrlCitation(web.title, web.uri, ++groundingIndexNumber, undefined, undefined, undefined, undefined);
        }
      }

      // -> Candidates[0] -> Token Stop Reason
      if (candidate0.finishReason) {
        switch (candidate0.finishReason) {
          case 'STOP':
            // this is expected for every fragment up to the end, when it may switch to one of the reasons below in the last packet
            // we cannot assume this signals a good ending, however it will be `pt` to set it to 'ok' if not set to an issue by the end
            break;

          case 'MAX_TOKENS':
            pt.setTokenStopReason('out-of-tokens');
            // NOTE: we call setEnded instread of setDialectTerminatingIssue, because we don't want an extra message appended,
            // as we know that 'out-of-tokens' will likely append a brick wall (simple/universal enough).
            return pt.setEnded('issue-dialect');

          case 'SAFETY':
            pt.setTokenStopReason('filter-content');
            return pt.setDialectTerminatingIssue(`Generation stopped due to SAFETY: ${_explainGeminiSafetyIssues(candidate0.safetyRatings)}`, null);

          case 'RECITATION':
            pt.setTokenStopReason('filter-recitation');
            return pt.setDialectTerminatingIssue(`Generation stopped due to RECITATION`, IssueSymbols.Recitation);

          case 'LANGUAGE':
            pt.setTokenStopReason('filter-content');
            return pt.setDialectTerminatingIssue(`Generation stopped due to LANGUAGE`, IssueSymbols.Language);

          case 'OTHER':
            pt.setTokenStopReason('filter-content');
            return pt.setDialectTerminatingIssue(`Generation stopped due to 'OTHER' (unknown reason)`, null);

          case 'BLOCKLIST':
            pt.setTokenStopReason('filter-content');
            return pt.setDialectTerminatingIssue(`Generation stopped due the content containing forbidden terms`, null);

          case 'PROHIBITED_CONTENT':
            pt.setTokenStopReason('filter-content');
            return pt.setDialectTerminatingIssue(`Generation stopped due to potentially containing prohibited content`, null);

          case 'SPII':
            pt.setTokenStopReason('filter-content');
            return pt.setDialectTerminatingIssue(`Generation stopped due to potentially containing Sensitive Personally Identifiable Information (SPII)`, null);

          case 'MALFORMED_FUNCTION_CALL':
            pt.setTokenStopReason('cg-issue');
            return pt.setDialectTerminatingIssue(`Generation stopped due to the function call generated by the model being invalid`, null);

          case 'IMAGE_SAFETY':
            pt.setTokenStopReason('filter-content');
            return pt.setDialectTerminatingIssue(`Generation stopped due the generated images contain safety violations`, null);

          default:
            throw new Error(`unexpected empty generation (finish reason: ${candidate0?.finishReason})`);
        }
      }
    } /* end of .candidates */

    // -> Stats
    if (generationChunk.usageMetadata) {
      const metricsUpdate: AixWire_Particles.CGSelectMetrics = {
        TIn: generationChunk.usageMetadata.promptTokenCount,
        TOut: generationChunk.usageMetadata.candidatesTokenCount,
      };

      // Add reasoning tokens if available
      if (generationChunk.usageMetadata.thoughtsTokenCount) {
        metricsUpdate.TOutR = generationChunk.usageMetadata.thoughtsTokenCount;
        metricsUpdate.TOut = (metricsUpdate.TOut ?? 0) + metricsUpdate.TOutR; // in gemini candidatesTokenCount does not include reasoning tokens
      }

      // Subtract auto-cached (read) input tokens
      if (generationChunk.usageMetadata.cachedContentTokenCount) {
        metricsUpdate.TCacheRead = generationChunk.usageMetadata.cachedContentTokenCount;
        if ((metricsUpdate.TIn ?? 0) > metricsUpdate.TCacheRead)
          metricsUpdate.TIn = (metricsUpdate.TIn ?? 0) - metricsUpdate.TCacheRead;
      }

      if (isStreaming && timeToFirstEvent !== undefined)
        metricsUpdate.dtStart = timeToFirstEvent;

      // the first end-1 packet will be skipped (when streaming)
      if (!skipComputingTotalsOnce) {
        metricsUpdate.dtAll = Date.now() - parserCreationTimestamp;
        if (!isStreaming && metricsUpdate.dtAll > timeToFirstEvent)
          metricsUpdate.dtInner = metricsUpdate.dtAll - timeToFirstEvent;
        if (isStreaming && metricsUpdate.TOut)
          metricsUpdate.vTOutInner = Math.round(100 * 1000 /*ms/s*/ * metricsUpdate.TOut / (metricsUpdate.dtInner || metricsUpdate.dtAll)) / 100;
      }
      // the second (end) packet will be sent
      skipComputingTotalsOnce = false;

      pt.updateMetrics(metricsUpdate);
    }

  };
}


function _explainGeminiSafetyIssues(safetyRatings?: GeminiWire_Safety.SafetyRating[]): string {
  if (!safetyRatings || !safetyRatings.length)
    return 'no safety ratings provided';
  safetyRatings = (safetyRatings || []).sort(_geminiHarmProbabilitySortFunction);
  // only for non-neglegible probabilities
  return safetyRatings
    .filter(rating => rating.probability !== 'NEGLIGIBLE')
    .map(rating => `${rating.category/*.replace('HARM_CATEGORY_', '')*/} (${rating.probability?.toLowerCase()})`)
    .join(', ') || 'Undocumented Gemini Safety Category.';
}

function _geminiHarmProbabilitySortFunction(a: { probability: string }, b: { probability: string }) {
  const order = ['NEGLIGIBLE', 'LOW', 'MEDIUM', 'HIGH'];
  return order.indexOf(b.probability) - order.indexOf(a.probability);
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/parsers/openai.parser.ts
================================================
import { safeErrorString } from '~/server/wire';
import { serverSideId } from '~/server/trpc/trpc.nanoid';

import type { AixWire_Particles } from '../../../api/aix.wiretypes';
import type { ChatGenerateParseFunction } from '../chatGenerate.dispatch';
import type { IParticleTransmitter } from '../IParticleTransmitter';
import { IssueSymbols } from '../ChatGenerateTransmitter';

import { OpenAIWire_API_Chat_Completions } from '../../wiretypes/openai.wiretypes';


/**
 * OpenAI Streaming Completions -  Messages Architecture
 *
 * OpenAI uses a chunk-based streaming protocol for its chat completions:
 * 1. Each chunk contains a 'choices' array, typically with a single item.
 * 2. The 'delta' field in each choice contains incremental updates to the message.
 * 3. Text content is streamed as string fragments in delta.content.
 * 4. Tool calls (function calls) are streamed incrementally in delta.tool_calls.
 * 5. There may be a final chunk which may contain a 'finish_reason' - but we won't rely on it.
 *
 * Assumptions:
 * - 'text' parts are incremental
 * - 'functionCall' are streamed incrementally, but follow a scheme.
 *    1. the firs delta chunk contains the the full ID and name of the function, and likley empty arguments.
 *    2. Subsequent delta chunks will only contain incremental text for the arguments.
 * - Begin/End: at any point:
 *    - it's either streaming Text or Tool Calls on each chunk
 *    - and there can be multiple chunks for a single completion (e.g. a text chunk and a tool call 1 chunk)
 *    - the temporal order of the chunks implies the beginning/end of a tool call.
 * - There's no explicit end in this data protocol, but it's handled in the caller with a sse:[DONE] event.
 */
export function createOpenAIChatCompletionsChunkParser(): ChatGenerateParseFunction {
  const parserCreationTimestamp = Date.now();
  let hasBegun = false;
  let hasWarned = false;
  let timeToFirstEvent: number | undefined;
  let progressiveCitationNumber = 1;
  // let perplexityAlreadyCited = false;
  let processedSearchResultUrls = new Set<string>();
  // NOTE: could compute rate (tok/s) from the first textful event to the last (to ignore the prefill time)

  // Supporting structure to accumulate the assistant message
  const accumulator: {
    content: string | null;
    tool_calls: {
      id: string;
      type: 'function';
      function: {
        name: string;
        arguments: string | null;
      };
    }[];
  } = {
    content: null,
    tool_calls: [],
  };

  return function(pt: IParticleTransmitter, eventData: string) {

    // Time to first event
    if (timeToFirstEvent === undefined)
      timeToFirstEvent = Date.now() - parserCreationTimestamp;

    // Throws on malformed event data
    // ```Can you extend the Zod chunk response object parsing (all optional) to include the missing data? The following is an exampel of the object I received:```
    const chunkData = JSON.parse(eventData); // this is here just for ease of breakpoint, otherwise it could be inlined

    // [OpenRouter/others] transmits upstream errors pre-parsing (object wouldn't be valid)
    if (_forwardOpenRouterDataError(chunkData, pt))
      return;

    const json = OpenAIWire_API_Chat_Completions.ChunkResponse_schema.parse(chunkData);

    // -> Model
    if (!hasBegun && json.model) {
      hasBegun = true;
      pt.setModelName(json.model);
    }

    // [OpenAI] an upstream error will be handled gracefully and transmitted as text (throw to transmit as 'error')
    if (json.error) {
      return pt.setDialectTerminatingIssue(safeErrorString(json.error) || 'unknown.', IssueSymbols.Generic);
    }

    // [OpenAI] if there's a warning, log it once
    if (json.warning && !hasWarned) {
      hasWarned = true;
      console.log('AIX: OpenAI-dispatch chunk warning:', json.warning);
    }

    // [Azure] we seem to get 'prompt_annotations' or 'prompt_filter_results' objects - which we will ignore to suppress the error
    if (json.id === '' && json.object === '' && json.model === '')
      return;


    // -> Stats
    if (json.usage) {
      const metrics = _fromOpenAIUsage(json.usage, parserCreationTimestamp, timeToFirstEvent);
      if (metrics)
        pt.updateMetrics(metrics);
      // [OpenAI] Expected correct case: the last object has usage, but an empty choices array
      if (!json.choices.length)
        return;
    }
    // [Groq] -> Stats
    // Note: if still in queue, reset the event stats, until we're out of the queue
    if (json.x_groq?.queue_length)
      timeToFirstEvent = undefined;
    if (json.x_groq?.usage) {
      const { prompt_tokens, completion_tokens, completion_time } = json.x_groq.usage;
      const metricsUpdate: AixWire_Particles.CGSelectMetrics = {
        TIn: prompt_tokens,
        TOut: completion_tokens,
        vTOutInner: (completion_tokens && completion_time) ? Math.round((completion_tokens / completion_time) * 100) / 100 : undefined,
        dtInner: Math.round((completion_time || 0) * 1000),
        dtAll: Date.now() - parserCreationTimestamp,
      };
      if (timeToFirstEvent !== undefined)
        metricsUpdate.dtStart = timeToFirstEvent;
      pt.updateMetrics(metricsUpdate);
    }

    // expect: 1 completion, or stop
    if (json.choices.length !== 1)
      throw new Error(`expected 1 completion, got ${json.choices.length}`);


    // [Perplexity] .search_results
    if (json.search_results && Array.isArray(json.search_results)) {

      // Process only new search results
      for (const searchResult of json.search_results) {

        // Incremental processing
        const url = searchResult?.url;
        if (!url || processedSearchResultUrls.has(url))
          continue;
        processedSearchResultUrls.add(url);

        // Append the new citation
        let pubTs: number | undefined;
        if (searchResult.date) {
          const date = new Date(searchResult.date);
          if (!isNaN(date.getTime()))
            pubTs = date.getTime();
        }
        pt.appendUrlCitation(searchResult.title || '', url, progressiveCitationNumber++, undefined, undefined, undefined, pubTs);
      }

    }
    // [Perplexity] .citations (DEPRECATED)
    // if (json.citations && !perplexityAlreadyCited && Array.isArray(json.citations)) {
    //
    //   for (const citationUrl of json.citations)
    //     if (typeof citationUrl === 'string')
    //       pt.appendUrlCitation('', citationUrl, progressiveCitationNumber++, undefined, undefined, undefined);
    //
    //   // Perplexity detection: streaming of full objects, hence we don't re-send the citations at every chunk
    //   if (json.object === 'chat.completion')
    //     perplexityAlreadyCited = true;
    //
    // }


    for (const { index, delta, finish_reason } of json.choices) {

      // n=1 -> single Choice only
      if (index !== 0 && index !== undefined /* [OpenRouter->Gemini] */)
        throw new Error(`expected completion index 0, got ${index}`);

      // handle missing content
      if (!delta)
        throw new Error(`server response missing content (finish_reason: ${finish_reason})`);

      // delta: Reasoning Content [Deepseek, 2025-01-20]
      let deltaHasReasoning = false;
      if (typeof delta.reasoning_content === 'string') {

        pt.appendReasoningText(delta.reasoning_content);
        deltaHasReasoning = true;

      }
      // delta: Reasoning [OpenRouter, 2025-01-24]
      else if (typeof delta.reasoning === 'string') {

        pt.appendReasoningText(delta.reasoning);
        deltaHasReasoning = true;

      }

      // delta: Text
      if (typeof delta.content === 'string' &&
        (!deltaHasReasoning || delta.content) // suppress if reasoning and empty
      ) {

        accumulator.content = (accumulator.content || '') + delta.content;
        pt.appendAutoText_weak(delta.content);

      }
      // 2025-03-26: we don't have the full concurrency combinations of content/reasoning/reasoning_content yet
      // if (delta.content !== undefined && delta.content !== null)
      //   throw new Error(`unexpected delta content type: ${typeof delta.content}`);

      // delta: Tool Calls
      for (const deltaToolCall of (delta.tool_calls || [])) {

        // validation
        if (deltaToolCall.type !== undefined && deltaToolCall.type !== 'function')
          throw new Error(`unexpected tool_call type: ${deltaToolCall.type}`);

        // Creation -  Ensure the tool call exists in our accumulated structure
        const tcIndex = deltaToolCall.index ?? accumulator.tool_calls.length;
        if (!accumulator.tool_calls[tcIndex]) {
          const created = accumulator.tool_calls[tcIndex] = {
            id: deltaToolCall.id || serverSideId('aix-tool-call-id'),
            type: 'function',
            function: {
              name: deltaToolCall.function.name || '',
              arguments: deltaToolCall.function.arguments || '',
            },
          };
          pt.startFunctionCallInvocation(created.id, created.function.name, 'incr_str', created.function.arguments);
          break;
        }

        // Updating arguments
        const accumulatedToolCall = accumulator.tool_calls[tcIndex];

        // Validate
        if (deltaToolCall.id && deltaToolCall.id !== accumulatedToolCall.id)
          throw new Error(`unexpected tool_call id change: ${deltaToolCall.id}`);
        if (deltaToolCall.function.name)
          throw new Error(`unexpected tool_call name change: ${deltaToolCall.function.name}`);

        // It's an arguments update - send it
        if (deltaToolCall.function?.arguments) {
          accumulatedToolCall.function.arguments += deltaToolCall.function.arguments;
          pt.appendFunctionCallInvocationArgs(accumulatedToolCall.id, deltaToolCall.function.arguments);
        }

      } // .choices.tool_calls[]

      // [OpenAI, 2025-03-11] delta: Annotations[].url_citation
      if (delta.annotations !== undefined) {

        if (Array.isArray(delta.annotations)) {
          for (const { type: annotationType, url_citation: urlCitation } of delta.annotations) {
            if (annotationType !== 'url_citation')
              throw new Error(`unexpected annotation type: ${annotationType}`);
            pt.appendUrlCitation(urlCitation.title, urlCitation.url, undefined, urlCitation.start_index, urlCitation.end_index, undefined, undefined);
          }
        } else {
          // we don't abort for this issue - for our users
          console.log('AIX: OpenAI-dispatch: unexpected annotations:', delta.annotations);
        }

      }

      // Token Stop Reason - usually missing in all but the last chunk, but we don't rely on it
      if (finish_reason) {
        const tokenStopReason = _fromOpenAIFinishReason(finish_reason);
        if (tokenStopReason !== null)
          pt.setTokenStopReason(tokenStopReason);
      }

      // Note: not needed anymore - Workaround for implementations that don't send the [DONE] event
      // if (finish_reason === 'max_tokens')
      //   pt.setDialectTerminatingIssue('finish-reason');

    } // .choices[]

  };
}


/// OpenAI non-streaming ChatCompletions

export function createOpenAIChatCompletionsParserNS(): ChatGenerateParseFunction {
  const parserCreationTimestamp = Date.now();
  let progressiveCitationNumber = 1;

  return function(pt: IParticleTransmitter, eventData: string) {

    // Throws on malformed event data
    const completeData = JSON.parse(eventData);

    // [OpenRouter/others] transmits upstream errors pre-parsing (object wouldn't be valid)
    if (_forwardOpenRouterDataError(completeData, pt))
      return;

    // [OpenAI] we don't know yet if warning messages are sent in non-streaming - for now we log
    if (completeData.warning)
      console.log('AIX: OpenAI-dispatch-NS warning:', completeData.warning);

    // Parse the complete response
    const json = OpenAIWire_API_Chat_Completions.Response_schema.parse(completeData);

    // -> Model
    if (json.model)
      pt.setModelName(json.model);

    // -> Stats
    if (json.usage) {
      const metrics = _fromOpenAIUsage(json.usage, parserCreationTimestamp, undefined);
      if (metrics)
        pt.updateMetrics(metrics);
    }

    // Assumption/validate: expect 1 completion, or stop
    if (json.choices.length !== 1)
      throw new Error(`expected 1 completion, got ${json.choices.length}`);

    for (const { index, message, finish_reason } of json.choices) {

      // n=1 -> single Choice only
      if (index !== 0)
        throw new Error(`expected completion index 0, got ${index}`);

      // handle missing content
      if (!message)
        throw new Error(`server response missing content (finish_reason: ${finish_reason})`);

      // message: Text
      if (typeof message.content === 'string') {
        if (message.content) {
          // we will return the EXACT content for non-streaming calls, hence we don't call `appendAutoText_weak` here
          pt.appendText(message.content);
        }
      } else if (message.content !== undefined && message.content !== null)
        throw new Error(`unexpected message content type: ${typeof message.content}`);

      // [OpenRouter, 2025-06-05] Handle reasoning field from OpenRouter
      if (typeof message.reasoning === 'string')
        pt.appendReasoningText(message.reasoning);

      // message: Tool Calls
      for (const toolCall of (message.tool_calls || [])) {

        // [Mistral] we had to relax the parser to miss type: 'function', as Mistral does not generate it
        // Note that we relaxed the
        const mayBeMistral = toolCall.type === undefined;

        if (toolCall.type !== 'function' && !mayBeMistral)
          throw new Error(`unexpected tool_call type: ${toolCall.type}`);
        pt.startFunctionCallInvocation(toolCall.id, toolCall.function.name, 'incr_str', toolCall.function.arguments);
        pt.endMessagePart();
      } // .choices.tool_calls[]

      // Token Stop Reason - expected to be set
      const tokenStopReason = _fromOpenAIFinishReason(finish_reason);
      if (tokenStopReason !== null)
        pt.setTokenStopReason(tokenStopReason);

      // [OpenAI, 2025-03-11] message: Annotations[].url_citation
      if (message.annotations !== undefined) {

        if (Array.isArray(message.annotations)) {
          for (const { type: annotationType, url_citation: urlCitation } of message.annotations) {
            if (annotationType !== 'url_citation')
              throw new Error(`unexpected annotation type: ${annotationType}`);
            pt.appendUrlCitation(urlCitation.title, urlCitation.url, undefined, urlCitation.start_index, urlCitation.end_index, undefined, undefined);
          }
        } else {
          // we don't abort for this issue
          console.log('AIX: OpenAI-dispatch-NS unexpected annotations:', message.annotations);
        }

      }

    } // .choices[]

    // [Perplexity] .search_results
    if (json.search_results && Array.isArray(json.search_results)) {

      for (const searchResult of json.search_results) {
        const url = searchResult?.url;
        if (url) {
          // Append the new citation
          let pubTs: number | undefined;
          if (searchResult.date) {
            const date = new Date(searchResult.date);
            if (!isNaN(date.getTime()))
              pubTs = date.getTime();
          }
          pt.appendUrlCitation(searchResult.title || '', url, progressiveCitationNumber++, undefined, undefined, undefined, pubTs);
        }
      }

    }
    // [Perplexity] .citations (DEPRECATED)
    // if (json.citations && Array.isArray(json.citations)) {
    //
    //   for (const citationUrl of json.citations)
    //     if (typeof citationUrl === 'string')
    //       pt.appendUrlCitation('', citationUrl, progressiveCitationNumber++, undefined, undefined, undefined);
    //
    // }

  };
}


function _fromOpenAIFinishReason(finish_reason: string | null | undefined) {
  // expected: can be missing or nullified in certain cases - both for the streaming and non-streaming versions
  if (!finish_reason)
    return null;
  switch (finish_reason) {

    // [OpenAI] normal reach of a stop condition
    case 'stop':
    case 'stop_sequence': // [OpenRouter] Anthropic Claude 1
    case 'end_turn': // [OpenRouter] Anthropic Claude 3.5 backend
    case 'COMPLETE': // [OpenRouter] Command R+
    case 'eos': // [OpenRouter] Phind: CodeLlama
      return 'ok';

    // [OpenAI] finished due to requesting tool+ to be called
    case 'tool_calls':
      return 'ok-tool_invocations';

    // [OpenAI] broken due to reaching the max tokens limit
    case 'length':
      return 'out-of-tokens';

    // [OpenAI] broken due to filtering
    case 'content_filter':
      return 'filter-content';
  }

  // Developers: show more finish reasons (not under flag for now, so we can add to the supported set)
  console.log('AIX: OpenAI-dispatch unexpected finish_reason:', finish_reason);
  return null;
}

function _fromOpenAIUsage(usage: OpenAIWire_API_Chat_Completions.Response['usage'], parserCreationTimestamp: number, timeToFirstEvent: number | undefined) {

  // -> Stats only in some packages
  if (!usage)
    return undefined;

  // Require at least the completion tokens, or issue a DEV warning otherwise
  if (usage.completion_tokens === undefined) {
    // Warn, so we may adjust this usage parsing for Non-OpenAI APIs
    console.log('[DEV] AIX: OpenAI-dispatch missing completion tokens in usage', { usage });
    return undefined;
  }

  // Create the metrics update object
  const metricsUpdate: AixWire_Particles.CGSelectMetrics = {
    TIn: usage.prompt_tokens ?? undefined,
    TOut: usage.completion_tokens,
    // dtInner: openAI is not reporting the time as seen by the servers
    dtAll: Date.now() - parserCreationTimestamp,
  };

  // Input Metrics

  // Input redistribution: Cache Read
  if (usage.prompt_tokens_details) {
    const TCacheRead = usage.prompt_tokens_details.cached_tokens;
    if (TCacheRead !== undefined && TCacheRead > 0) {
      metricsUpdate.TCacheRead = TCacheRead;
      if (metricsUpdate.TIn !== undefined)
        metricsUpdate.TIn -= TCacheRead;
    }
  }

  // [DeepSeek] Input redistribution: Cache Read
  if (usage.prompt_cache_hit_tokens !== undefined) {
    const TCacheRead = usage.prompt_cache_hit_tokens;
    if (TCacheRead > 0) {
      metricsUpdate.TCacheRead = TCacheRead;
      if (usage.prompt_cache_miss_tokens !== undefined)
        metricsUpdate.TIn = usage.prompt_cache_miss_tokens;
    }
  }

  // TODO Input redistribution: Audio tokens

  // Output Metrics

  // Output breakdown: Reasoning
  if (usage.completion_tokens_details) {
    const details = usage.completion_tokens_details || {};
    if (details.reasoning_tokens !== undefined)
      metricsUpdate.TOutR = usage.completion_tokens_details.reasoning_tokens;
  }

  // TODO: Output breakdown: Audio

  // Time Metrics

  if (timeToFirstEvent !== undefined)
    metricsUpdate.dtStart = timeToFirstEvent;

  return metricsUpdate;
}

/**
 * If there's an error in the pre-decoded message, push it down to the particle transmitter.
 */
function _forwardOpenRouterDataError(parsedData: any, pt: IParticleTransmitter) {

  // operate on .error
  if (!parsedData || !parsedData.error) return false;
  const { error } = parsedData;

  // require .message/.code to consider this a valid error object
  if (!(typeof error === 'object') || !('message' in error) || !('code' in error)) {
    console.log('AIX: OpenAI-dispatch ignored error:', { error });
    return false;
  }

  // prepare the text message
  let errorMessage = safeErrorString(error) || 'unknown.';

  // [OpenRouter] we may have a more specific error message inside the 'metadata' field
  if ('metadata' in error && typeof error.metadata === 'object') {
    const { metadata } = error;
    if ('provider_name' in metadata && 'raw' in metadata)
      errorMessage += ` -- cause: ${safeErrorString(metadata.provider_name)} error: ${safeErrorString(metadata.raw)}`;
    else
      errorMessage += ` -- cause: ${safeErrorString(metadata)}`;
  }

  // Transmit the error as text - note: throw if you want to transmit as 'error'
  pt.setDialectTerminatingIssue(errorMessage, IssueSymbols.Generic);
  return true;
}



================================================
FILE: src/modules/aix/server/dispatch/chatGenerate/parsers/openai.responses.parser.ts
================================================
import { safeErrorString } from '~/server/wire';

import type { AixWire_Particles } from '../../../api/aix.wiretypes';
import type { ChatGenerateParseFunction } from '../chatGenerate.dispatch';
import type { IParticleTransmitter } from '../IParticleTransmitter';
import { IssueSymbols } from '../ChatGenerateTransmitter';

import { OpenAIWire_API_Responses } from '../../wiretypes/openai.wiretypes';


// configuration
const OPENAI_RESPONSES_DEBUG_EVENT_SEQUENCE = false; // true: shows the sequence of events
const OPENAI_RESPONSES_SAME_PART_SPACER = '\n\n'; // true: shows the sequence of events


type TResponse = OpenAIWire_API_Responses.Response;
type TOutputItem = OpenAIWire_API_Responses.Response['output'][number];
type TEventType = OpenAIWire_API_Responses.StreamingEvent['type'];


/**
 * We need this just to ensure events are not out of order, as out streaming is progressive
 * and ordered part-by-part.
 *
 * Very simple, just checks for orders, indices, allowed operations.
 */
class ResponseParserStateMachine {

  // timings
  public parserCreationTimestamp = Date.now();
  public timeToFirstEvent: number | undefined; // time to the first event, in ms

  // low-level verifications
  #sequenceNumber: number = 0;
  #expectedEvents: TEventType[] | undefined;

  // most recently updated response object
  #response: TResponse | undefined;

  // outer index pointing at 'message', 'reasoning' and 'function_call'
  #inOutputIndex: number | undefined; // index of the output item being processed
  #inOutputType: TOutputItem['type'] | undefined; // type of the output item being processed

  // indices of the part within the output item
  #contentIndex: number | undefined; // within 'message' output items
  #contentAddSpacer: boolean = false; // whether we need to inject a spacer in the content part
  #summaryIndex: number | undefined; // within 'reasoning' output items
  #summaryAddSpacer: boolean = false; // whether we need to inject a spacer in the summary part


  // Validations

  validateSequenceNumber(sequenceNumber: number) {
    // time-to-first-event
    if (this.timeToFirstEvent === undefined)
      this.timeToFirstEvent = Date.now() - this.parserCreationTimestamp;

    if (sequenceNumber !== this.#sequenceNumber)
      console.warn(`[DEV] AIX: OpenAI Responses: sequence mismatch: got ${sequenceNumber}, expected ${this.#sequenceNumber}`);
    this.#sequenceNumber = sequenceNumber + 1;
  }

  validateExpectedEventType(eventType: TEventType) {
    if (!this.#expectedEvents || !this.#expectedEvents.length || this.#expectedEvents.includes(eventType))
      return true;
    console.warn(`[DEV] AIX: OpenAI Responses: unexpected event type: got ${eventType}, expected one of ${this.#expectedEvents.join(', ')}`);
    return false;
  }

  expectEvents(events: TEventType[] | undefined) {
    this.#expectedEvents = (!events || !events.length) ? undefined : events;
  }


  // Response validation

  setResponse(label: string, response: TResponse, excludeFields: string[] = []) {
    if (!this.#response) {
      this.#response = response;
      return false;
    }
    const diff = _warnIfObjectPropertiesDiffer(this.#response, response, excludeFields);
    if (diff)
      console.warn(`[DEV] AIX: ${label}: response differs:`, { diff, excludedFields: excludeFields });
    return !!diff;
  }

  get responseId() {
    return this.#response?.id ?? 'new response';
  }


  // Monotonic indices validation

  outputItemEnter(label: TEventType, outputIndex: number, outputType: TOutputItem['type']) {
    const expectedIndex = outputIndex === 0 ? undefined : outputIndex - 1;
    if (this.#inOutputIndex !== expectedIndex || this.#inOutputType !== undefined)
      console.warn(`[DEV] AIX: ${label} - output item enter index/type mismatch: expected ${expectedIndex}/${outputType}, got ${this.#inOutputIndex}/${this.#inOutputType}`);
    this.#inOutputIndex = outputIndex;
    this.#inOutputType = outputType;
  }

  outputItemExit(label: TEventType, outputIndex: number, outputType: TOutputItem['type']) {
    if (this.#inOutputIndex !== outputIndex || this.#inOutputType !== outputType)
      console.warn(`[DEV] AIX: ${label} - output item exit index/type mismatch: expected ${outputIndex}/${outputType}, got ${this.#inOutputIndex}/${this.#inOutputType}`);
    // this.#inOutputIndex = undefined; // leave the index to increase
    this.#inOutputType = undefined;
  }

  outputItemVisit(label: TEventType, outputIndex: number, outputType: TOutputItem['type']) {
    if (this.#inOutputIndex !== outputIndex || this.#inOutputType !== outputType)
      console.warn(`[DEV] AIX: ${label} - output item visit index/type mismatch: expected ${outputIndex}/${outputType}, got ${this.#inOutputIndex}/${this.#inOutputType}`);
    this.#inOutputIndex = outputIndex;
    this.#inOutputType = outputType;
  }


  contentPartEnter(label: TEventType, outputIndex: number, contentIndex: number) {
    this.outputItemVisit(label, outputIndex, 'message');
    const previousIndex = contentIndex === 0 ? undefined : contentIndex - 1;
    if (this.#contentIndex !== previousIndex)
      console.warn(`[DEV] AIX: ${label} - content index mismatch: expected ${previousIndex}, got ${this.#contentIndex}`);
    this.#contentIndex = contentIndex;
    this.#contentAddSpacer = contentIndex > 0;
  }

  contentPartExit(label: TEventType, outputIndex: number, contentIndex: number) {
    this.outputItemVisit(label, outputIndex, 'message');
    if (this.#contentIndex !== contentIndex)
      console.warn(`[DEV] AIX: ${label} - content index mismatch: expected ${contentIndex}, got ${this.#contentIndex}`);
    this.#contentIndex = contentIndex;
  }

  contentPartVisit(label: TEventType, outputIndex: number, contentIndex: number) {
    this.outputItemVisit(label, outputIndex, 'message');
    if (this.#contentIndex !== contentIndex)
      console.warn(`[DEV] AIX: ${label} - content index mismatch: expected ${contentIndex}, got ${this.#contentIndex}`);
    this.#contentIndex = contentIndex;
  }

  contentPartInjectSpacer() {
    if (!this.#contentAddSpacer) return false;
    this.#contentAddSpacer = false;
    return true;
  }


  summaryPartEnter(label: TEventType, outputIndex: number, summaryIndex: number) {
    this.outputItemVisit(label, outputIndex, 'reasoning');
    const previousIndex = summaryIndex === 0 ? undefined : summaryIndex - 1;
    if (this.#summaryIndex !== previousIndex)
      console.warn(`[DEV] AIX: ${label} - summary index mismatch: expected ${previousIndex}, got ${this.#summaryIndex}`);
    this.#summaryIndex = summaryIndex;
    this.#summaryAddSpacer = summaryIndex > 0;
  }

  summaryPartExit(label: TEventType, outputIndex: number, summaryIndex: number) {
    this.outputItemVisit(label, outputIndex, 'reasoning');
    if (this.#summaryIndex !== summaryIndex)
      console.warn(`[DEV] AIX: ${label} - summary index mismatch: expected ${summaryIndex}, got ${this.#summaryIndex}`);
    this.#summaryIndex = summaryIndex;
  }

  summaryPartVisit(label: TEventType, outputIndex: number, summaryIndex: number) {
    this.outputItemVisit(label, outputIndex, 'reasoning');
    if (this.#summaryIndex !== summaryIndex)
      console.warn(`[DEV] AIX: ${label} - summary index mismatch: expected ${summaryIndex}, got ${this.#summaryIndex}`);
    this.#summaryIndex = summaryIndex;
  }

  summaryPartInjectSpacer() {
    if (!this.#summaryAddSpacer) return false;
    this.#summaryAddSpacer = false;
    return true;
  }

}


/**
 * OpenAI Responses API Streaming Parser
 */
export function createOpenAIResponsesEventParser(): ChatGenerateParseFunction {

  const R = new ResponseParserStateMachine();

  return function(pt: IParticleTransmitter, eventData: string) {

    // throws on malformed event data
    const chunkData = JSON.parse(eventData);

    const event = OpenAIWire_API_Responses.StreamingEvent_schema.parse(chunkData);
    const eventType = event?.type;

    // Validations
    R.validateSequenceNumber(event.sequence_number);
    R.validateExpectedEventType(eventType);

    // Debugging: show the sequence of events
    OPENAI_RESPONSES_DEBUG_EVENT_SEQUENCE && console.log(`response ${R.responseId}: ${eventType}`);

    switch (eventType) {

      // level 1. Lifecycle events

      // 1.1. First event, with the response substrate
      case 'response.created':

        /* This response has the following worth noting:
         * - .id = 'resp_12345'
         *
         * Values set by the API even if unset in the request:
         * - .model = 'model-real-name'
         * - .temperature = 1
         * - .top_p = 1
         * - .tool_choice = 'auto', .tools = []
         * - .truncation = 'disabled'
         *
         * Not useful, still set:
         * - .text = { format: { type: 'text' } }
         * - .usage = null
         * - .metadata = {}
         */
        R.setResponse(eventType, event.response);

        // -> Model
        pt.setModelName(event.response.model);

        // -> TODO: Generation Details:
        //    .created_at, .truncation, .temperature, .top_p, .tool_choice, tool count, text output type
        break;

      case 'response.in_progress':
        // NO CHANGES expected, since 'response.created'
        R.setResponse(eventType, event.response);
        break;

      case 'response.completed':
        // CHANGE of { status, output, usage } expected
        R.setResponse(eventType, event.response, ['status', 'output', 'usage']);

        // -> Status
        // TODO: set the terminating reason?

        // -> Output
        // TODO: verify that we correctly captured all the outputs?

        // -> Usage (incl. dtAll)
        if (event.response.usage) {
          const metrics = _fromResponseUsage(event.response.usage, R.parserCreationTimestamp, R.timeToFirstEvent);
          if (metrics)
            pt.updateMetrics(metrics);
        }
        break;

      case 'response.failed':
      case 'response.incomplete':
        // TODO: We haven't seen one of those events yet; we need to see what happens and parse it!
        console.warn(`[DEV] AIX: FIXME: we got a Response ${eventType}:`);
        R.setResponse(eventType, event.response);
        break;


      // level 2: Output Item events - in our implementation we let them set an index to compare against

      case 'response.output_item.added':
        // expected the beginning of a new output item
        // BLANK item expected, of type 'message', 'reasoning' or 'function_call'
        R.outputItemEnter(eventType, event.output_index, event.item.type);
        break;

      case 'response.output_item.done':
        R.outputItemExit(eventType, event.output_index, event.item.type);

        // FULL ITEM parse
        const doneItem = event.item;
        const doneItemType = doneItem.type;
        switch (doneItemType) {
          case 'message':
            // already parsed incrementally
            break;

          case 'reasoning':
            // already parsed incrementally
            break;

          case 'function_call':
            // -> FC: we parse function calls in full, for convenience
            const {
              // id: fcId,
              call_id: fcCallId,
              arguments: fcArguments,
              name: fcName,
            } = doneItem;
            pt.startFunctionCallInvocation(fcCallId, fcName, 'incr_str', fcArguments);
            break;

          case 'web_search_call':
            // -> WSC: TODO
            console.warn('[DEV] notImplemented: OpenAI Responses: web_search_call', { doneItem });
            break;

          default:
            const _exhaustiveCheck: never = doneItemType;
            break;
        }

        // signal the end of the item
        pt.endMessagePart();
        break;


      // level 3: Output Items have multiple Parts

      // 3.1. Message Items: 'output_text' and 'output_refusal' parts

      case 'response.content_part.added':
        R.contentPartEnter(eventType, event.output_index, event.content_index);
        R.expectEvents(['response.output_text.delta', 'response.output_text.done', 'response.output_text_annotation.added', 'response.output_text.annotation.added', 'response.content_part.done']);
        // nothing else to do, the part is likely empty, and we will incrementally parse it
        break;

      case 'response.content_part.done':
        R.contentPartExit(eventType, event.output_index, event.content_index);
        R.expectEvents(undefined);
        pt.endMessagePart();
        break;

      // 3.2. Summary Items: 'summary_text' parts

      case 'response.reasoning_summary_part.added':
        R.summaryPartEnter(eventType, event.output_index, event.summary_index);
        R.expectEvents(['response.reasoning_summary_text.delta', 'response.reasoning_summary_text.done', 'response.reasoning_summary_part.done']);
        // nothing else to do, the part is likely empty, and we will incrementally parse it
        break;

      case 'response.reasoning_summary_part.done':
        R.summaryPartExit(eventType, event.output_index, event.summary_index);
        R.expectEvents(undefined);
        // nothing to do here, as we parsed the content incrementally already
        break;


      // level 4: Content Part sub-events (shall ensure this is within their added-done, to avoid out of sequence)

      // 4.1 - Content Items

      case 'response.output_text.delta':
        R.contentPartVisit(eventType, event.output_index, event.content_index);
        // .delta: -> append the text content
        pt.appendText(R.contentPartInjectSpacer() ? OPENAI_RESPONSES_SAME_PART_SPACER + event.delta : event.delta);
        break;

      case 'response.output_text.done':
        R.contentPartVisit(eventType, event.output_index, event.content_index);
        // .text: ignore finalized content, we already transmitted all partials
        break;

      case 'response.output_refusal.delta':
      case 'response.output_refusal.done':
        R.contentPartVisit(eventType, event.output_index, event.content_index);
        // .delta: ignore refusal string piece for now
        // .refusal: ignore finalized refusal, we already transmitted all partials
        // FIXME: implement this, if it shows up
        console.log(`[DEV] AIX: OpenAI Responses: ignoring output_refusal event: ${eventType}`, event);
        break;

      // 4.2 - Reasoning Items

      case 'response.reasoning_summary_text.delta':
        R.summaryPartVisit(eventType, event.output_index, event.summary_index);
        // .delta: -> append the reasoning content
        pt.appendReasoningText(R.summaryPartInjectSpacer() ? OPENAI_RESPONSES_SAME_PART_SPACER + event.delta : event.delta);
        break;

      case 'response.reasoning_summary_text.done':
        R.summaryPartVisit(eventType, event.output_index, event.summary_index);
        // .text: ignore finalized content, we already transmitted all partials
        break;

      // case 'response.reasoning.delta':
      //   break;
      // case 'response.reasoning.done':
      //   break;
      // case 'response.reasoning_summary.delta':
      //   break;
      // case 'response.reasoning_summary.done':
      //   break;

      // 4.3 - Function Calls

      case 'response.function_call_arguments.delta':
      case 'response.function_call_arguments.done':
        R.outputItemVisit(eventType, event.output_index, 'function_call');
        // .delta: we parse this at the end
        // .done: we parse this at the end
        break;

      // 1.5 - Error

      case 'error':
        // there are complexities related to parsing this type: the docs suggest a flat structure, but we see nested objects
        // see the explanation on OpenAIWire_API_Responses.ErrorEvent_schema

        const errorCode = safeErrorString(event.error?.type || event.error?.code || event.code) ?? undefined;
        const errorMessage = safeErrorString(event.error?.message || event?.message) ?? undefined;
        const errorParam = safeErrorString(event.error?.param || event?.param) ?? undefined;

        // Transmit the error as text - note: throw if you want to transmit as 'error'
        pt.setDialectTerminatingIssue(`${errorCode || 'Error'}: ${errorMessage || 'unknown.'}${errorParam ? ` (param: ${errorParam})` : ''}`, IssueSymbols.Generic);
        break;

      default:
        // const _exhaustiveCheck: never = eventType;
        // FIXME: if we're here, we prob needed to implement the part
        console.warn('[DEV] AIX: OpenAI Responses: unexpected event type:', eventType);
        break;

    }
  };
}


/**
 * OpenAI Responses API Non-Streaming Parser
 */
export function createOpenAIResponseParserNS(): ChatGenerateParseFunction {

  const parserCreationTimestamp = Date.now();

  return function(pt: IParticleTransmitter, eventData: string) {

    // Throws on malformed event data
    const responseData = JSON.parse(eventData);

    // .error: transmits upstream errors pre-parsing (object wouldn't be valid)
    if (_forwardResponseError(responseData, pt))
      return;

    // [OpenAI] possibly log the warnings to get more insights on the API
    if (responseData.warning)
      console.log('AIX: OpenAI-Response-NS warning:', responseData.warning);

    // full response parsing
    const response = OpenAIWire_API_Responses.Response_schema.parse(responseData);

    // -> Model
    if (response.model)
      pt.setModelName(response.model);

    // -> Usage
    if (response.usage) {
      const metrics = _fromResponseUsage(response.usage, parserCreationTimestamp, undefined);
      if (metrics)
        pt.updateMetrics(metrics);
    }

    // -> Status

    // say it's okay for now
    pt.setTokenStopReason('ok');

    switch (response.status) {
      case 'completed':
        // expected: the response is complete
        break;

      case 'incomplete':
        // pedantic check (.incomplete_details)
        if (response.incomplete_details && typeof response.incomplete_details === 'object') {

          // append the incomplete details as text
          pt.appendText(`**Incomplete response**: the response was incomplete because ${response.incomplete_details?.reason || 'unknown reason'}\n`);
          console.warn('[DEV] AIX: OpenAI-Response-NS response incomplete:', { incomplete_details: response.incomplete_details });

        } else {
          // unexpected: we don't expect to receive lifecycle-partial responses in the non-streaming mode
          console.warn('[DEV] AIX: OpenAI-Response-NS unexpected incomplete response details:', { response });
          // not sure what to parse if we get here?
        }
        break;

      case 'cancelled':
      case 'in_progress':
      case 'queued':
        // unexpected: we don't expect to receive lifecycle-partial responses in the non-streaming mode
        console.warn('[DEV] AIX: OpenAI-Response-NS unexpected response status:', { response });
        // not sure what to parse if we get here?
        break;

      case 'failed':
        // TODO: check the full response for the error
        console.log('[DEV] AIX: OpenAI-Response-NS response failed:', { response });
        break;

      default:
        const _exhaustiveCheck: never = response.status;
        console.warn('[DEV] AIX: OpenAI-Response-NS unexpected response status:', { status: response.status });
        break;
    }

    // -> Output[]
    for (const oItem of response.output) {

      // NOTE: we ignore the status field, as it's partial (only in message, not reasoning)
      //       and wrong (in 'message' items it still shows as 'in_progress' despite being
      //       done in the response)
      // pedantic check on status
      // switch (oItem.status) {
      //   case 'completed':
      //     break;
      //
      //   case 'in_progress':
      //   case 'incomplete':
      //     console.warn('[DEV] AIX: OpenAI-Response-NS unexpected output item status:', oItem.status);
      //     break;
      //
      //   default:
      //     console.warn('[DEV] AIX: OpenAI-Response-NS unexpected output item status:', oItem.status);
      //     break;
      // }

      const oItemType = oItem.type;
      switch (oItemType) {

        // Reasoning contains all the reasoning summaries (if present)
        case 'reasoning':
          const {
            // id: reasoningId,
            summary: reasoningSummary,
            // encrypted_content: reasoningEC,
          } = oItem;

          // pedantic check
          if (!Array.isArray(reasoningSummary)) {
            console.warn('[DEV] AIX: OpenAI-Response-NS unexpected reasoning summary type:', { reasoningSummary });
            break;
          }

          // TODO: implement once we know how this looks like
          for (const item of reasoningSummary) {
            if (!item.text) {
              console.warn('[DEV] AIX: OpenAI-Response-NS unexpected reasoning summary item:', { item });
              continue;
            }
            pt.appendReasoningText(item.text);
          }
          break;

        // Message contains the main 'assistant' response
        case 'message':
          const {
            // id: messageId,
            content: messageContent,
            // role: messageRole,
          } = oItem;

          // pedantic check
          if (!Array.isArray(messageContent)) {
            console.warn('[DEV] AIX: OpenAI-Response-NS unexpected message content type:', { messageContent });
            break;
          }

          // Message
          for (const content of messageContent) {
            const contentType = content.type;
            switch (contentType) {
              case 'output_text':
                pt.appendText(content.text || '');
                break;

              case 'refusal':
                // show in DEV as we don't know how this looks like
                console.log('[DEV] AIX: OpenAI-Response-NS refusal content:', { refusal: content });
                break;

              default:
                const _exhaustiveCheck: never = contentType;
                console.warn('[DEV] AIX: OpenAI-Response-NS unexpected message content type:', contentType);
                break;
            }
          }

          break;

        case 'function_call':
          const {
            id: fcId,
            call_id: fcCallId,
            arguments: fcArguments,
            name: fcName,
          } = oItem;

          // pedantic check (fcId = fcCallId)
          if (fcId !== fcCallId) {
            console.warn('[DEV] AIX: OpenAI-Response-NS unexpected function call ID mismatch:', { fcId, fcCallId });
            break;
          }

          pt.startFunctionCallInvocation(fcCallId, fcName, 'incr_str', fcArguments);
          pt.endMessagePart();
          break;

        case 'web_search_call':
          // -> WSC: TODO
          console.warn('[DEV] notImplemented: OpenAI Responses: web_search_call', { oItem });
          break;

        default:
          const _exhaustiveCheck: never = oItemType;
          console.warn('[DEV] AIX: OpenAI-Response-NS unexpected output item type:', oItemType);
          break;
      }

    } // .output[]

    // -> Status
    // .status: check for the status
    // if (response.status !== 'completed')
    //   console.warn('[DEV] AIX: OpenAI-Response-NS unexpected response status:', { status: response.status });

  };
}


function _fromResponseUsage(usage: OpenAIWire_API_Responses.Response['usage'], parserCreationTimestamp: number, timeToFirstEvent: number | undefined) {

  // -> Stats only in some packages
  if (!usage)
    return undefined;

  // Require at least the completion tokens, or issue a DEV warning otherwise
  if (usage.output_tokens === undefined) {
    // Warn, so we may adjust this usage parsing for Non-OpenAI APIs
    console.log('[DEV] AIX: OpenAI Responses missing completion tokens in usage', { usage });
    return undefined;
  }

  // Create the metrics update object
  const metricsUpdate: AixWire_Particles.CGSelectMetrics = {
    TIn: usage.input_tokens ?? undefined,
    TOut: usage.output_tokens,
    // dtInner: openAI is not reporting the time as seen by the servers
    dtAll: Date.now() - parserCreationTimestamp,
  };

  // Input Metrics

  // Input redistribution: Cache Read
  if (usage.input_tokens_details) {
    const TCacheRead = usage.input_tokens_details.cached_tokens;
    if (TCacheRead !== undefined && TCacheRead > 0) {
      metricsUpdate.TCacheRead = TCacheRead;
      if (metricsUpdate.TIn !== undefined)
        metricsUpdate.TIn -= TCacheRead;
    }
  }

  // TODO Input redistribution: Audio tokens

  // Output Metrics

  // Output breakdown: Reasoning
  if (usage.output_tokens_details) {
    const details = usage.output_tokens_details || {};
    if (details.reasoning_tokens !== undefined)
      metricsUpdate.TOutR = usage.output_tokens_details.reasoning_tokens;
  }

  // TODO: Output breakdown: Audio

  // Time Metrics

  if (timeToFirstEvent !== undefined)
    metricsUpdate.dtStart = timeToFirstEvent;

  return metricsUpdate;
}

/**
 * If there's an error in the pre-decoded message, push it down to the particle transmitter.
 */
function _forwardResponseError(parsedData: any, pt: IParticleTransmitter) {

  // operate on .error
  if (!parsedData || !parsedData.error) return false;
  const { error } = parsedData;

  // require .message/.code to consider this a valid error object
  if (!(typeof error === 'object') || !('message' in error) || !('code' in error)) {
    console.log('[DEV] AIX: OpenAI-Responses-dispatch ignored error:', { error });
    return false;
  }

  // Transmit the error as text - note: throw if you want to transmit as 'error'
  pt.setDialectTerminatingIssue(safeErrorString(error) || 'unknown.', IssueSymbols.Generic);
  return true;
}


// Support functions

/**
 * Generic function to compare two objects and return their differences.
 * Uses JSON.stringify for deep comparison of top-level properties.
 */
function _warnIfObjectPropertiesDiffer(
  a: object,
  b: object,
  excludeFields: string[] = [],
): null | Record<string, { a: any, b: any }> {

  // Get all keys from both objects
  const aKeys = Object.keys(a);
  const bKeys = Object.keys(b);
  const allKeys = new Set([...aKeys, ...bKeys]);

  // Remove excluded fields
  const fieldsToCompare = Array.from(allKeys).filter(key => !excludeFields.includes(key));

  // Compare each property using JSON.stringify for deep comparison
  const diff: Record<string, { a: any, b: any }> = {};

  for (const key of fieldsToCompare) {
    const aValue = (a as any)[key];
    const bValue = (b as any)[key];

    // Deep compare using JSON.stringify
    const aStr = JSON.stringify(aValue);
    const bStr = JSON.stringify(bValue);

    if (aStr !== bStr) {
      diff[key] = { a: aValue, b: bValue };
    }
  }

  return Object.keys(diff).length > 0 ? diff : null;
}



================================================
FILE: src/modules/aix/server/dispatch/wiretypes/anthropic.wiretypes.ts
================================================
import * as z from 'zod/v4';


/**
 * See the latest Anthropic Typescript definitions on:
 * https://github.com/anthropics/anthropic-sdk-typescript/blob/main/src/resources/messages.ts
 *
 * ## Updates
 *
 * ### 2024-10-22
 * - ToolDefinition: added 'cache_control' and 'type' fields
 * - Request.tool_choice: added 'disable_parallel_tool_use'
 * - Request.messages: removed refine() as the sequence can now be not-alternating and starting from non-user
 *
 */
export namespace AnthropicWire_Blocks {

  /// Content parts - Input and Output

  export const _CacheControl_schema = z.object({
    type: z.literal('ephemeral'),
  });

  const _CommonBlock_schema = z.object({
    cache_control: _CacheControl_schema.optional(),
  });

  export const TextBlock_schema = _CommonBlock_schema.extend({
    type: z.literal('text'),
    text: z.string(), // length: 1+
    // citations: z.any().optional(), // 2025-02-24: first seen here, not adding it yet - 3 kinds of this block - TODO: define
  });

  export const ImageBlock_schema = _CommonBlock_schema.extend({
    type: z.literal('image'),
    source: z.object({
      type: z.literal('base64'),
      media_type: z.enum(['image/jpeg', 'image/png', 'image/gif', 'image/webp']),
      data: z.string(),
    }),
  });

  export const ToolUseBlock_schema = _CommonBlock_schema.extend({
    type: z.literal('tool_use'),
    id: z.string(),
    name: z.string(), // length: 1-64
    input: z.any(), // FC args OBJ/STRING? - NOTE: formally an 'object', not any, probably relaxed for Zod parsing, will be checked via code
  });

  export const ToolResultBlock_schema = _CommonBlock_schema.extend({
    type: z.literal('tool_result'),
    tool_use_id: z.string(),
    // NOTE: could be a string too, but we force it to be an array for a better implementation
    content: z.array(z.union([TextBlock_schema, ImageBlock_schema])).optional(), // FC-R response STRING!
    is_error: z.boolean().optional(), // default: false
  });

  export const DocumentBlock_schema = _CommonBlock_schema.extend({
    type: z.literal('document'),
    title: z.string().nullable().optional(), // length: 1-500
    context: z.string().nullable().optional(), // length: 1+
    citations: z.object({ enabled: z.boolean() }).optional(),
    source: z.discriminatedUnion('type', [
      // Base64PDFSource
      z.object({
        type: z.literal('base64'),
        media_type: z.enum(['application/pdf']),
        data: z.string(),
      }),
      // PlainTextSource
      z.object({
        type: z.literal('text'),
        media_type: z.enum(['text/plain']),
        data: z.string(),
      }),
      // ContentBlockSource
      z.object({
        type: z.literal('content'),
        // NOTE: could be a string too, but we force it to be an array for a better implementation
        content: z.array(z.union([TextBlock_schema, ImageBlock_schema])).optional(),
      }),
    ]),
  });

  export const ThinkingBlock_schema = z.object({
    type: z.literal('thinking'),
    thinking: z.string(),
    signature: z.string(),
  });

  export const RedactedThinkingBlock_schema = z.object({
    type: z.literal('redacted_thinking'),
    data: z.string(),
  });

  export function TextBlock(text: string): z.infer<typeof TextBlock_schema> {
    return { type: 'text', text };
  }

  export function ImageBlock(mediaType: 'image/jpeg' | 'image/png' | 'image/gif' | 'image/webp', base64: string): z.infer<typeof ImageBlock_schema> {
    return { type: 'image', source: { type: 'base64', media_type: mediaType, data: base64 } };
  }

  export function ToolUseBlock(id: string, name: string, input: string | null): z.infer<typeof ToolUseBlock_schema> {
    // Anthropic Tool Invocations want the input as object, and will reject 'null' inputs for instance.
    // - ".input: Input should be a valid dictionary" - Anthropic
    // - ".input: Field required" - Anthropic
    // -> we replace 'null' and '', with {}
    return { type: 'tool_use', id, name, input: !input ? {} : JSON.parse(input) /* 2024-11-03: Anthropic requires an object in 'input' */ };
  }

  export function ToolResultBlock(tool_use_id: string, content: z.infer<typeof ToolResultBlock_schema>['content'], is_error?: boolean): z.infer<typeof ToolResultBlock_schema> {
    return { type: 'tool_result', tool_use_id, content: content?.length ? content : undefined, is_error };
  }

  // export function DocumentBase64PDFSourceBlock(mediaType: 'application/pdf', base64: string): z.infer<typeof DocumentBlock_schema> {
  //   // ...
  // }

  // export function DocumentPlainTextSourceBlock(mediaType: 'text/plain', text: string): z.infer<typeof DocumentBlock_schema> {
  //   // ...
  // }

  // export function DocumentContentBlockSourceBlock(content: z.infer<typeof DocumentBlock_schema>['source']['content']): z.infer<typeof DocumentBlock_schema> {
  //   // ...
  // }

  export function ThinkingBlock(thinking: string, signature: string): z.infer<typeof ThinkingBlock_schema> {
    return { type: 'thinking', thinking, signature };
  }

  export function RedactedThinkingBlock(data: string): z.infer<typeof RedactedThinkingBlock_schema> {
    return { type: 'redacted_thinking', data };
  }

  export function blockSetCacheControl(block: z.infer<typeof _CommonBlock_schema>, cacheControl: z.infer<typeof _CacheControl_schema>['type']): void {
    block.cache_control = { type: cacheControl };
  }

}

export namespace AnthropicWire_Messages {

  const _ContentBlockInput_schema = z.discriminatedUnion('type', [
    AnthropicWire_Blocks.TextBlock_schema,
    AnthropicWire_Blocks.ImageBlock_schema,
    AnthropicWire_Blocks.ToolUseBlock_schema,
    AnthropicWire_Blocks.ToolResultBlock_schema,
    AnthropicWire_Blocks.DocumentBlock_schema,
    AnthropicWire_Blocks.ThinkingBlock_schema,
    AnthropicWire_Blocks.RedactedThinkingBlock_schema,
  ]);

  export const MessageInput_schema = z.object({
    role: z.enum(['user', 'assistant']),
    content: z.array(_ContentBlockInput_schema), // NOTE: could be a string, but we force it to be an array
  });

  export const ContentBlockOutput_schema = z.discriminatedUnion('type', [
    AnthropicWire_Blocks.TextBlock_schema,
    AnthropicWire_Blocks.ToolUseBlock_schema,
    AnthropicWire_Blocks.ThinkingBlock_schema,
    AnthropicWire_Blocks.RedactedThinkingBlock_schema,
  ]);

}

export namespace AnthropicWire_Tools {

  const _ToolDefinitionBase_schema = z.object({
    /** This is how the tool will be called by the model and in tool_use blocks. */
    name: z.string(),

    /** 2024-10-22: cache-control can be set on the Tools block as well. We could make use of this instead of the System Instruction blocks for prompts with longer tools. */
    cache_control: AnthropicWire_Blocks._CacheControl_schema.nullish(),
  });

  const _CustomToolDefinition_schema = _ToolDefinitionBase_schema.extend({
    /**
     * Client defined tool (non-built-in).
     * Note: we force the value to be 'custom' although the API would allow for undefined or null as well. For ease
     *       of development, we force the value to be 'custom' to use a discriminating union.
     */
    type: z.literal('custom'),  // .nullable().optional() // see note above

    /**
     * Description of what this tool does. Tool descriptions should be as detailed as possible.
     * The more information that the model has about what the tool is and how to use it, the better it will perform.
     * @see aixFunctionCallSchema
     */
    description: z.string().optional(),

    /**
     * [JSON schema](https://json-schema.org/) for this tool's input.
     *
     * This defines the shape of the `input` that your tool accepts and that the model will provide.
     */
    input_schema: z.object({
      type: z.literal('object'),
      properties: z.json().nullable(), // FC-DEF params schema
      required: z.array(z.string()).optional(), // 2025-02-24: seems to be removed; we may still have this, but it may also be within the 'properties' object
    }),
    // .and(z.record(z.unknown())), // 2025-06-26: removed this - unknown why it was here
  });

  const _ComputerUseTool_20241022_schema = _ToolDefinitionBase_schema.extend({
    type: z.enum(['computer_20241022']),
    name: z.literal('computer'),

    // tool configuration
    display_height_px: z.number().int(),
    display_width_px: z.number().int(),
    display_number: z.number().int().nullable().optional(),
  });

  const _BashTool_20241022_schema = _ToolDefinitionBase_schema.extend({
    type: z.enum(['bash_20241022']),
    name: z.literal('bash'),
  });

  const _TextEditor_20241022_schema = _ToolDefinitionBase_schema.extend({
    type: z.enum(['text_editor_20241022']),
    name: z.literal('str_replace_editor'),
  });

  export const ToolDefinition_schema = z.discriminatedUnion('type', [
    _CustomToolDefinition_schema,
    _ComputerUseTool_20241022_schema,
    _BashTool_20241022_schema,
    _TextEditor_20241022_schema,
  ]);

}


//
// Messages > Create
//
export namespace AnthropicWire_API_Message_Create {

  /// Request

  export type Request = z.infer<typeof Request_schema>;
  export const Request_schema = z.object({
    /**
     * (required) The maximum number of tokens to generate before stopping.
     */
    max_tokens: z.number(),

    /**
     * (required) The model to use for generating the response.
     * See [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.
     */
    model: z.string(),

    /**
     * If you want to include a system prompt, you can use the top-level system parameter — there is no "system" role for input messages in the Messages API.
     */
    system: z.array(AnthropicWire_Blocks.TextBlock_schema).optional(),

    /**
     * (required) Input messages. - operates on alternating user and assistant conversational turns - the first message must always use the user role
     * If the final message uses the assistant role, the response content will continue immediately from the content in that message.
     * This can be used to constrain part of the model's response.
     */
    messages: z.array(AnthropicWire_Messages.MessageInput_schema),
    // 2024-10-22: Removed the refine() method, as this is not a requirement anymore for the API, since October 8th, 2024
    // .refine(
    //   (messages) => {
    //
    //     // Ensure the first message uses the user role
    //     if (messages.length === 0 || messages[0].role !== 'user')
    //       return false;
    //
    //     // Ensure messages alternate between user and assistant roles
    //     for (let i = 1; i < messages.length; i++)
    //       if (messages[i].role === messages[i - 1].role)
    //         return false;
    //
    //     return true;
    //   },
    //   { message: `messages must alternate between User and Assistant roles, starting with the User role` },
    // ),

    /**
     * How the model should use the provided tools. The model can use a specific tool, any available tool, or decide by itself.
     */
    tool_choice: z.union([
      z.object({ type: z.literal('auto'), disable_parallel_tool_use: z.boolean().optional() }),
      z.object({ type: z.literal('any'), disable_parallel_tool_use: z.boolean().optional() }),
      z.object({ type: z.literal('tool'), name: z.string(), disable_parallel_tool_use: z.boolean().optional() }),
    ]).optional(),

    /**
     * (optional) Tools that the model can use to generate the response.
     */
    tools: z.array(AnthropicWire_Tools.ToolDefinition_schema).optional(),

    /**
     * (optional) Metadata to include with the request.
     * user_id: This should be a uuid, hash value, or other opaque identifier.
     */
    metadata: z.object({
      user_id: z.string().optional(),
    }).optional(),

    /**
     * Custom text sequences that will cause the model to stop generating.
     */
    stop_sequences: z.array(z.string()).optional(),

    /**
     * Whether to incrementally stream the response using server-sent events. Default: false
     */
    stream: z.boolean().optional(),

    /**
     * When enabled, responses include thinking content blocks showing Claude's thinking process before the final answer.
     */
    thinking: z.union([
      // Requires a minimum budget of 1,024 tokens and counts towards your max_tokens limit.
      z.object({
        type: z.literal('enabled'),
        budget_tokens: z.number().int(),
      }),
      // having this for completeness, but seems like it's not needed / can be omitted
      z.object({ type: z.literal('disabled') }),
    ]).optional(),

    /**
     * Defaults to 1.0. Ranges from 0.0 to 1.0. Use temperature closer to 0.0 for analytical / multiple choice, and closer to 1.0 for creative and generative tasks.
     */
    temperature: z.number().optional(),

    /**
     * Only sample from the top K options for each subsequent token.
     * Recommended for advanced use cases only. You usually only need to use `temperature`.
     */
    top_k: z.number().optional(),

    /**
     * Use nucleus sampling.
     * Recommended for advanced use cases only. You usually only need to use `temperature`.
     * */
    top_p: z.number().optional(),
  });

  /// Response

  export type Response = z.infer<typeof Response_schema>;
  export const Response_schema = z.object({
    // Unique object identifier.
    id: z.string(),

    // For Messages, this is always "message".
    type: z.literal('message'),
    // Conversational role of the generated message. This will always be "assistant".
    role: z.literal('assistant'),
    // The model that handled the request.
    model: z.string(),

    /**
     * Content generated by the model.
     * This is an array of content blocks, each of which has a type that determines its shape. Currently, the only type in responses is "text".
     */
    content: z.array(AnthropicWire_Messages.ContentBlockOutput_schema),

    /**
     * This may be one the following values:
     *
     * "end_turn": the model reached a natural stopping point
     * "max_tokens": we exceeded the requested max_tokens or the model's maximum
     * "stop_sequence": one of your provided custom stop_sequences was generated
     * Note that these values are different than those in /v1/complete, where end_turn and stop_sequence were not differentiated.
     *
     * In non-streaming mode this value is always non-null. In streaming mode, it is null in the message_start event and non-null otherwise.
     */
    stop_reason: z.enum(['end_turn', 'max_tokens', 'stop_sequence', 'tool_use']).nullable(),
    // Which custom stop sequence was generated, if any.
    stop_sequence: z.string().nullable(),

    // Billing and rate-limit usage.
    usage: z.object({
      input_tokens: z.number(),
      cache_creation_input_tokens: z.number().optional(),
      cache_read_input_tokens: z.number().optional(),
      output_tokens: z.number(),
    }),
  });

  /// Streaming Response

  export const event_MessageStart_schema = z.object({
    type: z.literal('message_start'),
    message: Response_schema,
  });

  export const event_MessageStop_schema = z.object({
    type: z.literal('message_stop'),
  });

  export const event_MessageDelta_schema = z.object({
    type: z.literal('message_delta'),
    // MessageDelta
    delta: z.object({
      stop_reason: z.enum(['end_turn', 'max_tokens', 'stop_sequence', 'tool_use']).nullable(),
      stop_sequence: z.string().nullable(),
    }),
    // MessageDeltaUsage
    usage: z.object({ output_tokens: z.number() }),
  });

  export const event_ContentBlockStart_schema = z.object({
    type: z.literal('content_block_start'),
    index: z.number(),
    content_block: AnthropicWire_Messages.ContentBlockOutput_schema,
  });

  export const event_ContentBlockStop_schema = z.object({
    type: z.literal('content_block_stop'),
    index: z.number(),
  });

  export const event_ContentBlockDelta_schema = z.object({
    type: z.literal('content_block_delta'),
    index: z.number(),
    delta: z.union([
      z.object({
        type: z.literal('text_delta'),
        text: z.string(),
      }),
      z.object({
        type: z.literal('input_json_delta'),
        partial_json: z.string(),
      }),
      z.object({
        type: z.literal('thinking_delta'),
        thinking: z.string(),
      }),
      z.object({
        type: z.literal('signature_delta'),
        signature: z.string(),
      }),
    ]),
  });

}



================================================
FILE: src/modules/aix/server/dispatch/wiretypes/gemini.wiretypes.ts
================================================
import * as z from 'zod/v4';


export namespace GeminiWire_ContentParts {

  // The IANA standard MIME type of the source data. Examples: - image/png - image/jpeg
  // For a complete list of supported types, see Supported file formats:
  // https://ai.google.dev/gemini-api/docs/prompting_with_media?lang=node#supported_file_formats
  const ianaStandardMimeType_schema = z.enum([
    // Image formats
    'image/png',
    'image/jpeg',
    'image/webp',
    'image/heic',
    'image/heif',
    // Audio formats
    'audio/wav',
    'audio/mp3',
    'audio/aiff',
    'audio/aac',
    'audio/ogg',
    'audio/flac',
    // Video formats
    'video/mp4',
    'video/mpeg',
    'video/mov',
    'video/avi',
    'video/x-flv',
    'video/mpg',
    'video/webm',
    'video/wmv',
    'video/3gpp',
    // Plain text formats
    'text/plain',
    'text/html',
    'text/css',
    'text/javascript',
    'application/x-javascript',
    'text/x-typescript',
    'application/x-typescript',
    'text/csv',
    'text/markdown',
    'text/x-python',
    'application/x-python-code',
    'application/json',
    'text/xml',
    'application/rtf',
    'text/rtf',
  ]);

  export const ContentPartModality_enum = z.enum([
    'MODALITY_UNSPECIFIED',
    'TEXT', // plain text
    'IMAGE',
    'VIDEO',
    'AUDIO',
    'DOCUMENT', // e.g. PDF
  ]);

  /// Content parts - Input

  export const TextPart_schema = z.object({
    text: z.string(),
    thought: z.boolean().optional(), // [Gemini, 2025-01-23] CoT support
  });

  const InlineDataPart_schema = z.object({
    inlineData: z.object({
      mimeType: z.union([z.string(), ianaStandardMimeType_schema]),
      data: z.string(), // base64-encoded string
    }),
  });

  export const FunctionCallPart_schema = z.object({
    functionCall: z.object({
      id: z.string().optional(), // if populated, the client to execute the functionCall and return the response with the matching id
      name: z.string(),
      /** The function parameters and values in JSON object format. */
      args: z.json().optional(), // FC args
    }),
  });

  /**
   * The result output from a FunctionCall that contains a string representing the FunctionDeclaration.name
   * and a structured JSON object containing any output from the function is used as context to the model.
   * This should contain the result of a FunctionCall made based on model prediction.
   *
   * NOTE from the online Google docs on 2024-07-20:
   * - The next conversation turn may contain a [FunctionResponse][content.part.function_response] with
   *   the [content.role] "function" generation context for the next model turn.
   *   This is extremely weird, because role should only be 'user' or 'model'. FIXME GOOGLE!
   */
  const FunctionResponsePart_schema = z.object({
    functionResponse: z.object({
      /** The id of the function call this response is for */
      id: z.string().optional(), // populated by the client to match the corresponding function call id.
      /** Corresponds to the related FunctionDeclaration.name */
      name: z.string(),
      /** The function response in JSON object format */
      response: z.json().optional(), // FC-R response

      // -- the following fields are only applicable to NON_BLOCKING function calls

      /** Signals that function call continues, and more responses will be returned, turning the function call into a generator. */
      willContinue: z.boolean().optional(),
      /** Specifies how the response should be scheduled in the conversation */
      scheduling: z.enum([
        'SCHEDULING_UNSPECIFIED', // unused
        'SILENT', // only add the result to the conversation context, do not interrupt or trigger generation
        'WHEN_IDLE', // add the result to the conversation context, and prompt to generate output without interrupting ongoing generation
        'INTERRUPT', // add the result to the conversation context, interrupt ongoing generation and prompt to generate output.
      ]).optional(),
    }),
  });

  const FileDataPart_schema = z.object({
    fileData: z.object({
      mimeType: z.union([z.string(), ianaStandardMimeType_schema]).optional(),
      fileUri: z.string(),
    }),
  });

  export const ExecutableCodePart_schema = z.object({
    executableCode: z.object({
      language: z.enum([
        // /**
        //  * Unspecified language. This value should not be used.
        //  */
        // 'LANGUAGE_UNSPECIFIED',
        /** Python >= 3.10, with numpy and simpy available. */
        'PYTHON',
      ]),
      /** The code to be executed. */
      code: z.string(),
    }),
  });

  export const CodeExecutionResultPart_schema = z.object({
    codeExecutionResult: z.object({
      outcome: z.enum([
        // /**
        //  * Unspecified status. This value should not be used.
        //  */
        // 'OUTCOME_UNSPECIFIED',
        /**
         * Code execution completed successfully.
         */
        'OUTCOME_OK',
        /**
         * Code execution finished but with a failure. stderr should contain the reason.
         */
        'OUTCOME_FAILED',
        /**
         * Code execution ran for too long, and was cancelled. There may or may not be a partial output present.
         */
        'OUTCOME_DEADLINE_EXCEEDED',
      ]),
      /**
       * Contains stdout when code execution is successful, stderr or other description otherwise.
       */
      output: z.string().optional(),
    }),
  });


  /// Content Parts (union of) - (input) request.contents[number].parts

  export type ContentPart = z.infer<typeof ContentPart_schema>;
  export const ContentPart_schema = z.union([
    TextPart_schema,
    InlineDataPart_schema,
    FunctionCallPart_schema,
    FunctionResponsePart_schema,
    FileDataPart_schema,
    ExecutableCodePart_schema,
    CodeExecutionResultPart_schema,
  ]);


  /// Content Parts (union of) - (model output) response.candidates[number].content.parts

  export const ModelContentPart_schema = z.union([
    TextPart_schema,
    InlineDataPart_schema,
    FunctionCallPart_schema,
    ExecutableCodePart_schema,
    CodeExecutionResultPart_schema,
  ]);


  /// Content Parts - Factories

  export function TextPart(text: string): z.infer<typeof TextPart_schema> {
    return { text };
  }

  export function InlineDataPart(mimeType: string, data: string): z.infer<typeof InlineDataPart_schema> {
    return { inlineData: { mimeType, data } };
  }

  export function FunctionCallPart(name: string, args?: Record<string, any>): z.infer<typeof FunctionCallPart_schema> {
    return { functionCall: { name, args } };
  }

  export function FunctionResponsePart(name: string, response?: Record<string, any>): z.infer<typeof FunctionResponsePart_schema> {
    return { functionResponse: { name, response } };
  }

  export function ExecutableCodePart(language: 'PYTHON', code: string): z.infer<typeof ExecutableCodePart_schema> {
    return { executableCode: { language, code } };
  }

  export function CodeExecutionResultPart(outcome: 'OUTCOME_OK' | 'OUTCOME_FAILED' | 'OUTCOME_DEADLINE_EXCEEDED', output?: string): z.infer<typeof CodeExecutionResultPart_schema> {
    return { codeExecutionResult: { outcome, output } };
  }

}

export namespace GeminiWire_Messages {

  /// System Instruction

  export const SystemInstruction_schema = z.object({
    // Note: should be 'contents' object, but since it's text-only, we cast it down with a custom definition
    parts: z.array(GeminiWire_ContentParts.TextPart_schema),
  });

  // Content - request.contents[]

  export type Content = z.infer<typeof Content_schema>;
  export const Content_schema = z.object({
    // Must be either 'user' or 'model'. Optional but must be set if there are multiple "Content" objects in the parent array.
    role: z.enum(['user', 'model']).optional(),
    // Ordered Parts that constitute a single message. Parts may have different MIME types.
    parts: z.array(GeminiWire_ContentParts.ContentPart_schema),
  });

  // Model Content - response.candidates[number].content

  export const ModelContent_schema = Content_schema.extend({
    role: z.literal('model')
      .or(z.literal('MODEL')) // [Gemini]: 2024-10-29: code execution seems to return .role='MODEL' instead of 'model' when .parts=[codeExecutionResult]
      .optional(), // 2025-01-10: added because sometimes gemini sends the empty `{"candidates": [{"content": {}, ...` just for the finishreason
    // 'Model' generated contents are of fewer types compared to the ContentParts, which represent also user objects
    parts: z.array(GeminiWire_ContentParts.ModelContentPart_schema)
      .optional(), // 2025-01-10: added because sometimes gemini sends the empty `{"candidates": [{"content": {}, ...` just for the finishreason
  });

  // export const UserMessage_schema = Content_schema.extend({
  //   role: z.literal('user'),
  // });

}

export namespace GeminiWire_ToolDeclarations {

  /// Tool definitions - Input

  const CodeExecution_schema = z.object({
    // This type has no fields.
    // Tool that executes code generated by the model, and automatically returns the result to the model.
    // See also ExecutableCode and CodeExecutionResult which are only generated when using this tool.
  });

  export type FunctionDeclaration = z.infer<typeof FunctionDeclaration_schema>;
  export const FunctionDeclaration_schema = z.object({
    name: z.string(),
    description: z.string(),

    /**
     *  Subset of OpenAPI 3.0 schema object
     *  https://ai.google.dev/api/rest/v1beta/cachedContents#schema
     *  Here we relax the check.
     */
    parameters: z.object({
      type: z.literal('object'),
      /**
       * For stricter validation, use the OpenAPI_Schema.Object_schema
       */
      properties: z.json().optional(), // FC-DEF params schema
      required: z.array(z.string()).optional(),
    }).optional(),

    /**
     * The Schema defines the type used for the 'future' response value of the function.
     * JSON Schema output format (per-function). Reflects the Open API 3.03 Response Object.
     */
    response: z.json().optional(), // FC-DEF output schema

    /** Specifies the function Behavior. Currently only supported by the BidiGenerateContent method. */
    behavior: z.enum([
      'UNSPECIFIED', // unused
      'BLOCKING', // if set, the system will wait to receive the function response before continuing the conversation
      'NON_BLOCKING', // if set, the system will attempt to handle function responses as they become available while maintaining the conversation between the user and the model
    ]).optional(),
  });

  const GoogleSearch_schema = z.object({
    // Empty object in the API definition
  });

  // 2025-03-14: Gemini has de-facto phased out GoogleSearchRetrieval, there's no more
  const GoogleSearchRetrieval_schema = z.object({
    dynamicRetrievalConfig: z.object({
      /** The mode of the predictor to be used in dynamic retrieval. */
      mode: z.enum(['MODE_UNSPECIFIED', 'MODE_DYNAMIC']),
      /** The threshold to be used in dynamic retrieval. If not set, a system default value is used. */
      dynamicThreshold: z.number().optional(),
    }).optional(),
  });

  export const Tool_schema = z.object({
    codeExecution: CodeExecution_schema.optional(),
    functionDeclarations: z.array(FunctionDeclaration_schema).optional(),
    googleSearch: GoogleSearch_schema.optional(),
    // 2025-03-14: disabled as it's gone for all models
    googleSearchRetrieval: GoogleSearchRetrieval_schema.optional(),
  });

  export const ToolConfig_schema = z.object({
    functionCallingConfig: z.object({
      mode: z.enum([
        // /**
        //  * Unspecified function calling mode. This value should not be used.
        //  */
        // 'MODE_UNSPECIFIED',
        /**
         * (default) The model decides to predict either a function call or a natural language response.
         */
        'AUTO',
        /**
         * The model is constrained to always predict a function call.
         * If allowed_function_names is provided, the model picks from the set of allowed functions.
         * Also used to force a specific function by setting allowed_function_names to a single function name.
         */
        'ANY',
        /**
         * The model behavior is the same as if you don't pass any function declarations.
         */
        'NONE',
      ]).optional(),
      allowedFunctionNames: z.array(z.string()).optional(),
    }).optional(),
  });

}

export namespace GeminiWire_Safety {

  /// Safety Rating

  export const HarmCategory_enum = z.enum([
    'HARM_CATEGORY_UNSPECIFIED',
    // PaLM-only classifications:
    'HARM_CATEGORY_DEROGATORY',
    'HARM_CATEGORY_TOXICITY',
    'HARM_CATEGORY_VIOLENCE',
    'HARM_CATEGORY_SEXUAL',
    'HARM_CATEGORY_MEDICAL',
    'HARM_CATEGORY_DANGEROUS',
    // Gemini classifications:
    'HARM_CATEGORY_HARASSMENT',
    'HARM_CATEGORY_HATE_SPEECH',
    'HARM_CATEGORY_SEXUALLY_EXPLICIT',
    'HARM_CATEGORY_DANGEROUS_CONTENT',
    'HARM_CATEGORY_CIVIC_INTEGRITY', // 2025-01-10
  ]);

  export const HarmProbability_enum = z.enum([
    'HARM_PROBABILITY_UNSPECIFIED',
    'NEGLIGIBLE',
    'LOW',
    'MEDIUM',
    'HIGH',
  ]);

  export type SafetyRating = z.infer<typeof SafetyRating_schema>;
  export const SafetyRating_schema = z.object({
    category: GeminiWire_Safety.HarmCategory_enum,
    probability: GeminiWire_Safety.HarmProbability_enum,
    blocked: z.boolean().optional(),
  });

  /// Settings

  export type HarmBlockThreshold = z.infer<typeof HarmBlockThreshold_enum>;
  export const HarmBlockThreshold_enum = z.enum([
    'HARM_BLOCK_THRESHOLD_UNSPECIFIED',
    'BLOCK_LOW_AND_ABOVE',      // allows NEGLIGIBLE
    'BLOCK_MEDIUM_AND_ABOVE',   // allows NEGLIGIBLE, LOW
    'BLOCK_ONLY_HIGH',          // allows NEGLIGIBLE, LOW, MEDIUM
    'BLOCK_NONE',               // allows all
    /**
     * 2025-01-10: see bug #720 and https://discuss.ai.google.dev/t/flash-2-0-doesnt-respect-block-none-on-all-harm-categories/59352/1
     */
    'OFF', // turns off the safety filter.
  ]);

  export const SafetySetting_schema = z.object({
    category: HarmCategory_enum,
    /** Block at and beyond a specified harm probability. */
    threshold: HarmBlockThreshold_enum,
  });

  /// Blocking

  const BlockReason_enum = z.enum([
    'BLOCK_REASON_UNSPECIFIED', // unused
    'SAFETY',                   // inspect safetyRatings to see the category that blocked
    'OTHER',                    // unknown reason
    'BLOCKLIST',                // terms are included in the terminology blocklist
    'PROHIBITED_CONTENT',       // prohibited content
    'IMAGE_SAFETY',             // unsafe image generation content
  ]);

  export const PromptFeedback_schema = z.object({
    /** Optional. If set, the prompt was blocked and no candidates are returned. */
    blockReason: BlockReason_enum.optional(),
    /** At most one rating per category. */
    safetyRatings: z.array(SafetyRating_schema),
  });

}


//
// Models > Generate Content
//
export namespace GeminiWire_API_Generate_Content {

  export const postPath = '/v1beta/{model=models/*}:generateContent';
  export const streamingPostPath = '/v1beta/{model=models/*}:streamGenerateContent?alt=sse'; // https://cloud.google.com/apis/docs/system-parameters#definitions

  /// Request

  const responseMimeType_enum = z.enum([
    'text/plain',       // default
    'application/json', // JSON mode (JSON response in the response candidates)
    'text/x.enum',      // ENUM as a string response in the response candidates
  ]);

  const responseModality_enum = z.enum([
    'MODALITY_UNSPECIFIED',
    'TEXT', // model should return text
    'IMAGE', // model should return images
    'AUDIO', // model should return audio
  ]);

  const mediaResolution_enum = z.enum([
    'MEDIA_RESOLUTION_UNSPECIFIED',
    'MEDIA_RESOLUTION_LOW',     // 64 tokens
    'MEDIA_RESOLUTION_MEDIUM',  //	256 tokens
    'MEDIA_RESOLUTION_HIGH',    //	zoomed reframing with 256 tokens
  ]);

  const SpeechConfig_schema = z.object({
    /** The configuration for the speaker to use. */
    voiceConfig: z.object({
      /** The configuration for the prebuilt voice to use. */
      prebuiltVoiceConfig: z.object({
        /** The name of the preset voice to use. */
        voiceName: z.string(),
      }).optional(),
    }).optional(),
  });

  const GenerationConfig_schema = z.object({
    /**
     * The set of character sequences (up to 5) that will stop output generation. If specified, the API will stop at the first appearance of a stop sequence.
     */
    stopSequences: z.array(z.string()).optional(),

    /**
     * - [default] 'text/plain'
     * - [JSON mode] 'application/json' + set .responseSchema => JSON response in the candidates
     * - [Classify mode] 'text/x.enum' + { "type": "STRING", "enum": ["A", "B", "C"] } = ENUM as a string response
     */
    responseMimeType: responseMimeType_enum.optional(),
    /**
     * Output schema of the generated candidate text.
     * Schemas must be a subset of the OpenAPI schema and can be objects, primitives or arrays.
     * if set -> responseMimeType must be 'application/json'
     */
    responseSchema: z.json().optional(), // JSON Mode: schema

    /**
     * Requested modalities of the response. (if empty this is equivalent ot ['TEXT'])
     * Exact match to the modalities of the response.
     * An Error is raised if the array doesn't exactly match a supported combo for the model.
     */
    responseModalities: z.array(responseModality_enum).optional(), // TODO

    /** Optional. Enables enhanced civic answers. Not be available for all models. */
    enableEnhancedCivicAnswers: z.boolean().optional(), // TODO
    /** Optional. The speech generation config. Still in preview (allowlist, 2025-03-14) */
    speechConfig: SpeechConfig_schema.optional(), // TODO
    /** Optional. The media resolution for the response. */
    mediaResolution: mediaResolution_enum.optional(), // TODO

    candidateCount: z.number().int().optional(), // currently can only be set to 1
    maxOutputTokens: z.number().int().optional(),
    temperature: z.number().min(0).max(2).optional(),
    topP: z.number().optional(),
    topK: z.number().int().optional(),

    // [Gemini, 2025-01-23] CoT support - undocumented yet
    thinkingConfig: z.object({
      /**
       * [2025-04-17] Used to work with v1alpha API, now it seems to not work in any model/api version combo.
       */
      includeThoughts: z.boolean().optional(),
      /**
       * [Gemini, 2025-04-17] Introduced in Flash-2.5-Preview to set the thinking budget.
       * - must be an integer in the range 0 to 24576; budgets from 1 to 1024 tokens will be set to 1024
       * - set to 0 to disable thinking
       */
      thinkingBudget: z.number().optional(),
    }).optional(),

    // Added on 2025-01-10 - Low-level - not requested/used yet but added
    presencePenalty: z.number().optional(),     // A positive penalty incresases the vocabulary of the response
    frequencyPenalty: z.number().optional(),    // A positive penalty incresases the vocabulary of the response
    responseLogprobs: z.boolean().optional(),   // if true, exports the logprobs
    logprobs: z.number().int().optional(),      // number of top logprobs to return
  });

  export type Request = z.infer<typeof Request_schema>;
  export const Request_schema = z.object({
    // the 'model' parameter is in the path of the `generateContent` POST

    // required
    contents: z.array(GeminiWire_Messages.Content_schema),

    // all optional
    tools: z.array(GeminiWire_ToolDeclarations.Tool_schema).optional(),
    toolConfig: GeminiWire_ToolDeclarations.ToolConfig_schema.optional(),
    safetySettings: z.array(GeminiWire_Safety.SafetySetting_schema).optional(),
    systemInstruction: GeminiWire_Messages.SystemInstruction_schema.optional(),
    generationConfig: GenerationConfig_schema.optional(),
    cachedContent: z.string().optional(),
  });

  // Response

  /** Last synced from https://ai.google.dev/api/generate-content#candidate on 2024-08-03 */
  const FinishReason_enum = z.enum([
    'FINISH_REASON_UNSPECIFIED',  // unused
    'STOP',                       // Natural stop point of the model or provided stop sequence.
    'MAX_TOKENS',                 // The maximum number of tokens as specified in the request was reached.
    'SAFETY',                     // The candidate content was flagged for safety reasons. See safetyRatings.
    'RECITATION',                 // The candidate content was flagged for recitation reasons. See citationMetadata.
    'LANGUAGE',                   // The candidate content was flagged for using an unsupported language.
    'OTHER',                      // Unknown reason
    'BLOCKLIST',                  // Token generation stopped because the content contains forbidden terms.
    'PROHIBITED_CONTENT',         // Token generation stopped for potentially containing prohibited content.
    'SPII',                       // Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).
    'MALFORMED_FUNCTION_CALL',    // The function call generated by the model is invalid.
    'IMAGE_SAFETY',               // Token generation stopped because generated images contain safety violations.
  ]);

  /** A citation to a source for a portion of a specific response. **/
  const CitationSource_schema = z.object({
    startIndex: z.number().optional(),  // Start of segment of the response that is attributed to this source.
    endIndex: z.number().optional(),    // End of the attributed segment, exclusive.
    uri: z.string().optional(),         // URI that is attributed as a source for a portion of the text.
    license: z.string().optional(),     // License for the GitHub project that is attributed as a source for segment.
  });

  /** A collection of source attributions for a piece of content. */
  const CitationMetadata_schema = z.object({
    citationSources: z.array(CitationSource_schema),
  });

  // for GenerateAnswer calls - UNWANTED by us
  /*const GroundingAttribution_schema = z.object({
    sourceId: z.object({
      groundingPassage: z.object({
        passageId: z.string(),
        partIndex: z.number().int(),
      }).optional(),
      semanticRetrieverChunk: z.object({
        source: z.string(),
        chunk: z.string(),
      }).optional(),
    }),
    content: GeminiWire_Messages.ModelContent_schema,
  });*/

  const groundingMetadata_Segment_schema = z.object({
    partIndex: z.number().int().optional(),
    startIndex: z.number().int().optional(),
    endIndex: z.number().int(),
    text: z.string(),
  });

  const GroundingMetadata_schema = z.object({
    /** supporting references retrieved from specified grounding source */
    groundingChunks: z.array(/*z.union([*/z.object({
      web: z.object({
        uri: z.string(),
        title: z.string(),
      }),
    })).optional(),

    /** List of grounding support: segment + arrays of chunks + arrays of probs  */
    groundingSupports: z.array(z.object({
      groundingChunkIndices: z.array(z.number().int()), // citations associated with the claim, indices into ../groundingChunks[]
      confidenceScores: z.array(z.number()),            // 0..1
      segment: groundingMetadata_Segment_schema,
    })).optional(),

    /** Web search queries for the following-up web search. */
    webSearchQueries: z.array(z.string()).optional(),

    /** Optional. Google search entry for the following-up web searches. */
    searchEntryPoint: z.object({
      renderedContent: z.string().optional(),   // Web content snippet that can be embedded in a web page or an app webview
      sdkBlob: z.string().optional(),           // Base64 encoded JSON representing array of <search term, search url> tuple
    }).optional(),

    /** Metadata related to retrieval in the grounding flow. */
    retrievalMetadata: z.object({
      googleSearchDynamicRetrievalScore: z.number().optional(), // 0..1 indicating how likely information from google search could help answer the prompt
    }).optional(),
  });

  const Candidate_schema = z.object({
    /**
     * Index of the candidate in the list of response candidates.
     * NOTE: see GenerationConfig_schema.candidateCount, which can only be set to 1, so index is supposed to be 0.
     */
    index: z.number()
      .optional(), // for `1.5-002` models, on Sept 24, 2024, this became optional
    /**
     * This seems to be equal to 'STOP' on all streaming chunks.
     * In theory: if empty, the model has not stopped generating the tokens.
     */
    finishReason: z.union([FinishReason_enum, z.string()]).optional(),
    /**
     * Generated content returned from the model.
     */
    content: GeminiWire_Messages.ModelContent_schema.optional(), // this can be missing if the finishReason is not 'MAX_TOKENS'
    /**
     * List of ratings for the safety of this response candidate. At most one rating per category.
     *
     * Empirical observations:
     * - Not present on the first packet? Second and after?
     * - Not present when finishReason is 'RECITATION'
     * - Usually defined for 4 categories: SEXUALLY_EXPLICIT, HATE_SPEECH, HARASSMENT, DANGEROUS_CONTENT (verified 2025-03-14)
     */
    safetyRatings: z.array(GeminiWire_Safety.SafetyRating_schema).optional(),
    /**
     * Automatic - will cite sources seldomly (e.g. when asking for the national anthem)
     * This field may be populated with recitation information for any text included in the content.
     * These are passages that are "recited" from copyrighted material in the foundational LLM's training data.
     *
     * Empirical observations:
     * - 2024-07-15: Unreliable: some of the sources seem to be hallucinated
     * - 2024-07-15: Not present when finishReason is 'RECITATION'; maybe the packet before it?
     */
    citationMetadata: CitationMetadata_schema.optional(),
    /**
     * Token count for this candidate.
     * Empirical observations:
     * - NOTE: not present(!), probably replaced by the ^usageMetadata field, so we DISABLE this field
     */
    // tokenCount: z.number(),

    /**
     * Attribution information for sources that contributed to a grounded answer.
     * ONLY FOR GenerateAnswer calls - so we do not want this
     */
    // groundingAttributions: z.array(GroundingAttribution_schema).optional(),
    /**
     * Grounding metadata for the candidate.
     * This field is populated for GenerateContent calls.
     * ONLY for GenerateContent calls with grounding enabled:
     * - tools = [{googleSearch: {}}], or
     * - tools = [{googleSearchRetrieval: {}}]
     */
    groundingMetadata: GroundingMetadata_schema.optional(),

    // We choose to ignore the following and save the parsing time (we do not use or support logProbs):
    // avgLogprobs: z.number().optional(),
    // logprobsResult: LogprobsResult_schema.optional(),
  });


  const ModalityTokenCount_schema = z.object({
    modality: GeminiWire_ContentParts.ContentPartModality_enum,
    tokenCount: z.number(),
  });

  const UsageMetadata_schema = z.object({
    // effective prompt size, including tokens in the cached content
    promptTokenCount: z.number(),

    // (usually there: missing on first packets, or 'RECITATION' answers) total tokens across all the generated candidates
    candidatesTokenCount: z.number().optional(),

    // (never missing, but optional for future safety) total tokens across all the generated candidates
    // if candidatesTokenCount is missing, this is = promptTokenCount
    totalTokenCount: z.number().optional(),

    // Input parts
    // (optional: only if caching) tokens in the cached part of the prompt (the cached content)
    cachedContentTokenCount: z.number().optional(),
    // (optional: only if tool usage) tokens in tool-use prompt(s)
    toolUsePromptTokenCount: z.number().optional(),

    // Output parts
    // (optional: only for thinking models - and not in all packets) tokens of thoughts for thinking models
    thoughtsTokenCount: z.number().optional(),

    // Modality breakdowns - mostly commented out because we don't want to spend energy parsing them for now (we don't use them)
    promptTokensDetails: z.array(ModalityTokenCount_schema).optional(),
    cacheTokensDetails: z.array(ModalityTokenCount_schema).optional(),
    // candidatesTokensDetails: z.array(ModalityTokenCount_schema).optional(),
    // toolUsePromptTokensDetails: z.array(ModalityTokenCount_schema).optional(),
  });


  export type Response = z.infer<typeof Response_schema>;
  export const Response_schema = z.object({
    candidates: z.array(Candidate_schema)
      .optional(), // 2024-09-27: added for when Gemini only sends usageMetadata (happened firs this day, on gemini-pro-1.5-001)
    promptFeedback: GeminiWire_Safety.PromptFeedback_schema.optional(), // rarely sent (only on violations?)
    /**
     * Metadata on the generation requests' token usage.
     * Note: seems to be present on all packets now, so we're commending the .optional()
     */
    usageMetadata: UsageMetadata_schema, // .optional()
    /** Real model version used to generate the response (what we got, not what we asked for). */
    modelVersion: z.string(),
  });

}


//
// Models > List
//
export namespace GeminiWire_API_Models_List {

  export const getPath = '/v1beta/models?pageSize=1000';

  export const Methods_enum = z.enum([
    'bidiGenerateContent', // appeared on 2024-12, see https://github.com/enricoros/big-AGI/issues/700
    'countMessageTokens',
    'countTextTokens',
    'countTokens',
    'createCachedContent', // appeared on 2024-06-10, see https://github.com/enricoros/big-AGI/issues/565
    'createTunedModel',
    'createTunedTextModel',
    'embedContent',
    'embedText',
    'generateAnswer',
    'generateContent',
    'generateMessage',
    'generateText',
    'predict', // appeared on 2025-02-09, for `models/imagen-3.0-generate-002`
    'predictLongRunning', // appeared on 2025-04-10, for `models/veo-2.0-generate-001`
  ]);

  export type Model = z.infer<typeof Model_schema>;
  const Model_schema = z.object({
    name: z.string(),           // The resource name of the Model. Format: models/{model} with a {model} naming convention of: "{baseModelId}-{version}"
    // baseModelId: z.string(),    // [Gemini]: documented as required, but not present! The name of the base model, pass this to the generation request.
    version: z.string(),
    displayName: z.string(),    // Human readable
    description: z.string().optional(),
    inputTokenLimit: z.number(),
    outputTokenLimit: z.number(),
    supportedGenerationMethods: z.array(z.union([Methods_enum, z.string()])), // relaxed with z.union to not break on expansion
    temperature: z.number().optional(),
    topP: z.number().optional(),
    topK: z.number().int().optional(),
    maxTemperature: z.number().optional(),
    thinking: z.boolean().optional(),
  });

  export type Response = z.infer<typeof Response_schema>;
  export const Response_schema = z.object({
    models: z.array(Model_schema),
    nextPageToken: z.string().optional(),
  });

}



================================================
FILE: src/modules/aix/server/dispatch/wiretypes/openai.wiretypes.ts
================================================
import * as z from 'zod/v4';


//
// Implementation notes (see https://platform.openai.com/docs/changelog for upstream changes):
// - 2024-12-17: "Reasoning Effort" - added reasoning_effort and the 'developer' message role
// - 2024-11-05: "Predicted Outputs"
// - 2024-10-17: "gpt-4o-audio-preview" - not fully added: "Audio inputs and outputs are now available in the Chat Completions API" - TBA
// - 2024-10-01: "DevDay" - added prompt_tokens_details, audio_tokens, and refusal messages
// - 2024-09-12: "o1" - max_tokens is deprecated in favor of max_completion_tokens, added completion_tokens_details
// - 2024-08-06: "Structured Outputs" - added JSON Schema and strict schema adherence
// - 2024-07-09: skipping Functions as they're deprecated
// - 2024-07-09: ignoring logprobs
// - 2024-07-09: ignoring the advanced model configuration
//


export namespace OpenAIWire_ContentParts {

  /// Content parts - Input

  export type TextContentPart = z.infer<typeof TextContentPart_schema>;
  const TextContentPart_schema = z.object({
    type: z.literal('text'),
    text: z.string(),
  });

  const ImageContentPart_schema = z.object({
    type: z.literal('image_url'),
    image_url: z.object({
      // Either a URL of the image or the base64 encoded image data.
      url: z.string(),
      // Control how the model processes the image and generates its textual understanding.
      // https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding
      detail: z.enum(['auto', 'low', 'high']).optional(),
    }),
  });

  const OpenAI_AudioContentPart_schema = z.object({
    // [OpenAI, 2024-10-17] input content: audio
    type: z.literal('input_audio'),
    input_audio: z.object({
      // Base64 encoded audio data.
      data: z.string(),
      // The format of the encoded audio data. Currently supports "wav" and "mp3".
      format: z.enum(['wav', 'mp3']),
    }),
  });

  export const ContentPart_schema = z.discriminatedUnion('type', [
    TextContentPart_schema,
    ImageContentPart_schema,
    OpenAI_AudioContentPart_schema,
  ]);

  export function TextContentPart(text: string): z.infer<typeof TextContentPart_schema> {
    return { type: 'text', text };
  }

  export function ImageContentPart(url: string, detail?: 'auto' | 'low' | 'high'): z.infer<typeof ImageContentPart_schema> {
    return { type: 'image_url', image_url: { url, detail } };
  }

  export function OpenAI_AudioContentPart(data: string, format: 'wav' | 'mp3'): z.infer<typeof OpenAI_AudioContentPart_schema> {
    return { type: 'input_audio', input_audio: { data, format } };
  }

  /// Content parts - Output

  const PredictedFunctionCall_schema = z.object({
    /*
     * .optional: for Mistral non-streaming generation - this is fairly weak, and does not let the discriminator work;
     *            please remove this hack asap.
     */
    type: z.literal('function').optional(),
    id: z.string(),
    function: z.object({
      name: z.string(),
      /**
       * Note that the model does not always generate valid JSON, and may hallucinate parameters
       * not defined by your function schema.
       * Validate the arguments in your code before calling your function.
       */
      arguments: z.string(), // FC args STRING
    }),
  });

  export function PredictedFunctionCall(toolCallId: string, functionName: string, functionArgs: string): z.infer<typeof PredictedFunctionCall_schema> {
    return { type: 'function', id: toolCallId, function: { name: functionName, arguments: functionArgs } };
  }

  export const ToolCall_schema = z.discriminatedUnion('type', [
    PredictedFunctionCall_schema,
  ]);

  /// Annotation - Output - maybe not even content parts

  export const OpenAI_AnnotationObject_schema = z.object({
    type: z.literal('url_citation'),
    url_citation: z.object({
      start_index: z.number().optional(),
      end_index: z.number().optional(),
      title: z.string(),
      url: z.string(),
    }),
  });

}

export namespace OpenAIWire_Messages {

  /// Messages - Input

  // const _optionalParticipantName = z.string().optional();

  const SystemMessage_schema = z.object({
    role: z.literal('system'),
    content: z.string(),
    // name: _optionalParticipantName,
  });

  const OpenAI_DeveloperMessage_schema = z.object({
    // [OpenAI, 2024-12-17] The developer message
    role: z.literal('developer'),
    content: z.string(), // Note: content could be an unspecified 'array' according to the docs, but we constrain it to string here
    // name: _optionalParticipantName,
  });

  const UserMessage_schema = z.object({
    role: z.literal('user'),
    content: z.union([z.string(), z.array(OpenAIWire_ContentParts.ContentPart_schema)]),
    // name: _optionalParticipantName,
  });

  export const AssistantMessage_schema = z.object({
    role: z.literal('assistant'),
    /**
     * The contents of the assistant message. Required unless tool_calls or function_call is specified.
     *
     * NOTE: the assistant message is also extending to be an array, but as of 2024-12-24, it's not important
     *       enough to require array support. The documentation of the array[] behavior of the field is:
     *       "An array of content parts with a defined type. Can be one or more of type text, or exactly one of type refusal."
     */
    content: z.string().nullable(),
    /**
     * The tool calls generated by the model, such as function calls.
     */
    tool_calls: z.array(OpenAIWire_ContentParts.ToolCall_schema).optional()
      .nullable(), // [Mistral] added .nullable()
    /**
     * [OpenAI, 2024-10-01] The refusal message generated by the model.
     */
    refusal: z.string().nullable().optional(),
    /**
     * [OpenAI, 2024-10-17] Data about a previous audio response from the model. Usage depends on the context:
     * - request (this schema): has an id, if present
     * - non-streaming response: has the generated audio and some metadata
     * - streaming response: NO audio fields
     */
    audio: z.object({
      id: z.string(),
    }).nullable().optional(),

    /**
     * [OpenRouter, 2025-06-05] The reasoning text generated by the model (e.g. with Anthropic thinking requests).
     */
    reasoning: z.string().nullable().optional(),

    // function_call: // ignored, as it's deprecated
    // name: _optionalParticipantName, // omitted by choice: generally unsupported
  });

  const ToolMessage_schema = z.object({
    role: z.literal('tool'),
    content: z.string(), // FC-R response STRING
    tool_call_id: z.string(),
  });

  export function ToolMessage(toolCallId: string, content: string): z.infer<typeof ToolMessage_schema> {
    return { role: 'tool', content, tool_call_id: toolCallId };
  }

  export const Message_schema = z.discriminatedUnion('role', [
    SystemMessage_schema,
    OpenAI_DeveloperMessage_schema,
    UserMessage_schema,
    AssistantMessage_schema,
    ToolMessage_schema,
  ]);

}

export namespace OpenAIWire_Tools {

  /// Tool definitions - Input

  export type FunctionDefinition = z.infer<typeof FunctionDefinition_schema>;
  export const FunctionDefinition_schema = z.object({
    /**
     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
     */
    name: z.string().regex(/^[a-zA-Z0-9_-]{1,64}$/, {
      message: 'Tool name must be 1-64 characters long and contain only letters, numbers, underscores, and hyphens',
    }),
    /**
     * A description of what the function does, used by the model to choose when and how to call the function.
     */
    description: z.string().optional(),
    /**
     * The parameters the functions accepts, described as a JSON Schema object.
     * Omitting parameters defines a function with an empty parameter list.
     */
    parameters: z.object({
      type: z.literal('object'),
      /**
       * For stricter validation, use the OpenAPI_Schema.Object_schema
       */
      properties: z.json().optional(), // FC-DEF params schema
      required: z.array(z.string()).optional(),
    }).optional(),
    /**
     * [OpenAI Structured Outputs, 2024-08-06]
     * Whether to enable strict schema adherence when generating the function call. Defaults to false.
     * [OpenAI] Only a subset of the schema would be supported and enforced.
     */
    strict: z.boolean().optional(),
  });

  export const ToolDefinition_schema = z.discriminatedUnion('type', [
    z.object({
      type: z.literal('function'),
      function: FunctionDefinition_schema,
    }),
  ]);

  export const ToolChoice_schema = z.union([
    z.literal('none'), // Do not use any tools
    z.literal('auto'), // Let the model decide whether to use tools or generate content
    z.literal('required'), // Must call one or more
    z.object({
      type: z.literal('function'),
      function: z.object({ name: z.string() }),
    }),
    // [Mistral] Mistral only, requires an 'any' value
    // Commented because we'll disable Mistral function calling instead
    // z.literal('any'),
  ]);

}


//
// Chat > Create chat completion
//
export namespace OpenAIWire_API_Chat_Completions {

  /// Request

  export type Request = z.infer<typeof Request_schema>;
  export const Request_schema = z.object({

    // basic input
    model: z.string(),
    messages: z.array(OpenAIWire_Messages.Message_schema),

    // tool definitions and calling policy
    tools: z.array(OpenAIWire_Tools.ToolDefinition_schema).optional(),
    tool_choice: OpenAIWire_Tools.ToolChoice_schema.optional(),
    parallel_tool_calls: z.boolean().optional(), // defaults to true

    // common model configuration
    max_completion_tokens: z.number().int().positive().optional(), // [OpenAI o1, 2024-09-12]
    max_tokens: z.number().optional(), // Deprecated in favor of max_completion_tokens - but still used by pre-o1 models and OpenAI-compatible APIs
    temperature: z.number().min(0).max(2).optional(),
    top_p: z.number().min(0).max(1).optional(),

    // new output modalities
    modalities: z.array(z.enum(['text', 'audio'])).optional(), // defaults to ['text']
    audio: z.object({  // Parameters for audio output. Required when audio output is requested with `modalities: ["audio"]`
      voice: z.enum([
        'ash', 'ballad', 'coral', 'sage', 'verse', // recommended
        'alloy', 'echo', 'shimmer', // discouraged
      ]),
      format: z.enum(['wav', 'mp3', 'flac', 'opus', 'pcm16']),
    }).optional(),

    // API configuration
    n: z.number().int().positive().optional(), // Defaults to 1, as the derived-ecosystem does not support it
    stream: z.boolean().optional(), // If set, partial message deltas will be sent, with the stream terminated by a `data: [DONE]` message.
    stream_options: z.object({
      include_usage: z.boolean().optional(), // If set, an additional chunk will be streamed with a 'usage' field on the entire request.
    }).optional(),
    reasoning_effort: z.enum(['low', 'medium', 'high']).optional(), // [OpenAI, 2024-12-17] [Perplexity, 2025-06-23] reasoning effort
    include_reasoning: z.boolean().optional(), // [OpenRouter, 2025-01-24] enables reasoning tokens
    reasoning: z.object({ // [OpenRouter, 2025-06-05] Reasoning parameter for Claude models
      max_tokens: z.number().int().positive(),
    }).optional(),
    prediction: z.object({ // [OpenAI, 2024-11-05] Predicted Outputs - for regenerating a file with only minor changes to most of the content.
      type: z.literal('content'),
      content: z.union([z.string(), z.array(OpenAIWire_ContentParts.ContentPart_schema)]),
    }).optional(),
    response_format: z.discriminatedUnion('type', [
      z.object({
        type: z.literal('text'), // Default
      }),
      /**
       * When using JSON mode, you must also instruct the model to produce JSON
       * yourself via a system or user message. Without this, the model may generate
       * an unending stream of whitespace until the generation reaches the token limit,
       * resulting in a long-running and seemingly "stuck" request.
       *
       * Also note that the message content may be partially cut off if
       * finish_reason="length", which indicates the generation exceeded max_tokens or
       * the conversation exceeded the max context length.
       */
      z.object({
        type: z.literal('json_object'),
      }),
      /**
       * [OpenAI Structured Outputs, 2024-08-06]
       * Whether to enable strict schema adherence when generating the output.
       * If set to true, the model will always follow the exact schema defined
       * in the schema field.
       * Only a subset of JSON Schema is supported when strict is true.
       */
      z.object({
        type: z.literal('json_schema'),
        json_schema: z.object({
          name: z.string().regex(/^[a-zA-Z0-9_-]{1,64}$/),
          description: z.string().optional(),
          schema: z.json().optional(), // JSON Mode: schema
          strict: z.boolean().optional(),
        }),
      }),
    ]).optional(),
    web_search_options: z.object({
      /**
       * High level guidance for the amount of context window space to use for the search. One of low, medium, or high. medium is the default.
       */
      search_context_size: z.enum(['low', 'medium', 'high']).optional(),
      /**
       * Approximate location parameters for the search.
       */
      user_location: z.object({
        type: z.literal('approximate'),
        approximate: z.object({
          city: z.string().optional(),      // free text for the city of the user, e.g. 'San Francisco'
          country: z.string().optional(),   // two-letter ISO country code of the user, e.g. 'US'
          region: z.string().optional(),    // free text, e.g. 'California'
          timezone: z.string().optional(),  // IANA timezone of the user, e.g. 'America/Los_Angeles'
        }),
      }).nullable().optional(),
    }).optional(),

    // [Perplexity, 2025-06-23] Perplexity-specific search parameters
    search_mode: z.enum(['academic']).optional(), // Academic filter for scholarly sources
    search_after_date_filter: z.string().optional(), // Date filter in MM/DD/YYYY format

    // [xAI] xAI-specific search parameters
    search_parameters: z.record(z.string(), z.any()).optional(), // xAI Live Search parameters - keeping flexible for API evolution

    seed: z.number().int().optional(),
    stop: z.array(z.string()).optional(), // Up to 4 sequences where the API will stop generating further tokens.
    user: z.string().optional(),

    // (deprecated upstream, OMITTED BY CHOICE): function_call and functions

    // (OMITTED BY CHOICE) advanced model configuration
    // frequency_penalty: z.number().min(-2).max(2).optional(), // Defaults to 0
    // presence_penalty: z.number().min(-2).max(2).optional(),  // Defaults to 0
    // logit_bias: z.record(z.number()).optional(),
    // logprobs: z.boolean().optional(), // Defaults to false
    // top_logprobs: z.number().int().min(0).max(20).optional(),

    // (OMITTED BY CHOICE) advanced API configuration
    // store: z.boolean().optional(), // Defaults to false. Whether or not to store the output of this chat completion request for use in our model distillation or evals products.
    // metadata: z.record(z.string(), z.any()).optional(), // Developer-defined tags and values used for filtering completions in [the dashboard](https://platform.openai.com/completions)
    // service_tier: z.string().optional(),

  });

  /// Response

  const FinishReason_Enum = z.enum([
    'stop', // natural completion, or stop sequence hit
    'length', // max_tokens exceeded
    'tool_calls', // the model called a tool
    'content_filter', // upstream content was omitted due to a flag from content filters

    // Disabling Function Call, OMITTED BY CHOICE
    // 'function_call', // (deprecated) the model called a function

    // Extensions // disabled: we now use a string union to accept any value without breaking
    // '', // [LocalAI] bad response from LocalAI which breaks the parser
    // 'COMPLETE', // [OpenRouter->Command-R+]
    // 'STOP', // [OpenRouter->Gemini]
    // 'end_turn', // [OpenRouter->Anthropic]
    // 'eos', // [OpenRouter->Phind]
    // 'error', // [OpenRouter] their network error
    // 'stop_sequence', // [OpenRouter->Anthropic] added 'stop_sequence' which is the same as 'stop'
  ]);

  const Usage_schema = z.object({
    prompt_tokens: z.number(),
    completion_tokens: z.number(),
    total_tokens: z.number(),

    // [OpenAI, 2024-10-01] breaks down the input tokens into components
    prompt_tokens_details: z.object({
      audio_tokens: z.number().optional(),
      cached_tokens: z.number().optional(),
    }).optional()
      .nullable(), // [2025-06-02] Chutes.ai using slang server returns null for prompt_tokens_details

    // [OpenAI o1, 2024-09-12] breaks down the completion tokens into components
    completion_tokens_details: z.object({
      reasoning_tokens: z.number().optional(), // [Discord, 2024-04-10] reported missing
      // text_tokens: z.number().optional(), // [Discord, 2024-04-10] revealed as present on custom OpenAI endpoint - not using it here yet
      audio_tokens: z.number().optional(), // [OpenAI, 2024-10-01] audio tokens used in the completion (charged at a different rate)
      accepted_prediction_tokens: z.number().optional(), // [OpenAI, 2024-11-05] Predicted Outputs
      rejected_prediction_tokens: z.number().optional(), // [OpenAI, 2024-11-05] Predicted Outputs
    }).optional() // not present in other APIs yet
      .nullable(), // [2025-06-02] no issues yet, but preventive

    // [DeepSeek, 2024-08-02] context caching on disk
    prompt_cache_hit_tokens: z.number().optional(),
    prompt_cache_miss_tokens: z.number().optional(),
  }).nullable();

  /**
   * NOTE: this is effectively the OUTPUT message (from the Chat Completion output object).
   * - 2025-03-11: the docs show that 'role' is not mandated to be 'assistant' anymore and could be different
   */
  const ChoiceMessage_NS_schema = OpenAIWire_Messages.AssistantMessage_schema.extend({
    //
    // IMPORTANT - this message *extends* the AssistantMessage_schema, to inherit all fields while performing any other change
    //

    // .string, instead of .assistant -- but we keep it strict for now, for parser correctness
    // role: z.string(),

    // .optional: when parsing a non-streaming message with just a FC, the content can be missing
    content: z.string().nullable().optional(),

    /**
     * [OpenAI, 2025-03-11] Annotations
     * This is a full assistant message, which is parsed by the non-streaming parser.
     */
    annotations: z.array(OpenAIWire_ContentParts.OpenAI_AnnotationObject_schema).nullable().optional(),

    /**
     * [OpenAI, 2024-10-17] Audio output (non-streaming only)
     * If the audio output modality is requested, this object contains data about the audio response from the model
     */
    audio: z.object({
      id: z.string(),
      data: z.string(), // Base64 encoded audio data
      expires_at: z.number(), // Unix timestamp
      transcript: z.string().optional(),
    }).nullable().optional(),

  });

  const Choice_NS_schema = z.object({
    index: z.number(),

    // NOTE: the OpenAI api does not force role: 'assistant', it's only induced
    // We recycle the assistant message response here, with either content or tool_calls
    message: ChoiceMessage_NS_schema,

    finish_reason: z.union([FinishReason_Enum, z.string()])
      .nullable(),

    // (OMITTED BY CHOICE) We will not support logprobs for now, so it's disabled here and in the request
    // logprobs: z.any().nullable().optional() // Log probability information for the choice.
  });

  export type Response = z.infer<typeof Response_schema>;
  export const Response_schema = z.object({
    object: z.literal('chat.completion'),
    id: z.string(), // A unique identifier for the chat completion.

    /**
     * A list of chat completion choices. Can be more than one if n is greater than 1.
     */
    choices: z.array(Choice_NS_schema),

    model: z.string(), // The model used for the chat completion.
    usage: Usage_schema.optional(), // If requested
    created: z.number(), // The Unix timestamp (in seconds) of when the chat completion was created.
    system_fingerprint: z.string().optional() // The backend configuration that the model runs with.
      .nullable(), // [Groq, undocumented OpenAI] fingerprint is null on some OpenAI examples too
    // service_tier: z.string().optional().nullable(), // OMITTED BY CHOICE

    // undocumented messages that are not part of the official schema, but can be found when the server sends and error
    error: z.any().optional(),
    warning: z.unknown().optional(),

    // [Perplexity] String array of citations, the first element is the first reference, i.e. '[1]'.
    // DEPRECATED: The citations field is being deprecated in favor of the new search_results field
    citations: z.array(z.any()).optional(),
    // [Perplexity, 2025-06-23] Search results
    search_results: z.array(z.object({
      title: z.string().optional().nullable(), // Title of the search result
      url: z.string().optional().nullable(), // URL of the search result
      date: z.string().optional().nullable(), // Date of the search result, e.g. '2024-01-01'
    })).optional(),
  });

  /// Streaming Response

  const _UndocumentedError_schema = z.object({
    // (undocumented) first experienced on 2023-06-19 on streaming APIs
    message: z.string().optional(),
    type: z.string().optional(),
    param: z.string().nullable().optional(),
    code: z.string().nullable().optional()
      .or(z.number()), // [OpenRouter, 2024-11-21] code can be a number too

    // [OpenRouter, 2024-11-21] OpenRouter can have an additional 'metadata' field
    metadata: z.record(z.string(), z.any()).optional(),
  });

  const _UndocumentedWarning_schema = z.string();

  /* Note: this is like the predicted function call, but with fields optional,
     as after the first chunk (which carries type and id), the model will just emit
     some index and function.arguments

     Note2: we found issues with Together, Openrouter, Mistral, and others we don't remember
     This object's status is really a mess for OpenAI and their downstream 'compatibles'.
   */
  const ChunkDeltaToolCalls_schema = z.object({
    index: z.number() // index is not present in non-streaming calls
      .optional(), // [Mistral] not present

    type: z.literal('function').optional(), // currently (2024-10-01) only 'function' is supported

    id: z.string().optional(), // id of the tool call - set likely only in the first chunk

    function: z.object({
      /**
       * Empirical observations:
       * - the name field seems to be set, in full, in the first call
       * - [TogetherAI] added .nullable() - exclusive with 'arguments'
       */
      name: z.string().optional().nullable(),
      /**
       * Note that the model does not always generate valid JSON, and may hallucinate parameters
       * not defined by your function schema.
       * Validate the arguments in your code before calling your function.
       * [TogetherAI] added .nullable() - exclusive with 'name'
       */
      arguments: z.string().optional().nullable(),
    }),
  });

  const ChunkDelta_schema = z.object({
    role: z.literal('assistant').optional()
      .nullable(), // [Deepseek] added .nullable()
    // delta-text content
    content: z.string().nullable().optional(),
    // delta-reasoning content
    reasoning_content: z.string().nullable().optional(), // [Deepseek, 2025-01-20]
    reasoning: z.string().optional() // [OpenRouter, 2025-01-24]
      .nullable(), // [OpenRouter, 2025-06-05] null on Anthropic text responses past the reasoning blocks
    // delta-tool-calls content
    tool_calls: z.array(ChunkDeltaToolCalls_schema).optional()
      .nullable(), // [TogetherAI] added .nullable(), see https://github.com/togethercomputer/together-python/issues/160
    refusal: z.string().nullable().optional(), // [OpenAI, 2024-10-01] refusal message
    /**
     * [OpenAI, 2025-03-11] Annotations
     * not documented yet in the API guide; shall improve this once defined
     */
    annotations: z.array(OpenAIWire_ContentParts.OpenAI_AnnotationObject_schema).optional(),
  });

  const ChunkChoice_schema = z.object({
    index: z.number()
      .optional(), // [OpenRouter] added .optional() which implies index=0 I guess

    // A chat completion delta generated by streamed model responses.
    delta: ChunkDelta_schema,

    finish_reason: z.union([FinishReason_Enum, z.string()])
      .nullable()   // very common, e.g. Azure
      .optional(),  // [OpenRouter] added .optional() which only has the delta field in the whole chunk choice

    // (OMITTED BY CHOICE) We will not support logprobs for now, so it's disabled here and in the request
    // logprobs: z.any().nullable().optional() // Log probability information for the choice.
  });

  export const ChunkResponse_schema = z.object({
    object: z.enum([
      'chat.completion.chunk',
      'chat.completion', // [Perplexity] sent an email on 2024-07-14 to inform them about the misnomer
      '', // [Azure] bad response: the first packet communicates 'prompt_filter_results'
    ])
      .optional(), // [FastAPI, 2025-04-24] the FastAPI dialect sadly misses the 'chat.completion.chunk' type
    id: z.string(),

    /**
     * A list of chat completion choices.
     * Can contain more than one elements if n is greater than 1.
     * Can also be empty for the last chunk if you set stream_options: {"include_usage": true}
     */
    choices: z.array(ChunkChoice_schema),

    model: z.string(), // The model used for the chat completion.
    usage: Usage_schema.optional(), // If requested
    created: z.number() // The Unix timestamp (in seconds) of when the chat completion was created.
      .optional(), // [FastAPI, 2025-04-24] the FastAPI dialect sadly misses the 'created' field
    system_fingerprint: z.string().optional() // The backend configuration that the model runs with.
      .nullable(), // [Grow, undocumented OpenAI] fingerprint is null on some OpenAI examples too
    // service_tier: z.unknown().optional(),

    // [OpenAI] undocumented streaming messages
    error: _UndocumentedError_schema.optional(),
    warning: _UndocumentedWarning_schema.optional(),

    // [Groq] undocumented statistics message
    x_groq: z.object({
      id: z.string().optional(),
      usage: z.object({
        queue_time: z.number().optional(),
        prompt_tokens: z.number().optional(),
        prompt_time: z.number().optional(),
        completion_tokens: z.number().optional(),
        completion_time: z.number().optional(),
        total_tokens: z.number().optional(),
        total_time: z.number().optional(),
      }).optional(),
      queue_length: z.number().optional(),
    }).optional(),

    // [Perplexity] String array of citations, the first element is the first reference, i.e. '[1]'.
    // DEPRECATED: The citations field is being deprecated in favor of the new search_results field
    citations: z.array(z.any()).optional(),
    // [Perplexity, 2025-06-23] Search results
    search_results: z.array(z.object({
      title: z.string().optional().nullable(), // Title of the search result
      url: z.string().optional().nullable(), // URL of the search result
      date: z.string().optional().nullable(), // Date of the search result, e.g. '2024-01-01'
    })).optional(),
  });

}


//
// Images > Create Image
// https://platform.openai.com/docs/api-reference/images/create
//
export namespace OpenAIWire_API_Images_Generations {

  export type Request = z.infer<typeof Request_schema>;
  const Request_schema = z.object({

    // 32,000 for gpt-image-1, 4,000 for dall-e-3, 1,000 for dall-e-2
    prompt: z.string().max(32000),

    model: z.enum([
      'gpt-image-1',
      'dall-e-3',
      'dall-e-2', // default
    ]).optional(),

    // The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.
    n: z.number().min(1).max(10).nullable().optional(),

    // Image quality
    quality: z.enum([
      'auto',                   // default
      'high', 'medium', 'low',  // gpt-image-1
      'hd', 'standard',         // dall-e-3: hd | standard, dall-e-2: only standard
    ]).optional(),

    // The format in which generated images with dall-e-2 and dall-e-3 are returned.
    //`gpt-image-1` will always return base64-encoded images and does NOT support this parameter.
    response_format: z.enum(['url', 'b64_json']).optional(),

    // size of the generated images
    size: z.enum([
      'auto',       // GI (or default if omitted)
      '256x256',    //          D2
      '512x512',    //          D2
      '1024x1024',  // GI  D3  D2
      // landscape
      '1536x1024',  // GI
      '1792x1024',  //      D3
      // portrait
      '1024x1536',  // GI
      '1024x1792',  //      D3
    ]).optional(),

    // optional unique identifier representing your end-user
    user: z.string().optional(),


    // -- GPT Image 1 Specific Parameters --

    // Allows to set transparency (in that case, format = png or webp)
    background: z.enum(['transparent', 'opaque', 'auto' /* default */]).optional(),

    // Control the content-moderation level for images generated by gpt-image-1.
    moderation: z.enum(['low', 'auto' /* default */]).optional(),

    // The format in which the generated images are returned
    output_format: z.enum(['png' /* default */, 'jpeg', 'webp']).optional(),

    // WEBP/JPEG compression level for gpt-image-1
    output_compression: z.number().min(0).max(100).int().optional(),


    // -- Dall-E 3 Specific Parameters --

    // DALL-E 3 ONLY - style - defaults to vivid
    style: z.enum(['vivid', 'natural']).optional(),

  });

  export type Response = z.infer<typeof Response_schema>;
  export const Response_schema = z.object({
    created: z.number(),
    data: z.array(z.object({
      b64_json: z.string().optional(),
      revised_prompt: z.string().optional(),
      url: z.url().optional(), // if the response_format is 'url' - DEPRECATED
    })),

    // gpt-image-1 only
    usage: z.object({
      total_tokens: z.number(),
      input_tokens: z.number(), // images + text tokens in the input prompt
      output_tokens: z.number(), // image tokens in the output image
      input_tokens_details: z.object({
        text_tokens: z.number(),
        image_tokens: z.number().optional(), // present if editing
      }).optional(),
    }).optional(),
  });

}

// Images > Edit Image
export namespace OpenAIWire_API_Images_Edits {

  export type Request = z.infer<typeof Request_schema>;

  /**
   * This API method only accepts 'multipart/form-data' requests.
   * The request body must be a FormData object, which we build outside.
   * The spec below represents the first part.
   */
  export const Request_schema = z.object({

    // 32,000 for gpt-image-1, 1,000 for dall-e-2
    prompt: z.string().max(32000),

    // image: file | file[] - REQUIRED - Handled as file uploads in FormData ('image' field)

    // mask: file - OPTIONAL - Handled as file upload in FormData ('mask' field)

    model: z.enum(['gpt-image-1', 'dall-e-2']).optional(),

    // Number of images to generate, between 1 and 10
    n: z.number().min(1).max(10).nullable().optional(),

    // Image quality
    quality: z.enum([
      'auto',                   // default
      'high', 'medium', 'low',  // gpt-image-1
      'standard',               // dall-e-2: only standard
    ]).optional(),

    // response_format: string - OPTIONAL - Defaults to 'url'. Only for DALL-E 2. gpt-image-1 always returns b64_json.
    // OMITTED here as we'll enforce b64_json or handle it based on model if DALL-E 2 edit were supported.

    // size of the generated images
    size: z.enum([
      'auto',       // GI (or default if omitted)
      '256x256',    //          D2
      '512x512',    //          D2
      '1024x1024',  // GI       D2
      // landscape
      '1536x1024',  // GI
      // portrait
      '1024x1536',  // GI
    ]).optional(),

    // optional unique identifier representing your end-user
    user: z.string().optional(),

  });

  // The response schema is identical to OpenAIWire_API_Images_Generations.Response_schema
  export type Response = OpenAIWire_API_Images_Generations.Response;

}


//
// Models > List Models
//
export namespace OpenAIWire_API_Models_List {

  export type Model = z.infer<typeof Model_schema>;
  const Model_schema = z.object({
    id: z.string(),
    object: z.literal('model'),
    created: z.number().optional(),
    // [dialect:OpenAI] 'openai' | 'openai-dev' | 'openai-internal' | 'system'
    owned_by: z.string().optional(),

    // **Extensions**
    // [Openrouter] non-standard - commented because dynamically added by the Openrouter vendor code
    // context_length: z.number().optional(),
  });

  export type Response = z.infer<typeof Response_schema>;
  const Response_schema = z.object({
    object: z.literal('list'),
    data: z.array(Model_schema),
  });

}


//
// Moderations > Create Moderation
//
export namespace OpenAIWire_API_Moderations_Create {

  export type Request = z.infer<typeof Request_schema>;
  const Request_schema = z.object({
    // input: z.union([z.string(), z.array(z.string())]),
    input: z.string(),
    model: z.enum(['text-moderation-stable', 'text-moderation-latest']).optional(),
  });

  const Category_schema = z.enum([
    'sexual',
    'hate',
    'harassment',
    'self-harm',
    'sexual/minors',
    'hate/threatening',
    'violence/graphic',
    'self-harm/intent',
    'self-harm/instructions',
    'harassment/threatening',
    'violence',
  ]);

  const Result_schema = z.object({
    flagged: z.boolean(),
    categories: z.record(Category_schema, z.boolean()),
    category_scores: z.record(Category_schema, z.number()),
  });

  export type Response = z.infer<typeof Response_schema>;
  const Response_schema = z.object({
    id: z.string(),
    model: z.string(),
    results: z.array(Result_schema),
  });

}


// Chat > Responses API

export namespace OpenAIWire_Responses_Items {

  // Parts - Input

  const Input_TextPart_schema = z.object({
    type: z.literal('input_text'),
    text: z.string(),
  });

  const Input_ImagePart_schema = z.object({
    type: z.literal('input_image'),
    detail: z.enum(['auto', 'low', 'high']).optional(), // defaults to 'auto'
    image_url: z.string().optional(), // URL or base64 encoded image in a data URL.
    file_id: z.string().optional(),
  });

  const Input_FilePart_schema = z.object({
    type: z.literal('input_file'),
    file_data: z.string().optional(), // content of the file
    file_id: z.string().optional(), // ID of the file
    filename: z.string().optional(), // name of the file
  });


  // Parts - Output

  export const ContentItem_TextPart_schema = z.object({
    type: z.literal('output_text'),
    text: z.string(),
    // NOTE: this could also be file_citation, container_file_citation, file_path
    annotations: z.array(z.object({
      type: z.literal('url_citation'),
      url: z.string(),
      title: z.string(),
      start_index: z.number().optional(),
      end_index: z.number().optional(),
    })).optional(),
    // Log Probabilities are ignored on purpose
  });

  export const ContentItem_RefusalPart_schema = z.object({
    type: z.literal('refusal'),
    refusal: z.string(), // explanation
  });

  export const _ContentItem_Parts_schema = z.union([
    ContentItem_TextPart_schema,
    ContentItem_RefusalPart_schema,
  ]);

  export const ReasoningItem_SummaryTextPart_schema = z.object({
    type: z.literal('summary_text'),
    text: z.string(), // summary text
  });


  // Output Items: Content ('message': ['output_text', 'refusal']), Reasoning ('reasoning': [ReasoningItemSummaryTextPart_schema]), Function Call ('function_call': [OutputFunctionCallItem_schema]), and more

  const _OutputItemBase_schema = z.object({
    status: z.enum(['in_progress', 'completed', 'incomplete']).optional(), // status of the output item
  });

  const OutputContentItem_schema = _OutputItemBase_schema.extend({
    type: z.literal('message'),
    id: z.string(), // unique ID of the output item
    role: z.literal('assistant'),
    content: z.array(_ContentItem_Parts_schema),
  });

  const OutputReasoningItem = _OutputItemBase_schema.extend({
    type: z.literal('reasoning'),
    /**
     * ID seems missing from the reasoning output (at least in response.reasoning_summary_part.added),
     * but the docs say it's required as input?
     */
    // id: z.string(),
    summary: z.array(ReasoningItem_SummaryTextPart_schema), // summary of the reasoning
    encrypted_content: z.string().nullish(), // populated when a response is generated with reasoning.encrypted_content in the include
  });

  export type OutputFunctionCallItem = z.infer<typeof OutputFunctionCallItem_schema>;
  const OutputFunctionCallItem_schema = _OutputItemBase_schema.extend({
    type: z.literal('function_call'),
    id: z.string().optional(), // unique ID of the output item - optional when looped back to input
    arguments: z.string(), // FC args STRING (Responses) - JSON string of the arguments to pass to the function
    call_id: z.string(), //  unique ID of the function tool call -- same as ID? verify
    name: z.string(), // name of the function to call
  });

  const OutputWebSearchCallItem_schema = _OutputItemBase_schema.extend({
    type: z.literal('web_search_call'),
    id: z.string(), // unique ID of the output item
    action: z.any().optional(), // TODO: expand this later
  });

  // const ImageGenerationCallOutput_schema = z.object({
  //   type: z.literal('image_generation_call'),
  //   id: z.string(), // unique ID of the image generation call (output item ID)
  //   result: z.string().nullish(), // base64 image data
  //   status: _OutputItemStatus_schema.optional(),
  // });

  /**
   * Output Items:
   *
   * - Content Item
   *   - output_text part
   *   - refusal part
   *
   * - Reasoning Item
   *   - summary_text part
   *
   * - Function Call Item (no parts, details are inside)
   *
   */
  export const OutputItem_schema = z.union([
    OutputContentItem_schema,
    OutputReasoningItem,
    OutputFunctionCallItem_schema,
    OutputWebSearchCallItem_schema,
    // ImageGenerationCallOutput_schema,
    // FileSearchCallOutput_schema,
    // WebSearchCallOutput_schema,
    // ComputerUseCallOutput_schema,
    // CodeInterpreterCallOutput_schema,
    // LocalShellCallOutput_schema,
    // MCPToolCallOutput_schema,
    // MCPListToolsOutput_schema,
    // MCPApprovalRequestOutput_schema,
  ]);


  // Request 'Input' Item

  const _InputItem_schema = z.object({
    status: z.enum(['incomplete', 'in_progress', 'completed']).optional(),
  });

  export type UserItemMessage = z.infer<typeof UserItemMessage_schema>;
  const UserItemMessage_schema = _InputItem_schema.extend({
    type: z.literal('message'),
    role: z.enum(['user', 'system', 'developer']),
    content: z.array(z.union([
      Input_TextPart_schema,
      Input_ImagePart_schema,
      Input_FilePart_schema,
    ])),
  });

  export type FunctionToolCallOutput = z.infer<typeof FunctionToolCallOutput_schema>;
  const FunctionToolCallOutput_schema = _InputItem_schema.extend({
    type: z.literal('function_call_output'),
    id: z.string().optional(), // The unique ID of the function tool call output. Populated when this item is returned via API.
    output: z.string(), // FC-R response STRING (Responses) - a JSON string of the output of the function call
    call_id: z.string(), // unique ID of the function tool call generated by the model.
  });

  // Ignoring for now:
  // - type: 'file_search_call'
  // - type: 'computer_call'
  // - type: 'web_search_call'
  // - type: 'image_generation_call'
  // - type: 'code_interpreter_call'
  // - type: 'local_shell_call'
  // - type: 'local_shell_call_output'
  // - type: 'mcp_list_tools'
  // - type: 'mcp_approval_request'
  // - type: 'mcp_approval_response'
  // - type: 'mcp_call'


  /*
   * Old-style Item Message, used for compatibility with older APIs.
   *
   * NOTE: Over time we will move to the 'Item' type below, but it requires tracking lots
   * of 3rd party IDs (to messages, reasoning items, calls, etc.), which will be a vendor
   * lock-in potentially.
   *
   * In the meantime this is a way out of that.
   */
  export type InputMessage_Compat = z.infer<typeof InputMessage_Compat_schema>;

  const _InputMessage_Compat_User_schema = z.object({
    type: z.literal('message'),
    role: z.enum(['user', 'system', 'developer']),
    // user/system/developer inputs: 'input_text', 'input_image', 'input_file'
    content: z.array(z.union([
      Input_TextPart_schema,
      Input_ImagePart_schema,
      Input_FilePart_schema,
    ])),
  });
  const _InputMessage_Compat_Model_schema = z.object({
    type: z.literal('message'),
    role: z.literal('assistant'),
    // assistant inputs: 'output_text', 'refusal'
    content: z.array(_ContentItem_Parts_schema),
  });

  const InputMessage_Compat_schema = z.union([
    _InputMessage_Compat_User_schema,
    _InputMessage_Compat_Model_schema,
  ]);

  // Input Item (combined)

  export type InputItem = z.infer<typeof InputItem_schema>;
  export const InputItem_schema = z.union([
    // Old-style Item Message
    InputMessage_Compat_schema,
    // Item:
    UserItemMessage_schema,
    FunctionToolCallOutput_schema,
    OutputItem_schema,
    // Item Reference (not used yet):
    z.object({
      type: z.literal('item_reference'),
      id: z.string(), // ID of the item to reference
    }),
  ]);
}

export namespace OpenAIWire_Responses_Tools {

  // Custom tool definitions

  const CustomFunctionTool_schema = z.object({
    type: z.literal('function'),
    name: z.string().regex(/^[a-zA-Z0-9_-]{1,64}$/),
    description: z.string(), // Used by the model to determine whether or not to call the function.
    parameters: z.object({
      type: z.literal('object'),
      properties: z.json().optional(), // FC-DEF params schema (Responses)
      required: z.array(z.string()).optional(),
    }).optional(),
    strict: z.boolean().optional(), // enforce strict parameter validation
  });

  // Hosted tools definitions

  const WebSearchTool_schema = z.object({
    type: z.enum(['web_search_preview', 'web_search_preview_2025_03_11']),
    search_context_size: z.enum(['low', 'medium', 'high']).optional(),
    user_location: z.object({
      type: z.literal('approximate'),
      city: z.string().optional(),
      country: z.string().optional(),
      region: z.string().optional(),
      timezone: z.string().optional(),
    }).optional(),
  });

  // Combined tools

  export type Tool = z.infer<typeof Tool_schema>;
  export const Tool_schema = z.union([
    // custom function tools
    CustomFunctionTool_schema,
    // hosted tools
    WebSearchTool_schema,
    // CodeInterpreterTool_schema,
    // ComputerUseTool_schema,
    // FileSearchTool_schema,
    // ImageGenerationTool_schema,
    // LocalShellTool_schema,
    // MCPTool_schema,
  ]);

  export const ToolChoice_schema = z.union([
    z.literal('none'), // do not call any tool
    z.literal('auto'), // pick between generating a message or calling 1+ tools
    z.literal('required'), // must call 1+ tools
    z.object({ // function tool
      type: z.literal('function'),
      name: z.string(),
    }),
    z.object({ // hosted tool
      type: z.enum([
        // 'file_search',
        'web_search_preview',
        // 'computer_use_preview',
        // 'code_interpreter',
        // 'mcp',
        // 'image_generation',
        // 'local_shell' ?
      ]),
    }),
  ]);

}

export namespace OpenAIWire_API_Responses {

  /// Request

  export type Request = z.infer<typeof Request_schema>;
  export const Request_schema = z.object({

    // Model configuration
    model: z.string(),
    max_output_tokens: z.number().int().positive().nullish(),
    temperature: z.number().min(0).nullish(), // [OpenAI] Defaults to 1, max: 2
    top_p: z.number().min(0).nullish(), // [OpenAI] Defaults to 1, max: 1

    // Input
    instructions: z.string().nullish(),
    input: z.array(OpenAIWire_Responses_Items.InputItem_schema),

    // Tools
    tools: z.array(OpenAIWire_Responses_Tools.Tool_schema).optional(),
    tool_choice: OpenAIWire_Responses_Tools.ToolChoice_schema.optional(),
    parallel_tool_calls: z.boolean().nullish(),

    // configure reasoning
    reasoning: z.object({
      effort: z.enum(['low', 'medium', 'high']).nullish(), // defaults to 'medium'
      summary: z.enum(['auto', 'concise', 'detailed']).nullish(),
    }).nullish(),

    // configure text output
    text: z.object({
      format: z.union([
        z.object({ type: z.literal('text') }),
        z.object({
          type: z.literal('json_schema'),
          name: z.string(), // The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
          description: z.string().optional(), // A description of what the response format is for, used by the model to determine how to respond in the format.
          schema: z.json(), // JSON Mode: schema (Responses)
          strict: z.boolean().nullish(), // only a subset of JSON Schema is supported when strict is true
        }),
        // z.object({ type: z.literal('json_object') }), // deprecated
      ]).optional(),
    }).optional(),

    // State management (we won't use this for stateless)
    store: z.boolean().nullish(), // defaults to true(!)
    previous_response_id: z.string().nullish(),

    // API options
    stream: z.boolean().nullish(),
    background: z.boolean().nullish(),
    truncation: z.enum(['auto', 'disabled']).nullish(), // defaults to 'disabled', 'auto' drops input items in the middle of the conversation.
    user: z.string().optional(), // stable identifier for your end-users

    // Unused
    // include: z.array(z.string()).nullish(), // additional output to include in the response: 'file_search_call.results', 'message.input_image.image_url', 'computer_call_output.output.image_url', 'reasoning.encrypted_content', 'code_interpreter_call.outputs'
    // metadata: z.record(z.string(), z.any()).optional(), // set of 16 key-value pairs that can be attached to an object
    // service_tier: z.enum(['auto', 'default', 'flex', 'priority']).nullish(),
    // prompt: z.object({
    //   id: z.string(),
    //   version: z.string().optional(),
    //   variables: z.record(z.string(), z.any()).optional(),
    // }).optional(),
  });


  /// Response


  export type Response = z.infer<typeof Response_schema>;
  export const Response_schema = z.object({
    object: z.literal('response'),

    id: z.string(), // unique ID for this response
    created_at: z.number(), // unix timestamp (in seconds)
    status: z.enum(['completed', 'failed', 'in_progress', 'cancelled', 'queued', 'incomplete']),
    incomplete_details: z.object({ reason: z.string() }).nullish(), // why the response is incomplete
    error: z.object({ code: z.string(), message: z.string() }).nullish(), // (null)

    model: z.string(), // model used for the response

    output: z.array(OpenAIWire_Responses_Items.OutputItem_schema),

    usage: z.object({
      input_tokens: z.number(),
      input_tokens_details: z.object({
        cached_tokens: z.number().optional(),
      }).optional(),
      output_tokens: z.number(),
      output_tokens_details: z.object({
        reasoning_tokens: z.number().optional(),
      }).optional(),
      total_tokens: z.number(),
    }).nullish(),

    // NOTE: the following fields seem an exact echo of what's in the request - let's ignore these for now
    // background: ... (false)
    // instructions: ...
    // max_output_tokens: ...
    // metadata: ...
    // parallel_tool_calls: ...
    // previous_response_id: ... (null)
    // prompt: ...
    // reasoning: ...
    // service_tier: ...
    // temperature: ...
    // text: ...
    // tool_choice: ...
    // tools: ...
    // top_p: ...
    // truncation: ...
    // user: ...

  });


  // Response - Streaming Events

  const _BaseEvent_schema = z.object({
    sequence_number: z.number(),
  });

  // Streaming > Response lifecycle

  const ResponseCreatedEvent_schema = _BaseEvent_schema.extend({
    type: z.literal('response.created'),
    response: Response_schema,
  });

  const ResponseInProgress_schema = _BaseEvent_schema.extend({
    type: z.literal('response.in_progress'),
    response: Response_schema,
  });

  const ResponseCompletedEvent_schema = _BaseEvent_schema.extend({
    type: z.literal('response.completed'),
    response: Response_schema,
  });

  // finishes as failed
  const ResponseFailedEvent_schema = _BaseEvent_schema.extend({
    type: z.literal('response.failed'),
    response: Response_schema,
  });

  // finishes as incomplete
  const ResponseIncompleteEvent_schema = _BaseEvent_schema.extend({
    type: z.literal('response.incomplete'),
    response: Response_schema,
  });

  // Streaming > Output item

  const _OutputItemEvent_schema = _BaseEvent_schema.extend({
    output_index: z.number(), // identifies the output item in the response
  });

  const OutputItemAddedEvent_schema = _OutputItemEvent_schema.extend({
    type: z.literal('response.output_item.added'),
    item: OpenAIWire_Responses_Items.OutputItem_schema,
  });

  const OutputItemDoneEvent_schema = _OutputItemEvent_schema.extend({
    type: z.literal('response.output_item.done'),
    item: OpenAIWire_Responses_Items.OutputItem_schema,
  });

  const _OutputIndexedEvent_schema = _OutputItemEvent_schema.extend({
    item_id: z.string(), // items[output_index].id
  });

  // Streaming > Output Item > Content Part

  const _PartIndexedEvent_schema = _OutputIndexedEvent_schema.extend({
    content_index: z.number(), // identifies the content part in the output item
  });

  const ContentPartAddedEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.content_part.added'),
    part: OpenAIWire_Responses_Items._ContentItem_Parts_schema,
  });

  const ContentPartDoneEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.content_part.done'),
    part: OpenAIWire_Responses_Items._ContentItem_Parts_schema,
  });

  const OutputTextDeltaEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.output_text.delta'),
    delta: z.string(),
  });

  const OutputTextDoneEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.output_text.done'),
    text: z.string(),
  });

  const OutputRefusalDeltaEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.output_refusal.delta'),
    delta: z.string(),
  });

  const OutputRefusalDoneEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.output_refusal.done'),
    refusal: z.string(),
  });

  const OutputTextAnnotationAddedEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.enum([
      'response.output_text_annotation.added', // from the spec
      'response.output_text.annotation.added', // from unsing web_search_call
    ]),
    annotation_index: z.number(),
    annotation: z.any(), // TODO will spec later
  });

  const OutputResponseReasoningDeltaEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.reasoning.delta'),
    delta: z.any(), // will spec later - seems { text: string } from the spec? smells
  });

  const OutputResponseReasoningDoneEvent_schema = _PartIndexedEvent_schema.extend({
    type: z.literal('response.reasoning.done'),
    text: z.string(), // finalized reasoning text
  });

  // Streaming > Output Item > Reasoning Summary

  const _SummaryIndexedEvent_schema = _OutputIndexedEvent_schema.extend({
    summary_index: z.number(), // identifies the reasoning summary in the output item
  });

  const OutputReasoningSummaryDeltaEvent_schema = _SummaryIndexedEvent_schema.extend({
    type: z.literal('response.reasoning_summary.delta'),
    delta: z.any(), // object // will spec later
  });

  const OutputReasoningSummaryDoneEvent_schema = _SummaryIndexedEvent_schema.extend({
    type: z.literal('response.reasoning_summary.done'),
    text: z.string(), // finalized reasoning summary text.
  });

  const OutputReasoningSummaryPartAddedEvent_schema = _SummaryIndexedEvent_schema.extend({
    type: z.literal('response.reasoning_summary_part.added'),
    part: OpenAIWire_Responses_Items.ReasoningItem_SummaryTextPart_schema,
  });

  const OutputReasoningSummaryPartDoneEvent_schema = _SummaryIndexedEvent_schema.extend({
    type: z.literal('response.reasoning_summary_part.done'),
    part: OpenAIWire_Responses_Items.ReasoningItem_SummaryTextPart_schema,
  });

  const OutputReasoningSummaryTextDeltaEvent_schema = _SummaryIndexedEvent_schema.extend({
    type: z.literal('response.reasoning_summary_text.delta'),
    delta: z.string(),
  });

  const OutputReasoningSummaryTextDoneEvent_schema = _SummaryIndexedEvent_schema.extend({
    type: z.literal('response.reasoning_summary_text.done'),
    text: z.string(), // final summary text
  });

  // Streaming > Output Item: Function Call Arguments

  const FunctionCallArgumentsDeltaEvent_schema = _OutputIndexedEvent_schema.extend({
    type: z.literal('response.function_call_arguments.delta'),
    delta: z.string(),
  });

  const FunctionCallArgumentsDoneEvent_schema = _OutputIndexedEvent_schema.extend({
    type: z.literal('response.function_call_arguments.done'),
    arguments: z.string(), // JSON string of the arguments to pass to the function
  });

  // Streaming > Output Item: Web Search Call

  const OutputWebSearchCallInProgress_schema = _OutputIndexedEvent_schema.extend({
    type: z.literal('response.web_search_call.in_progress'),
  });

  const OutputWebSearchCallSearching_schema = _OutputIndexedEvent_schema.extend({
    type: z.literal('response.web_search_call.searching'),
  });

  const OutputWebSearchCallCompleted_schema = _OutputIndexedEvent_schema.extend({
    type: z.literal('response.web_search_call.completed'),
  });

  // Streaming > Output Item: Ignoring:
  // - file_search_call.*
  // - web_search_call.*
  // - image_generation_call.*
  // - mcp_call.*, mcp_list_tools.*
  // - code_interpreter_call.*, code_interpreter_call_code.*

  // Error event
  const ErrorEvent_schema = _BaseEvent_schema.extend({
    type: z.literal('error'),

    // error as per the docs
    code: z.number().or(z.string()).nullish(),
    message: z.string().nullish(),
    param: z.string().nullish(),

    // error received sometimes:
    error: z.object({
      type: z.union([z.enum(['invalid_request_error']), z.string()]).nullish(),
      message: z.string().nullish(),
      code: z.number().or(z.string()).nullish(),
      param: z.string().nullish(),
    }).nullish(),
  });

  // Combined streaming event
  export type StreamingEvent = z.infer<typeof StreamingEvent_schema>;
  export const StreamingEvent_schema = z.discriminatedUnion('type', [
    ResponseCreatedEvent_schema,
    ResponseInProgress_schema,
    ResponseCompletedEvent_schema,
    ResponseFailedEvent_schema,
    ResponseIncompleteEvent_schema,
    OutputItemAddedEvent_schema,
    OutputItemDoneEvent_schema,
    ContentPartAddedEvent_schema,
    ContentPartDoneEvent_schema,
    OutputTextDeltaEvent_schema,
    OutputTextDoneEvent_schema,
    OutputRefusalDeltaEvent_schema,
    OutputRefusalDoneEvent_schema,
    OutputTextAnnotationAddedEvent_schema,
    OutputResponseReasoningDeltaEvent_schema,
    OutputResponseReasoningDoneEvent_schema,
    OutputReasoningSummaryDeltaEvent_schema,
    OutputReasoningSummaryDoneEvent_schema,
    OutputReasoningSummaryPartAddedEvent_schema,
    OutputReasoningSummaryPartDoneEvent_schema,
    OutputReasoningSummaryTextDeltaEvent_schema,
    OutputReasoningSummaryTextDoneEvent_schema,
    FunctionCallArgumentsDeltaEvent_schema,
    FunctionCallArgumentsDoneEvent_schema,
    OutputWebSearchCallInProgress_schema,
    OutputWebSearchCallSearching_schema,
    OutputWebSearchCallCompleted_schema,
    ErrorEvent_schema,
  ]);

}



================================================
FILE: src/modules/backend/backend.router.ts
================================================
import * as z from 'zod/v4';

import { Release } from '~/common/app.release';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { env } from '~/server/env';
import { fetchJsonOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

// critical to make sure we `import type` here
import type { BackendCapabilities } from './store-backend-capabilities';


function sdbmHash(str: string): string {
  let hash = 0;
  for (let i = 0; i < str.length; i++) {
    const char = str.charCodeAt(i);
    hash = char + (hash << 6) + (hash << 16) - hash;
  }
  // Convert to unsigned 32-bit integer and then to hex string
  return (hash >>> 0).toString(16);
}

function generateLlmEnvConfigHash(env: Record<string, unknown>): string {
  const envAPIKeys = Object.keys(env)     // get all env keys
    .filter(key => !!env[key])            // minus the empty
    .filter(key => key.includes('_API_')) // minus the non-API keys
    .map(key => `${key}=${env[key]}`)     // create key-value pairs
    .sort();                              // ignore order
  const hashInputs = [
    Release.Monotonics.Aix.toString(),  // triggers at every change (large downstream effect, know what you are doing)
    Release.TenantSlug.toString(),          // triggers when branch changes
    ...envAPIKeys,                      // triggers when env keys change
  ];
  return sdbmHash(hashInputs.join(';'));
}


/**
 * This is the primary router for the backend. Mainly, this deals with letting
 * the frontend know what capabilities are available, by virtue of being
 * pre-configured in the servr. In the future this will evolve to a better
 * server-side configuration system.
 */
export const backendRouter = createTRPCRouter({

  /* List server-side capabilities (pre-configured by the deployer) */
  listCapabilities: publicProcedure
    .query(async ({ ctx: _unused }): Promise<BackendCapabilities> => {
      return {
        // llms
        hasLlmAlibaba: !!env.ALIBABA_API_KEY || !!env.ALIBABA_API_HOST,
        hasLlmAnthropic: !!env.ANTHROPIC_API_KEY,
        hasLlmAzureOpenAI: !!env.AZURE_OPENAI_API_KEY && !!env.AZURE_OPENAI_API_ENDPOINT,
        hasLlmDeepseek: !!env.DEEPSEEK_API_KEY,
        hasLlmGemini: !!env.GEMINI_API_KEY,
        hasLlmGroq: !!env.GROQ_API_KEY,
        hasLlmLocalAIHost: !!env.LOCALAI_API_HOST,
        hasLlmLocalAIKey: !!env.LOCALAI_API_KEY,
        hasLlmMistral: !!env.MISTRAL_API_KEY,
        hasLlmOllama: !!env.OLLAMA_API_HOST,
        hasLlmOpenAI: !!env.OPENAI_API_KEY || !!env.OPENAI_API_HOST,
        hasLlmOpenPipe: !!env.OPENPIPE_API_KEY,
        hasLlmOpenRouter: !!env.OPENROUTER_API_KEY,
        hasLlmPerplexity: !!env.PERPLEXITY_API_KEY,
        hasLlmTogetherAI: !!env.TOGETHERAI_API_KEY,
        hasLlmXAI: !!env.XAI_API_KEY,
        // others
        hasDB: (!!env.MDB_URI) || (!!env.POSTGRES_PRISMA_URL && !!env.POSTGRES_URL_NON_POOLING),
        hasBrowsing: !!env.PUPPETEER_WSS_ENDPOINT,
        hasGoogleCustomSearch: !!env.GOOGLE_CSE_ID && !!env.GOOGLE_CLOUD_API_KEY,
        hasVoiceElevenLabs: !!env.ELEVENLABS_API_KEY,
        // hashes
        hashLlmReconfig: generateLlmEnvConfigHash(env),
        // build data
        build: Release.buildInfo('backend'),
      };
    }),


  // The following are used for various OAuth integrations

  /**
   * Exchange the OpenrRouter 'code' (from PKCS) for an OpenRouter API Key
   */
  exchangeOpenRouterKey: publicProcedure
    .input(z.object({ code: z.string() }))
    .query(async ({ input }) => {
      // Documented here: https://openrouter.ai/docs#oauth
      return await fetchJsonOrTRPCThrow<{ key: string }, { code: string }>({
        url: 'https://openrouter.ai/api/v1/auth/keys',
        method: 'POST',
        body: { code: input.code },
        name: 'Backend.exchangeOpenRouterKey',
      });
    }),

});



================================================
FILE: src/modules/backend/store-backend-capabilities.ts
================================================
import { create } from 'zustand';
import { useShallow } from 'zustand/react/shallow';

/*
 NOTE: this file is used IN THE FRONTEND - it's meant to be telling the frontend what the backend capabilities are.
 NOTE: this file is also used in the BACKEND for type safety of the returned payload.
 */

export interface BackendCapabilities {
  // llms
  hasLlmAlibaba: boolean;
  hasLlmAnthropic: boolean;
  hasLlmAzureOpenAI: boolean;
  hasLlmDeepseek: boolean;
  hasLlmGemini: boolean;
  hasLlmGroq: boolean;
  hasLlmLocalAIHost: boolean;
  hasLlmLocalAIKey: boolean;
  hasLlmMistral: boolean;
  hasLlmOllama: boolean;
  hasLlmOpenAI: boolean;
  hasLlmOpenPipe: boolean;
  hasLlmOpenRouter: boolean;
  hasLlmPerplexity: boolean;
  hasLlmTogetherAI: boolean;
  hasLlmXAI: boolean;
  // others
  hasDB: boolean;
  hasBrowsing: boolean;
  hasGoogleCustomSearch: boolean;
  hasVoiceElevenLabs: boolean;
  // hashes
  hashLlmReconfig: string;
  // build data
  build?: {
    gitSha?: string;
    pkgVersion?: string;
    timestamp?: string;
  };
}

interface BackendStore extends BackendCapabilities {
  _loadedCapabilities: boolean;
  setCapabilities: (capabilities: Partial<BackendCapabilities>) => void;
}

const useBackendCapabilitiesStore = create<BackendStore>()(
  (set) => ({

    // initial values
    hasLlmAlibaba: false,
    hasLlmAnthropic: false,
    hasLlmAzureOpenAI: false,
    hasLlmDeepseek: false,
    hasLlmGemini: false,
    hasLlmGroq: false,
    hasLlmLocalAIHost: false,
    hasLlmLocalAIKey: false,
    hasLlmMistral: false,
    hasLlmOllama: false,
    hasLlmOpenAI: false,
    hasLlmOpenPipe: false,
    hasLlmOpenRouter: false,
    hasLlmPerplexity: false,
    hasLlmTogetherAI: false,
    hasLlmXAI: false,
    hasDB: false,
    hasBrowsing: false,
    hasGoogleCustomSearch: false,
    hasVoiceElevenLabs: false,
    hashLlmReconfig: '',
    build: undefined,
    _loadedCapabilities: false,

    setCapabilities: (capabilities: Partial<BackendCapabilities>) =>
      set({
        ...capabilities,
        _loadedCapabilities: true,
      }),

  }),
);


export function useKnowledgeOfBackendCaps(): [boolean, (capabilities: Partial<BackendCapabilities>) => void] {
  return useBackendCapabilitiesStore(useShallow(state => [state._loadedCapabilities, state.setCapabilities]));
}

export function getBackendCapabilities(): BackendCapabilities {
  return useBackendCapabilitiesStore.getState();
}



================================================
FILE: src/modules/beam/beam.config.ts
================================================
import type { SxProps } from '@mui/joy/styles/types';
import { OVERLAY_BUTTON_ZINDEX } from '~/modules/blocks/OverlayButton';

// BEAM recap - Nomenclature:
//  - Beam (public name) = Scatter (technology process) -> Ray[] (single scatter thread)
//  - Merge (public name) = Gather (technology process) -> Fusion[] (single gather thread)

// configuration [BEAM Common]
export const BEAM_INVERT_BACKGROUND = true;
export const BEAM_BTN_SX: SxProps = { minWidth: 128 };
export const BEAM_PANE_ZINDEX = OVERLAY_BUTTON_ZINDEX + 1; // on top of the overlay buttons
export const BEAM_SHOW_REASONING_ICON = false;

// configuration [BEAM Scatter]
export const SCATTER_COLOR = 'neutral' as const;
export const SCATTER_DEBUG_STATE = false;
export const SCATTER_PLACEHOLDER = '🖊️ ...'; // 💫 ..., 🖊️ ...
export const SCATTER_RAY_DEF = 2;
export const SCATTER_RAY_MAX = 8;
export const SCATTER_RAY_MIN = 1;
export const SCATTER_RAY_PRESETS = [2, 4, 8];
export const SCATTER_RAY_SHOW_DRAG_HANDLE = false;

// configuration [BEAM Gather]
export const GATHER_COLOR = 'success' as const;
export const GATHER_PLACEHOLDER = '📦 ...';



================================================
FILE: src/modules/beam/BeamCard.tsx
================================================
import type { SxProps } from '@mui/joy/styles/types';
import { Box, styled } from '@mui/joy';

import { animationShadowLimey } from '~/common/util/animUtils';

import { BEAM_INVERT_BACKGROUND, BEAM_PANE_ZINDEX } from './beam.config';


export const beamCardClasses = {
  fusionIdle: 'beamCard-fusionIdle',
  errored: 'beamCard-Errored',
  selectable: 'beamCard-Selectable',
  attractive: 'beamCard-Attractive',
  smashTop: 'beamCard-SmashTop',
};

/**
 * Used for message-containing cards.
 */
export const BeamCard = styled(Box)(({ theme }) => ({
  '--Card-padding': '1rem',

  backgroundColor: theme.vars.palette.background.surface,
  border: '1px solid',
  borderColor: theme.vars.palette.neutral.outlinedBorder,
  borderRadius: theme.radius.md,

  padding: 'var(--Card-padding)',

  // [`&.${beamCardClasses.active}`]: {
  //   boxShadow: 'inset 0 0 0 2px #00f, inset 0 0 0 4px #00a',
  // },

  [`&.${beamCardClasses.fusionIdle}`]: {
    backgroundColor: BEAM_INVERT_BACKGROUND ? theme.vars.palette.background.level2 : theme.vars.palette.background.surface,
  },
  [`&.${beamCardClasses.selectable}`]: {
    backgroundColor: theme.vars.palette.background.popup,
  },
  [`&.${beamCardClasses.errored}`]: {
    backgroundColor: theme.vars.palette.danger.softBg,
    borderColor: theme.vars.palette.danger.outlinedBorder,
  },
  [`&.${beamCardClasses.attractive}`]: {
    animation: `${animationShadowLimey} 2s linear infinite`,
  },
  [`&.${beamCardClasses.smashTop}`]: {
    borderTop: 'none',
    borderTopLeftRadius: 0,
    borderTopRightRadius: 0,
  },

  position: 'relative',

  display: 'flex',
  flexDirection: 'column',
  gap: 'var(--Pad_2)',

  // uncomment the following to limit the card height
  // maxHeight: 'calc(0.8 * (100dvh - 16rem))',
  // overflow: 'auto',
}));
BeamCard.displayName = 'BeamCard'; // [shared] scatter/gather pane style


export const beamCardMessageWrapperSx: SxProps = {
  minHeight: '1.5rem',
  display: 'flex',
  flexDirection: 'column',
  // uncomment the following to limit the message height
  // overflow: 'auto',
  // maxHeight: 'calc(0.8 * (100vh - 16rem))',
  // aspectRatio: 1,
};

export const beamCardMessageSx: SxProps = {
  // style: to undo the style of ChatMessage
  backgroundColor: 'none',
  border: 'none',
  mx: -1.5, // compensates for the marging (e.g. RenderChatText, )
  my: 0,
  px: 0,
  py: 0,
};

export const beamCardMessageScrollingSx: SxProps = {
  ...beamCardMessageSx,
  overflow: 'auto',
  maxHeight: 'max(18rem, calc(50lvh - 16rem))',
};


/**
 * Props for the two panes.
 */
export const beamPaneSx: SxProps = {
  // style
  p: 'var(--Pad)',
  py: 'calc(3 * var(--Pad) / 4)',
  zIndex: BEAM_PANE_ZINDEX, // cast shadow on the rays/fusion, and be on top of the overlay pane

  // layout
  display: 'flex',
  flexWrap: 'wrap',
  alignItems: 'center',
  justifyContent: 'space-between',
  gap: 'var(--Pad_2)',
};


================================================
FILE: src/modules/beam/BeamExplainer.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { ExplainerCarousel, ExplainerPage } from '~/common/components/ExplainerCarousel';
import { animationEnterScaleUp } from '~/common/util/animUtils';


const beamSteps: ExplainerPage[] = [
  {
    stepDigits: '',
    stepName: 'Welcome',
    // titlePrefix: 'Welcome to Beam.', //  Better answers, faster.
    titlePrefix: 'Welcome to ', titleSpark: 'Beam',
    // titleSpark: 'B E A M',
    // titleSuffix: ' azing',
    // titleSquircle: true,
    mdContent: `
**Beam** is a chat modality in Big-AGI to engage multiple AI models, [together](https://big-agi.com/blog/beam-multi-model-ai-reasoning). 
 
It's like having a brainstorm session with several smart people,
each adding their own unique perspective.
Beam lets you make the best of them all.

![big-AGI BEAM Rays](https://big-agi.com/app/journeys/beam/explainer-beam-scatter-1200px-alpha.png)

`, // Let&apos;s get you to better chat answers, faster.
  },
  {
    stepDigits: '01',
    stepName: 'Beam',
    titlePrefix: 'Explore with ', titleSpark: 'Beam', titleSuffix: '.',
    // titleSpark: 'Beaming', titleSuffix: ': Exploration',
    mdContent: `
**Beaming is the exploration phase**, where AI models generate ideas.

Simply pick the AI models you want to use (you can load/save combos) and start them. 
You can then select a single response to continue the chat,
or keep the responses you like and do a Merge.

**Important:** _Best used in earlier / shorter chats_. 💰 Beware of the token usage of Beaming and Merging;
being parallel and lengthy operations, they will use more tokens than regular chats. 

Use a mix of different AI models to get a diverse set of ideas and perspectives. 
`, // and delete the ones that aren't helpful
  },
  {
    stepDigits: '02',
    stepName: 'Merge',
    titlePrefix: 'Combine with ', titleSpark: 'Merge', titleSuffix: '.',
    // titleSpark: 'Merging', titleSuffix: ': Synthesis', // Synthesis, Convergence
    mdContent: `
Merging is **combining the best parts of each response** into a great, coherent answer.

You can choose from various merge options, including **Fusion**, **Checklist**, **Compare**, and **Custom**.
Experiment with different options to find the one that works best for your chat.

![big-AGI BEAM Rays](https://big-agi.com/app/journeys/beam/explainer-beam-gather-1600px-alpha.png)
    `, // > Merge until you have a single, high-quality response. Or choose the final response manually, skipping merge.
  },
//   {
//     stepDigits: '',
//     stepName: 'Tips',
//     titleSuffix: 'Effectiveness Tips', //  · N × GPT-4 -> GPT-5
//     mdContent: `
// #### Human as a Judge
// You, the user, provide creative direction and final judgement. The AI models are powerful tools that generate drafts for you to quickly evaluate and refine.
// There are profound reasons why this approach works, which we explore [in our blog](https://big-agi.com/blog/introducing-beam).
//
// #### Best Use
// This tool is designed for the **early stages** of a process, where it delivers unparalleled insights and perspectives precisely **when your
// project needs clarity and direction**.
//
// The diversity of perspectives acts **like the wisdom of a seasoned team**, offering a wide array of solutions and viewpoints.
//
// #### Considerations
// The tool **will consume more Tokens** than a regular chat, which is another reason to use it early on when
// a chat history is short, and the return on investment is greater.
// `,
//   },
] as const;


const beamExplainerSx: SxProps = {
  // allows the content to be scrolled (all browsers)
  overflowY: 'auto',
  // actually make sure this scrolls & fills
  height: '100%',

  // style
  padding: 3, // { xs: 3, md: 3 },
  animation: `${animationEnterScaleUp} 0.2s cubic-bezier(.17,.84,.44,1)`,

  // layout
  display: 'grid',
};


export function BeamExplainer(props: {
  onWizardComplete: () => any,
}) {

  return (
    <Box
      // variant={grayUI ? 'solid' : 'soft'}
      // invertedColors={grayUI ? true : undefined}
      sx={beamExplainerSx}
    >

      <ExplainerCarousel
        explainerId='beam-onboard'
        steps={beamSteps}
        // footer={
        //   <Typography level='body-xs' sx={{ textAlign: 'center', maxWidth: '400px', mx: 'auto' }}>
        //     {/*Unlock beaming, combine AI wisdom, achieve clarity.*/}
        //     {/*Discover, Design and Dream.*/}
        //     {/*The journey from exploration to refinement is iterative.*/}
        //     {/*Each cycle sharpens your ideas, bringing you closer to innovation.*/}
        //   </Typography>
        // }
        onFinished={props.onWizardComplete}
      />

    </Box>

  );
}


================================================
FILE: src/modules/beam/BeamView.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Alert, Box, CircularProgress } from '@mui/joy';

import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { ShortcutKey, useGlobalShortcuts } from '~/common/components/shortcuts/useGlobalShortcuts';
import { animationEnterScaleUp } from '~/common/util/animUtils';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { messageFragmentsReduceText } from '~/common/stores/chat/chat.message';
import { useUICounter } from '~/common/stores/store-ui';

import { BeamExplainer } from './BeamExplainer';
import { BeamFusionGrid } from './gather/BeamFusionGrid';
import { BeamGatherPane } from './gather/BeamGatherPane';
import { BeamRayGrid } from './scatter/BeamRayGrid';
import { BeamScatterInput } from './scatter/BeamScatterInput';
import { BeamScatterPane } from './scatter/BeamScatterPane';
import { BeamStoreApi, useBeamStore } from './store-beam.hooks';
import { useModuleBeamStore } from './store-module-beam';


export function BeamView(props: {
  beamStore: BeamStoreApi,
  isMobile: boolean,
  showExplainer?: boolean,
  // sx?: SxProps,
}) {

  // state
  const [hasAutoMerged, setHasAutoMerged] = React.useState(false);
  const [warnIsScattering, setWarnIsScattering] = React.useState(false);

  // external state
  const { novel: explainerUnseen, touch: explainerCompleted, forget: explainerShow } = useUICounter('beam-wizard');
  const { cardAdd, gatherAutoStartAfterScatter } = useModuleBeamStore(useShallow(state => ({
    cardAdd: state.cardAdd,
    gatherAutoStartAfterScatter: state.gatherAutoStartAfterScatter,
  })));
  const {
    /* root */ inputHistoryReplaceMessageFragment,
    /* scatter */ setRayCount, startScatteringAll, stopScatteringAll,
  } = props.beamStore.getState();
  const {
    /* root */ inputHistory, inputIssues, inputReady,
    /* scatter */ hadImportedRays, isScattering, raysReady,
    /* gather (composite) */ canGather,
  } = useBeamStore(props.beamStore, useShallow(state => ({
    // input
    inputHistory: state.inputHistory,
    inputIssues: state.inputIssues,
    inputReady: state.inputReady,
    // scatter
    hadImportedRays: state.hadImportedRays,
    isScattering: state.isScattering,
    raysReady: state.raysReady,
    // gather (composite)
    canGather: state.raysReady >= 2 && state.currentFactoryId !== null && state.currentGatherLlmId !== null,
  })));
  // the following are independent because of useShallow, which would break in the above call
  const rayIds = useBeamStore(props.beamStore, useShallow(state => state.rays.map(ray => ray.rayId)));
  const fusionIds = useBeamStore(props.beamStore, useShallow(state => state.fusions.map(fusion => fusion.fusionId)));

  // derived state
  const raysCount = rayIds.length;


  // handlers

  const handleRaySetCount = React.useCallback((n: number) => setRayCount(n), [setRayCount]);

  const handleRayIncreaseCount = React.useCallback(() => setRayCount(raysCount + 1), [setRayCount, raysCount]);

  const handleRaysOperation = React.useCallback((operation: 'copy' | 'use') => {
    const { rays, onSuccessCallback } = props.beamStore.getState();
    const allFragments = rays.flatMap(ray => ray.message.fragments);
    if (allFragments.length) {
      switch (operation) {
        case 'copy':
          const combinedText = messageFragmentsReduceText(allFragments, '\n\n\n---\n\n\n');
          copyToClipboard(combinedText, 'All Beams');
          break;
        case 'use':
          onSuccessCallback?.({ fragments: allFragments });
          break;
      }
    }
  }, [props.beamStore]);

  const handleScatterStart = React.useCallback((restart: boolean) => {
    setHasAutoMerged(false);
    startScatteringAll(restart);
  }, [startScatteringAll]);


  const handleCreateFusion = React.useCallback(() => {
    // if scatter is busy, ask for confirmation
    if (isScattering) {
      setWarnIsScattering(true);
      return;
    }
    props.beamStore.getState().createFusion();
  }, [isScattering, props.beamStore]);


  const handleStartMergeConfirmation = React.useCallback(() => {
    setWarnIsScattering(false);
    stopScatteringAll();
    handleCreateFusion();
  }, [handleCreateFusion, stopScatteringAll]);

  const handleStartMergeDenial = React.useCallback(() => setWarnIsScattering(false), []);


  // auto-merge
  const shallAutoMerge = gatherAutoStartAfterScatter && canGather && !isScattering && !hasAutoMerged;
  React.useEffect(() => {
    if (shallAutoMerge) {
      setHasAutoMerged(true);
      handleStartMergeConfirmation();
    }
  }, [handleStartMergeConfirmation, shallAutoMerge]);

  // (great ux) scatter finished while the "start merge" (warning) dialog is up: dismiss dialog and proceed
  // here we assume that 'warnIsScattering' shows the intention of the user to proceed with a merge asap
  const shallResumeMerge = warnIsScattering && !isScattering && !gatherAutoStartAfterScatter;
  React.useEffect(() => {
    if (shallResumeMerge)
      handleStartMergeConfirmation();
  }, [handleStartMergeConfirmation, shallResumeMerge]);


  // runnning

  // [effect] pre-populate a default number of rays
  // const bootup = raysCount < SCATTER_RAY_DEF;
  // React.useEffect(() => {
  //   bootup && handleRaySetCount(SCATTER_RAY_DEF);
  // }, [bootup, handleRaySetCount]);


  // intercept ctrl+enter and esc
  useGlobalShortcuts('BeamView', React.useMemo(() => [
    { key: ShortcutKey.Enter, ctrl: true, action: () => handleScatterStart(false), disabled: isScattering, level: 1 },
    ...(isScattering ? [{ key: ShortcutKey.Esc, action: stopScatteringAll, level: 10 + 1 /* becasuse > ChatBarAltBeam */ }] : []),
  ], [handleScatterStart, isScattering, stopScatteringAll]));


  // Explainer, if unseen
  if (props.showExplainer && explainerUnseen)
    return <BeamExplainer onWizardComplete={explainerCompleted} />;

  return <>

    <Box role='beam-list' sx={{
      // scroller fill
      minHeight: '100%',
      // ...props.sx,

      // enter animation
      // NOTE: disabled: off-putting/confusing when the beam content is large - things won't combine nicely
      // animation: `${animationEnterScaleUp} 5s cubic-bezier(.17,.84,.44,1)`,

      // config
      '--Pad': { xs: '1rem', md: '1.5rem' },
      '--Pad_2': 'calc(var(--Pad) / 2)',

      // layout
      display: 'flex',
      flexDirection: 'column',
      gap: 'var(--Pad)',
    }}>

      {/* Config Issues */}
      {!!inputIssues && <Alert>{inputIssues}</Alert>}


      {/* User Message */}
      <BeamScatterInput
        isMobile={props.isMobile}
        history={inputHistory}
        onMessageFragmentReplace={inputHistoryReplaceMessageFragment}
      />

      {/* Scatter Controls */}
      <BeamScatterPane
        beamStore={props.beamStore}
        isMobile={props.isMobile}
        rayCount={raysCount}
        setRayCount={handleRaySetCount}
        showRayAdd={!cardAdd}
        startEnabled={inputReady}
        startBusy={isScattering}
        startRestart={!props.isMobile && raysReady >= 1 && raysReady < raysCount && !isScattering}
        onStart={handleScatterStart}
        onStop={stopScatteringAll}
        onExplainerShow={explainerShow}
      />


      {/* Rays Grid - BeamRay[] > <ChatMessage /> */}
      <BeamRayGrid
        beamStore={props.beamStore}
        isMobile={props.isMobile}
        rayIds={rayIds}
        showRayAdd={cardAdd}
        showRaysOps={(isScattering || raysReady < 2) ? undefined : raysReady}
        hadImportedRays={hadImportedRays}
        onIncreaseRayCount={handleRayIncreaseCount}
        onRaysOperation={handleRaysOperation}
        // linkedLlmId={currentGatherLlmId}
      />


      {/* Gapper between Rays and Merge, without compromising the auto margin of the Ray Grid */}
      <Box />


      {/* Gather Controls */}
      <BeamGatherPane
        beamStore={props.beamStore}
        canGather={canGather}
        isMobile={props.isMobile}
        // onAddFusion={handleCreateFusion}
        raysReady={raysReady}
      />

      {/* Fusion Grid - Fusion[] > <ChatMessage /> */}
      <BeamFusionGrid
        beamStore={props.beamStore}
        canGather={canGather}
        fusionIds={fusionIds}
        isMobile={props.isMobile}
        onAddFusion={handleCreateFusion}
        raysCount={raysCount}
      />

    </Box>


    {/* Confirm Stop Scattering */}
    {warnIsScattering && (
      <ConfirmationModal
        open
        onClose={handleStartMergeDenial}
        onPositive={handleStartMergeConfirmation}
        // lowStakes
        noTitleBar
        confirmationText='Some responses are still being generated. Do you want to stop and proceed with merging the available responses now?'
        positiveActionText='Proceed with Merge'
        negativeActionText='Wait for All Responses'
        negativeActionStartDecorator={
          <CircularProgress color='neutral' sx={{ '--CircularProgress-size': '24px', '--CircularProgress-trackThickness': '1px' }} />
        }
      />
    )}

  </>;
}


/* Commented code with a callout box to explain the first message
  <Box>
    <CalloutTopRightIcon sx={{ color: 'primary.solidBg', fontSize: '2.53rem', rotate: '-10deg' }} />
    <Chip
      color='primary'
      variant='solid'
      endDecorator={<ChipDelete onClick={() => alert('aa')} />}
      sx={{
        mx: -2,
        py: 1,
        px: 2,
      }}
    >
      Last message in the conversation
    </Chip>
  </Box>
*/


================================================
FILE: src/modules/beam/store-beam.hooks.ts
================================================
import * as React from 'react';
import { type StoreApi, useStore } from 'zustand';

import { useShallowStable } from '~/common/util/hooks/useShallowObject';

import type { BeamStore } from './store-beam_vanilla';


export type BeamStoreApi = Readonly<StoreApi<BeamStore>>;


export const useBeamStore = <T, >(beamStore: BeamStoreApi, selector: (store: BeamStore) => T): T =>
  useStore(beamStore, selector);

/*export const useIsBeamOpen = (beamStore?: BeamStoreApi) => {
  const [open, setOpen] = React.useState(false);

  // attach to the current beamStore
  React.useEffect(() => {
    if (!beamStore) {
      setOpen(false);
      return;
    }
    setOpen(beamStore.getState().isOpen);
    return beamStore.subscribe((state: BeamState, prevState: BeamState) => {
      (state.isOpen !== prevState.isOpen) && setOpen(state.isOpen);
    });
  }, [beamStore]);

  return open;
};*/

export function useAreBeamsOpen(beamStores: (BeamStoreApi | null)[]): boolean[] {

  // state
  const [_changeVersion, setChangeVersion] = React.useState(0);

  // [effect] monitor the stores for changes
  React.useEffect(() => {
    const updateIfOpenChanges = (state: BeamStore, prevState: BeamStore) => {
      if (state.isOpen !== prevState.isOpen)
        setChangeVersion(version => version + 1);
    };

    // monitor the open status of all stores
    const unsubscribes = beamStores.filter(store => !!store).map((beamStore) => {
      return beamStore?.subscribe(updateIfOpenChanges);
    });

    // unsubscribe on cleanup or when the stores change
    return () => unsubscribes.forEach((unsubscribe) => unsubscribe?.());
  }, [beamStores]);

  return useShallowStable(beamStores.map(beamStore => beamStore?.getState().isOpen ?? false));
}


================================================
FILE: src/modules/beam/store-beam_vanilla.ts
================================================
import type { StoreApi } from 'zustand';
import { createStore as createVanillaStore, StateCreator } from 'zustand/vanilla';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import type { DMessage, DMessageId } from '~/common/stores/chat/chat.message';
import type { DMessageFragment, DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import { llmsHeuristicGetTopDiverseLlmIds } from '~/common/stores/llms/store-llms-domains_slice';

import { BeamConfigSnapshot, useModuleBeamStore } from './store-module-beam';
import { SCATTER_RAY_DEF } from './beam.config';
import { createGatherSlice, GatherStoreSlice, reInitGatherStateSlice } from './gather/beam.gather';
import { createScatterSlice, reInitScatterStateSlice, ScatterStoreSlice } from './scatter/beam.scatter';


/// Beam Store (vanilla, creator function) ///
// Uses the Slices pattern, described in: https://docs.pmnd.rs/zustand/guides/typescript#slices-pattern

export type BeamStore = RootStoreSlice & GatherStoreSlice & ScatterStoreSlice;

export const createBeamVanillaStore = (): StoreApi<BeamStore> => createVanillaStore<BeamStore>()((...a) => ({

  ...createRootSlice(...a),
  ...createScatterSlice(...a),
  ...createGatherSlice(...a),

}));


/// Common Store Slice ///

type BeamSuccessCallback = (messageUpdate: Pick<DMessage, 'fragments' | 'generator'>) => void;

interface RootStateSlice {

  isOpen: boolean;
  isEditMode: boolean;
  isMaximized: boolean;
  inputHistory: DMessage[] | null;
  inputIssues: string | null;
  inputReady: boolean;
  onSuccessCallback: BeamSuccessCallback | null;

}

const initRootStateSlice = (): RootStateSlice => ({

  isOpen: false,
  isEditMode: false,
  isMaximized: false,
  inputHistory: null,
  inputIssues: null,
  inputReady: false,
  onSuccessCallback: null,

});

export interface RootStoreSlice extends RootStateSlice {

  // lifecycle
  open: (chatHistory: Readonly<DMessage[]>, initialChatLlmId: DLLMId | null, isEditMode: boolean, callback: BeamSuccessCallback) => void;
  terminateKeepingSettings: () => void;
  loadBeamConfig: (preset: BeamConfigSnapshot | null) => void;

  setIsMaximized: (maximized: boolean) => void;
  inputHistoryReplaceMessageFragment: (messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment) => void;

}


const createRootSlice: StateCreator<BeamStore, [], [], RootStoreSlice> = (_set, _get) => ({

  // init state
  ...initRootStateSlice(),


  open: (chatHistory: Readonly<DMessage[]>, initialChatLlmId: DLLMId | null, isEditMode: boolean, callback: BeamSuccessCallback) => {
    const { isOpen: wasAlreadyOpen, terminateKeepingSettings, loadBeamConfig, hadImportedRays, setRayLlmIds, setCurrentGatherLlmId } = _get();

    // reset pending operations
    terminateKeepingSettings();

    // validate history
    const history = [...chatHistory];
    const isValidHistory = history.length >= 1 && history[history.length - 1].role === 'user';

    // show and set input
    _set({
      // input
      isOpen: true,
      isEditMode,
      inputHistory: isValidHistory ? history : null,
      inputIssues: isValidHistory ? null : 'Invalid conversation history: missing user message',
      inputReady: isValidHistory,
      onSuccessCallback: callback,

      // rays already reset
      hadImportedRays,

      // update the model only if the dialog was not already open
      ...(!wasAlreadyOpen && initialChatLlmId && {
        currentGatherLlmId: initialChatLlmId,
      } satisfies Partial<GatherStoreSlice>),
    });

    // if not empty (recycle an existing open beam for this chat), we're done
    if (_get().rays.length)
      return;

    // if empty, initialize from the persisted config, if any
    loadBeamConfig(useModuleBeamStore.getState().lastConfig);
    if (_get().rays.length)
      return;

    // it no config (first-time): Heuristic: auto-pick the best models for the user, based on their ELO and variety
    const autoLlmIds = llmsHeuristicGetTopDiverseLlmIds(SCATTER_RAY_DEF, true, initialChatLlmId);
    if (autoLlmIds.length > 0) {
      setRayLlmIds(autoLlmIds);
      setCurrentGatherLlmId(autoLlmIds[0]);
    }
  },

  terminateKeepingSettings: () =>
    _set(state => ({
      ...initRootStateSlice(),
      ...reInitScatterStateSlice(state.rays),
      ...reInitGatherStateSlice(state.fusions, state.currentGatherLlmId),  // remember after termination
    })),


  loadBeamConfig: (preset: BeamConfigSnapshot | null) => {
    if (preset) {
      const { setRayLlmIds, setCurrentGatherLlmId, setCurrentFactoryId } = _get();
      preset.rayLlmIds?.length && setRayLlmIds(preset.rayLlmIds);
      preset.gatherLlmId && setCurrentGatherLlmId(preset.gatherLlmId);
      preset.gatherFactoryId && setCurrentFactoryId(preset.gatherFactoryId);
    }
  },


  setIsMaximized: (maximized: boolean) =>
    _set({
      isMaximized: maximized,
    }),

  inputHistoryReplaceMessageFragment: (messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment) =>
    _set(state => ({
      inputHistory: state.inputHistory?.map((message): DMessage => {
        if (message.id !== messageId)
          return message;

        // probably unnecessary development warning
        if (message.fragments.findIndex(f => f.fId === fragmentId) === -1) {
          console.error(`inputHistoryReplaceMessageFragment: cannot find missing fragment ID ${fragmentId} for message ${messageId}`);
          return message;
        }

        const updatedFragments = message.fragments.map((fragment) =>
          (fragment.fId === fragmentId)
            ? newFragment
            : fragment,
        );

        return {
          ...message,
          fragments: updatedFragments,
          updated: Date.now(),
        };
      }),
    })),

});




================================================
FILE: src/modules/beam/store-module-beam.tsx
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import type { DLLMId } from '~/common/stores/llms/llms.types';
import { agiUuid } from '~/common/util/idUtils';

import type { FFactoryId } from './gather/instructions/beam.gather.factories';


/// Presets (persisted as zustand store) ///

export interface BeamConfigSnapshot {
  id: string;
  name: string;
  rayLlmIds: DLLMId[];
  gatherFactoryId?: FFactoryId | null;  // added post launch
  gatherLlmId?: DLLMId | null;          // added post launch
}


interface ModuleBeamState {

  // stored
  presets: BeamConfigSnapshot[];
  lastConfig: BeamConfigSnapshot | null;
  cardAdd: boolean;
  cardScrolling: boolean;
  scatterShowLettering: boolean;
  scatterShowPrevMessages: boolean;
  gatherAutoStartAfterScatter: boolean;
  gatherShowAllPrompts: boolean;

  // non-stored, temporary but useful for the UI
  openBeamConversationIds: Record<string, boolean>;

}

interface ModuleBeamStore extends ModuleBeamState {
  addPreset: (name: string, rayLlmIds: DLLMId[], gatherLlmId: DLLMId | null, gatherFactoryId: FFactoryId | null) => void;
  deletePreset: (id: string) => void;
  renamePreset: (id: string, name: string) => void;

  updateLastConfig: (update: Partial<BeamConfigSnapshot>) => void;
  deleteLastConfig: () => void;

  toggleCardAdd: () => void;
  toggleCardScrolling: () => void;
  toggleScatterShowLettering: () => void;
  toggleScatterShowPrevMessages: () => void;
  toggleGatherAutoStartAfterScatter: () => void;
  toggleGatherShowAllPrompts: () => void;

  setBeamOpenForConversation: (conversationId: DConversationId, isOpen: boolean) => void;
  clearBeamOpenForConversation: (conversationId: DConversationId) => void;
}


export const useModuleBeamStore = create<ModuleBeamStore>()(persist(
  (_set, _get) => ({

    presets: [],
    lastConfig: null,
    cardAdd: true,
    cardScrolling: false,
    scatterShowLettering: false,
    scatterShowPrevMessages: false,
    gatherShowAllPrompts: false,
    gatherAutoStartAfterScatter: false,
    openBeamConversationIds: {},


    addPreset: (name, rayLlmIds, gatherLlmId, gatherFactoryId) => _set(state => ({
      presets: [...state.presets, {
        id: agiUuid('beam-preset-config'),
        name,
        rayLlmIds,
        gatherLlmId: gatherLlmId ?? undefined,
        gatherFactoryId: gatherFactoryId ?? undefined,
      }],
    })),

    deletePreset: (id) => _set(state => ({
      presets: state.presets.filter(preset => preset.id !== id),
    })),

    renamePreset: (id, name) => _set(state => ({
      presets: state.presets.map(preset => preset.id === id ? { ...preset, name } : preset),
    })),


    updateLastConfig: (update) => _set(({ lastConfig }) => ({
      lastConfig: !lastConfig
        ? { id: 'current', name: '', rayLlmIds: [], ...update }
        : { ...lastConfig, ...update },
    })),

    deleteLastConfig: () => _set({ lastConfig: null }),


    toggleCardAdd: () => _set(state => ({ cardAdd: !state.cardAdd })),

    toggleCardScrolling: () => _set(state => ({ cardScrolling: !state.cardScrolling })),

    toggleScatterShowLettering: () => _set(state => ({ scatterShowLettering: !state.scatterShowLettering })),

    toggleScatterShowPrevMessages: () => _set(state => ({ scatterShowPrevMessages: !state.scatterShowPrevMessages })),

    toggleGatherAutoStartAfterScatter: () => _set(state => ({ gatherAutoStartAfterScatter: !state.gatherAutoStartAfterScatter })),

    toggleGatherShowAllPrompts: () => _set(state => ({ gatherShowAllPrompts: !state.gatherShowAllPrompts })),

    setBeamOpenForConversation: (conversationId, isOpen) => _set(state => {
      const openBeams = { ...state.openBeamConversationIds };
      if (isOpen)
        openBeams[conversationId] = true;
      else
        delete openBeams[conversationId];
      return { openBeamConversationIds: openBeams };
    }),

    clearBeamOpenForConversation: (conversationId) => _set(state => {
      const openBeams = { ...state.openBeamConversationIds };
      delete openBeams[conversationId];
      return { openBeamConversationIds: openBeams };
    }),

  }), {
    name: 'app-module-beam',
    version: 1,

    partialize: (state) => {
      // exclude openBeamConversationIds from persistence
      const { openBeamConversationIds, ...persistedState } = state;
      return persistedState;
    },

    migrate: (state: any, fromVersion: number): Omit<ModuleBeamState, 'openBeamConversationIds'> => {
      // 0 -> 1: rename 'scatterPresets' to 'presets'
      if (state && fromVersion === 0 && !state.presets)
        return { ...state, presets: state.scatterPresets || [] };
      return state;
    },
  },
));


export function getBeamCardScrolling() {
  return useModuleBeamStore.getState().cardScrolling;
}

export function useBeamCardScrolling() {
  return useModuleBeamStore((state) => state.cardScrolling);
}

export function useBeamScatterShowLettering() {
  return useModuleBeamStore((state) => state.scatterShowLettering);
}

export function useIsBeamOpenForConversation(conversationId: DConversationId | null): boolean {
  return useModuleBeamStore(state => conversationId ? state.openBeamConversationIds[conversationId] ?? false : false);
}

export function updateBeamLastConfig(update: Partial<BeamConfigSnapshot>) {
  useModuleBeamStore.getState().updateLastConfig(update);
}


================================================
FILE: src/modules/beam/gather/beam.gather.ts
================================================
import * as React from 'react';
import type { StateCreator } from 'zustand/vanilla';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import type { DMessage } from '~/common/stores/chat/chat.message';
import { agiUuid } from '~/common/util/idUtils';

import { CUSTOM_FACTORY_ID, FFactoryId, findFusionFactory, FUSION_FACTORIES, FUSION_FACTORY_DEFAULT } from './instructions/beam.gather.factories';
import { RootStoreSlice } from '../store-beam_vanilla';
import { ScatterStoreSlice } from '../scatter/beam.scatter';
import { gatherStartFusion, gatherStopFusion, Instruction } from './instructions/beam.gather.execution';
import { updateBeamLastConfig } from '../store-module-beam';


/// Gather Store > BFusion ///

type BFusionId = string;

type BFusionStage =
  | 'idle'      // at the beginning, never go back here
  | 'fusing'    // in progress (progressX is defined)
  | 'success'   // completed successfully
  | 'stopped'   // aborted by the user
  | 'error';    // failed (fusionIssue is defined)


export interface BFusion {
  // const
  readonly fusionId: BFusionId;
  readonly factoryId: FFactoryId;

  // options
  instructions: Instruction[];
  llmId: DLLMId | null;

  // status
  stage: BFusionStage;
  errorText?: string;
  outputDMessage?: DMessage;

  // execution state to sync Instruction I/O with the UI
  fusingAbortController?: AbortController; // of the full chain
  fusingProgressComponent?: React.ReactNode;
  fusingInstructionComponent?: React.ReactNode;
}

const createBFusion = (factoryId: FFactoryId, instructions: Instruction[], llmId: DLLMId | null): BFusion => ({
  // const
  fusionId: agiUuid('beam-fusion'),
  factoryId,

  // options
  instructions,
  llmId,

  // status
  stage: 'idle',
  errorText: undefined,
  outputDMessage: undefined,

  // execution progress
  fusingAbortController: undefined,
  fusingProgressComponent: undefined,
  fusingInstructionComponent: undefined,
});


export function fusionIsEditable(fusion: BFusion | null): boolean {
  return fusion?.factoryId === CUSTOM_FACTORY_ID;
}

export function fusionIsIdle(fusion: BFusion | null): boolean {
  return fusion?.stage === 'idle';
}

export function fusionIsFusing(fusion: BFusion | null): boolean {
  return fusion?.stage === 'fusing';
}

export function fusionIsStopped(fusion: BFusion | null): boolean {
  return fusion?.stage === 'stopped';
}

export function fusionIsUsableOutput(fusion: BFusion | null): boolean {
  return !!fusion?.outputDMessage?.fragments.length;
}

export function fusionIsError(fusion: BFusion | null): boolean {
  return fusion?.stage === 'error' || fusion?.errorText !== undefined;
}


/// Gather State Slice ///

interface GatherStateSlice {

  currentFactoryId: FFactoryId | null;
  currentGatherLlmId: DLLMId | null;

  fusions: BFusion[];

  // derived state (just acts as a cache to avoid re-calculating)
  isGatheringAny: boolean;
  // fusionsReady: number;

}

export const reInitGatherStateSlice = (prevFusions: BFusion[], gatherLlmId: DLLMId | null): GatherStateSlice => {
  // stop any ongoing fusions
  prevFusions.forEach(gatherStopFusion);

  return {
    currentFactoryId: FUSION_FACTORY_DEFAULT,
    currentGatherLlmId: gatherLlmId, // may be re-set during open() of the Beam Store

    fusions: [],

    isGatheringAny: false,
    // fusionsReady: 0,
  };
};

export type FusionUpdateOrFn = Partial<BFusion> | ((fusion: BFusion) => (Partial<BFusion> | null));

export interface GatherStoreSlice extends GatherStateSlice {

  setCurrentGatherLlmId: (llmId: DLLMId | null) => void;
  setCurrentFactoryId: (factoryId: FFactoryId | null) => void;

  _fusionUpdate: (fusionId: BFusionId, update: FusionUpdateOrFn) => void;
  fusionRecreateAsCustom: (sourceFusionId: BFusionId) => void;
  fusionInstructionUpdate: (fusionId: BFusionId, instructionIndex: number, update: Partial<Instruction>) => void;
  fusionSetLlmId: (fusionId: BFusionId, llmId: DLLMId | null) => void;

  createFusion: () => void;
  removeFusion: (fusionId: BFusionId) => void;
  toggleFusionGathering: (fusionId: BFusionId) => void;

}

export const createGatherSlice: StateCreator<RootStoreSlice & ScatterStoreSlice & GatherStoreSlice, [], [], GatherStoreSlice> = (_set, _get) => ({

  // initial state
  ...reInitGatherStateSlice([], null),


  setCurrentFactoryId: (factoryId: FFactoryId | null) => {
    _set({
      currentFactoryId: factoryId,
    });
    updateBeamLastConfig({ gatherFactoryId: factoryId });
  },

  setCurrentGatherLlmId: (llmId: DLLMId | null) => {
    _set({
      currentGatherLlmId: llmId,
    });
    updateBeamLastConfig({ gatherLlmId: llmId });
  },


  _fusionUpdate: (fusionId: BFusionId, update: FusionUpdateOrFn) => {
    const { fusions } = _get();

    const newFusions = fusions.map(fusion => (fusion.fusionId === fusionId)
      ? { ...fusion, ...(typeof update === 'function' ? update(fusion) : update) }
      : fusion,
    );

    // 'or' the status of all fusions
    const isGatheringAny = newFusions.some(fusionIsFusing);
    // const fusionsReady = newFusions.filter(fusionIsUsableOutput).length;

    _set({
      fusions: newFusions,
      isGatheringAny,
      // fusionsReady,
    });
  },

  fusionRecreateAsCustom: (sourceFusionId: BFusionId) => {
    const { fusions, currentGatherLlmId } = _get();

    // finds the fusion and its factory
    const sourceFusion = fusions.find(fusion => fusion.fusionId === sourceFusionId);
    const sourceFusionFactory = findFusionFactory(sourceFusion?.factoryId);
    if (!sourceFusion || !sourceFusionFactory)
      return;

    // create a custom from the source fusion factory
    const newCustomFusion: BFusion = createBFusion(CUSTOM_FACTORY_ID, sourceFusionFactory.createInstructions(), currentGatherLlmId);

    // replace the only editable fusion with the new custom fusion
    _set({
      fusions: fusions.map(_f => {
        if (!fusionIsEditable(_f)) return _f;
        gatherStopFusion(_f);
        return newCustomFusion;
      }),
    });
  },

  fusionInstructionUpdate: (fusionId: BFusionId, instructionIndex: number, update: Partial<Instruction>) =>
    _get()._fusionUpdate(fusionId, fusion => ({
      instructions: fusion.instructions.map((instruction, index) => (index === instructionIndex)
        ? { ...instruction, ...update as any /* Note: do not update a different 'type' of instruction ... */ }
        : instruction,
      ),
    })),

  fusionSetLlmId: (fusionId: BFusionId, llmId: DLLMId | null) =>
    _get()._fusionUpdate(fusionId, {
      llmId,
    }),


  createFusion: () => {
    // get factory
    const { currentFactoryId, currentGatherLlmId, fusions, toggleFusionGathering } = _get();
    const factory = FUSION_FACTORIES.find(factory => factory.factoryId === currentFactoryId);
    if (!factory)
      return;

    // create and append the fusion
    const newFusion = createBFusion(factory.factoryId, factory.createInstructions(), currentGatherLlmId);
    _set({
      fusions: [...fusions, newFusion],
    });

    // start the fusion, if not custom
    if (newFusion.factoryId !== CUSTOM_FACTORY_ID)
      toggleFusionGathering(newFusion.fusionId);
  },

  removeFusion: (fusionId: BFusionId) => {
    const fusion = _get().fusions.find(fusion => fusion.fusionId === fusionId);
    if (fusion) {
      gatherStopFusion(fusion);
      _set(state => ({
        fusions: state.fusions.filter(fusion => fusion.fusionId !== fusionId),
      }));
    }
  },


  toggleFusionGathering: (fusionId: BFusionId) => {
    // this will start/stop the fusion
    const fusion = _get().fusions.find(fusion => fusion.fusionId === fusionId);
    if (!fusion) return;

    // stop if fusing
    if (fusion?.stage === 'fusing')
      return gatherStopFusion(fusion);

    // start: update the model (NOTE: keep the same per-fusion)
    // _fusionUpdate(fusion.fusionId, { llmId: currentGatherLlmId });

    // start the fusion
    const { inputHistory, rays, _fusionUpdate } = _get();
    const chatMessages = inputHistory ? [...inputHistory] : [];
    const rayMessages = rays.map(ray => ray.message).filter(message => !!message.fragments.length);
    const onUpdate = (update: FusionUpdateOrFn) => _fusionUpdate(fusion.fusionId, update);
    gatherStartFusion(fusion, chatMessages, rayMessages, onUpdate);
  },

});



================================================
FILE: src/modules/beam/gather/BeamFusionGrid.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { SxProps, VariantProp } from '@mui/joy/styles/types';
import { Alert, Box, Button, Typography, useTheme } from '@mui/joy';
import AddCircleOutlineRoundedIcon from '@mui/icons-material/AddCircleOutlineRounded';
import LanguageRoundedIcon from '@mui/icons-material/LanguageRounded';

import { BrowserLang } from '~/common/util/pwaUtils';

import { Fusion } from './Fusion';
import { findFusionFactory, FusionFactorySpec } from './instructions/beam.gather.factories';

import { BeamCard, beamCardClasses } from '../BeamCard';
import { BeamStoreApi, useBeamStore } from '../store-beam.hooks';
import { GATHER_COLOR } from '../beam.config';


const fusionGridDesktopSx: SxProps = {
  mt: 'calc(-1 * var(--Pad))', // absorb parent 'gap' to previous

  px: 'var(--Pad)',
  pb: 'var(--Pad)',
  // backgroundColor: 'neutral.solidBg',
  // mb:'auto',

  // like rayGridDesktopSx
  display: 'grid',
  gridTemplateColumns: 'repeat(auto-fit, minmax(max(min(100%, 390px), 100%/5), 1fr))',
  gap: 'var(--Pad)',
} as const;

const fusionGridMobileSx: SxProps = {
  ...fusionGridDesktopSx,
  gridTemplateColumns: 'repeat(auto-fit, minmax(320px, 1fr))',
} as const;


export function FusionAddButton(props: {
  canGather: boolean,
  currentFactory: FusionFactorySpec | null,
  onAddFusion: () => void,
  sx?: SxProps,
  small?: boolean,
  textOverride?: string,
  variant?: VariantProp,
}) {
  if (props.currentFactory === null) return null;
  return (
    <Button
      size={props.small ? 'sm' : undefined}
      color={GATHER_COLOR}
      variant={props.variant}
      disabled={!props.canGather}
      onClick={props.onAddFusion}
      startDecorator={props.currentFactory?.Icon ? <props.currentFactory.Icon /> : <AddCircleOutlineRoundedIcon />}
      sx={{
        // justifyContent: 'end',
        // gap: 1,
        ...props.sx,
      }}
    >
      {props.textOverride || props.currentFactory?.addLabel}
    </Button>
  );
}


export function BeamFusionGrid(props: {
  beamStore: BeamStoreApi,
  canGather: boolean,
  fusionIds: string[],
  isMobile: boolean,
  onAddFusion: () => void,
  raysCount: number,
}) {

  // external state
  const {
    currentFactory,
  } = useBeamStore(props.beamStore, useShallow(state => ({
    currentFactory: findFusionFactory(state.currentFactoryId),
  })));
  const isDarkMode = useTheme().palette.mode === 'dark';


  // derived state
  const isEmpty = props.fusionIds.length === 0;
  const isNoFactorySelected = currentFactory === null;


  // to balance things out with the ray grid, we may need to pad the items
  // const targetCount = props.raysCount + 1;
  // const fusionCount = props.fusionIds.length + 1;
  // // const padItems = targetCount - fusionCount;
  // const padItems = 1;

  return (
    <Box sx={{
      ...(props.isMobile ? fusionGridMobileSx : fusionGridDesktopSx),
      ...(isEmpty ? {
        backgroundColor: isDarkMode ? 'neutral.900' : 'neutral.solidBg',
      } : {
        backgroundColor: isDarkMode ? 'success.900' : '#F2FFFA', // f8fff8 was good, too close to the gree hue
        pt: 'var(--Pad)',
      }),
    }}>

      {/* Fusions */}
      {props.fusionIds.map((fusionId) => (
        <Fusion
          key={'fusion-' + fusionId}
          beamStore={props.beamStore}
          fusionId={fusionId}
          isMobile={props.isMobile}
        />
      ))}

      {/* Add Fusion (Card) */}
      {(isEmpty || !isNoFactorySelected) && (
        <BeamCard
          className={isEmpty ? beamCardClasses.smashTop : undefined}
          sx={{
            backgroundColor: props.canGather ? `${GATHER_COLOR}.softBg` : isDarkMode ? 'neutral.700' : undefined,
            // boxShadow: `0px 6px 16px -12px rgb(var(--joy-palette-${props.canGather ? GATHER_COLOR : 'neutral'}-darkChannel) / 40%)`,
            mb: 'auto',
          }}
        >
          {isNoFactorySelected ? null : props.canGather ? <Box sx={{ display: 'flex', flexDirection: props.isMobile ? 'column-reverse' : undefined, alignItems: props.isMobile ? undefined : 'center', gap: 1 }}>

            <FusionAddButton
              // small
              // variant='soft'
              canGather={props.canGather}
              currentFactory={currentFactory}
              onAddFusion={props.onAddFusion}
              sx={{
                minHeight: props.isMobile ? 'calc(2 * var(--Card-padding) + 2rem - 0.5rem)' : undefined,
                // marginBottom: 'calc(-1 * var(--Card-padding) + 0.25rem)',
                // marginInline: 'calc(-1 * var(--Card-padding) + 0.375rem)',
                whiteSpace: 'nowrap',
              }}
            />

            <Typography level='body-sm' variant='soft' color={GATHER_COLOR}>
              {currentFactory.description}
            </Typography>

          </Box> : (
            <Typography level='body-sm' sx={{ opacity: 0.8 }}>
              {/*You need two or more replies for a {currentFactory?.shortLabel?.toLocaleLowerCase() ?? ''} merge.*/}
              Waiting for multiple responses.
            </Typography>
          )}
        </BeamCard>
      )}

      {/* Full-width warning if not */}
      {BrowserLang.notUS && (
        <Alert color='warning' sx={{
          // full row of the grid
          gridColumn: '1 / -1',
        }}>
          <Typography level='body-sm' color='warning' startDecorator={<LanguageRoundedIcon />}>
            Note: Merges are defined in English and have not been translated to your browser language ({navigator.language}) yet.
          </Typography>
        </Alert>
      )}

      {/* Pad items: N * <Box/> */}
      {/*{padItems > 0 && (*/}
      {/*  Array.from({ length: padItems }).map((_, index) => (*/}
      {/*    <Box key={'pad-' + index} />*/}
      {/*  ))*/}
      {/*)}*/}

    </Box>
  );
}


================================================
FILE: src/modules/beam/gather/BeamGatherPane.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { ColorPaletteProp, SxProps } from '@mui/joy/styles/types';
import { Box, Button, ButtonGroup, FormControl, Typography } from '@mui/joy';
import AutoAwesomeIcon from '@mui/icons-material/AutoAwesome';
import AutoAwesomeOutlinedIcon from '@mui/icons-material/AutoAwesomeOutlined';

import { LLM_IF_OAI_Reasoning } from '~/common/stores/llms/llms.types';
import { animationColorBeamGather } from '~/common/util/animUtils';
import { useLLMSelect } from '~/common/components/forms/useLLMSelect';

import { BeamStoreApi, useBeamStore } from '../store-beam.hooks';
import { FFactoryId, FUSION_FACTORIES } from './instructions/beam.gather.factories';
import { BEAM_SHOW_REASONING_ICON, GATHER_COLOR } from '../beam.config';
import { beamPaneSx } from '../BeamCard';
import { useModuleBeamStore } from '../store-module-beam';


const gatherPaneClasses = {
  busy: 'gatherPane-Busy',
  ready: 'gatherPane-Ready',
};

const gatherPaneSx: SxProps = {
  ...beamPaneSx,
  borderTop: '1px solid',
  borderTopColor: 'neutral.outlinedBorder',

  backgroundColor: 'background.surface',
  boxShadow: `0px 6px 20px -8px rgb(var(--joy-palette-neutral-darkChannel) / 30%)`,
  [`&.${gatherPaneClasses.ready}`]: {
    backgroundColor: 'background.popup',
    // boxShadow: `0px 6px 16px -8px rgb(var(--joy-palette-success-darkChannel) / 40%)`,
  },
  [`&.${gatherPaneClasses.busy}`]: {
    // animation: `${animationShadowRingLimey} 2s linear infinite`,
  },
};

const mobileGatherPaneSx: SxProps = {
  ...gatherPaneSx,

  // [mobile] larger gap in between rows, as on mobile we have a smaller gap
  rowGap: 'var(--Pad)',
};

const desktopGatherPaneSx: SxProps = {
  ...gatherPaneSx,

  // [desktop] keep visible at the bottom
  position: 'sticky',
  bottom: 0,
  top: 0,
};


export function BeamGatherPane(props: {
  beamStore: BeamStoreApi,
  canGather: boolean,
  isMobile: boolean,
  // onAddFusion: () => void,
  raysReady: number,
}) {


  // external state
  // const { setStickToBottom } = useScrollToBottom();
  const {
    currentFactoryId, currentGatherLlmId, isGatheringAny, hasFusions,
    setCurrentFactoryId, setCurrentGatherLlmId,
  } = useBeamStore(props.beamStore, useShallow(state => ({
    // state
    // currentFactory: findFusionFactory(state.currentFactoryId),
    currentFactoryId: state.currentFactoryId,
    currentGatherLlmId: state.currentGatherLlmId,
    isGatheringAny: state.isGatheringAny,
    hasFusions: state.fusions.length > 0,

    // actions
    setCurrentFactoryId: state.setCurrentFactoryId,
    setCurrentGatherLlmId: state.setCurrentGatherLlmId,
  })));
  const gatherAutoStartAfterScatter = useModuleBeamStore(state => state.gatherAutoStartAfterScatter);
  const disableUnlessAutoStart = !props.canGather && !gatherAutoStartAfterScatter;
  const [llmOrNull, gatherLlmComponent/*, gatherLlmIcon*/] = useLLMSelect(currentGatherLlmId, setCurrentGatherLlmId, {
    label: props.isMobile ? '' : 'Merge Model',
    disabled: disableUnlessAutoStart,
  });

  // derived state
  const llmShowReasoning = !BEAM_SHOW_REASONING_ICON ? false : llmOrNull?.interfaces?.includes(LLM_IF_OAI_Reasoning) ?? false;
  // const isNoFactorySelected = currentFactoryId === null;

  // const CurrentFactoryIcon = currentFactory?.Icon ?? null;
  // const currentFactoryDescription = currentFactory?.description ?? '';

  const handleFactoryActivate = React.useCallback((factoryId: FFactoryId, shiftPressed: boolean) => {
    // setStickToBottom(true);
    setCurrentFactoryId((factoryId !== currentFactoryId || !shiftPressed) ? factoryId : null);
  }, [currentFactoryId, setCurrentFactoryId]);


  const MainLlmIcon = /*gatherLlmIcon ||*/ (isGatheringAny ? AutoAwesomeIcon : AutoAwesomeOutlinedIcon);

  return (
    <Box
      className={`${props.canGather ? gatherPaneClasses.ready : ''} ${isGatheringAny ? gatherPaneClasses.busy : ''}`}
      sx={props.isMobile ? mobileGatherPaneSx : desktopGatherPaneSx}
    >

      {/* Title */}
      <Box>
        <Typography
          level='h4' component='h3'
          // endDecorator={<ScrollToBottomButton inline />}
          // sx={{ my: 0.25 }}
          sx={(props.canGather || hasFusions || isGatheringAny) ? undefined : { color: 'primary.solidDisabledColor', ['& > svg']: { color: 'primary.solidDisabledColor' } }}
        >
          <MainLlmIcon sx={{ fontSize: '1rem', mr: 0.625, animation: isGatheringAny ? `${animationColorBeamGather} 2s linear infinite` : undefined }} />
          Merge
        </Typography>
        <Typography level='body-sm' sx={{ whiteSpace: 'nowrap' }}>
          {/* may merge or not (hasInputs) N replies.. put this in pretty messages */}
          {props.canGather ? `Combine the ${props.raysReady} replies` : /*'Fuse all replies'*/ ''}
        </Typography>
      </Box>

      {/* Method */}
      <FormControl sx={{ my: '-0.25rem' }}>
        {/*{!props.isMobile && <FormLabelStart title='Method' />}*/}
        <ButtonGroup
          variant='outlined'
          size='md'
          disabled={disableUnlessAutoStart}
          // sx={{ boxShadow: isNoFactorySelected ? 'xs' : undefined }}
        >
          {FUSION_FACTORIES.map(factory => {
            const { factoryId, shortLabel } = factory;
            const isActive = factoryId === currentFactoryId;
            const buttonColor: ColorPaletteProp = isActive ? GATHER_COLOR : 'neutral';
            return (
              <Button
                key={'factory-' + factoryId}
                color={buttonColor}
                onClick={event => handleFactoryActivate(factoryId, !!event?.shiftKey)}
                // startDecorator={(isActive && Icon) ? <Icon /> : null}
                sx={{
                  backgroundColor: isActive ? `${buttonColor}.softBg` : 'background.popup',
                  // fontWeight: isActive ? 'lg' : 'md', /* reset, from 600 */
                  // minHeight: '2.25rem',
                }}
              >
                {shortLabel}
              </Button>
            );
          })}
        </ButtonGroup>
      </FormControl>

      {/* Display a Reasoning LLM */}
      {(BEAM_SHOW_REASONING_ICON && llmShowReasoning) ? '🧠' : null}

      {/* LLM */}
      <Box sx={{ my: '-0.25rem', minWidth: 190, maxWidth: 300 }}>
        {gatherLlmComponent}
      </Box>

      {/* Add Fusion */}
      {/*<FusionAddButton*/}
      {/*  textOverride='Add'*/}
      {/*  canGather={props.canGather}*/}
      {/*  currentFactory={currentFactory}*/}
      {/*  onAddFusion={props.onAddFusion}*/}
      {/*  sx={BEAM_BTN_SX}*/}
      {/*/>*/}

      {/* pad */}
      <Box />

    </Box>
  );
}


================================================
FILE: src/modules/beam/gather/Fusion.tsx
================================================
import * as React from 'react';

import { Box, IconButton } from '@mui/joy';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import TelegramIcon from '@mui/icons-material/Telegram';

import { ChatMessageMemo } from '../../../apps/chat/components/message/ChatMessage';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { messageFragmentsReduceText } from '~/common/stores/chat/chat.message';

import { GoodTooltip } from '~/common/components/GoodTooltip';
import { InlineError } from '~/common/components/InlineError';
import { animationEnterBelow } from '~/common/util/animUtils';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { useLLMSelect } from '~/common/components/forms/useLLMSelect';

import { BeamCard, beamCardClasses, beamCardMessageScrollingSx, beamCardMessageSx, beamCardMessageWrapperSx } from '../BeamCard';
import { BeamStoreApi, useBeamStore } from '../store-beam.hooks';
import { FusionControlsMemo } from './FusionControls';
import { FusionInstructionsEditor } from './FusionInstructionsEditor';
import { GATHER_COLOR } from '../beam.config';
import { findFusionFactory } from './instructions/beam.gather.factories';
import { fusionIsEditable, fusionIsError, fusionIsFusing, fusionIsIdle, fusionIsStopped, fusionIsUsableOutput } from './beam.gather';
import { useBeamCardScrolling } from '../store-module-beam';
import { useMessageAvatarLabel } from '~/common/util/dMessageUtils';


export function Fusion(props: {
  beamStore: BeamStoreApi,
  fusionId: string,
  isMobile: boolean,
}) {

  // state
  const [showLlmSelector, setShowLlmSelector] = React.useState(false);

  // external state
  const fusion = useBeamStore(props.beamStore, store => store.fusions.find(fusion => fusion.fusionId === props.fusionId) ?? null);
  const cardScrolling = useBeamCardScrolling();

  // derived state
  const isEditable = fusionIsEditable(fusion);
  const isIdle = fusionIsIdle(fusion);
  const isError = fusionIsError(fusion);
  const isFusing = fusionIsFusing(fusion);
  const isStopped = fusionIsStopped(fusion);
  const isUsable = fusionIsUsableOutput(fusion);
  const showUseButtons = isUsable && !isFusing;
  const { tooltip: fusionAvatarTooltip } = useMessageAvatarLabel(fusion?.outputDMessage, 'pro');

  const factory = findFusionFactory(fusion?.factoryId);

  const { removeFusion, toggleFusionGathering, fusionSetLlmId } = props.beamStore.getState();

  // get LLM Label and Vendor Icon
  const llmId = fusion?.llmId ?? null;
  const setLlmId = React.useCallback((llmId: DLLMId | null) => fusionSetLlmId(props.fusionId, llmId), [props.fusionId, fusionSetLlmId]);
  const [llmOrNull, llmComponent, llmVendorIcon] = useLLMSelect(llmId, setLlmId, {
    label: '',
    disabled: isFusing,
  });

  // hide selector when fusion starts
  React.useEffect(() => {
    isFusing && setShowLlmSelector(false);
  }, [isFusing]);

  // more derived
  const llmLabel = llmOrNull?.label || 'Model unknown';

  // handlers
  const handleFusionCopyToClipboard = React.useCallback(() => {
    const { fusions } = props.beamStore.getState();
    const fusion = fusions.find(fusion => fusion.fusionId === props.fusionId);
    if (fusion?.outputDMessage?.fragments.length)
      copyToClipboard(messageFragmentsReduceText(fusion.outputDMessage.fragments), 'Merge');
  }, [props.beamStore, props.fusionId]);

  const handleFusionUse = React.useCallback(() => {
    // get snapshot values, so we don't have to react to the hook
    const { fusions, onSuccessCallback } = props.beamStore.getState();
    const fusion = fusions.find(fusion => fusion.fusionId === props.fusionId);
    if (fusion?.outputDMessage?.fragments.length && onSuccessCallback)
      onSuccessCallback(fusion.outputDMessage);
  }, [props.beamStore, props.fusionId]);

  const handleIconClick = React.useCallback((event: React.MouseEvent) => {
    if (event.shiftKey) {
      const fusion = props.beamStore.getState().fusions.find(fusion => fusion.fusionId === props.fusionId);
      console.log({ fusion });
      return;
    }
    // Toggle LLM selector
    setShowLlmSelector(!showLlmSelector);
  }, [showLlmSelector, props.beamStore, props.fusionId]);

  const handleFusionRemove = React.useCallback(() => {
    removeFusion(props.fusionId);
  }, [props.fusionId, removeFusion]);

  const handleToggleFusionGather = React.useCallback(() => {
    toggleFusionGathering(props.fusionId);
  }, [props.fusionId, toggleFusionGathering]);

  // escape hatch: no factory, no fusion - nothing to do
  if (!fusion || !factory)
    return;

  return (
    <BeamCard
      role='beam-card'
      tabIndex={-1}
      className={
        // (isIdle ? beamCardClasses.fusionIdle : '')
        (isError ? beamCardClasses.errored + ' ' : '')
        + ((isUsable || isFusing || isIdle) ? beamCardClasses.selectable + ' ' : '')
        + (isFusing ? beamCardClasses.attractive + ' ' : '')
        // + (beamCardClasses.smashTop + ' ')
      }
    >

      {/* Controls Row */}
      <FusionControlsMemo
        fusion={fusion}
        factory={factory}
        isFusing={isFusing}
        isInterrupted={isStopped}
        isMobile={props.isMobile}
        isUsable={isUsable}
        llmComponent={(isFusing || !showLlmSelector) ? undefined : llmComponent}
        llmLabel={llmLabel}
        llmVendorIcon={llmVendorIcon}
        fusionAvatarTooltip={fusionAvatarTooltip}
        onIconClick={isFusing ? undefined : handleIconClick}
        onRemove={handleFusionRemove}
        onToggleGenerate={handleToggleFusionGather}
      />

      {isEditable && (
        <FusionInstructionsEditor
          beamStore={props.beamStore}
          factory={factory}
          fusionId={props.fusionId}
          instructions={fusion.instructions}
          isFusing={isFusing}
          isIdle={isIdle}
          onStart={handleToggleFusionGather}
        />
      )}

      {/* Show issue, if any */}
      {isError && <InlineError error={fusion?.errorText || 'Merge Issue'} />}


      {/* Dynamic: instruction-specific components */}
      {!!fusion?.fusingInstructionComponent && fusion.fusingInstructionComponent}

      {/* Output Message */}
      {(!!fusion?.outputDMessage?.fragments.length || fusion?.stage === 'fusing') && (
        <Box sx={beamCardMessageWrapperSx}>
          {!!fusion.outputDMessage && (
            <ChatMessageMemo
              message={fusion.outputDMessage}
              fitScreen={true}
              isMobile={props.isMobile}
              hideAvatar
              showUnsafeHtmlCode={true}
              adjustContentScaling={-1}
              sx={!cardScrolling ? beamCardMessageSx : beamCardMessageScrollingSx}
            />
          )}
        </Box>
      )}


      {/* Use Fusion */}
      {showUseButtons && (
        <Box sx={{ mt: 'auto', mb: -1, mr: -1, placeSelf: 'end', display: 'flex', gap: 1 }}>

          {/* Copy */}
          <GoodTooltip title='Copy'>
            <IconButton
              onClick={handleFusionCopyToClipboard}
            >
              <ContentCopyIcon sx={{ fontSize: 'md' }} />
            </IconButton>
          </GoodTooltip>

          {/* Continue */}
          <GoodTooltip title='Use this message'>
            <IconButton
              size='sm'
              // variant='plain'
              color={GATHER_COLOR}
              disabled={isFusing}
              onClick={handleFusionUse}
              // endDecorator={<TelegramIcon />}
              sx={{
                // ...BEAM_BTN_SX,
                fontSize: 'xs',
                // '--Icon-fontSize': 'var(--joy-fontSize-xl)',
                // backgroundColor: 'background.popup',
                // border: '1px solid',
                // borderColor: `${GATHER_COLOR}.outlinedBorder`,
                // boxShadow: `0 4px 16px -4px rgb(var(--joy-palette-${GATHER_COLOR}-mainChannel) / 20%)`,
                animation: `${animationEnterBelow} 0.1s ease-out`,
                whiteSpace: 'nowrap',
              }}
            >
              {/*Use*/}
              <TelegramIcon />
            </IconButton>
          </GoodTooltip>

        </Box>
      )}

    </BeamCard>
  );
}


================================================
FILE: src/modules/beam/gather/FusionControls.tsx
================================================
import * as React from 'react';

import { Box, CircularProgress, IconButton, Sheet, SvgIconProps } from '@mui/joy';
import BuildCircleIcon from '@mui/icons-material/BuildCircle';
import PlayArrowRoundedIcon from '@mui/icons-material/PlayArrowRounded';
import RemoveCircleOutlineRoundedIcon from '@mui/icons-material/RemoveCircleOutlineRounded';
import ReplayRoundedIcon from '@mui/icons-material/ReplayRounded';
import StopRoundedIcon from '@mui/icons-material/StopRounded';

import { GoodTooltip } from '~/common/components/GoodTooltip';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';

import { rayControlsMobileSx, rayControlsSx } from '../scatter/BeamRay';

import type { BFusion } from './beam.gather';
import type { FusionFactorySpec } from './instructions/beam.gather.factories';


export const FusionControlsMemo = React.memo(FusionControls);

function FusionControls(props: {
  fusion: BFusion,
  factory: FusionFactorySpec,
  isFusing: boolean,
  isInterrupted: boolean,
  isMobile: boolean,
  isUsable: boolean,
  llmComponent?: React.ReactNode,
  llmLabel: string,
  llmVendorIcon?: React.FunctionComponent<SvgIconProps>,
  fusionAvatarTooltip: React.ReactNode,
  onIconClick?: (event: React.MouseEvent) => void,
  onRemove: () => void,
  onToggleGenerate: () => void,
}) {
  return (
    <Box sx={props.isMobile ? rayControlsMobileSx : rayControlsSx}>

      {/* LLM Icon with Tooltip - Clickable to toggle selector */}
      <TooltipOutlined asLargePane enableInteractive title={props.fusionAvatarTooltip || props.llmLabel} placement='top-start'>
        {/*<Box sx={{ display: 'flex' }} onClick={props.onIconClick}>*/}
        {/*  <props.llmVendorIcon sx={{ fontSize: 'lg', my: 'auto' }} />*/}
        {/*</Box>*/}
        <IconButton
          size='sm'
          variant={props.llmComponent ? 'plain' : 'plain'}
          onClick={props.onIconClick}
          sx={{
            m: '-7px',
            // minWidth: 'unset',
            // minHeight: 'unset',
            zIndex: 1, // only for the outline to go over the selector border
            transition: 'all 0.2s',
            '&:hover': {
              opacity: 1,
              transform: 'scale(1.1)',
              backgroundColor: 'transparent',
            },
          }}
        >
          {props.llmVendorIcon ? <props.llmVendorIcon sx={{ fontSize: 'lg' }} /> : <BuildCircleIcon sx={{ fontSize: 'lg' }} />}
        </IconButton>
      </TooltipOutlined>

      {/* Title Box OR LLM Selector */}
      {props.llmComponent ? (
        // Show LLM selector in place of title box
        <Box sx={{ flex: 1 }}>
          {props.llmComponent}
        </Box>
      ) : (
        // Show title box
        <Sheet
          variant='outlined'
          // color={GATHER_COLOR}
          sx={{
            // backgroundColor: `${GATHER_COLOR}.softBg`,
            flex: 1,
            borderRadius: 'sm',
            minHeight: '2rem',
            pl: 1,
            // layout
            display: 'flex',
            alignItems: 'center',
            gap: 1,
          }}
        >

          {/* [progress] Spinner | Factory Icon */}
          {props.fusion.fusingProgressComponent ? (
            <CircularProgress color='neutral' size='sm' sx={{ '--CircularProgress-size': '16px', '--CircularProgress-trackThickness': '2px' }} />
          ) : (
            !!props.factory.Icon && <props.factory.Icon sx={{ fontSize: 'lg' }} />
          )}

          {/* [progress] Component | Title */}
          {props.fusion.fusingProgressComponent
            // Show the progress in place of the title
            ? props.fusion.fusingProgressComponent
            : (
              <Box sx={{ fontSize: 'sm', fontWeight: 'md' }}>
                {props.factory.cardTitle} {props.isInterrupted && <em> - Interrupted</em>}
              </Box>
            )}
        </Sheet>
      )}

      {/* Generate / Stop Button */}
      {!props.isFusing ? (
        <GoodTooltip title={!props.isUsable ? 'Start Merge' : 'Retry'}>
          <IconButton size='sm' variant='plain' color='success' onClick={props.onToggleGenerate}>
            {!props.isUsable ? <PlayArrowRoundedIcon sx={{ fontSize: 'xl2' }} /> : <ReplayRoundedIcon />}
          </IconButton>
        </GoodTooltip>
      ) : (
        <GoodTooltip title='Stop'>
          <IconButton size='sm' variant='plain' color='danger' onClick={props.onToggleGenerate}>
            <StopRoundedIcon />
          </IconButton>
        </GoodTooltip>
      )}

      {/* Remove Button */}
      <GoodTooltip title='Remove'>
        <IconButton size='sm' variant='plain' color='neutral' onClick={props.onRemove}>
          <RemoveCircleOutlineRoundedIcon />
        </IconButton>
      </GoodTooltip>
    </Box>
  );
}


================================================
FILE: src/modules/beam/gather/FusionInstructionsEditor.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Divider, Typography } from '@mui/joy';

import { InlineTextarea } from '~/common/components/InlineTextarea';

import type { BeamStoreApi } from '../store-beam.hooks';
import type { GatherInstruction } from './instructions/GatherInstruction';
import type { FusionFactorySpec } from './instructions/beam.gather.factories';
import type { Instruction } from './instructions/beam.gather.execution';
import { useModuleBeamStore } from '../store-module-beam';


// Editor for a ChatInstruction
function EditableChatInstructionPrompt(props: {
  isEditable: boolean,
  itemKey: keyof GatherInstruction,
  itemValue: GatherInstruction['systemPrompt'],
  label: string,
  onEdit: (update: Partial<GatherInstruction>) => void,
}) {

  // state
  const [_isEditing, setIsEditing] = React.useState(false);


  // handlers

  const handleEditBegin = React.useCallback(() => setIsEditing(true), []);

  const handleEditCancel = React.useCallback(() => setIsEditing(false), []);

  const { onEdit } = props;
  const handleEdit = React.useCallback((text: string) => {
    setIsEditing(false);
    text && onEdit({ [props.itemKey]: text });
  }, [onEdit, props.itemKey]);


  return <>

    {/* Label */}
    <Typography level='body-xs' sx={{ minHeight: '1.5rem', display: 'flex', alignItems: 'end' }}>
      {props.label}
    </Typography>

    {/* Instruction > Key > Text | Edit */}
    {props.isEditable ? (
      <InlineTextarea
        decolor
        initialText={props.itemValue}
        minRows={3}
        selectAllOnFocus={false}
        onCancel={handleEditCancel}
        onEdit={handleEdit}
        sx={{
          // fontSize: 'sm',
          gridColumn: '2 / -1',
          // backgroundColor: 'background.level1',
          '&:focus-within': { backgroundColor: 'background.popup' },
        }}
      />
    ) : (
      <Box onDoubleClick={props.isEditable ? handleEditBegin : undefined} sx={{
        // fontSize: 'sm',
        whiteSpace: 'break-spaces',
      }}>
        {props.itemValue}
      </Box>
    )}

    {/* Duplicate Button */}
    {/*  <Tooltip disableInteractive title='Edit as Custom'>*/}
    {/*    <IconButton size='sm' onClick={handleEditBegin}>*/}
    {/*      <EditRoundedIcon />*/}
    {/*    </IconButton>*/}
    {/*  </Tooltip>*/}
  </>;
}


// Editor for any Instruction (specializes the implementation)
function EditableInstruction(props: {
  instruction: Instruction,
  instructionIndex: number,
  isEditable: boolean,
  onInstructionEdit: (instructionIndex: number, update: Partial<Instruction>) => void,
}) {

  // external state
  const gatherShowAllPrompts = useModuleBeamStore(state => state.gatherShowAllPrompts);

  // derived state
  const { instruction, instructionIndex, onInstructionEdit } = props;


  const handleEditInstructionItem = React.useCallback((update: Partial<Instruction>) => {
    onInstructionEdit(instructionIndex, update);
  }, [instructionIndex, onInstructionEdit]);


  return (instruction.type === 'gather') ? (
    <>
      {gatherShowAllPrompts && (
        <EditableChatInstructionPrompt
          isEditable={props.isEditable}
          itemKey='systemPrompt'
          itemValue={instruction.systemPrompt}
          label='System Instruction:'
          onEdit={handleEditInstructionItem}
        />
      )}
      <EditableChatInstructionPrompt
        isEditable={props.isEditable}
        itemKey='userPrompt'
        itemValue={instruction.userPrompt}
        label='User Instruction:'
        onEdit={handleEditInstructionItem}
      />
    </>
  ) : (
    <>
      <Typography level='body-xs' sx={{ minHeight: '2.5rem', display: 'flex', alignItems: 'center' }}>
        Type
      </Typography>
      <Typography level='body-sm' sx={{ gridColumn: '2 / -1' }}>
        {instruction.type}
      </Typography>
    </>
  );
}


const instructionsListSx: SxProps = {
  // not enabled from the former implementation
  // '--Card-padding': { xs: '0.5rem', md: '1rem' },
  //
  // mx: 'var(--Pad)',
  // mb: 'calc(-1 * var(--Pad))', // absorb gap to the next-top
  // px: 'var(--Card-padding)',
  // py: 'calc(var(--Card-padding) / 2)',
  //
  // border: '1px solid',
  // borderColor: 'neutral.outlinedBorder',
  // borderRadius: 'md',
  // borderBottom: 'none',
  // borderBottomLeftRadius: 0,
  // borderBottomRightRadius: 0,
  //
  // backgroundColor: 'background.surface',

  // every child apart from the last one has a bottom border
  // '& > *:not(:last-child)': {
  //   borderBottom: '1px solid',
  //   borderColor: 'neutral.outlinedBorder',
  // },

  // layout
  // gridTemplateColumns: 'auto 1fr auto',
  // columnGap: 'var(--Pad_2)',
  display: 'grid',
  alignItems: 'center',
  gap: 'var(--Pad_2)',
};


export function FusionInstructionsEditor(props: {
  beamStore: BeamStoreApi,
  factory: FusionFactorySpec,
  fusionId: string,
  instructions: Instruction[],
  isFusing: boolean,
  isIdle: boolean,
  onStart: () => void,
}) {

  // derived state
  const { beamStore, fusionId, instructions, isFusing } = props;


  // handlers
  // const handleFusionCopyAsCustom = React.useCallback(() => {
  //   beamStore.getState().fusionRecreateAsCustom(fusionId);
  // }, [fusionId, beamStore]);

  const handleInstructionEdit = React.useCallback((instructionIndex: number, update: Partial<Instruction>) => {
    beamStore.getState().fusionInstructionUpdate(fusionId, instructionIndex, update);
  }, [fusionId, beamStore]);


  const instructionsMemo = React.useMemo(() => {
    const elements: React.JSX.Element[] = [];
    instructions.forEach((instruction, instructionIndex) => {

      // Separator between instructions
      if (instructionIndex > 0)
        elements.push(<Divider key={'div-' + instructionIndex} sx={{ gridColumn: '1 / -1' }} />);

      elements.push(
        <EditableInstruction
          key={'inst-' + instructionIndex}
          isEditable
          instruction={instruction}
          instructionIndex={instructionIndex}
          onInstructionEdit={handleInstructionEdit}
          // onFusionCopyAsCustom={handleFusionCopyAsCustom}
        />,
      );
    });
    return elements;
  }, [handleInstructionEdit, instructions]);


  return <>

    {!props.isFusing && (
      <Box sx={instructionsListSx}>
        {instructionsMemo}
      </Box>
    )}

    {/* Bottom message */}
    {props.isIdle && (
      <Typography level='body-xs' endDecorator={undefined/* <PlayArrowRoundedIcon aria-label='Start Merge' onClick={props.onStart} /> */}>
        Just press the Start Merge button when done.
      </Typography>
    )}

  </>;
}


================================================
FILE: src/modules/beam/gather/instructions/beam.gather.execution.tsx
================================================
import * as React from 'react';
import { Typography } from '@mui/joy';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { createDMessageEmpty, DMessage } from '~/common/stores/chat/chat.message';
import { createPlaceholderVoidFragment } from '~/common/stores/chat/chat.fragments';

import type { BFusion, FusionUpdateOrFn } from '../beam.gather';
import { executeGatherInstruction, GatherInstruction } from './GatherInstruction';
import { GATHER_PLACEHOLDER } from '../../beam.config';
import { executeUserInputChecklistInstruction, UserInputChecklistInstruction } from './UserInputChecklistInstruction';


/// [Asynchronous Instruction Framework] ///

export interface BaseInstruction {
  type: string;
  label: string;
}

export interface ExecutionInputState {
  // inputs
  readonly chatMessages: DMessage[];
  readonly rayMessages: DMessage[];
  readonly llmId: DLLMId;
  readonly contextRef: string; // not useful
  // interaction
  readonly chainAbortController: AbortController;
  readonly updateProgressComponent: (component: React.ReactNode) => void;
  readonly updateInstructionComponent: (component: React.ReactNode) => void;
  // output1 -> input2
  readonly intermediateDMessage: DMessage;
}

export type Instruction = GatherInstruction | UserInputChecklistInstruction;


export function gatherStartFusion(
  initialFusion: Readonly<BFusion>,
  chatMessages: DMessage[],
  rayMessages: DMessage[],
  onUpdateBFusion: (update: FusionUpdateOrFn) => void,
) {

  // abort any current fusion
  const { instructions } = initialFusion;
  initialFusion.fusingAbortController?.abort('Merge Stopped');

  // validate preconditions
  const onError = (errorText: string) => onUpdateBFusion({
    stage: 'error',
    errorText: errorText,
    fusingAbortController: undefined,
  });
  if (instructions.length < 1)
    return onError('No fusion instructions available');
  if (chatMessages.length < 1)
    return onError('No conversation history available');
  if (rayMessages.length <= 1)
    return onError('No responses available');
  if (!initialFusion.llmId)
    return onError('No Merge model selected');


  // full execution state
  const inputState: ExecutionInputState = {
    // inputs
    chatMessages: chatMessages,
    rayMessages: rayMessages,
    llmId: initialFusion.llmId,
    contextRef: initialFusion.fusionId,
    // interaction
    chainAbortController: new AbortController(),
    updateProgressComponent: (component: React.ReactNode) => onUpdateBFusion({ fusingProgressComponent: component }),
    updateInstructionComponent: (component: React.ReactNode) => onUpdateBFusion({ fusingInstructionComponent: component }),
    // output1 -> input2
    intermediateDMessage: createDMessageEmpty('assistant'), // [state] assistant:Fusion_pending
  };


  // BFusion: startup full status reset
  onUpdateBFusion({
    // status
    stage: 'fusing',
    errorText: undefined,
    outputDMessage: undefined,

    // execution progress
    fusingAbortController: inputState.chainAbortController,
    fusingProgressComponent: undefined,
    fusingInstructionComponent: undefined,
  });


  // Execute the instructions in sequence
  type PipedValueType = string;
  const chainedInitialValue: PipedValueType = '';
  let promiseChain: Promise<PipedValueType> = Promise.resolve(chainedInitialValue);
  for (const instruction of instructions) {
    promiseChain = promiseChain.then((precedingValue: PipedValueType) => {
      // You can use chainedValue here, if needed
      inputState.updateProgressComponent(
        <Typography
          level='body-sm'
          sx={{ color: 'text.secondary' }}
        >
          {instructions.length > 1 && <>{1 + instructions.indexOf(instruction)}/{instructions.length} · </>}
          {instruction.label} ...
        </Typography>,
      );

      // reset the intermediate message
      inputState.intermediateDMessage.fragments = [createPlaceholderVoidFragment(GATHER_PLACEHOLDER)];
      inputState.intermediateDMessage.pendingIncomplete = true;
      inputState.intermediateDMessage.updated = null;

      // return the promise from the instruction
      switch (instruction.type) {
        case 'gather':
          return executeGatherInstruction(instruction, inputState, precedingValue);
        case 'user-input-checklist':
          return executeUserInputChecklistInstruction(instruction, inputState, precedingValue);
        default:
          return Promise.reject(new Error('Unsupported Merge instruction'));
      }
    });
  }

  // Chain completion handlers
  promiseChain
    .then(() => {
      onUpdateBFusion({
        stage: 'success',
        errorText: undefined,
        fusingProgressComponent: undefined,
      });
    })
    .catch((error) => {
      // User abort: no need to show an error
      if (inputState.chainAbortController.signal.aborted) {
        return onUpdateBFusion({
          stage: 'stopped',
          // errorText: 'Merge Canceled.',
          fusingProgressComponent: undefined,
        });
      }

      // Error handling
      onUpdateBFusion({
        stage: 'error',
        errorText: 'Issue: ' + (error?.message || error?.toString() || 'Unknown error'),
      });
    })
    .finally(() => onUpdateBFusion({
      // let the intermediate be the final output
      outputDMessage: inputState.intermediateDMessage,
      fusingAbortController: undefined,
      fusingInstructionComponent: undefined,
    }));
}


export function gatherStopFusion(fusion: BFusion): BFusion {
  fusion.fusingAbortController?.abort('Merge Stopped');
  return {
    ...fusion,
    ...(fusion.stage === 'fusing' ? { status: 'stopped' /* speculative as the abort shall do the same */ } : {}),
    fusingAbortController: undefined,
  };
}



================================================
FILE: src/modules/beam/gather/instructions/beam.gather.factories.ts
================================================
import type { SvgIcon } from '@mui/material';
import BuildRoundedIcon from '@mui/icons-material/BuildRounded';
import CheckBoxOutlinedIcon from '@mui/icons-material/CheckBoxOutlined';
import MediationOutlinedIcon from '@mui/icons-material/MediationOutlined';
import TableViewRoundedIcon from '@mui/icons-material/TableViewRounded';

import type { Instruction } from './beam.gather.execution';


export type FFactoryId = string;
export const CUSTOM_FACTORY_ID = 'custom' as const;

export interface FusionFactorySpec {
  factoryId: FFactoryId;
  shortLabel: string; // used in the button group selector
  addLabel: string;   // used in the add card
  cardTitle: string;   // used as the title
  Icon?: typeof SvgIcon;
  description: string;
  createInstructions: () => Instruction[];
}

export function findFusionFactory(factoryId?: FFactoryId | null): FusionFactorySpec | null {
  if (!factoryId) return null;
  return FUSION_FACTORIES.find(f => f.factoryId === factoryId) ?? null;
}

export const FUSION_FACTORY_DEFAULT = 'fuse';

export const FUSION_FACTORIES: FusionFactorySpec[] = [
  {
    factoryId: 'fuse',
    shortLabel: 'Fuse',
    addLabel: 'Add Fusion',
    cardTitle: 'Combined Response',
    Icon: MediationOutlinedIcon,
    description: 'AI combines conversation details and ideas into one clear, comprehensive answer.',
    createInstructions: () => [
      {
        type: 'gather',
        label: 'Synthesizing Fusion',
        method: 's-s0-h0-u0-aN-u',
        systemPrompt: `
You are an expert AI text synthesizer, your task is to analyze the following inputs and generate a single, comprehensive response that addresses the core objectives or questions.

Consider the conversation history, the last user message, and the diverse perspectives presented in the {{N}} response alternatives.

Your response should integrate the most relevant insights from these inputs into a cohesive and actionable answer.

Synthesize the perfect response that merges the key insights and provides clear guidance or answers based on the collective intelligence of the alternatives.`.trim(),
        userPrompt: `
Synthesize the perfect cohesive response to my last message that merges the collective intelligence of the {{N}} alternatives above.`.trim(),
        // evalPrompt: `Evaluate the synthesized response provided by the AI synthesizer. Consider its relevance to the original query, the coherence of the integration of different perspectives, and its completeness in addressing the objectives or questions raised throughout the conversation.`.trim(),
      },
    ],
  },
  {
    factoryId: 'guided',
    shortLabel: 'Guided',
    addLabel: 'Add Checklist',
    cardTitle: 'Guided Response',
    Icon: CheckBoxOutlinedIcon,
    description: 'Choose between options extracted by AI from the replies, and the model will combine your selections into a single answer.',
    // description: 'This approach employs a two-stage, interactive process where an AI first generates a checklist of insights from a conversation for user selection, then synthesizes those selections into a tailored, comprehensive response, integrating user preferences with AI analysis and creativity.',
    createInstructions: () => [
      {
        type: 'gather',
        label: 'Generating Checklist',
        display: 'chat-message',
        method: 's-s0-h0-u0-aN-u',
        systemPrompt: `
You are an intelligent agent tasked with analyzing a set of {{N}} AI-generated responses to the user message to identify key insights, solutions, or themes.
Your goal is to distill these into a clear, concise, and actionable checklist that the user can review and select from.
The checklist should be brief, commensurate with the task at hand, and formatted precisely as follows:

- [ ] **Insight/Solution/Theme name 1**: [Very brief, actionable description]
- [ ] **Insight/Solution/Theme name 2**: [Very brief, actionable description]
...
- [ ] **Insight/Solution/Theme name N**: [Very brief, actionable description]

The checklist should contain no more than 3-9 items orthogonal items, especially points of difference, in a single brief line each (no end period).
Prioritize items based on what would be most helpful to the user when merging the {{N}} response alternatives.`.trim(),
// Remember, the checklist should only include the most critical and relevant points, ensuring clarity and conciseness. Begin by identifying the essential insights or themes.
        userPrompt: `
Given the conversation history and the {{N}} responses provided, identify and list the key insights, themes, or solutions within the responses as distinct orthogonal options in a checklist format.
Each item should be clearly briefly articulated to allow for easy selection by the user.
Ensure the checklist is comprehensive, covering the breadth of ideas presented in the {{N}} responses, yet concise enough to facilitate clear decision-making.`.trim(),
      },
      {
        type: 'user-input-checklist',
        label: 'Criteria Selection',
        outputPrompt: `
The user selected:
{{YesAnswers}}

The user did NOT select:
{{NoAnswers}} 
`.trim(),
      },
      {
        type: 'gather',
        label: 'Checklist-guided Merge',
        method: 's-s0-h0-u0-aN-u',
        systemPrompt: `
You are a master synthesizer, equipped with specific directions selected by the user from a checklist you previously helped generate.
Your task is to combine the {{N}} response alternatives into a single cohesive response, following the preferences of the user. 
This synthesis should address the user's original query comprehensively, incorporating the {{N}} response alternatives following the user's chosen options.
Aim for clarity and coherence in your final output.`.trim(),
        userPrompt: `
Given the user preferences below, synthesize the {{N}} response alternatives above into a single, cohesive, comprehensive response that follows the user query and the preferences below:

{{PrevStepOutput}}

Ensure the synthesis is coherent, integrating the response alternatives in a clear manner.
The final output should reflect a deep understanding of the user's preferences and the conversation's context.`.trim(),
      },
    ],
  },
  {
    factoryId: 'eval',
    shortLabel: 'Compare',
    addLabel: 'Add Breakdown',
    cardTitle: 'Evaluation Table',
    Icon: TableViewRoundedIcon,
    description: 'Analyzes and compares AI responses, offering a structured framework to support your response choice.',
    createInstructions: () => [
      {
        type: 'gather',
        label: 'Evaluation',
        method: 's-s0-h0-u0-aN-u',
        systemPrompt: `
You are an advanced analytical tool designed to process and evaluate a set of AI-generated responses related to a user\'s query.

Your objective is to organize these responses in a way that aids decision-making.
You will first identify key criteria essential for evaluating the responses based on relevance, quality, and applicability.

Then, you will analyze each response against these criteria.

Finally, you will synthesize your findings into a table, providing a clear overview of how each response measures up. Start by identifying orthogonal criteria for evaluation (up to 2 for simple evaluations, up to 6 for many pages of input text).`.trim(),
        userPrompt: `
Now that you have reviewed the {{N}} alternatives, proceed with the following steps:

1. **Identify Criteria:** Define the most important orthogonal criteria for evaluating the responses. Identify up to 2 criteria for simple evaluations, or up to 6 for more complex evaluations. Ensure these criteria are distinct and relevant to the responses provided.

2. **Analyze Responses:** Evaluate each response individually against the criteria you identified. Assess how well each response meets each criterion, noting strengths and weaknesses. Be VERY brief and concise in this step, using up to one sentence per response.

3. **Generate Table:** Organize your analysis into a table. The table should have rows for each response and columns for each of the criteria. Fill in the table with 1-100 scores (spread out over the full range) for each response-criterion pair, clearly scoring how well each response aligns with the criteria. 

**Table Format:**

| Response | Criterion 1 | Criterion 2 | ... | Criterion C | Total |
|----------|-------------|-------------|-----|-------------|-------|
| R1 | ... | ... | ... | ... | ... |
| R2 | ... | ... | ... | ... | ... |
| ... | ... | ... | ... | ... | ... |
| RN | ... | ... | ... | ... | ... |

Complete this table to offer a structured and detailed comparison of the {{N}} options, providing an at-a-glance overview that will significantly aid in the decision-making process.

Finally declare the best response.

Only work with the provided {{N}} responses. Begin with listing the criteria.`.trim(),
      },
    ],
  },
  {
    factoryId: CUSTOM_FACTORY_ID,
    shortLabel: 'Custom',
    addLabel: 'Add Custom',
    cardTitle: 'User Defined',
    Icon: BuildRoundedIcon,
    description: 'Define your own fusion prompt.',
    createInstructions: () => [
      {
        type: 'gather',
        label: 'Executing Your Merge',
        method: 's-s0-h0-u0-aN-u',
        systemPrompt: `
Your task is to synthesize a cohesive and relevant response based on the following messages: the original system message, the full conversation history up to the user query, the user query, and a set of {{N}} answers generated independently.
These alternatives explore different solutions and perspectives and are presented in random order. Your output should integrate insights from these alternatives, aligned with the conversation's context and objectives, into a single, coherent response that addresses the user's needs and questions as expressed throughout the conversation.`.trim(),
        userPrompt: `
Based on the {{N}} alternatives provided, synthesize a single, comprehensive response.`.trim(),
        // userPrompt: 'Answer again using the best elements from the {{N}} answers above. Be truthful, honest, reliable.',
        // userPrompt: 'Based on the {{N}} alternatives provided, synthesize a single, comprehensive response that effectively addresses the query or problem at hand.',
      },
    ],
  },
];



================================================
FILE: src/modules/beam/gather/instructions/GatherInstruction.tsx
================================================
import * as React from 'react';

import { Typography } from '@mui/joy';

import { ChatMessage } from '../../../../apps/chat/components/message/ChatMessage';

import { AixChatGenerateContent_DMessage, aixChatGenerateContent_DMessage_FromConversation } from '~/modules/aix/client/aix.client';
import { bareBonesPromptMixer } from '~/modules/persona/pmix/pmix';

import { createDMessageTextContent, DMessage, messageFragmentsReduceText, messageWasInterruptedAtStart } from '~/common/stores/chat/chat.message';
import { getIsMobile } from '~/common/components/useMatchMedia';
import { getUXLabsHighPerformance } from '~/common/stores/store-ux-labs';

import type { BaseInstruction, ExecutionInputState } from './beam.gather.execution';
import { beamCardMessageScrollingSx, beamCardMessageSx } from '../../BeamCard';
import { getBeamCardScrolling } from '../../store-module-beam';


type ChatGenerateMethods =
  | 's-s0-h0-u0-aN-u'; // sandwiches the existing history and the new proposals in between the System and User prompts of the Instruction

export interface GatherInstruction extends BaseInstruction {
  type: 'gather';
  display?:
    | 'chat-message' /* default */
    | 'character-count'
    | 'mute';
  method: ChatGenerateMethods;
  systemPrompt: string;
  userPrompt: string;
  // evalPrompt?: string;
}


/**
 * Merge Execution: uses a chain of Promises to queue up (cancellable) seuqential instructions.
 */
export async function executeGatherInstruction(_i: GatherInstruction, inputs: ExecutionInputState, prevStepOutput: string): Promise<string> {

  // build the input messages
  if (_i.method !== 's-s0-h0-u0-aN-u')
    throw new Error(`Unsupported Chat Generate method: ${_i.method}`);

  // validate preconditions, to be sure
  if (!inputs.chatMessages.length)
    throw new Error('No conversation history available');
  if (!inputs.rayMessages.length)
    throw new Error('No responses available');
  for (let rayMessage of inputs.rayMessages)
    if (rayMessage.role !== 'assistant')
      throw new Error('Invalid response role');

  const gatherSystemInstruction = createDMessageTextContent('system', _mixChatGeneratePrompt(_i.systemPrompt, inputs.rayMessages.length, prevStepOutput));
  const chatMessagesWithoutSystem = inputs.chatMessages.filter(_m => (_m.role === 'user' || _m.role === 'assistant'));
  const gatherHistory: DMessage[] = [
    // s0-h0-u0
    ...chatMessagesWithoutSystem,
    // aN: every proposal is an assistant message
    // FIXME: there could be an issue with aix.dispatch fusion of assistant messages, and in the future, this should require a
    //        re-encoding or structuring of sorts, e.g.: .map(_m => ({ ..._m, metadata: { ..._m.metadata, asAttachment: true } }))
    ...inputs.rayMessages,
    // u
    createDMessageTextContent('user', _mixChatGeneratePrompt(_i.userPrompt, inputs.rayMessages.length, prevStepOutput)),
  ];

  // update the UI
  const onMessageUpdated = (update: AixChatGenerateContent_DMessage, completed: boolean) => {
    // in-place update of the intermediate message
    const { fragments: incrementalFragments, ...incrementalRest } = update;
    Object.assign(inputs.intermediateDMessage, incrementalRest);
    if (incrementalFragments?.length) {
      inputs.intermediateDMessage.fragments = incrementalFragments;
      inputs.intermediateDMessage.updated = Date.now();
    }
    if (completed)
      delete inputs.intermediateDMessage.pendingIncomplete;

    switch (_i.display) {
      case 'mute':
        return;

      case 'character-count':
        inputs.updateInstructionComponent(
          <Typography level='body-xs' sx={{ opacity: 0.5 }}>{messageFragmentsReduceText(incrementalFragments || []).length} characters</Typography>,
        );
        return;

      case 'chat-message':
      default:
        const isMobile = getIsMobile(); // no need to react to this
        // recreate the UI for this
        inputs.updateInstructionComponent(
          <ChatMessage /* Not Memo as this changes frequently */
            message={inputs.intermediateDMessage}
            fitScreen={isMobile}
            isMobile={isMobile}
            hideAvatar
            adjustContentScaling={-1}
            sx={!getBeamCardScrolling() ? beamCardMessageSx : beamCardMessageScrollingSx}
          />,
        );
        return;
    }
  };

  // stream the gathered message
  return aixChatGenerateContent_DMessage_FromConversation(
    inputs.llmId,
    gatherSystemInstruction,
    gatherHistory,
    'beam-gather', inputs.contextRef,
    { abortSignal: inputs.chainAbortController.signal, throttleParallelThreads: getUXLabsHighPerformance() ? 0 : 1 },
    onMessageUpdated,
  ).then((status) => {

    const clearFragments = messageWasInterruptedAtStart(status.lastDMessage);
    if (clearFragments)
      inputs.intermediateDMessage.fragments = [];

    // re-throw errors, as streamAssistantMessage catches internally
    if (status.outcome === 'aborted') {
      // this message will be discarded as the abort status is checked in the next `catch`
      throw new Error('Instruction Stopped.');
    }
    if (status.outcome === 'errored')
      throw new Error(`Model execution error: ${status.errorMessage || 'Unknown error'}`);

    // Proceed to the next step
    return messageFragmentsReduceText(inputs.intermediateDMessage.fragments); // returns the PipedValueType
  });
}


function _mixChatGeneratePrompt(prompt: string, raysReady: number, prevStepOutput: string): string {
  return bareBonesPromptMixer(prompt, undefined, {
    '{{N}}': raysReady.toString(),
    '{{PrevStepOutput}}': prevStepOutput,
  });
}


================================================
FILE: src/modules/beam/gather/instructions/UserInputChecklistComponent.tsx
================================================
import * as React from 'react';

import { Box, Button, Checkbox } from '@mui/joy';

import { GATHER_COLOR } from '../../beam.config';
import { UserChecklistOption } from './UserInputChecklistInstruction';


export function parseTextToChecklist(text: string, relaxMatch: boolean): UserChecklistOption[] {
  // Updated regex to match optional spaces (one or two) before '-', and both [ ] and [x] (case-insensitive for 'x')
  const regex = !relaxMatch ? /^ {0,2}[-*•] \[([ xX])] (.*)$/gm : /^ {0,2}[-*•]\s+(.*)$/gm;
  let matches;
  const options: UserChecklistOption[] = [];

  // Use while loop to iterate over all matches
  while ((matches = regex.exec(text)) !== null) {
    // matches[1] contains the space or 'x', indicating if the option is selected
    const selected = matches[1].toLowerCase() === 'x';
    const label = matches[2]; // The actual label of the option

    options.push({
      id: `option-${options.length}`,
      label: label,
      selected: selected,
    });
  }

  return options;
}


function parseMarkdownBold(text: string) {
  // Split the text by the markdown bold syntax
  const parts = text.split(/(\*\*.*?\*\*)/g);

  return parts.map((part, index) => {
    // Check if the part is meant to be bold
    if (part.startsWith('**') && part.endsWith('**')) {
      return <strong key={index}>{part.slice(2, -2)}</strong>;
    }
    return part;
  });
}


export function UserInputChecklistComponent(props: {
  options: UserChecklistOption[];
  onConfirm: (selectedOptions: UserChecklistOption[]) => void;
  onCancel: () => void;
}) {
  // Use local state to manage selections
  const [localOptions, setLocalOptions] = React.useState<UserChecklistOption[]>(props.options);

  const handleToggle = React.useCallback((optionId: string) => {
    setLocalOptions((currentOptions) =>
      currentOptions.map((option) =>
        option.id === optionId
          ? { ...option, selected: !option.selected }
          : option,
      ),
    );
  }, []);

  const moreThanHalfSelected = localOptions.filter(option => option.selected).length > localOptions.length / 2;

  return (
    <Box sx={{ display: 'grid', gap: 2, mt: 1 }}>
      {/*<Typography sx={{ mt: 1, fontWeight: 'md', fontSize: 'sm' }}>*/}
      {/*  Select how you want the merge:*/}
      {/*</Typography>*/}

      {localOptions.map((option) => (
        <Checkbox
          key={option.id}
          size='sm'
          color={GATHER_COLOR}
          // color='primary'
          checked={option.selected}
          onChange={() => handleToggle(option.id)}
          label={parseMarkdownBold(option.label)}
          slotProps={{
            root: { sx: { lineHeight: 'lg', ml: '1.625rem' } },
            checkbox: { sx: { mt: 0.25 } },
          }}
        />
      ))}

      <Box sx={{ display: 'flex', gap: 1, mt: 1 }}>
        <Button
          color={GATHER_COLOR}
          onClick={() => props.onConfirm(localOptions)}
        >
          Confirm Selection
        </Button>

        <Button
          color='neutral'
          variant='soft'
          onClick={() => setLocalOptions(localOptions.map(option => ({ ...option, selected: !moreThanHalfSelected })))}
        >
          {moreThanHalfSelected ? 'Uncheck All' : 'Check All'}
        </Button>

        <Button
          color='neutral'
          variant='soft'
          onClick={props.onCancel}
          sx={{ ml: 'auto' }}
        >
          Cancel
        </Button>
      </Box>
    </Box>
  );
}


================================================
FILE: src/modules/beam/gather/instructions/UserInputChecklistInstruction.tsx
================================================
import { bareBonesPromptMixer } from '~/modules/persona/pmix/pmix';

import type { BaseInstruction, ExecutionInputState } from './beam.gather.execution';
import { parseTextToChecklist, UserInputChecklistComponent } from './UserInputChecklistComponent';


export interface UserInputChecklistInstruction extends BaseInstruction {
  type: 'user-input-checklist';
  outputPrompt: string;
}

export interface UserChecklistOption {
  id: string,
  label: string,
  selected: boolean,
}


export async function executeUserInputChecklistInstruction(
  _i: UserInputChecklistInstruction,
  inputs: ExecutionInputState,
  prevStepOutput: string,
): Promise<string> {
  return new Promise((resolve, reject) => {

    // initial text to options
    let options = parseTextToChecklist(prevStepOutput, false);
    const relaxMatch = options.length < 2;
    if (relaxMatch)
      options = parseTextToChecklist(prevStepOutput, true);

    // if no options, there's an error
    if (options.length < 2) {
      reject(new Error('Oops! It looks like we had trouble understanding the Model. Could you please try again?'));
      return;
    }

    // react to aborts
    const abortHandler = () => {
      reject(new Error('Checklist Selection Stopped.'));
    };
    inputs.chainAbortController.signal.addEventListener('abort', abortHandler);

    const clearState = () => {
      inputs.updateInstructionComponent(undefined);
      inputs.chainAbortController.signal.removeEventListener('abort', abortHandler); // Cleanup
    };

    const onConfirm = (selectedOptions: UserChecklistOption[]) => {
      clearState();

      // output prompt mixer
      const outputPrompt = bareBonesPromptMixer(_i.outputPrompt, undefined, {
        '{{YesAnswers}}': selectedOptions.filter(o => o.selected).map(o => `- ${o.label.trim()}`).join('\n') || 'None',
        '{{NoAnswers}}': selectedOptions.filter(o => !o.selected).map(o => `- ${o.label.trim()}`).join('\n') || 'None',
      });

      // Proceed to the next step
      resolve(outputPrompt);
    };

    const onCancel = () => {
      clearState();
      inputs.chainAbortController.abort('User cancelled the input.');
      reject();
    };

    // Remove the placeholder message
    inputs.updateProgressComponent(null);

    // Update the instruction component to render the checklist
    inputs.updateInstructionComponent(
      <UserInputChecklistComponent
        options={options}
        onCancel={onCancel}
        onConfirm={onConfirm}
      />,
    );

  });
}


================================================
FILE: src/modules/beam/scatter/beam.scatter.ts
================================================
import type { StateCreator } from 'zustand/vanilla';

import { AixChatGenerateContent_DMessage, aixChatGenerateContent_DMessage_FromConversation } from '~/modules/aix/client/aix.client';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { agiUuid } from '~/common/util/idUtils';
import { createDMessageEmpty, DMessage, duplicateDMessage, messageWasInterruptedAtStart } from '~/common/stores/chat/chat.message';
import { createPlaceholderVoidFragment } from '~/common/stores/chat/chat.fragments';
import { findLLMOrThrow } from '~/common/stores/llms/store-llms';
import { getUXLabsHighPerformance } from '~/common/stores/store-ux-labs';
import { splitSystemMessageFromHistory } from '~/common/stores/chat/chat.conversation';

import type { RootStoreSlice } from '../store-beam_vanilla';
import { SCATTER_DEBUG_STATE, SCATTER_PLACEHOLDER } from '../beam.config';
import { updateBeamLastConfig } from '../store-module-beam';


export type BRayId = string;

export interface BRay {
  rayId: BRayId;
  status: 'empty' | 'scattering' | 'success' | 'stopped' | 'error';
  message: DMessage;
  rayLlmId: DLLMId | null;
  scatterIssue?: string;
  genAbortController?: AbortController;
  userSelected: boolean;
  imported: boolean;
}


export function createBRayEmpty(llmId: DLLMId | null): BRay {
  return {
    rayId: agiUuid('beam-ray'),
    status: 'empty',
    message: createDMessageEmpty('assistant'), // [state] assistant:Ray_empty
    rayLlmId: llmId,
    userSelected: false,
    imported: false,
  };
}

function rayScatterStart(ray: BRay, llmId: DLLMId | null, inputHistory: DMessage[], onlyIdle: boolean, playNice: boolean, scatterStore: ScatterStoreSlice): BRay {
  if (ray.genAbortController)
    return ray;
  if (onlyIdle && ray.status !== 'empty')
    return ray;
  if (!llmId)
    return { ...ray, scatterIssue: 'No model selected' };

  const { rays, _rayUpdate, _syncRaysStateToScatter } = scatterStore;

  // validate history
  if (!inputHistory || inputHistory.length < 1 || inputHistory[inputHistory.length - 1].role !== 'user')
    return { ...ray, scatterIssue: `Invalid conversation history (${inputHistory?.length})` };

  // split pre dynamic-personas
  const { chatSystemInstruction: scatterSystemInstruction, chatHistory: scatterInputHistory } = splitSystemMessageFromHistory(inputHistory);


  const abortController = new AbortController();

  const onMessageUpdated = (incrementalMessage: AixChatGenerateContent_DMessage, completed: boolean) => {
    const { fragments: incrementalFragments, ...incrementalRest } = incrementalMessage;
    _rayUpdate(ray.rayId, (ray) => ({
      message: {
        ...ray.message,
        ...(incrementalFragments?.length ? { fragments: [...incrementalFragments] } : {}),
        ...incrementalRest,
        ...(completed ? { pendingIncomplete: undefined } : {}), // clear the pending flag once the message is complete
        ...(incrementalFragments?.length ? { updated: Date.now() } : {}), // refresh the update timestamp once the content comes
      },
    }));
  };

  // stream the ray's messages directly to the state store
  aixChatGenerateContent_DMessage_FromConversation(
    llmId,
    scatterSystemInstruction,
    scatterInputHistory,
    'beam-scatter', ray.rayId,
    { abortSignal: abortController.signal, throttleParallelThreads: getUXLabsHighPerformance() ? 0 : !playNice ? 1 : rays.length },
    onMessageUpdated,
  )
    .then((status) => {
      const clearFragments = messageWasInterruptedAtStart(status.lastDMessage);
      _rayUpdate(ray.rayId, {
        ...(clearFragments && { message: createDMessageEmpty('assistant') }),
        status: (status.outcome === 'success') ? 'success'
          : (status.outcome === 'aborted') ? 'stopped'
            : (status.outcome === 'errored') ? 'error' : 'empty',
        scatterIssue: status.errorMessage || undefined,
        genAbortController: undefined,
      });
    })
    .finally(() => {
      _syncRaysStateToScatter();
    });

  const newMessage: DMessage = {
    ...ray.message,
    fragments: [createPlaceholderVoidFragment(SCATTER_PLACEHOLDER)],
    pendingIncomplete: true,
    created: Date.now(),
    updated: null,
  };

  return {
    rayId: ray.rayId,
    status: 'scattering',
    message: newMessage,
    rayLlmId: llmId,
    scatterIssue: undefined,
    genAbortController: abortController,
    userSelected: false,
    imported: false,
  };
}

function rayScatterStop(ray: BRay): BRay {
  ray.genAbortController?.abort('Beam Stopped');
  return {
    ...ray,
    ...(ray.status === 'scattering' ? { status: 'stopped' } : {}),
    genAbortController: undefined,
  };
}


export function rayIsError(ray: BRay | null): boolean {
  return ray?.status === 'error';
}

export function rayIsScattering(ray: BRay | null): boolean {
  return ray?.status === 'scattering';
}

export function rayIsSelectable(ray: BRay | null): boolean {
  // NOTE: this was here before, but prob not needed anymore after the MP refactor
  //        && !!ray.message.text && ray.message.text !== SCATTER_PLACEHOLDER
  // any ray is selectable once it's 'updated' (message started flowing in)
  // return !!ray?.message?.updated /*&& !ray.message.pendingIncomplete*/;
  return !!ray?.message.fragments.length;
}

export function rayIsUserSelected(ray: BRay | null): boolean {
  return !!ray?.userSelected;
}

export function rayIsImported(ray: BRay | null): boolean {
  return !!ray?.imported;
}


/// Scatter Store Slice ///

interface ScatterStateSlice {

  rays: BRay[];
  hadImportedRays: boolean;

  // derived state
  isScattering: boolean; // true if any ray is scattering at the moment
  raysReady: number;     // 0, or number of the rays that are ready

}

export const reInitScatterStateSlice = (prevRays: BRay[]): ScatterStateSlice => {
  // stop all ongoing rays
  prevRays.forEach(rayScatterStop);

  return {
    // recreate empty rays to match the previous count, with the same llms too
    rays: prevRays.map(prevRay => createBRayEmpty(prevRay.rayLlmId)),
    hadImportedRays: false,

    isScattering: false,
    raysReady: 0,
  };
};

export interface ScatterStoreSlice extends ScatterStateSlice {

  // ray actions
  setRayCount: (count: number) => void;
  removeRay: (rayId: BRayId) => void;
  importRays: (messages: DMessage[], raysLlmIdFallback: DLLMId | null) => void;
  setRayLlmIds: (rayLlmIds: DLLMId[]) => void;
  startScatteringAll: (restart: boolean) => void;
  stopScatteringAll: () => void;
  rayToggleScattering: (rayId: BRayId) => void;
  raySetLlmId: (rayId: BRayId, llmId: DLLMId | null) => void;
  _rayUpdate: (rayId: BRayId, update: Partial<BRay> | ((ray: BRay) => Partial<BRay>)) => void;

  _storeLastScatterConfig: () => void;
  _syncRaysStateToScatter: () => void;

}


export const createScatterSlice: StateCreator<RootStoreSlice & ScatterStoreSlice, [], [], ScatterStoreSlice> = (_set, _get) => ({

  // init state
  ...reInitScatterStateSlice([]),


  setRayCount: (count: number) => {
    const { rays, _storeLastScatterConfig, _syncRaysStateToScatter } = _get();
    if (count < rays.length) {
      // Terminate exceeding rays
      rays.slice(count).forEach(rayScatterStop);
      _set({
        rays: rays.slice(0, count),
      });
    } else if (count > rays.length) {
      _set({
        rays: [
          ...rays,
          // add missing empties, carrying forward the last llm
          ...Array(count - rays.length)
            .fill(null)
            .map(() => createBRayEmpty(rays[rays.length - 1]?.rayLlmId || null)),
        ],
      });
    }
    _storeLastScatterConfig();
    _syncRaysStateToScatter();
  },

  removeRay: (rayId: BRayId) => {
    const { _storeLastScatterConfig, _syncRaysStateToScatter } = _get();
    _set(state => ({
      rays: state.rays.filter((ray) => {
        const shallStay = ray.rayId !== rayId;
        // Terminate the removed ray
        !shallStay && rayScatterStop(ray);
        return shallStay;
      }),
    }));
    _storeLastScatterConfig();
    _syncRaysStateToScatter();
  },

  importRays: (messages: DMessage[], raysLlmIdFallback: DLLMId | null) => {
    const { rays, _storeLastScatterConfig, _syncRaysStateToScatter } = _get();

    // create new rays for the imported messages
    const importedRays = messages.map((message) => {

      // if present, use the model from the imported message
      let raysLlmId = raysLlmIdFallback;
      if (message.generator?.mgt === 'aix') {
        const aixLlmId = message.generator?.aix?.mId;
        if (aixLlmId) {
          try {
            findLLMOrThrow(aixLlmId);
            raysLlmId = aixLlmId;
          } catch (e) {
            // not found (can happen, could have been removed), keep the fallback
            // console.error('importRays: LLM not found', aixLlmId);
          }
        }
      }

      const emptyRay = createBRayEmpty(raysLlmId);

      // pre-fill the ray with the imported message
      if (message.fragments.length) {
        emptyRay.status = 'success';
        emptyRay.message = duplicateDMessage(message, false); // [beam] import dmessage copy from chat
        emptyRay.message.updated = Date.now();
        emptyRay.imported = true;
      }

      return emptyRay;
    });

    // remove the empty rays that have the same models as the imported messages
    const raysToRemove = rays
      .filter(_r => _r.status === 'empty' && importedRays.some((importedRay) => importedRay.rayLlmId === _r.rayLlmId))
      .slice(0, importedRays.length);

    _set({
      rays: [
        ...importedRays,
        ...rays.filter((ray) => !raysToRemove.includes(ray)),
      ],
      hadImportedRays: messages.length > 0,
    });
    _storeLastScatterConfig();
    _syncRaysStateToScatter();
  },

  setRayLlmIds: (rayLlmIds: DLLMId[]) => {
    const { setRayCount, _storeLastScatterConfig, _syncRaysStateToScatter } = _get();
    // NOTE: the behavior was to only enlarge the set, but turns out that the UX would be less intuitive
    // if (rayLlmIds.length > rays.length)
    setRayCount(rayLlmIds.length);
    _set(state => ({
      rays: state.rays.map((ray, index): BRay => index >= rayLlmIds.length ? ray : {
        ...ray,
        rayLlmId: rayLlmIds[index] || null,
      }),
    }));
    _storeLastScatterConfig();
    _syncRaysStateToScatter();
  },


  startScatteringAll: (restart: boolean) => {
    const { inputHistory } = _get();
    _set(state => ({
      // Start all rays
      rays: state.rays.map(ray =>
        (!restart || ray.status !== 'empty')
          ? rayScatterStart(ray, ray.rayLlmId, inputHistory || [], false, true, _get())
          : ray
      ),
    }));
    _get()._syncRaysStateToScatter();
  },

  stopScatteringAll: () =>
    _set(state => ({
      isScattering: false,
      // Terminate all rays
      rays: state.rays.map(rayScatterStop),
    })),

  rayToggleScattering: (rayId: BRayId) => {
    const { inputHistory, _rayUpdate, _syncRaysStateToScatter } = _get();
    _rayUpdate(rayId, (ray) =>
      ray.status === 'scattering'
        ? /* User Terminated the ray */ rayScatterStop(ray)
        : /* User Started the ray */ rayScatterStart(ray, ray.rayLlmId, inputHistory || [], false, false, _get()),
    );
    _syncRaysStateToScatter();
  },

  raySetLlmId: (rayId: BRayId, llmId: DLLMId | null) => {
    const { _rayUpdate, _storeLastScatterConfig } = _get();
    _rayUpdate(rayId, {
      rayLlmId: llmId,
    });
    _storeLastScatterConfig();
  },

  _rayUpdate: (rayId: BRayId, update: Partial<BRay> | ((ray: BRay) => Partial<BRay>)) =>
    _set(state => ({
      rays: state.rays.map(ray => (ray.rayId === rayId)
        ? { ...ray, ...(typeof update === 'function' ? update(ray) : update) }
        : ray,
      ),
    })),

  _storeLastScatterConfig: () => {
    updateBeamLastConfig({
      rayLlmIds: _get().rays.map(ray => ray.rayLlmId).filter(Boolean) as DLLMId[],
    });
  },

  _syncRaysStateToScatter: () => {
    const { rays } = _get();

    // Check if all rays have finished generating
    const hasRays = rays.length > 0;
    const allDone = !rays.some(rayIsScattering);
    const raysReady = rays.filter(rayIsSelectable).length;

    // [debug]
    if (SCATTER_DEBUG_STATE)
      console.log('_syncRaysStateToScatter', { rays: rays.length, allDone, raysReady, isScattering: hasRays && !allDone });

    _set({
      isScattering: hasRays && !allDone,
      raysReady,
    });
  },

});



================================================
FILE: src/modules/beam/scatter/BeamRay.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, IconButton, SvgIconProps, Typography } from '@mui/joy';
import CheckCircleOutlineRoundedIcon from '@mui/icons-material/CheckCircleOutlineRounded';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import DragIndicatorIcon from '@mui/icons-material/DragIndicator';
import PlayArrowRoundedIcon from '@mui/icons-material/PlayArrowRounded';
import RemoveCircleOutlineRoundedIcon from '@mui/icons-material/RemoveCircleOutlineRounded';
import ReplayRoundedIcon from '@mui/icons-material/ReplayRounded';
import StopRoundedIcon from '@mui/icons-material/StopRounded';
import TelegramIcon from '@mui/icons-material/Telegram';

import { ChatMessageMemo } from '../../../apps/chat/components/message/ChatMessage';

import { DLLMId, LLM_IF_OAI_Reasoning } from '~/common/stores/llms/llms.types';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { InlineError } from '~/common/components/InlineError';
import { animationEnterBelow } from '~/common/util/animUtils';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { messageFragmentsReduceText } from '~/common/stores/chat/chat.message';
import { useLLMSelect } from '~/common/components/forms/useLLMSelect';

import { BeamCard, beamCardClasses, beamCardMessageScrollingSx, beamCardMessageSx, beamCardMessageWrapperSx } from '../BeamCard';
import { BeamStoreApi, useBeamStore } from '../store-beam.hooks';
import { BEAM_SHOW_REASONING_ICON, GATHER_COLOR, SCATTER_COLOR, SCATTER_RAY_SHOW_DRAG_HANDLE } from '../beam.config';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { rayIsError, rayIsImported, rayIsScattering, rayIsSelectable, rayIsUserSelected } from './beam.scatter';
import { useBeamCardScrolling, useBeamScatterShowLettering } from '../store-module-beam';
import { useMessageAvatarLabel } from '~/common/util/dMessageUtils';


/*const letterSx: SxProps = {
  width: '1rem',
  py: 0.25,
  fontSize: 'xs',
  boxShadow: 'xs',
  border: '1px solid',
  borderColor: 'divider',
  borderRadius: '0.25rem',
  textAlign: 'center',
};*/

export const rayControlsSx: SxProps = {
  // layout
  display: 'flex', alignItems: 'center', gap: 1,
};

export const rayControlsMobileSx: SxProps = {
  ...rayControlsSx,

  // anchor top
  position: 'sticky', top: 0, bottom: 64,

  // looks (absorb parent padding, and overwrite with color and zIndex to stay on top)
  zIndex: 2, // because 'Chip' component have a zIndex of 1 in the inner label
  backgroundColor: 'inherit',
  mx: 'calc(-1 * var(--Card-padding))',
  px: 'var(--Card-padding)',
  my: -1,
  py: 1,
};

const RayControlsMemo = React.memo(RayControls);

function RayControls(props: {
  isEmpty: boolean,
  isMobile: boolean,
  isRemovable: boolean,
  isScattering: boolean,
  llmComponent: React.ReactNode,
  llmShowReasoning?: boolean,
  llmVendorIcon?: React.FunctionComponent<SvgIconProps>,
  onIconClick: (event: React.MouseEvent) => void,
  onRemove: () => void,
  onToggleGenerate: () => void,
  rayLetter?: string,
  rayAvatarTooltip: React.ReactNode,
  // isLlmLinked: boolean,
  // onLink: () => void,
}) {
  return <Box sx={props.isMobile ? rayControlsMobileSx : rayControlsSx}>

    {/* Drag Handle */}
    {SCATTER_RAY_SHOW_DRAG_HANDLE && (
      <div style={{ display: 'flex' }}>
        <DragIndicatorIcon sx={{ fontSize: 'xl', my: 'auto' }} />
      </div>
    )}

    {/* Letter / LLM Icon (default) */}
    <TooltipOutlined asLargePane enableInteractive title={props.rayAvatarTooltip} placement='top-start'>
      <Box sx={{ display: 'flex' }} onClick={props.onIconClick}>
        {props.rayLetter ? (
          <Typography level='title-sm' color={SCATTER_COLOR !== 'neutral' ? SCATTER_COLOR : undefined}>
            {props.rayLetter}
          </Typography>
        ) : props.llmVendorIcon ? <props.llmVendorIcon sx={{ fontSize: 'lg' }} />
          : null
          // : <TextureIcon sx={{ fontSize: 'lg' }} />
        }
      </Box>
    </TooltipOutlined>

    {/* Display a Reasoning LLM */}
    {(BEAM_SHOW_REASONING_ICON && props.llmShowReasoning) ? '🧠' : null}

    {/* LLM Select */}
    <Box sx={{ flex: 1 }}>
      {props.llmComponent}
    </Box>

    {/*{!props.isLlmLinked && (*/}
    {/*  <GoodTooltip title={props.isLlmLinked ? undefined : 'Link to the Merge model'}>*/}
    {/*    <IconButton disabled={props.isLlmLinked || props.isScattering} size='sm' onClick={props.onLink}>*/}
    {/*      {props.isLlmLinked ? <LinkIcon /> : <LinkOffIcon />}*/}
    {/*    </IconButton>*/}
    {/*  </GoodTooltip>*/}
    {/*)}*/}

    {!props.isScattering ? (
      <GoodTooltip title='Generate'>
        <IconButton size='sm' variant='plain' color='success' onClick={props.onToggleGenerate}>
          {props.isEmpty ? <PlayArrowRoundedIcon sx={{ fontSize: 'xl2' }} /> : <ReplayRoundedIcon />}
        </IconButton>
      </GoodTooltip>
    ) : (
      <GoodTooltip title='Stop'>
        <IconButton size='sm' variant='plain' color='danger' onClick={props.onToggleGenerate}>
          <StopRoundedIcon />
        </IconButton>
      </GoodTooltip>
    )}

    {props.isRemovable && (
      <GoodTooltip title='Remove'>
        <IconButton disabled={!props.isRemovable} size='sm' variant='plain' color='neutral' onClick={props.onRemove}>
          <RemoveCircleOutlineRoundedIcon />
        </IconButton>
      </GoodTooltip>
    )}
  </Box>;
}


export function BeamRay(props: {
  beamStore: BeamStoreApi,
  hadImportedRays: boolean,
  isMobile: boolean,
  isRemovable: boolean,
  rayId: string,
  rayIndexWeak: number,
  // linkedLlmId: DLLMId | null,
}) {

  // external state
  const ray = useBeamStore(props.beamStore, store => store.rays.find(ray => ray.rayId === props.rayId) ?? null);
  const cardScrolling = useBeamCardScrolling();
  const showLettering = useBeamScatterShowLettering();

  // derived state
  const isError = rayIsError(ray);
  const isScattering = rayIsScattering(ray);
  const isSelectable = rayIsSelectable(ray);
  const isSelected = rayIsUserSelected(ray);
  const isImported = rayIsImported(ray);
  const showUseButtons = isSelectable && !isScattering;
  const { removeRay, rayToggleScattering, raySetLlmId } = props.beamStore.getState();
  const { tooltip: rayAvatarTooltip } = useMessageAvatarLabel(ray?.message, 'pro');

  // This old code used the Gather LLM as Ray fallback - but now we use the last Scatter LLM as fallback
  // const isLlmLinked = !!props.linkedLlmId && !ray?.rayLlmId;
  // const llmId: DLLMId | null = isLlmLinked ? props.linkedLlmId : ray?.rayLlmId || null;
  // const handleLlmLink = React.useCallback(() => setLlmId(null), [setLlmId]);

  const llmId = ray?.rayLlmId ?? null;
  const setLlmId = React.useCallback((llmId: DLLMId | null) => raySetLlmId(props.rayId, llmId), [props.rayId, raySetLlmId]);
  const [llmOrNull, llmComponent, llmVendorIcon] = useLLMSelect(llmId, setLlmId, {
    label: '',
    disabled: isScattering,
  });

  // more derived
  const llmShowReasoning = !BEAM_SHOW_REASONING_ICON ? false : llmOrNull?.interfaces?.includes(LLM_IF_OAI_Reasoning) ?? false;


  // handlers

  const handleRayCopyToClipboard = React.useCallback(() => {
    const { rays } = props.beamStore.getState();
    const ray = rays.find(ray => ray.rayId === props.rayId);
    if (ray?.message.fragments.length)
      copyToClipboard(messageFragmentsReduceText(ray.message.fragments), 'Response');
  }, [props.beamStore, props.rayId]);

  const handleRayUse = React.useCallback(() => {
    // get snapshot values, so we don't have to react to the hook
    const { rays, onSuccessCallback } = props.beamStore.getState();
    const ray = rays.find(ray => ray.rayId === props.rayId);
    if (ray && ray.message.fragments.length && onSuccessCallback)
      onSuccessCallback(ray.message);
  }, [props.beamStore, props.rayId]);

  const handleDebugPrint = React.useCallback((event: React.MouseEvent) => {
    if (!event.shiftKey) return;
    const ray = props.beamStore.getState().rays.find(ray => ray.rayId === props.rayId);
    console.log({ ray });
  }, [props.beamStore, props.rayId]);

  const handleRayRemove = React.useCallback(() => {
    removeRay(props.rayId);
  }, [props.rayId, removeRay]);

  const handleRayToggleGenerate = React.useCallback(() => {
    rayToggleScattering(props.rayId);
  }, [props.rayId, rayToggleScattering]);

  /*const handleRayToggleSelect = React.useCallback(() => {
    toggleUserSelection(props.rayId);
  }, [props.rayId, toggleUserSelection]);*/


  return (
    <BeamCard
      role='beam-card'
      tabIndex={-1}
      // onClick={isSelectable ? handleRayToggleSelect : undefined}
      className={
        (isError ? beamCardClasses.errored : '')
        + (isSelectable ? beamCardClasses.selectable + ' ' : '')
      }
    >

      {/* Controls Row */}
      <RayControlsMemo
        isEmpty={!isSelectable}
        isMobile={props.isMobile}
        isRemovable={props.isRemovable}
        isScattering={isScattering}
        llmComponent={llmComponent}
        llmShowReasoning={llmShowReasoning}
        llmVendorIcon={llmVendorIcon}
        onIconClick={handleDebugPrint}
        onRemove={handleRayRemove}
        onToggleGenerate={handleRayToggleGenerate}
        rayLetter={showLettering ? 'R' + (1 + props.rayIndexWeak) : undefined}
        rayAvatarTooltip={rayAvatarTooltip}
        // isLlmLinked={isLlmLinked}
        // onLink={handleLlmLink}
      />

      {/* Show issue, if any */}
      {!!ray?.scatterIssue && <InlineError error={ray.scatterIssue} />}

      {/* Ray Message */}
      {(!!ray?.message?.fragments.length || ray?.status === 'scattering') && (
        <Box sx={beamCardMessageWrapperSx}>
          {!!ray.message && (
            <ChatMessageMemo
              message={ray.message}
              fitScreen={true}
              isMobile={props.isMobile}
              hideAvatar
              showUnsafeHtmlCode={true}
              adjustContentScaling={-1}
              sx={!cardScrolling ? beamCardMessageSx : beamCardMessageScrollingSx}
            />
          )}
        </Box>
      )}

      {/* Use Ray */}
      {showUseButtons && (
        <Box sx={{ mt: 'auto', mb: -1, mr: -1, placeSelf: 'end', height: 'calc(2.25rem - var(--Pad_2))', position: 'relative' }}>
          <Box sx={{
            position: 'absolute',
            bottom: 0,
            right: 0,
            display: 'flex',
            gap: 1,
          }}>

            {/* Copy */}
            {!isImported && (
              <GoodTooltip title='Copy'>
                <IconButton
                  size='sm'
                  onClick={handleRayCopyToClipboard}
                >
                  <ContentCopyIcon sx={{ fontSize: 'md' }} />
                </IconButton>
              </GoodTooltip>
            )}

            {/* Continue */}
            <GoodTooltip title='Choose this message'>
              <IconButton
                size='sm'
                // variant='plain'
                color={GATHER_COLOR}
                disabled={isImported || isScattering}
                onClick={handleRayUse}
                // endDecorator={!isImported ? <TelegramIcon /> : null}
                sx={{
                  fontSize: 'xs',
                  // '--Icon-fontSize': 'var(--joy-fontSize-xl)',
                  px: isImported ? 1 : undefined,
                  animation: `${animationEnterBelow} 0.1s ease-out`,
                  whiteSpace: 'nowrap',
                }}
              >
                {isImported ? 'From Chat (copied)' : /*props.hadImportedRays ? 'Replace' : 'Use'*/ <TelegramIcon />}
              </IconButton>
            </GoodTooltip>

          </Box>
        </Box>
      )}

      {/* Readiness | Selection indicator */}
      {isSelected && (
        <Box sx={{
          display: 'flex',
          position: 'absolute',
          bottom: '0.5rem',
          right: '0.5rem',
        }}>
          <CheckCircleOutlineRoundedIcon sx={{ fontSize: 'md', color: 'success.solidBg' }} />
        </Box>
      )}
    </BeamCard>
  );
}


================================================
FILE: src/modules/beam/scatter/BeamRayGrid.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button } from '@mui/joy';
import AddCircleOutlineRoundedIcon from '@mui/icons-material/AddCircleOutlineRounded';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import TelegramIcon from '@mui/icons-material/Telegram';

import type { BeamStoreApi } from '../store-beam.hooks';
import { BeamCard } from '../BeamCard';
import { SCATTER_RAY_MAX, SCATTER_RAY_MIN } from '../beam.config';

import { BeamRay } from './BeamRay';


const rayGridDesktopSx: SxProps = {
  mx: 'var(--Pad)',
  mb: 'auto',
  display: 'grid',
  gridTemplateColumns: 'repeat(auto-fit, minmax(max(min(100%, 390px), 100%/5), 1fr))',
  gap: 'var(--Pad)',
} as const;

const rayGridMobileSx: SxProps = {
  ...rayGridDesktopSx,
  gridTemplateColumns: 'repeat(auto-fit, minmax(320px, 1fr))',
} as const;


export function BeamRayGrid(props: {
  beamStore: BeamStoreApi,
  hadImportedRays: boolean,
  isMobile: boolean,
  onIncreaseRayCount: () => void,
  onRaysOperation: (operation: 'copy' | 'use') => void,
  rayIds: string[],
  showRayAdd: boolean,
  showRaysOps: undefined | number,
}) {

  const raysCount = props.rayIds.length;

  return (
    <Box sx={props.isMobile ? rayGridMobileSx : rayGridDesktopSx}>

      {/* Rays */}
      {props.rayIds.map((rayId, index) => (
        <BeamRay
          key={'ray-' + rayId}
          rayIndexWeak={index}
          beamStore={props.beamStore}
          hadImportedRays={props.hadImportedRays}
          isMobile={props.isMobile}
          isRemovable={raysCount > SCATTER_RAY_MIN}
          rayId={rayId}
          // linkedLlmId={props.linkedLlmId}
        />
      ))}

      {/* Add Ray */}
      {(props.showRayAdd && raysCount < SCATTER_RAY_MAX) && (
        <BeamCard sx={{ mb: 'auto' }}>
          <Button variant='plain' color='neutral' onClick={props.onIncreaseRayCount} sx={{
            minHeight: 'calc(2 * var(--Card-padding) + 2rem - 0.5rem)',
            marginBlock: 'calc(-1 * var(--Card-padding) + 0.25rem)',
            marginInline: 'calc(-1 * var(--Card-padding) + 0.375rem)',
            // justifyContent: 'end',
          }}>
            <AddCircleOutlineRoundedIcon />
          </Button>
        </BeamCard>
      )}

      {/* Multi-Use and Copy Buttons */}
      {!!props.showRaysOps && (
        <Box sx={{ gridColumn: '1 / -1', display: 'flex', justifyContent: 'center', gap: 2, mt: 2 }}>
          <Button size='sm' variant='outlined' color='neutral' onClick={() => props.onRaysOperation('copy')} endDecorator={<ContentCopyIcon sx={{ fontSize: 'md' }} />} sx={{
            backgroundColor: 'background.surface',
            '&:hover': { backgroundColor: 'background.popup' },
          }}>
            Copy {props.showRaysOps}
          </Button>
          <Button size='sm' variant='outlined' color='success' onClick={() => props.onRaysOperation('use')} endDecorator={<TelegramIcon sx={{ fontSize: 'xl' }} />} sx={{
            justifyContent: 'space-between',
            backgroundColor: 'background.surface',
            '&:hover': { backgroundColor: 'background.popup' },
          }}>
            Use {props.showRaysOps == 2 ? 'both' : 'all ' + props.showRaysOps} messages
          </Button>
        </Box>
      )}

      {/*/!* Takes a full row *!/*/}
      {/*<Divider sx={{*/}
      {/*  gridColumn: '1 / -1',*/}
      {/*  // marginBlock: 'var(--Pad)',*/}
      {/*}}>*/}
      {/*  Merges*/}
      {/*</Divider>*/}

      {/* Fusions */}
      {/*{props.fusionIds.map((fusionId) => (*/}
      {/*  <BeamFusion*/}
      {/*    key={'fusion-' + fusionId}*/}
      {/*    beamStore={props.beamStore}*/}
      {/*    fusionId={fusionId}*/}
      {/*  />*/}
      {/*))}*/}

      {/* Add Fusion */}
      {/*<BeamFusionAdd*/}
      {/*  beamStore={props.beamStore}*/}
      {/*  isMobile={props.isMobile}*/}
      {/*/>*/}

    </Box>
  );
}


================================================
FILE: src/modules/beam/scatter/BeamScatterInput.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Typography, useTheme } from '@mui/joy';

import { ChatMessageMemo } from '../../../apps/chat/components/message/ChatMessage';

import type { DMessage, DMessageId } from '~/common/stores/chat/chat.message';
import type { DMessageFragment, DMessageFragmentId } from '~/common/stores/chat/chat.fragments';
import { hasSystemMessageInHistory } from '~/common/stores/chat/chat.conversation';

import { BEAM_INVERT_BACKGROUND } from '../beam.config';
import { useModuleBeamStore } from '../store-module-beam';


const userMessageWrapperSx: SxProps = {
  mb: 'calc(-1 * var(--Pad))', // absorb parent 'gap' to next
  px: 'var(--Pad)',
  pt: 'var(--Pad)',

  // sticky user message, only displaced by the scatter controls
  // NOTE: disabled: should feel good but feels weird
  // position: 'sticky',
  // top: 0,
};

const userMessageWrapperINVSx: SxProps = {
  ...userMessageWrapperSx,
  backgroundColor: 'neutral.solidBg',
  pt: 0,
};

const userMessageWrapperDarkINVSx: SxProps = {
  ...userMessageWrapperSx,
  backgroundColor: 'neutral.800',
  pt: 0,
};

const userChatMessageSx: SxProps = {
  border: 'none',
  // border: '1px solid',
  // borderBottom: 'none',
  // borderColor: 'primary.outlinedBorder',
  borderRadius: 'md',
  borderBottomLeftRadius: 0,
  borderBottomRightRadius: 0,
  // px: '0.5rem',
  pr: '0.125rem',
  // boxShadow: 'sm',
  // the following make it end-aligned
  // borderBottomRightRadius: 0,
  // borderRight: 'none',
  // px: 'var(--Pad)',
} as const;


export function BeamScatterInput(props: {
  isMobile: boolean,
  history: DMessage[] | null,
  onMessageFragmentReplace: (messageId: DMessageId, fragmentId: DMessageFragmentId, newFragment: DMessageFragment) => void,
}) {

  // state
  // const [showHistoryMessage, setShowHistoryMessage] = React.useState(true);

  // external state
  const isDarkMode = useTheme().palette.mode === 'dark';
  const scatterShowPrevMessages = useModuleBeamStore(state => state.scatterShowPrevMessages);

  // derived state

  const lastHistoryMessage = props.history?.slice(-1)[0] || null;

  const isFirstMessageSystem = hasSystemMessageInHistory(props.history || []);

  const otherHistoryCount = Math.max(0, (props.history?.length || 0) - 1);


  // user message decorator

  const userMessageDecorator = React.useMemo(() => {
    return (/*showHistoryMessage &&*/ otherHistoryCount >= 1 && scatterShowPrevMessages) ? (
      // <Chip color='primary' variant='outlined' endDecorator={<ChipDelete />} sx={{ my: 1 }}>
      <Typography level='body-xs' sx={{ my: 1, textAlign: 'center', color: 'neutral.softColor' }} onClick={undefined /*() => setShowHistoryMessage(on => !on)*/}>
        ... {otherHistoryCount === 1 ? (isFirstMessageSystem ? '1 system message' : '1 message') : `${otherHistoryCount} messages`} before this one ...
      </Typography>
      // </Chip>
    ) : null;
  }, [scatterShowPrevMessages, isFirstMessageSystem, otherHistoryCount/*, showHistoryMessage*/]);


  // skip rendering if no message
  if (!lastHistoryMessage)
    return null;

  return (
    <Box sx={!BEAM_INVERT_BACKGROUND ? userMessageWrapperSx : isDarkMode ? userMessageWrapperDarkINVSx : userMessageWrapperINVSx}>
      <ChatMessageMemo
        message={lastHistoryMessage}
        fitScreen={props.isMobile}
        isMobile={props.isMobile}
        adjustContentScaling={-1}
        topDecorator={userMessageDecorator}
        onMessageFragmentReplace={props.onMessageFragmentReplace}
        sx={userChatMessageSx}
      />
    </Box>
  );
}


================================================
FILE: src/modules/beam/scatter/BeamScatterPane.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, ButtonGroup, FormControl, Typography } from '@mui/joy';
import AutoAwesomeIcon from '@mui/icons-material/AutoAwesome';
import AutoAwesomeOutlinedIcon from '@mui/icons-material/AutoAwesomeOutlined';
import PlayArrowRoundedIcon from '@mui/icons-material/PlayArrowRounded';
import PlusOneRoundedIcon from '@mui/icons-material/PlusOneRounded';
import StopRoundedIcon from '@mui/icons-material/StopRounded';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';

import type { BeamStoreApi } from '../store-beam.hooks';
import { BEAM_BTN_SX, SCATTER_COLOR, SCATTER_RAY_PRESETS } from '../beam.config';
import { BeamScatterDropdown } from './BeamScatterPaneDropdown';
import { beamPaneSx } from '../BeamCard';


const scatterPaneSx: SxProps = {
  ...beamPaneSx,
  backgroundColor: 'background.popup',

  // col gap is pad/2 (8px), row is double (1rem)
  rowGap: 'var(--Pad)',

  // [desktop] scatter: primary-chan shadow
  // boxShadow: '0px 6px 12px -8px rgb(var(--joy-palette-primary-darkChannel) / 35%)',
  // boxShadow: '0px 16px 16px -24px rgb(var(--joy-palette-primary-darkChannel) / 35%)',
  boxShadow: '0px 6px 16px -12px rgb(var(--joy-palette-primary-darkChannel) / 50%)',
  // boxShadow: '0px 8px 20px -16px rgb(var(--joy-palette-primary-darkChannel) / 30%)',
};

const mobileScatterPaneSx: SxProps = scatterPaneSx;

const desktopScatterPaneSx: SxProps = {
  ...scatterPaneSx,

  // the fact that this works, means we got the CSS and layout right
  position: 'sticky',
  top: 0,
};

const _styles = {

  icon: {
    fontSize: '1rem',
    mr: 0.625,
  } as const,

  iconActive: {
    fontSize: '1rem',
    mr: 0.625,
    // NOTE: no reason to animate the color here, it's just a waste of power...
    // animation: `${animationColorBeamScatter} 2s linear infinite`,
    // ...and so we just fallback to the first color of the animation
    color: 'rgb(85, 140, 47)',
  } as const,

} as const;


export function BeamScatterPane(props: {
  beamStore: BeamStoreApi,
  isMobile: boolean,
  rayCount: number,
  setRayCount: (n: number) => void,
  showRayAdd: boolean
  startEnabled: boolean,
  startBusy: boolean,
  startRestart: boolean,
  onStart: (restart: boolean) => void,
  onStop: () => void,
  onExplainerShow: () => any,
}) {

  const dropdownMemo = React.useMemo(() => (
    <BeamScatterDropdown
      beamStore={props.beamStore}
      onExplainerShow={props.onExplainerShow}
    />
  ), [props.beamStore, props.onExplainerShow]);

  const { onStart, startRestart } = props;

  const handleStartClicked = React.useCallback((event: React.MouseEvent) => {
    onStart(!startRestart ? false : event.shiftKey);
  }, [onStart, startRestart]);

  return (
    <Box sx={props.isMobile ? mobileScatterPaneSx : desktopScatterPaneSx}>

      {/* Title */}
      <Box>
        <Typography
          level='h4' component='h3'
          endDecorator={dropdownMemo}
          // sx={{ my: 0.25 }}
        >
          {props.startBusy
            ? <AutoAwesomeIcon sx={_styles.iconActive} />
            : <AutoAwesomeOutlinedIcon sx={_styles.icon} />}
          Beam
        </Typography>
        <Typography level='body-sm' sx={{ whiteSpace: 'nowrap' }}>
          Explore different replies
          {/* Explore the solution space */}
        </Typography>
      </Box>

      {/* Ray presets */}
      <FormControl sx={{ my: '-0.25rem' }}>
        <FormLabelStart title='Beam Count' sx={/*{ mb: '0.25rem' }*/ undefined} />
        <ButtonGroup variant='outlined'>
          {SCATTER_RAY_PRESETS.map((n) => {
            const isActive = n === props.rayCount;
            return (
              <Button
                key={n}
                // variant={isActive ? 'solid' : undefined}
                color={isActive ? SCATTER_COLOR : 'neutral'}
                // color='neutral'
                size='sm'
                onClick={() => props.setRayCount(n)}
                sx={{
                  // backgroundColor: isActive ? 'background.popup' : undefined,
                  backgroundColor: !isActive ? `${SCATTER_COLOR}.softBg` : 'background.popup',
                  fontWeight: isActive ? 'xl' : 400, /* reset, from 600 */
                  width: '3rem',
                }}
              >
                {n}
              </Button>
            );
          })}
          {props.showRayAdd && (
            <Button
              color='neutral'
              size='sm'
              onClick={() => props.setRayCount(props.rayCount + 1)}
              sx={{
                backgroundColor: 'background.popup',
                fontWeight: 'xl',
                width: '3rem',
              }}
            >
              {/*{'+'}*/}
              <PlusOneRoundedIcon />
            </Button>
          )}
        </ButtonGroup>
      </FormControl>

      {/* Start / Stop buttons */}
      {!props.startBusy ? (
        <TooltipOutlined slowEnter title={startRestart ? 'Shift + Click to re-run active Beams' : null} placement='top-end'>
          <Button
            // key='scatter-start' // used for animation triggering, which we don't have now
            variant='solid' color={SCATTER_COLOR}
            disabled={!props.startEnabled || props.startBusy} loading={props.startBusy}
            endDecorator={<PlayArrowRoundedIcon />}
            onClick={handleStartClicked}
            sx={BEAM_BTN_SX}
          >
            Start
          </Button>
        </TooltipOutlined>
      ) : (
        <Button
          // key='scatter-stop'
          variant='solid' color='danger'
          endDecorator={<StopRoundedIcon />}
          onClick={props.onStop}
          sx={BEAM_BTN_SX}
        >
          Stop
          {/*{props.rayCount > props.raysReady && ` (${props.rayCount - props.raysReady})`}*/}
        </Button>
      )}

    </Box>
  );
}


================================================
FILE: src/modules/beam/scatter/BeamScatterPaneDropdown.tsx
================================================
import * as React from 'react';

import { Box, Button, DialogContent, DialogTitle, Dropdown, FormControl, FormLabel, IconButton, Input, ListDivider, ListItem, ListItemDecorator, Menu, MenuButton, MenuItem, Modal, ModalClose, ModalDialog, Typography } from '@mui/joy';
import CheckRoundedIcon from '@mui/icons-material/CheckRounded';
import DeleteOutlineRoundedIcon from '@mui/icons-material/DeleteOutlineRounded';
import DriveFileRenameOutlineRoundedIcon from '@mui/icons-material/DriveFileRenameOutlineRounded';
import MoreVertIcon from '@mui/icons-material/MoreVert';
import SchoolRoundedIcon from '@mui/icons-material/SchoolRounded';

import { DEV_MODE_SETTINGS } from '../../../apps/settings-modal/UxLabsSettings';

import type { DLLMId } from '~/common/stores/llms/llms.types';

import type { BeamStoreApi } from '../store-beam.hooks';
import { useModuleBeamStore } from '../store-module-beam';


/// Naming Dialog ///

function DialogNamePreset(props: {
  open: boolean,
  onClose: () => void,
  onStore: (name: string) => void,
}) {

  // state
  const [name, setName] = React.useState('');

  const handleClose = () => {
    setName('');
    props.onClose();
  };

  return (
    <Modal open={props.open} onClose={handleClose}>
      <ModalDialog>
        <ModalClose />
        <DialogTitle>Save Preset</DialogTitle>
        <DialogContent>Store the Models configuration.</DialogContent>
        <form onSubmit={(event: React.FormEvent<HTMLFormElement>) => {
          event.preventDefault();
          if (name.trim())
            props.onStore(name);
          handleClose();
        }}>
          <Box sx={{ display: 'grid', gap: 2 }}>
            <FormControl>
              <FormLabel>Name</FormLabel>
              <Input autoFocus required value={name} onChange={event => setName(event.target.value)} />
            </FormControl>
            <Button type='submit'>Save</Button>
          </Box>
        </form>
      </ModalDialog>
    </Modal>
  );
}


export function BeamScatterDropdown(props: {
  beamStore: BeamStoreApi,
  onExplainerShow: () => any,
}) {

  // state
  const [namingOpened, setNamingOpened] = React.useState(false);

  // external state
  const {
    presets, addPreset, deletePreset,
    cardAdd, toggleCardAdd,
    cardScrolling, toggleCardScrolling,
    scatterShowPrevMessages, toggleScatterShowPrevMessages,
    scatterShowLettering, toggleScatterShowLettering,
    gatherAutoStartAfterScatter, toggleGatherAutoStartAfterScatter,
    gatherShowAllPrompts, toggleGatherShowAllPrompts,
  } = useModuleBeamStore();


  // handlers - load/save presets

  const handleClosePresetNaming = React.useCallback(() => setNamingOpened(false), []);

  const handlePresetSave = React.useCallback((presetName: string) => {
    const { rays, currentGatherLlmId, currentFactoryId } = props.beamStore.getState();
    const rayLlmIds = rays.map(ray => ray.rayLlmId).filter(Boolean) as DLLMId[];
    addPreset(presetName, rayLlmIds, currentGatherLlmId, currentFactoryId);
    handleClosePresetNaming();
  }, [addPreset, handleClosePresetNaming, props.beamStore]);

  const handlePresetLoad = React.useCallback((presetId: string) => {
    const preset = useModuleBeamStore.getState().presets.find(preset => preset.id === presetId);
    preset && props.beamStore.getState().loadBeamConfig(preset);
  }, [props.beamStore]);

  // NOTE: DEVS only - DEBUG only
  const handleClearLastConfig = React.useCallback(() => {
    // this is used to debug the heuristics for model selection
    useModuleBeamStore.getState().deleteLastConfig();
  }, []);


  return <>

    {/* Scatter Dropdown */}
    <Dropdown>
      <MenuButton
        aria-label='Beam Options'
        slots={{ root: IconButton }}
        slotProps={{ root: { size: 'sm', sx: { my: -0.25 } } }}
      >
        <MoreVertIcon />
      </MenuButton>

      <Menu placement='right-end' sx={{ minWidth: 200, zIndex: 'var(--joy-zIndex-modal)' /* on top of its own modal in FS */ }}>
        <ListItem>
          <Typography level='body-sm'>Model Presets</Typography>
        </ListItem>

        {/* Save New */}
        <MenuItem onClick={() => setNamingOpened(true)}>
          <ListItemDecorator>
            <DriveFileRenameOutlineRoundedIcon />
          </ListItemDecorator>
          Save new ...
        </MenuItem>

        {/* Load any preset */}
        {presets.map(preset =>
          <MenuItem key={preset.id} onClick={() => handlePresetLoad(preset.id)}>
            <ListItemDecorator />
            <Typography>
              Load &quot;{preset.name}&quot; &nbsp;<span style={{ opacity: 0.5, marginRight: '2rem' }}>x{preset.rayLlmIds?.length}</span>
            </Typography>
            <IconButton
              size='sm'
              variant='outlined'
              onClick={(event) => {
                event.stopPropagation();
                deletePreset(preset.id);
              }}
              sx={{ ml: 'auto' }}
            >
              <DeleteOutlineRoundedIcon />
            </IconButton>
          </MenuItem>,
        )}

        {/*<ListDivider inset='startContent' />*/}

        <ListItem>
          <Typography level='body-sm'>View</Typography>
        </ListItem>

        <MenuItem onClick={toggleScatterShowPrevMessages}>
          <ListItemDecorator>{scatterShowPrevMessages && <CheckRoundedIcon />}</ListItemDecorator>
          History
        </MenuItem>

        <MenuItem onClick={toggleCardAdd}>
          <ListItemDecorator>{cardAdd && <CheckRoundedIcon />}</ListItemDecorator>
          Add Button
        </MenuItem>

        <MenuItem onClick={toggleCardScrolling}>
          <ListItemDecorator>{cardScrolling && <CheckRoundedIcon />}</ListItemDecorator>
          Resize Beams
        </MenuItem>

        <MenuItem onClick={toggleScatterShowLettering}>
          <ListItemDecorator>{scatterShowLettering && <CheckRoundedIcon />}</ListItemDecorator>
          Response Numbers
        </MenuItem>

        <ListItem onClick={DEV_MODE_SETTINGS ? () => handleClearLastConfig() : undefined}>
          <Typography level='body-sm'>Advanced</Typography>
        </ListItem>

        <MenuItem onClick={toggleGatherAutoStartAfterScatter}>
          <ListItemDecorator>{gatherAutoStartAfterScatter && <CheckRoundedIcon />}</ListItemDecorator>
          Auto-Merge
        </MenuItem>

        <MenuItem onClick={toggleGatherShowAllPrompts}>
          <ListItemDecorator>{gatherShowAllPrompts && <CheckRoundedIcon />}</ListItemDecorator>
          Detailed Custom Merge
        </MenuItem>

        <ListDivider inset='gutter' />

        <MenuItem onClick={props.onExplainerShow}>
          <ListItemDecorator>
            <SchoolRoundedIcon />
          </ListItemDecorator>
          Tutorial ...
        </MenuItem>

      </Menu>
    </Dropdown>

    {/* Options dialog */}
    <DialogNamePreset open={namingOpened} onClose={handleClosePresetNaming} onStore={handlePresetSave} />

  </>;
}


================================================
FILE: src/modules/blocks/AutoBlocksRenderer.tsx
================================================
import * as React from 'react';

import type { ContentScaling } from '~/common/app.theme';
import type { DMessageRole } from '~/common/stores/chat/chat.message';

import { BlocksContainer } from './BlocksContainers';
import { EnhancedRenderCode } from './enhanced-code/EnhancedRenderCode';
import { RenderDangerousHtml } from './danger-html/RenderDangerousHtml';
import { RenderImageURL } from './image/RenderImageURL';
import { RenderMarkdown, RenderMarkdownMemo } from './markdown/RenderMarkdown';
import { RenderPlainText } from './plaintext/RenderPlainText';
import { RenderWordsDiff, WordsDiff } from './wordsdiff/RenderWordsDiff';
import { ToggleExpansionButton } from './ToggleExpansionButton';
import { renderCodeMemoOrNot } from './code/RenderCode';
import { useAutoBlocksMemoSemiStable, useTextCollapser } from './blocks.hooks';
import { useScaledCodeSx, useScaledImageSx, useScaledTypographySx, useToggleExpansionButtonSx } from './blocks.styles';


// configuration
const DISABLE_MARKDOWN_PROGRESSIVE_PREPROCESS = true; // set to false to render LaTeX inline formulas as they come in, not at the end of the message


// To get to the 'ref' version (which doesn't seem to be used anymore, and was used to isolate the source of the bubble bar):
// export const AutoBlocksRenderer = React.forwardRef<HTMLDivElement, BlocksRendererProps>((props, ref) => {
// AutoBlocksRenderer.displayName = 'AutoBlocksRenderer';

export type AutoBlocksCodeRenderVariant = 'outlined' | 'plain' | 'enhanced';

/**
 * Features: collpase/expand, auto-detects HTML, SVG, Code, etc..
 * Used by (and more):
 * - DocAttachmentFragmentEditor
 * - ContentPartPlaceholder
 */
export function AutoBlocksRenderer(props: {
  // required
  text: string;
  fromRole: DMessageRole;

  contentScaling: ContentScaling;
  fitScreen: boolean;
  isMobile: boolean;

  showAsDanger?: boolean;
  showAsItalic?: boolean;
  showUnsafeHtmlCode?: boolean;

  renderAsCodeWithTitle?: string;
  renderAsWordsDiff?: WordsDiff;

  blocksProcessor?: 'diagram',
  codeRenderVariant?: AutoBlocksCodeRenderVariant /* default: outlined */,
  textRenderVariant: 'markdown' | 'text',

  /**
   * optimization: allow memo to all individual blocks except the last one
   * work in progress on that
   */
  optiAllowSubBlocksMemo?: boolean;

  onContextMenu?: (event: React.MouseEvent) => void;
  onDoubleClick?: (event: React.MouseEvent) => void;

  /**
   * If defined, this is a function that will replace the first occurrence of
   * the search string with the replace string.
   */
  setText?: (newText: string) => void;

}) {

  // props-derived state
  const fromAssistant = props.fromRole === 'assistant';
  const fromSystem = props.fromRole === 'system';
  const fromUser = props.fromRole === 'user';
  const isUserCommand = fromUser && props.text.startsWith('/');

  // state
  const { text, isTextCollapsed, forceTextExpanded, handleToggleExpansion } =
    useTextCollapser(props.text, fromUser);
  const autoBlocksStable = useAutoBlocksMemoSemiStable(
    text,
    props.renderAsCodeWithTitle,
    fromSystem,
    props.renderAsWordsDiff,
    props.blocksProcessor === 'diagram',
  );

  // handlers
  const { setText } = props;
  const handleReplaceCode = React.useCallback((search: string, replace: string): boolean => {
    if (setText) {
      const newText = text.replace(search, replace);
      if (newText !== text) {
        setText(newText);
        return true;
      }
    }
    return false;
  }, [setText, text]);


  // Memo the styles, to minimize re-renders
  const scaledCodeSx = useScaledCodeSx(fromAssistant, props.contentScaling, props.codeRenderVariant || 'outlined');
  const scaledImageSx = useScaledImageSx(props.contentScaling);
  const scaledTypographySx = useScaledTypographySx(props.contentScaling, !!props.showAsDanger, !!props.showAsItalic);
  const toggleExpansionButtonSx = useToggleExpansionButtonSx(props.contentScaling, props.codeRenderVariant || 'outlined');


  return (
    <BlocksContainer
      // ref={ref /* this will assign the ref, now not needed anymore */}
      onContextMenu={props.onContextMenu}
      onDoubleClick={props.onDoubleClick}
    >

      {/* sequence of render components, for each Block */}
      {autoBlocksStable.map((bkInput, index) => {

        // Optimization: only memo the non-currently-rendered components, if the message is still in flux
        const optimizeMemoBeforeLastBlock = props.optiAllowSubBlocksMemo === true && index < (autoBlocksStable.length - 1);
        // Optimization: disable the markdown preprocessor on the last block, only do it at the end not while in progress
        const optimizeDisableProcessorsOnLast = DISABLE_MARKDOWN_PROGRESSIVE_PREPROCESS && props.optiAllowSubBlocksMemo === true && index === (autoBlocksStable.length - 1);

        switch (bkInput.bkt) {

          case 'md-bk':
            const RenderMarkdownMemoOrNot = optimizeMemoBeforeLastBlock ? RenderMarkdownMemo : RenderMarkdown;
            return (props.textRenderVariant === 'text' || fromSystem || isUserCommand) ? (
              // Keep in sync with ScaledPlainTextRenderer
              <RenderPlainText
                key={'txt-bk-' + index}
                content={bkInput.content}
                sx={scaledTypographySx}
              />
            ) : (
              // Keep in sync with ScaledMarkdownRenderer
              <RenderMarkdownMemoOrNot
                key={'md-bk-' + index}
                content={bkInput.content}
                disablePreprocessor={optimizeDisableProcessorsOnLast}
                sx={scaledTypographySx}
              />
            );

          case 'code-bk':
            // NOTE: 2024-09-24: Just memo the code all the time to prevent state loss on the last block when it switches to complete
            // const RenderCodeMemoOrNot = renderCodeMemoOrNot(true /* optimizeMemoBeforeLastBlock */);
            // NOTE: 2024-09-24/2: Keep it for now, as the issue seems to be on the upstream ChatMessage
            const RenderCodeMemoOrNot = renderCodeMemoOrNot(optimizeMemoBeforeLastBlock);

            // Custom handling for some of our blocks
            let disableEnhancedRender = bkInput.isPartial || (!bkInput.title && bkInput.lines <= 3);
            let enhancedStartCollapsed = false;

            return (props.codeRenderVariant === 'enhanced' && !disableEnhancedRender) ? (
              <EnhancedRenderCode
                key={'code-bk-' + index}
                semiStableId={bkInput.bkId}
                code={bkInput.code} title={bkInput.title} isPartial={bkInput.isPartial || isTextCollapsed}
                contentScaling={props.contentScaling}
                fitScreen={props.fitScreen}
                isMobile={props.isMobile}
                initialShowHTML={props.showUnsafeHtmlCode}
                initialIsCollapsed={enhancedStartCollapsed}
                noCopyButton={props.blocksProcessor === 'diagram' || isTextCollapsed}
                optimizeLightweight={optimizeMemoBeforeLastBlock}
                onReplaceInCode={(!setText || isTextCollapsed) ? undefined : handleReplaceCode}
                codeSx={scaledCodeSx}
              />
            ) : (
              <RenderCodeMemoOrNot
                key={'code-bk-' + index}
                semiStableId={bkInput.bkId}
                code={bkInput.code} title={bkInput.title} isPartial={bkInput.isPartial || isTextCollapsed}
                fitScreen={props.fitScreen}
                initialShowHTML={props.showUnsafeHtmlCode /* && !bkInput.isPartial NOTE: with this, it would be only auto-rendered at the end, preventing broken renders */}
                noCopyButton={props.blocksProcessor === 'diagram' || isTextCollapsed}
                optimizeLightweight={optimizeMemoBeforeLastBlock}
                onReplaceInCode={(!setText || isTextCollapsed) ? undefined : handleReplaceCode}
                sx={scaledCodeSx}
              />
            );

          case 'dang-html-bk':
            return (
              <RenderDangerousHtml
                key={'dang-html-bk-' + index}
                html={bkInput.html}
                sx={scaledCodeSx}
              />
            );

          case 'img-url-bk':
            return (
              <RenderImageURL
                key={'img-url-bk-' + index}
                imageURL={bkInput.url}
                expandableText={bkInput.alt}
                onImageRegenerate={undefined /* we'd need to have selective fragment editing as there could be many of these URL images in a fragment */}
                scaledImageSx={scaledImageSx}
                variant='content-part'
              />
            );

          case 'txt-diffs-bk':
            return (
              <RenderWordsDiff
                key={'txt-diffs-bk-' + index}
                wordsDiff={bkInput.wordsDiff}
                sx={scaledTypographySx}
              />
            );
        }
      })}

      {(isTextCollapsed || forceTextExpanded) && (
        <ToggleExpansionButton
          color={props.codeRenderVariant === 'plain' ? 'neutral' : undefined}
          isCollapsed={isTextCollapsed}
          onToggle={handleToggleExpansion}
          sx={toggleExpansionButtonSx}
        />
      )}

    </BlocksContainer>
  );
}


================================================
FILE: src/modules/blocks/blocks.hooks.ts
================================================
import * as React from 'react';

import { agiId } from '~/common/util/idUtils';
import { countLines } from '~/common/util/textUtils';
import { shallowEquals } from '~/common/util/hooks/useShallowObject';

import type { RenderBlockInputs } from './blocks.types';
import type { WordsDiff } from './wordsdiff/RenderWordsDiff';
import { parseBlocksFromText } from './blocks.textparser';


// configuration
const USER_COLLAPSED_LINES: number = 8;


export function useTextCollapser(origText: string, enable: boolean) {

  // state
  const [forceTextExpanded, setForceTextExpanded] = React.useState(false);

  // quick memo
  const { text, isTextCollapsed } = React.useMemo(() => {
    // nothing to do
    if (!enable || forceTextExpanded)
      return { text: origText, isTextCollapsed: false };

    // count lines
    const textLines = origText.split('\n');
    if (textLines.length <= USER_COLLAPSED_LINES)
      return { text: origText, isTextCollapsed: false };

    // chop to the first few lines
    return { text: textLines.slice(0, USER_COLLAPSED_LINES).join('\n'), isTextCollapsed: true };
  }, [enable, forceTextExpanded, origText]);

  // memo handlers
  const handleToggleExpansion = React.useCallback(() => setForceTextExpanded(on => !on), []);

  return {
    text,
    isTextCollapsed,
    forceTextExpanded,
    handleToggleExpansion,
  };
}


// Helper function to compare blocks without considering their IDs
function areBlocksEqualIdIgnored(block1: RenderBlockInputs[number] | undefined, block2: RenderBlockInputs[number] | undefined): boolean {
  if (!block1 || !block2)
    return false;
  const { bkId: _, ...rest1 } = block1;
  const { bkId: __, ...rest2 } = block2;
  return shallowEquals(rest1, rest2);
}


/**
 * Note: this will keep generally stable IDs, but will change them when:
 * - when the AutoBlocksRenderer goes from non-memo to Memo: reassigned: *
 * - when the text is still being parsed, e.g. a string will find a "```" block
 *   as part of the the running text, in which case the growing text will be
 *   reassigned (when it's chopped to before the code block, in the next call)
 */
export function useAutoBlocksMemoSemiStable(text: string, forceAsFenced: string | undefined, forceAsMarkdown: boolean, forceAsWordsDiff: WordsDiff | undefined, selectSingleCodeBlock: boolean): RenderBlockInputs {

  // state - previous blocks, to stabilize objects
  const prevBlocksRef = React.useRef<RenderBlockInputs>([]);
  const prevTextRef = React.useRef('');

  return React.useMemo(() => {
    let newBlocks: RenderBlockInputs;
    if (forceAsFenced !== undefined)
      newBlocks = [{ bkt: 'code-bk', title: forceAsFenced, code: text, lines: countLines(text), isPartial: false }];
    else if (forceAsMarkdown)
      newBlocks = [{ bkt: 'md-bk', content: text }];
    else if (forceAsWordsDiff && forceAsWordsDiff.length >= 1)
      newBlocks = [{ bkt: 'txt-diffs-bk', wordsDiff: forceAsWordsDiff }];
    else {
      newBlocks = parseBlocksFromText(text);
      if (selectSingleCodeBlock && newBlocks.length > 1)
        newBlocks = newBlocks.filter(({ bkt }) => bkt === 'code-bk');
    }

    const recycledBlocks: RenderBlockInputs = newBlocks.map((newBlock, index) => {
      const prevBlock = prevBlocksRef.current[index] ?? undefined;
      const isLastBlock = index === newBlocks.length - 1;
      const isStreaming = isLastBlock && text.startsWith(prevTextRef.current);

      if (areBlocksEqualIdIgnored(prevBlock, newBlock))
        return prevBlock;

      if (isStreaming && prevBlock?.bkt === newBlock.bkt)
        return { ...newBlock, bkId: prevBlock.bkId };

      return { ...newBlock, bkId: agiId('chat-block') };
    });

    prevBlocksRef.current = recycledBlocks;
    prevTextRef.current = text;

    return recycledBlocks;
  }, [forceAsFenced, forceAsMarkdown, forceAsWordsDiff, selectSingleCodeBlock, text]);
}


================================================
FILE: src/modules/blocks/blocks.styles.ts
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';

import { ContentScaling, themeScalingMap } from '~/common/app.theme';

import type { AutoBlocksCodeRenderVariant } from './AutoBlocksRenderer';


// Styles for the various block components

export function useScaledCodeSx(fromAssistant: boolean, contentScaling: ContentScaling, codeRenderVariant: AutoBlocksCodeRenderVariant): SxProps {
  return React.useMemo(() => ({
    // Note: we don't handle 'enhanced' here, as we'll do it when the EnhancedRenderCode
    //       kicks in for real, and in what instance we patch this object.
    my:
      codeRenderVariant === 'plain' ? 0
        : themeScalingMap[contentScaling]?.blockCodeMarginY ?? 0,
    backgroundColor:
      codeRenderVariant === 'plain' ? 'background.surface'
        : fromAssistant ? 'background.level1' // was 'neutral.plainHoverBg', turned to background.level1 to improve the dark mode contrast while keeping light the same
          : 'primary.plainActiveBg', // could use plainActiveBg to increase the background contrast in dark mode (#631), but it's really too bright in that case
    boxShadow:
      codeRenderVariant === 'plain' ? undefined
        : 'inset 2px 0px 5px -4px var(--joy-palette-background-backdrop)', // was 'xs'
    borderRadius: 'sm',
    fontFamily: 'code',
    fontSize: themeScalingMap[contentScaling]?.blockCodeFontSize ?? '0.875rem',
    fontWeight: 'md', // JetBrains Mono has a lighter weight, so we need that extra bump
    fontVariantLigatures: 'none',
    lineHeight: themeScalingMap[contentScaling]?.blockLineHeight ?? 1.75,
    minWidth: 288,
    minHeight: '2.75rem',
  }), [codeRenderVariant, contentScaling, fromAssistant]);
}

export function useScaledImageSx(contentScaling: ContentScaling): SxProps {
  return React.useMemo(() => ({
    fontSize: themeScalingMap[contentScaling]?.blockFontSize ?? undefined,
    lineHeight: themeScalingMap[contentScaling]?.blockLineHeight ?? 1.75,
    marginBottom: themeScalingMap[contentScaling]?.blockImageGap ?? 1.5,
  }), [contentScaling]);
}

export function useScaledTypographySx(contentScaling: ContentScaling, showAsDanger: boolean, showAsItalic: boolean) {
  return React.useMemo(() => ({
    fontSize: themeScalingMap[contentScaling]?.blockFontSize ?? undefined,
    lineHeight: themeScalingMap[contentScaling]?.blockLineHeight ?? 1.75,
    ...(showAsDanger ? { color: 'danger.500', fontWeight: 500 } : {}),
    ...(showAsItalic ? { fontStyle: 'italic' } : {}),
  }), [contentScaling, showAsDanger, showAsItalic]);
}

export function useToggleExpansionButtonSx(contentScaling: ContentScaling, codeRenderVariant: AutoBlocksCodeRenderVariant): SxProps {
  return React.useMemo(() => ({
    width: '100%',
    fontSize: themeScalingMap[contentScaling]?.fragmentButtonFontSize ?? undefined,
    borderTopLeftRadius: 0,
    borderTopRightRadius: 0,
    ...(codeRenderVariant === 'plain' ? {
      // Style when inside the <DocumentFragmentEditor />
      backgroundColor: 'background.surface',
      // marginTop: -0.5,
    } : {
      // Style when inside <ChatMessage /> in particular for 'user' messages
      marginTop: 1,
    }),
  }), [codeRenderVariant, contentScaling]);
}



================================================
FILE: src/modules/blocks/blocks.textparser.ts
================================================
import type { RenderBlockInputs } from './blocks.types';
import { heuristicAllMarkdownImageReferences } from './image/RenderImageURL';
import { heuristicIsBlockPureHTML } from './danger-html/RenderDangerousHtml';
import { countLines } from '~/common/util/textUtils';


export function parseBlocksFromText(text: string): RenderBlockInputs {

  // special case: this could be generated by a proxy that returns an HTML page instead of the API response
  if (heuristicIsBlockPureHTML(text))
    return [{ bkt: 'dang-html-bk', html: text }];

  // special case: markdown image references (e.g., ![alt text](https://example.com/image.png))
  const imageBkInputs = heuristicAllMarkdownImageReferences(text);
  if (imageBkInputs)
    return imageBkInputs;

  const regexPatterns = {
    // was: \w\x20\\.+-_ for tge filename, but was missing too much
    // REVERTED THIS: was: (`{3,}\n?|$), but was matching backticks within blocks. so now it must end with a newline or stop
    // This was the longest in use, and still we're based on it
    // codeBlock: /`{3,}([\S\x20]+)?\n([\s\S]*?)(`{3,}\n?|$)/g,
    // This is way more promising, but will either not perform a partial match (no match at all) or match a single line
    // codeBlock: /^( {0,3})`{3,}([^\n`]*)\n([\s\S]*?)(?:\n^\1`{3,}[^\S\n]*(?=\n|$))?/gm,
    codeBlock: /`{3,}([^\n`]*)\n([\s\S]*?)(`{3,}(?=[ *\n]|$)|$)/g,
    htmlCodeBlock: /<!DOCTYPE html>([\s\S]*?)<\/html>/gi,
    svgBlock: /<svg (xmlns|width|viewBox)=([\s\S]*?)<\/svg>/g,
  };

  const blocks: RenderBlockInputs = [];
  let lastIndex = 0;

  while (true) {

    // find the first match (if any) trying all the regexes
    let match: RegExpExecArray | null = null;
    let matchType: keyof typeof regexPatterns | null = null;
    let earliestMatchIndex: number | null = null;

    for (const type in regexPatterns) {
      const regex = regexPatterns[type as keyof typeof regexPatterns];
      regex.lastIndex = lastIndex;
      const currentMatch = regex.exec(text);
      if (currentMatch && (earliestMatchIndex === null || currentMatch.index < earliestMatchIndex)) {
        match = currentMatch;
        matchType = type as keyof typeof regexPatterns;
        earliestMatchIndex = currentMatch.index;
      }
    }
    if (match === null)
      break;

    // anything leftover before the match is text
    if (match.index > lastIndex)
      blocks.push({ bkt: 'md-bk', content: text.slice(lastIndex, match.index) });

    // add the block
    switch (matchType) {
      case 'codeBlock':
        const blockTitle: string = (match[1] || '').trim();
        // note: we don't trim blockCode to preserve leading spaces, however if the last line is only made of spaces or tabs, we trim that
        const blockCode: string = match[2].replace(/[\t ]+$/, '');
        const blockEnd: string = match[3];
        blocks.push({ bkt: 'code-bk', title: blockTitle, code: blockCode, lines: countLines(blockCode), isPartial: !blockEnd.startsWith('```') });
        break;

      case 'htmlCodeBlock':
        const preMatchHtml: string = `<!DOCTYPE html>${match[1]}</html>`;
        blocks.push({ bkt: 'code-bk', title: 'html', code: preMatchHtml, lines: countLines(preMatchHtml), isPartial: false });
        break;

      case 'svgBlock':
        blocks.push({ bkt: 'code-bk', title: 'svg', code: match[0], lines: countLines(match[0]), isPartial: false });
        break;
    }

    // advance the pointer
    lastIndex = match.index + match[0].length;
  }

  // remainder is text
  if (lastIndex < text.length)
    blocks.push({ bkt: 'md-bk', content: text.slice(lastIndex) });

  return blocks;
}



================================================
FILE: src/modules/blocks/blocks.types.ts
================================================
import type { WordsDiff } from './wordsdiff/RenderWordsDiff';


export type RenderBlockInputs = BlockInput[];


// In order of priority from the most frequent to the least
type BlockInput = {
  bkId?: string;
  /* Other fields remain the same */
} & ({
  /* Rendered as markdown or plain text */
  bkt: 'md-bk';
  content: string;
} | {
  /* Rendered as Code (can be copied, LiveFile'd, etc) */
  // NOTE: this should actually be called 'Fenced' block?
  bkt: 'code-bk';
  title: string;
  code: string;
  lines: number;
  isPartial: boolean;
} | {
  /* Rendered as HTML (dangerous) */
  bkt: 'dang-html-bk';
  html: string;
} | {
  /* (Markdown Image) Rendered as an image */
  bkt: 'img-url-bk';
  url: string;
  alt?: string;
} | {
  /* Rendered as red/green text diffs */
  bkt: 'txt-diffs-bk';
  wordsDiff: WordsDiff;
});


================================================
FILE: src/modules/blocks/BlocksContainers.tsx
================================================
import { Box, styled, Textarea } from '@mui/joy';

import { lineHeightChatTextMd } from '~/common/app.theme';


const blocksTextStyleSx = {
  // note: this will be used for non-blocks mainly (errors and other strings ourside of RenderXYX)
  lineHeight: lineHeightChatTextMd,

  // customize the text selection color (also in edit mode)
  '&::selection': {
    // backgroundColor: '#fc70c3',
    backgroundColor: 'var(--joy-palette-primary-solidBg)',
    color: 'var(--joy-palette-primary-solidColor)',
  },
};


/**
 * This style is reused by all the Fragments (BlocksRenderer being the Text one),
 * contained within a singe Grid (1fr) in the Message component.
 */
export const BlocksContainer = styled(Box)({
  // the parent is a Grid, and this takes up to the Grid's width
  // - maxWidth: '100%' makes sure we don't x-scroll the whole chat window
  // - width: '100%' would also maximize the fragment width to the containing grid even if smaller
  // NOTE 1: we choose just `maxWidth` to allow the grid to place this towards the start/end of the message
  // however see `ContentPartTextEdit` where we set the width to 100% as we need a large editor
  // NOTE 2: after seeing html/code fragments smaller than the text fragments before them, we're back
  // to using width: 100% to make sure the fragments are all the same width (we lose the alignment unfortunately)
  width: '100%',

  // enables children's x-scrollbars (clips to the Fragment, so sub-parts will stay within this)
  overflowX: 'auto',

  // text style
  ...blocksTextStyleSx,
});

/**
 * Use this TextArea for block-like looks while editing.
 */
export const BlocksTextarea = styled(Textarea)({
  // very important: back to a 100% width - the parent is a Grid - see why we need this in BlocksContainer
  width: '100%',

  // just shrink padding tiny bit
  paddingBlock: '0.25rem',
  // marginBlock: '-0.25rem',

  // make the editing stand out a bit more
  boxShadow: 'inset 1px 0px 3px -2px var(--joy-palette-warning-softColor)',
  outline: '1px solid',
  outlineColor: 'var(--joy-palette-warning-solidBg)',

  // text style
  ...blocksTextStyleSx,
});



================================================
FILE: src/modules/blocks/OverlayButton.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { IconButton, IconButtonProps, styled, Tooltip, TooltipProps } from '@mui/joy';


// configuration
export const OVERLAY_BUTTON_RADIUS = '4px';   // note: can't use 'sm', 'md', etc.
export const OVERLAY_BUTTON_ZINDEX = 2;       // top of message and its chips

export const overlayButtonsClassName = 'overlay-buttons';

export const overlayButtonsTopRightSx: SxProps = {
  // stick to the top-right corner
  position: 'absolute',
  top: 0,
  right: 0,
  zIndex: OVERLAY_BUTTON_ZINDEX, // top of message and its chips

  // stype
  p: 0.5,

  // layout
  display: 'flex',
  flexDirection: 'row',
  gap: 1,

  // faded-out defaults
  opacity: 'var(--AGI-overlay-start-opacity, 0)',
  pointerEvents: 'none',

  // 2024-08-24: disabled the fading in/out, it's slow
  // transition: 'opacity 0.1s cubic-bezier(.17,.84,.44,1)',

  // buttongroup: background
  // '& > div > button': {
  //   backgroundColor: 'background.surface',
  //   backdropFilter: 'blur(12px)',
  // },
};

export const overlayButtonsActiveSx = {
  opacity: 1,
  pointerEvents: 'auto',
};


export const StyledOverlayButton = styled(IconButton)(({ theme, variant }) => ({
  backgroundColor: variant === 'outlined' ? theme.palette.background.surface : undefined,
  '--Icon-fontSize': theme.fontSize.lg,
})) as typeof IconButton;

export const overlayButtonShadowSx: SxProps = {
  boxShadow: '0px 1px 3px -2px var(--joy-palette-background-backdrop)',
  // boxShadow:'sm',
};

export const overlayGroupWithShadowSx: SxProps = {
  ...overlayButtonShadowSx,
  '--ButtonGroup-radius': OVERLAY_BUTTON_RADIUS,
};


// New props interface that combines IconButton and Tooltip props
interface OverlayButtonWithTooltipProps extends IconButtonProps {
  tooltip?: React.ReactNode;
  placement?: TooltipProps['placement'];
  tooltipProps?: Partial<Omit<TooltipProps, 'children'>>;
  smShadow?: boolean;
}

export const OverlayButton = ({ tooltip, placement, tooltipProps, smShadow, color, variant, ...buttonProps }: OverlayButtonWithTooltipProps) =>
  tooltip ? (
    <Tooltip disableInteractive arrow placement={placement || 'top'} title={tooltip} color={color} {...tooltipProps}>
      <StyledOverlayButton color={color} variant={variant || 'outlined'} sx={smShadow ? overlayButtonShadowSx : undefined} {...buttonProps} />
    </Tooltip>
  ) : (
    <StyledOverlayButton color={color} variant={variant || 'outlined'} sx={smShadow ? overlayButtonShadowSx : undefined} {...buttonProps} />
  );



================================================
FILE: src/modules/blocks/ScaledTextBlockRenderer.tsx
================================================
import * as React from 'react';

import type { ContentScaling } from '~/common/app.theme';

import { BlocksContainer } from './BlocksContainers';
import { RenderMarkdown } from './markdown/RenderMarkdown';
import { RenderPlainText } from './plaintext/RenderPlainText';
import { useScaledTypographySx } from './blocks.styles';


/**
 * Smaller and lighter-weight version of AutoBlocksRenderer for rendering just some text
 */
export function ScaledTextBlockRenderer(props: {
  text: string,
  contentScaling: ContentScaling,
  textRenderVariant: 'text' | 'markdown',
  showAsDanger?: boolean,
  showAsItalic?: boolean,
}) {

  // state
  const scaledTypographySx = useScaledTypographySx(props.contentScaling, !!props.showAsDanger, !!props.showAsItalic);

  return (
    <BlocksContainer>
      {props.textRenderVariant === 'markdown' ? <RenderMarkdown content={props.text} sx={scaledTypographySx} />
        : props.textRenderVariant === 'text' ? <RenderPlainText content={props.text} sx={scaledTypographySx} />
          : ('unknown textRenderVariant: ' + props.textRenderVariant)}
    </BlocksContainer>
  );
}



================================================
FILE: src/modules/blocks/ToggleExpansionButton.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Button, ColorPaletteProp } from '@mui/joy';
import ExpandLessIcon from '@mui/icons-material/ExpandLess';
import ExpandMoreIcon from '@mui/icons-material/ExpandMore';


/**
 * Simple button to 'Show more' or 'Show less' content
 */
export function ToggleExpansionButton(props: {
  color?: ColorPaletteProp;
  isCollapsed: boolean;
  onToggle: () => void;
  sx: SxProps;
}) {
  return (
    <div style={{ lineHeight: 1 /* Absorbs some weird height issue since the parent has an extended line height (lineHeightChatTextMd) */ }}>
      <Button
        variant='soft'
        color={props.color}
        size='sm'
        onClick={props.onToggle}
        startDecorator={props.isCollapsed ? <ExpandMoreIcon /> : <ExpandLessIcon />}
        sx={props.sx}
      >
        {props.isCollapsed ? 'Show more' : 'Show less'}
      </Button>
    </div>
  );
}


================================================
FILE: src/modules/blocks/code/RenderCode.css
================================================
/* Used for rendering line numbers in code blocks */
/* adapted from: prismjs/plugins/line-numbers/prism-line-numbers.css */

code.line-numbers {
    --ln-padding: 4.5em;
    padding-left: var(--ln-padding);

    .code-container {
        position: relative;
        counter-reset: linenumber;
        /*white-space: inherit;*/
    }

    .line-numbers-rows {
        position: absolute;
        top: 0;
        left: calc(-1 * var(--ln-padding));
        width: calc(var(--ln-padding) - 0.8em);
        font-size: 100%;
        letter-spacing: -1px;
        /*noinspection CssUnresolvedCustomProperty*/
        border-right: 1px solid var(--joy-palette-primary-solidDisabledColor);

        -webkit-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
        pointer-events: none;

        > span {
            display: block;
            counter-increment: linenumber;
        }

        > span:before {
            content: counter(linenumber);
            /*noinspection CssUnresolvedCustomProperty*/
            color: var(--joy-palette-primary-solidDisabledColor);
            display: block;
            padding-right: 0.8em;
            font-weight: 400;
            text-align: right;
        }
    }
}



================================================
FILE: src/modules/blocks/code/RenderCode.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, ButtonGroup, Dropdown, ListItem, Menu, MenuButton, Sheet, Tooltip, Typography } from '@mui/joy';
import ChangeHistoryTwoToneIcon from '@mui/icons-material/ChangeHistoryTwoTone';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import FitScreenIcon from '@mui/icons-material/FitScreen';
import HtmlIcon from '@mui/icons-material/Html';
import NumbersRoundedIcon from '@mui/icons-material/NumbersRounded';
import SquareTwoToneIcon from '@mui/icons-material/SquareTwoTone';
import WrapTextIcon from '@mui/icons-material/WrapText';
import ZoomOutMapIcon from '@mui/icons-material/ZoomOutMap';

import { copyToClipboard } from '~/common/util/clipboardUtils';
import { useFullscreenElement } from '~/common/components/useFullscreenElement';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { OVERLAY_BUTTON_RADIUS, OverlayButton, overlayButtonsActiveSx, overlayButtonsClassName, overlayButtonsTopRightSx, overlayGroupWithShadowSx, StyledOverlayButton } from '../OverlayButton';
import { RenderCodeHtmlIFrame } from './code-renderers/RenderCodeHtmlIFrame';
import { RenderCodeMermaid } from './code-renderers/RenderCodeMermaid';
import { heuristicIsSVGCode, RenderCodeSVG } from './code-renderers/RenderCodeSVG';
import { RenderCodeSyntax } from './code-renderers/RenderCodeSyntax';
import { heuristicIsBlockPureHTML } from '../danger-html/RenderDangerousHtml';
import { heuristicIsCodePlantUML, RenderCodePlantUML, usePlantUmlSvg } from './code-renderers/RenderCodePlantUML';
import { useOpenInWebEditors } from './code-buttons/useOpenInWebEditors';
import { useStickyCodeOverlay } from './useStickyCodeOverlay';

// style for line-numbers
import './RenderCode.css';


// configuration
const ALWAYS_SHOW_OVERLAY = true;


// RenderCode

export const renderCodeMemoOrNot = (memo: boolean) => memo ? RenderCodeMemo : RenderCode;

export const RenderCodeMemo = React.memo(RenderCode);

interface RenderCodeBaseProps {
  semiStableId: string | undefined,
  title: string,
  code: string,
  isPartial: boolean,
  fitScreen?: boolean,
  initialShowHTML?: boolean,
  noCopyButton?: boolean,
  optimizeLightweight?: boolean,
  onReplaceInCode?: (search: string, replace: string) => boolean;
  renderHideTitle?: boolean,
  sx?: SxProps,
}

function RenderCode(props: RenderCodeBaseProps) {
  return (
    <React.Suspense
      fallback={
        // Mimic the structure of the RenderCodeImpl - to mitigate race conditions that could cause problematic rendering
        // of code (where two components were missing from the structure)
        <Box sx={renderCodecontainerSx}>
          <Box component='code' className='language-unknown' aria-label='Displaying Code...' sx={{ p: 1.5, display: 'block', ...props.sx }}>
            <Box component='span' sx={{ flex: 1, display: 'flex', flexDirection: 'column' }}>
              <Box component='span' className='code-container' aria-label='Code block'>
                {/* Just wait until the correct implementation renders */}
              </Box>
            </Box>
          </Box>
        </Box>
      }
    >
      <_DynamicPrism {...props} />
    </React.Suspense>
  );
}


// Lazy loader of the heavy prism functions
const _DynamicPrism = React.lazy(async () => {

  // Dynamically import the code highlight functions
  const { highlightCode, inferCodeLanguage } = await import('~/modules/blocks/code/code-highlight/codePrism');

  return {
    default: (props: RenderCodeBaseProps) => <RenderCodeImpl highlightCode={highlightCode} inferCodeLanguage={inferCodeLanguage} {...props} />,
  };
});


// Actual implemetation of the code rendering

const renderCodecontainerSx: SxProps = {
  // position the overlay buttons - this has to be one level up from the code, otherwise the buttons will h-scroll with the code
  position: 'relative',

  // style
  '--IconButton-radius': OVERLAY_BUTTON_RADIUS,

  // fade in children buttons
  [`&:hover > .${overlayButtonsClassName}`]: overlayButtonsActiveSx,
};

const overlayGridSx: SxProps = {
  ...overlayButtonsTopRightSx,
  display: 'grid',
  gap: 0.5,
  justifyItems: 'end',
};


const overlayFirstRowSx: SxProps = {
  display: 'flex',
  gap: 0.5,
};

function RenderCodeImpl(props: RenderCodeBaseProps & {
  highlightCode: (inferredCodeLanguage: string | null, code: string, addLineNumbers: boolean) => string,
  inferCodeLanguage: (blockTitle: string, code: string) => string | null,
}) {

  // state
  // const [isHovering, setIsHovering] = React.useState(false);
  const [fitScreen, setFitScreen] = React.useState(!!props.fitScreen);
  const [showHTML, setShowHTML] = React.useState(props.initialShowHTML === true);
  const [showMermaid, setShowMermaid] = React.useState(true);
  const [showPlantUML, setShowPlantUML] = React.useState(true);
  const [showSVG, setShowSVG] = React.useState(true);
  const fullScreenElementRef = React.useRef<HTMLDivElement>(null);

  // external state
  const { isFullscreen, enterFullscreen, exitFullscreen } = useFullscreenElement(fullScreenElementRef);
  const { overlayRef, overlayBoundaryRef } = useStickyCodeOverlay({ disabled: props.optimizeLightweight || isFullscreen });

  // sticky overlay positioning
  const { uiComplexityMode, showLineNumbers, showSoftWrap, setShowLineNumbers, setShowSoftWrap } = useUIPreferencesStore(useShallow(state => ({
    uiComplexityMode: state.complexityMode,
    showLineNumbers: state.renderCodeLineNumbers,
    showSoftWrap: state.renderCodeSoftWrap,
    setShowLineNumbers: state.setRenderCodeLineNumbers,
    setShowSoftWrap: state.setRenderCodeSoftWrap,
  })));

  // derived props
  const {
    title: blockTitle,
    code,
    isPartial: blockIsPartial,
    highlightCode,
    inferCodeLanguage,
  } = props;

  const noTooltips = props.optimizeLightweight /*|| !isHovering*/;


  // handlers

  // const handleMouseOverEnter = React.useCallback(() => setIsHovering(true), []);

  // const handleMouseOverLeave = React.useCallback(() => setIsHovering(false), []);

  const handleCopyToClipboard = React.useCallback((e: React.MouseEvent) => {
    e.stopPropagation();
    copyToClipboard(code, 'Code');
  }, [code]);


  // heuristics for specialized rendering

  const lcBlockTitle = blockTitle.trim().toLowerCase();

  const isHTMLCode = heuristicIsBlockPureHTML(code);
  const renderHTML = isHTMLCode && showHTML;

  const isMermaidCode = lcBlockTitle === 'mermaid' && !blockIsPartial;
  const renderMermaid = isMermaidCode && showMermaid;

  const isPlantUMLCode = heuristicIsCodePlantUML(code.trim());
  let renderPlantUML = isPlantUMLCode && showPlantUML;
  const { data: plantUmlSvgData, error: plantUmlError } = usePlantUmlSvg(renderPlantUML, code);
  renderPlantUML = renderPlantUML && (!!plantUmlSvgData || !!plantUmlError);

  const isSVGCode = heuristicIsSVGCode(code);
  const renderSVG = isSVGCode && showSVG;
  const canScaleSVG = renderSVG && code.includes('viewBox="');

  const renderSyntaxHighlight = !renderHTML && !renderMermaid && !renderPlantUML && !renderSVG;
  const cannotRenderLineNumbers = !renderSyntaxHighlight || showSoftWrap;
  const renderLineNumbers = !cannotRenderLineNumbers && ((showLineNumbers && uiComplexityMode !== 'minimal') || isFullscreen);


  // Language & Highlight (2-stages)
  const inferredCodeLanguage = React.useMemo(() => {
    // shortcut - this mimics a similar path in inferCodeLanguage
    if (isHTMLCode)
      return 'html';
    // workhorse - could be slow, hence the memo
    return inferCodeLanguage(blockTitle, code);
  }, [blockTitle, code, inferCodeLanguage, isHTMLCode]);

  const highlightedCode = React.useMemo(() => {
    // fast-off
    if (!renderSyntaxHighlight || !code)
      return null;
    return highlightCode(inferredCodeLanguage, code, renderLineNumbers);
  }, [code, highlightCode, inferredCodeLanguage, renderLineNumbers, renderSyntaxHighlight]);


  // Title
  let showBlockTitle = !props.renderHideTitle && (blockTitle != inferredCodeLanguage) && (blockTitle.includes('.') || blockTitle.includes('://'));
  // Beautify: hide the block title when rendering HTML
  if (renderHTML)
    showBlockTitle = false;
  const isBorderless = (renderHTML || renderSVG) && !showBlockTitle;


  // External Buttons
  const openExternallyItems = useOpenInWebEditors(code, blockTitle, blockIsPartial, inferredCodeLanguage, isSVGCode);

  // style

  const isRenderingDiagram = renderMermaid || renderPlantUML;
  const hasExternalButtons = openExternallyItems.length > 0;

  const codeSx: SxProps = React.useMemo(() => ({

    // style
    p: isBorderless ? 0 : 1.5, // this block gets a thicker border (but we 'fullscreen' html in case there's no title)
    overflowX: 'auto', // ensure per-block x-scrolling
    whiteSpace: showSoftWrap ? 'break-spaces' : 'pre',

    // layout
    display: 'flex',
    flexDirection: 'column',
    // justifyContent: (renderMermaid || renderPlantUML) ? 'center' : undefined,

    // fix for SVG diagrams over dark mode: https://github.com/enricoros/big-AGI/issues/520
    '[data-joy-color-scheme="dark"] &': isRenderingDiagram ? { backgroundColor: 'neutral.500' } : {},

    // lots more style, incl font, background, embossing, radius, etc.
    ...props.sx,

    // patch the min height if we have the second row
    // ...(hasExternalButtons ? { minHeight: '5.25rem' } : {}),

  }), [isBorderless, isRenderingDiagram, props.sx, showSoftWrap]);


  return (
    <Box
      ref={overlayBoundaryRef}
      // onMouseEnter={handleMouseOverEnter}
      // onMouseLeave={handleMouseOverLeave}
      sx={renderCodecontainerSx}
    >

      <Box
        ref={fullScreenElementRef}
        component='code'
        className={`language-${inferredCodeLanguage || 'unknown'}${renderLineNumbers ? ' line-numbers' : ''}`}
        sx={!isFullscreen ? codeSx : { ...codeSx, backgroundColor: 'background.surface' }}
      >

        {/* Markdown Title (File/Type) */}
        {showBlockTitle && (
          <Sheet sx={{ backgroundColor: 'background.popup', boxShadow: 'xs', borderRadius: 'sm', border: '1px solid var(--joy-palette-neutral-outlinedBorder)', m: -0.5, mb: 1.5 }}>
            <Typography level='body-sm' sx={{ px: 1, py: 0.5, color: 'text.primary' }} className='agi-ellipsize'>
              {blockTitle}
              {/*{inferredCodeLanguage}*/}
            </Typography>
          </Sheet>
        )}

        {/* NOTE: this 'div' is only here to avoid some sort of collapse of the RenderCodeSyntax,
            which box disappears for some reason and the parent flex layout ends up lining up
            chars in a non-proper way.
            Since this damages the 'fullscreen' operation, we restore it somehow.
        */}
        <Box component='span' sx={!isFullscreen ? undefined : { flex: 1, display: 'flex', flexDirection: 'column' }}>
          {/* Renders HTML, or inline SVG, inline plantUML rendered, or highlighted code */}
          {renderHTML ? <RenderCodeHtmlIFrame htmlCode={code} isFullscreen={isFullscreen} />
            : renderMermaid ? <RenderCodeMermaid mermaidCode={code} fitScreen={fitScreen} />
              : renderSVG ? <RenderCodeSVG svgCode={code} fitScreen={fitScreen} />
                : (renderPlantUML && (plantUmlSvgData || plantUmlError)) ? <RenderCodePlantUML svgCode={plantUmlSvgData ?? null} error={plantUmlError} fitScreen={fitScreen} />
                  : <RenderCodeSyntax highlightedSyntaxAsHtml={highlightedCode} presenterMode={isFullscreen} />}
        </Box>

      </Box>

      {/* [overlay] Buttons (Code blocks (SVG, diagrams, HTML, syntax, ...)) */}
      {(ALWAYS_SHOW_OVERLAY /*|| isHovering*/) && (
        <Box
          ref={overlayRef}
          className={overlayButtonsClassName}
          sx={overlayGridSx}
        >

          {/* [row 1] */}
          <Box sx={overlayFirstRowSx}>

            {/* Show HTML */}
            {isHTMLCode && (
              <OverlayButton tooltip={noTooltips ? null : renderHTML ? 'Show Code' : 'Show Web Page'} variant={renderHTML ? 'solid' : 'outlined'} color='danger' smShadow onClick={() => setShowHTML(!showHTML)}>
                <HtmlIcon sx={{ fontSize: 'xl2' }} />
              </OverlayButton>
            )}

            {/* SVG, Mermaid, PlantUML -- including a max-out button */}
            {(isSVGCode || isMermaidCode || isPlantUMLCode) && (
              <ButtonGroup aria-label='Diagram' sx={overlayGroupWithShadowSx}>
                {/* Toggle rendering */}
                <OverlayButton
                  tooltip={noTooltips ? null
                    : (renderSVG || renderMermaid || renderPlantUML) ? 'Show Code'
                      : isSVGCode ? 'Render SVG'
                        : isMermaidCode ? 'Mermaid Diagram'
                          : 'PlantUML Diagram'
                  }
                  variant={(renderMermaid || renderPlantUML) ? 'solid' : 'outlined'}
                  color={isSVGCode ? 'warning' : undefined}
                  onClick={() => {
                    if (isSVGCode) setShowSVG(on => !on);
                    if (isMermaidCode) setShowMermaid(on => !on);
                    if (isPlantUMLCode) setShowPlantUML(on => !on);
                  }}>
                  {isSVGCode ? <ChangeHistoryTwoToneIcon /> : <SquareTwoToneIcon />}
                </OverlayButton>

                {/* Fit-Content */}
                {((isMermaidCode && showMermaid) || (isPlantUMLCode && showPlantUML && !plantUmlError) || (isSVGCode && showSVG && canScaleSVG)) && (
                  <OverlayButton tooltip={noTooltips ? null : fitScreen ? 'Original Size' : 'Fit Content'} variant={fitScreen ? 'solid' : 'outlined'} onClick={() => setFitScreen(on => !on)}>
                    <FitScreenIcon />
                  </OverlayButton>
                )}
              </ButtonGroup>
            )}

            {/* Group: Text Options */}
            <ButtonGroup aria-label='Text and code options' sx={overlayGroupWithShadowSx}>

              {/* Fullscreen */}
              <OverlayButton tooltip={noTooltips ? null : isFullscreen ? 'Exit Fullscreen' : !renderSyntaxHighlight ? 'Fullscreen' : 'Present'} variant={isFullscreen ? 'solid' : 'outlined'} onClick={isFullscreen ? exitFullscreen : enterFullscreen}>
                <ZoomOutMapIcon sx={{ fontSize: 'xl' }} />
              </OverlayButton>

              {/* Soft Wrap toggle */}
              {renderSyntaxHighlight && (
                <OverlayButton tooltip={noTooltips ? null : 'Wrap Lines'} disabled={!renderSyntaxHighlight} variant={(showSoftWrap && renderSyntaxHighlight) ? 'solid' : 'outlined'} onClick={() => setShowSoftWrap(!showSoftWrap)}>
                  <WrapTextIcon />
                </OverlayButton>
              )}

              {/* Line Numbers toggle */}
              {renderSyntaxHighlight && uiComplexityMode !== 'minimal' && (
                <OverlayButton tooltip={noTooltips ? null : 'Line Numbers'} disabled={cannotRenderLineNumbers} variant={(renderLineNumbers && renderSyntaxHighlight) ? 'solid' : 'outlined'} onClick={() => setShowLineNumbers(!showLineNumbers)}>
                  <NumbersRoundedIcon />
                </OverlayButton>
              )}

              {/* Open In Web Editors */}
              {hasExternalButtons && (
                <Dropdown>
                  <Tooltip disableInteractive arrow placement='top' title='Web Editors'>
                    <MenuButton
                      slots={{ root: StyledOverlayButton }}
                      slotProps={{ root: { variant: 'outlined' } }}
                    >
                      <EditRoundedIcon />
                    </MenuButton>
                  </Tooltip>
                  <Menu sx={{ minWidth: 160 }} placement='bottom-end'>
                    <ListItem>
                      <Typography level='body-sm'>Edit with:</Typography>
                    </ListItem>
                    {openExternallyItems}
                  </Menu>
                </Dropdown>
              )}

              {/* Copy */}
              {props.noCopyButton !== true && (
                <OverlayButton tooltip={noTooltips ? null : 'Copy Code'} variant='outlined' onClick={handleCopyToClipboard}>
                  <ContentCopyIcon />
                </OverlayButton>
              )}
            </ButtonGroup>

          </Box>

          {/* DISABLED: Converted to a Dropdown */}
          {/* [row 2, optional] Group: Open Externally */}
          {/*{!!openExternallyButtons.length && (*/}
          {/*  <ButtonGroup aria-label='Open code in external editors' sx={overlayGroupWithShadowSx}>*/}
          {/*    {openExternallyButtons}*/}
          {/*  </ButtonGroup>*/}
          {/*)}*/}

        </Box>
      )}

    </Box>
  );
}



================================================
FILE: src/modules/blocks/code/RenderCodePanelFrame.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, ColorPaletteProp, Sheet, useColorScheme } from '@mui/joy';

import { ContentScaling, themeScalingMap } from '~/common/app.theme';


export const enhancedCodePanelTitleTooltipSx: SxProps = {
  p: 1,
  display: 'grid',
  gridTemplateColumns: 'auto 1fr auto 1fr',
  alignItems: 'center',
  columnGap: 2,
  rowGap: 1,
  '& > :nth-of-type(odd)': {
    color: 'text.tertiary',
    fontSize: 'xs',
  },
};


export function RenderCodePanelFrame(props: {
  color: ColorPaletteProp;
  toolbarColor?: ColorPaletteProp;
  gutterBlock?: boolean;
  noOuterShadow?: boolean;
  contentScaling: ContentScaling;
  headerRow?: React.ReactNode;
  subHeaderInline?: React.ReactNode;
  toolbarRow?: React.ReactNode;
  selectedOutline?: boolean
  onHeaderClick?: () => void;
  onHeaderContext?: (event: React.MouseEvent<HTMLElement>) => void;
  children: React.ReactNode;
}) {

  // react to scheme change
  const isDarkMode = useColorScheme().mode === 'dark';

  // handlers

  const { onHeaderClick } = props;
  const isClickableHeader = !!onHeaderClick;

  const handleKeyDown = React.useCallback((event: React.KeyboardEvent) => {
    if (onHeaderClick && (event.key === 'Enter' || event.key === ' ')) {
      event.preventDefault();
      onHeaderClick();
    }
  }, [onHeaderClick]);


  const [frameSx, headersBlockSx, headerRowSx, subHeaderContainedSx, toolbarRowSx] = React.useMemo((): SxProps[] => [
    {
      // frame
      // add top margin (gutter) only of this is not the first block in the sequence
      ...(props.gutterBlock && {
        '&:not(:first-of-type)': { mt: themeScalingMap[props.contentScaling]?.blockCodeMarginY ?? 1 },
        '&:not(:last-of-type)': { mb: themeScalingMap[props.contentScaling]?.blockCodeMarginY /* * 1.25 */ ?? 1 },
      }),
      backgroundColor: /*props.noOuterShadow ? 'background.popup' :*/ 'background.surface',
      border: '1px solid',
      borderColor: !props.selectedOutline ? `${props.color}.outlinedBorder` : `${props.color}.outlinedColor`,
      borderRadius: 'sm',
      ...(!props.noOuterShadow && { boxShadow: 'sm' }),
      // boxShadow: 'inset 2px 0px 5px -4px var(--joy-palette-background-backdrop)',
      // contain: 'paint',
    },
    {
      // headers block
      // border moved to: Toolbar (for the Attachment Doc Part) and children (for the Code block)
      // borderBottom: '1px solid',
      // borderBottomColor: `${props.toolbarColor || props.color}.outlinedBorder`,
      ...(isClickableHeader && {
        cursor: 'pointer',
        borderRadius: 'sm',
        '&:hover': {
          backgroundColor: 'background.popup',
        },
      }),
    },
    {
      // header row 1
      // see DocAttachmentFragmentButton.buttonSx for the same scaling
      minHeight: props.contentScaling === 'xs' ? '2.25rem' : props.contentScaling === 'sm' ? '2.375rem' : '2.5rem',
      px: 1,
      // borderRadius: 'sm',
      // borderBottomLeftRadius: 0,
      // borderBottomRightRadius: 0,
      // layout
      display: 'flex',
      flexWrap: 'nowrap', // changed on 2025-06-18 to have a single row
      // flexWrap: 'wrap',
      justifyContent: 'space-between',
      alignItems: 'center',
      gap: 1,
    },
    {
      // subheader row 2
      m: 1,
      mt: 0,
    },
    {
      // toolbar row
      backgroundColor: `${props.toolbarColor || props.color}.${isDarkMode ? 900 : 50}`,
      // borderTop: '1px solid',
      // borderTopColor: `${props.toolbarColor || props.color}.outlinedBorder`,
      // borderBottom: '1px solid',
      // borderBottomColor: /*isEditing ? 'transparent' :*/ `${props.toolbarColor || props.color}.outlinedBorder`,
      p: 1,
      // layout
      display: 'grid',
      gap: 1,
    },

  ], [isClickableHeader, isDarkMode, props.color, props.contentScaling, props.gutterBlock, props.noOuterShadow, props.selectedOutline, props.toolbarColor]);

  return (
    <Box sx={frameSx}>

      {/* header(s) */}
      {(!!props.headerRow || !!props.subHeaderInline) && (
        <Box
          aria-label={isClickableHeader ? 'Click to expand/collapse' : undefined}
          role={isClickableHeader ? 'button' : undefined}
          tabIndex={isClickableHeader ? 0 : undefined}
          onKeyDown={handleKeyDown}
          onClick={props.onHeaderClick}
          onContextMenu={props.onHeaderContext}
          sx={headersBlockSx}
        >
          {props.headerRow && (
            <Box sx={headerRowSx}>
              {props.headerRow}
            </Box>
          )}
          {props.subHeaderInline && (
            <Box sx={subHeaderContainedSx}>
              {props.subHeaderInline}
            </Box>
          )}
        </Box>
      )}

      {/* toolbar */}
      {props.toolbarRow && (
        <Sheet color='primary' variant='soft' sx={toolbarRowSx}>
          {props.toolbarRow}
        </Sheet>
      )}

      {/* contents */}
      {props.children}

    </Box>
  );
}


================================================
FILE: src/modules/blocks/code/useStickyCodeOverlay.tsx
================================================
import * as React from 'react';

interface UseStickyCodeOverlayOptions {
  disabled?: boolean;
  /** Custom data attribute to define scroll boundary (default: 'data-sticky-boundary') */
  boundarySelector?: string;
}

/**
 * Makes overlay elements stick to scroll container top during scroll.
 * Performance-optimized: only runs JavaScript when hovering (when overlays are visible).
 * 
 * ```
 * ScrollContainer [role="scrollable" or custom boundary selector]
 *   └── ... (other content)
 *       └── OverlayBoundary (overlayBoundaryRef - hover events + positioning bounds)
 *           └── OverlayElement (overlayRef - gets sticky positioning)
 * ```
 * 
 * Key insights:
 * - overlayBoundaryRef serves dual purpose: hover detection AND positioning bounds calculation
 * - Scroll listeners only active during hover = zero JavaScript execution when not hovering
 * - Fallback: if overlayBoundaryRef unused, defaults to overlay's parent for hover detection
 * - Finds scroll container via closest() with role="scrollable" or custom boundarySelector
 */
export function useStickyCodeOverlay(options?: UseStickyCodeOverlayOptions) {

  // state passed to the caller
  const overlayRef = React.useRef<HTMLElement>(null);
  const overlayBoundaryRef = React.useRef<HTMLElement>(null);


  React.useEffect(() => {
    if (options?.disabled || !overlayRef.current) return;
    
    // Find the scrolling container using closest() - try custom boundary first, then role='scrollable'
    const boundarySelector = options?.boundarySelector || '[data-sticky-boundary]';
    const scrollContainer = 
      overlayRef.current.closest(boundarySelector) || 
      overlayRef.current.closest('[role="scrollable"]');
    
    if (!scrollContainer) return; // No scroll container found

    // -- Scrolling interception & element positioning while Active --

    // Sticky positioning logic
    const applyStickyPosition = () => {
      if (!overlayRef.current) return;
      
      const codeContainer = overlayRef.current.parentElement;
      if (!codeContainer) return;
      
      const containerRect = codeContainer.getBoundingClientRect();
      const scrollRect = scrollContainer.getBoundingClientRect();
      const stickyThreshold = scrollRect.top + 2; // 2px offset like chat avatars
      
      const shouldBeSticky = 
        containerRect.top < stickyThreshold && 
        containerRect.bottom > stickyThreshold + 44; // 44px minimum visibility
      
      const overlay = overlayRef.current;
      if (shouldBeSticky) {
        overlay.style.position = 'fixed';
        overlay.style.top = `${stickyThreshold}px`;
        overlay.style.right = `${window.innerWidth - containerRect.right}px`;
        overlay.style.zIndex = '1';
      } else if (overlay.style.position === 'fixed') {
        resetToNormalPosition();
      }
    };
    
    const resetToNormalPosition = () => {
      if (!overlayRef.current) return;
      const overlay = overlayRef.current;
      overlay.style.position = '';
      overlay.style.top = '';
      overlay.style.right = '';
      overlay.style.zIndex = '';
    };
    
    const handleScroll = () => requestAnimationFrame(applyStickyPosition);


    // -- Activation/deactivation logic - only when overlay is visible (on hover) --

    const activateStickyBehavior = () => {
      scrollContainer.addEventListener('scroll', handleScroll, { passive: true });
      applyStickyPosition(); // Check initial position
    };
    
    const deactivateStickyBehavior = () => {
      scrollContainer.removeEventListener('scroll', handleScroll);
      resetToNormalPosition();
    };
    
    const boundaryContainer = overlayBoundaryRef.current || overlayRef.current.parentElement;
    if (boundaryContainer) {
      boundaryContainer.addEventListener('mouseenter', activateStickyBehavior);
      boundaryContainer.addEventListener('mouseleave', deactivateStickyBehavior);
    }
    
    return () => {
      if (boundaryContainer) {
        boundaryContainer.removeEventListener('mouseenter', activateStickyBehavior);
        boundaryContainer.removeEventListener('mouseleave', deactivateStickyBehavior);
      }
      // Ensure scroll listener is removed
      scrollContainer.removeEventListener('scroll', handleScroll);
    };
  }, [options?.disabled, options?.boundarySelector]);
  
  return {
    overlayRef,
    overlayBoundaryRef,
  };
}


================================================
FILE: src/modules/blocks/code/code-buttons/openInCodePen.tsx
================================================
import { Brand } from '~/common/app.config';
import { prettyTimestampForFilenames } from '~/common/util/timeUtils';


// CodePen is a web-based HTML, CSS, and JavaScript code editor
const _languages = ['html', 'css', 'javascript', 'json', 'typescript'];

export function isCodePenSupported(language: string | null, isSVG: boolean) {
  return isSVG || (!!language && _languages.includes(language));
}

export function openInCodePen(code: string, language: string) {
  // CodePen has 3 editors: HTML, CSS, JS - we decide here where to put the code
  const hasCSS = language === 'css';
  const hasJS = language ? ['javascript', 'json', 'typescript'].includes(language) : false;
  const hasHTML = !hasCSS && !hasJS; // use HTML as fallback if an unanticipated frontend language is used

  const form = document.createElement('form');
  form.action = 'https://codepen.io/pen/define';
  form.method = 'POST';
  form.target = '_blank';

  const payload = {
    title: `${Brand.Title.Base} Code - ${prettyTimestampForFilenames()}`,
    css: hasCSS ? code : '',
    html: hasHTML ? code : '',
    js: hasJS ? code : '',
    editors: `${hasHTML ? 1 : 0}${hasCSS ? 1 : 0}${hasJS ? 1 : 0}`, // eg '101' for HTML, JS
  };

  const input = document.createElement('input');
  input.type = 'hidden';
  input.name = 'data';
  input.value = JSON.stringify(payload);
  form.appendChild(input);

  document.body.appendChild(form);
  form.submit();
  document.body.removeChild(form);
}



================================================
FILE: src/modules/blocks/code/code-buttons/openInGoogleColab.tsx
================================================
import { copyToClipboard } from '~/common/util/clipboardUtils';


export function isGoogleColabSupported(language: string | null) {
  return !!language && language === 'python';
}


export function openInGoogleColab(code: string) {
  // Copy the code to the clipboard
  copyToClipboard(code, 'Python code');

  // Open a new Google Colab notebook
  window.open('https://colab.research.google.com/#create=true', '_blank');
}



================================================
FILE: src/modules/blocks/code/code-buttons/openInJsFiddle.tsx
================================================
// JSFiddle is a web-based HTML, CSS, and JavaScript code editor
const _languages = ['html', 'css', 'javascript', 'json', 'typescript'];

export function isJSFiddleSupported(language: string | null, code: string) {
  return !!language && _languages.includes(language) && code?.length > 10;
}

export function openInJsFiddle(code: string, language: string) {
  // heuristics to build the request
  const isHTML = language === 'html';
  const isCSS = language === 'css';
  const isJSorUnknown = !isHTML && !isCSS;

  const form = document.createElement('form');
  form.action = 'https://jsfiddle.net/api/post/library/pure/';
  form.method = 'POST';
  form.target = '_blank'; // Open in a new tab

  // Dynamically determine what to populate based on language or content type
  const inputHtml = document.createElement('input');
  inputHtml.type = 'hidden';
  inputHtml.name = 'html'; // For HTML content
  inputHtml.value = isHTML ? code : '';
  form.appendChild(inputHtml);

  const inputCss = document.createElement('input');
  inputCss.type = 'hidden';
  inputCss.name = 'css'; // For CSS content
  inputCss.value = isCSS ? code : '';
  form.appendChild(inputCss);

  const inputJs = document.createElement('input');
  inputJs.type = 'hidden';
  inputJs.name = 'js'; // For JavaScript content
  inputJs.value = isJSorUnknown ? code : '';
  form.appendChild(inputJs);

  document.body.appendChild(form);
  form.submit();
  document.body.removeChild(form);
}



================================================
FILE: src/modules/blocks/code/code-buttons/openInStackBlitz.tsx
================================================
import { Brand } from '~/common/app.config';
import { prettyTimestampForFilenames } from '~/common/util/timeUtils';


const _languages = [
  'typescript',
  'javascript', 'json',
  'html', 'css',
  // 'python',
];

// Mapping of languages to StackBlitz templates
const languageToTemplateMapping: { [language: string]: string } = {
  typescript: 'typescript',
  javascript: 'javascript', json: 'javascript',
  html: 'html', css: 'html',
  // python: 'secret-python', // webcontainers? secret-python? python?
};

// Mapping of languages to their primary file names in StackBlitz
const languageToFileExtensionMapping: { [language: string]: string } = {
  typescript: 'index.ts',
  javascript: 'index.js', json: 'data.json',
  html: 'index.html', css: 'style.css',
  // python: 'main.py',
};


export function isStackBlitzSupported(language: string | null) {
  return !!language && _languages.includes(language);
}

export function openInStackBlitz(code: string, language: string, title?: string) {

  const template = languageToTemplateMapping[language] || 'javascript'; // Fallback to 'javascript'
  const fileName = languageToFileExtensionMapping[language] || 'index.js'; // Fallback to 'index.js'

  const projectDetails = {
    files: { [fileName]: code },
    template: template,
    description: `${Brand.Title.Common} file created on ${prettyTimestampForFilenames()}`,
    title: language == 'python' ? 'Python Starter' : title,
  } as const;

  const form = document.createElement('form');
  form.action = 'https://stackblitz.com/run';
  form.method = 'POST';
  form.target = '_blank';

  const addField = (name: string, value: string) => {
    const input = document.createElement('input');
    input.type = 'hidden';
    input.name = name;
    input.value = value;
    form.appendChild(input);
  };

  Object.keys(projectDetails.files).forEach((filePath) => {
    addField(`project[files][${filePath}]`, projectDetails.files[filePath]);
  });

  addField('project[description]', projectDetails.description);
  addField('project[template]', projectDetails.template);
  !!projectDetails.title && addField('project[title]', projectDetails.title);

  document.body.appendChild(form);
  form.submit();
  document.body.removeChild(form);
}



================================================
FILE: src/modules/blocks/code/code-buttons/useOpenInWebEditors.tsx
================================================
import * as React from 'react';

import { ListItemDecorator, MenuItem } from '@mui/joy';

import { CodePenIcon } from '~/common/components/icons/3rdparty/CodePenIcon';
import { GoogleColabIcon } from '~/common/components/icons/3rdparty/GoogleColabIcon';
import { JSFiddleIcon } from '~/common/components/icons/3rdparty/JSFiddleIcon';
import { StackBlitzIcon } from '~/common/components/icons/3rdparty/StackBlitzIcon';

import { isCodePenSupported, openInCodePen } from './openInCodePen';
import { isGoogleColabSupported, openInGoogleColab } from './openInGoogleColab';
import { isJSFiddleSupported, openInJsFiddle } from './openInJsFiddle';
import { isStackBlitzSupported, openInStackBlitz } from './openInStackBlitz';

const stableNoButtons: React.ReactNode[] = [];

export function useOpenInWebEditors(
  code: string,
  blockTitle: string,
  blockIsPartial: boolean,
  inferredCodeLanguage: string | null,
  isSVGCode: boolean,
) {
  return React.useMemo(() => {
    if (blockIsPartial) return stableNoButtons;

    const mayExternal = code?.indexOf('\n') > 0;
    if (!mayExternal) return stableNoButtons;

    const items: React.ReactNode[] = [];

    const canJSFiddle = isJSFiddleSupported(inferredCodeLanguage, code);
    if (canJSFiddle)
      items.push(
        <MenuItem key='jsfiddle' onClick={() => openInJsFiddle(code, inferredCodeLanguage!)}>
          <ListItemDecorator>
            <JSFiddleIcon />
          </ListItemDecorator>
          JSFiddle
        </MenuItem>,
      );

    const canCodePen = isCodePenSupported(inferredCodeLanguage, isSVGCode);
    if (canCodePen)
      items.push(
        <MenuItem key='codepen' onClick={() => openInCodePen(code, inferredCodeLanguage!)}>
          <ListItemDecorator>
            <CodePenIcon />
          </ListItemDecorator>
          CodePen
        </MenuItem>,
      );

    const canStackBlitz = isStackBlitzSupported(inferredCodeLanguage);
    if (canStackBlitz)
      items.push(
        <MenuItem key='stackblitz' onClick={() => openInStackBlitz(code, inferredCodeLanguage!, blockTitle)}>
          <ListItemDecorator>
            <StackBlitzIcon />
          </ListItemDecorator>
          StackBlitz
        </MenuItem>,
      );

    const canGoogleColab = isGoogleColabSupported(inferredCodeLanguage);
    if (canGoogleColab)
      items.push(
        <MenuItem key='googlecolab' onClick={() => openInGoogleColab(code)}>
          <ListItemDecorator>
            <GoogleColabIcon />
          </ListItemDecorator>
          Copy &amp; Paste in Colab
        </MenuItem>,
      );

    return items?.length > 0 ? items : stableNoButtons;
  }, [code, blockIsPartial, blockTitle, inferredCodeLanguage, isSVGCode]);
}



================================================
FILE: src/modules/blocks/code/code-highlight/codePrism.ts
================================================
import Prism from 'prismjs';

// per-language JS plugins
import 'prismjs/components/prism-bash';
import 'prismjs/components/prism-css';
import 'prismjs/components/prism-java';
import 'prismjs/components/prism-javascript';
import 'prismjs/components/prism-json';
import 'prismjs/components/prism-markdown';
import 'prismjs/components/prism-mermaid';
import 'prismjs/components/prism-plant-uml';
import 'prismjs/components/prism-python';
import 'prismjs/components/prism-sql';
import 'prismjs/components/prism-typescript';

// NOTE: must match Prism components imports
const hPrismLanguages = ['bash', 'css', 'java', 'javascript', 'json', 'markdown', 'mermaid', 'plant-uml', 'python', 'sql', 'typescript'];

const hFileExtensionsMap: { [key: string]: string } = {
  bash: 'bash', cs: 'csharp', html: 'html', java: 'java', js: 'javascript', json: 'json', jsx: 'javascript',
  md: 'markdown', mmd: 'mermaid', py: 'python', sh: 'bash', sql: 'sql', ts: 'typescript', tsx: 'typescript', xml: 'xml',
};

const hCodeIncipitMap: { starts: string[], language: string }[] = [
  { starts: ['<!DOCTYPE html', '<html'], language: 'html' },
  { starts: ['<'], language: 'xml' },
  { starts: ['from '], language: 'python' },
  { starts: ['import ', 'export '], language: 'typescript' }, // or python
  { starts: ['interface ', 'function '], language: 'typescript' }, // ambiguous
  { starts: ['package '], language: 'java' },
  { starts: ['using '], language: 'csharp' },
  { starts: ['#!/bin/'], language: 'bash' },
  { starts: ['@startuml', '@startmindmap', '@startsalt', '@startwbs', '@startgantt'], language: 'plant-uml' },
];


export function inferCodeLanguage(blockTitle: string, code: string): string | null {

  // if we have a block title, use it to infer the language
  if (blockTitle) {

    // single word: assume it's the syntax highlight language
    if (!blockTitle.includes('.'))
      return hFileExtensionsMap.hasOwnProperty(blockTitle) ? hFileExtensionsMap[blockTitle] : blockTitle;

    // file extension: map back to a language
    const extension = blockTitle.split('.').pop();
    if (extension && hFileExtensionsMap.hasOwnProperty(extension))
      return hFileExtensionsMap[extension];
  }

  // or, based on the first line of code, return the language
  for (const codeIncipit of hCodeIncipitMap)
    if (codeIncipit.starts.some((start) => code.startsWith(start)))
      return codeIncipit.language;

  // or, use Prism with language tokenization to and-detect the language
  // FIXME: this is a very poor way to detect the language, as it's tokenizing it in any language
  //        and getting the one with the most tokens - which may as well be the wrong one
  let detectedLanguage: string | null = null;
  let maxTokens = 0;
  hPrismLanguages.forEach((language) => {
    const grammar = Prism.languages[language];
    // Load the specified language if it's not loaded yet
    // NOTE: this is commented out because it inflates the size of the bundle by 200k
    // if (!Prism.languages[language]) {
    //   try {
    //     require(`prismjs/components/prism-${language}`);
    //   } catch (e) {
    //     console.warn(`Prism language '${language}' not found, falling back to 'typescript'`);
    //   }
    // }
    const tokens = Prism.tokenize(code, grammar);
    const tokenCount = tokens.filter((token) => typeof token !== 'string').length;
    if (tokenCount > maxTokens) {
      maxTokens = tokenCount;
      detectedLanguage = language;
    }
  });
  return detectedLanguage;
}

export function highlightCode(inferredCodeLanguage: string | null, blockCode: string, addLineNumbers: boolean): string {
  // NOTE: to save power, we could skip highlighting until the block is complete (future feature)
  const safeHighlightLanguage = inferredCodeLanguage || 'typescript';
  const code = Prism.highlight(
    blockCode,
    Prism.languages[safeHighlightLanguage] || Prism.languages.typescript,
    safeHighlightLanguage,
  );
  // add line numbers to the code block
  if (addLineNumbers) {
    // https://stackoverflow.com/questions/59508413/static-html-generation-with-prismjs-how-to-enable-line-numbers
    const linesMatcher = code.match(/\n(?!$)/g);
    const linesCount = linesMatcher ? linesMatcher.length + 1 : 1;
    const linesSpans = new Array(linesCount + 1).join('<span></span>');
    return code + `<span aria-hidden='true' class='line-numbers-rows'>${linesSpans}</span>`;
  }
  return code;
}


================================================
FILE: src/modules/blocks/code/code-renderers/plantuml.utils.ts
================================================
// Check if CompressionStream is supported in this browser
//const hasCompressionStream = typeof CompressionStream !== 'undefined';

export async function encodeWithCompressionStream(text: string): Promise<string> {

  // string -> Uint8Array
  const inputData = new TextEncoder().encode(text);

  // deflate compression, without header
  const compressedStream = new ReadableStream({
    start(controller) {
      controller.enqueue(inputData);
      controller.close();
    },
  }).pipeThrough(new CompressionStream('deflate-raw'));

  // read compressed chunks
  const reader = compressedStream.getReader();
  const chunks: Uint8Array[] = [];
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    chunks.push(value);
  }

  // combine compressed chunks
  const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
  const compressed = new Uint8Array(totalLength);
  let offset = 0;
  for (const chunk of chunks) {
    compressed.set(chunk, offset);
    offset += chunk.length;
  }

  // custom base64~like PlantUML encoding
  return plantUmlEncode64(compressed);
}


function plantUmlEncode64(data: Uint8Array): string {
  let result = '';
  for (let i = 0; i < data.length; i += 3) {
    if (i + 2 === data.length) {
      result += append3bytes(data[i], data[i + 1], 0);
    } else if (i + 1 === data.length) {
      result += append3bytes(data[i], 0, 0);
    } else {
      result += append3bytes(data[i], data[i + 1], data[i + 2]);
    }
  }
  return result;
}

function append3bytes(b1: number, b2: number, b3: number): string {
  const c1 = b1 >> 2;
  const c2 = ((b1 & 0x3) << 4) | (b2 >> 4);
  const c3 = ((b2 & 0xF) << 2) | (b3 >> 6);
  const c4 = b3 & 0x3F;
  return encode6bit(c1 & 0x3F) + encode6bit(c2 & 0x3F) +
    encode6bit(c3 & 0x3F) + encode6bit(c4 & 0x3F);
}

function encode6bit(b: number): string {
  if (b < 10) return String.fromCharCode(48 + b); // 0-9
  b -= 10;
  if (b < 26) return String.fromCharCode(65 + b); // A-Z
  b -= 26;
  if (b < 26) return String.fromCharCode(97 + b); // a-z
  b -= 26;
  return b === 0 ? '-' : b === 1 ? '_' : '?';
}

// Fallback for browsers without CompressionStream
// function hexEncode(text: string): string {
//   let hex = '~h';
//   for (let i = 0; i < text.length; i++) {
//     const charCode = text.charCodeAt(i);
//     hex += (charCode < 16 ? '0' : '') + charCode.toString(16);
//   }
//   return hex;
// }



================================================
FILE: src/modules/blocks/code/code-renderers/RenderCodeHtmlIFrame.tsx
================================================
import * as React from 'react';


const simpleCssReset = `
*, *::before, *::after { box-sizing: border-box; }
body, html { margin: 0; padding: 0; }
body { min-height: 100vh; line-height: 1.5; -webkit-font-smoothing: antialiased; }
img, picture, svg, video { display: block;max-width: 100%; }
`;

export const blocksRenderHTMLIFrameCss: React.CSSProperties = {
  flexGrow: 1,
  width: '100%',
  height: '54svh',
  border: 'none',
  boxSizing: 'border-box',
  maxWidth: '100%',
  maxHeight: '100%',
} as const;

const blocksRenderHTMLIFrameFullScreenCss: React.CSSProperties = {
  ...blocksRenderHTMLIFrameCss,
  height: undefined,
  flex: 1,
} as const;


function _renderHtmlInIFrame(iframeDoc: Document, htmlString: string) {
  // Note: not using this for now (2024-06-15), or it would remove the JS code
  // which is what makes the HTML interactive.
  // Sanitize the HTML string to remove any potentially harmful content
  // const sanitizedHtml = DOMPurify.sanitize(props.htmlString);

  // Inject the CSS reset
  const modifiedHtml = htmlString.replace(/<style/i, `<style>${simpleCssReset}</style><style`);

  // Write the HTML to the iframe
  iframeDoc.open();
  try {
    iframeDoc.write(modifiedHtml);
  } catch (error) {
    console.error('Error writing to iframe:', error);
  }
  iframeDoc.close();

  // Enhanced Security with Content Security Policy
  // NOTE: 2024-06-15 disabled until we understand exactly all the implications
  // In theory we want script from self, images from everywhere, and styles from self
  // const meta = iframeDoc.createElement('meta');
  // meta.httpEquiv = 'Content-Security-Policy';
  // // meta.content = 'default-src \'self\'; script-src \'self\';';
  // meta.content = 'script-src \'self\' \'unsafe-inline\';';
  // iframeDoc.head.appendChild(meta);

  // Adding this event listener to prevent arrow keys from scrolling the parent page
  iframeDoc.addEventListener('keydown', (event: any) => {
    if (['ArrowUp', 'ArrowDown', 'ArrowLeft', 'ArrowRight'].includes(event.key)) {
      event.preventDefault();
    }
  });
}

export function RenderCodeHtmlIFrame(props: { htmlCode: string, isFullscreen?: boolean }) {

  // state
  const iframeRef = React.useRef<HTMLIFrameElement>(null);
  const firstRender = React.useRef(true);

  React.useEffect(() => {
    if (!props.htmlCode)
      return;

    // Immediately render the first time, but delay subsequent renders
    const delay = firstRender.current ? 0 : 200;
    firstRender.current = false;

    // Coalesce the rendering of the HTML content to prevent flickering and work around the React StrictMode
    const timeoutId = setTimeout(() => {
      const iframeDoc = iframeRef.current?.contentWindow?.document;
      iframeDoc && !!props.htmlCode && _renderHtmlInIFrame(iframeDoc, props.htmlCode);
    }, delay);

    return () => clearTimeout(timeoutId);
  }, [props.htmlCode]);

  return (
    <iframe
      ref={iframeRef}
      style={props.isFullscreen ? blocksRenderHTMLIFrameFullScreenCss : blocksRenderHTMLIFrameCss}
      title='Sandboxed Web Content'
      aria-label='Interactive content frame'
      sandbox='allow-scripts allow-same-origin allow-forms' // restrict to only these
      loading='lazy' // do not load until visible in the viewport
    />
  );
}



================================================
FILE: src/modules/blocks/code/code-renderers/RenderCodeMermaid.tsx
================================================
import * as React from 'react';
import { create as createStoreForReactiveGlobals } from 'zustand';
import { useQuery } from '@tanstack/react-query';

import { Box, Typography } from '@mui/joy';

import { isBrowser } from '~/common/util/pwaUtils';
import { themeCodeFontFamilyCss, themeFontFamilyCss } from '~/common/app.theme';

import { diagramErrorSx, diagramSx } from './RenderCodePlantUML';
import { patchSvgString } from './RenderCodeSVG';


/**
 * We are loading Mermaid from the CDN (and spending all the work to dynamically load it
 * and strong type it), because the Mermaid dependencies (npm i mermaid) are too heavy
 * and would slow down development for everyone.
 *
 * If you update this file, also make sure the interfaces/type definitions and initialization
 * options are updated accordingly.
 */
const MERMAID_CDN_FILE: string = 'https://cdn.jsdelivr.net/npm/mermaid@11.4.1/dist/mermaid.min.js';

interface MermaidAPI {
  initialize: (config: any) => void;
  render: (id: string, text: string, svgContainingElement?: Element) => Promise<{ svg: string, bindFunctions?: (element: Element) => void }>;
}

// extend the Window interface, to allow for the mermaid API to be found
declare global {
  // noinspection JSUnusedGlobalSymbols
  interface Window {
    mermaid: MermaidAPI;
  }
}

interface MermaidAPIStore {
  mermaidAPI: MermaidAPI | null,
  loadingError: string | null,
}

const useMermaidStore = createStoreForReactiveGlobals<MermaidAPIStore>()(
  () => ({
    mermaidAPI: null,
    loadingError: null,
  }),
);

let loadingStarted: boolean = false;
let loadingError: string | null = null;


function _loadMermaidFromCDN() {
  if (isBrowser && !loadingStarted) {
    loadingStarted = true;
    const script = document.createElement('script');
    script.src = MERMAID_CDN_FILE;
    script.defer = true;
    script.onload = () => {
      useMermaidStore.setState({
        mermaidAPI: _initializeMermaid(window.mermaid),
        loadingError: null,
      });
    };
    script.onerror = () => {
      useMermaidStore.setState({
        mermaidAPI: null,
        loadingError: `Script load error for ${script.src}`,
      });
    };
    document.head.appendChild(script);
  }
}

/**
 * Pass the current font families at loading time. Note that the font families will be compiled by next to something like this:
 * - code: "'__JetBrains_Mono_dc2b2d', '__JetBrains_Mono_Fallback_dc2b2d', monospace",
 * - text: "'__Inter_1870e5', '__Inter_Fallback_1870e5', Helvetica, Arial, sans-serif"
 */
function _initializeMermaid(mermaidAPI: MermaidAPI): MermaidAPI {
  mermaidAPI.initialize({
    startOnLoad: false,

    // gfx options
    fontFamily: themeCodeFontFamilyCss,
    altFontFamily: themeFontFamilyCss,

    // style configuration
    htmlLabels: true,
    securityLevel: 'loose',
    theme: 'forest',

    // per-chart configuration
    mindmap: { useMaxWidth: false },
    flowchart: { useMaxWidth: false },
    sequence: { useMaxWidth: false },
    timeline: { useMaxWidth: false },
    class: { useMaxWidth: false },
    state: { useMaxWidth: false },
    pie: { useMaxWidth: false },
    er: { useMaxWidth: false },
    gantt: { useMaxWidth: false },
    gitGraph: { useMaxWidth: false },
  });
  return mermaidAPI;
}

function useMermaidLoader() {
  const { mermaidAPI } = useMermaidStore();

  React.useEffect(() => {
    if (!mermaidAPI)
      _loadMermaidFromCDN();
  }, [mermaidAPI]);

  return { mermaidAPI, isSuccess: !!mermaidAPI, hasStartedLoading: loadingStarted, error: loadingError };
}

type MermaidResult =
  | { success: true; svg: string }
  | { success: false; error: string };


export function RenderCodeMermaid(props: { mermaidCode: string, fitScreen: boolean }) {

  // state
  const mermaidContainerRef = React.useRef<HTMLDivElement>(null);

  // external state
  const { mermaidAPI, error: mermaidLoadError } = useMermaidLoader();

  // [effect] re-render on code changes
  const { data } = useQuery<MermaidResult>({
    enabled: !!mermaidAPI && !!props.mermaidCode,
    queryKey: ['mermaid', props.mermaidCode],
    queryFn: async (): Promise<MermaidResult> => {
      try {
        const elementId = `mermaid-${Math.random().toString(36).substring(2, 9)}`;
        const { svg } = await mermaidAPI!.render(elementId, props.mermaidCode, mermaidContainerRef.current!);
        return svg ? { success: true, svg } : { success: false, error: 'No SVG returned.' };
      } catch (error: any) {
        return { success: false, error: error?.message ?? error?.toString() ?? 'unknown error' };
      }
    },
    staleTime: 1000 * 60 * 60 * 24, // 1 day
  });

  // derived
  const hasMermaidLoadError = !!mermaidLoadError;

  return (
    <Box component='div'>
      {data?.success === false && (
        <Typography level='body-sm' color='danger' variant='plain' sx={{ mb: 2, borderRadius: 'xs' }}>
          Unable to display diagram. Issue with the generated Mermaid code.
        </Typography>
      )}
      <Box
        component='div'
        ref={mermaidContainerRef}
        dangerouslySetInnerHTML={{
          __html:
            hasMermaidLoadError ? mermaidLoadError
              : data?.success === false ? data.error
                : patchSvgString(props.fitScreen, data?.svg) || 'Loading Diagram...',
        }}
        sx={data?.success === false ? diagramErrorSx : diagramSx}
      />
    </Box>
  );
}



================================================
FILE: src/modules/blocks/code/code-renderers/RenderCodePlantUML.tsx
================================================
import { useQuery } from '@tanstack/react-query';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Typography } from '@mui/joy';

import { frontendSideFetch } from '~/common/util/clientFetchers';

import { encodeWithCompressionStream } from './plantuml.utils';
import { patchSvgString } from './RenderCodeSVG';
import * as React from 'react';


export function heuristicIsCodePlantUML(code: string) {
  return (code.startsWith('@startuml') && code.endsWith('@enduml'))
    || (code.startsWith('@startmindmap') && code.endsWith('@endmindmap'))
    || (code.startsWith('@startsalt') && code.endsWith('@endsalt'))
    || (code.startsWith('@startwbs') && code.endsWith('@endwbs'))
    || (code.startsWith('@startgantt') && code.endsWith('@endgantt'));
}


export const diagramSx: SxProps = {
  textAlign: 'center',
  mx: 'auto',
  minHeight: 100,
};

export const diagramErrorSx: SxProps = {
  ...diagramSx,
  textAlign: undefined,
  whiteSpace: 'break-spaces',
};


// PlantUML -> SVG fetchers

export function usePlantUmlSvg(enabled: boolean, code: string) {
  return useQuery({
    enabled,
    queryKey: ['plantuml', code],
    queryFn: () => _fetchPlantUmlSvg(code),
    staleTime: 24 * 60 * 60 * 1000, // 1 day
  });
}

export function getPlantUmlServerUrl(): string {
  // set at nextjs build time
  return process.env.NEXT_PUBLIC_PLANTUML_SERVER_URL || 'https://www.plantuml.com/plantuml/svg/';
}

async function _fetchPlantUmlSvg(plantUmlCode: string): Promise<string | null> {
  // Get the PlantUML server from inline env var
  let plantUmlServerUrl = getPlantUmlServerUrl();
  if (!plantUmlServerUrl.endsWith('/'))
    plantUmlServerUrl += '/';

  // fetch the PlantUML SVG
  let text: string = '';
  try {
    // retrieve and manually adapt the SVG, to remove the background
    const encodedPlantUML: string = await encodeWithCompressionStream(plantUmlCode);
    const response = await frontendSideFetch(`${plantUmlServerUrl}${encodedPlantUML}`);
    text = await response.text();
  } catch (error) {
    console.error('Error rendering PlantUML on server:', plantUmlServerUrl, error);
    return null;
  }

  // validate/extract the SVG
  const start = text.indexOf('<svg ');
  const end = text.indexOf('</svg>');
  if (start < 0 || end <= start)
    throw new Error('Could not render PlantUML');

  // remove the background color
  const svg = text
    .slice(start, end + 6) // <svg ... </svg>
    .replace('background:#FFFFFF;', '');

  // check for syntax errors
  if (svg.includes('>Syntax Error?</text>'))
    throw new Error('Syntax issue (it happens).\nPlease regenerate the message using a different language model.');

  return svg;
}


export function RenderCodePlantUML(props: {
  svgCode: string | null;
  error: Error | null;
  fitScreen: boolean;
}) {

  if (props.error && !props.svgCode)
    return (
      <Typography level='body-sm' color='danger' variant='plain' sx={{ mb: 2, borderRadius: 'xs' }}>
        <div>{`Unable to display diagram: ${props.error?.message || props.error?.toString() || 'Unknown error'}`}</div>
      </Typography>
    );

  return (
    <Box
      component='div'
      className='code-container'
      dangerouslySetInnerHTML={{
        __html: patchSvgString(props.fitScreen, props.svgCode) || (props.error ? `PlantUML Error: ${props.error.message}` : 'No PlantUML code'),
      }}
      sx={(!props.svgCode && props.error) ? undefined : diagramSx}
    />
  );
}



================================================
FILE: src/modules/blocks/code/code-renderers/RenderCodeSVG.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';


function _removePotentialComments(code: string): string {
  return code.replace(/^(<!--[^>]*-->)*\s*/i, '');
}

/**
 * Detects whether a string contains valid SVG trimmedCode
 */
export function heuristicIsSVGCode(trimmedCode: string): boolean {

  // quick outs
  if (!trimmedCode.startsWith('<') || !trimmedCode.endsWith('</svg>')) return false;

  // strip HTML comments from the start of the trimmedCode
  const codeWithoutInitialComments = trimmedCode.startsWith('<!--') ? _removePotentialComments(trimmedCode) : trimmedCode;

  // check for standard SVG patterns
  return codeWithoutInitialComments.startsWith('<svg') || codeWithoutInitialComments.startsWith('<?xml version="1.0" encoding="UTF-8"?>\n<svg');
}


export function patchSvgString(fitScreen: boolean, svgCode?: string | null): string | null {
  return fitScreen ? svgCode?.replace('<svg ', `<svg style="width: 100%; height: 100%; object-fit: contain" `) || null : svgCode || null;
}


const svgSx: SxProps = {
  lineHeight: 0,
};

export function RenderCodeSVG(props: {
  svgCode: string;
  fitScreen: boolean;
}) {
  return (
    <Box
      component='div'
      className='code-container'
      dangerouslySetInnerHTML={{
        __html: patchSvgString(props.fitScreen, props.svgCode) || 'No SVG code',
      }}
      sx={svgSx}
    />
  );
}



================================================
FILE: src/modules/blocks/code/code-renderers/RenderCodeSyntax.tsx
================================================
import * as React from 'react';

import { Box } from '@mui/joy';


export function RenderCodeSyntax(props: {
  highlightedSyntaxAsHtml: string | null;
  presenterMode?: boolean;
}) {
  return (
    <Box
      component='span'
      aria-label='Code block'
      className='code-container'
      dangerouslySetInnerHTML={{ __html: props.highlightedSyntaxAsHtml ?? '' }}
      sx={props.presenterMode ? { fontSize: '125%' } : undefined}
    />
  );
}



================================================
FILE: src/modules/blocks/danger-html/RenderDangerousHtml.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, Typography } from '@mui/joy';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import WebIcon from '@mui/icons-material/Web';

import { copyToClipboard } from '~/common/util/clipboardUtils';

import { OverlayButton, overlayButtonsActiveSx, overlayButtonsClassName, overlayButtonsTopRightSx } from '../OverlayButton';
import { RenderCodeHtmlIFrame } from '../code/code-renderers/RenderCodeHtmlIFrame';


// this is used by the blocks parser (for full text detection) and by the Code component (for inline rendering)
export function heuristicIsBlockPureHTML(text: string): boolean {
  return ['<!DOCTYPE html', '<!doctype html', '<head'].some((start) => text.startsWith(start));
}


export function RenderDangerousHtml(props: { html: string, sx?: SxProps }) {

  // state
  const [showHTML, setShowHTML] = React.useState(false);

  // remove the font* properties from sx
  const sx: any = props.sx || {};
  for (const key in sx)
    if (key.startsWith('font'))
      delete sx[key];

  const handleCopyToClipboard = (e: React.MouseEvent) => {
    e.stopPropagation();
    copyToClipboard(props.html, 'HTML');
  };

  return (
    <Box sx={{ position: 'relative' /* for overlay buttons to stick properly */ }}>
      <Box
        sx={{
          minWidth: { sm: '480px', md: '750px', lg: '950px', xl: '1200px' },
          mx: 0,
          p: 1.5, // this block gets a thicker border
          display: 'block',
          overflowX: 'auto',
          [`&:hover > .${overlayButtonsClassName}`]: overlayButtonsActiveSx,
          ...sx,
        }}
      >

        {/* Highlighted Code / SVG render */}
        {showHTML
          ? <RenderCodeHtmlIFrame htmlCode={props.html} />
          : <Box>
            <Typography>
              <b>CAUTION</b> - The content you are about to access is an HTML page. It is possible that an
              unauthorized entity is monitoring this connection and has generated this content.
              Please exercise caution and do not trust the contents blindly. Be aware that proceeding
              may pose potential risks. Click the button to view the content, if you wish to proceed.
            </Typography>
            <Box sx={{ display: 'flex', gap: 1, justifyContent: 'flex-end', mt: 2 }}>
              <Button variant='plain' color='neutral' onClick={() => setShowHTML(false)}>
                Ignore
              </Button>
              <Button variant='solid' color='danger' onClick={() => setShowHTML(true)}>
                Show HTML Page
              </Button>
            </Box>
          </Box>
        }

        {/* [overlay] Buttons (dangerous-HTML) */}
        <Box className={overlayButtonsClassName} sx={overlayButtonsTopRightSx}>

          <OverlayButton tooltip={showHTML ? 'Close HTML Page' : 'Show HTML Page'} variant={showHTML ? 'solid' : 'outlined'} color='danger' smShadow onClick={() => setShowHTML(!showHTML)}>
            <WebIcon />
          </OverlayButton>

          <OverlayButton tooltip='Copy Code' variant='outlined' smShadow onClick={handleCopyToClipboard}>
            <ContentCopyIcon />
          </OverlayButton>

        </Box>

      </Box>
    </Box>
  );
}


================================================
FILE: src/modules/blocks/enhanced-code/codeCollapseManager.ts
================================================
class CodeCollapseManager extends EventTarget {
  private static instance: CodeCollapseManager | null = null;

  private constructor() {
    super();
  }

  static getInstance(): CodeCollapseManager {
    if (!CodeCollapseManager.instance) {
      CodeCollapseManager.instance = new CodeCollapseManager();
    }
    return CodeCollapseManager.instance;
  }

  // called by the menu
  triggerCollapseAll(collapse: boolean) {
    this.dispatchEvent(new CustomEvent('codeCollapseAll', { detail: collapse }));
  }

  // useEffect'd by the EhancedRenderCode component
  addCollapseAllListener(onCodeCollapse: (collapse: boolean) => void) {
    const handleCollapse = (event: Event) => {
      const customEvent = event as CustomEvent<boolean>;
      onCodeCollapse(customEvent.detail);
    };
    this.addEventListener('codeCollapseAll', handleCollapse);
    return () => this.removeEventListener('codeCollapseAll', handleCollapse);
  }

}

export function getCodeCollapseManager(): CodeCollapseManager {
  return CodeCollapseManager.getInstance();
}


================================================
FILE: src/modules/blocks/enhanced-code/EnhancedRenderCode.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, ColorPaletteProp, IconButton, Typography } from '@mui/joy';
import CodeIcon from '@mui/icons-material/Code';
import MoreVertIcon from '@mui/icons-material/MoreVert';

import type { ContentScaling } from '~/common/app.theme';
import { ExpanderControlledBox } from '~/common/components/ExpanderControlledBox';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';

import { EnhancedRenderCodeMenu } from './EnhancedRenderCodeMenu';
import { RenderCodeMemo } from '../code/RenderCode';
import { enhancedCodePanelTitleTooltipSx, RenderCodePanelFrame } from '../code/RenderCodePanelFrame';
import { getCodeCollapseManager } from './codeCollapseManager';
import { useLiveFilePatch } from './livefile-patch/useLiveFilePatch';


export function EnhancedRenderCode(props: {
  semiStableId: string | undefined,

  title: string,
  code: string,
  isPartial: boolean,

  fitScreen: boolean,
  isMobile: boolean,
  initialShowHTML?: boolean,
  noCopyButton?: boolean,
  optimizeLightweight?: boolean,

  codeSx?: SxProps,

  language?: string,
  color?: ColorPaletteProp;
  contentScaling: ContentScaling;
  initialIsCollapsed: boolean;

  // onLiveFileCreate?: () => void,
  onReplaceInCode?: (search: string, replace: string) => boolean;
}) {

  // state
  const [contextMenuAnchor, setContextMenuAnchor] = React.useState<HTMLElement | null>(null);
  const [isCodeCollapsed, setIsCodeCollapsed] = React.useState(props.initialIsCollapsed);

  // LiveFile - patch state
  const { button: liveFileButton, actionBar: liveFileActionBar } = useLiveFilePatch(
    props.title, props.code, props.isPartial,
    props.isMobile,
  );


  // React to changes in the collapsed state. Note that by default, nothing is collapsed
  React.useEffect(() => {
    setIsCodeCollapsed(props.initialIsCollapsed);
  }, [props.initialIsCollapsed]);


  // handlers

  const handleCloseContextMenu = React.useCallback(() => setContextMenuAnchor(null), []);

  const handleToggleCodeCollapse = React.useCallback(() => {
    setIsCodeCollapsed(c => !c);
    handleCloseContextMenu();
  }, [handleCloseContextMenu]);

  const handleToggleContextMenu = React.useCallback((event: React.MouseEvent<HTMLElement>) => {
    event.preventDefault(); // added for the Right mouse click (to prevent the menu)

    // NOTE: disabled because a click here won't close other menus (won't trigger other component's ClickAwayListeners)
    // event.stopPropagation();

    setContextMenuAnchor(anchor => anchor ? null : event.currentTarget);
  }, []);


  // effects
  React.useEffect(() => {
    return getCodeCollapseManager().addCollapseAllListener((collapseAll: boolean) => {
      setIsCodeCollapsed(collapseAll);
      handleCloseContextMenu();
    });
  }, [handleCloseContextMenu]);


  // components

  const headerTooltipContents = React.useMemo(() => (
    <Box sx={enhancedCodePanelTitleTooltipSx}>
      {/* This is what we have */}
      <div><strong>Code Block</strong></div>
      <div></div>
      <div>{props.isPartial ? 'Partial ' : 'Complete'}</div>
      <div></div>
      <div>Title</div>
      <div>{props.title || '(empty)'}</div>
      <div>Version</div>
      <div>{/* TODO props.version ||*/ '(none)'}</div>
      {/*<div>Language</div>*/}
      {/*<div>{props.language}</div>*/}
      <div>Code Lines</div>
      <div>{props.code.split('\n').length} lines</div>
      <div>Characters</div>
      <div>{props.code.length}</div>
      <div>tempId</div>
      <div><small>{props.semiStableId || '(none)'}</small></div>
      {/* This is what attachments carry */}
      {/*<div>Attachment Title</div>*/}
      {/*<div>{fragment.title}</div>*/}
      {/*<div>Doc Title</div>*/}
      {/*<div>{fragmentDocPart.l1Title}</div>*/}
      {/*<div>Identifier</div>*/}
      {/*<div>{fragmentDocPart.ref}</div>*/}
      {/*<div>Render type</div>*/}
      {/*<div>{fragmentDocPart.vdt}</div>*/}
      {/*<div>Text Mime type</div>*/}
      {/*<div>{fragmentDocPart.data?.mimeType || '(unknown)'}</div>*/}
      {/*<div>Text Buffer Id</div>*/}
      {/*<div>{fragmentId}</div>*/}
    </Box>
  ), [props.code, props.isPartial, props.semiStableId, props.title]);

  const headerRow = React.useMemo(() => {
    const Icon = CodeIcon;
    return <>
      {/* Icon and Title */}
      <TooltipOutlined placement='top-start' color='neutral' title={headerTooltipContents}>
        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, overflow: 'hidden' }}>
          <Icon
            aria-hidden
            onClick={handleToggleCodeCollapse}
            sx={{
              transform: isCodeCollapsed ? 'rotate(-90deg)' : 'none',
              transition: 'transform 0.2s cubic-bezier(.17,.84,.44,1)',
              cursor: 'pointer',
            }}
          />
          <Typography level={'title-sm'} className='agi-ellipsize'>
            {props.title || 'Code'}
          </Typography>
        </Box>
      </TooltipOutlined>

      {/* LiveFile - Select */}
      {liveFileButton}

      {/* Menu Options button */}
      <IconButton
        size='sm'
        onClick={handleToggleContextMenu}
        // onContextMenu={handleToggleContextMenu} // NOTE: disabled because onContextMenu prevents */ClickAwayListeners
        sx={{ mr: -0.5 }}
      >
        <MoreVertIcon />
      </IconButton>

    </>;
  }, [handleToggleCodeCollapse, handleToggleContextMenu, headerTooltipContents, isCodeCollapsed, liveFileButton, props.title]);

  // const toolbarRow = React.useMemo(() => <>
  //   {props.onLiveFileCreate && (
  //     <Button
  //       size='sm'
  //       variant='outlined'
  //       color='neutral'
  //       startDecorator={<LiveHelpIcon />}
  //       onClick={props.onLiveFileCreate}
  //     >
  //       Create Live File
  //     </Button>
  //   )}
  //   {/* Add more toolbar items here */}
  // </>, [props.onLiveFileCreate]);


  // styles

  const patchCodeSx = React.useMemo(() => ({
    ...props.codeSx,
    my: 0,
    borderTop: '1px solid',
    borderTopColor: `neutral.outlinedBorder`,
    borderTopLeftRadius: 0,
    borderTopRightRadius: 0,
  }), [props.codeSx]);


  return (
    <RenderCodePanelFrame
      color={props.color || 'neutral'}
      gutterBlock
      noOuterShadow
      contentScaling={props.contentScaling}
      headerRow={headerRow}
      subHeaderInline={liveFileActionBar}
      onHeaderClick={/*props.isMobile ? handleToggleCodeCollapse :*/ undefined}
      // onHeaderContext={handleToggleContextMenu} // disabled because ERC got larger, and this will intercept it all
    >

      {/* Body of the message (it's a RenderCode with patched sx, for looks) */}
      <ExpanderControlledBox expanded={!isCodeCollapsed}>
        <RenderCodeMemo
          semiStableId={props.semiStableId}
          code={props.code} title={props.title} isPartial={props.isPartial}
          fitScreen={props.fitScreen}
          initialShowHTML={props.initialShowHTML}
          noCopyButton={props.noCopyButton}
          optimizeLightweight={props.optimizeLightweight}
          onReplaceInCode={props.onReplaceInCode}
          renderHideTitle={true /* because we show it already, outside */}
          sx={patchCodeSx}
        />
      </ExpanderControlledBox>

      {/* Context Menu */}
      {contextMenuAnchor && (
        <EnhancedRenderCodeMenu
          anchor={contextMenuAnchor}
          code={props.code} title={props.title}
          onClose={handleCloseContextMenu}
          isCollapsed={isCodeCollapsed}
          onToggleCollapse={handleToggleCodeCollapse}
        />
      )}

    </RenderCodePanelFrame>
  );
}


================================================
FILE: src/modules/blocks/enhanced-code/EnhancedRenderCodeMenu.tsx
================================================
import * as React from 'react';
import { fileSave } from 'browser-fs-access';
import { useShallow } from 'zustand/react/shallow';

import { Box, ListDivider, ListItemDecorator, MenuItem } from '@mui/joy';
import CheckRoundedIcon from '@mui/icons-material/CheckRounded';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import UnfoldLessIcon from '@mui/icons-material/UnfoldLess';
import UnfoldMoreIcon from '@mui/icons-material/UnfoldMore';
import SaveAsOutlinedIcon from '@mui/icons-material/SaveAsOutlined';

import { CloseablePopup } from '~/common/components/CloseablePopup';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { isLiveFileSupported } from '~/common/livefile/store-live-file';
import { reverseLookupMdTitle, reverseLookupMimeType } from '~/common/attachment-drafts/attachment.mimetypes';
import { useUXLabsStore } from '~/common/stores/store-ux-labs';

import { getCodeCollapseManager } from './codeCollapseManager';


/**
 * Small hidden context menu to toggle the code enhancer, globally.
 */
export function EnhancedRenderCodeMenu(props: {
  anchor: HTMLElement,
  title: string,
  code: string,
  onClose: () => void,
  isCollapsed: boolean,
  onToggleCollapse: () => void,
}) {

  // state
  // const { showPromisedOverlay } = useOverlayComponents();
  // const labsDevMode = useLabsDevMode();
  const { labsEnhanceCodeLiveFile, setLabsEnhanceCodeLiveFile } = useUXLabsStore(useShallow(state => ({
    // labsEnhanceCodeBlocks: state.labsEnhanceCodeBlocks,
    // setLabsEnhanceCodeBlocks: state.setLabsEnhanceCodeBlocks,
    labsEnhanceCodeLiveFile: state.labsEnhanceCodeLiveFile,
    setLabsEnhanceCodeLiveFile: state.setLabsEnhanceCodeLiveFile,
  })));


  // handlers

  const handleCollapseAllCodeBlocks = React.useCallback(() => {
    getCodeCollapseManager().triggerCollapseAll(true);
  }, []);

  const handleExpandAllCodeBlocks = React.useCallback(() => {
    getCodeCollapseManager().triggerCollapseAll(false);
  }, []);

  const { onClose } = props;

  const handleCopyToClipboard = React.useCallback(() => {
    copyToClipboard(props.code, 'Code');
  }, [props.code]);

  const handleSaveAs = React.useCallback(async () => {
    // guess the mimetype from the markdown title
    let mimeType = 'text/plain';
    let extension = '';
    const hasExtension = props.title.includes('.');
    if (hasExtension) {
      extension = props.title.split('.').pop()!;
      mimeType = reverseLookupMimeType(extension) || 'text/plain';
    } else {
      const data = reverseLookupMdTitle(props.title);
      if (data?.extension)
        extension = data.extension;
      if (data?.mimeType)
        mimeType = data.mimeType;
    }

    // content to be saved
    const blob = new Blob([props.code], { type: mimeType });

    // save content
    await fileSave(blob, {
      fileName: props.title || undefined,
      extensions: extension ? [`.${extension}`] : undefined,
      mimeTypes: mimeType ? [mimeType] : undefined,
    }).then(() => onClose())
      .catch(() => null);
  }, [onClose, props.code, props.title]);

  // const toggleEnhanceCodeBlocks = React.useCallback(() => {
  //   // turn blocks on (may not even be called, ever)
  //   if (!labsEnhanceCodeBlocks) {
  //     setLabsEnhanceCodeBlocks(true);
  //     return;
  //   }
  //   // ask to turn the blocks off
  //   showPromisedOverlay('blocks-off-enhance-code', {}, ({ onResolve, onUserReject }) =>
  //     <ConfirmationModal
  //       open onClose={onUserReject} onPositive={() => onResolve(true)}
  //       title='Turn off enhanced code blocks?'
  //       confirmationText='This will disable LiveFile functionality. You can turn it back on anytime by going to Settings > Labs > Enhance Legacy Code.'
  //       positiveActionText='Turn Off'
  //     />,
  //   ).then(() => setLabsEnhanceCodeBlocks(false)).catch(() => null /* ignore closure */);
  // }, [labsEnhanceCodeBlocks, setLabsEnhanceCodeBlocks, showPromisedOverlay]);

  const toggleEnhanceCodeLiveFile = React.useCallback(() => {
    setLabsEnhanceCodeLiveFile(!labsEnhanceCodeLiveFile);
  }, [labsEnhanceCodeLiveFile, setLabsEnhanceCodeLiveFile]);

  const liveFileSupported = isLiveFileSupported();


  return (
    <CloseablePopup
      menu anchorEl={props.anchor} onClose={props.onClose}
      dense
      minWidth={250}
      placement='bottom-end'
    >

      <Box sx={{ display: 'flex', alignItems: 'center' }}>
        <MenuItem onClick={props.onToggleCollapse} sx={{ flex: 0.6 }}>
          <ListItemDecorator>{props.isCollapsed ? <UnfoldMoreIcon /> : <UnfoldLessIcon />}</ListItemDecorator>
          {props.isCollapsed ? 'Expand' : 'Collapse'}
        </MenuItem>
        <MenuItem onClick={props.isCollapsed ? handleExpandAllCodeBlocks : handleCollapseAllCodeBlocks} sx={{ justifyContent: 'center', flex: 0.4 }}>
          <ListItemDecorator>{props.isCollapsed ? <UnfoldMoreIcon /> : <UnfoldLessIcon />}</ListItemDecorator>
          All
        </MenuItem>
      </Box>

      <ListDivider />

      <MenuItem onClick={handleCopyToClipboard}>
        <ListItemDecorator><ContentCopyIcon /></ListItemDecorator>
        Copy
      </MenuItem>

      <MenuItem onClick={handleSaveAs}>
        <ListItemDecorator><SaveAsOutlinedIcon /></ListItemDecorator>
        Save As ...
      </MenuItem>

      <ListDivider />

      <MenuItem onClick={toggleEnhanceCodeLiveFile} disabled={!liveFileSupported}>
        <ListItemDecorator>{(labsEnhanceCodeLiveFile && liveFileSupported) && <CheckRoundedIcon />}</ListItemDecorator>
        {liveFileSupported ? 'LiveFile Patch' : 'LiveFile - No Browser Support'}
      </MenuItem>

      {/*{labsDevMode && (*/}
      {/*  // A mix in between UxLabsSettings (labsEnhanceCodeBlocks) and the ChatDrawer MenuItems*/}
      {/*  <MenuItem onClick={toggleEnhanceCodeBlocks}>*/}
      {/*    <ListItemDecorator>{labsEnhanceCodeBlocks && <CheckRoundedIcon />}</ListItemDecorator>*/}
      {/*    [DEV] Enhanced Code Blocks*/}
      {/*  </MenuItem>*/}
      {/*)}*/}

    </CloseablePopup>
  );
}


================================================
FILE: src/modules/blocks/enhanced-code/livefile-patch/useLiveFilePatch.tsx
================================================
import * as React from 'react';
import { fileOpen } from 'browser-fs-access';
import { Box, Button, ColorPaletteProp, Sheet } from '@mui/joy';

import { useUXLabsStore } from '~/common/stores/store-ux-labs';

// Workspace
import type { DWorkspaceId } from '~/common/stores/workspace/workspace.types';
import { WorkspaceLiveFilePicker } from '~/common/stores/workspace/WorkspaceLiveFilePicker';
import { workspaceActions } from '~/common/stores/workspace/store-client-workspace';

// LiveFile
import type { LiveFileId } from '~/common/livefile/liveFile.types';
import { isLiveFileSupported, liveFileCreateOrThrow } from '~/common/livefile/store-live-file';
import { liveFileSheetSx } from '~/common/livefile/livefile.theme';
import { usePatchingWorkflow } from '~/modules/blocks/enhanced-code/livefile-patch/usePatchingWorkflow';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';


export function useLiveFilePatch(title: string, code: string, isPartial: boolean, isMobile: boolean) {

  /**
   * state - Warning: very local.
   * This will get wiped just on a component remount - so it's just a temporary solution.
   */
  const [liveFileId, setLiveFileId] = React.useState<LiveFileId | null>(null);

  // external state
  const isEnabled = useUXLabsStore((state) => state.labsEnhanceCodeLiveFile && isLiveFileSupported());


  const { status, patchState, targetOverwriteWithPatch } = usePatchingWorkflow(liveFileId, code);

  // const processLiveFile = React.useCallback(async (fileId: LiveFileId) => {
  //   // reset state
  //   // setStatus({ message: 'Processing...', mtype: 'info' });
  //   // setPatchState({ srcContent: null, patchContent: null, newContent: null });
  //
  //   try {
  //
  //     // Step 1: Load the latest version of the file
  //     const srcContent = await targetReloadFromDisk();
  //     if (!srcContent)
  //       return;
  //
  //     // Step 2: Generate patch
  //     const patchContent = await targetGeneratePatch(srcContent, code);
  //     if (!patchContent)
  //       return;
  //
  //     // Step 3: Apply patch and check if it succeeds
  //     await targetApplyPatch(srcContent, patchContent);
  //
  //     // Step 4: Success - user can decide to proceed
  //     // setStatus({ message: 'Patch generated and applied successfully. Ready to save.', mtype: 'success' });
  //
  //   } catch (error) {
  //     // setStatus({
  //     //   message: `Error: ${error instanceof Error ? error.message : 'An unknown error occurred'}`,
  //     //   mtype: 'error',
  //     // });
  //   }
  // }, [code, targetApplyPatch, targetGeneratePatch, targetReloadFromDisk]);

  // const handleSavePatch = React.useCallback(async () => {
  //   if (!liveFileId || !patchState.newContent) return;
  //
  //   setStatus({ message: 'Saving changes to file...', mtype: 'info' });
  //   try {
  //     const writeSuccess = await contentWriteAndReload(liveFileId, patchState.newContent);
  //     if (!writeSuccess) {
  //       throw new Error('Failed to write to file');
  //     }
  //     setStatus({ message: 'Changes saved successfully.', mtype: 'success' });
  //   } catch (error) {
  //     setStatus({
  //       message: `Error saving changes: ${error instanceof Error ? error.message : 'An unknown error occurred'}`,
  //       mtype: 'error',
  //     });
  //   }
  // }, [liveFileId, patchState.newContent, contentWriteAndReload]);

  const handleSelectLiveFile = React.useCallback(async (id: LiveFileId | null) => {
    setLiveFileId(id);
    // if (id) {
    //   await processLiveFile(id);
    // }
  }, []);

  const handleSelectFileSystemFileHandle = React.useCallback(async (workspaceId: DWorkspaceId | null, fsfHandle: FileSystemFileHandle) => {
    try {
      const newId = await liveFileCreateOrThrow(fsfHandle);
      setLiveFileId(newId);

      // Attach it to the workspace
      if (workspaceId)
        workspaceActions().liveFileAssign(workspaceId, newId);
      else
        console.warn('[DEV] No workspaceId to pair the file with.');

      // proceed
      // await processLiveFile(newId);
    } catch (error) {
      console.error('Error creating new file:', error);
      // setStatus({
      //   message: `Error pairing the file: ${error instanceof Error ? error.message : 'Unknown error'}`,
      //   mtype: 'error',
      // });
    }
  }, []);

  const handleSelectFilePicker = React.useCallback(async (workspaceId: DWorkspaceId | null) => {
    // pick a file
    const fileWithHandle = await fileOpen({ description: 'Link file...' }).catch(() => null /* The User closed the files picker */);
    if (!fileWithHandle)
      return;
    const fileSystemFileHandle = fileWithHandle.handle;
    if (!fileSystemFileHandle) {
      // setStatus({
      //   message: `Browser does not support LiveFile operations. ${isLiveFileSupported() ? 'No filesystem handles.' : ''}`,
      //   mtype: 'error',
      // });
      return;
    }
    // proceed
    await handleSelectFileSystemFileHandle(workspaceId, fileSystemFileHandle);
  }, [handleSelectFileSystemFileHandle]);


  // components

  const button = React.useMemo(() => !isEnabled ? null : (
    <Box sx={{ ml: 'auto' }}>
      <WorkspaceLiveFilePicker
        allowRemove
        autoSelectName={title}
        labelButton='Apply ...'
        labelTooltip='Apply this change to your file'
        liveFileId={liveFileId}
        onSelectFileOpen={handleSelectFilePicker}
        onSelectFileSystemFileHandle={handleSelectFileSystemFileHandle}
        onSelectLiveFile={handleSelectLiveFile}
      />
    </Box>
  ), [handleSelectLiveFile, handleSelectFilePicker, handleSelectFileSystemFileHandle, isEnabled, liveFileId, title]);

  const actionBar = React.useMemo(() => {

    if (!isEnabled || !liveFileId || !status)
      return null;

    const isError = status?.mtype === 'error';

    const statusColor: ColorPaletteProp =
      isError ? 'warning'
        : status?.mtype === 'success' ? 'neutral'
          : 'neutral';

    return (
      <Sheet color={statusColor} sx={liveFileSheetSx}>

        {status.message}

        {/*<Chip variant='soft' color='primary'>*/}
        {/*  loaded*/}
        {/*</Chip>*/}

        {/*<Chip variant='solid' color='primary'>*/}
        {/*  applying ...*/}
        {/*</Chip>*/}

        {/*<Button*/}
        {/*  variant='soft'*/}
        {/*  color='primary'*/}
        {/*  size='sm'*/}
        {/*  // disabled={isLoadingFile /* commented to not make this flash *!/*/}
        {/*  // onClick={handleLoadFromDisk}*/}
        {/*  // aria-label='Load content from disk'*/}
        {/*>*/}
        {/*  loaded*/}
        {/*</Button>*/}


        {status.mtype === 'success' && patchState.newContent && (
          <Box sx={{ display: 'flex', gap: 1 }}>

            <Button
              color='success'
              size='sm'
              variant='outlined'
              onClick={targetOverwriteWithPatch}
              sx={{
                // backgroundColor: 'red', // doesn't show?
                boxShadow: 'xs',
              }}
            >
              Overwrite File
            </Button>

            <TooltipOutlined title='Not yet available'>
              <Button
                disabled
                color='neutral'
                variant='soft'
                size='sm'
              >
                Patch File
              </Button>
            </TooltipOutlined>

            {/*<Button onClick={() => processLiveFile(liveFileId)} color='neutral' size='sm'>*/}
            {/*  Regenerate Patch*/}
            {/*</Button>*/}

          </Box>
        )}

      </Sheet>
    );
  }, [isEnabled, liveFileId, patchState.newContent, status, targetOverwriteWithPatch]);

  return {
    button,
    actionBar,
  };
}



================================================
FILE: src/modules/blocks/enhanced-code/livefile-patch/usePatchingWorkflow.tsx
================================================
import * as React from 'react';

import type { LiveFileId } from '~/common/livefile/liveFile.types';
import { useLiveFileStore } from '~/common/livefile/store-live-file';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';


interface FileOperationStatus {
  message: React.ReactNode;
  mtype: 'info' | 'success' | 'error';

}

interface PatchState {
  srcContent: string | null;
  patchContent: string | null;
  newContent: string | null;
}


// Helper function to apply patch (to be implemented)
function applyPatch(srcContent: string, patch: string): string {
  // Implement patch application logic
  // FIXME: this just overwrites, LOL
  return patch;
}


export function usePatchingWorkflow(targetLiveFileId: LiveFileId | null, textBuffer: string) {

  // local status
  const { showPromisedOverlay } = useOverlayComponents();
  const [status, setStatus] = React.useState<FileOperationStatus | null>(null);
  const [patchState, setPatchState] = React.useState<PatchState>({ srcContent: null, patchContent: null, newContent: null });


  const isError = status?.mtype === 'error';
  const canLoad = !!targetLiveFileId;
  const canGenerate = !!patchState.srcContent;
  const canVerify = !!patchState.patchContent;
  const canSave = !!patchState.newContent;


  // Reload LiveFile from disk

  const targetReloadFromDisk = React.useCallback(async (): Promise<string | null> => {
    if (!targetLiveFileId) return null;
    setStatus({ message: 'Loading latest file version...', mtype: 'info' });
    setPatchState({ srcContent: null, patchContent: null, newContent: null });
    const srcContent = await useLiveFileStore.getState().contentReloadFromDisk(targetLiveFileId);
    if (!srcContent) {
      setStatus({ message: 'Failed to load file content.', mtype: 'error' });
      return null;
    }
    setPatchState(prev => ({ ...prev, srcContent }));
    return srcContent;
  }, [targetLiveFileId]);

  // [effect] reload LiveFile once set
  React.useEffect(() => {
    if (!canLoad) return;
    void targetReloadFromDisk();
  }, [canLoad, targetReloadFromDisk]);


  // Generate patch

  const generatePatch = React.useCallback(async (srcContent: string, code: string): Promise<string> => {
    setStatus({ message: 'Generating patch...', mtype: 'info' });
    // const patch = await generatePatch(srcContent, code);
    const patchContent = code;
    setPatchState(prev => ({ ...prev, patchContent }));
    return patchContent;
  }, []);

  // [effect] generate patch once srcContent is set
  React.useEffect(() => {
    if (!canGenerate) return;
    void generatePatch(patchState.srcContent!, textBuffer);
  }, [canGenerate, generatePatch, patchState.srcContent, textBuffer]);


  // Verify and apply patch

  const verifyPatch = React.useCallback(async (srcContent: string, patchContent: string) => {
    if (!canVerify) return;
    setStatus({ message: 'Verifying patch...', mtype: 'info' });
    const newContent = applyPatch(srcContent, patchContent);
    setPatchState(prev => ({ ...prev, newContent }));
    setStatus({ message: 'Ready.', mtype: 'success' });
    // setStatus({ message: 'Verification successful. Ready to apply.', mtype: 'success' });
  }, [canVerify]);

  // [effect] apply patch once generated
  React.useEffect(() => {
    if (!canVerify) return;
    void verifyPatch(patchState.srcContent!, patchState.patchContent!);
  }, [canVerify, patchState.patchContent, patchState.srcContent, verifyPatch]);


  // Save changes to LiveFile

  const targetWriteAndReload = React.useCallback(async (fileId: LiveFileId, newContent: string): Promise<boolean> => {
    if (!canSave) return false;
    setStatus({ message: 'Saving changes to file...', mtype: 'info' });
    const writeSuccess = await useLiveFileStore.getState().contentWriteAndReload(fileId, newContent);
    if (!writeSuccess)
      setStatus({ message: 'Failed to save changes.', mtype: 'error' });
    else
      setStatus({ message: 'Changes saved successfully.', mtype: 'success' });
    return writeSuccess;
  }, [canSave]);

  const targetOverwriteWithPatch = React.useCallback(async () => {
    if (!canSave) return;
    await targetWriteAndReload(targetLiveFileId!, patchState.newContent!);
  }, [canSave, patchState.newContent, targetLiveFileId, targetWriteAndReload]);

  // [effect] save changes once newContent is set
  // React.useEffect(() => {
  //   if (!canSave) return;
  //   showPromisedOverlay('agi-patch-workflow-save', { rejectWithValue: false }, ({ onResolve, onUserReject }) =>
  //     <ConfirmationModal
  //       open onClose={onUserReject} onPositive={() => onResolve(true)}
  //       title='Save change?'
  //       confirmationText='Do you want to save the changes to the file?'
  //       positiveActionText='Save'
  //     />,
  //   ).then((confirmed) => {
  //     if (confirmed)
  //       void targetWriteAndReload(targetLiveFileId!, patchState.newContent!);
  //   });
  // }, [canSave, patchState.newContent, showPromisedOverlay, targetLiveFileId, targetWriteAndReload]);


  return {
    status,
    patchState,
    targetApplyPatch: verifyPatch,
    targetGeneratePatch: generatePatch,
    targetReloadFromDisk,
    targetOverwriteWithPatch,
  };
}


================================================
FILE: src/modules/blocks/image/RenderImageRefDBlob.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';
import { useQuery } from '@tanstack/react-query';

import type { SxProps } from '@mui/joy/styles/types';
import { Box } from '@mui/joy';

import { t2iGenerateImageContentFragments } from '~/modules/t2i/t2i.client';

import { DBlobAssetId, DBlobImageAsset, useDBAsset } from '~/common/stores/blob/dblobs-portability';

import type { DMessageContentFragment } from '~/common/stores/chat/chat.fragments';
import { humanReadableBytes } from '~/common/util/textUtils';

import { RenderImageURL, RenderImageURLVariant } from './RenderImageURL';


export function RenderImageRefDBlob(props: {
  // from ImageRef
  dataRefDBlobAssetId: DBlobAssetId,
  dataRefMimeType: string,
  dataRefBytesSize?: number, // only used for the overlay text
  imageAltText?: string,
  imageWidth?: number,
  imageHeight?: number,
  // others
  variant: RenderImageURLVariant,
  disabled?: boolean,
  onClick?: (e: React.MouseEvent) => void,  // use this generic as a fallback, but should not be needed
  onDeleteFragment?: () => void,
  onReplaceFragment?: (newFragment: DMessageContentFragment) => void,
  onViewImage?: () => void
  scaledImageSx?: SxProps,
}) {

  // external state from the DB
  const [imageItem] = useDBAsset<DBlobImageAsset>(props.dataRefDBlobAssetId);


  // hook: async image regeneration

  const { label: imageItemLabel, origin: imageItemOrigin } = imageItem || {};
  // const _recreationWidth = imageItemMetadata?.width || props.imageWidth;
  // const _recreationHeight = imageItemMetadata?.height || props.imageHeight;
  const recreationPrompt = ((imageItemOrigin?.ot === 'generated') ? imageItemOrigin.prompt : undefined) || imageItemLabel || props.imageAltText;

  const { isFetching: isRegenerating, refetch: handleImageRegenerate } = useQuery({
    enabled: false,
    queryKey: ['regen-image-asset', props.dataRefDBlobAssetId, recreationPrompt],
    queryFn: async ({ signal }) => {
      if (signal?.aborted || !recreationPrompt || !props.onReplaceFragment) return;
      // NOTE: we shall prevent this operation from happening if the image was not fully generated from the prompt, but also had images
      // const recreationImages = [];
      const newImageFragments = await t2iGenerateImageContentFragments(null, recreationPrompt, [], 1, 'app-chat');
      if (newImageFragments.length === 1)
        props.onReplaceFragment?.(newImageFragments[0]);
    },
  });


  // memo the description and overlay text
  const { dataUrlMemo, altText, overlayText } = React.useMemo(() => {
    // if no image data, return null
    if (!imageItem?.data) {
      return {
        dataUrlMemo: null,
      };
    }

    // [attachment card] only return the data
    if (props.variant === 'attachment-card' || props.variant === 'attachment-button') {
      return {
        dataUrlMemo: `data:${imageItem.data.mimeType};base64,${imageItem.data.base64}`,
      };
    }

    let overlayText: React.ReactNode = null;
    const extension = (imageItem.data.mimeType || props.dataRefMimeType || '').replace('image/', '');
    const overlayDate = imageItem.updatedAt || imageItem.createdAt || undefined;
    const formattedSize = !props.dataRefBytesSize ? undefined : humanReadableBytes(props.dataRefBytesSize);

    switch (imageItem.origin.ot) {
      case 'user':
        overlayText = <Box sx={{ fontSize: '0.875em' }}>
          {/*&quot; {imageItem.label.length > 120 ? imageItem.label.slice(0, 120 - 3) + '...' : imageItem.label} &quot;*/}
          <Box sx={{ opacity: 0.8 }}>
            {imageItem.origin.source} · {imageItem.metadata?.width || props.imageWidth}x{imageItem.metadata?.height || props.imageHeight} · {extension}{formattedSize ? ' · ' + formattedSize : ''}
          </Box>
          <Box sx={{ opacity: 0.8 }}>
            {imageItem.origin.media}{imageItem.origin.fileName ? ' · ' + imageItem.origin.fileName : ''}
          </Box>
          {!!overlayDate && <Box sx={{ opacity: 0.5 }}>
            <TimeAgo date={overlayDate} />
          </Box>}
        </Box>;
        break;

      case 'generated':
        overlayText = <Box sx={{ fontSize: '0.875em' }}>
          &quot; {imageItem.label.length > 120 ? imageItem.label.slice(0, 120 - 3) + '...' : imageItem.label} &quot;
          <Box sx={{ opacity: 0.8 }}>
            AI Image · {imageItem.metadata?.width || props.imageWidth}x{imageItem.metadata?.height || props.imageHeight} · {extension}{formattedSize ? ' · ' + formattedSize : ''}
          </Box>
          <Box sx={{ opacity: 0.8 }}>
            {Object.entries(imageItem.origin.parameters).reduce((acc, [key, value]) => {
              acc.push(`${key}: ${value}`);
              return acc;
            }, [] as string[]).join(', ')}
          </Box>
          {!!overlayDate && <Box sx={{ opacity: 0.5 }}>
            <TimeAgo date={overlayDate} />
          </Box>}
        </Box>;
        break;
    }

    return {
      dataUrlMemo: `data:${imageItem.data.mimeType};base64,${imageItem.data.base64}`,
      altText: props.imageAltText || imageItem.metadata?.description || imageItem.label || '',
      overlayText: overlayText,
    };
  }, [imageItem, props.dataRefMimeType, props.dataRefBytesSize, props.imageAltText, props.imageHeight, props.imageWidth, props.variant]);

  return (
    <RenderImageURL
      imageURL={dataUrlMemo}
      expandableText={altText}
      overlayText={overlayText}
      onClick={props.onClick}
      onImageDelete={props.onDeleteFragment}
      onImageRegenerate={(!!recreationPrompt && !isRegenerating && !!props.onReplaceFragment) ? handleImageRegenerate : undefined}
      onViewImage={props.onViewImage}
      className={isRegenerating ? 'agi-border-4' /* CSS Effect while regenerating */ : undefined}
      scaledImageSx={props.scaledImageSx}
      disabled={props.disabled}
      variant={props.variant}
    />
  );
}



================================================
FILE: src/modules/blocks/image/RenderImageURL.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Alert, Box, IconButton, Sheet } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import InfoOutlinedIcon from '@mui/icons-material/InfoOutlined';
import OpenInNewIcon from '@mui/icons-material/OpenInNew';
import ReplayIcon from '@mui/icons-material/Replay';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { Link } from '~/common/components/Link';

import type { RenderBlockInputs } from '../blocks.types';
import { OverlayButton, overlayButtonsActiveSx, overlayButtonsClassName, overlayButtonsTopRightSx, StyledOverlayButton } from '../OverlayButton';


/// Heuristics to parse Markdown images (as URLs) ///

/**
 * Checks if the entire content consists solely of Markdown image references.
 * If so, returns an array of ImageBlock objects for each image reference.
 * If any non-image content is present or if there are no image references, returns null.
 */
export function heuristicAllMarkdownImageReferences(fullText: string) {

  // Check if all lines are valid Markdown image references with image URLs
  const imageBlocks: RenderBlockInputs = [];
  for (const line of fullText.split('\n')) {
    if (line.trim() === '') continue; // skip empty lines
    const match = mdImageReferenceRegex.exec(line);
    if (match && imageExtensions.test(match[2])) {
      const alt = match[1];
      const url = match[2];
      imageBlocks.push({ bkt: 'img-url-bk', url, alt });
    } else {
      // if there is any outlier line, return null
      return null;
    }
  }

  // Return the image blocks if all lines are image references with valid image URLs
  return imageBlocks.length > 0 ? imageBlocks : null;
}

const mdImageReferenceRegex = /^!\[([^\]]*)]\(([^)]+)\)$/;
const imageExtensions = /\.(jpg|jpeg|png|gif|bmp|svg)/i;


const overlayButtonsGridSx: SxProps = {
  ...overlayButtonsTopRightSx,
  display: 'grid',
  gridTemplateColumns: 'auto auto',
  gap: 0.5,
};

export type RenderImageURLVariant = 'content-part' | 'attachment-card' | 'attachment-button';

/**
 * Renders an Image Data URL, or a remote URL.
 */
export const RenderImageURL = (props: {
  imageURL: string | null,        // remote URL, or data URL: `data:image/png;base64,...`
  overlayText?: React.ReactNode,  // bottom overlay text
  expandableText?: string,        // expandable pane below the image
  variant: RenderImageURLVariant,  // either a responsive Block image, or an inline Card
  disabled?: boolean,             // if true, interaction is disabled
  onImageDelete?: () => void,
  onImageRegenerate?: () => void,
  onClick?: (e: React.MouseEvent) => void,  // use this generic as a fallback, but should not be needed
  onViewImage?: (e: React.MouseEvent) => void,
  scaledImageSx?: SxProps,
  className?: string,
}) => {

  // state
  const [infoOpen, setInfoOpen] = React.useState(false);
  const [loadingTimeout, setLoadingTimeout] = React.useState(false);
  const [deleteArmed, setDeleteArmed] = React.useState(false);
  const [regenArmed, setRegenArmed] = React.useState(false);
  const [showDalleAlert, setShowDalleAlert] = React.useState(true);

  // Effect
  React.useEffect(() => {
    const timeout = setTimeout(() => setLoadingTimeout(true), 2000);
    return () => clearTimeout(timeout);
  }, []);

  // handlers
  const { onImageDelete, onImageRegenerate, onViewImage } = props;

  const handleToggleInfoOpen = React.useCallback(() => {
    setDeleteArmed(false);
    setRegenArmed(false);
    setInfoOpen(open => !open);
  }, []);

  const handleViewImage = React.useCallback((e: React.MouseEvent) => {
    setDeleteArmed(false);
    setRegenArmed(false);
    onViewImage?.(e);
  }, [onViewImage]);

  const handleToggleDeleteArmed = React.useCallback((event: React.MouseEvent) => {
    // immediate deletion if shift is pressed
    if (!deleteArmed && event.shiftKey) // immediately delete:image
      return onImageDelete?.();
    setRegenArmed(false);
    setDeleteArmed(armed => !armed);
  }, [deleteArmed, onImageDelete]);

  const handleImageRegenerate = React.useCallback(() => {
    setDeleteArmed(false);
    setRegenArmed(false);
    onImageRegenerate?.();
  }, [onImageRegenerate]);

  const handleToggleRegenArmed = React.useCallback((event: React.MouseEvent) => {
    // immediate regeneration if shift is pressed
    if (!regenArmed && event.shiftKey) // immediately regenerate:image
      return handleImageRegenerate();
    setDeleteArmed(false);
    setRegenArmed(armed => !armed);
  }, [handleImageRegenerate, regenArmed]);


  // derived state
  const isCard = props.variant === 'attachment-card';
  const isOnButton = props.variant === 'attachment-button';
  const isTempDalleUrl = props.imageURL?.startsWith('https://oaidalle') || false;


  return (
    <Box>

      <Sheet
        color={isCard ? 'primary' : undefined}
        variant={isCard ? 'outlined' : 'solid'}
        aria-disabled={props.disabled}
        onClick={props.onClick}
        className={props.className}
        sx={{
          // style
          mx: isOnButton ? undefined : 1.5,  // 1.5 like the other 'Render*' components
          minWidth: isOnButton ? 20 : 256,
          minHeight: isOnButton ? 20 : 128,
          boxShadow: isCard ? undefined : isOnButton ? '0 2px 6px 0 rgba(0, 0, 0, 0.2)' : 'sm',

          // enable anchoring
          position: 'relative',

          // resizeable image
          '& picture': { display: 'flex', justifyContent: 'center' },
          '& img': { maxWidth: '100%', maxHeight: '100%', filter: props.disabled ? 'grayscale(100%)' : undefined },
          [`&:hover > .${overlayButtonsClassName}`]: overlayButtonsActiveSx,
          '&:hover .overlay-text': overlayButtonsActiveSx,

          // layout
          display: 'flex',
          flexDirection: 'column',
          alignItems: 'center',
          justifyContent: 'center',

          // this shall apply font scaling and maybe margins, not much
          ...props.scaledImageSx,
        }}
      >

        {/* Image and Overlay */}
        <Box sx={{ position: 'relative' }}>

          {/* Image / Loading Indicator */}
          {props.imageURL ? (
            <picture>
              {/* eslint-disable-next-line @next/next/no-img-element */}
              <img src={props.imageURL} alt={props.expandableText ? `Generated Image: ${props.expandableText}` : 'Generated Image'} />
            </picture>
          ) : (
            <Box
              sx={{
                flex: 1,
                p: { xs: 1, md: 3 },
                overflowWrap: 'anywhere',
                whiteSpace: 'break-spaces',
                display: 'block',
              }}
            >
              {loadingTimeout ? 'Image Missing' : 'Loading...'}
            </Box>
          )}

          {/* [overlay] Description */}
          {!!props.overlayText && (
            <Box className='overlay-text' sx={{
              position: 'absolute',
              bottom: 0,
              left: 0,
              right: 0,
              backgroundColor: `rgba(0 0 0 / 0.85)`,
              // backgroundColor: `rgba(${theme.vars.palette.neutral.darkChannel} / 0.85)`,
              p: { xs: 1, md: 2 },
              opacity: infoOpen ? 1 : 0,
              transition: 'opacity 0.16s cubic-bezier(.17,.84,.44,1)',
            }}>
              {props.overlayText}
            </Box>
          )}
        </Box>

        {/* Bottom Expander: information */}
        {!!props.expandableText && infoOpen && (
          <Box sx={{
            p: { xs: 1, md: 2 },
            overflowWrap: 'anywhere',
            whiteSpace: 'break-spaces',
          }}>
            {props.expandableText}
          </Box>
        )}

        {/* [overlay] Buttons (RenderImage) */}
        {!props.disabled && <Box className={overlayButtonsClassName} sx={overlayButtonsGridSx}>

          {!!props.expandableText && (
            <OverlayButton tooltip={infoOpen ? 'Hide Prompt' : 'Show Prompt'} variant={infoOpen ? 'solid' : 'outlined'} color={isCard ? 'primary' : undefined} onClick={handleToggleInfoOpen} sx={{ gridRow: '1', gridColumn: '1' }}>
              <InfoOutlinedIcon />
            </OverlayButton>
          )}

          {!!props.imageURL && (
            props.onViewImage ? (
              <OverlayButton tooltip='View Image' variant='outlined' color={isCard ? 'primary' : undefined} onClick={handleViewImage} sx={{ gridRow: '1', gridColumn: '2' }}>
                <OpenInNewIcon />
              </OverlayButton>
            ) : props.imageURL.startsWith('http') ? (
              <StyledOverlayButton variant='outlined' color={isCard ? 'primary' : undefined} component={Link} href={props.imageURL} download={props.expandableText || 'Image'} target='_blank' sx={{ gridRow: '1', gridColumn: '2' }}>
                <OpenInNewIcon />
              </StyledOverlayButton>
            ) : <span />
          )}


          {/* Deletion */}

          {deleteArmed && !regenArmed && (
            <OverlayButton tooltip='Confirm Deletion' placement='bottom' variant='outlined' color='danger' onClick={onImageDelete} sx={{ gridRow: '2', gridColumn: '1' }}>
              <DeleteForeverIcon sx={{ color: 'danger.solidBg' }} />
            </OverlayButton>
          )}

          {!!onImageDelete && !regenArmed && (
            <OverlayButton tooltip={deleteArmed ? 'Cancel Deletion' : 'Delete Image'} placement='bottom' variant={deleteArmed ? 'solid' : 'outlined'} color={isCard ? 'primary' : undefined} onClick={handleToggleDeleteArmed} sx={{ gridRow: '2', gridColumn: '2' }}>
              {deleteArmed ? <CloseRoundedIcon /> : <DeleteOutlineIcon />}
            </OverlayButton>
          )}

          {!!onImageRegenerate && !deleteArmed && (
            <OverlayButton tooltip={regenArmed ? 'Cancel Regeneration' : 'Draw again with the present configuration'} placement='bottom' variant={regenArmed ? 'solid' : 'outlined'} onClick={handleToggleRegenArmed} sx={{ gridRow: '2', gridColumn: '1' }}>
              {regenArmed
                ? <CloseRoundedIcon />
                : <ReplayIcon />
              }
            </OverlayButton>
          )}

          {/* Regenerate [armed, arming] buttons */}
          {regenArmed && !deleteArmed && (
            <OverlayButton tooltip='Confirm Regeneration' placement='bottom' variant='outlined' color='success' onClick={handleImageRegenerate} sx={{ gridRow: '2', gridColumn: '2' }}>
              <ReplayIcon sx={{ color: 'success.solidBg' }} />
            </OverlayButton>
          )}

        </Box>}
      </Sheet>


      {/* (Remove in 2025) Dalle Warning notice */}
      {isTempDalleUrl && showDalleAlert && (
        <Alert
          variant='soft' color='neutral'
          startDecorator={<WarningRoundedIcon />}
          endDecorator={
            <IconButton variant='soft' aria-label='Close Alert' onClick={() => setShowDalleAlert(on => !on)} sx={{ my: -0.5 }}>
              <CloseRoundedIcon />
            </IconButton>
          }
          sx={{
            mx: 0.5,
            ...props.scaledImageSx,
          }}
        >
          <div>
            <strong>Please Save Locally</strong> · OpenAI will delete this image link from their servers one hour after creation.
          </div>
        </Alert>
      )}

    </Box>
  );
};



================================================
FILE: src/modules/blocks/markdown/CustomARenderer.tsx
================================================
import * as React from 'react';

import { Avatar, Box, Chip, FormControl, Link } from '@mui/joy';

import { TooltipOutlined } from '~/common/components/TooltipOutlined';


interface URLInfo {
  domain: string;
  prettyUrl: string;
  isSecure: boolean;
  // type: 'social' | 'academic' | 'news' | 'default';
}

// function _detectUrlType(domain: string): 'social' | 'academic' | 'news' | 'default' {
//   const socialDomains = ['twitter.com', 'facebook.com', 'linkedin.com'];
//   const academicDomains = ['scholar.google.com', 'arxiv.org', 'academia.edu'];
//   const newsDomains = ['reuters.com', 'bloomberg.com', 'nytimes.com'];
//
//   if (socialDomains.some(d => domain.includes(d))) return 'social';
//   if (academicDomains.some(d => domain.includes(d))) return 'academic';
//   if (newsDomains.some(d => domain.includes(d))) return 'news';
//   return 'default';
// }

function _prettyHref(href: string): string {
  try {
    const url = new URL(href);
    const text = url.origin + url.pathname;
    return text.endsWith('/') ? text.slice(0, -1) : text;
  } catch {
    return href;
  }
}

function _analyzeUrl(url: string): URLInfo {
  try {
    const urlObj = new URL(url);
    return {
      domain: urlObj.hostname,
      prettyUrl: _prettyHref(url),
      isSecure: urlObj.protocol === 'https:',
      // type: _detectUrlType(urlObj.hostname),
    };
  } catch {
    return {
      domain: url,
      prettyUrl: url,
      isSecure: false,
      // type: 'default',
    };
  }
}


function GoogleFavicon(props: {
  domain: string;
  size?: number;
  iconRes?: number;
  noShadow?: boolean;
}) {

  const { domain, size = 16, iconRes = 32, noShadow } = props;

  // using Google's favicon service, with
  const faviconUrl = `https://www.google.com/s2/favicons?domain=${domain}&sz=${iconRes}`;

  return (
    <Avatar
      component='span'
      variant='plain'
      sx={{
        mx: 0.5,
        borderRadius: noShadow ? 0 : 'xs',
        boxShadow: noShadow ? 'none' : 'xs',
        width: size,
        height: size,
        fontSize: size * 0.8,
        // bgcolor: 'neutral.softBg',
        // outline: noShadow ? undefined : '1px solid',
        // outlineColor: noShadow ? undefined : 'neutral.outlinedBorder',
        '&:hover': {
          outlineColor: 'neutral.outlinedColor',
          bgcolor: 'neutral.softActiveBg',
          borderRadius: 'none',
          boxShadow: 'md',
        },
      }}
      src={faviconUrl}
    >
      {domain.charAt(0).toUpperCase()}
    </Avatar>
  );
}

function LinkPreview({ urlInfo }: { urlInfo: URLInfo }) {
  return (
    <FormControl sx={{ px: 0.5, py: 0.75, minWidth: 200 }}>
      <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
        <GoogleFavicon domain={urlInfo.domain} size={32} iconRes={64} noShadow />
        <Box sx={{ flex: 1 }}>
          <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
            <Box sx={{ fontSize: 'xs', color: 'text.tertiary' }}>Open in new tab</Box>
            {urlInfo.isSecure && <Chip size='sm' variant='soft' color='success'>Secure</Chip>}
          </Box>
          <Box sx={{ color: 'text.secondary' }}>{urlInfo.prettyUrl}</Box>
        </Box>
        {/*<Typography level='body-xs' mt={1}>Click to open</Typography>*/}
      </Box>
    </FormControl>
  );
}


export function CustomARenderer({ node, href, children, ...props }: {
  node?: any;
  href?: string;
  children: React.ReactNode;
}) {

  const isEmptyInlineLink = React.Children.count(children) === 0;

  // Empty Inline Link:  render the favicon with a popup for [](https://..)
  if (isEmptyInlineLink && href) {
    const urlInfo = _analyzeUrl(href);

    return (
      <TooltipOutlined title={<LinkPreview urlInfo={urlInfo} />}>
        <Link level='inherit' {...props} href={href} target='_blank' rel='noopener'>
          {children} <GoogleFavicon domain={urlInfo.domain} size={16} />
        </Link>
      </TooltipOutlined>
    );
  }

  // adds a target="_blank" to all links
  return (
    <a {...props} href={href} target='_blank' rel='noopener'>
      {children}
    </a>
  );
}



================================================
FILE: src/modules/blocks/markdown/CustomMarkdownRenderer.tsx
================================================
import * as React from 'react';
import { stringify as csvStringify } from 'csv-stringify/browser/esm/sync';

import type { Pluggable as UnifiedPluggable } from 'unified';
import { Components as ReactMarkdownComponents, default as ReactMarkdown } from 'react-markdown';
import { default as rehypeKatex } from 'rehype-katex';
import { default as remarkGfm } from 'remark-gfm';
import { default as remarkMath } from 'remark-math';
import { remarkMark } from 'remark-mark-highlight';

import { Box, Chip } from '@mui/joy';

import { copyToClipboard } from '~/common/util/clipboardUtils';
import { downloadBlob } from '~/common/util/downloadUtils';

import { CustomARenderer } from './CustomARenderer';
import { wrapWithMarkdownSyntax } from './markdown.wrapper';


// DelRenderer adds a strikethrough to the text
function DelRenderer({ children }: { children: React.ReactNode }) {
  return <del className='agi-content-delete'>{children}</del>;
}

// Mark Renderer adds a yellow background to the text
function MarkRenderer({ children }: { children: React.ReactNode }) {
  // Mark by default has a yellow background, but we want to set a custom class here, so we can style it
  return <mark className='agi-highlight'>{children}</mark>;
}


// configuration
const MAX_PREPROCESSOR_LENGTH = 50_000; // 50kB, this is the max length of the text we want to preprocess for annotations/formulas


// TableRenderer adds a CSV Download Link and a Copy Markdown Button

const _styles = {

  tableStyle: {
    borderCollapse: 'collapse',
    width: '100%',
    marginBottom: '0.5rem',
  } as const,

  buttons: {
    mb: 2,
    display: 'flex',
    alignItems: 'center',
    gap: 1,
  } as const,

  button: {
    // backgroundColor: 'background.popup',
    borderRadius: 0,
    px: 1.5,
    py: 0.375,
    outline: '1px solid',
    outlineColor: 'neutral.outlinedBorder', // .outlinedBorder
    // boxShadow: `1px 2px 4px -3px var(--joy-palette-neutral-solidBg)`,
  } as const,

};

interface TableRendererProps {
  node?: any; // an optional field we want to not pass to element
  children: React.JSX.Element;
}

function TableRenderer({ children, node, ...props }: TableRendererProps) {

  // extracts the table data by parsing the DOM
  const tableData = _extractTableData(children);

  // handlers

  const handleDownloadCsv = React.useCallback(() => {
    if (!tableData?.length) return;

    // take all rows except the first one
    const dataRows = tableData.slice(1);

    // convert to CSV
    const csvString = csvStringify(dataRows, {
      bom: true,                 // add BOM marker for UTF-8 detection in Excel
      quoted: true,              // quote all fields
      quote: '"',                // use double quotes
      escape: '"',               // escape quotes with double quotes
      header: true,
      columns: tableData[0],
    });

    // create blob and trigger download
    const blob = new Blob([csvString], { type: 'text/csv;charset=utf-8;' });
    downloadBlob(blob, 'table.csv');
  }, [tableData]);

  const handleCopyMarkdown = React.useCallback(() => {
    if (!tableData?.length) return;
    const markdownString = generateMarkdownTableFromData(tableData);
    copyToClipboard(markdownString, 'Markdown Table');
  }, [tableData]);


  return (
    <>
      <table style={_styles.tableStyle} {...props}>
        {children}
      </table>

      {/* Download CSV link and Copy Markdown Button */}
      {tableData?.length >= 1 && (
        <Box sx={_styles.buttons}>
          {/* Download button*/}
          <Chip
            variant='soft'
            color='neutral'
            size='sm'
            onClick={handleDownloadCsv}
            // endDecorator={<DownloadIcon />}
            sx={_styles.button}
          >
            Download CSV
          </Chip>

          {/* Button to copy markdown */}
          <Chip
            variant='soft'
            color='neutral'
            size='sm'
            onClick={handleCopyMarkdown}
            // endDecorator={<ContentCopyIcon />}
            sx={_styles.button}
          >
            Copy Markdown
          </Chip>
        </Box>
      )}
    </>
  );
}

// Function to extract text from a React element or component
function extractText(element: any): string {
  if (element === null)
    return '';
  // Base case: if the element is a string, return it
  if (typeof element === 'string') {
    return element;
  }
  // If the element has children, recursively extract text from them
  if (element.props?.children) {
    if (Array.isArray(element.props.children)) {
      return element.props.children.map(extractText).join('');
    }
    return extractText(element.props.children);
  }
  return '';
}

// Function to traverse and extract data from table rows and cells
function traverseAndExtract(elements: React.JSX.Element, tableData: any[] = []): any[] {
  React.Children.forEach(elements, (element) => {
    if (element.type === 'tr') {
      const rowData = React.Children.map(element.props?.children, (cell) => {
        // Extract and return the text content of each cell
        return extractText(cell);
      });
      tableData.push(rowData);
    } else if (element.props?.children) {
      traverseAndExtract(element.props.children, tableData);
    }
  });
  return tableData;
}

function _extractTableData(children: React.JSX.Element) {
  return traverseAndExtract(children);
}

function generateMarkdownTableFromData(tableData: any[]): string {
  if (tableData.length === 0)
    return '';

  // Extract header and rows
  const [header, ...rows] = tableData;

  // Create markdown header
  const headerMarkdown = `| ${header.join(' | ')} |`;
  // Create separator
  const separator = `| ${header.map(() => '---').join(' | ')} |`;
  // Create markdown rows
  const rowsMarkdown = rows.map(row => `| ${row.join(' | ')} |`).join('\n');

  // Combine all parts
  return [headerMarkdown, separator, rowsMarkdown].join('\n');
}


// shared components for the markdown renderer

const reactMarkdownComponents = {
  a: CustomARenderer, // override the link renderer to add target="_blank"
  del: DelRenderer, // renders the <del> tag (~~strikethrough~~)
  mark: MarkRenderer, // renders the <mark> tag (==highlight==)
  table: TableRenderer, // override the table renderer to show the download CSV links and Copy Markdown button
  // math/inlineMath components are not needed, rehype-katex handles this automatically
} as ReactMarkdownComponents;

const remarkPluginsStable: UnifiedPluggable[] = [
  remarkGfm, // GitHub Flavored Markdown
  remarkMark, // Mark-Highlight, for ==yellow==
  [remarkMath, {
    /**
     * NOTE: this could be configurable, some users reported liking single dollar signs math, despite even the official
     * LaTeX documentation recommending against it: https://docs.mathjax.org/en/latest/input/tex/delimiters.html
     * So in the future this could be a user setting.
     */
    singleDollarTextMath: false,
  }],
];

const rehypePluginsStable: UnifiedPluggable[] = [
  rehypeKatex, // KaTeX
];


let warnedAboutLength = false;
let warnedAboutPreprocessor = false;

const INLINE_LATEX_REGEX = /(\s*)\\\(([^\n]*?)\\\)/g;
// noinspection RegExpRedundantEscape
const BLOCK_LATEX_REGEX = /(\s*)\\\[((?:.|\n)*?)\\\]/g;

/*
 * Convert OpenAI-style markdown with LaTeX to 'remark-math' compatible format.
 * Note that inline or block will both be converted to $$...$$ format, and we
 * disable on purpose the single dollar sign for inline math, as it can clash
 * with other markdown syntax.
 */
function preprocessMarkdown(markdownText: string) {
  try {
    // for performance, disable the preprocessor if the text is too long
    if (markdownText.length > MAX_PREPROCESSOR_LENGTH) {
      if (!warnedAboutLength) {
        console.warn('[DEV] Preprocessing markdown: text too long, skipping');
        warnedAboutLength = true;
      }
      return markdownText;
    }
    return markdownText
      // Replace LaTeX delimiters with $$...$$
      // Replace inline LaTeX delimiters \( and \) with $$
      // [2025-04-20] NOTE: it was reported that we had infinite recursion on the (.*?) version of inline math; as such, we now stay on the same line
      .replace(INLINE_LATEX_REGEX, (_match, leadingSpace, mathContent) =>
        `${leadingSpace}$$${mathContent}$$`,
      )
      // Replace block LaTeX delimiters \[ and \] with $$
      .replace(BLOCK_LATEX_REGEX, (_match, leadingSpace, mathContent) =>
        `${leadingSpace}$$${mathContent}$$`,
      )
      // Replace <mark>...</mark> with ==...==, but not in multiple lines, or if preceded by a backtick (disabled, was (?<!`))
      .replace(/<mark>([\s\S]*?)<\/mark>/g, (_match, p1) => wrapWithMarkdownSyntax(p1, '=='))
      // Replace <del>...</del> with ~~...~~, but not in multiple lines, or if preceded by a backtick (disabled, was (?<!`))
      .replace(/<del>([\s\S]*?)<\/del>/g, (_match, p1) => wrapWithMarkdownSyntax(p1, '~~'));
  } catch (error: any) {
    if (!warnedAboutPreprocessor) {
      console.warn('[DEV] Issue with the markdown preprocessor. Please open a bug with the offending text.', { error, markdownText });
      warnedAboutPreprocessor = true;
    }
    return markdownText;
  }
}

export default function CustomMarkdownRenderer(props: { content: string, disablePreprocessor?: boolean }) {
  return (
    <ReactMarkdown
      components={reactMarkdownComponents}
      remarkPlugins={remarkPluginsStable}
      rehypePlugins={rehypePluginsStable}
    >
      {props.disablePreprocessor ? props.content : preprocessMarkdown(props.content)}
    </ReactMarkdown>
  );
}


================================================
FILE: src/modules/blocks/markdown/markdown.wrapper.ts
================================================
export function wrapWithMarkdownSyntax(text: string, marker: '~~' | '**' | '=='): string {
  // Extract leading and trailing spaces
  const startMatch = text.match(/^\s*/);
  const endMatch = text.match(/\s*$/);

  const startSpaces = startMatch ? startMatch[0] : '';
  const endSpaces = endMatch ? endMatch[0] : '';

  // Trim the inner content and escape special characters
  const innerContent = text.trim();
  const escapedContent = innerContent.replace(/([\\`*_\[\]{}()#+\-.!])/g, '\\$1');

  // Wrap the inner content with the specified markers
  return `${startSpaces}${marker}${escapedContent}${marker}${endSpaces}`;
}


================================================
FILE: src/modules/blocks/markdown/RenderMarkdown.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, styled } from '@mui/joy';

import { lineHeightChatTextMd } from '~/common/app.theme';


/*
 * For performance reasons, we style this component here and copy the equivalent of 'props.sx' (the lineHeight) locally.
 */
const RenderMarkdownBox = styled(Box)({
  // same look as the other RenderComponents
  marginInline: '0.75rem !important',                             // margin: 1.5 like other blocks
  // this is here for usage outside of the Blocks (which set it in `sx`)
  lineHeight: lineHeightChatTextMd,

  // patch the CSS
  // fontFamily: `inherit !important`,                    // (not needed anymore, as CSS is under our control) use the default font family
  // '--color-canvas-default': 'transparent !important',  // (not needed anymore) remove the default background color
  '& table': { width: 'inherit !important' },           // un-break auto-width (tables have 'max-content', which overflows)
});

const DynamicMarkdownRenderer = React.lazy(() => import('./CustomMarkdownRenderer'));

export function RenderMarkdown(props: { content: string; disablePreprocessor?: boolean, sx?: SxProps; }) {
  return (
    <RenderMarkdownBox
      className='markdown-body' /* NODE: see GithubMarkdown.css for the dark/light switch, synced with Joy's */
      sx={props.sx}
    >
      <React.Suspense fallback={<div>Loading...</div>}>
        <DynamicMarkdownRenderer content={props.content} disablePreprocessor={props.disablePreprocessor} />
      </React.Suspense>
    </RenderMarkdownBox>
  );
}

export const RenderMarkdownMemo = React.memo(RenderMarkdown);


================================================
FILE: src/modules/blocks/plaintext/RenderPlainText.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Chip, Typography } from '@mui/joy';

import { extractChatCommand } from '../../../apps/chat/commands/commands.registry';


const _style = {
  mx: 1.5,
  // display: 'flex', // Commented on 2023-12-29: the commands were drawn as columns
  alignItems: 'baseline',
  overflowWrap: 'anywhere',
  whiteSpace: 'break-spaces',
} as const;


/**
 * Renders a text block with chat commands.
 * NOTE: should remove the commands parsing dependency.
 */
export const RenderPlainText = (props: { content: string; sx?: SxProps; }) => {

  const elements = extractChatCommand(props.content);

  const memoSx = React.useMemo(() => ({ ..._style, ...props.sx }), [props.sx]);

  return (
    <Typography sx={memoSx}>
      {elements.map((element, index) =>
        <React.Fragment key={index}>
          {element.type === 'cmd'
            ? <>
              <Chip component='span' size='md' variant='solid' color={element.isErrorNoArgs ? 'danger' : 'neutral'} sx={{ mr: 1 }}>
                {element.command}
              </Chip>
              <span>{element.params}</span>
            </>
            : <span>{element.value}</span>
          }
        </React.Fragment>,
      )}
    </Typography>
  );
};


================================================
FILE: src/modules/blocks/wordsdiff/RenderWordsDiff.tsx
================================================
import * as React from 'react';
import { diffWords } from 'diff';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Typography } from '@mui/joy';


// configuration
const COALESCE_TIMEOUT = 200;


export type WordsDiff = {
  value: string;                    // the string value of this chunk of words
  count?: number | undefined;       // total number of words
  added?: boolean | undefined;      // is this an insertion
  removed?: boolean | undefined;    // is this a deletion
}[];


export function useWordsDifference(_text: string, _diffText: string | undefined, enabled: boolean) {
  // state
  const [diffs, setDiffs] = React.useState<WordsDiff | null>(null);

  const inputText = enabled ? _text : null;
  const inputPrevText = enabled ? _diffText : null;

  // async processing of diffs
  React.useEffect(() => {
    if (!inputText || !inputPrevText)
      return setDiffs(null);

    const callback = () => setDiffs(diffWords(inputPrevText, inputText));

    // slight delay to cancel the previous operation if too close to this
    const timeout = setTimeout(callback, COALESCE_TIMEOUT);
    return () => clearTimeout(timeout);
  }, [inputPrevText, inputText]);

  return diffs;
}


export function RenderWordsDiff(props: { wordsDiff: WordsDiff; sx?: SxProps; }) {
  return (
    <Typography
      sx={{
        mx: 1.5,
        // display: 'flex', alignItems: 'baseline',
        overflowWrap: 'anywhere',
        whiteSpace: 'break-spaces',
        display: 'block',
        ...props.sx,
        '.added': {
          backgroundColor: 'success.softActiveBg',
          color: 'success.softColor',
          paddingY: '0.125rem',
          borderRadius: '0.125rem',
        },
        '.removed': {
          backgroundColor: 'danger.softActiveBg',
          color: 'danger.plainColor',
          paddingY: '0.125rem',
          borderRadius: '0.125rem',
          // textDecoration: 'line-through',
        },
      }}
    >
      {props.wordsDiff.map((diff, index) =>
        <Box
          component='span'
          key={'diff-' + index}
          className={diff.added ? 'added' : diff.removed ? 'removed' : undefined}
        >
          {diff.value}
        </Box>,
      )}
    </Typography>
  );
}



================================================
FILE: src/modules/browse/browse.client.ts
================================================
import { BrowsePageTransform, useBrowseStore } from '~/modules/browse/store-module-browsing';

import { apiStreamNode } from '~/common/util/trpc.client';


/**
 * Error handling for browsing:
 * - connection issue: .mutate throws a "Invalid response or stream interrupted" TRPCClientError
 * - router throws: client rethrows TRPCClientError (code 500 if no code is provided) with the message
 * - other errors from parsing (and in the payload we get): we'll throw nicer messages
 */
export async function callBrowseFetchPageOrThrow(
  url: string,
  transforms?: BrowsePageTransform[],
  screenshotOptions?: { width: number, height: number, quality?: number },
  allowFileDownloads?: boolean,
) {

  // validate url
  url = url?.trim() || '';
  if (!url)
    throw new Error('Browsing error: Invalid URL');

  // noinspection HttpUrlsUsage: assume https if no protocol is provided
  if (!url.startsWith('http://') && !url.startsWith('https://'))
    url = 'https://' + url;

  const { wssEndpoint, pageTransform } = useBrowseStore.getState();

  // Connect to our service
  let streamingResponse: Awaited<ReturnType<typeof apiStreamNode.browse.fetchPagesStreaming.mutate>>;
  try {
    streamingResponse = await apiStreamNode.browse.fetchPagesStreaming.mutate({
      access: {
        dialect: 'browse-wss',
        ...(!!wssEndpoint && { wssEndpoint }),
      },
      requests: [{
        url,
        transforms: transforms ? transforms : [pageTransform],
        screenshot: screenshotOptions || undefined,
        allowFileDownloads: allowFileDownloads || false,
      }],
    });
  } catch (error: any) {
    console.warn('[DEV] browse.client: connection error:', error);
    throw new Error('Connectivity Issue.');
  }

  // Retrieve the response - let errors throw as they behave well
  // - the router throws a TRPCClientError if the WSS endpoint is invalid, with a nice message
  // - if the network is interrupted, a StreamInterruptedError will be thrown
  //   - with cause 'TypeError: network error'
  //   - with message 'Invalid response or stream interrupted'
  // - we will throw more errors if we can't validate
  for await (const message of streamingResponse) {
    switch (message.type) {
      case 'ack-start':
        // ignore
        break;

      case 'result':
        if (message.pages.length !== 1)
          throw new Error(`Browser downloaded ${message.pages?.length} pages, but only one was expected`);

        // throw if there's an error
        const page = message.pages[0];
        if (page.error) {
          const haveNoContent = !page.content || !Object.keys(page.content).length;
          console.warn('[DEV] browse.client: puppeteer error:', { page });
          if (haveNoContent)
            throw new Error(page.error);
        }

        // we did it
        return page;
    }
  }

  // no page received
  throw new Error('No page received');
}



================================================
FILE: src/modules/browse/browse.files.ts
================================================
import type { HTTPResponse } from 'puppeteer-core';


/**
 * When Puppeteer downloads a file instead of a web page, we run it through allowlists before deciding
 * whether to process it or not. This is to reduce the likelihood of downloading malicious files.
 * However the end responsibility lies with the user, as both the server and the client won't validate
 * further.
 */
const SERVER_SUPPORTED_DOWNLOADS = {
  document: {
    mimetypes: new Set([
      // PDF
      'application/pdf',
      'application/x-pdf',
      'application/acrobat',
      // Word
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    ]),
    maxSizeMB: 20,
  },
  text: {
    mimetypes: new Set([
      // Basic Text
      'text/plain',
      'text/markdown',
      'text/html',
      'text/rtf',
      'application/rtf',
      // Code - JavaScript/TypeScript
      'text/javascript',
      'application/javascript',
      'text/typescript',
      'application/typescript',
      // Web
      'text/css',
      'text/csv',
      'text/xml',
      'application/json',
      // Programming Languages
      'text/x-python',
      'text/x-java',
      'text/x-c',
      'text/x-cpp',
      'text/x-csharp',
      'text/x-ruby',
      'text/x-go',
      'text/x-rust',
    ]),
    maxSizeMB: 2,
  },
  image: {
    mimetypes: new Set([
      'image/jpeg',
      'image/png',
      'image/webp',
      'image/gif',
      'image/svg+xml',
    ]),
    maxSizeMB: 10,
  },
} as const;


function _getMimeCategory(mimeType: string): keyof typeof SERVER_SUPPORTED_DOWNLOADS | null {
  const cleanMime = mimeType.split(';')[0].toLowerCase();
  return Object.entries(SERVER_SUPPORTED_DOWNLOADS).find(([_, { mimetypes }]) => {
    return mimetypes.has(cleanMime);
  })?.[0] as keyof typeof SERVER_SUPPORTED_DOWNLOADS | null;
}

function _sanitizeFilename(filename: string): string {
  // Remove or replace potentially problematic characters
  return filename
    .replace(/[<>:"/\\|?*]/g, '_') // Replace Windows-unsafe characters
    .replace(/\.\./g, '_')         // Prevent directory traversal
    .replace(/^\./, '_')          // No leading dots
    .replace(/\s+/g, '_')         // Replace spaces with underscores
    .slice(0, 255);               // Maximum length for most filesystems
}


/**
 * SECURITY NOTE - while we validate MIME types and sizes, the server-provided MIME type
 * is still trusted for initial categorization.
 */
export async function workerPuppeteerDownloadFileOrThrow(response: HTTPResponse): Promise<{
  file: {
    mimeType: string;
    data: string;
    size: number;
    filename?: string;
    category?: keyof typeof SERVER_SUPPORTED_DOWNLOADS;
  }
}> {

  // validate content-type
  const headers = response.headers();
  const mimeType = headers['content-type']?.split(';')[0].toLowerCase() || '';
  if (!mimeType)
    throw new Error('No content-type header received');

  const category = _getMimeCategory(mimeType);
  if (!category)
    throw new Error(`Unsupported file type: ${mimeType}`);

  // validate size
  // NOTE: disabled due to real-world server returning chunked sizes, etc.
  // const size = parseInt(headers['content-length'] || '0');
  // const maxSize = SERVER_SUPPORTED_DOWNLOADS[category].maxSizeMB * 1024 * 1024;
  // if (size > maxSize)
  //   throw new Error('File size exceeds the limit. Please download it manually and attach it as file.');

  // get the content
  const buffer = await response.buffer();
  if (!buffer || buffer.length === 0)
    throw new Error('No content received');

  // validate actual size against our limits
  const maxSize = SERVER_SUPPORTED_DOWNLOADS[category].maxSizeMB * 1024 * 1024;
  if (buffer.length > maxSize)
    throw new Error(`File exceeds the size limit for download (${SERVER_SUPPORTED_DOWNLOADS[category].maxSizeMB}MB). Please attach it manually.`);

  // heuristic: guess filename if possible
  let filename: string | undefined;
  const contentDisposition = headers['content-disposition'];
  if (contentDisposition) {
    const filenameMatch = /filename[^;=\n]*=((['"]).*?\2|[^;\n]*)/.exec(contentDisposition);
    if (filenameMatch) {
      const rawFilename = filenameMatch[1].replace(/['"]/g, '');
      filename = _sanitizeFilename(rawFilename);
    }
  }

  return {
    file: {
      mimeType,
      data: buffer.toString('base64'),
      size: buffer.length,
      ...(filename && { filename }),
      category,
    },
  };
}



================================================
FILE: src/modules/browse/browse.router.ts
================================================
import * as z from 'zod/v4';
import { TRPCError } from '@trpc/server';

import puppeteer, { Browser, BrowserContext, ScreenshotOptions } from 'puppeteer-core';
import { default as TurndownService } from 'turndown';
import { load as cheerioLoad } from 'cheerio';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { env } from '~/server/env';

import { workerPuppeteerDownloadFileOrThrow } from './browse.files';


// configuration
const DISABLE_FILE_DOWNLOADS = true;
const WORKER_TIMEOUT = 20 * 1000; // 20 seconds


// Input schemas

const pageTransformSchema = z.enum(['html', 'text', 'markdown']);

type PageTransformSchema = z.infer<typeof pageTransformSchema>;

const fetchPageInputSchema = z.object({
  access: z.object({
    dialect: z.enum(['browse-wss']),
    wssEndpoint: z.string().trim().optional(),
  }),
  requests: z.array(z.object({
    url: z.url(),
    transforms: z.array(pageTransformSchema),
    allowFileDownloads: z.boolean().optional(),
    screenshot: z.object({
      width: z.number(),
      height: z.number(),
      quality: z.number().optional(),
    }).optional(),
  })),
});


// Output schemas

const fetchPageWorkerOutputSchema = z.object({
  url: z.string(),
  title: z.string(),

  content: z.partialRecord(pageTransformSchema, z.string()).optional(), // either...
  file: z.object({ // ...or
    mimeType: z.string(),
    encoding: z.literal('base64'),
    data: z.string(),
    size: z.number(),
    fileName: z.string().optional(),
  }).optional(), // ...or

  error: z.string().optional(),
  stopReason: z.enum(['end', 'timeout', 'error']),
  screenshot: z.object({
    imgDataUrl: z.string().startsWith('data:image/webp'),
    mimeType: z.string().startsWith('image/'),
    width: z.number(),
    height: z.number(),
  }).optional(),
});
export type FetchPageWorkerOutputSchema = z.infer<typeof fetchPageWorkerOutputSchema>;


export const browseRouter = createTRPCRouter({

  fetchPagesStreaming: publicProcedure
    .input(fetchPageInputSchema)
    .mutation(async function* ({ input: { access, requests } }) {

      // get endpoint
      const endpoint = (access.wssEndpoint || env.PUPPETEER_WSS_ENDPOINT || '').trim();
      if (!endpoint || (!endpoint.startsWith('wss://') && !endpoint.startsWith('ws://')))
        throw new TRPCError({ code: 'PRECONDITION_FAILED', message: 'Invalid WSS browser endpoint' });
      const workerHost = new URL(endpoint).host;

      yield { type: 'ack-start' as const };

      // start all requests in parallel, intercepting errors too
      const results = await Promise.allSettled(requests.map(request =>
        workerPuppeteer(endpoint, request.url, request.transforms, request.allowFileDownloads || false, request.screenshot),
      ));

      // return all pages trapping errors
      const pages: FetchPageWorkerOutputSchema[] = results.map((result, index) => {
        switch (result.status) {
          case 'fulfilled':
            return result.value;
          case 'rejected':
            // server-side log the exception
            console.warn('[DEV] browse.worker: fetchPagesStreaming error:', result.reason);
            return {
              url: requests[index].url,
              title: '',
              content: undefined,
              file: undefined,
              error: typeof result.reason === 'string' ? result.reason
                : result.reason instanceof Error ? result.reason.message
                  : result.reason ? JSON.stringify(result.reason)
                    : 'Unknown fetch error',
              stopReason: 'error',
              screenshot: undefined,
            } satisfies FetchPageWorkerOutputSchema;
        }
      });

      // final result
      yield {
        type: 'result' as const,
        pages,
        workerHost,
      };
    }),

});


async function workerPuppeteer(
  browserWSEndpoint: string,
  targetUrl: string,
  transforms: PageTransformSchema[],
  allowFileDownloads: boolean,
  screenshotOptions?: { width: number, height: number, quality?: number },
): Promise<FetchPageWorkerOutputSchema> {

  // FIXME: remove this line for authenticated users(!)
  if (DISABLE_FILE_DOWNLOADS)
    allowFileDownloads = false;

  const result: FetchPageWorkerOutputSchema = {
    url: targetUrl,
    title: '',
    content: undefined,
    file: undefined,
    error: undefined,
    stopReason: 'error',
    screenshot: undefined,
  };

  // [puppeteer] start the remote session
  const browser: Browser = await puppeteer.connect({
    browserWSEndpoint,
    // Add default options for better stability
    // defaultViewport: { width: 1024, height: 768 },
    // acceptInsecureCerts: true,
    protocolTimeout: WORKER_TIMEOUT,
  });

  // for local testing, open an incognito context, to separate cookies
  let incognitoContext: BrowserContext | null = null;
  const isLocalBrowser = browserWSEndpoint.startsWith('ws://');
  if (isLocalBrowser)
    incognitoContext = await browser.createBrowserContext();
  const page = incognitoContext ? await incognitoContext.newPage() : await browser.newPage();
  page.setDefaultNavigationTimeout(WORKER_TIMEOUT);

  // open url
  try {
    const response = await page.goto(targetUrl, {
      waitUntil: 'networkidle0', // Wait until network is idle
      timeout: WORKER_TIMEOUT,
    });
    if (!response) {
      // noinspection ExceptionCaughtLocallyJS
      throw new Error('No response received');
    }

    // check if the response is a file or a web page
    const contentType = response.headers()['content-type'];
    const isWebPage = contentType?.startsWith('text/html') || contentType?.startsWith('text/plain') || false;
    if (!isWebPage) {
      if (!allowFileDownloads) {
        // noinspection ExceptionCaughtLocallyJS
        throw new Error(`Not a webpage: ${contentType}`);
      } else {
        try {
          const { file } = await workerPuppeteerDownloadFileOrThrow(response);
          result.file = {
            mimeType: file.mimeType,
            encoding: 'base64',
            data: file.data,
            size: file.size,
            fileName: file.filename || '',
          };
          result.stopReason = 'end';
          result.title = file.filename || '';
        } catch (error: any) {
          // noinspection ExceptionCaughtLocallyJS
          throw new Error(error?.message || 'File download failed');
        }
      }
    } else {
      result.stopReason = 'end';
    }
  } catch (error: any) {
    // This was "error instanceof TimeoutError;" but threw some type error - trying the below instead
    const isTimeout = error?.message?.includes('Navigation timeout') || false;
    result.stopReason = isTimeout ? 'timeout' : 'error';
    if (!isTimeout) {
      result.error = '[Puppeteer] ' + (error?.message || error?.toString() || 'Unknown navigation error');
    }
  }

  // Get the page title after successful navigation
  if (result.stopReason !== 'error' && !result.file) {
    try {
      result.title = await page.title();
    } catch (error: any) {
      // result.error = '[Puppeteer] ' + (error?.message || error?.toString() || 'Unknown title error');
    }
  }

  // transform the content of the page as text
  try {
    if (result.stopReason !== 'error' && !result.file) {
      result.content = {};
      for (const transform of transforms) {
        switch (transform) {
          case 'html':
            result.content.html = cleanHtml(await page.content());
            break;
          case 'text':
            result.content.text = await page.evaluate(() => document.body.innerText || document.textContent || '');
            break;
          case 'markdown':
            const html = await page.content();
            const cleanedHtml = cleanHtml(html);
            const turndownService = new TurndownService({ headingStyle: 'atx' });
            result.content.markdown = turndownService.turndown(cleanedHtml);
            break;
        }
      }
      if (!Object.keys(result.content).length)
        result.error = '[Puppeteer] Empty content';
    }
  } catch (error: any) {
    result.error = '[Puppeteer] ' + (error?.message || error?.toString() || 'Unknown content error');
  }

  // get a screenshot of the page
  try {
    if (screenshotOptions?.width && screenshotOptions?.height && !result.file) {
      const { width, height, quality } = screenshotOptions;
      const scale = Math.round(100 * width / 1024) / 100;

      await page.setViewport({
        width: width / scale,
        height: height / scale,
        deviceScaleFactor: scale,
      });

      const imageType: ScreenshotOptions['type'] = 'webp';
      const mimeType = `image/${imageType}`;

      const dataString = await page.screenshot({
        type: imageType,
        encoding: 'base64',
        clip: { x: 0, y: 0, width: width / scale, height: height / scale },
        ...(quality && { quality }),
      }) as string;

      result.screenshot = {
        imgDataUrl: `data:${mimeType};base64,${dataString}`,
        mimeType,
        width,
        height,
      };
    }
  } catch (error: any) {
    console.error('workerPuppeteer: page.screenshot', error);
  }

  // Cleanup: close everything in reverse order
  await page.close().catch((error) =>
    console.error('workerPuppeteer: page.close error', { error }));

  if (incognitoContext) await incognitoContext.close().catch((error) =>
    console.error('workerPuppeteer: context.close error', { error }));

  if (!isLocalBrowser) await browser.disconnect().catch((error) =>
    console.error('workerPuppeteer: browser.disconnect error', { error }));
  else await browser.close().catch((error) =>
    console.error('workerPuppeteer: browser.close error', { error }));

  return result;
}


function cleanHtml(html: string): string {
  try {
    const _C = cheerioLoad(html);

    // 1. --unwanted elements
    const unwantedSelectors = [
      // core unwanted
      'script', 'style', 'link', 'noscript', 'iframe', 'svg', 'canvas',

      // navigation and structural elements
      'nav:not(main nav)', 'aside', 'footer:not(article footer)',

      // common web clutter
      '.ad, .ads, .advertisement, .banner, .popup, .modal, .overlay',
      '.cookie-banner, .newsletter-signup, .social-share, .comments',
      '.sidebar, .widget, .carousel, .slider',

      // hidden elements
      '[aria-hidden="true"]',
      '[hidden]',
      '[style*="display: none"]',
      '[style*="visibility: hidden"]',

      // tracking and analytics
      '[data-analytics]',
      '[data-tracking]',
      '[data-gtm]',

      // meta elements except essential ones
      'meta:not([charset], [name="viewport"], [name="description"])',
    ].join(', ');
    _C(unwantedSelectors).remove();

    // 2. --unwanted attributes tag-specific
    const tagSpecificAttrs: Record<string, string[]> = {
      a: ['href', 'title', 'rel'],
      img: ['src', 'alt', 'title', 'width', 'height'],
      video: ['src', 'controls', 'width', 'height'],
      audio: ['src', 'controls'],
      source: ['src', 'type'],
      meta: ['charset', 'name', 'content', 'viewport'],
      time: ['datetime'],
      input: ['type', 'name', 'value', 'checked', 'disabled'],
      button: ['type', 'disabled'],
      th: ['scope', 'colspan', 'rowspan'],
      td: ['colspan', 'rowspan'],
      table: ['summary'],
      figure: ['role'],
      figcaption: [],
    };
    const commonAttrs = ['id', 'lang'];
    _C('*').each(function() {
      const el = _C(this);
      if (!('tagName' in this)) return;
      const tagName = this.tagName?.toLowerCase() || '';

      // Get allowed attributes for this tag
      const allowedAttrs = new Set([
        ...(tagSpecificAttrs[tagName] || []),
        ...commonAttrs,
      ]);

      // -all non-allowed attributes
      const attribs = Object.keys(this.attribs || {});
      attribs.forEach(attr => {
        if (!allowedAttrs.has(attr.toLowerCase()))
          el.removeAttr(attr);
      });

      // cleanup href attributes on anchors
      if (tagName === 'a') {
        const href = el.attr('href');
        if (href) {
          // -javascript: links
          if (href.toLowerCase().startsWith('javascript:'))
            el.removeAttr('href');
          // -tracking parameters
          else if (href.includes('?')) {
            try {
              const url = new URL(href);
              const cleanParams = new URLSearchParams();
              url.searchParams.forEach((value, key) => {
                // keep only essential query parameters
                if (!key.match(/^(utm_|fbclid|gclid|msclkid)/i))
                  cleanParams.append(key, value);
              });
              const cleanHref = `${url.origin}${url.pathname}${
                cleanParams.toString() ? '?' + cleanParams.toString() : ''
              }${url.hash}`;
              el.attr('href', cleanHref);
            } catch (e) {
              // If URL parsing fails, keep original href
            }
          }
        }
      }
    });

    // 3. --comments
    _C('*').contents().filter(function() {
      return this.type === 'comment';
    }).remove();

    // 4. --empty element
    const preserveTags = new Set([
      'img', 'br', 'hr', 'input', 'source', 'meta', 'link',
      'area', 'base', 'col', 'embed', 'param', 'track', 'wbr',
    ]);
    _C('*').each(function() {
      const $el = _C(this);
      if (!('tagName' in this)) return;
      const tagName = this.tagName?.toLowerCase() || '';
      const hasContent =
        $el.text().trim() ||
        $el.find('img, video, audio, iframe, canvas, svg').length ||
        preserveTags.has(tagName) ||
        (tagName === 'a' && $el.attr('href'));

      if (!hasContent && !$el.children().length)
        $el.remove();
    });

    // 5. simplify nested structure
    _C('div > div:only-child, section > section:only-child').each(function() {
      const $parent = _C(this).parent();
      if ($parent.children().length === 1)
        $parent.replaceWith(_C(this));
    });

    // 6. div to paragraph conversion
    _C('div').each(function() {
      const $div = _C(this);
      const hasBlockElements = $div.children('div, p, section, article, aside, header, footer, nav').length > 0;
      if (!hasBlockElements && $div.text().trim())
        $div.replaceWith(`<p>${$div.html()}</p>`);
    });

    // 7. clean up whitespace
    _C('*').each(function() {
      if (this.type === 'text') {
        const text = _C(this).text().trim().replace(/\s+/g, ' ');
        if (text) _C(this).text(text);
      }
    });

    // 8. format final output
    return _C.html()
      .replace(/>\s+</g, '>\n<')
      .replace(/\n\s+/g, '\n')
      .replace(/^\s+|\s+$/gm, '')
      .replace(/\n{3,}/g, '\n\n')
      .trim();

  } catch (error) {
    console.error('HTML cleaning error:', error);
    return html; // Return original if cleaning fails
  }
}


================================================
FILE: src/modules/browse/BrowseSettings.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Checkbox, FormControl, FormHelperText, FormLabel, Option, Select, Typography } from '@mui/joy';

import { AlreadySet } from '~/common/components/AlreadySet';
import { ExternalLink } from '~/common/components/ExternalLink';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { platformAwareKeystrokes } from '~/common/components/KeyStroke';

import { useBrowseCapability, useBrowseStore } from './store-module-browsing';


const _styleHelperText = {
  fontSize: 'xs',
} as const;


export function BrowseSettings() {

  // external state
  const { mayWork, isServerConfig, isClientValid, inComposer, inReact, inPersonas } = useBrowseCapability();
  const {
    wssEndpoint, setWssEndpoint,
    pageTransform, setPageTransform,
    setEnableComposerAttach, setEnableReactTool, setEnablePersonaTool,
  } = useBrowseStore(useShallow(state => ({
    wssEndpoint: state.wssEndpoint,
    pageTransform: state.pageTransform,
    setPageTransform: state.setPageTransform,
    setWssEndpoint: state.setWssEndpoint,
    setEnableComposerAttach: state.setEnableComposerAttach,
    setEnableReactTool: state.setEnableReactTool,
    setEnablePersonaTool: state.setEnablePersonaTool,
  })));

  const handlePageTransformChange = (_event: any, value: typeof pageTransform | null) => value && setPageTransform(value);


  return <>

    <Typography level='body-sm'>
      Enables downloading of web pages. <ExternalLink href='https://big-agi.com/docs/config-feature-browse'>Learn more</ExternalLink>.<br />
      <b>Web Search</b> is configured separately and requires a Google API key.
      {/*Web Browser lets the AI visit and analyze web pages in real-time. <ExternalLink href='https://big-agi.com/docs/config-feature-browse'>Learn more about setup</ExternalLink>.*/}
    </Typography>

    <FormInputKey
      autoCompleteId='browse-wss' label='Puppeteer Wss' noKey
      value={wssEndpoint} onChange={setWssEndpoint}
      rightLabel={<AlreadySet required={!isServerConfig} />}
      required={!isServerConfig} isError={!isClientValid && !isServerConfig}
      placeholder='wss://...'
    />


    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Web page to LLM' description={pageTransform === 'text' ? 'Converts to text' : pageTransform === 'markdown' ? 'Converts to markdown' : 'Preserves HTML (heavy)'} />
      <Select
        variant='outlined'
        value={pageTransform} onChange={handlePageTransformChange}
        slotProps={{
          root: { sx: { minWidth: '140px' } },
          indicator: { sx: { opacity: 0.5 } },
          button: { sx: { whiteSpace: 'inherit' } },
        }}
      >
        <Option value='text'>Text (default)</Option>
        <Option value='markdown'>Markdown</Option>
        <Option value='html'>HTML</Option>
      </Select>
    </FormControl>


    <FormLabel>Enable page loading for:</FormLabel>

    <FormControl disabled={!mayWork}>
      <Checkbox size='sm' label='Attachments' checked={inComposer} onChange={(event) => setEnableComposerAttach(event.target.checked)} />
      <FormHelperText sx={_styleHelperText}>{platformAwareKeystrokes('Load and attach when pasting a URL')}</FormHelperText>
    </FormControl>

    <FormControl disabled={!mayWork}>
      <Checkbox size='sm' label='ReAct' checked={inReact} onChange={(event) => setEnableReactTool(event.target.checked)} />
      <FormHelperText sx={_styleHelperText}>Enables loadURL() in ReAct</FormHelperText>
    </FormControl>

    <FormControl disabled>
      <Checkbox size='sm' label='Personas browsing tool' checked={false} onChange={(event) => setEnablePersonaTool(event.target.checked)} />
      <FormHelperText sx={_styleHelperText}>Coming soon</FormHelperText>
      {/*<FormHelperText sx={_styleHelperText}>Enable loading URLs by Personas</FormHelperText>*/}
    </FormControl>

  </>;
}


================================================
FILE: src/modules/browse/store-module-browsing.tsx
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

import { CapabilityBrowsing } from '~/common/components/useCapabilities';
import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';


export type BrowsePageTransform = 'html' | 'text' | 'markdown';

interface BrowseState {

  wssEndpoint: string;
  setWssEndpoint: (url: string) => void;

  pageTransform: BrowsePageTransform;
  setPageTransform: (transform: BrowsePageTransform) => void;

  enableComposerAttach: boolean;
  setEnableComposerAttach: (value: boolean) => void;

  enableReactTool: boolean;
  setEnableReactTool: (value: boolean) => void;

  enablePersonaTool: boolean;
  setEnablePersonaTool: (value: boolean) => void;

}

export const useBrowseStore = create<BrowseState>()(
  persist(
    (set) => ({

      wssEndpoint: '', // default WSS endpoint
      setWssEndpoint: (wssEndpoint: string) => set(() => ({ wssEndpoint })),

      pageTransform: 'text',
      setPageTransform: (pageTransform: BrowsePageTransform) => set(() => ({ pageTransform })),

      enableComposerAttach: true,
      setEnableComposerAttach: (enableComposerAttach: boolean) => set(() => ({ enableComposerAttach })),

      enableReactTool: true,
      setEnableReactTool: (enableReactTool: boolean) => set(() => ({ enableReactTool })),

      enablePersonaTool: true,
      setEnablePersonaTool: (enablePersonaTool: boolean) => set(() => ({ enablePersonaTool })),

    }),
    {
      name: 'app-module-browse',
    },
  ),
);


export function useBrowseCapability(): CapabilityBrowsing {
  // server config
  const isServerConfig = getBackendCapabilities().hasBrowsing;

  // external client state
  const { wssEndpoint, enableComposerAttach, enableReactTool, enablePersonaTool } = useBrowseStore();

  // derived state
  const isClientConfig = !!wssEndpoint;
  const isClientValid = (wssEndpoint?.startsWith('wss://') && wssEndpoint?.length > 10) || (wssEndpoint?.startsWith('ws://') && wssEndpoint?.length > 9);
  const mayWork = isServerConfig || (isClientConfig && isClientValid);

  return {
    mayWork,
    isServerConfig,
    isClientConfig,
    isClientValid,
    inComposer: mayWork && enableComposerAttach,
    inReact: mayWork && enableReactTool,
    inPersonas: mayWork && enablePersonaTool,
  };
}


================================================
FILE: src/modules/dblobs/dblobs.db.ts
================================================
import Dexie from 'dexie';

import type { DBlobAsset, DBlobAssetId, DBlobAssetType, DBlobDBAsset, DBlobDBContextId, DBlobDBScopeId } from './dblobs.types';


/**
 * Dexie DB for Big-AGI
 * - assets: we store large assets like images/audio/video/documents...
 *
 * [DEV NOTE] To delete the full DB (don't do it!):
 * - indexedDB.deleteDatabase('NAME').onsuccess = console.log;
 *
 * [DEV NOTE] This is related to storageUtils.ts's requestPersistentStorage,
 * aswe need to request persistent storage for the current origin, sot that
 * indexedDB's content is not evicted.
 */
class BigAgiDB extends Dexie {
  largeAssets!: Dexie.Table<DBlobDBAsset, string>;

  constructor() {
    super('Big-AGI');
    this.version(1).stores({
      // Index common properties (and compound indexes)
      largeAssets: 'id, [contextId+scopeId], assetType, [assetType+contextId+scopeId], data.mimeType, origin.ot, origin.source, createdAt, updatedAt',
    });
    // Note: can re-add wId and uId in version 2 if needed
  }
}

// In development mode, reuse the same instance of the DB to avoid re-creating it on every hot reload
const globalForDexie = globalThis as unknown as {
  bigAgiDB: BigAgiDB | undefined;
};

const _db = globalForDexie.bigAgiDB ?? new BigAgiDB();
if (process.env.NODE_ENV !== 'production') globalForDexie.bigAgiDB = _db;

const assetsTable = _db.largeAssets;


// CRUD

export async function _addDBAsset<T extends DBlobAsset>(asset: T, contextId: DBlobDBContextId, scopeId: DBlobDBScopeId): Promise<DBlobAssetId> {
  try {
    // returns the id of the added asset
    return await assetsTable.add({
      ...asset,
      contextId,
      scopeId,
    });
  } catch (error) {
    console.error('addDBAsset: Error adding asset', error);
    throw error;
  }
}


// READ

// export async function getDBlobAssetIds(): Promise<DBlobAssetId[]> {
//   return assetsTable.toCollection().primaryKeys();
// }

// async function _getDBlobAssetIdsByScope(contextId: DBlobDBContextId, scopeId: DBlobDBScopeId): Promise<DBlobAssetId[]> {
//   return assetsTable.where({
//     contextId: contextId,
//     scopeId: scopeId,
//   }).primaryKeys();
// }

export async function getDBAsset<T extends DBlobAsset = DBlobDBAsset>(id: DBlobAssetId) {
  return await assetsTable.get(id) as T | undefined;
}

/**
 * Warning: this function all the matching assets data in memory - not suitable for large datasets.
 */
// export async function getDBAssetsByType<T extends DBlobAsset = DBlobDBAsset>(assetType: T['assetType']) {
//   return await assetsTable.where({
//     assetType: assetType,
//   }).toArray() as unknown as T[];
// }

/**
 * Warning: this function all the matching assets data in memory - not suitable for large datasets.
 */
export async function getDBAssetsByScopeAndType<T extends DBlobAsset = DBlobDBAsset>(assetType: T['assetType'], contextId: DBlobDBContextId, scopeId: DBlobDBScopeId) {
  const assets = await assetsTable.where({
    assetType: assetType, contextId: contextId, scopeId: scopeId,
  }).sortBy('createdAt');
  return assets.reverse() as unknown as T[];
}


// UPDATE

async function _updateDBAsset<T extends DBlobDBAsset = DBlobDBAsset>(id: DBlobAssetId, updates: Partial<T>) {
  return assetsTable.update(id, updates);
}

export async function transferDBAssetContextScope(id: DBlobAssetId, contextId: DBlobDBContextId, scopeId: DBlobDBScopeId) {
  await _updateDBAsset(id, { contextId, scopeId });
}


// DELETE

export async function deleteDBAsset(id: DBlobAssetId) {
  return assetsTable.delete(id);
}

// export async function deleteDBAssets(ids: DBlobAssetId[]) {
//   return assetsTable.bulkDelete(ids);
// }

// export async function deleteAllScopedAssets(contextId: DBlobDBContextId, scopeId: DBlobDBScopeId) {
//   return (contextId && scopeId) ? assetsTable.where({
//     contextId: contextId,
//     scopeId: scopeId,
//   }).delete() : 0;
// }

export async function gcDBAssetsByScope(contextId: DBlobDBContextId, scopeId: DBlobDBScopeId, assetType: DBlobAssetType | null, keepIds: DBlobAssetId[]) {
  // get all the DB keys
  const dbAssetIds = await assetsTable.where((assetType !== null) ? {
    assetType: assetType,
    contextId: contextId,
    scopeId: scopeId,
  } : {
    contextId: contextId,
    scopeId: scopeId,
  }).primaryKeys();

  // find the unreferenced keys
  const unreferencedAssetIds = keepIds.length ? dbAssetIds.filter(id => !keepIds.includes(id)) : dbAssetIds;

  // delete the unreferenced keys
  if (unreferencedAssetIds.length > 0)
    await assetsTable.bulkDelete(unreferencedAssetIds);
}



================================================
FILE: src/modules/dblobs/dblobs.hooks.ts
================================================
import { useLiveQuery } from 'dexie-react-hooks';

import type { DBlobAsset, DBlobAssetId, DBlobDBAsset, DBlobDBContextId, DBlobDBScopeId } from './dblobs.types';
import { getDBAsset, getDBAssetsByScopeAndType } from './dblobs.db';


// export function useDBlobItems<T extends DBlobItem>(assetType: T['assetType']): [T[] | undefined, (item: T, contextId: DBlobDBContextId, scopeId: DBlobDBScopeId) => Promise<void>, (id: DBlobAssetId) => Promise<void>] {
//   const items = useLiveQuery(() => getAssetsByType<T>(assetType), [assetType]);
//
//   const addDBlobItemHandler = async (item: T, contextId: DBlobDBContextId, scopeId: DBlobDBScopeId) => {
//     await addDBlobItem(item, contextId, scopeId);
//   };
//
//   const deleteDBlobItemHandler = async (id: DBlobAssetId) => {
//     await deleteDBlobItem(id);
//   };
//
//   return [items, addDBlobItemHandler, deleteDBlobItemHandler];
// }

/**
 * Warning - this function will load all data in memory and will be incredibly slow for large datasets.
 * TODO: convert to an index + cursor based approach
 */
export function useDBAssetsByScopeAndType<TAsset extends DBlobAsset = DBlobDBAsset>(
  assetType: TAsset['assetType'],
  contextId: DBlobDBContextId,
  scopeId: DBlobDBScopeId,
): [TAsset[] | undefined, /*(item: TAsset, contextId: DBlobDBContextId, scopeId: DBlobDBScopeId) => Promise<DBlobAssetId>, (id: DBlobAssetId) => Promise<void>*/] {
  const items = useLiveQuery(
    () => getDBAssetsByScopeAndType<TAsset>(assetType, contextId, scopeId),
    [assetType, contextId, scopeId],
  );

  // const addDBlobItemHandler = async (item: TAsset, contextId: DBlobDBContextId, scopeId: DBlobDBScopeId): Promise<DBlobAssetId> => {
  //   return await addDBAsset(item, contextId, scopeId);
  // };

  // const deleteDBlobItemHandler = async (id: DBlobAssetId) => {
  //   await deleteDBAsset(id);
  // };

  return [items];
}


export function useDBAsset<T extends DBlobAsset = DBlobDBAsset>(id: DBlobAssetId): [T | undefined /*, (updates: Partial<T>) => Promise<void>*/] {
  const item = useLiveQuery(
    () => getDBAsset<T>(id),
    [id],
  );

  // const updateDBlobItemHandler = async (updates: Partial<T>) => {
  //   await updateDBAsset(id, updates);
  // };

  return [item /*, updateDBlobItemHandler */];
}

// example custom
// export function useHighResImages(): DBlobImageItem[] | undefined {
//   return useLiveQuery(() => getHighResImages());
// }


================================================
FILE: src/modules/dblobs/dblobs.images.ts
================================================
import { Is } from '~/common/util/pwaUtils';
import { convert_Base64WithMimeType_To_Blob, convert_Blob_To_Base64 } from '~/common/util/blobUtils';
import { imageBlobResizeIfNeeded } from '~/common/util/imageUtils';

import { _addDBAsset, gcDBAssetsByScope, getDBAsset } from './dblobs.db';
import { _createAssetObject, DBlobAssetId, DBlobAssetType, DBlobDBContextId, DBlobDBScopeId, DBlobImageAsset, DBlobMimeType } from './dblobs.types';


// configuration
const THUMBNAIL_ENCODING_MIMETYPE = !Is.Browser.Safari ? DBlobMimeType.IMG_WEBP : DBlobMimeType.IMG_JPEG;
const THUMBNAIL_ENCODING_LOSSY_QUALITY = 0.9; // 90% quality for JPEG/WEBP thumbnails


export async function addDBImageAsset(
  scopeId: DBlobDBScopeId,
  imageBlob: Blob,
  image: {
    label: string,
    origin: DBlobImageAsset['origin'],
    metadata: DBlobImageAsset['metadata'],
  },
): Promise<DBlobAssetId> {

  // Blob -> base64
  const base64Data = await convert_Blob_To_Base64(imageBlob, 'addDBImageAsset');
  const imageType = imageBlob.type; // We assume the mime type is supported

  const assetData: DBlobImageAsset['data'] = {
    base64: base64Data,
    mimeType: imageType as any,
  };

  // create the image asset object
  const imageAsset = _createAssetObject(
    DBlobAssetType.IMAGE,
    image.label,
    assetData,
    image.origin,
    image.metadata,
  );


  // Auto-Thumbnail: when adding an image, generate a thumbnail-256 cache level
  if (!imageAsset.cache?.thumb256) {
    try {
      // create a thumbnail-256 from the image
      const resizedDataForCache = await imageBlobResizeIfNeeded(
        imageBlob,
        'thumbnail-256',
        THUMBNAIL_ENCODING_MIMETYPE,
        THUMBNAIL_ENCODING_LOSSY_QUALITY,
      );

      // set the cached data
      if (resizedDataForCache) {
        const thumbBase64Data = await convert_Blob_To_Base64(resizedDataForCache.blob, 'addDBImageAsset.thumb256');
        imageAsset.cache = {
          ...imageAsset.cache, // ensure we don't overwrite existing cache levels
          thumb256: {
            base64: thumbBase64Data,
            mimeType: THUMBNAIL_ENCODING_MIMETYPE,
          },
        };
      }

    } catch (thumbnailError) {
      console.warn('[DEV] addDBImageAsset: Error creating thumbnail-256', thumbnailError);
      // ignore error, this is not critical
    }
  }

  // DB add
  return _addDBAsset<typeof imageAsset>(imageAsset, 'global', scopeId);
}


// R

// async function getAllImages() {
//   return await getDBAssetsByType<DBlobImageAsset>(DBlobAssetType.IMAGE);
// }

export async function getImageAsset(id: DBlobAssetId) {
  return await getDBAsset<DBlobImageAsset>(id);
}

export async function getImageAssetAsBlobURL(id: DBlobAssetId) {
  const imageAsset = await getImageAsset(id);
  if (!imageAsset) return null;
  try {
    const imageBlob = await convert_Base64WithMimeType_To_Blob(imageAsset.data.base64, imageAsset.data.mimeType, 'getImageAssetAsBlobURL');
    return URL.createObjectURL(imageBlob);
  } catch (error) {
    console.warn('[DEV] getImageAssetAsBlobURL: Failed to convert image data to Blob.', error);
    return null;
  }
}

// export async function getImageAssetAsDataURL(id: DBlobAssetId) {
//   const imageAsset = await getImageAsset(id);
//   return imageAsset ? `data:${imageAsset.data.mimeType};base64,${imageAsset.data.base64}` : null;
// }


// U


// D

export async function gcDBImageAssets(contextId: DBlobDBContextId, scopeId: DBlobDBScopeId, keepIds: DBlobAssetId[]) {
  await gcDBAssetsByScope(contextId, scopeId, DBlobAssetType.IMAGE, keepIds);
}



================================================
FILE: src/modules/dblobs/dblobs.types.ts
================================================
import { agiUuid } from '~/common/util/idUtils';


// DB - Assets

/**
 * This is the asset when stored/loaded in the DB. Carries some more context out of band from the asset itself.
 */
export type DBlobDBAsset = {
  contextId: DBlobDBContextId;
  scopeId: DBlobDBScopeId;
} & DBlobAsset;

export type DBlobDBContextId = 'global';
export type DBlobDBScopeId = 'app-chat' | 'app-draw' | 'attachment-drafts';


// Assets

export type DBlobAsset = DBlobImageAsset | DBlobAudioAsset; // | DBlobVideoAsset | DBlobDocumentAsset | DBlobTextAsset;

export type DBlobImageAsset = DBlobAssetImplV1<
  /* assetType: */ DBlobAssetType.IMAGE,
  /* data: <mime> */ DBlobMimeType.IMG_PNG | DBlobMimeType.IMG_JPEG | DBlobMimeType.IMG_WEBP,
  /* metadata: */ ImageAssetMetadata
>;

export type DBlobAudioAsset = DBlobAssetImplV1<
  /* assetType: */ DBlobAssetType.AUDIO,
  /* data: <mime> */ DBlobMimeType.AUDIO_MPEG | DBlobMimeType.AUDIO_WAV,
  /* metadata: */ AudioAssetMetadata
>;

// type DBlobVideoAsset = DBlobAssetImplV1<DBlobAssetType.VIDEO, DBlobDataMimeType.VIDEO_MP4, VideoAssetMetadata>;
// type DBlobDocumentAsset = DBlobAssetImplV1<DBlobAssetType.DOCUMENT, DBlobDataMimeType.DOCUMENT_PDF, DocumentAssetMetadata>;
// type DBlobTextAsset = DBlobAssetImplV1<DBlobAssetType.TEXT, DBlobDataMimeType.DOCUMENT_PLAIN, {}>;


// DB - Asset Generic Type

interface DBlobAssetImplV1<TAssetType extends DBlobAssetType, TMime extends DBlobMimeType, TMeta extends Record<string, any>> {
  id: DBlobAssetId; // Unique identifier
  assetType: TAssetType; // Type of asset, used for discrimination

  label: string; // Textual representation
  data: DBlobAssetData<TMime>; // Original data as a BlobData object
  origin: DBlobAssetOrigin; // Source of the data (e.g., "upload", "generated")

  createdAt: Date; // Creation date
  updatedAt: Date; // Last updated date

  metadata: TMeta; // Flexible metadata for specific .type(s)
  // cache: Record<string, DBlobData<DBlobMimeType>>; // Cached conversions as BlobData objects
  cache: {
    thumb256?: DBlobAssetData<DBlobMimeType.IMG_WEBP | DBlobMimeType.IMG_JPEG>; // Cache for the thumbnail-256 conversion
  };
}

export type DBlobAssetId = string;

export enum DBlobAssetType {
  IMAGE = 'image',
  AUDIO = 'audio',
  // VIDEO = 'video',
  // DOCUMENT = 'document',
  // EGO = 'ego',
}


// Asset Data

interface DBlobAssetData<M extends DBlobMimeType> {
  mimeType: M;
  base64: string; // Base64 encoded content (not a data URL)
  // NOTE: the data url will be "data:${mimeType};base64,${base64}"
  // size?: number; // Size in bytes (optional)
  // altMimeType?: DBlobMimeType; // Alternative MIME type for the input (optional)
  // altData?: string; // Alternative data for the input (optional)
}

export enum DBlobMimeType {
  IMG_PNG = 'image/png', IMG_JPEG = 'image/jpeg', IMG_WEBP = 'image/webp',
  AUDIO_MPEG = 'audio/mpeg', AUDIO_WAV = 'audio/wav',
  // VIDEO_MP4 = 'video/mp4',
  // DOCUMENT_PDF = 'application/pdf', DOCUMENT_PLAIN = 'text/plain', DOCUMENT_HTML = 'text/html',
}


// Asset Origin

type DBlobAssetOrigin = UserOrigin | GeneratedOrigin;

interface UserOrigin {
  ot: 'user';
  source: 'attachment'; // 'attachment' | 'message' | 'note' | 'task' | 'event' | 'contact' | 'file' | 'url' | 'text' | 'ego'..
  media: string; // file: 'camera' | 'screencapture' | 'file-open' | 'clipboard-read' | 'drop' | 'paste',  url: 'url',  'unknown'
  url?: string;
  fileName?: string;
  // fileSize?: number; // Size of the uploaded file (optional)
  // fileType?: string; // Type of the uploaded file (optional)
  // attachmentMessageId?: string; // ID of the message that the attachment is associated with (optional)
}

interface GeneratedOrigin {
  ot: 'generated';
  source: 'ai-text-to-image';
  generatorName: string;
  prompt: string; // Prompt used for generation
  parameters: { [key: string]: any }; // Parameters used for generation
  generatedAt?: string; // When was generated (optional ISO date)
}

/*interface UrlOrigin {
  source: 'url';
  dir: OriginDirection;
  url: string; // URL of the source
  // refUrl: string; // Reference URL
  fetchedAt?: string; // When the URL was fetched (optional ISO date)
}

interface FileOrigin {
  source: 'file';
  dir: OriginDirection;
  filePath: string;
  fileLastModifiedAt?: string; // Modified date of the file (optional ISO date)
}

interface TextOrigin {
  source: 'text';
  dir: OriginDirection;
  method: 'clipboard-read' | 'drop' | 'paste';
  textPlain?: string; // Plain text content (optional)
  textHtml?: string; // HTML text content (optional)
  capturedAt?: string; // Time when the text was captured (optional ISO date)
}

interface EgoOrigin {
  dir: OriginDirection;
  source: 'ego';
  label: string; // Label for the ego message
  blockTitle: string; // Title of the block
  textPlain: string; // Plain text content
  messageId?: string; // ID of the message (optional)
}*/


// Asset Metadata

interface ImageAssetMetadata {
  width: number;
  height: number;
  averageColor?: string; // Average html color of the image (optional)
  author?: string; // Author of the image (optional)
  tags?: string[]; // Tags associated with the image (optional)
  description?: string; // Description of the image (optional)
}

interface AudioAssetMetadata {
  duration: number; // Duration in seconds
  sampleRate: number; // Sample rate of the audio
  bitrate?: number; // Bitrate of the audio (optional)
  channels?: number; // Number of audio channels (optional)
  // artist?: string; // Artist of the audio (optional)
  // album?: string; // Album of the audio (optional)
  // genre?: string; // Genre of the audio (optional)
}

/*interface VideoMetadata {
  width: number;
  height: number;
  duration: number; // Duration in seconds
  frameRate?: number; // Frame rate of the video (optional)
  bitrate?: number; // Bitrate of the video (optional)
  codec?: string; // Codec used for the video (optional)
  // director?: string; // Director of the video (optional)
  // cast?: string[]; // Cast members of the video (optional)
  // genre?: string; // Genre of the video (optional)
}

interface DocumentMetadata {
  pageCount: number; // Number of pages in the document
  author?: string; // Author of the document (optional)
  title?: string; // Title of the document (optional)
  subject?: string; // Subject of the document (optional)
  keywords?: string[]; // Keywords associated with the document (optional)
}*/


// DB Item Data

export function _createAssetObject<TType extends DBlobAssetType, TMime extends DBlobMimeType, TMeta extends Record<string, any>>(
  assetType: TType,
  label: string,
  data: DBlobAssetData<TMime>,
  origin: DBlobAssetOrigin,
  metadata: TMeta,
): DBlobAssetImplV1<TType, TMime, TMeta> {
  const creationDate = new Date();
  return {
    id: agiUuid('dblob-asset'),
    assetType,
    label,
    data,
    origin,
    createdAt: creationDate,
    updatedAt: creationDate,
    metadata,
    cache: {},
  };
}



================================================
FILE: src/modules/elevenlabs/elevenlabs.client.ts
================================================
import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';

import { AudioLivePlayer } from '~/common/util/audio/AudioLivePlayer';
import { AudioPlayer } from '~/common/util/audio/AudioPlayer';
import { CapabilityElevenLabsSpeechSynthesis } from '~/common/components/useCapabilities';
import { apiStream } from '~/common/util/trpc.client';
import { convert_Base64_To_UInt8Array } from '~/common/util/blobUtils';
import { useUIPreferencesStore } from '~/common/stores/store-ui';

import { getElevenLabsData, useElevenLabsData } from './store-module-elevenlabs';


export const isValidElevenLabsApiKey = (apiKey?: string) => !!apiKey && apiKey.trim()?.length >= 32;

export const isElevenLabsEnabled = (apiKey?: string) =>
  apiKey ? isValidElevenLabsApiKey(apiKey)
    : getBackendCapabilities().hasVoiceElevenLabs;


export function useCapability(): CapabilityElevenLabsSpeechSynthesis {
  const [clientApiKey, voiceId] = useElevenLabsData();
  const isConfiguredServerSide = getBackendCapabilities().hasVoiceElevenLabs;
  const isConfiguredClientSide = clientApiKey ? isValidElevenLabsApiKey(clientApiKey) : false;
  const mayWork = isConfiguredServerSide || isConfiguredClientSide || !!voiceId;
  return { mayWork, isConfiguredServerSide, isConfiguredClientSide };
}


interface ElevenLabsSpeakResult {
  success: boolean;
  audioBase64?: string; // Available when not streaming
}


/**
 * Speaks text using ElevenLabs TTS
 * @returns Object with success status and optionally the audio base64 (when not streaming)
 */
export async function elevenLabsSpeakText(text: string, voiceId: string | undefined, audioStreaming: boolean, audioTurbo: boolean): Promise<ElevenLabsSpeakResult> {
  // Early validation
  if (!(text?.trim())) {
    // console.log('ElevenLabs: No text to speak');
    return { success: false };
  }

  const { elevenLabsApiKey, elevenLabsVoiceId } = getElevenLabsData();
  if (!isElevenLabsEnabled(elevenLabsApiKey)) {
    // console.warn('ElevenLabs: Service not enabled or configured');
    return { success: false };
  }

  const { preferredLanguage } = useUIPreferencesStore.getState();
  const nonEnglish = !(preferredLanguage?.toLowerCase()?.startsWith('en'));

  // audio live player instance, if needed
  let liveAudioPlayer: AudioLivePlayer | undefined;
  let playbackStarted = false;
  let audioBase64: string | undefined;

  try {

    const stream = await apiStream.elevenlabs.speech.mutate({
      xiKey: elevenLabsApiKey,
      voiceId: voiceId || elevenLabsVoiceId,
      text: text,
      nonEnglish,
      audioStreaming,
      audioTurbo,
    });

    for await (const piece of stream) {

      // ElevenLabs stream buffer
      if (piece.audioChunk) {
        try {
          // create the live audio player as needed
          // NOTE: in the future we can have a centralized audio playing system
          if (!liveAudioPlayer)
            liveAudioPlayer = new AudioLivePlayer();

          // enqueue a decoded audio chunk - this will throw on malformed base64 data
          const chunkArray = convert_Base64_To_UInt8Array(piece.audioChunk.base64, 'elevenLabsSpeakText (chunk)');
          liveAudioPlayer.enqueueChunk(chunkArray.buffer);
          playbackStarted = true;
        } catch (audioError) {
          console.error('ElevenLabs audio chunk error:', audioError);
          return { success: false };
        }
      }

      // ElevenLabs full audio buffer
      else if (piece.audio) {
        try {
          // return base64 for potential reuse
          if (!audioStreaming)
            audioBase64 = piece.audio.base64;

          // also consider merging LiveAudioPlayer into AudioPlayer - note this will throw on malformed base64 data
          const audioArray = convert_Base64_To_UInt8Array(piece.audio.base64, 'elevenLabsSpeakText');
          void AudioPlayer.playBuffer(audioArray.buffer); // fire/forget - it's a single piece of audio (could be long tho)
          playbackStarted = true;
        } catch (audioError) {
          console.error('ElevenLabs audio buffer error:', audioError);
          return { success: false };
        }
      }

      // Errors
      else if (piece.errorMessage) {
        console.error('ElevenLabs error:', piece.errorMessage);
        return { success: false };
      } else if (piece.warningMessage) {
        console.warn('ElevenLabs warning:', piece.warningMessage);
        // Continue processing warnings
      } else if (piece.control === 'start' || piece.control === 'end') {
        // Control messages - continue processing
      } else {
        console.log('ElevenLabs unknown piece:', piece);
      }
    }
    return { success: playbackStarted, audioBase64 };
  } catch (error) {
    console.error('ElevenLabs playback error:', error);
    return { success: false };
  }
}



================================================
FILE: src/modules/elevenlabs/elevenlabs.router.ts
================================================
import * as z from 'zod/v4';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { env } from '~/server/env';
import { fetchJsonOrTRPCThrow, fetchResponseOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';


// configuration
const SAFETY_TEXT_LENGTH = 1000;
const MIN_CHUNK_SIZE = 4096; // Minimum chunk size in bytes


// Schema definitions
export type SpeechInputSchema = z.infer<typeof speechInputSchema>;
export const speechInputSchema = z.object({
  xiKey: z.string().optional(),
  voiceId: z.string().optional(),
  text: z.string(),
  nonEnglish: z.boolean(),
  audioStreaming: z.boolean(),
  audioTurbo: z.boolean(),
});

export type VoiceSchema = z.infer<typeof voiceSchema>;
const voiceSchema = z.object({
  id: z.string(),
  name: z.string(),
  description: z.string().nullable(),
  previewUrl: z.string().nullable(),
  category: z.string(),
  default: z.boolean(),
});


export const elevenlabsRouter = createTRPCRouter({

  /**
   * List Voices available to this API key
   */
  listVoices: publicProcedure
    .input(z.object({
      elevenKey: z.string().optional(),
    }))
    .output(z.object({
      voices: z.array(voiceSchema),
    }))
    .query(async ({ input }) => {

      const { elevenKey } = input;
      const { headers, url } = elevenlabsAccess(elevenKey, '/v1/voices');

      const voicesList = await fetchJsonOrTRPCThrow<ElevenlabsWire.VoicesList>({
        url,
        headers,
        name: 'ElevenLabs',
      });

      // bring category != 'premade' to the top
      voicesList.voices.sort((a, b) => {
        if (a.category === 'premade' && b.category !== 'premade') return 1;
        if (a.category !== 'premade' && b.category === 'premade') return -1;
        return 0;
      });

      return {
        voices: voicesList.voices.map((voice, idx) => ({
          id: voice.voice_id,
          name: voice.name,
          description: voice.description,
          previewUrl: voice.preview_url,
          category: voice.category,
          default: idx === 0,
        })),
      };

    }),

  /**
   * Speech synthesis procedure using tRPC streaming
   */
  speech: publicProcedure
    .input(speechInputSchema)
    .mutation(async function* ({ input: { xiKey, text, voiceId, nonEnglish, audioStreaming, audioTurbo }, ctx }) {

      // start streaming back
      yield { control: 'start' };

      // Safety check: trim text that's too long
      if (text.length > SAFETY_TEXT_LENGTH) {
        text = text.slice(0, SAFETY_TEXT_LENGTH);
        yield { warningMessage: 'text was truncated to maximum length' };
      }

      let response: Response;
      try {

        // Prepare the upstream request
        const path = `/v1/text-to-speech/${elevenlabsVoiceId(voiceId)}${audioStreaming ? '/stream' : ''}`;
        const { headers, url } = elevenlabsAccess(xiKey, path);
        const body: ElevenlabsWire.TTSRequest = {
          text: text,
          model_id:
            audioTurbo ? 'eleven_turbo_v2_5'
              : nonEnglish ? 'eleven_multilingual_v2'
                : 'eleven_multilingual_v2', // even for english, use the latest multilingual model
        };

        // Blocking fetch
        response = await fetchResponseOrTRPCThrow({ url, method: 'POST', headers, body, signal: ctx.reqSignal, name: 'ElevenLabs' });

      } catch (error: any) {
        yield { errorMessage: `fetch issue: ${error.message || 'Unknown error'}` };
        return;
      }

      // Parse headers
      const responseHeaders = _safeParseTTSResponseHeaders(response.headers);

      // If not streaming, return the entire audio
      if (!audioStreaming) {
        const audioArrayBuffer = await response.arrayBuffer();
        yield {
          audio: {
            base64: Buffer.from(audioArrayBuffer).toString('base64'),
            contentType: responseHeaders.contentType,
            characterCost: responseHeaders.characterCost,
            ttsLatencyMs: responseHeaders.ttsLatencyMs,
          },
        };
        yield { control: 'end' };
        return;
      }

      const reader = response.body?.getReader();
      if (!reader) {
        yield { errorMessage: 'stream issue: No reader' };
        return;
      }

      // STREAM the audio chunks back to the client
      try {

        // Initialize a buffer to accumulate chunks
        const accumulatedChunks: Uint8Array[] = [];
        let accumulatedSize = 0;

        // Read loop
        while (true) {
          const { value, done: readerDone } = await reader.read();
          if (readerDone) break;
          if (!value) continue;

          // Accumulate chunks
          accumulatedChunks.push(value);
          accumulatedSize += value.length;

          // When accumulated size reaches or exceeds MIN_CHUNK_SIZE, yield the chunk
          if (accumulatedSize >= MIN_CHUNK_SIZE) {
            yield {
              audioChunk: {
                base64: Buffer.concat(accumulatedChunks).toString('base64'),
              },
            };
            // Reset the accumulation
            accumulatedChunks.length = 0;
            accumulatedSize = 0;
          }
        }

        // If there's any remaining data, yield it as well
        if (accumulatedSize) {
          yield {
            audioChunk: {
              base64: Buffer.concat(accumulatedChunks).toString('base64'),
            },
          };
        }
      } catch (error: any) {
        yield { errorMessage: `stream issue: ${error.message || 'Unknown error'}` };
        return;
      }

      // end streaming (if a control error wasn't thrown)
      yield { control: 'end' };
    }),

});

/**
 * Helper function to construct ElevenLabs API access details
 */
export function elevenlabsAccess(elevenKey: string | undefined, apiPath: string): { headers: HeadersInit; url: string } {
  // API key
  elevenKey = (elevenKey || env.ELEVENLABS_API_KEY || '').trim();
  if (!elevenKey)
    throw new Error('Missing ElevenLabs API key.');

  // API host
  let host = (env.ELEVENLABS_API_HOST || 'api.elevenlabs.io').trim();
  if (!host.startsWith('http'))
    host = `https://${host}`;
  if (host.endsWith('/') && apiPath.startsWith('/'))
    host = host.slice(0, -1);

  return {
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': elevenKey,
    },
    url: host + apiPath,
  };
}

export function elevenlabsVoiceId(voiceId?: string): string {
  return voiceId?.trim() || env.ELEVENLABS_VOICE_ID || '21m00Tcm4TlvDq8ikWAM';
}


function _safeParseTTSResponseHeaders(headers: Headers): ElevenlabsWire.TTSResponseHeaders {
  return {
    contentType: headers.get('content-type') || 'audio/mpeg',
    characterCost: parseInt(headers.get('character-cost') || '0'),
    currentConcurrentRequests: parseInt(headers.get('current-concurrent-requests') || '0'),
    maximumConcurrentRequests: parseInt(headers.get('maximum-concurrent-requests') || '0'),
    ttsLatencyMs: parseInt(headers.get('tts-latency-ms') || '0'),
  };
}


/// This is the upstream API [rev-eng on 2023-04-12]
export namespace ElevenlabsWire {
  export interface TTSRequest {
    text: string;
    model_id?:
      | 'eleven_monolingual_v1'
      | 'eleven_multilingual_v1'
      | 'eleven_multilingual_v2'
      | 'eleven_turbo_v2'
      | 'eleven_turbo_v2_5';
    voice_settings?: {
      stability: number;
      similarity_boost: number;
    };
  }

  export interface TTSResponseHeaders {
    // Response metadata
    contentType: string;                // Should be 'audio/mpeg'

    // Cost and usage metrics
    characterCost: number;               // Cost in characters for this generation
    currentConcurrentRequests: number;   // Current number of concurrent requests
    maximumConcurrentRequests: number;   // Maximum allowed concurrent requests
    ttsLatencyMs?: number;               // Time taken to generate speech (not in streaming mode)
  }

  export interface VoicesList {
    voices: Voice[];
  }

  interface Voice {
    voice_id: string;
    name: string;
    //samples: Sample[];
    category: string;
    // fine_tuning: FineTuning;
    labels: Record<string, string>;
    description: string;
    preview_url: string;
    // available_for_tiers: string[];
    settings: {
      stability: number;
      similarity_boost: number;
    };
  }
}


================================================
FILE: src/modules/elevenlabs/ElevenlabsSettings.tsx
================================================
import * as React from 'react';

import { FormControl } from '@mui/joy';

import { useChatAutoAI } from '../../apps/chat/store-app-chat';

import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormRadioControl } from '~/common/components/forms/FormRadioControl';
import { useCapabilityElevenLabs } from '~/common/components/useCapabilities';

import { isElevenLabsEnabled } from './elevenlabs.client';
import { useElevenLabsVoiceDropdown, useElevenLabsVoices } from './useElevenLabsVoiceDropdown';
import { useElevenLabsApiKey } from './store-module-elevenlabs';


export function ElevenlabsSettings() {

  // state
  const [apiKey, setApiKey] = useElevenLabsApiKey();

  // external state
  const { autoSpeak, setAutoSpeak } = useChatAutoAI();
  const { hasVoices } = useElevenLabsVoices();
  const { isConfiguredServerSide } = useCapabilityElevenLabs();
  const { voicesDropdown } = useElevenLabsVoiceDropdown(true);


  // derived state
  const isValidKey = isElevenLabsEnabled(apiKey);


  return <>

    {/*<FormHelperText>*/}
    {/*  📢 Hear AI responses, even in your own voice*/}
    {/*</FormHelperText>*/}

    <FormRadioControl
      title='Speak Responses'
      description={autoSpeak === 'off' ? 'Off' : 'First paragraph'}
      tooltip={!hasVoices ? 'No voices available, please configure a voice synthesis service' : undefined}
      disabled={!hasVoices}
      options={[
        { value: 'off', label: 'Off' },
        { value: 'firstLine', label: 'Start' },
        { value: 'all', label: 'Full' },
      ]}
      value={autoSpeak} onChange={setAutoSpeak}
    />


    {!isConfiguredServerSide && <FormInputKey
      autoCompleteId='elevenlabs-key' label='ElevenLabs API Key'
      rightLabel={<AlreadySet required={!isConfiguredServerSide} />}
      value={apiKey} onChange={setApiKey}
      required={!isConfiguredServerSide} isError={!isValidKey}
    />}

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Assistant Voice' />
      {voicesDropdown}
    </FormControl>

  </>;
}


================================================
FILE: src/modules/elevenlabs/store-module-elevenlabs.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import { useShallow } from 'zustand/react/shallow';


interface ModuleElevenlabsStore {

  // ElevenLabs Text to Speech settings

  elevenLabsApiKey: string;
  setElevenLabsApiKey: (apiKey: string) => void;

  elevenLabsVoiceId: string;
  setElevenLabsVoiceId: (voiceId: string) => void;

}

const useElevenlabsStore = create<ModuleElevenlabsStore>()(
  persist(
    (set) => ({

      // ElevenLabs Text to Speech settings

      elevenLabsApiKey: '',
      setElevenLabsApiKey: (elevenLabsApiKey: string) => set({ elevenLabsApiKey }),

      elevenLabsVoiceId: '',
      setElevenLabsVoiceId: (elevenLabsVoiceId: string) => set({ elevenLabsVoiceId }),

    }),
    {
      name: 'app-module-elevenlabs',
    }),
);

export const useElevenLabsApiKey = (): [string, (apiKey: string) => void] => {
  const apiKey = useElevenlabsStore(state => state.elevenLabsApiKey);
  return [apiKey, useElevenlabsStore.getState().setElevenLabsApiKey];
};

export const useElevenLabsVoiceId = (): [string, (voiceId: string) => void] => {
  const voiceId = useElevenlabsStore(state => state.elevenLabsVoiceId);
  return [voiceId, useElevenlabsStore.getState().setElevenLabsVoiceId];
};

export const useElevenLabsData = (): [string, string] =>
  useElevenlabsStore(useShallow(state => [state.elevenLabsApiKey, state.elevenLabsVoiceId]));

export const getElevenLabsData = (): { elevenLabsApiKey: string, elevenLabsVoiceId: string } =>
  useElevenlabsStore.getState();



================================================
FILE: src/modules/elevenlabs/useElevenLabsVoiceDropdown.tsx
================================================
import * as React from 'react';

import { CircularProgress, Option, Select } from '@mui/joy';
import KeyboardArrowDownIcon from '@mui/icons-material/KeyboardArrowDown';
import RecordVoiceOverTwoToneIcon from '@mui/icons-material/RecordVoiceOverTwoTone';

import { AudioPlayer } from '~/common/util/audio/AudioPlayer';
import { apiQuery } from '~/common/util/trpc.client';

import { VoiceSchema } from './elevenlabs.router';
import { isElevenLabsEnabled } from './elevenlabs.client';
import { useElevenLabsApiKey, useElevenLabsVoiceId } from './store-module-elevenlabs';


function VoicesDropdown(props: {
  isValidKey: boolean,
  isFetchingVoices: boolean,
  isErrorVoices: boolean,
  disabled?: boolean,
  voices: VoiceSchema[],
  voiceId: string | null,
  setVoiceId: (voiceId: string) => void,
}) {

  const handleVoiceChange = (_event: any, value: string | null) => props.setVoiceId(value || '');

  return (
    <Select
      value={props.voiceId} onChange={handleVoiceChange}
      variant='outlined' disabled={props.disabled || !props.voices.length}
      // color={props.isErrorVoices ? 'danger' : undefined}
      placeholder={props.isErrorVoices ? 'Issue loading voices' : props.isValidKey ? 'Select a voice' : 'Missing API Key'}
      startDecorator={<RecordVoiceOverTwoToneIcon />}
      endDecorator={props.isValidKey && props.isFetchingVoices && <CircularProgress size='sm' />}
      indicator={<KeyboardArrowDownIcon />}
      slotProps={{
        root: { sx: { width: '100%' } },
        indicator: { sx: { opacity: 0.5 } },
      }}
    >
      {props.voices.map(voice => (
        <Option key={voice.id} value={voice.id}>
          {voice.name}
        </Option>
      ))}
    </Select>
  );
}


export function useElevenLabsVoices() {
  const [apiKey] = useElevenLabsApiKey();

  const isConfigured = isElevenLabsEnabled(apiKey);

  const { data, isError, isFetching, isPending } = apiQuery.elevenlabs.listVoices.useQuery({ elevenKey: apiKey }, {
    enabled: isConfigured,
    staleTime: 1000 * 60 * 5, // 5 minutes
  });

  return {
    isConfigured,
    isError,
    isFetching,
    hasVoices: !isPending && !!data?.voices.length,
    voices: data?.voices || [],
  };
}


export function useElevenLabsVoiceDropdown(autoSpeak: boolean, disabled?: boolean) {

  // external state
  const { isConfigured, isError, isFetching, hasVoices, voices } = useElevenLabsVoices();
  const [voiceId, setVoiceId] = useElevenLabsVoiceId();

  // derived state
  const voice: VoiceSchema | undefined = voices.find(voice => voice.id === voiceId);

  // [E] autoSpeak
  const previewUrl = (autoSpeak && voice?.previewUrl) || null;
  React.useEffect(() => {
    if (previewUrl)
      void AudioPlayer.playUrl(previewUrl);
  }, [previewUrl]);

  const voicesDropdown = React.useMemo(() =>
      <VoicesDropdown
        isValidKey={isConfigured} isFetchingVoices={isFetching} isErrorVoices={isError} disabled={disabled}
        voices={voices}
        voiceId={voiceId} setVoiceId={setVoiceId}
      />,
    [disabled, isConfigured, isError, isFetching, setVoiceId, voiceId, voices],
  );

  return {
    hasVoices,
    voiceId,
    voiceName: voice?.name,
    voicesDropdown,
  };
}


================================================
FILE: src/modules/google/GoogleSearchSettings.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { FormControl, Input, Typography } from '@mui/joy';
import KeyIcon from '@mui/icons-material/Key';
import SearchIcon from '@mui/icons-material/Search';

import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';

import { ExternalLink } from '~/common/components/ExternalLink';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { Link } from '~/common/components/Link';

import { isValidGoogleCloudApiKey, isValidGoogleCseId } from './search.client';
import { useGoogleSearchStore } from './store-module-google';


export function GoogleSearchSettings() {

  // external state
  const backendHasGoogle = getBackendCapabilities().hasGoogleCustomSearch;
  const { googleCloudApiKey, setGoogleCloudApiKey, googleCSEId, setGoogleCSEId, restrictToDomain, setRestrictToDomain } = useGoogleSearchStore(useShallow(state => ({
    googleCloudApiKey: state.googleCloudApiKey, setGoogleCloudApiKey: state.setGoogleCloudApiKey,
    googleCSEId: state.googleCSEId, setGoogleCSEId: state.setGoogleCSEId,
    restrictToDomain: state.restrictToDomain, setRestrictToDomain: state.setRestrictToDomain,
  })));


  // derived state
  const isValidKey = googleCloudApiKey ? isValidGoogleCloudApiKey(googleCloudApiKey) : backendHasGoogle;
  const isValidId = googleCSEId ? isValidGoogleCseId(googleCSEId) : backendHasGoogle;


  const handleGoogleApiKeyChange = (e: React.ChangeEvent<HTMLInputElement>) => setGoogleCloudApiKey(e.target.value);

  const handleCseIdChange = (e: React.ChangeEvent<HTMLInputElement>) => setGoogleCSEId(e.target.value);

  const handleDomainChange = (e: React.ChangeEvent<HTMLInputElement>) => setRestrictToDomain(e.target.value);


  return <>

    <Typography level='body-sm'>
      Enables searching the web for links. Uses the Google <ExternalLink href='https://developers.google.com/custom-search/v1/overview'>Programmable Search Engine</ExternalLink> API.
    </Typography>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='GCP API Key'
                      description={<>Create one <Link href='https://console.cloud.google.com/apis/credentials' noLinkStyle target='_blank'>here</Link></>}
                      tooltip='Create your Google Cloud "API Key Credential" and enter it here' />
      <Input
        variant='outlined' placeholder={backendHasGoogle ? '...' : 'missing'} error={!isValidKey}
        value={googleCloudApiKey} onChange={handleGoogleApiKeyChange}
        startDecorator={<KeyIcon />}
        slotProps={{ input: { sx: { width: '100%' } } }}
        sx={{ width: '100%' }}
      />
    </FormControl>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Search Engine ID'
                      description={<>Get it <Link href='https://programmablesearchengine.google.com/' noLinkStyle target='_blank'>here</Link></>}
                      tooltip='Create your Google "Programmable Search Engine" and enter its ID here' />
      <Input
        variant='outlined' placeholder={backendHasGoogle ? '...' : 'missing'} error={!isValidId}
        value={googleCSEId} onChange={handleCseIdChange}
        startDecorator={<SearchIcon />}
        slotProps={{ input: { sx: { width: '100%' } } }}
        sx={{ width: '100%' }}
      />
    </FormControl>

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Restrict to Domain'
                      description='Optional'
                      tooltip='Limit searches to a specific domain (e.g., "wikipedia.org")' />
      <Input
        variant='outlined' placeholder='example.com'
        value={restrictToDomain} onChange={handleDomainChange}
        // startDecorator={<LanguageIcon />}
        slotProps={{ input: { sx: { width: '100%' } } }}
        sx={{ width: '100%' }}
      />
    </FormControl>

  </>;
}


================================================
FILE: src/modules/google/search.client.ts
================================================
import { apiAsync } from '~/common/util/trpc.client';

import { Search } from './search.types';
import { useGoogleSearchStore } from './store-module-google';


export const isValidGoogleCloudApiKey = (apiKey?: string) => !!apiKey && apiKey.trim()?.length >= 39;
export const isValidGoogleCseId = (cseId?: string) => !!cseId && cseId.trim()?.length >= 17;


/**
 * This function either returns the Search JSON response, or throws a descriptive error string
 */
export async function callApiSearchGoogle(query: string, items: number, restrictToDomain?: string): Promise<{ pages: Search.API.BriefResult[] }> {

  // get the keys (empty if they're on server)
  const { googleCloudApiKey, googleCSEId, restrictToDomain: defaultRestrictToDomain } = useGoogleSearchStore.getState();

  try {
    return await apiAsync.googleSearch.search.query({
      query,
      items,
      key: googleCloudApiKey,
      cx: googleCSEId,
      restrictToDomain: restrictToDomain || defaultRestrictToDomain || null,
    });
  } catch (error: any) {
    const errorMessage = error?.message || error?.toString() || 'Unknown error';
    console.error(`callApiSearchGoogle: ${errorMessage}`);
    throw new Error(errorMessage);
  }
}


================================================
FILE: src/modules/google/search.router.ts
================================================
import { TRPCError } from '@trpc/server';
import * as z from 'zod/v4';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { env } from '~/server/env';
import { fetchJsonOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { Search } from './search.types';


export const googleSearchRouter = createTRPCRouter({

  /**
   * Google Search via the Google Programmable Search product
   */
  search: publicProcedure
    .input(z.object({
      query: z.string(),
      items: z.number(),
      key: z.string().optional(), // could be server-set
      cx: z.string().optional(), // could be server-set
      restrictToDomain: z.string().nullable(),
    }))
    .query(async ({ input }): Promise<{ pages: Search.API.BriefResult[] }> => {

      const customSearchParams: Search.Wire.RequestParams = {
        q: input.query.trim(),
        cx: (input.cx || env.GOOGLE_CSE_ID || '').trim(),
        key: (input.key || env.GOOGLE_CLOUD_API_KEY || '').trim(),
        num: input.items,
      };

      // add domain restriction if provided
      if (input.restrictToDomain) {
        customSearchParams.siteSearch = input.restrictToDomain.trim();
        customSearchParams.siteSearchFilter = 'i'; // 'i' to include only these results (vs 'e' to exclude)
      }

      if (!customSearchParams.key || !customSearchParams.cx)
        throw new Error('Missing API Key or Custom Search Engine ID');

      const url = `https://www.googleapis.com/customsearch/v1?${objectToQueryString(customSearchParams)}`;
      const data: Search.Wire.SearchResponse & { error?: { message?: string } } = await fetchJsonOrTRPCThrow({
        url,
        name: 'Google Custom Search',
        headers: {
          'Accept': 'application/json',
          'Accept-Encoding': 'gzip',
          'User-Agent': 'Big-AGI (gzip)',
        },
      });

      if (data.error)
        throw new TRPCError({
          code: 'BAD_REQUEST',
          message: `Google Custom Search API error: ${data.error?.message}`,
        });

      return {
        pages: data.items?.map((result): Search.API.BriefResult => ({
          title: result.title,
          link: result.link,
          snippet: result.snippet,
        })) || [],
      };
    }),

});


function objectToQueryString(params: Record<string, any>): string {
  return Object.entries(params)
    .map(([key, value]) => encodeURIComponent(key) + '=' + encodeURIComponent(value))
    .join('&');
}


================================================
FILE: src/modules/google/search.types.ts
================================================
export namespace Search {

  /// Client (Browser) -> Server (Next.js)
  export namespace API {

    export interface BriefResult {
      title: string;
      link: string;
      snippet: string;
      // htmlTitle: string;
      // htmlSnippet: string;
      // displayLink: string;
      // formattedUrl: string;
    }

  }

  // This is the upstream API [rev-eng on 2023-04-27], for Server (Next.js) -> Upstream Server
  export namespace Wire {

    // https://developers.google.com/custom-search/v1/reference/rest/v1/cse/list
    export interface RequestParams {
      key: string; // API key
      cx: string; // Programmable Search Engine ID
      q: string; // Query
      num: number; // Number of search results to return (1 to 10)
      start?: number; // Index of the first result to return
      // lr?: string; // Restricts the search to documents written in a particular language (e.g., lr=lang_ja)
      // safe?: string; // Search safety level ("active" or "off")
      // sort?: string; // Sort expression to apply to the results (e.g., sort=date)
      // filter?: string; // Controls turning on or off the duplicate content filter ("0" or "1")
      // gl?: string; // Geolocation of end user (two-letter country code)
      // cr?: string; // Restricts search results to documents originating in a particular country
      // googlehost?: string; // Deprecated. Use the gl parameter for a similar effect
      // c2coff?: string; // Enables or disables Simplified and Traditional Chinese Search ("1" or "0")
      // hq?: string; // Appends the specified query terms to the query, as if they were combined with a logical AND operator
      // hl?: string; // Sets the user interface language
      siteSearch?: string; // Specifies a given site which should always be included or excluded from results
      siteSearchFilter?: string; // Controls whether to include or exclude results from the site named in the siteSearch parameter ("e" or "i")
      // exactTerms?: string; // Identifies a phrase that all documents in the search results must contain
      // excludeTerms?: string; // Identifies a word or phrase that should not appear in any documents in the search results
      // linkSite?: string; // Specifies that all search results should contain a link to a particular URL
      // orTerms?: string; // Provides additional search terms to check for in a document, where each document in the search results must contain at least one of the additional search terms
      // relatedSite?: string; // Specifies that all search results should be pages that are related to the specified URL
      // dateRestrict?: string; // Restricts results to URLs based on date (e.g., d[number], w[number], m[number], y[number])
      // lowRange?: string; // Specifies the starting value for a search range
      // highRange?: string; // Specifies the ending value for a search range
      // searchType?: string; // Specifies the search type: image
      // fileType?: string; // Restricts results to files of a specified extension
      // rights?: string; // Filters based on licensing (e.g., cc_publicdomain, cc_attribute, cc_sharealike, cc_noncommercial, cc_nonderived)
      // imgSize?: string; // Returns images of a specified size (e.g., "huge", "icon", "large", "medium", "small", "xlarge", "xxlarge")
      // imgType?: string; // Returns images of a type (e.g., "clipart", "face", "lineart", "stock", "photo", "animated")
      // imgColorType?: string; // Returns black and white, grayscale, transparent, or color images (e.g., "color", "gray", "mono", "trans")
      // imgDominantColor?: string; // Returns images of a specific dominant color (e.g., "black", "blue", "brown", "gray", "green", "orange", "pink", "purple", "red", "teal", "white", "yellow")
      // alt?: string; // Alternative representation type
    }

    export interface SearchResponse {
      kind: string;
      url: {
        type: string;
        template: string;
      };
      queries: {
        request: QueryMetadata[];
        nextPage: QueryMetadata[];
      };
      context: {
        title: string;
      };
      searchInformation: {
        searchTime: number;
        formattedSearchTime: string;
        totalResults: string;
        formattedTotalResults: string;
      };
      items: Result[];
    }

    interface QueryMetadata {
      title: string;
      totalResults: string;
      searchTerms: string;
      count: number;
      startIndex: number;
      inputEncoding: string;
      outputEncoding: string;
      safe: string;
      cx: string;
    }

    export interface Result {
      kind: string; // A unique identifier for the type of current object, 'customsearch#result'
      title: string; // The title of the search result, in plain text
      htmlTitle: string; // The title of the search result, in HTML
      link: string; // The full URL to which the search result is pointing
      displayLink: string; // An abridged version of this search result’s URL
      snippet: string; // The snippet of the search result, in plain text
      htmlSnippet: string; // The snippet of the search result, in HTML
      cacheId: string; // Indicates the ID of Google's cached version of the search result
      formattedUrl: string; // The URL displayed after the snippet for each search result
      htmlFormattedUrl: string; // The HTML-formatted URL displayed after the snippet for each search result
      // pagemap: PageMap; // Contains PageMap information for this search result
      // mime: string; // The MIME type of the search result
      // fileFormat: string; // The file format of the search result
      // image: {
      //   contextLink: string; // A URL pointing to the webpage hosting the image
      //   height: number; // The height of the image, in pixels
      //   width: number; // The width of the image, in pixels
      //   byteSize: number; // The size of the image, in pixels
      //   thumbnailLink: string; // A URL to the thumbnail image
      //   thumbnailHeight: number; // The height of the thumbnail image, in pixels
      //   thumbnailWidth: number; // The width of the thumbnail image, in pixels
      // };
      // labels: {
      //   name: string; // The name of a refinement label, use displayName for UI
      //   displayName: string; // The display name of a refinement label, for UI
      //   label_with_op: string; // Refinement label and the associated refinement operation
      // }[];
    }

    /*interface PageMap {
      cse_thumbnail: {
        src: string;
        width: string;
        height: string;
      }[];
      VideoObject?: any[];
      imageobject: {
        width: string;
        url: string;
        height: string;
      }[];
      broadcastevent: {
        islivebroadcast: string;
        enddate: string;
        startdate: string;
      }[];
      person: {
        name: string;
        url: string;
      }[];
      metatags: {
        [key: string]: string;
      }[];
      videoobject: {
        [key: string]: string;
      }[];
      cse_image: {
        src: string;
      }[];
    }*/

  }

}


================================================
FILE: src/modules/google/store-module-google.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';


interface ModuleGoogleSearchStore {

  // Google Custom Search settings

  googleCloudApiKey: string;
  setGoogleCloudApiKey: (googleApiKey: string) => void;

  googleCSEId: string;
  setGoogleCSEId: (cseId: string) => void;

  restrictToDomain: string;
  setRestrictToDomain: (domain: string) => void;

}

export const useGoogleSearchStore = create<ModuleGoogleSearchStore>()(
  persist(
    (set) => ({

      // Google Custom Search settings

      googleCloudApiKey: '',
      setGoogleCloudApiKey: (googleApiKey: string) => set({ googleCloudApiKey: googleApiKey }),

      googleCSEId: '',
      setGoogleCSEId: (cseId: string) => set({ googleCSEId: cseId }),

      restrictToDomain: '',
      setRestrictToDomain: (domain: string) => set({ restrictToDomain: domain }),

    }),
    {
      name: 'app-module-google-search',
    }),
);


================================================
FILE: src/modules/llms/llm.client.hooks.ts
================================================
import type { TRPCClientErrorBase } from '@trpc/client';
import { useQuery } from '@tanstack/react-query';

import type { DModelsService } from '~/common/stores/llms/llms.service.types';

import type { ModelDescriptionSchema } from './server/llm.server.types';
import { llmsUpdateModelsForServiceOrThrow } from './llm.client';


/**
 * Hook that fetches the list of models from the vendor and updates the store,
 * while returning the fetch state.
 */
export function useLlmUpdateModels<TServiceSettings extends object>(
  enabled: boolean,
  service: DModelsService<TServiceSettings> | null,
  // discardUserEdits?: boolean,
): {
  isFetching: boolean,
  refetch: () => void,
  isError: boolean,
  error: TRPCClientErrorBase<any> | null
} {
  return useQuery<{ models: ModelDescriptionSchema[] }, TRPCClientErrorBase<any> | null>({
    enabled: enabled && !!service,
    queryKey: ['list-models', service?.id || 'missing-service'],
    queryFn: async () => {
      if (!service)
        throw new Error('No service provided to fetch models for');
      return await llmsUpdateModelsForServiceOrThrow(service.id, true /*!discardUserEdits*/);
    },
    staleTime: Infinity,
  });
}



================================================
FILE: src/modules/llms/llm.client.ts
================================================
import { hasGoogleAnalytics, sendGAEvent } from '~/common/components/3rdparty/GoogleAnalytics';

import type { DModelsService, DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { DLLM, LLM_IF_HOTFIX_NoTemperature, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn } from '~/common/stores/llms/llms.types';
import { applyModelParameterInitialValues, FALLBACK_LLM_PARAM_TEMPERATURE } from '~/common/stores/llms/llms.parameters';
import { isModelPricingFree } from '~/common/stores/llms/llms.pricing';
import { llmsStoreActions } from '~/common/stores/llms/store-llms';

import type { ModelDescriptionSchema } from './server/llm.server.types';
import { findServiceAccessOrThrow } from './vendors/vendor.helpers';


// LLM Model Updates Client Functions

export async function llmsUpdateModelsForServiceOrThrow(serviceId: DModelsServiceId, keepUserEdits: boolean): Promise<{ models: ModelDescriptionSchema[] }> {

  // get the access, assuming there's no client config and the server will do all
  const { service, vendor, transportAccess } = findServiceAccessOrThrow(serviceId);

  // fetch models
  const data = await vendor.rpcUpdateModelsOrThrow(transportAccess);

  // update the global models store
  llmsStoreActions().setServiceLLMs(
    service.id,
    data.models.map(model => _createDLLMFromModelDescription(model, service)),
    keepUserEdits,
    false,
  );

  // figure out which vendors are actually used and useful
  hasGoogleAnalytics && sendGAEvent('event', 'app_models_updated', {
    app_models_source_id: service.id,
    app_models_source_label: service.label,
    app_models_updated_count: data.models.length || 0,
    app_models_vendor_id: vendor.id,
    app_models_vendor_label: vendor.name,
  });

  // return the fetched models
  return data;
}

const _fallbackInterfaces = [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn];

function _createDLLMFromModelDescription(d: ModelDescriptionSchema, service: DModelsService): DLLM {

  // null means unknown contenxt/output tokens
  const contextTokens = d.contextWindow || null;
  const maxOutputTokens = d.maxCompletionTokens || (contextTokens ? Math.round(contextTokens / 2) : null);
  const llmResponseTokensRatio = d.maxCompletionTokens ? 1 : 1 / 4;
  const llmResponseTokens = maxOutputTokens ? Math.round(maxOutputTokens * llmResponseTokensRatio) : null;

  // DLLM is a fundamental type in our application
  const dllm: DLLM = {

    // this id is Big-AGI specific, not the vendor's
    id: !d.idVariant ? `${service.id}-${d.id}`
      : `${service.id}-${d.id}-${d.idVariant}`,

    // editable properties
    label: d.label,
    created: d.created || 0,
    updated: d.updated || 0,
    description: d.description,
    hidden: !!d.hidden,

    // hard properties
    contextTokens,
    maxOutputTokens,
    trainingDataCutoff: d.trainingDataCutoff,
    interfaces: d.interfaces?.length ? d.interfaces : _fallbackInterfaces,
    benchmark: d.benchmark,
    // pricing: undefined, // set below, since it needs some adaptation

    // parameters system (spec and initial values)
    parameterSpecs: d.parameterSpecs?.length ? d.parameterSpecs : [],
    initialParameters: {
      llmRef: d.id, // this is the vendor model id
      llmTemperature: d.interfaces.includes(LLM_IF_HOTFIX_NoTemperature) ? null : FALLBACK_LLM_PARAM_TEMPERATURE,
      llmResponseTokens: llmResponseTokens,
    },

    // references
    sId: service.id,
    vId: service.vId,

    // user edited properties: not set
    // userLabel: undefined,
    // userHidden: undefined,
    // userParameters: undefined,
  };

  // set other params from spec
  if (dllm.parameterSpecs?.length)
    applyModelParameterInitialValues(dllm.initialParameters, dllm.parameterSpecs, false);

  // set the pricing
  if (d.chatPrice && typeof d.chatPrice === 'object') {
    dllm.pricing = {
      chat: {
        ...d.chatPrice,
        // compute the free status
        _isFree: isModelPricingFree(d.chatPrice),
      },
    };
  }

  return dllm;
}



================================================
FILE: src/modules/llms/components/LLMVendorIcon.tsx
================================================
import * as React from 'react';

import type { SvgIconProps } from '@mui/joy';

import type { ModelVendorId } from '../vendors/vendors.registry';

// fallback icon
import { PhRobot } from '~/common/components/icons/phosphor/PhRobot';


// direct imports for all vendor icons - given we use them frequently, we won't consider lazy loading them
import { AlibabaCloudIcon } from '~/common/components/icons/vendors/AlibabaCloudIcon';
import { AnthropicIcon } from '~/common/components/icons/vendors/AnthropicIcon';
import { AzureIcon } from '~/common/components/icons/vendors/AzureIcon';
import { DeepseekIcon } from '~/common/components/icons/vendors/DeepseekIcon';
import { GeminiIcon } from '~/common/components/icons/vendors/GeminiIcon';
import { GroqIcon } from '~/common/components/icons/vendors/GroqIcon';
import { LMStudioIcon } from '~/common/components/icons/vendors/LMStudioIcon';
import { LocalAIIcon } from '~/common/components/icons/vendors/LocalAIIcon';
import { MistralIcon } from '~/common/components/icons/vendors/MistralIcon';
import { OllamaIcon } from '~/common/components/icons/vendors/OllamaIcon';
import { OpenAIIcon } from '~/common/components/icons/vendors/OpenAIIcon';
import { OpenPipeIcon } from '~/common/components/icons/vendors/OpenPipeIcon';
import { OpenRouterIcon } from '~/common/components/icons/vendors/OpenRouterIcon';
import { PerplexityIcon } from '~/common/components/icons/vendors/PerplexityIcon';
import { TogetherIcon } from '~/common/components/icons/vendors/TogetherIcon';
import { XAIIcon } from '~/common/components/icons/vendors/XAIIcon';


/**
 * Add to this registry to register a new Vendor Icon.
 *
 * They are used throughout the app and frequently.
 */
const vendorIcons: Record<ModelVendorId, React.FunctionComponent<SvgIconProps>> = {
  alibaba: AlibabaCloudIcon,
  anthropic: AnthropicIcon,
  azure: AzureIcon,
  deepseek: DeepseekIcon,
  googleai: GeminiIcon,
  groq: GroqIcon,
  lmstudio: LMStudioIcon,
  localai: LocalAIIcon,
  mistral: MistralIcon,
  ollama: OllamaIcon,
  openai: OpenAIIcon,
  openpipe: OpenPipeIcon,
  openrouter: OpenRouterIcon,
  perplexity: PerplexityIcon,
  togetherai: TogetherIcon,
  xai: XAIIcon,
};


/**
 * Get the icon component for a vendor ID
 * @param vendorId - The vendor ID to get the icon for
 * @returns The icon component or undefined if not found
 */
export function llmsGetVendorIcon(vendorId: ModelVendorId | undefined): React.FunctionComponent<SvgIconProps> {
  return vendorId ? vendorIcons[vendorId] ?? PhRobot : PhRobot;
}

/**
 * Render a vendor icon with optional props
 * @param vendorId - The vendor ID to render the icon for
 * @param props - Optional SVG icon props to pass to the icon component
 * @returns The rendered icon element or null if vendor not found
 */
export function LLMVendorIcon({ vendorId, ...props }: { vendorId: ModelVendorId | undefined } & SvgIconProps): React.ReactElement {
  const Icon = llmsGetVendorIcon(vendorId);
  return <Icon {...props} />;
}


/**
 * Type guard to check if a vendor has an icon
 * @param vendorId - The vendor ID to check
 * @returns True if the vendor has an icon
 */
export function hasVendorIcon(vendorId: ModelVendorId | undefined): boolean {
  return !!vendorId && !!vendorIcons[vendorId];
}


/**
 * Get all vendor icons as an array
 * @returns Array of {vendorId, Icon} objects
 */
export function getAllVendorIcons(): Array<{ vendorId: ModelVendorId; Icon: React.FunctionComponent<SvgIconProps> }> {
  return Object.entries(vendorIcons).map(([vendorId, Icon]) => ({
    vendorId: vendorId as ModelVendorId,
    Icon,
  }));
}



================================================
FILE: src/modules/llms/components/LLMVendorSetup.tsx
================================================
import * as React from 'react';

import type { DModelsService, DModelsServiceId } from '~/common/stores/llms/llms.service.types';

import { findModelVendor, ModelVendorId } from '../vendors/vendors.registry';


// direct imports for all vendor setup components - NOTE: we could lazy load if this becomes a performance issue
import { AlibabaServiceSetup } from '../vendors/alibaba/AlibabaServiceSetup';
import { AnthropicServiceSetup } from '../vendors/anthropic/AnthropicServiceSetup';
import { AzureServiceSetup } from '../vendors/azure/AzureServiceSetup';
import { DeepseekAIServiceSetup } from '../vendors/deepseek/DeepseekAIServiceSetup';
import { GeminiServiceSetup } from '../vendors/gemini/GeminiServiceSetup';
import { GroqServiceSetup } from '../vendors/groq/GroqServiceSetup';
import { LMStudioServiceSetup } from '../vendors/lmstudio/LMStudioServiceSetup';
import { LocalAIServiceSetup } from '../vendors/localai/LocalAIServiceSetup';
import { MistralServiceSetup } from '../vendors/mistral/MistralServiceSetup';
import { OllamaServiceSetup } from '../vendors/ollama/OllamaServiceSetup';
import { OpenAIServiceSetup } from '../vendors/openai/OpenAIServiceSetup';
import { OpenPipeServiceSetup } from '../vendors/openpipe/OpenPipeServiceSetup';
import { OpenRouterServiceSetup } from '../vendors/openrouter/OpenRouterServiceSetup';
import { PerplexityServiceSetup } from '../vendors/perplexity/PerplexityServiceSetup';
import { TogetherAIServiceSetup } from '../vendors/togetherai/TogetherAIServiceSetup';
import { XAIServiceSetup } from '../vendors/xai/XAIServiceSetup';


/**
 * Add to this map to register a new Vendor Setup Component.
 * NOTE: we do it here to only depend on this file (even lazily) and avoid to import all the Components (UI)
 *       code on vendor definitions (which must be lightweight as it impacts boot time).
 */
const vendorSetupComponents: Record<ModelVendorId, React.ComponentType<{ serviceId: DModelsServiceId }>> = {
  alibaba: AlibabaServiceSetup,
  anthropic: AnthropicServiceSetup,
  azure: AzureServiceSetup,
  deepseek: DeepseekAIServiceSetup,
  googleai: GeminiServiceSetup,
  groq: GroqServiceSetup,
  lmstudio: LMStudioServiceSetup,
  localai: LocalAIServiceSetup,
  mistral: MistralServiceSetup,
  ollama: OllamaServiceSetup,
  openai: OpenAIServiceSetup,
  openpipe: OpenPipeServiceSetup,
  openrouter: OpenRouterServiceSetup,
  perplexity: PerplexityServiceSetup,
  togetherai: TogetherAIServiceSetup,
  xai: XAIServiceSetup,
} as const;


export function LLMVendorSetup(props: { service: DModelsService }) {
  const vendor = findModelVendor(props.service.vId);
  if (!vendor)
    return 'Configuration issue: Vendor not found for Service ' + props.service.id;

  const SetupComponent = vendorSetupComponents[vendor.id];
  if (!SetupComponent)
    return 'Configuration issue: Setup component not found for vendor ' + vendor.id;

  return <SetupComponent key={props.service.id} serviceId={props.service.id} />;
}



================================================
FILE: src/modules/llms/models-modal/LLMOptionsGlobal.tsx
================================================
import * as React from 'react';

import { DLLM, LLM_IF_HOTFIX_NoTemperature } from '~/common/stores/llms/llms.types';
import type { DModelParameterId, DModelParameterValues } from '~/common/stores/llms/llms.parameters';
import { InlineError } from '~/common/components/InlineError';
import { llmsStoreActions } from '~/common/stores/llms/store-llms';

import { LLMParametersEditor } from './LLMParametersEditor';


export function LLMOptionsGlobal(props: { llm: DLLM }) {

  // derived input
  const llm = props.llm;
  const llmId = llm?.id ?? null;

  // handlers

  const handleChangeParameter = React.useCallback((partial: Partial<DModelParameterValues>) => {
    llmsStoreActions().updateLLMUserParameters(llmId, partial);
  }, [llmId]);

  const handleRemoveParameter = React.useCallback((parameterId: DModelParameterId) => {
    llmsStoreActions().deleteLLMUserParameter(llmId, parameterId);
  }, [llmId]);


  if (!llmId)
    return <InlineError error='No model selected' />;

  return (
    <LLMParametersEditor
      maxOutputTokens={llm.maxOutputTokens}
      parameterSpecs={llm.parameterSpecs}
      parameterOmitTemperature={llm.interfaces.includes(LLM_IF_HOTFIX_NoTemperature)}
      baselineParameters={llm.initialParameters}
      parameters={llm.userParameters}
      onChangeParameter={handleChangeParameter}
      onRemoveParameter={handleRemoveParameter}
    />
  );
}


================================================
FILE: src/modules/llms/models-modal/LLMOptionsModal.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, Button, ButtonGroup, Divider, FormControl, Input, Switch, Tooltip, Typography } from '@mui/joy';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';
import StarBorderIcon from '@mui/icons-material/StarBorder';
import StarIcon from '@mui/icons-material/Star';
import VisibilityIcon from '@mui/icons-material/Visibility';
import VisibilityOffIcon from '@mui/icons-material/VisibilityOff';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import type { DPricingChatGenerate } from '~/common/stores/llms/llms.pricing';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { ModelDomainsList, ModelDomainsRegistry } from '~/common/stores/llms/model.domains.registry';
import { llmsStoreActions } from '~/common/stores/llms/store-llms';
import { useModelDomains } from '~/common/stores/llms/hooks/useModelDomains';
import { useLLM } from '~/common/stores/llms/llms.hooks';

import { LLMOptionsGlobal } from './LLMOptionsGlobal';


function prettyPricingComponent(pricingChatGenerate: DPricingChatGenerate): React.ReactNode {
  if (!pricingChatGenerate) return 'Pricing not available';

  const formatPrice = (price: DPricingChatGenerate['input']): string => {
    if (!price) return 'N/A';
    if (price === 'free') return 'Free';
    if (typeof price === 'number') return `$${price.toFixed(2)}`;
    if (Array.isArray(price))
      return price.map(bp => `${bp.upTo === null ? '>' : '<='} ${bp.upTo || ''} tokens: ${formatPrice(bp.price)}`).join(', ');
    return 'Unknown';
  };

  const inputPrice = formatPrice(pricingChatGenerate.input);
  const outputPrice = formatPrice(pricingChatGenerate.output);

  let cacheInfo = '';
  if (pricingChatGenerate.cache) {
    switch (pricingChatGenerate.cache.cType) {
      case 'ant-bp': {
        const { read, write, duration } = pricingChatGenerate.cache;
        cacheInfo = `Cache: Read ${formatPrice(read)}, Write ${formatPrice(write)}, Duration: ${duration}s`;
        break;
      }
      case 'oai-ac': {
        const { read } = pricingChatGenerate.cache;
        cacheInfo = `Cache: Read ${formatPrice(read)}`;
        break;
      }
      default:
        throw new Error('LLMOptionsModal: Unknown cache type');
    }
  }

  return (
    <div>
      <span>pricing ($/M tokens):</span><br />
      &nbsp;- Input: {inputPrice}<br />
      &nbsp;- Output: {outputPrice}<br />
      {cacheInfo && <>&nbsp;- {cacheInfo}<br /></>}
    </div>
  );
}


export function LLMOptionsModal(props: { id: DLLMId, onClose: () => void }) {

  // state
  const [showDetails, setShowDetails] = React.useState(false);

  // external state
  const llm = useLLM(props.id);
  const domainAssignments = useModelDomains();
  const { removeLLM, updateLLM, assignDomainModelId } = llmsStoreActions();

  if (!llm)
    return <>Options issue: LLM not found for id {props.id}</>;

  const handleLlmLabelSet = (event: React.ChangeEvent<HTMLInputElement>) => updateLLM(llm.id, { label: event.target.value || '' });

  const handleLlmVisibilityToggle = () => updateLLM(llm.id, { hidden: !llm.hidden });

  const handleLlmStarredToggle = () => updateLLM(llm.id, { userStarred: !llm.userStarred });

  const handleLlmDelete = () => {
    removeLLM(llm.id);
    props.onClose();
  };

  return (

    <GoodModal
      title={<><b>{llm.label}</b> options</>}
      open={!!props.id} onClose={props.onClose}
      startButton={
        <Button variant='plain' color='neutral' onClick={handleLlmDelete} startDecorator={<DeleteOutlineIcon />}>
          Delete
        </Button>
      }
    >

      <Box sx={{ display: 'grid', gap: 'var(--Card-padding)' }}>
        <LLMOptionsGlobal llm={llm} />
      </Box>

      <Divider />

      <FormControl orientation='horizontal' sx={{ flexWrap: 'wrap', alignItems: 'center' }}>
        <FormLabelStart title='Name' sx={{ minWidth: 80 }} />
        <Input variant='outlined' value={llm.label} onChange={handleLlmLabelSet} />
      </FormControl>

      <FormControl orientation='horizontal' sx={{ flexWrap: 'wrap', alignItems: 'center' }}>
        <FormLabelStart title='Assignment' description='Default model' sx={{ minWidth: 80 }} />
        <ButtonGroup orientation='horizontal' size='sm' variant='outlined'>
          {ModelDomainsList.map(domainId => {
            const domainSpec = ModelDomainsRegistry[domainId];
            const domainModelId = domainAssignments[domainId]?.modelId;
            const isActive = domainModelId === llm.id;
            return (
              // Note: use Tooltip instead of GoodTooltip here, because GoodTooltip is not working well with ButtonGroup
              <Tooltip arrow placement='top' key={domainId} title={domainSpec.confTooltip}>
                <Button variant={isActive ? 'solid' : undefined} onClick={() => assignDomainModelId(domainId, isActive ? null : llm.id)}>{domainSpec.confLabel}</Button>
              </Tooltip>
            );
          })}
        </ButtonGroup>
      </FormControl>

      <FormControl orientation='horizontal' sx={{ flexWrap: 'wrap', alignItems: 'center' }}>
        <FormLabelStart title='Starred' sx={{ minWidth: 80 }} />
        <Tooltip title={llm.userStarred ? 'Unstar this model' : 'Star this model for quick access'}>
          <Switch checked={!!llm.userStarred} onChange={handleLlmStarredToggle}
                  endDecorator={llm.userStarred ? <StarIcon sx={{ color: '#fad857' }} /> : <StarBorderIcon />}
                  slotProps={{ endDecorator: { sx: { minWidth: 26 } } }}
          />
        </Tooltip>
      </FormControl>

      <FormControl orientation='horizontal' sx={{ flexWrap: 'wrap', alignItems: 'center' }}>
        <FormLabelStart title='Visible' sx={{ minWidth: 80 }} />
        <Tooltip title={!llm.hidden ? 'Show this model in the list of Chat models' : 'Hide this model from the list of Chat models'}>
          <Switch checked={!llm.hidden} onChange={handleLlmVisibilityToggle}
                  endDecorator={!llm.hidden ? <VisibilityIcon /> : <VisibilityOffIcon />}
                  slotProps={{ endDecorator: { sx: { minWidth: 26 } } }} />
        </Tooltip>
      </FormControl>

      <FormControl orientation='horizontal' sx={{ flexWrap: 'nowrap' }}>
        <FormLabelStart title='Details' sx={{ minWidth: 80 }} onClick={() => setShowDetails(!showDetails)} />
        {showDetails && <Box sx={{ display: 'flex', flexDirection: 'column', wordBreak: 'break-word', gap: 1 }}>
          {!!llm.description && <Typography level='body-sm'>
            {llm.description}
          </Typography>}
          {!!llm.pricing?.chat?._isFree && <Typography level='body-xs'>
            🎁 Free model - note: refresh models to check for updates in pricing
          </Typography>}
          <Typography level='body-xs'>
            llm id: {llm.id}<br />
            context tokens: <b>{llm.contextTokens ? llm.contextTokens.toLocaleString() : 'not provided'}</b>{` · `}
            max output tokens: <b>{llm.maxOutputTokens ? llm.maxOutputTokens.toLocaleString() : 'not provided'}</b><br />
            {!!llm.created && <>created: <TimeAgo date={new Date(llm.created * 1000)} /><br /></>}
            {/*· tags: {llm.tags.join(', ')}*/}
            {!!llm.pricing?.chat && prettyPricingComponent(llm.pricing.chat)}
            {/*{!!llm.benchmark && <>benchmark: <b>{llm.benchmark.cbaElo?.toLocaleString() || '(unk) '}</b> CBA Elo<br /></>}*/}
            {llm.parameterSpecs?.length > 0 && <>options: {llm.parameterSpecs.map(ps => ps.paramId).join(', ')}<br /></>}
            {Object.keys(llm.initialParameters || {}).length > 0 && <>initial parameters: {JSON.stringify(llm.initialParameters, null, 2)}<br /></>}
            {Object.keys(llm.userParameters || {}).length > 0 && <>user parameters: {JSON.stringify(llm.userParameters, null, 2)}<br /></>}
          </Typography>
        </Box>}
      </FormControl>

    </GoodModal>

  );
}


================================================
FILE: src/modules/llms/models-modal/LLMParametersEditor.tsx
================================================
import * as React from 'react';

import { Box, IconButton, Tooltip } from '@mui/joy';
import AutoModeIcon from '@mui/icons-material/AutoMode';
import ClearIcon from '@mui/icons-material/Clear';
import LocalFireDepartmentIcon from '@mui/icons-material/LocalFireDepartment';
import PowerSettingsNewIcon from '@mui/icons-material/PowerSettingsNew';

import { DModelParameterId, DModelParameterRegistry, DModelParameterSpec, DModelParameterValues, FALLBACK_LLM_PARAM_RESPONSE_TOKENS, FALLBACK_LLM_PARAM_TEMPERATURE, getAllModelParameterValues } from '~/common/stores/llms/llms.parameters';
import { FormSelectControl } from '~/common/components/forms/FormSelectControl';
import { FormSliderControl } from '~/common/components/forms/FormSliderControl';
import { FormSwitchControl } from '~/common/components/forms/FormSwitchControl';
import { InlineError } from '~/common/components/InlineError';
import { webGeolocationRequest } from '~/common/util/webGeolocationUtils';


const _UNSPECIFIED = '_UNSPECIFIED' as const;
const _reasoningEffortOptions = [
  { value: 'high', label: 'High', description: 'Deep, thorough analysis' } as const,
  { value: 'medium', label: 'Medium', description: 'Balanced reasoning depth' } as const,
  { value: 'low', label: 'Low', description: 'Quick, concise responses' } as const,
  { value: _UNSPECIFIED, label: 'Default', description: 'Default value (unset)' } as const,
] as const;
const _webSearchContextOptions = [
  { value: 'high', label: 'Comprehensive', description: 'Largest, highest cost, slower' } as const,
  { value: 'medium', label: 'Medium', description: 'Balanced context, cost, and speed' } as const,
  { value: 'low', label: 'Low', description: 'Smallest, cheapest, fastest' } as const,
  { value: _UNSPECIFIED, label: 'Default', description: 'Default value (unset)' } as const,
] as const;
const _perplexitySearchModeOptions = [
  { value: _UNSPECIFIED, label: 'Default', description: 'General web sources' },
  { value: 'academic', label: 'Academic', description: 'Scholarly and peer-reviewed sources' },
] as const;
const _perplexityDateFilterOptions = [
  { value: _UNSPECIFIED, label: 'All Time', description: 'No date restriction' },
  { value: '1m', label: 'Last Month', description: 'Results from last 30 days' },
  { value: '3m', label: 'Last 3 Months', description: 'Results from last 90 days' },
  { value: '6m', label: 'Last 6 Months', description: 'Results from last 6 months' },
  { value: '1y', label: 'Last Year', description: 'Results from last 12 months' },
] as const;

const _xaiSearchModeOptions = [
  { value: 'auto', label: 'Auto', description: 'Model decides (default)' },
  { value: 'on', label: 'On', description: 'Always search active sources' },
  { value: 'off', label: 'Off', description: 'Never perform a search' },
] as const;

const _xaiDateFilterOptions = [
  { value: 'unfiltered', label: 'All Time', description: 'No date restriction' },
  { value: '1d', label: 'Last Day', description: 'Results from last 24 hours' },
  { value: '1w', label: 'Last Week', description: 'Results from last 7 days' },
  { value: '1m', label: 'Last Month', description: 'Results from last 30 days' },
  { value: '6m', label: 'Last 6 Months', description: 'Results from last 6 months' },
  { value: '1y', label: 'Last Year', description: 'Results from last 12 months' },
] as const;

export function LLMParametersEditor(props: {
  // constants
  maxOutputTokens: number | null,
  parameterSpecs: DModelParameterSpec<DModelParameterId>[],
  parameterOmitTemperature?: boolean,
  baselineParameters: DModelParameterValues,

  // value and onChange for the parameters
  parameters: undefined | DModelParameterValues,
  onChangeParameter: (parameterValue: DModelParameterValues) => void,
  onRemoveParameter: (parameterId: DModelParameterId) => void,

  // rendering options
  simplified?: boolean,
}) {

  // registry (const) values
  const defAntTB = DModelParameterRegistry['llmVndAntThinkingBudget'];
  const defGemTB = DModelParameterRegistry['llmVndGeminiThinkingBudget'];

  // specs: whether a models supports a parameter
  const modelParamSpec = React.useMemo(() => {
    return Object.fromEntries(
      (props.parameterSpecs ?? []).map(spec => [spec.paramId, spec]),
    ) as Record<DModelParameterId, DModelParameterSpec<DModelParameterId>>;
  }, [props.parameterSpecs]);


  // current values: { ...fallback, ...baseline, ...user }
  const allParameters = getAllModelParameterValues(props.baselineParameters, props.parameters);
  const {
    llmResponseTokens = FALLBACK_LLM_PARAM_RESPONSE_TOKENS, // fallback for undefined, result is number | null
    llmTemperature = FALLBACK_LLM_PARAM_TEMPERATURE, // fallback for undefined, result is number | null
    llmForceNoStream,
    llmVndAntThinkingBudget,
    llmVndGeminiShowThoughts,
    llmVndGeminiThinkingBudget,
    llmVndOaiReasoningEffort,
    llmVndOaiRestoreMarkdown,
    llmVndOaiWebSearchContext,
    llmVndOaiWebSearchGeolocation,
    llmVndPerplexityDateFilter,
    llmVndPerplexitySearchMode,
    llmVndXaiSearchMode,
    llmVndXaiSearchSources,
    llmVndXaiSearchDateFilter,
  } = allParameters;


  // state (here because the initial state depends on props)
  const tempAboveOne = llmTemperature !== null && llmTemperature > 1;
  const [overheat, setOverheat] = React.useState(tempAboveOne);
  const showOverheatButton = overheat || llmTemperature === 1 || tempAboveOne;


  // handlers

  const { onChangeParameter, onRemoveParameter } = props;

  const handleOverheatToggle = React.useCallback(() => {
    // snap to 1 when disabling overheating
    if (overheat && tempAboveOne)
      onChangeParameter({ llmTemperature: 1 });

    // toggle overheating
    setOverheat(on => !on);
  }, [onChangeParameter, overheat, tempAboveOne]);


  // semantics
  function showParam(paramId: DModelParameterId): boolean {
    return paramId in modelParamSpec && !modelParamSpec[paramId].hidden;
  }

  const temperatureHide = showParam('llmVndAntThinkingBudget');
  const antThinkingOff = llmVndAntThinkingBudget === null;
  const gemThinkingAuto = llmVndGeminiThinkingBudget === undefined;
  const gemThinkingOff = llmVndGeminiThinkingBudget === 0;

  // Get the range override if available for Gemini thinking budget
  const gemTBSpec = modelParamSpec['llmVndGeminiThinkingBudget'];
  const gemTBMinMax = gemTBSpec?.rangeOverride || defGemTB.range;

  return <>

    {!temperatureHide && <FormSliderControl
      title='Temperature' ariaLabel='Model Temperature'
      description={llmTemperature === null ? 'Unsupported' : llmTemperature < 0.33 ? 'More strict' : llmTemperature > 1 ? 'Extra hot ♨️' : llmTemperature > 0.67 ? 'Larger freedom' : 'Creativity'}
      disabled={props.parameterOmitTemperature}
      min={0} max={overheat ? 2 : 1} step={0.1} defaultValue={0.5}
      valueLabelDisplay={props.parameters?.llmTemperature !== undefined ? 'on' : 'auto'} // detect user-overridden or not
      value={llmTemperature}
      onChange={value => onChangeParameter({ llmTemperature: value })}
      endAdornment={
        <Tooltip arrow disableInteractive title={overheat ? 'Disable LLM Overheating' : 'Increase Max LLM Temperature to 2'} sx={{ p: 1 }}>
          <IconButton
            disabled={!showOverheatButton}
            variant={overheat ? 'soft' : 'plain'} color={overheat ? 'danger' : 'neutral'}
            onClick={handleOverheatToggle} sx={{ ml: 2 }}
          >
            <LocalFireDepartmentIcon />
          </IconButton>
        </Tooltip>
      }
    />}

    {llmResponseTokens === null || props.maxOutputTokens === null ? (
      <InlineError error='Max Output Tokens: Token computations are disabled because this model does not declare the context window size.' />
    ) : !props.simplified && (
      <Box sx={{ mr: 1 }}>
        <FormSliderControl
          title='Output Tokens' ariaLabel='Model Max Tokens'
          description='Max Size'
          min={256} max={props.maxOutputTokens} step={256} defaultValue={1024}
          valueLabelDisplay={props.parameters?.llmResponseTokens !== undefined ? 'on' : 'auto'} // detect user-overridden or not
          value={llmResponseTokens}
          onChange={value => onChangeParameter({ llmResponseTokens: value })}
        />
      </Box>
    )}

    {showParam('llmVndAntThinkingBudget') && (
      <FormSliderControl
        title='Thinking Budget' ariaLabel='Anthropic Extended Thinking Token Budget'
        description='Tokens'
        min={defAntTB.range[0]} max={defAntTB.range[1]} step={1024}
        valueLabelDisplay={antThinkingOff ? 'off' : 'on'}
        value={llmVndAntThinkingBudget ?? 0}
        disabled={antThinkingOff}
        onChange={value => onChangeParameter({ llmVndAntThinkingBudget: value })}
        endAdornment={
          <Tooltip arrow disableInteractive title={antThinkingOff ? 'Enable Thinking' : 'Disable Thinking'}>
            <IconButton
              variant={antThinkingOff ? 'solid' : 'outlined'}
              onClick={() => antThinkingOff
                ? onRemoveParameter('llmVndAntThinkingBudget')
                : onChangeParameter({ llmVndAntThinkingBudget: null })
              }
              sx={{ ml: 2 }}
            >
              <ClearIcon />
            </IconButton>
          </Tooltip>
        }
      />
    )}

    {showParam('llmVndGeminiShowThoughts') && (
      <FormSwitchControl
        title='Show Chain of Thought'
        description={`Displays Gemini\'s reasoning process`}
        checked={!!llmVndGeminiShowThoughts}
        onChange={checked => onChangeParameter({ llmVndGeminiShowThoughts: checked })}
      />
    )}

    {showParam('llmVndGeminiThinkingBudget') && (
      <FormSliderControl
        title='Thinking Budget' ariaLabel='Gemini Thinking Token Budget'
        description={gemThinkingAuto ? 'Auto' : gemThinkingOff ? 'Thinking Off' : 'Tokens'}
        min={gemTBMinMax[0]} max={gemTBMinMax[1]} step={1024}
        valueLabelDisplay={(gemThinkingAuto || gemThinkingOff) ? 'off' : 'on'}
        value={llmVndGeminiThinkingBudget ?? [gemTBMinMax[0], gemTBMinMax[1]]}
        variant={gemThinkingAuto ? 'soft' : undefined}
        // disabled={gemThinkingAuto}
        onChange={value => onChangeParameter({ llmVndGeminiThinkingBudget: Array.isArray(value) ? (value[0] || value[1]) : value })}
        startAdornment={gemTBMinMax[0] === 0 && (
          <Tooltip arrow disableInteractive title={gemThinkingOff ? 'Thinking Off' : 'Disable Thinking'}>
            <IconButton
              variant={gemThinkingOff ? 'solid' : 'outlined'}
              // disabled={gemThinkingOff}
              onClick={() => onChangeParameter({ llmVndGeminiThinkingBudget: 0 })}
              sx={{ mr: 2 }}
            >
              {gemThinkingOff ? <ClearIcon sx={{ fontSize: 'lg' }} /> : <PowerSettingsNewIcon />}
            </IconButton>
          </Tooltip>
        )}
        endAdornment={
          <Tooltip arrow disableInteractive title={gemThinkingAuto ? 'Automatic Thinking (default)' : 'Auto Budget'}>
            <IconButton
              variant={gemThinkingAuto ? 'solid' : 'outlined'}
              // disabled={gemThinkingAuto}
              onClick={() => onRemoveParameter('llmVndGeminiThinkingBudget')}
              sx={{ ml: 2 }}
            >
              <AutoModeIcon sx={{ fontSize: 'xl' }} />
            </IconButton>
          </Tooltip>
        }
      />
    )}

    {showParam('llmVndPerplexitySearchMode') && (
      <FormSelectControl
        title='Search Mode'
        tooltip='Type of sources to prioritize in search results'
        value={llmVndPerplexitySearchMode ?? _UNSPECIFIED}
        onChange={(value) => {
          if (value === _UNSPECIFIED || !value)
            onRemoveParameter('llmVndPerplexitySearchMode');
          else
            onChangeParameter({ llmVndPerplexitySearchMode: value });
        }}
        options={_perplexitySearchModeOptions}
      />
    )}

    {showParam('llmVndOaiWebSearchContext') && (
      <FormSelectControl
        title='Search Size'
        tooltip='Controls how much context is retrieved from the web (low = default for Perplexity, medium = default for OpenAI)'
        value={llmVndOaiWebSearchContext ?? _UNSPECIFIED}
        onChange={(value) => {
          if (value === _UNSPECIFIED || !value)
            onRemoveParameter('llmVndOaiWebSearchContext');
          else
            onChangeParameter({ llmVndOaiWebSearchContext: value });
        }}
        options={_webSearchContextOptions}
      />
    )}

    {showParam('llmVndOaiWebSearchGeolocation') && (
      <FormSwitchControl
        title='Add User Location'
        description='Use approximate location for better search results'
        tooltip='When enabled, uses browser geolocation API to provide approximate location data to improve search results relevance'
        checked={!!llmVndOaiWebSearchGeolocation}
        onChange={checked => {
          if (!checked)
            onRemoveParameter('llmVndOaiWebSearchGeolocation');
          else {
            webGeolocationRequest().then((locationOrNull) => {
              if (locationOrNull)
                onChangeParameter({ llmVndOaiWebSearchGeolocation: true });
            });
          }
        }}
      />
    )}

    {showParam('llmVndPerplexityDateFilter') && (
      <FormSelectControl
        title='Date Range'
        tooltip='Filter search results by publication date'
        value={llmVndPerplexityDateFilter ?? _UNSPECIFIED}
        onChange={(value) => {
          if (value === _UNSPECIFIED || !value)
            onRemoveParameter('llmVndPerplexityDateFilter');
          else
            onChangeParameter({ llmVndPerplexityDateFilter: value });
        }}
        options={_perplexityDateFilterOptions}
      />
    )}

    {showParam('llmVndOaiReasoningEffort') && (
      <FormSelectControl
        title='Reasoning Effort'
        tooltip='Controls how much effort the model spends on reasoning'
        value={llmVndOaiReasoningEffort ?? _UNSPECIFIED}
        onChange={(value) => {
          if (value === _UNSPECIFIED || !value)
            onRemoveParameter('llmVndOaiReasoningEffort');
          else
            onChangeParameter({ llmVndOaiReasoningEffort: value });
        }}
        options={_reasoningEffortOptions}
      />
    )}

    {showParam('llmVndOaiRestoreMarkdown') && (
      <FormSwitchControl
        title='Restore Markdown'
        description='Enable markdown formatting'
        tooltip='o1 and o3 models in the API will avoid generating responses with markdown formatting. This option signals to the model to re-enable markdown formatting in the respons'
        checked={!!llmVndOaiRestoreMarkdown}
        onChange={checked => {
          if (!checked)
            onChangeParameter({ llmVndOaiRestoreMarkdown: false });
          else
            onChangeParameter({ llmVndOaiRestoreMarkdown: true });
        }}
      />
    )}

    {showParam('llmForceNoStream') && (
      <FormSwitchControl
        title='Disable Streaming'
        description='Receive complete responses'
        tooltip='Turn on to get entire responses at once. Useful for models with streaming issues, but will make responses appear slower.'
        checked={!!llmForceNoStream}
        onChange={checked => {
          if (!checked)
            onRemoveParameter('llmForceNoStream');
          else
            onChangeParameter({ llmForceNoStream: true });
        }}
      />
    )}

    {showParam('llmVndXaiSearchMode') && (
      <FormSelectControl
        title='Search Mode'
        tooltip='Controls when to search'
        value={llmVndXaiSearchMode ?? 'auto'}
        onChange={value => onChangeParameter({ llmVndXaiSearchMode: value })}
        options={_xaiSearchModeOptions}
      />
    )}

    {showParam('llmVndXaiSearchSources') && (
      <Box sx={{ display: 'flex', flexDirection: 'column', gap: 1, ml: 0 }}>
        {[
          { key: 'web', label: 'Web Search', description: 'Search websites' },
          { key: 'x', label: 'X Posts', description: 'Search X posts' },
          { key: 'news', label: 'News', description: 'Search news' },
        ].map(({ key, label, description }) => {
          const currentSources = llmVndXaiSearchSources?.split(',').map(s => s.trim()).filter(Boolean) || [];
          const isEnabled = currentSources.includes(key);
          const searchIsOff = llmVndXaiSearchMode === 'off';

          return (
            <FormSwitchControl
              key={key}
              title={label}
              description={description}
              checked={isEnabled}
              disabled={searchIsOff}
              onChange={checked => {
                const newSources = currentSources.filter(s => s !== key);
                if (checked) newSources.push(key);
                const newValue = newSources.length > 0 ? newSources.join(',') : undefined;
                onChangeParameter({ llmVndXaiSearchSources: newValue || 'web,x' });
              }}
            />
          );
        })}
      </Box>
    )}

    {showParam('llmVndXaiSearchDateFilter') && (
      <FormSelectControl
        title='Search Period'
        // tooltip='Recency of search results'
        disabled={llmVndXaiSearchMode === 'off'}
        value={llmVndXaiSearchDateFilter ?? 'unfiltered'}
        onChange={(value) => {
          if (value === 'unfiltered' || !value)
            onRemoveParameter('llmVndXaiSearchDateFilter');
          else
            onChangeParameter({ llmVndXaiSearchDateFilter: value });
        }}
        options={_xaiDateFilterOptions}
      />
    )}

  </>;
}


================================================
FILE: src/modules/llms/models-modal/ModelsConfiguratorModal.tsx
================================================
import * as React from 'react';

import { Box, Button, Divider } from '@mui/joy';

import type { DModelsService } from '~/common/stores/llms/llms.service.types';
import { AppBreadcrumbs } from '~/common/components/AppBreadcrumbs';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { optimaActions } from '~/common/layout/optima/useOptima';
import { useHasLLMs } from '~/common/stores/llms/llms.hooks';
import { useIsMobile } from '~/common/components/useMatchMedia';

import { LLMVendorSetup } from '../components/LLMVendorSetup';
import { ModelsList } from './ModelsList';
import { ModelsServiceSelector } from './ModelsServiceSelector';
import { ModelsWizard } from './ModelsWizard';


// configuration
const MODELS_WIZARD_ENABLE_INITIALLY = true;


type TabValue = 'wizard' | 'setup' | 'defaults';

/**
 * Note: the reason for this component separation from the parent state, is delayed state initialization.
 */
export function ModelsConfiguratorModal(props: {
  modelsServices: DModelsService[],
  confServiceId: string | null,
  setConfServiceId: (serviceId: string | null) => void,
  // allowAutoTrigger: boolean,
}) {

  const { modelsServices, confServiceId, setConfServiceId } = props;

  // state
  // const [showAllServices, setShowAllServices] = React.useState<boolean>(false);
  const [tab, setTab] = React.useState<TabValue>(MODELS_WIZARD_ENABLE_INITIALLY && !modelsServices.length ? 'wizard' : 'setup');
  const showAllServices = false;

  // external state
  const isMobile = useIsMobile();
  const hasLLMs = useHasLLMs();


  // active service with fallback to the last added service
  const activeServiceId = confServiceId
    ?? modelsServices[modelsServices.length - 1]?.id
    ?? null;

  const activeService = modelsServices.find(s => s.id === activeServiceId);

  const hasAnyServices = !!modelsServices.length;
  const isTabWizard = tab === 'wizard';
  const isTabSetup = tab === 'setup';
  // const isTabDefaults = tab === 'defaults';


  // Auto-add the default service - at boot, when no service is present
  // const autoAddTrigger = !showWizard && props.allowAutoTrigger;
  // React.useEffect(() => {
  //   // Note: we use the immediate version to not react to deletions
  //   const { createModelsService, sources: modelsServices } = llmsStoreState();
  //   if (autoAddTrigger && !modelsServices.length)
  //     createModelsService(getDefaultModelVendor());
  // }, [autoAddTrigger]);

  // [effect] Re-trigger easy mode when going back to 0 services
  const triggerWizard = !modelsServices.length;
  React.useEffect(() => {
    if (triggerWizard)
      setTab('wizard');
  }, [triggerWizard]);


  // handlers
  const handleShowAdvanced = React.useCallback(() => setTab('setup'), []);
  const handleShowWizard = React.useCallback(() => setTab('wizard'), []);
  // const handleToggleDefaults = React.useCallback(() => setTab(tab => tab === 'defaults' ? 'setup' : 'defaults'), []);


  // start button
  const startButton = React.useMemo(() => {
    if (isTabWizard)
      return <Button variant='outlined' color='neutral' onClick={handleShowAdvanced} sx={{ backgroundColor: 'background.popup' }}>{isMobile ? 'More Services' : 'More Services'}</Button>;
    // return <Badge size='sm' badgeContent='14 Services' color='neutral' variant='outlined'><Button variant='outlined' color='neutral' onClick={handleShowAdvanced}>{isMobile ? 'Advanced' : 'Switch to Advanced'}</Button></Badge>;
    if (!hasAnyServices)
      return <Button variant='outlined' color='neutral' onClick={handleShowWizard} sx={{ backgroundColor: 'background.popup' }}>{isMobile ? 'Quick Setup' : 'Quick Setup'}</Button>;
    return undefined;
    // if (isMultiServices) {
    //   return (
    //     <Checkbox
    //       label='All Services'
    //       sx={{ my: 'auto' }}
    //       checked={showAllServices} onChange={() => setShowAllServices(all => !all)}
    //     />
    //   );
    // }
  }, [handleShowAdvanced, handleShowWizard, hasAnyServices, isMobile, isTabWizard]);


  return (
    <GoodModal
      title={isTabWizard ? (
        <AppBreadcrumbs size='md' rootTitle='Welcome'>
          <AppBreadcrumbs.Leaf>Setup <b>AI Models</b></AppBreadcrumbs.Leaf>
        </AppBreadcrumbs>
      ) : (
        // <>Configure <b>AI Models</b></>
        <AppBreadcrumbs size='md' rootTitle='Configure'>
          <AppBreadcrumbs.Leaf><b>AI Models</b></AppBreadcrumbs.Leaf>
          {/*<Box sx={{ display: 'flex', gap: 1 }}>*/}
          {/*  {!hasLLMs ? <AppBreadcrumbs.Leaf>Setup</AppBreadcrumbs.Leaf> : <>*/}
          {/*    <Chip size='lg' variant={isTabSetup ? 'solid' : 'outlined'} color='neutral' onClick={isTabSetup ? undefined : handleToggleDefaults} sx={{}}>*/}
          {/*      Setup*/}
          {/*    </Chip>*/}
          {/*    <Chip size='lg' variant={isTabDefaults ? 'solid' : 'outlined'} color='neutral' onClick={isTabDefaults ? undefined : handleToggleDefaults} sx={{}}>*/}
          {/*      Defaults*/}
          {/*    </Chip>*/}
          {/*  </>}*/}
          {/*</Box>*/}
        </AppBreadcrumbs>
      )}
      open onClose={optimaActions().closeModels}
      darkBottomClose={!isTabWizard}
      closeText={isTabWizard ? 'Done' : undefined}
      animateEnter={!hasLLMs}
      unfilterBackdrop
      startButton={startButton}
      autoOverflow={true /* forces some shrinkage of the contents (ModelsList) */}
    >

      {isTabWizard && <Divider />}
      {isTabWizard && <ModelsWizard isMobile={isMobile} onSkip={optimaActions().closeModels} onSwitchToAdvanced={handleShowAdvanced} />}

      {isTabSetup && <ModelsServiceSelector modelsServices={modelsServices} selectedServiceId={activeServiceId} setSelectedServiceId={setConfServiceId} />}
      {isTabSetup && <Divider sx={activeService ? undefined : { visibility: 'hidden' }} />}
      {isTabSetup && (
        <Box sx={{ display: 'grid', gap: 'var(--Card-padding)' }}>
          {activeService
            ? <LLMVendorSetup service={activeService} />
            : <Box sx={{ minHeight: '7.375rem' }} />
          }
        </Box>
      )}

      {isTabSetup && hasLLMs && <Divider />}
      {isTabSetup && hasLLMs && (
        <ModelsList
          filterServiceId={showAllServices ? null : activeServiceId}
          onOpenLLMOptions={optimaActions().openModelOptions}
          sx={{
            // works in tandem with the parent (GoodModal > Dialog) overflow: 'auto'
            minHeight: '6rem',
            overflowY: 'auto',

            // style (list variant=outlined)
            '--ListItem-paddingY': '0rem',
            '--ListItem-paddingRight': '0.5rem', // instead of 0.75
            backgroundColor: 'rgb(var(--joy-palette-neutral-lightChannel) / 20%)',
            borderRadius: 'md',

            // [mobile] a bit less padding
            '@media (max-width: 900px)': {
              '--ListItem-paddingLeft': '0.5rem',
              '--ListItem-paddingRight': '0.25rem',
            },
          }}
        />
      )}

      <Divider sx={{ visibility: 'hidden', height: 0 }} />

    </GoodModal>
  );
}



================================================
FILE: src/modules/llms/models-modal/ModelsList.tsx
================================================
import * as React from 'react';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Chip, IconButton, List, ListItem, ListItemButton, Typography } from '@mui/joy';
import PsychologyOutlinedIcon from '@mui/icons-material/PsychologyOutlined';
import SdCardOutlinedIcon from '@mui/icons-material/SdCardOutlined';
import VisibilityOffOutlinedIcon from '@mui/icons-material/VisibilityOffOutlined';
import VisibilityOutlinedIcon from '@mui/icons-material/VisibilityOutlined';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { DLLM, DLLMId, LLM_IF_ANT_PromptCaching, LLM_IF_GEM_CodeExecution, LLM_IF_OAI_Chat, LLM_IF_OAI_Complete, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching, LLM_IF_OAI_Realtime, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Vision, LLM_IF_Outputs_Audio, LLM_IF_Outputs_Image, LLM_IF_Tools_WebSearch } from '~/common/stores/llms/llms.types';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { PhGearSixIcon } from '~/common/components/icons/phosphor/PhGearSixIcon';
import { findModelsServiceOrNull, llmsStoreActions } from '~/common/stores/llms/store-llms';
import { useLLMsByService } from '~/common/stores/llms/llms.hooks';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useModelDomains } from '~/common/stores/llms/hooks/useModelDomains';

import type { IModelVendor } from '../vendors/IModelVendor';
import { findModelVendor } from '../vendors/vendors.registry';


// configuration
const SHOW_LLM_INTERFACES = false;


const absorbListPadding: SxProps = { my: 'calc(var(--ListItem-paddingY) / -2)' };

const styles = {
  liButton: {
    border: 'none',
    width: '100%',
    display: 'flex',
    alignItems: 'center',
    gap: {
      xs: 0.5,
      md: 1,
    } as const,
  } as const,
  modelText: {
    flex: 1,
    wordBreak: 'break-all',
  } as const,
  modelHiddenText: {
    flex: 1,
    wordBreak: 'break-all',
    color: 'neutral.plainDisabledColor',
  } as const,
  chipPreferred: {
    // boxShadow: 'sm',
  } as const,
  chipFree: {
    // boxShadow: 'sm',
    boxShadow: 'md',
  } as const,
  chipCapability: {
    // boxShadow: 'sm',
    boxShadow: 'md',
  } as const,
  // styleNameChip: {
  //   marginLeft: '0.5rem',
  //   fontSize: '0.75rem',
  // } as const,
} as const;


function ModelItem(props: {
  llm: DLLM,
  serviceLabel: string,
  vendor: IModelVendor,
  chipChat: boolean,
  chipCode: boolean,
  chipFast: boolean,
  isMobile: boolean,
  onModelClicked: (llmId: DLLMId) => void,
  onModelSetHidden: (llmId: DLLMId, hidden: boolean) => void,
  onModelSetStarred: (llmId: DLLMId, starred: boolean) => void,
}) {

  // derived
  const { llm, onModelClicked, onModelSetHidden /*, onModelSetStarred*/ } = props;

  const seemsFree = !!llm.pricing?.chat?._isFree;
  const isNotSymlink = !llm.label.startsWith('🔗');


  const handleLLMConfigure = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    if (event.shiftKey) {
      console.log('llm', llm);
      return;
    }
    onModelClicked(llm.id);
  }, [llm, onModelClicked]);

  const handleLLMHide = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    onModelSetHidden(llm.id, true);
  }, [llm.id, onModelSetHidden]);

  const handleLLMUnhide = React.useCallback((event: React.MouseEvent) => {
    event.stopPropagation();
    onModelSetHidden(llm.id, false);
  }, [llm.id, onModelSetHidden]);

  // const handleLLMToggleStar = React.useCallback((event: React.MouseEvent) => {
  //   event.stopPropagation();
  //   onModelSetStarred(llm.id, !llm.userStarred);
  // }, [llm.id, llm.userStarred, onModelSetStarred]);


  // label will be of the form "Model Name (Date)" - here we extract the date
  // const label = llm.label;
  // const dateMatch = _label.match(/^(.*?)\s*\(([^)]+)\)$/);
  // const labelWithoutDate = dateMatch ? dateMatch[1].trim() : _label;
  // const labelDate = dateMatch ? dateMatch[2] : '';

  let tooltip = props.serviceLabel;
  if (llm.description)
    tooltip += ' · ' + llm.description;
  if (llm.contextTokens) {
    tooltip += '\n\n' + llm.contextTokens.toLocaleString() + ' tokens';
    if (llm.maxOutputTokens)
      tooltip += ' / ' + llm.maxOutputTokens.toLocaleString() + ' max output tokens';
  } else
    tooltip += ' · token count not provided';
  if (seemsFree)
    tooltip += '\n\n🎁 Free model - refresh to check for pricing updates';

  const chipsComponentsMemo = React.useMemo(() => {
    if (!SHOW_LLM_INTERFACES)
      return null;
    return llm.interfaces.map((iface, i) => {
      switch (iface) {
        // case LLM_IF_OAI_Chat:
        //   return <Chip key={i} size='sm' variant={props.chipChat ? 'solid' : 'plain'} sx={{ boxShadow: 'xs' }}><TextsmsOutlinedIcon /></Chip>;
        case LLM_IF_OAI_Vision:
          return <Chip key={i} size='sm' variant='plain' sx={{ boxShadow: 'xs' }}><VisibilityOutlinedIcon />️</Chip>;
        case LLM_IF_OAI_Reasoning:
          return <Chip key={i} size='sm' variant='plain' sx={{ boxShadow: 'xs' }}><PsychologyOutlinedIcon /></Chip>;
        case LLM_IF_ANT_PromptCaching:
        case LLM_IF_OAI_PromptCaching:
          return <Chip key={i} size='sm' variant='plain' sx={{ boxShadow: 'xs' }}><SdCardOutlinedIcon /></Chip>;
        // Ignored
        case LLM_IF_OAI_Json:
        case LLM_IF_OAI_Fn:
        case LLM_IF_OAI_Complete:
        case LLM_IF_OAI_Realtime:
        case LLM_IF_GEM_CodeExecution:
          return null;
      }
    }).reverse();
  }, [llm.interfaces]);

  return (
    <ListItem>
      <ListItemButton
        aria-label='Configure LLM'
        // color={(seemsFree && !llm.hidden) ? 'success' : undefined}
        // variant={(seemsFree && !llm.hidden) ? 'soft' : undefined}
        onClick={handleLLMConfigure}
        tabIndex={-1}
        sx={styles.liButton}
      >

        {/* Model Name */}
        <GoodTooltip title={tooltip}>
          <Box sx={llm.hidden ? styles.modelHiddenText : styles.modelText} className='agi-ellipsize'>
            {(/*props.isMobile &&*/ llm.userStarred) ? `⭐ ${llm.label}` : llm.label}
            {/*{labelWithoutDate}{labelDate && <Box component='span' sx={{ typography: 'body-sm',color: llm.hidden ? 'neutral.plainDisabledColor' : undefined  }}> · ({labelDate})</Box>}*/}
            {/*{llm.interfaces.includes(LLM_IF_OAI_Reasoning) && <span style={styles.styleNameChip}>🧠</span>}*/}
          </Box>
        </GoodTooltip>

        {/* Preferred Chips */}
        {SHOW_LLM_INTERFACES ? (chipsComponentsMemo && (
          <Box sx={{
            mr: 2,
            display: 'flex', gap: 0.5,
            // the following line is to absorb the padding of the list item
            // my: 'calc(var(--ListItem-paddingY) / -2)',
          }}>
            {chipsComponentsMemo}
          </Box>
        )) : <>
          {props.chipChat && <Chip size='sm' variant='solid' sx={styles.chipPreferred}>chat</Chip>}
          {props.chipCode && <Chip size='sm' variant='solid' sx={styles.chipPreferred}>code</Chip>}
          {props.chipFast && <Chip size='sm' variant='solid' sx={styles.chipPreferred}>util</Chip>}
        </>}

        {/* Features Chips - sync with `useLLMSelect.tsx` */}
        {llm.interfaces.includes(LLM_IF_OAI_Reasoning) && isNotSymlink && <Chip size='sm' variant='plain' sx={styles.chipCapability}>🧠</Chip>}
        {llm.interfaces.includes(LLM_IF_Tools_WebSearch) && isNotSymlink && <Chip size='sm' variant='plain' sx={styles.chipCapability}>🌐</Chip>}
        {llm.interfaces.includes(LLM_IF_Outputs_Audio) && isNotSymlink && <Chip size='sm' variant='plain' sx={styles.chipCapability}>🔊️</Chip>}
        {llm.interfaces.includes(LLM_IF_Outputs_Image) && isNotSymlink && <Chip size='sm' variant='plain' sx={styles.chipCapability}>🖼️</Chip>}
        {seemsFree && isNotSymlink && <Chip size='sm' color='success' variant='plain' sx={styles.chipFree}>free</Chip>}


        {/* Action Buttons */}

        <Box sx={{ display: 'flex', gap: 1 }}>

          {/*{!props.isMobile && <GoodTooltip title={llm.userStarred ? 'Unstar' : 'Star this model'}>*/}
          {/*  <IconButton size='sm' onClick={handleLLMToggleStar} sx={absorbListPadding}>*/}
          {/*    {llm.userStarred ? <StarIcon sx={{ color: '#fad857' }} /> : <StarBorderIcon sx={{ opacity: 0.5, fontSize: 'md' }} />}*/}
          {/*  </IconButton>*/}
          {/*</GoodTooltip>}*/}

          {!props.isMobile && <GoodTooltip title={llm.hidden ? 'Hidden' : 'Shown in Chat'}>
            <IconButton aria-label={llm.hidden ? 'Unhide' : 'Hide in Chat'} size='sm' onClick={llm.hidden ? handleLLMUnhide : handleLLMHide} sx={absorbListPadding}>
              {llm.hidden ? <VisibilityOffOutlinedIcon sx={{ opacity: 0.5, fontSize: 'md' }} /> : <VisibilityOutlinedIcon />}
            </IconButton>
          </GoodTooltip>}

          <GoodTooltip title='Options'>
            <IconButton aria-label='Configure LLM' size='sm' sx={absorbListPadding} onClick={handleLLMConfigure}>
              <PhGearSixIcon />
            </IconButton>
          </GoodTooltip>

        </Box>

      </ListItemButton>
    </ListItem>
  );
}

export function ModelsList(props: {
  filterServiceId: DModelsServiceId | null,
  onOpenLLMOptions: (id: DLLMId) => void,
  sx?: SxProps,
}) {

  // external state
  const isMobile = useIsMobile();
  const domainAssignments = useModelDomains();
  const llms = useLLMsByService(props.filterServiceId === null ? false : props.filterServiceId);

  const { onOpenLLMOptions } = props;

  const handleModelClicked = React.useCallback((llmId: DLLMId) => onOpenLLMOptions(llmId), [onOpenLLMOptions]);

  const handleModelSetHidden = React.useCallback((llmId: DLLMId, hidden: boolean) => llmsStoreActions().updateLLM(llmId, { hidden }), []);

  const handleModelSetStarred = React.useCallback((llmId: DLLMId, starred: boolean) => llmsStoreActions().updateLLM(llmId, { userStarred: starred }), []);

  const modelItems: React.ReactNode[] = React.useMemo(() => {

    // are we showing multiple services
    const showAllServices = !props.filterServiceId;
    const hasManyServices = llms.length >= 2 && llms.some(llm => llm.sId !== llms[0].sId);
    let lastGroupLabel = '';

    // derived
    const primaryChatLlmId = domainAssignments['primaryChat']?.modelId;
    // const codeApplyLlmId = domainAssignments['codeApply']?.modelId;
    const fastUtilLlmId = domainAssignments['fastUtil']?.modelId;

    // generate the list items, prepending headers when necessary
    const items: React.JSX.Element[] = [];
    for (const llm of llms) {

      // get the service label
      const serviceLabel = findModelsServiceOrNull(llm.sId)?.label ?? llm.sId;

      // prepend label when switching services
      if ((hasManyServices || showAllServices) && serviceLabel !== lastGroupLabel) {
        items.push(
          <ListItem key={'lab-' + llm.sId} sx={{ justifyContent: 'center' }}>
            <Typography>
              {serviceLabel}
            </Typography>
          </ListItem>,
        );
        lastGroupLabel = serviceLabel;
      }

      // for safety, ensure the vendor exists
      const vendor = findModelVendor(llm.vId);
      !!vendor && items.push(
        <ModelItem
          key={'llm-' + llm.id}
          llm={llm}
          serviceLabel={serviceLabel}
          vendor={vendor}
          chipChat={llm.id === primaryChatLlmId}
          chipCode={false /* do not show the CODE chip for now, to not confuse users llm.id === codeApplyLlmId*/}
          chipFast={llm.id === fastUtilLlmId}
          isMobile={isMobile}
          onModelClicked={handleModelClicked}
          onModelSetHidden={handleModelSetHidden}
          onModelSetStarred={handleModelSetStarred}
        />,
      );
    }

    return items;
  }, [domainAssignments, handleModelClicked, handleModelSetHidden, handleModelSetStarred, isMobile, llms, props.filterServiceId]);

  return (
    <List size={!isMobile ? undefined : 'sm'} variant='outlined' sx={props.sx}>
      {modelItems.length > 0 ? modelItems : (
        <ListItem sx={{ display: 'flex', flexDirection: 'column', gap: 0.5, flex: 1, justifyContent: 'center', alignItems: 'center' }}>
          <Typography level='body-sm'>
            Please complete the configuration and refresh the models list.
          </Typography>
          {/*<Skeleton variant='rectangular' animation={false} height={24} width={160} />*/}
          {/*<Skeleton variant='rectangular' animation={false} height={24} width={120} />*/}
          {/*<Skeleton variant='rectangular' animation={false} height={24} width={140} />*/}
        </ListItem>
      )}
    </List>
  );
}


================================================
FILE: src/modules/llms/models-modal/ModelsModals.tsx
================================================
import * as React from 'react';

import { optimaActions, useOptimaModals } from '~/common/layout/optima/useOptima';
import { useModelsServices } from '~/common/stores/llms/llms.hooks';

import { LLMOptionsModal } from './LLMOptionsModal';
import { ModelsConfiguratorModal } from './ModelsConfiguratorModal';


/**
 * This is here so we can lazy-load the ModelsModals component, which includes two medium-heavy modals.
 */
export function ModelsModals() {

  // external state
  const { showModels, showModelOptions } = useOptimaModals();
  const { modelsServices, confServiceId, setConfServiceId } = useModelsServices();


  return <>

    {/* Services Setup */}
    {showModels && (
      <ModelsConfiguratorModal
        modelsServices={modelsServices}
        confServiceId={confServiceId}
        setConfServiceId={setConfServiceId}
      />
    )}

    {/* per-LLM options */}
    {!!showModelOptions && (
      <LLMOptionsModal id={showModelOptions} onClose={optimaActions().closeModelOptions} />
    )}

  </>;
}



================================================
FILE: src/modules/llms/models-modal/ModelsServiceSelector.tsx
================================================
import * as React from 'react';

import { Badge, Box, Button, IconButton, ListItemDecorator, MenuItem, Option, Select, Tooltip, Typography } from '@mui/joy';
import AddIcon from '@mui/icons-material/Add';
import DeleteOutlineIcon from '@mui/icons-material/DeleteOutline';

import type { DModelsService, DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { CloseablePopup } from '~/common/components/CloseablePopup';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { llmsStoreActions } from '~/common/stores/llms/store-llms';
import { themeZIndexOverMobileDrawer } from '~/common/app.theme';
import { useIsMobile } from '~/common/components/useMatchMedia';
import { useOverlayComponents } from '~/common/layout/overlays/useOverlayComponents';

import type { IModelVendor } from '../vendors/IModelVendor';
import { LLMVendorIcon } from '../components/LLMVendorIcon';
import { findAllModelVendors, findModelVendor } from '../vendors/vendors.registry';
import { vendorHasBackendCap } from '../vendors/vendor.helpers';
// import { MODELS_WIZARD_OPTION_ID } from '~/modules/llms/models-modal/ModelsModal';


// configuration
const ENABLE_DELETE_LAST = true; // This will fall the menu back to the 'Quick Setup' mode. was: Release.IsNodeDevBuild;


/*function locationIcon(vendor?: IModelVendor | null) {
  if (vendor && vendor.id === 'openai' && vendorHasBackendCap(...))
    return <CloudDoneOutlinedIcon />;
  return !vendor ? null : vendor.location === 'local' ? <ComputerIcon /> : <CloudOutlinedIcon />;
}*/

function vendorIcon(vendor: IModelVendor | null, greenMark: boolean) {
  const icon = !vendor?.id ? null : <LLMVendorIcon vendorId={vendor.id} />;
  return (greenMark && icon)
    ? <Badge size='sm' badgeContent='' slotProps={{ badge: { sx: { backgroundColor: 'lime', boxShadow: 'none', border: '1px solid gray', p: 0 } } }}>{icon}</Badge>
    : icon;
}


export function ModelsServiceSelector(props: {
  modelsServices: DModelsService[],
  selectedServiceId: DModelsServiceId | null,
  setSelectedServiceId: (serviceId: DModelsServiceId | null) => void,
}) {

  // state
  const { showPromisedOverlay } = useOverlayComponents();
  const [vendorsMenuAnchor, setVendorsMenuAnchor] = React.useState<HTMLElement | null>(null);

  // external state
  const isMobile = useIsMobile();

  const handleShowVendors = (event: React.MouseEvent<HTMLElement>) => setVendorsMenuAnchor(event.currentTarget);

  const closeVendorsMenu = () => setVendorsMenuAnchor(null);


  // handlers

  const { modelsServices, setSelectedServiceId } = props;

  const handleAddServiceForVendor = React.useCallback((vendor: IModelVendor) => {
    closeVendorsMenu();
    const modelsService = llmsStoreActions().createModelsService(vendor);
    setSelectedServiceId(modelsService.id);
  }, [setSelectedServiceId]);

  const enableDeleteButton = !!props.selectedServiceId && (ENABLE_DELETE_LAST || modelsServices.length > 1);

  const handleDeleteService = React.useCallback(async (serviceId: DModelsServiceId, skipConfirmation: boolean) => {
    // [shift] to delete without confirmation
    if (skipConfirmation) {
      // select the next service
      setSelectedServiceId(modelsServices.find(s => s.id !== serviceId)?.id ?? null);
      // remove the service
      llmsStoreActions().removeService(serviceId);
      return;
    }
    showPromisedOverlay('llms-service-remove', {}, ({ onResolve, onUserReject }) =>
      <ConfirmationModal
        open onClose={onUserReject} onPositive={() => onResolve(true)}
        confirmationText='Are you sure you want to remove these models? The configuration data will be lost and you may have to enter it again.'
        positiveActionText='Remove'
      />,
    ).then(() => {
      // select the next service
      setSelectedServiceId(modelsServices.find(s => s.id !== serviceId)?.id ?? null);
      // remove the service
      llmsStoreActions().removeService(serviceId);
    }).catch(() => null /* ignore closure */);
  }, [modelsServices, setSelectedServiceId, showPromisedOverlay]);


  // vendor list items
  const vendorComponents = React.useMemo(() => {

    // prepare the items
    const vendorItems = findAllModelVendors()
      .filter(v => v.instanceLimit !== 0)
      .sort((a, b) => {
        // sort first by 'cloud' on top (vs. 'local'), then by name
        // if (a.location !== b.location)
        //   return a.location === 'cloud' ? -1 : 1;
        return a.name.localeCompare(b.name);
      })
      .map(vendor => {
          const vendorInstancesCount = modelsServices.filter(s => s.vId === vendor.id).length;
          const enabled = (vendor.instanceLimit ?? 1) > vendorInstancesCount;
          return {
            vendor,
            enabled,
            component: (
              <MenuItem key={vendor.id} disabled={!enabled} onClick={() => handleAddServiceForVendor(vendor)}>
                <ListItemDecorator>
                  {vendorIcon(vendor, vendorHasBackendCap(vendor))}
                </ListItemDecorator>
                {vendor.name}

                {/*{vendorInstancesCount > 0 && ` (added)`}*/}

                {/* Free indication */}
                {/*{!!vendor.hasFreeModels && ` 🎁`}*/}

                {/* Multiple instance hint */}
                {(vendor.instanceLimit ?? 1) > 1 && !!vendorInstancesCount && enabled && (
                  <Typography component='span' level='body-sm'>
                    #{vendorInstancesCount + 1}
                    {/*/{vendor.instanceLimit ?? 1}*/}
                  </Typography>
                )}

                {/* Local chip */}
                {/*{vendor.location === 'local' && (*/}
                {/*  <Chip variant='solid' size='sm'>*/}
                {/*    local*/}
                {/*  </Chip>*/}
                {/*)}*/}
              </MenuItem>
            ),
          };
        },
      );

    // prepend headers
    // const components: React.ReactNode[] = [];
    // let lastLocation: 'cloud' | 'local' | null = null;
    // vendorItems.forEach(item => {
    //   if (item.vendor.location !== lastLocation) {
    //     lastLocation = item.vendor.location;
    //     components.push(
    //       <Typography key={lastLocation} level='body-xs' sx={{
    //         color: 'text.tertiary',
    //         mx: 1.5,
    //         mt: 1,
    //         mb: 1,
    //       }}>
    //         {lastLocation === 'cloud' ? 'Cloud Services' : 'Local Services'}
    //       </Typography>,
    //     );
    //   }
    //   components.push(item.component);
    // });
    // return components;

    return vendorItems.map(item => item.component);
  }, [handleAddServiceForVendor, modelsServices]);

  // service items
  const serviceItems: { service: DModelsService, icon: React.ReactNode, component: React.ReactNode }[] = React.useMemo(() =>
      modelsServices.map(service => {
        const icon = vendorIcon(findModelVendor(service.vId), false);
        return {
          service,
          icon,
          component: (
            <Option key={service.id} value={service.id}>
              {/*<ListItemDecorator>{icon}</ListItemDecorator>*/}
              {service.label}
            </Option>
          ),
        };
      }).sort((a, b) => a.service.label.localeCompare(b.service.label))
    , [modelsServices]);

  const selectedServiceItem = serviceItems.find(item => item.service.id === props.selectedServiceId);
  const noServices = !serviceItems.length;

  return (
    <Box sx={{ display: 'flex', flexDirection: 'row', flexWrap: 'wrap', alignItems: 'center', gap: 1 }}>

      {/* Models: [Select] Add Delete */}
      {!isMobile && <Typography sx={{ mr: 1 }}>
        Service:
      </Typography>}

      <Select
        variant='outlined'
        value={props.selectedServiceId}
        disabled={noServices}
        onChange={(_event, value) => value && props.setSelectedServiceId(value)}
        startDecorator={selectedServiceItem?.icon}
        slotProps={{
          root: { sx: { minWidth: 180 } },
          indicator: { sx: { opacity: 0.5 } },
        }}
      >
        {serviceItems.map(item => item.component)}

        {/* Add Service button */}
        {/*<ListDivider />*/}
        {/*<ListItem onClick={handleShowVendors}>*/}
        {/*  <ListItemButton>*/}
        {/*    <ListItemDecorator>*/}
        {/*      <AddIcon />*/}
        {/*    </ListItemDecorator>*/}
        {/*    Add Service*/}
        {/*  </ListItemButton>*/}
        {/*</ListItem>*/}
      </Select>

      {(isMobile && !noServices) ? (
        <IconButton variant={noServices ? 'solid' : 'outlined'} color='primary' onClick={handleShowVendors} disabled={!!vendorsMenuAnchor} sx={{ borderColor: 'neutral.outlinedBorder' }}>
          <AddIcon />
        </IconButton>
      ) : (
        <Tooltip open={noServices && !vendorsMenuAnchor} variant='outlined' color='primary' size='md' placement={isMobile ? 'bottom-end' : 'top-start'} arrow title='Add your first AI service'>
          <Button variant={noServices ? 'solid' : 'outlined'} onClick={handleShowVendors} disabled={!!vendorsMenuAnchor} startDecorator={<AddIcon />} sx={{ borderColor: 'neutral.outlinedBorder' }}>
            Add
          </Button>
        </Tooltip>
      )}

      {enableDeleteButton && (
        <TooltipOutlined title={`Remove ${selectedServiceItem?.service.label || 'Service'}`}>
          <IconButton
            variant='plain' color='neutral' disabled={!enableDeleteButton} sx={{ ml: 'auto' }}
            onClick={(event) => props.selectedServiceId && handleDeleteService(props.selectedServiceId, event.shiftKey)}
          >
            <DeleteOutlineIcon />
          </IconButton>
        </TooltipOutlined>
      )}


      {/* vendors popup, for adding */}
      <CloseablePopup
        menu anchorEl={vendorsMenuAnchor} onClose={closeVendorsMenu}
        minWidth={200}
        placement='auto-end'
        zIndex={themeZIndexOverMobileDrawer}
      >
        {vendorComponents}
      </CloseablePopup>

    </Box>
  );
}


================================================
FILE: src/modules/llms/models-modal/ModelsWizard.tsx
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import { Avatar, Badge, Box, Button, Chip, CircularProgress, Input, Sheet, Typography } from '@mui/joy';

import { TooltipOutlined } from '~/common/components/TooltipOutlined';
import { llmsStoreActions, llmsStoreState, useModelsStore } from '~/common/stores/llms/store-llms';
import { useShallowStabilizer } from '~/common/util/hooks/useShallowObject';

import type { IModelVendor } from '../vendors/IModelVendor';
import { LLMVendorIcon } from '../components/LLMVendorIcon';
import { ModelVendorAnthropic } from '../vendors/anthropic/anthropic.vendor';
import { ModelVendorGemini } from '../vendors/gemini/gemini.vendor';
import { ModelVendorLMStudio } from '../vendors/lmstudio/lmstudio.vendor';
import { ModelVendorLocalAI } from '../vendors/localai/localai.vendor';
import { ModelVendorOllama } from '../vendors/ollama/ollama.vendor';
import { ModelVendorOpenAI } from '../vendors/openai/openai.vendor';
import { llmsUpdateModelsForServiceOrThrow } from '../llm.client';


// configuration
const WizardProviders: ReadonlyArray<WizardProvider> = [
  { cat: 'popular', vendor: ModelVendorOpenAI, settingsKey: 'oaiKey' } as const,
  { cat: 'popular', vendor: ModelVendorAnthropic, settingsKey: 'anthropicKey' } as const,
  { cat: 'popular', vendor: ModelVendorGemini, settingsKey: 'geminiKey' } as const,
  { cat: 'local', vendor: ModelVendorLocalAI, settingsKey: 'localAIHost' } as const,
  { cat: 'local', vendor: ModelVendorOllama, settingsKey: 'ollamaHost' } as const,
  { cat: 'local', vendor: ModelVendorLMStudio, settingsKey: 'oaiHost', omit: true } as const,
  // { vendor: ModelVendorOpenRouter, settingsKey: 'oaiKey' } as const,
] as const;

type VendorCategory = 'popular' | 'local';

interface WizardProvider {
  cat: VendorCategory,
  vendor: IModelVendor<Record<string, any>, Record<string, any>>,
  settingsKey: string,
  omit?: boolean,
}


const _styles = {

  container: {
    margin: 'calc(-1 * var(--Card-padding, 1rem))',
    padding: 'var(--Card-padding)',
    // paddingRight: 'calc(1.5 * var(--Card-padding))',
    // background: 'linear-gradient(135deg, var(--joy-palette-primary-500), var(--joy-palette-primary-700))',
    // background: 'linear-gradient(135deg, var(--joy-palette-background-level1), var(--joy-palette-background-level1))',
    display: 'grid',
    gap: 'calc(0.75 * var(--Card-padding))',
  } as const,

  text1: {
    my: 1,
    ml: 7.25,
    display: 'flex',
    flexDirection: 'column',
    gap: 0.25,
  } as const,

  text1Mobile: {
    mb: 2,
    display: 'flex',
    flexDirection: 'column',
    gap: 0.25,
  } as const,

  text2: {
    my: 1,
    ml: 7.25,
    color: 'text.tertiary',
    fontSize: 'sm',
  } as const,

  text2Mobile: {
    mt: 2,
    color: 'text.tertiary',
    fontSize: 'sm',
  } as const,

} as const;


function WizardProviderSetup(props: {
  provider: WizardProvider,
  isFirst: boolean,
  isHidden: boolean,
}) {

  const { cat: providerCat, vendor: providerVendor, settingsKey: providerSettingsKey, omit: providerOmit } = props.provider;

  // state
  const [localValue, setLocalValue] = React.useState<string | null>(null);
  const [isLoading, setIsLoading] = React.useState(false);
  const [updateError, setUpdateError] = React.useState<string | null>(null);

  // external state
  const stabilizeTransportAccess = useShallowStabilizer<Record<string, any>>();
  const { serviceKeyValue, serviceLLMsCount } = useModelsStore(useShallow(({ llms, sources }) => {

    // find the service | null
    const vendorService = sources.find(s => s.vId === providerVendor.id) ?? null;

    // (safe) service-derived properties
    const serviceLLMsCount = !vendorService ? null : llms.filter(llm => llm.sId === vendorService.id).length;
    const serviceAccess = stabilizeTransportAccess(providerVendor.getTransportAccess(vendorService?.setup));
    const serviceKeyValue = !serviceAccess ? null : vendorService?.setup[providerSettingsKey] ?? null;

    return {
      serviceKeyValue,
      serviceLLMsCount,
    };
  }));

  // [effect] initialize the local key
  const triggerValueLoad = localValue === null;
  React.useEffect(() => {
    if (triggerValueLoad)
      setLocalValue(serviceKeyValue || '');
  }, [serviceKeyValue, triggerValueLoad]);


  // derived
  const isLocal = providerCat === 'local';
  const valueName = isLocal ? 'server' : 'API Key';
  const { name: vendorName } = providerVendor;


  // handlers

  const handleTextChanged = React.useCallback((e: React.ChangeEvent) => {
    setLocalValue((e.target as HTMLInputElement).value);
  }, []);

  const handleSetServiceKeyValue = React.useCallback(async () => {

    // create the service if missing
    const { sources: llmsServices } = llmsStoreState();
    const { createModelsService, updateServiceSettings, setServiceLLMs } = llmsStoreActions();
    const vendorService = llmsServices.find(s => s.vId === providerVendor.id) || createModelsService(providerVendor);
    const vendorServiceId = vendorService.id;

    // set the key
    const newKey = localValue?.trim() ?? '';
    updateServiceSettings(vendorServiceId, { [providerSettingsKey]: newKey });

    // if the key is empty, remove the models
    if (!newKey) {
      setUpdateError(null);
      setServiceLLMs(vendorServiceId, [], false, false);
      return;
    }

    // update the models
    setUpdateError(null);
    setIsLoading(true);
    try {
      await llmsUpdateModelsForServiceOrThrow(vendorService.id, true);
    } catch (error: any) {
      let errorText = error.message || `An error occurred. Please check your ${valueName}.`;
      if (errorText.includes('Incorrect API key'))
        errorText = '[OpenAI issue] Unauthorized: Incorrect API key.';
      setUpdateError(errorText);
      setServiceLLMs(vendorServiceId, [], false, false);
    }
    setIsLoading(false);

  }, [localValue, providerSettingsKey, providerVendor, valueName]);


  // memoed components

  const endButtons = React.useMemo(() => ((localValue || '') === (serviceKeyValue || '')) ? null : (
    <Box sx={{ display: 'flex', gap: 2 }}>
      {/*<TooltipOutlined title='Clear Key'>*/}
      {/*  <IconButton variant='outlined' color='neutral' onClick={handleClear}>*/}
      {/*    <ClearIcon />*/}
      {/*  </IconButton>*/}
      {/*</TooltipOutlined>*/}
      {/*<TooltipOutlined title='Confirm'>*/}
      <Button
        variant='solid' color='primary'
        onClick={handleSetServiceKeyValue}
        // endDecorator={<CheckRoundedIcon />}
      >
        {!serviceKeyValue ? 'Confirm' : !localValue?.trim() ? 'Clear' : 'Update'}
      </Button>
      {/*</TooltipOutlined>*/}
    </Box>
  ), [handleSetServiceKeyValue, localValue, serviceKeyValue]);


  // heuristics for warnings
  const isOnLocalhost = typeof window !== 'undefined' && window.location.hostname === 'localhost';

  return props.isHidden ? null : providerOmit ? (
    <Box sx={{ ..._styles.text1, my: 0, minHeight: '2.5rem' /* to mimic the other items */ }}>
      {!isOnLocalhost && <Typography level='body-xs'>
        Please make sure the addresses can be reached from &quot;{typeof window !== 'undefined' ? window.location.hostname : 'this server'}&quot;. If you are using a local service, you may need to use a public URL.
      </Typography>}
    </Box>
  ) : (
    <Box sx={{ display: 'flex', flexDirection: 'column', gap: 1 }}>

      <Box sx={{ display: 'flex', alignItems: 'center', gap: 2 }}>

        {/* Left Icon */}
        <TooltipOutlined title={serviceLLMsCount ? `${serviceLLMsCount} ${vendorName} models available` : `${vendorName} API Key`} placement='top'>
          <Badge
            size='md' color='primary' variant='solid' badgeInset='12%'
            badgeContent={serviceLLMsCount} showZero={false}
            slotProps={{ badge: { sx: { boxShadow: 'xs', border: 'none' } } }}
          >
            <Avatar sx={{ height: '100%', aspectRatio: 1, backgroundColor: 'transparent' }}>
              {isLoading ? <CircularProgress color='primary' variant='solid' size='sm' /> : <LLMVendorIcon vendorId={providerVendor.id} />}
            </Avatar>
          </Badge>
        </TooltipOutlined>

        {/* Main key inputs */}
        <Box sx={{ flex: 1, display: 'grid' }}>

          {/* Line 1 */}
          {/*{!!props.serviceLabel && (*/}
          {/*  <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>*/}
          {/*    /!*<props.vendorIcon />*!/*/}
          {/*    <Box>{props.serviceLabel}</Box>*/}
          {/*  </Box>*/}
          {/*)}*/}

          {/* Line 2 */}
          <Input
            fullWidth
            name={`wizard-settings-value-${providerVendor.id}`}
            autoComplete='off'
            variant='outlined'
            value={localValue ?? ''}
            onChange={handleTextChanged}
            placeholder={`${vendorName} ${valueName}`}
            type={isLocal ? undefined : 'password'}
            // error={!isValidKey}
            // startDecorator={<props.vendorIcon />}
            endDecorator={endButtons}
          />

        </Box>

      </Box>

      {/*{isLoading && <Typography level='body-xs' sx={{ ml: 7, px: 0.5 }}>Loading your models...</Typography>}*/}
      {/*{!isLoading && !updateError && !!llmsCount && (*/}
      {/*  <Typography level='body-xs' sx={{ ml: 7, px: 0.5 }}>{llmsCount} models added.</Typography>*/}
      {/*)}*/}
      {!isLoading && !updateError && !serviceLLMsCount && !!serviceKeyValue && (
        <Typography level='body-xs' color='warning' sx={{ ml: 7, px: 0.5 }}>No models found.</Typography>
      )}
      {!!updateError && <Typography level='body-xs' color='danger' sx={{ ml: 7, px: 0.5 }}>{updateError}</Typography>}

    </Box>
  );
}


export function ModelsWizard(props: {
  isMobile: boolean,
  onSkip?: () => void,
  onSwitchToAdvanced?: () => void,
}) {

  // state
  const [activeCategory, setActiveCategory] = React.useState<VendorCategory>('popular');

  // derived
  const isLocal = activeCategory === 'local';

  return (
    <Sheet variant='soft' sx={_styles.container}>

      <Box sx={props.isMobile ? _styles.text1Mobile : _styles.text1}>
        <Typography component='div' level='title-sm'>
          Enter {isLocal ? 'the addresses of ' : 'your API keys for '}
          <Chip variant={!isLocal ? 'solid' : 'outlined'} sx={{ mx: 0.25 }} onClick={() => setActiveCategory('popular')}>
            Popular
          </Chip>
          <Chip variant={isLocal ? 'solid' : 'outlined'} sx={{ mx: 0.25 }} onClick={() => setActiveCategory('local')}>
            Local
          </Chip>
          {' '}AI services below.
        </Typography>
        {/*<Box sx={{ fontSize: 'sm', color: 'text.primary' }}>*/}
        {/*  Enter API keys to connect your AI services.{' '}*/}
        {/*  {!props.isMobile && <>Switch to <Box component='a' onClick={props.onSwitchToAdvanced} sx={{ textDecoration: 'underline', cursor: 'pointer' }}>Advanced</Box> for more options.</>}*/}
        {/*</Box>*/}
      </Box>

      {WizardProviders.map((provider, index) => (
        <WizardProviderSetup
          key={provider.vendor.id}
          provider={provider}
          isFirst={!index}
          isHidden={provider.cat !== activeCategory}
        />
      ))}

      <Box sx={props.isMobile ? _styles.text2Mobile : _styles.text2}>
        {/*{!props.isMobile && <>Switch to <Box component='a' onClick={props.onSwitchToAdvanced} sx={{ textDecoration: 'underline', cursor: 'pointer' }}>Advanced</Box> to choose between {getModelVendorsCount()} services.</>}{' '}*/}
        {!props.isMobile && <>
          Switch to{' '}
          <Box component='a' onClick={props.onSwitchToAdvanced} sx={{ textDecoration: 'underline', cursor: 'pointer' }}>advanced configuration</Box>
          {/*<Chip variant={isLocal ? 'solid' : 'outlined'} sx={{ ml: 0.25 }} onClick={props.onSwitchToAdvanced}>*/}
          {/*  more services*/}
          {/*</Chip>*/}
          {' '}for more services,
        </>}{' '}
        or <Box component='a' onClick={props.onSkip} sx={{ textDecoration: 'underline', cursor: 'pointer' }}>skip</Box> for now and do it later.
      </Box>

    </Sheet>
  );
}


================================================
FILE: src/modules/llms/server/llm.server.types.ts
================================================
import * as z from 'zod/v4';

import { LLMS_ALL_INTERFACES } from '~/common/stores/llms/llms.types';


export type ModelDescriptionSchema = z.infer<typeof ModelDescription_schema>;

// export namespace AixWire_API_ListModels {

/*
 * Note: this needs to be moved to the AixWire_API_ListModels namespace
 * HOWEVER if we did it now there will be some circular dependency issue
 */


/// Benchmark

const BenchmarksScores_schema = z.object({
  cbaElo: z.number().optional(),
  cbaMmlu: z.number().optional(),
  // heCode: z.number().optional(), // HumanEval, code, 0-shot
  // vqaMmmu: z.number().optional(), // Visual Question Answering, MMMU, 0-shot
});


/// Pricing

const PricePerMToken_schema = z.number().or(z.literal('free'));

const PriceUpTo_schema = z.object({
  upTo: z.number().nullable(),
  price: PricePerMToken_schema,
});

const TieredPricing_schema = z.union([
  PricePerMToken_schema,
  z.array(PriceUpTo_schema),
]);

// NOTE: (!) keep this in sync with DPricingChatGenerate (llms.pricing.ts)
const PricingChatGenerate_schema = z.object({
  input: TieredPricing_schema.optional(),
  output: TieredPricing_schema.optional(),
  // Future: Perplexity has a cost per request, consider this for future additions
  // perRequest: z.number().optional(), // New field for fixed per-request pricing
  cache: z.discriminatedUnion('cType', [
    z.object({
      cType: z.literal('ant-bp'), // [Anthropic] Breakpoint-based caching
      read: TieredPricing_schema,
      write: TieredPricing_schema,
      duration: z.number(),
    }),
    z.object({
      cType: z.literal('oai-ac'), // [OpenAI] Automatic Caching
      read: TieredPricing_schema,
      // write: TieredPricing_schema, // Not needed, as it's the same as input cost, i.e. = 0
    }),
  ]).optional(),
  // Not for the server-side, computed on the client only
  // _isFree: z.boolean().optional(),
});


/// Model Description (out)
const ModelParameterSpec_schema = z.object({
  /**
   * User-changeable parameters for this LLM.
   *
   * Uncommon idiosyncratic parameters for this model
   * - we have only the 'extra' params here, as `llmRef`, `llmResponseTokens` and `llmTemperature` are common
   * - see `llms.parameters.ts` for the full list
   *
   * NOTE: (!) keep this in sync with `DModelParameterId` (llms.parameters.ts) which is also used in AixAPI_Model when making the request
   */
  paramId: z.enum([
    'llmTopP',
    'llmForceNoStream',
    'llmVndAntThinkingBudget',
    'llmVndGeminiShowThoughts',
    'llmVndGeminiThinkingBudget',
    'llmVndOaiReasoningEffort',
    'llmVndOaiRestoreMarkdown',
    'llmVndOaiWebSearchContext',
    'llmVndOaiWebSearchGeolocation',
    'llmVndPerplexityDateFilter',
    'llmVndPerplexitySearchMode',
    'llmVndXaiSearchMode',
    'llmVndXaiSearchSources',
    'llmVndXaiSearchDateFilter',
  ]),
  required: z.boolean().optional(),
  hidden: z.boolean().optional(),
  initialValue: z.number().or(z.string()).or(z.boolean()).nullable().optional(),
  // special params
  rangeOverride: z.tuple([z.number(), z.number()]).optional(), // [min, max]
});

export const ModelDescription_schema = z.object({
  id: z.string(),
  idVariant: z.string().optional(),
  label: z.string(),
  created: z.number().optional(),
  updated: z.number().optional(),
  description: z.string(),
  contextWindow: z.number().nullable(),
  interfaces: z.array(z.enum(LLMS_ALL_INTERFACES)),
  parameterSpecs: z.array(ModelParameterSpec_schema).optional(),
  maxCompletionTokens: z.number().optional(),
  // rateLimits: rateLimitsSchema.optional(),
  trainingDataCutoff: z.string().optional(),
  benchmark: BenchmarksScores_schema.optional(),
  chatPrice: PricingChatGenerate_schema.optional(),
  hidden: z.boolean().optional(),
  // TODO: add inputTypes/Kinds..
});


/// ListModels Response

export const ListModelsResponse_schema = z.object({
  models: z.array(ModelDescription_schema),
});



================================================
FILE: src/modules/llms/server/anthropic/anthropic.models.ts
================================================
import { LLM_IF_ANT_PromptCaching, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../llm.server.types';


export const hardcodedAnthropicVariants: { [modelId: string]: Partial<ModelDescriptionSchema> } = {

  // Claude 4 models with thinking variants
  'claude-opus-4-20250514': {
    idVariant: 'thinking',
    label: 'Claude Opus 4 (Thinking)',
    description: 'Claude Opus 4 with extended thinking mode enabled for complex reasoning',
    parameterSpecs: [{ paramId: 'llmVndAntThinkingBudget', required: true, hidden: false }],
    maxCompletionTokens: 32000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching, LLM_IF_OAI_Reasoning],
    benchmark: { cbaElo: 1303 + 10 + 10 /* N/A - just rank it on top + thinking */ },
  },

  'claude-sonnet-4-20250514': {
    idVariant: 'thinking',
    label: 'Claude Sonnet 4 (Thinking)',
    description: 'Claude Sonnet 4 with extended thinking mode enabled for complex reasoning',
    parameterSpecs: [{ paramId: 'llmVndAntThinkingBudget', required: true, hidden: false }],
    maxCompletionTokens: 64000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching, LLM_IF_OAI_Reasoning],
    benchmark: { cbaElo: 1303 + 10 /* N/A - just rank it on top + thinking */ },
  },

  // Changes to the thinking variant (same model ID) for the Claude 3.7 Sonnet model
  'claude-3-7-sonnet-20250219': {
    idVariant: 'thinking',
    label: 'Claude 3.7 Sonnet (Thinking)',
    description: 'Claude 3.7 with extended thinking mode enabled for complex reasoning',
    parameterSpecs: [{ paramId: 'llmVndAntThinkingBudget', required: true, hidden: false }],
    maxCompletionTokens: 65536, // Extended thinking mode - note that the 'anthropic-beta: output-128k-2025-02-19' header would point to a 128k instead
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching, LLM_IF_OAI_Reasoning],
    benchmark: { cbaElo: 1303 },
  },

} as const;


export const hardcodedAnthropicModels: (ModelDescriptionSchema & { isLegacy?: boolean })[] = [

  // Claude 4 models
  {
    id: 'claude-opus-4-20250514', // Active
    label: 'Claude Opus 4', // 🌟
    description: 'Capable and intelligent model. Sets new standards in complex reasoning and advanced coding',
    contextWindow: 200000,
    maxCompletionTokens: 32000,
    trainingDataCutoff: 'Mar 2025',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 15, output: 75, cache: { cType: 'ant-bp', read: 1.50, write: 18.75, duration: 300 } },
    benchmark: { cbaElo: 1295 + 10 + 10 /* N/A - just rank it on top */ },
  },
  {
    id: 'claude-sonnet-4-20250514', // Active
    label: 'Claude Sonnet 4', // 🌟
    description: 'High-performance model with exceptional reasoning and efficiency',
    contextWindow: 200000,
    maxCompletionTokens: 64000,
    trainingDataCutoff: 'Mar 2025',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 3, output: 15, cache: { cType: 'ant-bp', read: 0.30, write: 3.75, duration: 300 } },
    benchmark: { cbaElo: 1295 + 10 /* N/A - just rank it on top */ },
  },

  // Claude 3.7 models
  {
    id: 'claude-3-7-sonnet-20250219', // Active | Guaranteed Until: February 2026
    label: 'Claude 3.7 Sonnet',
    description: 'High-performance model with early extended thinking',
    contextWindow: 200000,
    maxCompletionTokens: 8192,
    trainingDataCutoff: 'Oct 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 3, output: 15, cache: { cType: 'ant-bp', read: 0.30, write: 3.75, duration: 300 } },
    benchmark: { cbaElo: 1295 },
  },

  // Claude 3.5 models
  {
    id: 'claude-3-5-sonnet-20241022', // Active | Guaranteed Until: October 2025
    label: 'Claude 3.5 Sonnet',
    description: 'High level of intelligence and capability',
    contextWindow: 200000,
    maxCompletionTokens: 8192,
    trainingDataCutoff: 'Apr 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 3, output: 15, cache: { cType: 'ant-bp', read: 0.30, write: 3.75, duration: 300 } },
    benchmark: { cbaElo: 1283, cbaMmlu: 88.7 },
  },
  {
    id: 'claude-3-5-sonnet-20240620', // Active | Guaranteed Until: June 2025
    label: 'Claude 3.5 Sonnet (previous)',
    description: 'Previous version of Claude 3.5 Sonnet',
    contextWindow: 200000,
    maxCompletionTokens: 8192,
    trainingDataCutoff: 'Apr 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 3, output: 15, cache: { cType: 'ant-bp', read: 0.30, write: 3.75, duration: 300 } },
    benchmark: { cbaElo: 1268, cbaMmlu: 88.6 },
    hidden: true, // superseded by the v2
  },
  {
    id: 'claude-3-5-haiku-20241022', // Active | Guaranteed Until: October 2025
    label: 'Claude 3.5 Haiku',
    description: 'Intelligence at speed',
    contextWindow: 200000,
    maxCompletionTokens: 8192,
    trainingDataCutoff: 'Jul 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 0.80, output: 4.00, cache: { cType: 'ant-bp', read: 0.08, write: 1.00, duration: 300 } },
    benchmark: { cbaElo: 1237, cbaMmlu: 75.2 },
  },

  // Claude 3 models
  {
    id: 'claude-3-opus-20240229', // Active | Guaranteed Until: March 2025
    label: 'Claude 3 Opus',
    description: 'Powerful model for complex tasks',
    contextWindow: 200000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Aug 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 15, output: 75, cache: { cType: 'ant-bp', read: 1.50, write: 18.75, duration: 300 } },
    benchmark: { cbaElo: 1247, cbaMmlu: 86.8 },
  },
  {
    id: 'claude-3-haiku-20240307', // Active | Guaranteed Until: March 2025
    hidden: true, // close to the guaranteed date
    label: 'Claude 3 Haiku',
    description: 'Quick and accurate targeted performance',
    contextWindow: 200000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Aug 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    chatPrice: { input: 0.25, output: 1.25, cache: { cType: 'ant-bp', read: 0.03, write: 0.30, duration: 300 } },
    benchmark: { cbaElo: 1179, cbaMmlu: 75.1 },
  },

  // Legacy/Deprecated models
  {
    id: 'claude-3-sonnet-20240229', // Deprecated | Deprecated: January 21, 2025 | Retired: N/A
    label: 'Claude 3 Sonnet',
    description: 'Balance of intelligence and speed. Deprecated on 2025-01-21.',
    contextWindow: 200000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Aug 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision],
    chatPrice: { input: 3, output: 15 },
    benchmark: { cbaElo: 1201, cbaMmlu: 79 },
    hidden: true,
    isLegacy: true,
  },
  {
    id: 'claude-2.1', // Deprecated | Deprecated: January 21, 2025 | Retired: N/A
    label: 'Claude 2.1',
    description: 'Updated version of Claude 2 with improved accuracy. Deprecated on 2025-01-21.',
    contextWindow: 200000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Early 2023',
    interfaces: [LLM_IF_OAI_Chat],
    chatPrice: { input: 8, output: 24 },
    benchmark: { cbaElo: 1118 },
    hidden: true,
    isLegacy: true,
  },
  {
    id: 'claude-2.0', // Deprecated | Deprecated: January 21, 2025 | Retired: N/A
    label: 'Claude 2',
    description: 'Predecessor to Claude 3, offering strong all-round performance. Deprecated on 2025-01-21.',
    contextWindow: 100000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Early 2023',
    interfaces: [LLM_IF_OAI_Chat],
    chatPrice: { input: 8, output: 24 },
    benchmark: { cbaElo: 1132, cbaMmlu: 78.5 },
    hidden: true,
    isLegacy: true,
  },
];



================================================
FILE: src/modules/llms/server/anthropic/anthropic.router.ts
================================================
import * as z from 'zod/v4';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { env } from '~/server/env';
import { fetchJsonOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { LLM_IF_ANT_PromptCaching, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';

import { ListModelsResponse_schema, ModelDescriptionSchema } from '../llm.server.types';

import { hardcodedAnthropicModels, hardcodedAnthropicVariants } from './anthropic.models';
import { fixupHost } from '~/modules/llms/server/openai/openai.router';


// configuration and defaults
const DEFAULT_ANTHROPIC_HOST = 'api.anthropic.com';
const DEFAULT_HELICONE_ANTHROPIC_HOST = 'anthropic.hconeai.com';

const DEFAULT_ANTHROPIC_HEADERS = {
  // Latest version hasn't changed (as of Feb 2025)
  'anthropic-version': '2023-06-01',

  // Enable CORS for browsers - we don't use this
  // 'anthropic-dangerous-direct-browser-access': 'true',

  // Used for instance by Claude Code - shall we set it
  // 'x-app': 'big-agi',
} as const;

const DEFAULT_ANTHROPIC_BETA_FEATURES: string[] = [

  // NOTE: undocumented: I wonder what this is for
  // 'claude-code-20250219',

  // NOTE: disabled for now, as we don't have tested side-effects for this feature yet
  // 'token-efficient-tools-2025-02-19', // https://docs.anthropic.com/en/docs/build-with-claude/tool-use/token-efficient-tool-use

  /**
   * to use the prompt caching feature; adds to any API invocation:
   *  - message_start.message.usage.cache_creation_input_tokens: number
   *  - message_start.message.usage.cache_read_input_tokens: number
   */
  'prompt-caching-2024-07-31',

  // now default
  // 'messages-2023-12-15'
] as const;

const PER_MODEL_BETA_FEATURES: { [modelId: string]: string[] } = {
  'claude-3-7-sonnet-20250219': [

    /** enables long output for the 3.7 Sonnet model */
    'output-128k-2025-02-19',

    /** computer Tools for Sonnet 3.7 [computer_20250124, text_editor_20250124, bash_20250124] */
    'computer-use-2025-01-24',

  ] as const,
  'claude-3-5-sonnet-20241022': [

    /** computer Tools for Sonnet 3.5 v2 [computer_20241022, text_editor_20241022, bash_20241022] */
    'computer-use-2024-10-22',

  ] as const,
  'claude-3-5-sonnet-20240620': [

    /** to use the 8192 tokens limit for the FIRST 3.5 Sonnet model */
    'max-tokens-3-5-sonnet-2024-07-15',

  ] as const,
} as const;

function _anthropicHeaders(modelId?: string): HeadersInit {

  // accumulate the beta features
  const betaFeatures = [...DEFAULT_ANTHROPIC_BETA_FEATURES];
  if (modelId) {
    // string search (.includes) within the keys, to be more resilient to modelId changes/prefixing
    for (const [key, value] of Object.entries(PER_MODEL_BETA_FEATURES))
      if (key.includes(modelId))
        betaFeatures.push(...value);
  }

  return {
    ...DEFAULT_ANTHROPIC_HEADERS,
    'anthropic-beta': betaFeatures.join(','),
  };
}


// Mappers

async function anthropicGETOrThrow<TOut extends object>(access: AnthropicAccessSchema, antModelIdForBetaFeatures: undefined | string, apiPath: string /*, signal?: AbortSignal*/): Promise<TOut> {
  const { headers, url } = anthropicAccess(access, antModelIdForBetaFeatures, apiPath);
  return await fetchJsonOrTRPCThrow<TOut>({ url, headers, name: 'Anthropic' });
}

// async function anthropicPOST<TOut extends object, TPostBody extends object>(access: AnthropicAccessSchema, body: TPostBody, apiPath: string /*, signal?: AbortSignal*/): Promise<TOut> {
//   const { headers, url } = anthropicAccess(access, apiPath);
//   return await fetchJsonOrTRPCThrow<TOut, TPostBody>({ url, method: 'POST', headers, body, name: 'Anthropic' });
// }

export function anthropicAccess(access: AnthropicAccessSchema, antModelIdForBetaFeatures: undefined | string, apiPath: string): { headers: HeadersInit, url: string } {
  // API key
  const anthropicKey = access.anthropicKey || env.ANTHROPIC_API_KEY || '';

  // break for the missing key only on the default host
  if (!anthropicKey && !(access.anthropicHost || env.ANTHROPIC_API_HOST))
    throw new Error('Missing Anthropic API Key. Add it on the UI (Models Setup) or server side (your deployment).');

  // API host
  let anthropicHost = fixupHost(access.anthropicHost || env.ANTHROPIC_API_HOST || DEFAULT_ANTHROPIC_HOST, apiPath);

  // Helicone for Anthropic
  // https://docs.helicone.ai/getting-started/integration-method/anthropic
  const heliKey = access.heliconeKey || env.HELICONE_API_KEY || false;
  if (heliKey) {
    if (!anthropicHost.includes(DEFAULT_ANTHROPIC_HOST) && !anthropicHost.includes(DEFAULT_HELICONE_ANTHROPIC_HOST))
      throw new Error(`The Helicone Anthropic Key has been provided, but the host is set to custom. Please fix it in the Models Setup page.`);
    anthropicHost = `https://${DEFAULT_HELICONE_ANTHROPIC_HOST}`;
  }

  // 2024-10-22: we don't support this yet, but the Anthropic SDK has `dangerouslyAllowBrowser: true`
  // to use the API from Browsers via CORS

  return {
    headers: {
      'Accept': 'application/json',
      'Content-Type': 'application/json',
      ..._anthropicHeaders(antModelIdForBetaFeatures),
      'X-API-Key': anthropicKey,
      ...(heliKey && { 'Helicone-Auth': `Bearer ${heliKey}` }),
    },
    url: anthropicHost + apiPath,
  };
}

function roundTime(date: string) {
  return Math.round(new Date(date).getTime() / 1000);
}


// Input Schemas

export const anthropicAccessSchema = z.object({
  dialect: z.literal('anthropic'),
  anthropicKey: z.string().trim(),
  anthropicHost: z.string().trim().nullable(),
  heliconeKey: z.string().trim().nullable(),
});
export type AnthropicAccessSchema = z.infer<typeof anthropicAccessSchema>;

const listModelsInputSchema = z.object({
  access: anthropicAccessSchema,
});


// Router

export const llmAnthropicRouter = createTRPCRouter({

  /* [Anthropic] list models - https://docs.anthropic.com/claude/docs/models-overview */
  listModels: publicProcedure
    .input(listModelsInputSchema)
    .output(ListModelsResponse_schema)
    .query(async ({ input: { access } }) => {

      // get the models
      const wireModels = await anthropicGETOrThrow(access, undefined, '/v1/models?limit=1000');
      const { data: availableModels } = AnthropicWire_API_Models_List.Response_schema.parse(wireModels);

      // cast the models to the common schema
      const models = availableModels.reduce((acc, model) => {

        // find the model description
        const hardcodedModel = hardcodedAnthropicModels.find(m => m.id === model.id);
        if (hardcodedModel) {

          // update creation date
          if (!hardcodedModel.created && model.created_at)
            hardcodedModel.created = roundTime(model.created_at);

          // add the base model
          acc.push(hardcodedModel);

          // add a thinking variant, if defined
          if (hardcodedAnthropicVariants[model.id])
            acc.push({
              ...hardcodedModel,
              ...hardcodedAnthropicVariants[model.id],
            });

        } else {

          // for day-0 support of new models, create a placeholder model using sensible defaults
          const novelModel = _createPlaceholderModel(model);
          console.log('[DEV] anthropic.router: new model found, please configure it:', novelModel.id);
          acc.push(novelModel);

        }
        return acc;
      }, [] as ModelDescriptionSchema[]);

      // developers warning for obsoleted models (we have them, but they are not in the API response anymore)
      const apiModelIds = new Set(availableModels.map(m => m.id));
      const additionalModels = hardcodedAnthropicModels.filter(m => !apiModelIds.has(m.id));
      if (additionalModels.length > 0)
        console.log('[DEV] anthropic.router: obsoleted models:', additionalModels.map(m => m.id).join(', '));
      // additionalModels.forEach(m => {
      //   m.label += ' (Removed)';
      //   m.isLegacy = true;
      // });
      // models.push(...additionalModels);

      return { models };
    }),

});


/**
 * Create a placeholder ModelDescriptionSchema for models not in the hardcoded list,
 * using sensible defaults with the newest available interfaces.
 */
function _createPlaceholderModel(model: AnthropicWire_API_Models_List.ModelObject): ModelDescriptionSchema {
  return {
    id: model.id,
    label: model.display_name,
    created: Math.round(new Date(model.created_at).getTime() / 1000),
    description: 'Newest model, description not available yet.',
    contextWindow: 200000,
    maxCompletionTokens: 8192,
    trainingDataCutoff: 'Latest',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_ANT_PromptCaching],
    // chatPrice: ...
    // benchmark: ...
  };
}

/**
 * Namespace for the Anthropic API Models List response schema.
 * NOTE: not merged into AIX because of possible circular dependency issues - future work.
 */
namespace AnthropicWire_API_Models_List {

  export type ModelObject = z.infer<typeof ModelObject_schema>;
  const ModelObject_schema = z.object({
    type: z.literal('model'),
    id: z.string(),
    display_name: z.string(),
    created_at: z.string(),
  });

  export type Response = z.infer<typeof Response_schema>;
  export const Response_schema = z.object({
    data: z.array(ModelObject_schema),
    has_more: z.boolean(),
    first_id: z.string().nullable(),
    last_id: z.string().nullable(),
  });

}



================================================
FILE: src/modules/llms/server/gemini/gemini.models.ts
================================================
import type { GeminiWire_API_Models_List } from '~/modules/aix/server/dispatch/wiretypes/gemini.wiretypes';

import type { ModelDescriptionSchema } from '../llm.server.types';

import { LLM_IF_GEM_CodeExecution, LLM_IF_HOTFIX_NoStream, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_StripSys0, LLM_IF_HOTFIX_Sys0ToUsr0, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Vision, LLM_IF_Outputs_Audio, LLM_IF_Outputs_Image, LLM_IF_Outputs_NoText } from '~/common/stores/llms/llms.types';


// dev options
const DEV_DEBUG_GEMINI_MODELS = true;


// supported interfaces
const geminiChatInterfaces: GeminiWire_API_Models_List.Model['supportedGenerationMethods'] = ['generateContent'];

// unsupported interfaces
const filterUnallowedNames = ['Legacy'];
// const filterUnallowedInterfaces: GeminiWire_API_Models_List.Model['supportedGenerationMethods'] = [
//   'generateAnswer',     // e.g. removes "models/aqa"
//   'embedContent',       // e.g. removes "models/embedding-001"
//   'embedText',          // e.g. removes "models/text-embedding-004"
//   'predict',            // e.g. removes "models/imagen-3.0-generate-002" (appeared on 2025-02-09)
//   'predictLongRunning', // e.g. removes "models/veo-2.0-generate-001" (appeared on 2025-04-10)
// ];
const filterLyingModelNames: GeminiWire_API_Models_List.Model['name'][] = [
  // 2025-02-27: verified, old model is no more
  'models/gemini-2.0-flash-exp', // verified, replaced by gemini-2.0-flash, which is non-free anymore

  // 2025-02-09 update: as of now they cleared the list, so we restart
  // 2024-12-10: name of models that are not what they say they are (e.g. 1114 is actually 1121 as of )
  'models/gemini-1.5-flash-8b-exp-0924', // replaced by non-free
  'models/gemini-1.5-flash-8b-exp-0827', // replaced by non-free
];


/* Manual models details
   Gemini Name Mapping example:
   - Latest version    gemini-1.0-pro-latest    <model>-<generation>-<variation>-latest
   - Latest stable     version  gemini-1.0-pro  <model>-<generation>-<variation>
   - Stable versions   gemini-1.0-pro-001       <model>-<generation>-<variation>-<version>

   Gemini capabilities chart (updated 2025-06-05):
   - [table stakes] System instructions
   - JSON Mode, with optional JSON Schema
   - Adjustable Safety Settings
   - Caching
   - Tuning
   - Function calling, with configuration
   - Code execution
   - Thinking / Reasoning with thinking budget
   - Audio generation
   - Live API
   - Native Audio (dialog models)
   - Text-to-Speech models
*/

// Experimental Gemini models are Free of charge
const geminiExpFree: ModelDescriptionSchema['chatPrice'] = {
  input: 'free', output: 'free',
};


// Pricing based on https://ai.google.dev/pricing (June 26, 2025)

const gemini25ProPricing: ModelDescriptionSchema['chatPrice'] = {
  input: [{ upTo: 200000, price: 1.25 }, { upTo: null, price: 2.50 }],
  output: [{ upTo: 200000, price: 10.00 }, { upTo: null, price: 15.00 }],
  cache: { cType: 'oai-ac', read: [{ upTo: 200000, price: 0.31 }, { upTo: null, price: 0.625 }] },
};

const gemini25FlashPricing: ModelDescriptionSchema['chatPrice'] = {
  input: 0.30, // text/image/video; audio is $1.00 but we don't differentiate yet
  output: 2.50, // including thinking tokens
  cache: { cType: 'oai-ac', read: 0.075 }, // text/image/video; audio is $0.25 but we don't differentiate yet
};

const gemini25FlashLitePreviewPricing: ModelDescriptionSchema['chatPrice'] = {
  input: 0.10, // text/image/video; audio is $0.50 but we don't differentiate yet
  output: 0.40, // including thinking tokens
  cache: { cType: 'oai-ac', read: 0.025 }, // text/image/video; audio is $0.125 but we don't differentiate yet
};

const gemini25FlashNativeAudioPricing: ModelDescriptionSchema['chatPrice'] = {
  input: 0.50, // text; audio/video is $3.00 but we don't differentiate yet
  output: 2.00, // text; audio is $12.00 but we don't differentiate yet
  // NOTE: we don't account for audio yet
};

const gemini25FlashPreviewTTSPricing: ModelDescriptionSchema['chatPrice'] = {
  input: 0.50, // text input
  // output: 10.00, // AUDIO - not ready for audio output yet, as of 2025-05-27
};

const gemini25ProPreviewTTSPricing: ModelDescriptionSchema['chatPrice'] = {
  input: 1.00, // text input
  // output: 20.00, // AUDIO - not ready for audio output yet, as of 2025-05-27
};

const gemini20FlashPricing: ModelDescriptionSchema['chatPrice'] = {
  input: 0.10, // text/image/video; audio is $0.70 but we don't differentiate yet
  output: 0.40,
  // Implicit caching is only available in 2.5 models for now. cache: { cType: 'oai-ac', read: 0.025 }, // text/image/video; audio is $0.175 but we don't differentiate yet
  // Image generation pricing: 0.039 - Image output is priced at $30 per 1,000,000 tokens. Output images up to 1024x1024px consume 1290 tokens and are equivalent to $0.039 per image.
};

const gemini20FlashLivePricing: ModelDescriptionSchema['chatPrice'] = {
  input: 0.35, // text; audio/video is $2.10 but we don't differentiate yet
  output: 1.50, // text; audio is $8.50 but we don't differentiate yet
};

const gemini20FlashLitePricing: ModelDescriptionSchema['chatPrice'] = {
  input: 0.075,
  output: 0.30,
};

const gemini15FlashPricing: ModelDescriptionSchema['chatPrice'] = {
  input: [{ upTo: 128000, price: 0.075 }, { upTo: null, price: 0.15 }],
  output: [{ upTo: 128000, price: 0.30 }, { upTo: null, price: 0.60 }],
  // Implicit caching is only available in 2.5 models for now. cache: { cType: 'oai-ac', read: [{ upTo: 128000, price: 0.01875 }, { upTo: null, price: 0.0375 }] },
};

const gemini15Flash8BPricing: ModelDescriptionSchema['chatPrice'] = {
  input: [{ upTo: 128000, price: 0.0375 }, { upTo: null, price: 0.075 }],
  output: [{ upTo: 128000, price: 0.15 }, { upTo: null, price: 0.30 }],
  // Implicit caching is only available in 2.5 models for now. cache: { cType: 'oai-ac', read: [{ upTo: 128000, price: 0.01 }, { upTo: null, price: 0.02 }] },
};

const gemini15ProPricing: ModelDescriptionSchema['chatPrice'] = {
  input: [{ upTo: 128000, price: 1.25 }, { upTo: null, price: 2.50 }],
  output: [{ upTo: 128000, price: 5.00 }, { upTo: null, price: 10.00 }],
  // Implicit caching is only available in 2.5 models for now. cache: { cType: 'oai-ac', read: [{ upTo: 128000, price: 0.3125 }, { upTo: null, price: 0.625 }] },
};


const _knownGeminiModels: ({
  id: string,
  labelOverride?: string,
  isPreview?: boolean,
  symLink?: string,
  deprecated?: string, // Gemini may provide deprecation dates
  _delete?: boolean, // some gemini models are not acknowledged by Google Docs anymore, and leaving them in the list will confuse users
} & Pick<ModelDescriptionSchema, 'interfaces' | 'parameterSpecs' | 'chatPrice' | 'hidden' | 'benchmark'>)[] = [

  /// Generation 2.5

  // 2.5 Pro (Stable) - Released June 17, 2025
  {
    id: 'models/gemini-2.5-pro',
    labelOverride: 'Gemini 2.5 Pro',
    chatPrice: gemini25ProPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndGeminiThinkingBudget', rangeOverride: [128, 32768] /* does not support 0 which would turn thinking off */ }],
    benchmark: { cbaElo: 1470 }, // Same as preview-06-05 since it's the stable version
  },
  {
    id: 'models/gemini-2.5-pro-preview-06-05',
    labelOverride: 'Gemini 2.5 Pro Preview 06-05', // overriding because the API does not have the version on this
    isPreview: true,
    chatPrice: gemini25ProPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndGeminiThinkingBudget', rangeOverride: [128, 32768] /* does not support 0 which would turn thinking off */ }],
    benchmark: { cbaElo: 1467 },
  },
  {
    id: 'models/gemini-2.5-pro-preview-05-06',
    isPreview: true,
    chatPrice: gemini25ProPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution, LLM_IF_OAI_PromptCaching],
    benchmark: { cbaElo: 1446 },
    hidden: true, // superseded by 06-05 version
  },
  {
    id: 'models/gemini-2.5-pro-preview-03-25',
    isPreview: true,
    chatPrice: gemini25ProPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution, LLM_IF_OAI_PromptCaching],
    // parameterSpecs: [{ paramId: 'llmVndGeminiShowThoughts' }], // Gemini doesn't show thoughts anymore
    benchmark: { cbaElo: 1439 },
    hidden: true, // hard-superseded, but keeping this as non-symlink in case Gemini restores it
  },

  // 2.5 Pro Preview TTS
  {
    hidden: true, // single-turn-only model - unhide and just send a message to make use of this
    id: 'models/gemini-2.5-pro-preview-tts',
    isPreview: true,
    chatPrice: gemini25ProPreviewTTSPricing,
    interfaces: [
      LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json,
      LLM_IF_Outputs_Audio, LLM_IF_Outputs_NoText,
      LLM_IF_HOTFIX_StripSys0, // TTS: no system instruction
      LLM_IF_HOTFIX_NoStream, // TTS: no streaming - use generateContent instead
    ],
    benchmark: undefined, // TTS models are not benchmarkable
    // hidden: true, // audio outputs are unavailable as of 2025-05-27
  },

  // 2.5 Flash (Stable) - Released June 17, 2025
  {
    id: 'models/gemini-2.5-flash',
    labelOverride: 'Gemini 2.5 Flash',
    chatPrice: gemini25FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndGeminiThinkingBudget' }],
    benchmark: { cbaElo: 1424 }, // Same as preview-05-20 since it's the stable version
  },
  {
    id: 'models/gemini-2.5-flash-preview-05-20',
    isPreview: true,
    chatPrice: gemini25FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution],
    parameterSpecs: [{ paramId: 'llmVndGeminiThinkingBudget' }],
    benchmark: { cbaElo: 1424 },
  },
  {
    id: 'models/gemini-2.5-flash-preview-04-17',
    isPreview: true,
    chatPrice: gemini25FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution],
    parameterSpecs: [{ paramId: 'llmVndGeminiThinkingBudget' }],
    benchmark: { cbaElo: 1392 },
    hidden: true, // Hidden now that 05-20 is available
  },
  {
    id: 'models/gemini-2.5-flash-preview-04-17-thinking',
    labelOverride: 'Gemini 2.5 Flash Preview (Cursor, 04-17)',
    isPreview: true,
    chatPrice: gemini25FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution],
    parameterSpecs: [{ paramId: 'llmVndGeminiThinkingBudget' }],
    hidden: true,
  },

  // 2.5 Flash Preview TTS
  {
    id: 'models/gemini-2.5-flash-preview-tts',
    isPreview: true,
    chatPrice: gemini25FlashPreviewTTSPricing,
    interfaces: [
      LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json,
      LLM_IF_Outputs_Audio, LLM_IF_Outputs_NoText,
      LLM_IF_HOTFIX_StripSys0, // TTS: no system instruction
      LLM_IF_HOTFIX_NoStream, // TTS: no streaming - use generateContent instead
    ],
    benchmark: undefined, // TTS models are not benchmarkable
    hidden: true, // audio outputs are unavailable as of 2025-05-27
  },

  // 2.5 Flash Native Audio (Dialog and Thinking variants)
  {
    id: 'models/gemini-2.5-flash-preview-native-audio-dialog',
    isPreview: true,
    chatPrice: gemini25FlashNativeAudioPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_Outputs_Audio],
    benchmark: undefined, // Native audio models are not benchmarkable
    _delete: true, // dialog models unsupported as of 2025-05-27, but keeping the model for now
  },
  {
    id: 'models/gemini-2.5-flash-exp-native-audio-thinking-dialog',
    isPreview: true,
    chatPrice: gemini25FlashNativeAudioPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_Outputs_Audio],
    benchmark: undefined, // Native audio models are not benchmarkable
    _delete: true, // dialog models unsupported as of 2025-05-27, but keeping the model for now
  },

  // 2.5 Flash-Lite Preview
  {
    id: 'models/gemini-2.5-flash-lite-preview-06-17',
    labelOverride: 'Gemini 2.5 Flash-Lite Preview',
    isPreview: true,
    chatPrice: gemini25FlashLitePreviewPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndGeminiThinkingBudget' }],
    benchmark: { cbaElo: 1310 }, // Estimated based on 2.0 Flash-Lite performance
  },


  /// Generation 2.0

  // 2.0 Pro Experimental (Superseded by 2.5 Pro Preview/Exp)
  {
    hidden: true, // superseded by 'models/gemini-2.5-pro-preview-03-25', but not fully removed yet
    id: 'models/gemini-2.0-pro-exp-02-05', // Base model: Gemini 2.0 Pro
    isPreview: true,
    chatPrice: geminiExpFree,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1380 },
  },
  {
    hidden: true, // only keeping the latest
    id: 'models/gemini-2.0-pro-exp',
    symLink: 'models/gemini-2.0-pro-exp-02-05',
    // copied from symlink
    isPreview: true,
    chatPrice: geminiExpFree,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1380 },
  },
  {
    _delete: true, // replaced by gemini-2.0-pro-exp-02-05, 2025-02-27: verified, old model is no more
    id: 'models/gemini-exp-1206',
    labelOverride: 'Gemini 2.0 Pro Experimental 1206',
    isPreview: true,
    chatPrice: geminiExpFree,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1374 },
  },

  // 2.0 Flash Live
  {
    id: 'models/gemini-2.0-flash-live-001',
    labelOverride: 'Gemini 2.0 Flash Live',
    chatPrice: gemini20FlashLivePricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_Outputs_Audio, LLM_IF_GEM_CodeExecution],
    isPreview: true,
    // benchmark: not available because of the Live API (non benchmarkable)
  },

  // 2.0 Flash Thinking Experimental (superseded by 2.5 Flash Preview, but we still show it because it's free)
  {
    id: 'models/gemini-2.0-flash-thinking-exp-01-21',
    labelOverride: 'Gemini 2.0 Flash Thinking Experimental 01-21',
    chatPrice: geminiExpFree,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution],
    // parameterSpecs: [{ paramId: 'llmVndGeminiShowThoughts' }], // Gemini doesn't show thoughts anymore
    benchmark: { cbaElo: 1380 },
    isPreview: true,
    hidden: true, // superseded by Gemini 2.5 Flash Preview
  },
  {
    hidden: true, // show the symlinked instead
    id: 'models/gemini-2.0-flash-thinking-exp',
    labelOverride: 'Gemini 2.0 Flash Thinking Experimental',
    symLink: 'models/gemini-2.0-flash-thinking-exp-01-21',
    // copied from symlink
    chatPrice: geminiExpFree,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution],
    // parameterSpecs: [{ paramId: 'llmVndGeminiShowThoughts' }], // Gemini doesn't show thoughts anymore
    benchmark: { cbaElo: 1380 },
    isPreview: true,
  },
  {
    hidden: true, // replaced by gemini-2.0-flash-thinking-exp-01-21 - 2025-02-27: seems still different on the API, hence no deletion yet
    id: 'models/gemini-2.0-flash-thinking-exp-1219',
    labelOverride: 'Gemini 2.0 Flash Thinking Experimental 12-19',
    chatPrice: geminiExpFree,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Reasoning, LLM_IF_GEM_CodeExecution],
    // parameterSpecs: [{ paramId: 'llmVndGeminiShowThoughts' }], // Gemini doesn't show thoughts anymore
    benchmark: { cbaElo: 1363 },
    isPreview: true,
  },

  // 2.0 Flash Preview Image Generation (Newer than the Experimental, introduced on 05-07)
  {
    id: 'models/gemini-2.0-flash-preview-image-generation',
    // labelOverride: 'Gemini 2.0 Flash Image Generation Preview',
    isPreview: true,
    chatPrice: gemini20FlashPricing, // FIXME: this is missing the per-image generation pricing! (We don't have it in the code yet)
    interfaces: [
      LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_GEM_CodeExecution,
      LLM_IF_Outputs_Image,
      LLM_IF_HOTFIX_StripSys0, // This first Gemini Image Generation model does not support the developer instruction
    ],
    // non benchmarkable because generates images
  },

  // 2.0 Flash Experimental Image Generation
  {
    id: 'models/gemini-2.0-flash-exp-image-generation',
    // labelOverride: 'Gemini 2.0 Flash Image Generation Experimental',
    chatPrice: geminiExpFree,
    interfaces: [
      LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_GEM_CodeExecution,
      LLM_IF_Outputs_Image,
      LLM_IF_HOTFIX_StripSys0, // This first Gemini Image Generation model does not support the developer instruction
    ],
    parameterSpecs: [],
    // non benchmarkable because generates images
    isPreview: true,
  },

  // 2.0 Flash
  {
    id: 'models/gemini-2.0-flash-001',
    chatPrice: gemini20FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1355 },
  },
  {
    id: 'models/gemini-2.0-flash',
    symLink: 'models/gemini-2.0-flash-001',
    // copied from symlink
    chatPrice: gemini20FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1354 },
  },

  // 2.0 Flash Lite
  {
    id: 'models/gemini-2.0-flash-lite',
    chatPrice: gemini20FlashLitePricing,
    symLink: 'models/gemini-2.0-flash-lite-001',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn],
    benchmark: { cbaElo: 1310 },
  },
  {
    id: 'models/gemini-2.0-flash-lite-001',
    chatPrice: gemini20FlashLitePricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn],
    benchmark: { cbaElo: 1310 },
  },
  {
    hidden: true, // discouraged, as the official is out
    id: 'models/gemini-2.0-flash-lite-preview-02-05',
    isPreview: true,
    chatPrice: gemini20FlashLitePricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn],
    benchmark: { cbaElo: 1312 },
  },
  {
    id: 'models/gemini-2.0-flash-lite-preview',
    symLink: 'models/gemini-2.0-flash-lite-preview-02-05',
    // coped from symlink
    isPreview: true,
    chatPrice: gemini20FlashLitePricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn],
    benchmark: { cbaElo: 1311 },
  },


  /// Generation 1.5

  // Gemini 1.5 Flash Models
  {
    id: 'models/gemini-1.5-flash-latest', // updated regularly and might be a preview version
    isPreview: true,
    chatPrice: gemini15FlashPricing,
    // symLink: '-002 or newer',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    hidden: true, // old model, SNR
  },
  {
    id: 'models/gemini-1.5-flash',
    // Defaults to version 002 on Oct 8, 2024
    symLink: 'models/gemini-1.5-flash-002',
    chatPrice: gemini15FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1271 },
    hidden: true, // old model, SNR
  },
  {
    id: 'models/gemini-1.5-flash-002', // new stable version
    chatPrice: gemini15FlashPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1271 },
    hidden: true,
  },

  // Gemini 1.5 Flash-8B Models
  {
    id: 'models/gemini-1.5-flash-8b-latest',
    isPreview: false,
    chatPrice: gemini15Flash8BPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1212 },
    hidden: true, // old model, SNR
  },
  {
    id: 'models/gemini-1.5-flash-8b',
    symLink: 'models/gemini-1.5-flash-8b-001',
    chatPrice: gemini15Flash8BPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1212 },
    hidden: true, // old model, SNR
  },
  {
    id: 'models/gemini-1.5-flash-8b-001',
    chatPrice: gemini15Flash8BPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1212 },
    hidden: true,
  },

  // Gemini 1.5 Pro Models
  {
    id: 'models/gemini-1.5-pro-latest', // updated to latest stable version
    chatPrice: gemini15ProPricing,
    // symLink: '-002 or newer',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    hidden: true, // old model, SNR
  },
  {
    id: 'models/gemini-1.5-pro',
    symLink: 'models/gemini-1.5-pro-002',
    chatPrice: gemini15ProPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1302 },
    hidden: true, // old model, SNR
  },
  {
    id: 'models/gemini-1.5-pro-002',
    chatPrice: gemini15ProPricing,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_GEM_CodeExecution],
    benchmark: { cbaElo: 1302 },
    hidden: true,
  },


  /// Generation 1.0

  // Gemini 1.0 Pro Vision Model
  {
    id: 'models/gemini-1.0-pro-vision-latest',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision],
    hidden: true,
    _delete: true, // confusing and deprecated
  },
  {
    id: 'models/gemini-pro-vision',
    symLink: 'models/gemini-1.0-pro-vision',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision], // Text and Images
    _delete: true, // confusing and deprecated
  },


  /// Other Experimental Models

  // Gemma 3n Model (newer than 3, first seen on the May 2025 update)
  {
    id: 'models/gemma-3n-e4b-it',
    isPreview: true,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: geminiExpFree, // Free tier only according to pricing page
    benchmark: { cbaElo: 1311 }, // Estimating based on comparable models
  },
  {
    id: 'models/gemma-3n-e2b-it',
    isPreview: true,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: geminiExpFree, // Free tier only according to pricing page
    benchmark: { cbaElo: 1275 }, // Estimating based on comparable models
    hidden: true, // smaller model than the 3n-e4b-it
  },
  // Gemma 3 Experimental Models - note: we apply workarounds:
  // - LLM_IF_HOTFIX_StripImages, because: "Image input modality is not enabled for models/gemma-3-27b-it"
  // - LLM_IF_HOTFIX_Sys0ToUsr0, because: "Developer instruction is not enabled for models/gemma-3-27b-it"
  {
    id: 'models/gemma-3-27b-it',
    isPreview: true,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: geminiExpFree, // Pricing page indicates free tier only
    benchmark: { cbaElo: 1341 },
    // hidden: true, // Keep visible if it's a distinct offering
  },
  {
    hidden: true, // keep larger model
    id: 'models/gemma-3-12b-it',
    isPreview: true,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: geminiExpFree,
    benchmark: { cbaElo: 1321 },
  },
  {
    hidden: true, // keep larger model
    id: 'models/gemma-3-4b-it',
    isPreview: true,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: geminiExpFree,
    benchmark: { cbaElo: 1275 },
  },
  {
    hidden: true, // keep larger model
    id: 'models/gemma-3-1b-it',
    isPreview: true,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: geminiExpFree,
  },

  // LearnLM Experimental Model
  {
    id: 'models/learnlm-2.0-flash-experimental',
    isPreview: true,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision],
    chatPrice: geminiExpFree,
    // hidden: true,
    // _delete: true,
  },


  /// Media Generation Models - NOTE: THESE ARE FILTERED OUT (!) - but here anyway for reference

  // Imagen 3 - Image Generation
  {
    id: 'models/imagen-3.0-generate-002',
    isPreview: false,
    // chatPrice: { input: 0.03, output: 0.03 }, // per image pricing
    interfaces: [LLM_IF_Outputs_Image], // Not a chat model
    hidden: true, // Not accessible through the normal chat interface
  },

  // Veo 2 - Video Generation
  {
    id: 'models/veo-2.0-generate-001',
    isPreview: false,
    // chatPrice: { input: 0.35, output: 0.35 }, // per second pricing
    interfaces: [], // Not a chat model
    hidden: true, // Not accessible through the normal chat interface
  },

];


// Add to your code where you process the API response
export function geminiDevCheckForSuperfluousModels_DEV(apiModelIds: string[]): void {

  if (DEV_DEBUG_GEMINI_MODELS) {

    // editorial model ids
    const expectedModelIds = _knownGeminiModels.map(model => model.id);

    // find editorial models which aren't present in the API response anymore
    const missingModels = expectedModelIds.filter(id => !apiModelIds.includes(id));
    if (missingModels.length > 0)
      console.warn(`Gemini: superfluous model definitions: [ ${missingModels.join(', ')} ]`);

  }

}


/**
 * Checks if Gemini has updated the API.

 * Compares wireModels with parsedModels for missing or mismatched parsed data.
 * @param wireModels is the raw API response from Gemini, containing the .models[] array
 * @param parsedModels is the parsed models array, which should match the wireModels
 */
export function geminiDevCheckForParserMisses_DEV(wireModels: unknown, parsedModels: object[]): void {

  if (DEV_DEBUG_GEMINI_MODELS) {

    // ensure wireModels has .models array
    if (!wireModels || !Array.isArray((wireModels as any)?.models)) {
      console.warn('[DEV] Gemini: wireModels.models is not an array', wireModels);
      return;
    }

    // find differences between wireModels and parsedModels using JSON.stringify
    const wireModelsJson = JSON.stringify((wireModels as any).models);
    const parsedModelsJson = JSON.stringify(parsedModels);
    if (wireModelsJson !== parsedModelsJson)
      console.warn('[DEV] Gemini: wireModels and parsedModels do not match!', wireModelsJson, parsedModelsJson);

  }

}


export function geminiFilterModels(geminiModel: GeminiWire_API_Models_List.Model): boolean {
  const isAllowed = !filterUnallowedNames.some(name => geminiModel.displayName.includes(name));
  // const isSupported = !filterUnallowedInterfaces.some(iface => geminiModel.supportedGenerationMethods.includes(iface));
  const isChatSupported = geminiModel.supportedGenerationMethods.some(iface => geminiChatInterfaces.includes(iface));
  const isWhatItSaysItIs = !filterLyingModelNames.includes(geminiModel.name);
  return isAllowed && isChatSupported && isWhatItSaysItIs;
}


const _sortOderIdPrefix: string[] = [
  'models/gemini-exp',
  'models/gemini-2.5-pro',
  'models/gemini-2.5-pro-exp',
  'models/gemini-2.5-pro-preview',
  'models/gemini-2.5-pro-',
  'models/gemini-2.5-pro-preview-tts',
  'models/gemini-2.5-flash',
  'models/gemini-2.5-flash-preview',
  'models/gemini-2.5-flash-',
  'models/gemini-2.5-flash-preview-tts',
  'models/gemini-2.5-flash-lite-preview-',
  'models/gemini-2.5-flash-lite-',
  'models/gemini-2.0-pro',
  'models/gemini-2.0-pro-',
  'models/gemini-2.0-flash-exp-image-generation',
  'models/gemini-2.0-flash-preview-', // -image-generation
  'models/gemini-2.0-flash-thinking-exp-01-21',
  'models/gemini-2.0-flash-thinking',
  'models/gemini-2.0-flash-live',
  'models/gemini-2.0-flash-lite',
  'models/gemini-2.0-flash-0',
  'models/gemini-1.5-pro',
  'models/gemini-1.5-flash',
  'models/gemini-1.5-flash-8b',
  'models/gemini-1.0-pro',
  'models/gemini-pro',
  'models/gemma-3n-',
  'models/gemma-3-27b',
  'models/gemma-3-12b',
  'models/gemma-3-4b',
  'models/gemma',
  'models/learnlm',
  'models/imagen',
  'models/veo',
] as const;

export function geminiSortModels(a: ModelDescriptionSchema, b: ModelDescriptionSchema): number {
  // links to the bottom
  const aIsLink = a.label.startsWith('🔗');
  const bIsLink = b.label.startsWith('🔗');
  if (aIsLink && !bIsLink) return 1;
  if (!aIsLink && bIsLink) return -1;

  // hidden to the bottom, then names descending
  // if (a.hidden && !b.hidden) return 1;
  // if (!a.hidden && b.hidden) return -1;

  // models beginning with 'gemini-' to the top
  // const aGemini = a.label.startsWith('Gemini');
  // const bGemini = b.label.startsWith('Gemini');
  // if (aGemini && !bGemini) return -1;
  // if (!aGemini && bGemini) return 1;

  // exact match first ...
  const aExactIdx = _sortOderIdPrefix.findIndex(p => a.id === p); // exact match first
  const bExactIdx = _sortOderIdPrefix.findIndex(p => b.id === p); // exact match first
  const aLastIdx = _sortOderIdPrefix.findLastIndex(p => a.id.startsWith(p)); // exact or family match
  const bLastIdx = _sortOderIdPrefix.findLastIndex(p => b.id.startsWith(p));
  const aSortIdx = aExactIdx >= 0 ? aExactIdx : aLastIdx; // use exact match first, then family match
  const bSortIdx = bExactIdx >= 0 ? bExactIdx : bLastIdx; // use exact match first, then family match

  if (aSortIdx !== -1 && bSortIdx !== -1) {
    if (aSortIdx < bSortIdx) return -1;
    if (aSortIdx > bSortIdx) return 1;
  }

  // sort by label descending
  return b.label.localeCompare(a.label);
}


export function geminiModelToModelDescription(geminiModel: GeminiWire_API_Models_List.Model): ModelDescriptionSchema | null {
  const { description, displayName, name: modelId, supportedGenerationMethods } = geminiModel;

  // if (DEV_DEBUG_GEMINI_MODELS)
  //   console.log('geminiModelToModelDescription', geminiModel);

  // handle unsupported interfaces
  const hasChatInterfaces = supportedGenerationMethods.some(iface => geminiChatInterfaces.includes(iface));
  if (!hasChatInterfaces) {
    if (DEV_DEBUG_GEMINI_MODELS)
      console.warn(`geminiModelToModelDescription: no chat interfaces (${supportedGenerationMethods.join(', ')}) for model ${modelId} (${displayName}) - skipping.`);
    return null; // skip models without chat interfaces
  }


  // find known manual mapping
  const knownModel = _knownGeminiModels.find(m => m.id === modelId);
  if (!knownModel && DEV_DEBUG_GEMINI_MODELS)
    console.warn('geminiModelToModelDescription: unknown model', modelId, geminiModel);

  // handle _delete
  if (knownModel?._delete)
    return null;

  // handle symlinks
  let label = knownModel?.symLink
    ? `🔗 ${knownModel?.labelOverride || displayName} → ${knownModel.symLink}`
    : knownModel?.labelOverride || displayName;

  // FIX: the Gemini 1114 model now returns 1121 as the version.. highlight the issue
  // if (geminiModel.name.endsWith('1114') && label.endsWith('1121'))
  //   label += ' (really: 1114)';

  // handle hidden models
  const hidden = knownModel?.hidden || !!knownModel?.symLink || !hasChatInterfaces;

  // context window
  const { inputTokenLimit, outputTokenLimit } = geminiModel;
  const contextWindow = inputTokenLimit + outputTokenLimit;

  // description
  const { version, topK, topP, temperature } = geminiModel;
  const descriptionLong = (description || 'No description.') + ` (Version: ${version}, Defaults: temperature=${temperature}, topP=${topP}, topK=${topK}, interfaces=[${supportedGenerationMethods.join(',')}])`;

  // use known interfaces, or add chat if this is a generateContent model
  const interfaces: ModelDescriptionSchema['interfaces'] = knownModel?.interfaces || [];
  if (!interfaces.length && hasChatInterfaces) {
    // newer models get good capabilities by default
    interfaces.push(LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision, LLM_IF_OAI_Json);
  }

  return {
    id: modelId,
    label: label, // + (knownModel?.isNewest ? ' 🌟' : ''),
    // created: ...
    // updated: ...
    description: descriptionLong,
    contextWindow: contextWindow,
    maxCompletionTokens: outputTokenLimit,
    // trainingDataCutoff: knownModel?.trainingDataCutoff, // disabled as we don't get this from Gemini
    interfaces,
    parameterSpecs: knownModel?.parameterSpecs,
    // rateLimits: isGeminiPro ? { reqPerMinute: 60 } : undefined,
    benchmark: knownModel?.benchmark,
    chatPrice: knownModel?.chatPrice,
    hidden,
    // deprecated: knownModel?.deprecated,
  };
}


const hardcodedGeminiVariants: { [modelId: string]: Partial<ModelDescriptionSchema>[] } = {

  // The Gemini 2.5 Pro Preview model does not have a non-thinking variant,
  // so we cannot add it here.

  // Adding non-thinking variant for the newest Gemini 2.5 Flash Preview 05-20 model
  // 'models/gemini-2.5-flash-preview-05-20': [{
  //   idVariant: '-non-thinking',
  //   label: 'Gemini 2.5 Flash Preview (Non-thinking, 05-20)',
  //   chatPrice: gemini25FlashPricing,
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, /*LLM_IF_OAI_Reasoning,*/ LLM_IF_GEM_CodeExecution],
  //   parameterSpecs: [{
  //     paramId: 'llmVndGeminiThinkingBudget',
  //     hidden: true,
  //     initialValue: 0, // non-thinking: we fix the thinking budget to 0
  //   }],
  //   hidden: true,
  // }],

  // Changes to the thinking variant (same model ID) for the Gemini 2.5 Flash Preview model
  // 'models/gemini-2.5-flash-preview-04-17': [{
  //   idVariant: '-non-thinking',
  //   label: 'Gemini 2.5 Flash Preview (Non-thinking, 04-17)',
  //   chatPrice: gemini25FlashPricing,
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, /*LLM_IF_OAI_Reasoning,*/ LLM_IF_GEM_CodeExecution],
  //   parameterSpecs: [{
  //     paramId: 'llmVndGeminiThinkingBudget',
  //     hidden: true,
  //     initialValue: 0, // non-thinking: we fix the thinking budget to 0
  //   }],
  //   hidden: true,
  // }],

} as const;

export function geminiModelsAddVariants(models: ModelDescriptionSchema[]): ModelDescriptionSchema[] {
  return models.reduce((acc, model) => {

    // insert the model in the same order
    acc.push(model);

    // add variants, if defined
    if (hardcodedGeminiVariants[model.id])
      for (const variant of hardcodedGeminiVariants[model.id])
        acc.push({
          ...model,
          ...variant,
        });

    return acc;
  }, [] as ModelDescriptionSchema[]);
}



================================================
FILE: src/modules/llms/server/gemini/gemini.router.ts
================================================
import * as z from 'zod/v4';
import { env } from '~/server/env';

import packageJson from '../../../../../package.json';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { fetchJsonOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { GeminiWire_API_Models_List, GeminiWire_Safety } from '~/modules/aix/server/dispatch/wiretypes/gemini.wiretypes';

import { ListModelsResponse_schema } from '../llm.server.types';
import { geminiDevCheckForParserMisses_DEV, geminiDevCheckForSuperfluousModels_DEV, geminiFilterModels, geminiModelsAddVariants, geminiModelToModelDescription, geminiSortModels } from './gemini.models';
import { fixupHost } from '~/modules/llms/server/openai/openai.router';


// Default hosts
const DEFAULT_GEMINI_HOST = 'https://generativelanguage.googleapis.com';


// Mappers

export function geminiAccess(access: GeminiAccessSchema, modelRefId: string | null, apiPath: string, useV1Alpha: boolean): { headers: HeadersInit, url: string } {

  const geminiHost = fixupHost(access.geminiHost || DEFAULT_GEMINI_HOST, apiPath);
  let geminiKey = access.geminiKey || env.GEMINI_API_KEY || '';

  // multi-key with random selection - https://github.com/enricoros/big-AGI/issues/653
  if (geminiKey.includes(',')) {
    const multiKeys = geminiKey
      .split(',')
      .map(key => key.trim())
      .filter(Boolean);
    geminiKey = multiKeys[Math.floor(Math.random() * multiKeys.length)];
  }

  // update model-dependent paths
  if (apiPath.includes('{model=models/*}')) {
    if (!modelRefId)
      throw new Error(`geminiAccess: modelRefId is required for ${apiPath}`);
    apiPath = apiPath.replace('{model=models/*}', modelRefId);
  }

  // [Gemini, 2025-01-23] CoT support - requires `v1alpha` Gemini API
  if (useV1Alpha)
    apiPath = apiPath.replaceAll('v1beta', 'v1alpha');

  return {
    headers: {
      'Content-Type': 'application/json',
      'x-goog-api-client': `big-agi/${packageJson['version'] || '1.0.0'}`,
      'x-goog-api-key': geminiKey,
    },
    url: geminiHost + apiPath,
  };
}


async function geminiGET<TOut extends object>(access: GeminiAccessSchema, modelRefId: string | null, apiPath: string /*, signal?: AbortSignal*/, useV1Alpha: boolean): Promise<TOut> {
  const { headers, url } = geminiAccess(access, modelRefId, apiPath, useV1Alpha);
  return await fetchJsonOrTRPCThrow<TOut>({ url, headers, name: 'Gemini' });
}

async function geminiPOST<TOut extends object, TPostBody extends object>(access: GeminiAccessSchema, modelRefId: string | null, body: TPostBody, apiPath: string /*, signal?: AbortSignal*/, useV1Alpha: boolean): Promise<TOut> {
  const { headers, url } = geminiAccess(access, modelRefId, apiPath, useV1Alpha);
  return await fetchJsonOrTRPCThrow<TOut, TPostBody>({ url, method: 'POST', headers, body, name: 'Gemini' });
}


// Input/Output Schemas

export const geminiAccessSchema = z.object({
  dialect: z.enum(['gemini']),
  geminiKey: z.string(),
  geminiHost: z.string(),
  minSafetyLevel: GeminiWire_Safety.HarmBlockThreshold_enum,
});
export type GeminiAccessSchema = z.infer<typeof geminiAccessSchema>;


const accessOnlySchema = z.object({
  access: geminiAccessSchema,
});


/**
 * See https://github.com/google/generative-ai-js/tree/main/packages/main/src for
 * the official Google implementation.
 */
export const llmGeminiRouter = createTRPCRouter({

  /* [Gemini] models.list = /v1beta/models */
  listModels: publicProcedure
    .input(accessOnlySchema)
    .output(ListModelsResponse_schema)
    .query(async ({ input }) => {

      // get the models
      const wireModels = await geminiGET(input.access, null, GeminiWire_API_Models_List.getPath, false);
      const detailedModels = GeminiWire_API_Models_List.Response_schema.parse(wireModels).models;
      geminiDevCheckForParserMisses_DEV(wireModels, detailedModels);
      geminiDevCheckForSuperfluousModels_DEV(detailedModels.map(model => model.name));

      // NOTE: no need to retrieve info for each of the models (e.g. /v1beta/model/gemini-pro).,
      //       as the List API already all the info on all the models

      // first filter from the original list
      const filteredModels = detailedModels.filter(geminiFilterModels);

      // map to our output schema
      const models = filteredModels
        .map(geminiModelToModelDescription)
        .filter(model => !!model)
        .sort(geminiSortModels);

      return {
        models: geminiModelsAddVariants(models),
      };
    }),

});



================================================
FILE: src/modules/llms/server/ollama/ollama.models.ts
================================================
/**
 * This is here because the API does not provide a list of available upstream models, and does not provide
 * descriptions for the models.
 * (nor does it reliably provide context window sizes - upstream bug: https://github.com/ollama/ollama/issues/1473)
 *
 <<<
 Can you modify the following data structure, according to the updated information from the attached
 web page(https://ollama.ai/library?sort=featured). Be very thorough, do not skip any lines, both in
 the provided file and in the web page. Add/remove to reflect the order in the web page, update
 the *description* and *pulls*, and preserve the existing *added* field on existing entries, or set
 it to 20250312 on brand new entries. Note: the default contextWindow in code is 8192, so we do not redefine that.
 >>>
 */
export const OLLAMA_BASE_MODELS: { [key: string]: { description: string, pulls: number, contextWindow?: number, hasTools?: true, hasVision?: true, isEmbeddings?: true, tags?: string[], added?: string } } = {
  'qwq': { description: 'QwQ is the reasoning model of the Qwen series.', pulls: 866000, tags: ['32b'], hasTools: true, added: '20250312' },
  'deepseek-r1': { description: 'DeepSeek\'s first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.', pulls: 25500000, tags: ['1.5b', '7b', '8b', '14b', '32b', '70b', '671b'], added: '20250128' },
  'llama3.3': { description: 'New state of the art 70B model. Llama 3.3 70B offers similar performance compared to the Llama 3.1 405B model.', pulls: 1500000, tags: ['70b'], hasTools: true, added: '20241210' },
  'phi4': { description: 'Phi-4 is a 14B parameter, state-of-the-art open model from Microsoft.', pulls: 1000000, tags: ['14b'], added: '20250128' },
  'llama3.2': { description: 'Meta\'s Llama 3.2 goes small with 1B and 3B models.', pulls: 10400000, tags: ['1b', '3b'], hasTools: true, added: '20241210' },
  'llama3.1': { description: 'Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.', pulls: 26700000, tags: ['8b', '70b', '405b'], hasTools: true, added: '20241210' },
  'nomic-embed-text': { description: 'A high-performing open embedding model with a large token context window.', pulls: 18700000, tags: [], isEmbeddings: true, added: '20240501' },
  'mistral': { description: 'The 7B model released by Mistral AI, updated to version 0.3.', pulls: 10200000, tags: ['7b'], hasTools: true },
  'llama3': { description: 'Meta Llama 3: The most capable openly available LLM to date', pulls: 7600000, tags: ['8b', '70b'], added: '20240501' },
  'qwen2.5': { description: 'Qwen2.5 models are pretrained on Alibaba\'s latest large-scale dataset, encompassing up to 18 trillion tokens. The model supports up to 128K tokens and has multilingual support.', pulls: 5200000, tags: ['0.5b', '1.5b', '3b', '7b', '14b', '32b', '72b'], hasTools: true, added: '20241210' },
  'qwen2.5-coder': { description: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.', pulls: 4500000, tags: ['0.5b', '1.5b', '3b', '7b', '14b', '32b'], hasTools: true, added: '20241210' },
  'qwen': { description: 'Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters', pulls: 4500000, tags: ['0.5b', '1.8b', '4b', '7b', '14b', '32b', '72b', '110b'] },
  'gemma': { description: 'Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind. Updated to version 1.1', pulls: 4400000, tags: ['2b', '7b'], added: '20240501' },
  'qwen2': { description: 'Qwen2 is a new series of large language models from Alibaba group', pulls: 4100000, tags: ['0.5b', '1.5b', '7b', '72b'], hasTools: true, added: '20240628' },
  'llava': { description: '🌋 LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.', pulls: 4000000, tags: ['7b', '13b', '34b'], hasVision: true },
  'gemma2': { description: 'Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B.', pulls: 3400000, tags: ['2b', '9b', '27b'], added: '20240628' },
  'llama2': { description: 'Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.', pulls: 3000000, tags: ['7b', '13b', '70b'] },
  'phi3': { description: 'Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.', pulls: 2900000, tags: ['3.8b', '14b'], added: '20240501' },
  'codellama': { description: 'A large language model that can use text prompts to generate and discuss code.', pulls: 1800000, tags: ['7b', '13b', '34b', '70b'] },
  'mxbai-embed-large': { description: 'State-of-the-art large embedding model from mixedbread.ai', pulls: 1700000, tags: ['335m'], isEmbeddings: true, added: '20240501' },
  'llama3.2-vision': { description: 'Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.', pulls: 1500000, tags: ['11b', '90b'], hasVision: true, added: '20241210' },
  'tinyllama': { description: 'The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.', pulls: 1300000, tags: ['1.1b'] },
  'mistral-nemo': { description: 'A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.', pulls: 1300000, tags: ['12b'], hasTools: true, added: '20241210' },
  'starcoder2': { description: 'StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters.', pulls: 897600, tags: ['3b', '7b', '15b'], added: '20240501' },
  'deepseek-v3': { description: 'A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.', pulls: 748300, tags: ['671b'], added: '20250128' },
  'llama2-uncensored': { description: 'Uncensored Llama 2 model by George Sung and Jarrad Hope.', pulls: 728100, tags: ['7b', '70b'] },
  'deepseek-coder-v2': { description: 'An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks.', pulls: 722000, tags: ['16b', '236b'], added: '20240628' },
  'snowflake-arctic-embed': { description: 'A suite of text embedding models by Snowflake, optimized for performance.', pulls: 697600, tags: ['22m', '33m', '110m', '137m', '335m'], isEmbeddings: true, added: '20240501' },
  'deepseek-coder': { description: 'DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.', pulls: 601200, tags: ['1.3b', '6.7b', '33b'] },
  'mixtral': { description: 'A set of Mixture of Experts (MoE) model with open weights by Mistral AI in 8x7b and 8x22b parameter sizes.', pulls: 582600, tags: ['8x7b', '8x22b'], hasTools: true, added: '20250312' },
  'bge-m3': { description: 'BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity.', pulls: 555500, tags: ['567m'], isEmbeddings: true, added: '20241210' },
  'minicpm-v': { description: 'A series of multimodal LLMs (MLLMs) designed for vision-language understanding.', pulls: 535600, tags: ['8b'], hasVision: true, added: '20241210' },
  'codegemma': { description: 'CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following.', pulls: 530400, tags: ['2b', '7b'], added: '20240501' },
  'dolphin-mixtral': { description: 'Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of experts models that excels at coding tasks. Created by Eric Hartford.', pulls: 522200, tags: ['8x7b', '8x22b'], added: '20250312' },
  'openthinker': { description: 'A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.', pulls: 509700, tags: ['7b', '32b'], added: '20250219' },
  'phi': { description: 'Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities.', pulls: 496900, tags: ['2.7b'] },
  'llava-llama3': { description: 'A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several benchmarks.', pulls: 448000, tags: ['8b'], hasVision: true, added: '20240628' },
  'dolphin3': { description: 'Dolphin 3.0 Llama 3.1 8B 🐬 is the next generation of the Dolphin series of instruct-tuned models designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.', pulls: 386700, tags: ['8b'], added: '20250128' },
  'smollm2': { description: 'SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters.', pulls: 370800, tags: ['135m', '360m', '1.7b'], hasTools: true, added: '20241210' },
  'wizardlm2': { description: 'State of the art large language model from Microsoft AI with improved performance on complex chat, multilingual, reasoning and agent use cases.', pulls: 356800, tags: ['7b', '8x22b'], added: '20240501' },
  'olmo2': { description: 'OLMo 2 is a new family of 7B and 13B models trained on up to 5T tokens. These models are on par with or better than equivalently sized fully open models, and competitive with open-weight models such as Llama 3.1 on English academic benchmarks.', pulls: 352600, tags: ['7b', '13b'], added: '20250312' },
  'dolphin-mistral': { description: 'The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.', pulls: 325900, tags: ['7b'] },
  'all-minilm': { description: 'Embedding models on very large sentence level datasets.', pulls: 311500, tags: ['22m', '33m'], isEmbeddings: true, added: '20240501' },
  'mistral-small': { description: 'Mistral Small 3 sets a new benchmark in the "small" Large Language Models category below 70B.', pulls: 297800, tags: ['22b', '24b'], hasTools: true, added: '20250219' },
  'dolphin-llama3': { description: 'Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills.', pulls: 293500, tags: ['8b', '70b'], added: '20240501' },
  'command-r': { description: 'Command R is a Large Language Model optimized for conversational interaction and long context tasks.', pulls: 283000, tags: ['35b'], hasTools: true, added: '20240501' },
  'orca-mini': { description: 'A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware.', pulls: 277300, tags: ['3b', '7b', '13b', '70b'] },
  'yi': { description: 'Yi 1.5 is a high-performing, bilingual language model.', pulls: 267300, tags: ['6b', '9b', '34b'] },
  'hermes3': { description: 'Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous Research', pulls: 264700, tags: ['3b', '8b', '70b', '405b'], hasTools: true, added: '20241210' },
  'phi3.5': { description: 'A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models.', pulls: 249900, tags: ['3.8b'], added: '20241210' },
  'zephyr': { description: 'Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models that are trained to act as helpful assistants.', pulls: 238300, tags: ['7b', '141b'] },
  'codestral': { description: 'Codestral is Mistral AI\'s first-ever code model designed for code generation tasks.', pulls: 227900, tags: ['22b'], added: '20240628' },
  'granite-code': { description: 'A family of open foundation models by IBM for Code Intelligence', pulls: 191500, tags: ['3b', '8b', '20b', '34b'], added: '20240628' },
  'smollm': { description: '🪐 A family of small models with 135M, 360M, and 1.7B parameters, trained on a new high-quality dataset.', pulls: 188100, tags: ['135m', '360m', '1.7b'], added: '20241210' },
  'starcoder': { description: 'StarCoder is a code generation model trained on 80+ programming languages.', pulls: 187700, tags: ['1b', '3b', '7b', '15b'] },
  'wizard-vicuna-uncensored': { description: 'Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford.', pulls: 185800, tags: ['7b', '13b', '30b'] },
  'vicuna': { description: 'General use chat model based on Llama and Llama 2 with 2K to 16K context sizes.', pulls: 176200, tags: ['7b', '13b', '33b'] },
  'mistral-openorca': { description: 'Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset.', pulls: 167100, tags: ['7b'] },
  'llama2-chinese': { description: 'Llama 2 based model fine tuned to improve Chinese dialogue ability.', pulls: 149900, tags: ['7b', '13b'] },
  'openchat': { description: 'A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106.', pulls: 145400, tags: ['7b'] },
  'codegeex4': { description: 'A versatile model for AI software development scenarios, including code completion.', pulls: 139200, tags: ['9b'], added: '20241210' },
  'aya': { description: 'Aya 23, released by Cohere, is a new family of state-of-the-art, multilingual models that support 23 languages.', pulls: 136400, tags: ['8b', '35b'], added: '20240628' },
  'codeqwen': { description: 'CodeQwen1.5 is a large language model pretrained on a large amount of code data.', pulls: 132300, tags: ['7b'], added: '20240501' },
  'deepseek-llm': { description: 'An advanced language model crafted with 2 trillion bilingual tokens.', pulls: 132100, tags: ['7b', '67b'] },
  'deepseek-v2': { description: 'A strong, economical, and efficient Mixture-of-Experts language model.', pulls: 128300, tags: ['16b', '236b'], added: '20240628' },
  'mistral-large': { description: 'Mistral Large 2 is Mistral\'s new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages.', pulls: 125100, tags: ['123b'], hasTools: true, added: '20241210' },
  'glm4': { description: 'A strong multi-lingual general language model with competitive performance to Llama 3.', pulls: 123500, tags: ['9b'], added: '20241210' },
  'stable-code': { description: 'Stable Code 3B is a coding model with instruct and code completion variants on par with models such as Code Llama 7B that are 2.5x larger.', pulls: 122400, tags: ['3b'] },
  'openhermes': { description: 'OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets.', pulls: 122000, tags: [] },
  'nous-hermes2': { description: 'The powerful family of models by Nous Research that excels at scientific discussion and coding tasks.', pulls: 121900, tags: ['10.7b', '34b'] },
  'qwen2-math': { description: 'Qwen2 Math is a series of specialized math language models built upon the Qwen2 LLMs, which significantly outperforms the mathematical capabilities of open-source models and even closed-source models (e.g., GPT4o).', pulls: 120600, tags: ['1.5b', '7b', '72b'], added: '20241210' },
  'tinydolphin': { description: 'An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama.', pulls: 120500, tags: ['1.1b'] },
  'command-r-plus': { description: 'Command R+ is a powerful, scalable large language model purpose-built to excel at real-world enterprise use cases.', pulls: 119700, contextWindow: 128000, tags: ['104b'], hasTools: true, added: '20240501' },
  'wizardcoder': { description: 'State-of-the-art code generation model', pulls: 117200, tags: ['33b'] },
  'moondream': { description: 'moondream2 is a small vision language model designed to run efficiently on edge devices.', pulls: 116900, tags: ['1.8b'], hasVision: true, added: '20240501' },
  'bakllava': { description: 'BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA architecture.', pulls: 109700, tags: ['7b'], hasVision: true },
  'stablelm2': { description: 'Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.', pulls: 108100, tags: ['1.6b', '12b'] },
  'neural-chat': { description: 'A fine-tuned model based on Mistral with good coverage of domain and language.', pulls: 104700, tags: ['7b'] },
  'reflection': { description: 'A high-performing model trained with a new technique called Reflection-tuning that teaches a LLM to detect mistakes in its reasoning and correct course.', pulls: 103400, tags: ['70b'], added: '20241210' },
  'wizard-math': { description: 'Model focused on math and logic problems', pulls: 101100, tags: ['7b', '13b', '70b'] },
  'llama3-gradient': { description: 'This model extends LLama-3 8B\'s context length from 8k to over 1m tokens.', pulls: 98100, tags: ['8b', '70b'], added: '20240501' },
  'llama3-chatqa': { description: 'A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG).', pulls: 97200, tags: ['8b', '70b'], added: '20240628' },
  'sqlcoder': { description: 'SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks', pulls: 93700, tags: ['7b', '15b'] },
  'samantha-mistral': { description: 'A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.', pulls: 90100, tags: ['7b'] },
  'bge-large': { description: 'Embedding model from BAAI mapping texts to vectors.', pulls: 89700, tags: ['335m'], isEmbeddings: true, added: '20241210' },
  'xwinlm': { description: 'Conversational model based on Llama 2 that performs competitively on various benchmarks.', pulls: 84400, tags: ['7b', '13b'] },
  'dolphincoder': { description: 'A 7B and 15B uncensored variant of the Dolphin model family that excels at coding, based on StarCoder2.', pulls: 84200, tags: ['7b', '15b'], added: '20240501' },
  'nous-hermes': { description: 'General use models based on Llama and Llama 2 from Nous Research.', pulls: 82300, tags: ['7b', '13b'] },
  'granite3.1-dense': { description: 'The IBM Granite 2B and 8B models are text-only dense LLMs trained on over 12 trillion tokens of data, demonstrated significant improvements over their predecessors in performance and speed in IBM\'s initial testing.', pulls: 81800, tags: ['2b', '8b'], hasTools: true, added: '20250128' },
  'llava-phi3': { description: 'A new small LLaVA model fine-tuned from Phi 3 Mini.', pulls: 81700, tags: ['3.8b'], hasVision: true, added: '20240628' },
  'phind-codellama': { description: 'Code generation model based on Code Llama.', pulls: 81500, tags: ['34b'] },
  'starling-lm': { description: 'Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness.', pulls: 81300, tags: ['7b'] },
  'solar': { description: 'A compact, yet powerful 10.7B large language model designed for single-turn conversation.', pulls: 79100, tags: ['10.7b'] },
  'yarn-llama2': { description: 'An extension of Llama 2 that supports a context of up to 128k tokens.', pulls: 78900, contextWindow: 128000, tags: ['7b', '13b'] },
  'yi-coder': { description: 'Yi-Coder is a series of open-source code language models that delivers state-of-the-art coding performance with fewer than 10 billion parameters.', pulls: 77000, tags: ['1.5b', '9b'], added: '20241210' },
  'athene-v2': { description: 'Athene-V2 is a 72B parameter model which excels at code completion, mathematics, and log extraction tasks.', pulls: 76900, tags: ['72b'], hasTools: true, added: '20241210' },
  'wizardlm': { description: 'General use model based on Llama 2.', pulls: 75800, tags: [] },
  'internlm2': { description: 'InternLM2.5 is a 7B parameter model tailored for practical scenarios with outstanding reasoning capability.', pulls: 74100, tags: ['1m', '1.8b', '7b', '20b'], added: '20241210' },
  'falcon': { description: 'A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots.', pulls: 70100, tags: ['7b', '40b', '180b'] },
  'nemotron-mini': { description: 'A commercial-friendly small language model by NVIDIA optimized for roleplay, RAG QA, and function calling.', pulls: 69900, tags: ['4b'], hasTools: true, added: '20241210' },
  'nemotron': { description: 'Llama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries.', pulls: 66900, tags: ['70b'], hasTools: true, added: '20241210' },
  'deepscaler': { description: 'A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI\'s o1-preview with just 1.5B parameters on popular math evaluations.', pulls: 66200, tags: ['1.5b'], added: '20250219' },
  'dolphin-phi': { description: '2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language model by Microsoft Research.', pulls: 65900, tags: ['2.7b'] },
  'orca2': { description: 'Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta\'s Llama 2 models. The model is designed to excel particularly in reasoning.', pulls: 63800, tags: ['7b', '13b'] },
  'wizardlm-uncensored': { description: 'Uncensored version of Wizard LM model', pulls: 60900, tags: ['13b'] },
  'stable-beluga': { description: 'Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy.', pulls: 59000, tags: ['7b', '13b', '70b'] },
  'granite3-dense': { description: 'The IBM Granite 2B and 8B models are designed to support tool-based use cases and support for retrieval augmented generation (RAG), streamlining code generation, translation and bug fixing.', pulls: 57900, tags: ['2b', '8b'], hasTools: true, added: '20241210' },
  'llama3-groq-tool-use': { description: 'A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling.', pulls: 56100, tags: ['8b', '70b'], hasTools: true, added: '20240628' },
  'paraphrase-multilingual': { description: 'Sentence-transformers model that can be used for tasks like clustering or semantic search.', pulls: 53000, tags: ['278m'], isEmbeddings: true, added: '20241210' },
  'deepseek-v2.5': { description: 'An upgraded version of DeekSeek-V2 that integrates the general and coding abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct.', pulls: 49900, tags: ['236b'], added: '20241210' },
  'smallthinker': { description: 'A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model.', pulls: 48000, tags: ['3b'], added: '20241210' },
  'medllama2': { description: 'Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset.', pulls: 47700, tags: ['7b'] },
  'meditron': { description: 'Open-source medical large language model adapted from Llama 2 to the medical domain.', pulls: 47600, tags: ['7b', '70b'] },
  'aya-expanse': { description: 'Cohere For AI\'s language models trained to perform well across 23 different languages.', pulls: 46600, tags: ['8b', '32b'], hasTools: true, added: '20241210' },
  'llama-pro': { description: 'An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics.', pulls: 45700, tags: [] },
  'yarn-mistral': { description: 'An extension of Mistral to support context windows of 64K or 128K.', pulls: 45200, tags: ['7b'] },
  'granite3-moe': { description: 'The IBM Granite 1B and 3B models are the first mixture of experts (MoE) Granite models from IBM designed for low latency usage.', pulls: 44300, tags: ['1b', '3b'], hasTools: true, added: '20241210' },
  'falcon3': { description: 'A family of efficient AI models under 10B parameters performant in science, math, and coding through innovative training techniques.', pulls: 42200, tags: ['1b', '3b', '7b', '10b'], added: '20241210' },
  'nexusraven': { description: 'Nexus Raven is a 13B instruction tuned model for function calling tasks.', pulls: 41700, tags: ['13b'] },
  'codeup': { description: 'Great code generation model based on Llama2.', pulls: 39700, tags: ['13b'] },
  'everythinglm': { description: 'Uncensored Llama2 based model with support for a 16K context window.', pulls: 38500, tags: ['13b'] },
  'nous-hermes2-mixtral': { description: 'The Nous Hermes 2 model from Nous Research, now trained over Mixtral.', pulls: 38400, tags: ['8x7b'], added: '20241210' },
  'snowflake-arctic-embed2': { description: 'Snowflake\'s frontier embedding model. Arctic Embed 2.0 adds multilingual support without sacrificing English performance or scalability.', pulls: 37100, tags: ['568m'], isEmbeddings: true, added: '20241210' },
  'shieldgemma': { description: 'ShieldGemma is set of instruction tuned models for evaluating the safety of text prompt input and text output responses against a set of defined safety policies.', pulls: 36100, tags: ['2b', '9b', '27b'], added: '20241210' },
  'granite3.1-moe': { description: 'The IBM Granite 1B and 3B models are long-context mixture of experts (MoE) Granite models from IBM designed for low latency usage.', pulls: 35500, tags: ['1b', '3b'], hasTools: true, added: '20250128' },
  'marco-o1': { description: 'An open large reasoning model for real-world solutions by the Alibaba International Digital Commerce Group (AIDC-AI).', pulls: 33300, tags: ['7b'], added: '20241210' },
  'mathstral': { description: 'MathΣtral: a 7B model designed for math reasoning and scientific discovery by Mistral AI.', pulls: 32700, tags: ['7b'], added: '20241210' },
  'reader-lm': { description: 'A series of models that convert HTML content to Markdown content, which is useful for content conversion tasks.', pulls: 32500, tags: ['0.5b', '1.5b'], added: '20241210' },
  'falcon2': { description: 'Falcon2 is an 11B parameters causal decoder-only model built by TII and trained over 5T tokens.', pulls: 32300, tags: ['11b'] },
  'magicoder': { description: '🎩 Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets.', pulls: 32200, tags: ['7b'] },
  'stablelm-zephyr': { description: 'A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware.', pulls: 32100, tags: ['3b'] },
  'solar-pro': { description: 'Solar Pro Preview: an advanced large language model (LLM) with 22 billion parameters designed to fit into a single GPU', pulls: 32100, tags: ['22b'], added: '20241210' },
  'phi4-mini': { description: 'Phi-4-mini brings significant enhancements in multilingual support, reasoning, and mathematics, and now, the long-awaited function calling feature is finally supported.', pulls: 31900, tags: ['3.8b'], hasTools: true, added: '20250312' },
  'codebooga': { description: 'A high-performing code instruct model created by merging two existing code models.', pulls: 31400, tags: ['34b'] },
  'llama-guard3': { description: 'Llama Guard 3 is a series of models fine-tuned for content safety classification of LLM inputs and responses.', pulls: 30600, tags: ['1b', '8b'], added: '20241210' },
  'duckdb-nsql': { description: '7B parameter text-to-SQL model made by MotherDuck and Numbers Station.', pulls: 30500, tags: ['7b'] },
  'mistrallite': { description: 'MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts.', pulls: 30100, tags: ['7b'] },
  'wizard-vicuna': { description: 'Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj.', pulls: 29600, tags: ['13b'] },
  'exaone3.5': { description: 'EXAONE 3.5 is a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research.', pulls: 29100, tags: ['2.4b', '7.8b', '32b'], added: '20241210' },
  'nuextract': { description: 'A 3.8B model fine-tuned on a private high-quality synthetic dataset for information extraction, based on Phi-3.', pulls: 26400, tags: ['3.8b'], added: '20241210' },
  'opencoder': { description: 'OpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B models, supporting chat in English and Chinese languages.', pulls: 26100, tags: ['1.5b', '8b'], added: '20241210' },
  'megadolphin': { description: 'MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself.', pulls: 25300, tags: ['120b'] },
  'command-r7b': { description: 'The smallest model in Cohere\'s R series delivers top-tier speed, efficiency, and quality to build powerful AI applications on commodity GPUs and edge devices.', pulls: 24500, tags: ['7b'], hasTools: true, added: '20250312' },
  'notux': { description: 'A top-performing mixture of experts model, fine-tuned with high-quality data.', pulls: 24400, tags: ['8x7b'] },
  'open-orca-platypus2': { description: 'Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation.', pulls: 23900, tags: ['13b'] },
  'notus': { description: 'A 7B chat model fine-tuned with high-quality data and based on Zephyr.', pulls: 23700, tags: ['7b'] },
  'goliath': { description: 'A language model created by combining two fine-tuned Llama 2 70B models into one.', pulls: 23000, tags: [] },
  'bespoke-minicheck': { description: 'A state-of-the-art fact-checking model developed by Bespoke Labs.', pulls: 22700, tags: ['7b'], added: '20241210' },
  'granite-embedding': { description: 'The IBM Granite Embedding 30M and 278M models models are text-only dense biencoder embedding models, with 30M available in English only and 278M serving multilingual use cases.', pulls: 21300, tags: ['30m', '278m'], isEmbeddings: true, added: '20241210' },
  'tulu3': { description: 'Tülu 3 is a leading instruction following model family, offering fully open-source data, code, and recipes by the The Allen Institute for AI.', pulls: 20200, tags: ['8b', '70b'], added: '20241210' },
  'granite3.2-vision': { description: 'A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.', pulls: 19100, tags: ['2b'], hasVision: true, hasTools: true, added: '20250312' },
  'firefunction-v2': { description: 'An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities.', pulls: 19000, tags: ['70b'], hasTools: true, added: '20241210' },
  'dbrx': { description: 'DBRX is an open, general-purpose LLM created by Databricks.', pulls: 18400, tags: ['132b'], added: '20241210' },
  'granite3.2': { description: 'Granite-3.2 is a family of long-context AI models from IBM Granite fine-tuned for thinking capabilities.', pulls: 16900, tags: ['2b', '8b'], hasTools: true, added: '20250312' },
  'granite3-guardian': { description: 'The IBM Granite Guardian 3.0 2B and 8B models are designed to detect risks in prompts and/or responses.', pulls: 16600, tags: ['2b', '8b'], added: '20241210' },
  'r1-1776': { description: 'A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity.', pulls: 16100, tags: ['70b', '671b'], added: '20250312' },
  'alfred': { description: 'A robust conversational model designed to be used for both chat and instruct use cases.', pulls: 15900, tags: ['40b'] },
  'sailor2': { description: 'Sailor2 are multilingual language models made for South-East Asia. Available in 1B, 8B, and 20B parameter sizes.', pulls: 9788, tags: ['1b', '8b', '20b'], added: '20241210' },
  'gemma3': { description: 'The current strongest model that fits on a single GPU.', pulls: 6711, tags: ['1b', '4b', '12b', '27b'], added: '20250312' },
  'command-r7b-arabic': { description: 'A new state-of-the-art version of the lightweight Command R7B model that excels in advanced Arabic language capabilities for enterprises in the Middle East and Northern Africa.', pulls: 3347, tags: ['7b'], hasTools: true, added: '20250312' },
  // NOTE: we had older/low-pull models here, but they are not in the list anymore, as it's noise. We removed around 45 of those.
};
// export const OLLAMA_LAST_UPDATE: string = '20250312';
export const OLLAMA_PREV_UPDATE: string = '20250219';


================================================
FILE: src/modules/llms/server/ollama/ollama.router.ts
================================================
import * as z from 'zod/v4';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { env } from '~/server/env';
import { fetchJsonOrTRPCThrow, fetchTextOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { capitalizeFirstLetter } from '~/common/util/textUtils';

import { ListModelsResponse_schema } from '../llm.server.types';

import { OLLAMA_BASE_MODELS, OLLAMA_PREV_UPDATE } from './ollama.models';
import { wireOllamaListModelsSchema, wireOllamaModelInfoSchema } from './ollama.wiretypes';
import { fixupHost } from '~/modules/llms/server/openai/openai.router';


// Default hosts
const DEFAULT_OLLAMA_HOST = 'http://127.0.0.1:11434';
// export const OLLAMA_PATH_CHAT = '/api/chat';
const OLLAMA_PATH_TAGS = '/api/tags';
const OLLAMA_PATH_SHOW = '/api/show';


// Mappers

export function ollamaAccess(access: OllamaAccessSchema, apiPath: string): { headers: HeadersInit, url: string } {

  const ollamaHost = fixupHost(access.ollamaHost || env.OLLAMA_API_HOST || DEFAULT_OLLAMA_HOST, apiPath);

  return {
    headers: {
      'Content-Type': 'application/json',
    },
    url: ollamaHost + apiPath,
  };

}


/*export const ollamaChatCompletionPayload = (model: OpenAIModelSchema, history: OpenAIHistorySchema, jsonOutput: boolean, stream: boolean): WireOllamaChatCompletionInput => ({
  model: model.id,
  messages: history,
  options: {
    ...(model.temperature !== undefined && { temperature: model.temperature }),
  },
  ...(jsonOutput && { format: 'json' }),
  // n: ...
  // functions: ...
  // function_call: ...
  stream,
});*/


/* Unused: switched to the Chat endpoint (above). The implementation is left here for reference.
https://github.com/jmorganca/ollama/blob/main/docs/api.md#generate-a-completion
export function ollamaCompletionPayload(model: OpenAIModelSchema, history: OpenAIHistorySchema, stream: boolean) {

  // if the first message is the system prompt, extract it
  let systemPrompt: string | undefined = undefined;
  if (history.length && history[0].role === 'system') {
    const [firstMessage, ...rest] = history;
    systemPrompt = firstMessage.content;
    history = rest;
  }

  // encode the prompt for ollama, assuming the same template for everyone for now
  const prompt = history.map(({ role, content }) => {
    return role === 'assistant' ? `\n\nAssistant: ${content}` : `\n\nHuman: ${content}`;
  }).join('') + '\n\nAssistant:\n';

  // const prompt = history.map(({ role, content }) => {
  //   return role === 'assistant' ? `### Response:\n${content}\n\n` : `### User:\n${content}\n\n`;
  // }).join('') + '### Response:\n';

  return {
    model: model.id,
    prompt,
    options: {
      ...(model.temperature !== undefined && { temperature: model.temperature }),
    },
    ...(systemPrompt && { system: systemPrompt }),
    stream,
  };
}*/

async function ollamaGET<TOut extends object>(access: OllamaAccessSchema, apiPath: string /*, signal?: AbortSignal*/): Promise<TOut> {
  const { headers, url } = ollamaAccess(access, apiPath);
  return await fetchJsonOrTRPCThrow<TOut>({ url, headers, name: 'Ollama' });
}

async function ollamaPOST<TOut extends object, TPostBody extends object>(access: OllamaAccessSchema, body: TPostBody, apiPath: string /*, signal?: AbortSignal*/): Promise<TOut> {
  const { headers, url } = ollamaAccess(access, apiPath);
  return await fetchJsonOrTRPCThrow<TOut, TPostBody>({ url, method: 'POST', headers, body, name: 'Ollama' });
}


// Input/Output Schemas

export const ollamaAccessSchema = z.object({
  dialect: z.enum(['ollama']),
  ollamaHost: z.string().trim(),
  ollamaJson: z.boolean(),
});
export type OllamaAccessSchema = z.infer<typeof ollamaAccessSchema>;

const accessOnlySchema = z.object({
  access: ollamaAccessSchema,
});

const adminPullModelSchema = z.object({
  access: ollamaAccessSchema,
  name: z.string(),
});

// this may not be needed
const listPullableOutputSchema = z.object({
  pullableModels: z.array(z.object({
    id: z.string(),
    label: z.string(),
    tag: z.string(),
    tags: z.array(z.string()),
    description: z.string(),
    pulls: z.number(),
    isNew: z.boolean(),
  })),
});


export const llmOllamaRouter = createTRPCRouter({

  /* Ollama: models that can be pulled */
  adminListPullable: publicProcedure
    .input(accessOnlySchema)
    .output(listPullableOutputSchema)
    .query(async ({}) => {
      return {
        pullableModels: Object.entries(OLLAMA_BASE_MODELS).map(([model_id, model]) => ({
          id: model_id,
          label: capitalizeFirstLetter(model_id),
          tag: 'latest',
          tags: model.tags?.length ? model.tags : [],
          description: model.description,
          pulls: model.pulls,
          isNew: !!model.added && model.added > OLLAMA_PREV_UPDATE,
        })),
      };
    }),

  /* Ollama: pull a model */
  adminPull: publicProcedure
    .input(adminPullModelSchema)
    .mutation(async ({ input }) => {

      // fetch as a large text buffer, made of JSONs separated by newlines
      const { headers, url } = ollamaAccess(input.access, '/api/pull');
      const pullRequest = await fetchTextOrTRPCThrow({ url, method: 'POST', headers, body: { 'name': input.name }, name: 'Ollama::pull' });

      // accumulate status and error messages
      let lastStatus: string = 'unknown';
      let lastError: string | undefined = undefined;
      for (let string of pullRequest.trim().split('\n')) {
        const message = JSON.parse(string);
        if (message.status)
          lastStatus = input.name + ': ' + message.status;
        if (message.error)
          lastError = message.error;
      }

      return { status: lastStatus, error: lastError };
    }),

  /* Ollama: delete a model */
  adminDelete: publicProcedure
    .input(adminPullModelSchema)
    .mutation(async ({ input }) => {
      const { headers, url } = ollamaAccess(input.access, '/api/delete');
      const deleteOutput = await fetchTextOrTRPCThrow({ url, method: 'DELETE', headers, body: { 'name': input.name }, name: 'Ollama::delete' });
      if (deleteOutput?.length && deleteOutput !== 'null')
        throw new Error('Ollama delete issue: ' + deleteOutput);
    }),


  /* Ollama: List the Models available */
  listModels: publicProcedure
    .input(accessOnlySchema)
    .output(ListModelsResponse_schema)
    .query(async ({ input }) => {

      // get the models
      const wireModels = await ollamaGET(input.access, OLLAMA_PATH_TAGS);
      let models = wireOllamaListModelsSchema.parse(wireModels).models;

      // retrieve info for each of the models (/api/show, post call, in parallel)
      const detailedModels = await Promise.all(models.map(async model => {
        const wireModelInfo = await ollamaPOST(input.access, { 'name': model.name }, OLLAMA_PATH_SHOW);
        const modelInfo = wireOllamaModelInfoSchema.parse(wireModelInfo);
        return { ...model, ...modelInfo };
      }));

      return {
        models: detailedModels.map(model => {
          // the model name is in the format "name:tag" (default tag = 'latest')
          const [modelName, modelTag] = model.name.split(':');

          // pretty label and description
          const label = capitalizeFirstLetter(modelName) + ((modelTag && modelTag !== 'latest') ? ` (${modelTag})` : '');
          const baseModel = OLLAMA_BASE_MODELS[modelName] ?? {};
          let description = baseModel.description || 'Model unknown';

          // prepend the parameters count and quantization level
          if (model.details?.quantization_level || model.details?.format || model.details?.parameter_size) {
            let firstLine = model.details.parameter_size ? `${model.details.parameter_size} parameters ` : '';
            if (model.details.quantization_level)
              firstLine += `(${model.details.quantization_level}` + ((model.details.format) ? `, ${model.details.format})` : ')');
            if (model.size)
              firstLine += `, ${Math.round(model.size / 1024 / 1024).toLocaleString()} MB`;
            if (baseModel.hasTools)
              firstLine += ' [tools]';
            if (baseModel.hasVision)
              firstLine += ' [vision]';
            description = firstLine + '\n\n' + description;
          }

          /* Find the context window from the 'num_ctx' line in the parameters string, if present
           *  - https://github.com/enricoros/big-AGI/issues/309
           *  - Note: as of 2024-01-26 the num_ctx line is present in 50% of the models, and in most cases set to 4096
           *  - We are tracking the Upstream issue https://github.com/ollama/ollama/issues/1473 for better ways to do this in the future
           */
          let contextWindow = baseModel.contextWindow || 8192;
          if (model.parameters) {
            // split the parameters into lines, and find one called "num_ctx ...spaces... number"
            const paramsNumCtx = model.parameters.split('\n').find(line => line.startsWith('num_ctx '));
            if (paramsNumCtx) {
              const numCtxValue: string = paramsNumCtx.split(/\s+/)[1];
              if (numCtxValue) {
                const numCtxNumber: number = parseInt(numCtxValue);
                if (!isNaN(numCtxNumber))
                  contextWindow = numCtxNumber;
              }
            }
          }

          // auto-detect interfaces from the hardcoded description (in turn parsed from the html page)
          const interfaces = !baseModel.isEmbeddings ? [LLM_IF_OAI_Chat] : [];
          if (baseModel.hasTools)
            interfaces.push(LLM_IF_OAI_Fn);
          if (baseModel.hasVision || modelName.includes('-vision')) // Heuristic
            interfaces.push(LLM_IF_OAI_Vision);

          // console.log('>>> ollama model', model.name, model.template, model.modelfile, '\n');

          return {
            id: model.name,
            label,
            created: Date.parse(model.modified_at) ?? undefined,
            updated: Date.parse(model.modified_at) ?? undefined,
            description: description, // description: (model.license ? `License: ${model.license}. Info: ` : '') + model.modelfile || 'Model unknown',
            contextWindow,
            ...(contextWindow ? { maxCompletionTokens: Math.round(contextWindow / 2) } : {}),
            interfaces,
          };
        }),
      };
    }),

});



================================================
FILE: src/modules/llms/server/ollama/ollama.wiretypes.ts
================================================
import * as z from 'zod/v4';


const wireOllamaModelDetailsSchema = z.object({
  parent_model: z.string().optional(),
  format: z.string().optional(),                      // e.g. gguf
  family: z.string().optional(),                      // e.g. llama, phi2, stablelm
  // families: z.array(z.string()).nullable().optional(),// e.g. null, [llama], [phi2]
  parameter_size: z.string().optional(),              // e.g. 7B, 3B, 34B, 6B, 30B
  quantization_level: z.string().optional(),          // e.g. Q4_0, Q8_0, F16, ...
});

/**
 * List Local Models (/api/tags) - Response
 */
export const wireOllamaListModelsSchema = z.object({
  models: z.array(z.object({
    name: z.string(),
    modified_at: z.string(),
    size: z.number(),
    // digest: z.string(),
    // details: wireOllamaModelDetailsSchema.optional(),
  })),
});

/**
 * Show per-Model Information (/api/show) - Response
 */
export const wireOllamaModelInfoSchema = z.object({
  license: z.string().optional(),
  modelfile: z.string(),
  parameters: z.string().optional(),
  template: z.string().optional(),
  details: wireOllamaModelDetailsSchema.nullable().optional(),
});


/**
 * Chat Completion API - Request
 * https://github.com/jmorganca/ollama/blob/main/docs/api.md#generate-a-chat-completion
 */
// const wireOllamaChatCompletionInputSchema = z.object({
//
//   // required
//   model: z.string(),
//   messages: z.array(z.object({
//     role: z.enum(['system', 'user', 'assistant']),
//     content: z.string(),
//     images: z.array(z.string()).optional(), // base64 encoded images
//   })),
//
//   // optional
//   format: z.enum(['json']).optional(),
//   options: z.object({
//     // https://github.com/ollama/ollama/blob/main/docs/modelfile.md
//     // Maximum number of tokens to predict when generating text.
//     num_predict: z.number().int().optional(),
//     // Sets the random number seed to use for generation
//     seed: z.number().int().optional(),
//     // The temperature of the model
//     temperature: z.number().positive().optional(),
//     // Reduces the probability of generating nonsense (Default: 40)
//     top_k: z.number().positive().optional(),
//     // Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text. (Default 0.9)
//     top_p: z.number().positive().optional(),
//   }).optional(),
//   stream: z.boolean().optional(), // default: true
//   keep_alive: z.string().optional(), // e.g. '5m'
//
//   // Note: not used anymore as of 2024-05-07?
//   // template: z.string().optional(), // overrides what is defined in the Modelfile
//
//   // Future Improvements?
//   // n: z.number().int().optional(), // number of completions to generate
//   // functions: ...
//   // function_call: ...
// });
//export type WireOllamaChatCompletionInput = z.infer<typeof wireOllamaChatCompletionInputSchema>;


/**
 * Chat Completion or Generation APIs - Streaming Response
 */
// export const wireOllamaChunkedOutputSchema = z.union([
//   // Chat Completion Chunk
//   z.object({
//     model: z.string(),
//     // created_at: z.string(), // commented because unused
//
//     // [Chat Completion] (exclusive with 'response')
//     message: z.object({
//       role: z.enum(['assistant' /*, 'system', 'user' Disabled on purpose, to validate the response */]),
//       content: z.string(),
//     }).optional(), // optional on the last message
//
//     // [Generation] (non-chat, exclusive with 'message')
//     //response: z.string().optional(),
//
//     done: z.boolean(),
//
//     // only on the last message
//     // context: z.array(z.number()), // non-chat endpoint
//     // total_duration: z.number(),
//     prompt_eval_count: z.number().optional(),
//     // prompt_eval_duration: z.number(),
//     eval_count: z.number().optional(),
//     eval_duration: z.number().optional(),
//
//   }),
//   // Possible Error
//   z.object({
//     error: z.string(),
//   }),
// ]);


================================================
FILE: src/modules/llms/server/openai/fireworksai.wiretypes.ts
================================================
import * as z from 'zod/v4';


// [Fireworks AI] Models List API - Response

export const wireFireworksAIListOutputSchema = z.array(z.object({

  id: z.string(),
  object: z.literal('model'),
  owned_by: z.union([
    z.literal('fireworks'),
    z.literal('yi-01-ai'),
    z.string(),
  ]),
  created: z.number(),
  kind: z.union([
    z.literal('HF_BASE_MODEL'),
    z.literal('HF_PEFT_ADDON'),
    z.literal('FLUMINA_BASE_MODEL'),
    z.string(),
  ]).optional(),
  // these seem to be there all the time, but just in case make them optional
  supports_chat: z.boolean().optional(),
  supports_image_input: z.boolean().optional(),
  supports_tools: z.boolean().optional(),
  // Not all models have this, so make it optional
  context_length: z.number().optional(),
}));



================================================
FILE: src/modules/llms/server/openai/groq.wiretypes.ts
================================================
import * as z from 'zod/v4';


// [Groq] Models List API - Response

export const wireGroqModelsListOutputSchema = z.object({
  id: z.string(),
  object: z.literal('model'),
  created: z.number(),
  owned_by: z.string(),
  // Groq-specific
  active: z.boolean(),
  context_window: z.number(),
  // public_apps: z.any(),
  max_completion_tokens: z.number(), // first found on 2025-04-16
});




================================================
FILE: src/modules/llms/server/openai/localai.wiretypes.ts
================================================
import * as z from 'zod/v4';


export const wireLocalAIModelsAvailableOutputSchema = z.array(z.object({
  name: z.string(),       // (e.g.) tinydream
  url: z.string(),        // (e.g.) github:go-skynet/model-gallery/tinydream.yaml
  license: z.string().optional(),    // (e.g.) other
  gallery: z.object({
    url: z.string(),      // (e.g.) github:go-skynet/model-gallery/index.yaml
    name: z.string(),     // (e.g.) model-gallery
  }),
  urls: z.array(z.string()).optional(),
  files: z.array(z.object({
    filename: z.string(),          // voice-en-us-amy-low.tar.gz
    uri: z.string(),               // https://github.com/rhasspy/piper/releases/download/v0.0.2/voice-en-us-amy-low.tar.gz
    sha256: z.string().optional(), // often empty
  })).optional(),
})).nullable(); // null if galleries are not served

export const wireLocalAIModelsApplyOutputSchema = z.object({
  uuid: z.string(),
  status: z.string(),
});

export const wireLocalAIModelsListOutputSchema = z.object({
  file_name: z.string(),
  error: z.string().nullable(),
  processed: z.boolean(),
  message: z.string().nullable(),
  progress: z.number(),
  file_size: z.string(),
  downloaded_size: z.string(),
});


================================================
FILE: src/modules/llms/server/openai/models.cba.ts
================================================
// here for reference only - for future mapping of CBA scores to the model IDs
// const modelIdToPrefixMap: { [key: string]: string } = {
//   // Anthropic models
//   'Claude 3.5 Sonnet': 'claude-3-5-sonnet-20240620',
//   'Claude 3 Opus': 'claude-3-opus-20240229',
//   'Claude 3 Sonnet': 'claude-3-sonnet-20240229',
//   'Claude 3 Haiku': 'claude-3-haiku-20240307',
//   'Claude-2.1': 'claude-2.1',
//   'Claude-2.0': 'claude-2.0',
//   'Claude-1': '', // No exact match
//   'Claude-Instant-1': 'claude-instant-1.2', // Closest match
//
//   // Gemini models
//   'Gemini-1.5-Pro-Exp-0801': 'models/gemini-1.5-pro-latest', // Closest match
//   'Gemini Advanced App (2024-05-14)': '', // No exact match
//   'Gemini-1.5-Pro-001': 'models/gemini-1.5-pro-001',
//   'Gemini-1.5-Pro-Preview-0409': 'models/gemini-1.5-pro-latest', // Closest match
//   'Gemini-1.5-Flash-001': 'models/gemini-1.5-flash-001',
//   'Gemini App (2024-01-24)': '', // No exact match
//   'Gemini-1.0-Pro-001': 'models/gemini-1.0-pro-001',
//   'Gemini Pro': 'models/gemini-pro',
//
//   // OpenAI models (from the previous file)
//   'GPT-4o-2024-05-13': 'gpt-4o-2024-05-13',
//   'GPT-4o-mini-2024-07-18': 'gpt-4o-mini-2024-07-18',
//   'GPT-4-Turbo-2024-04-09': 'gpt-4-turbo-2024-04-09',
//   'GPT-4-1106-preview': 'gpt-4-1106-preview',
//   'GPT-4-0125-preview': 'gpt-4-0125-preview',
//   'GPT-4-0314': 'gpt-4-0314',
//   'GPT-4-0613': 'gpt-4-0613',
//   'GPT-3.5-Turbo-0613': 'gpt-3.5-turbo-0613',
//   'GPT-3.5-Turbo-0314': 'gpt-3.5-turbo-0314',
//   'GPT-3.5-Turbo-0125': 'gpt-3.5-turbo-0125',
//
//   // Mistral models (from the previous file)
//   'Mistral-Large-2402': 'mistral-large-2402',
//   'Mixtral-8x7b-Instruct-v0.1': 'mistralai/Mixtral-8x7B-Instruct-v0.1',
//
//   // Other models without matches
//   'Gemini-1.5-Pro-Exp-0801': '',
//   'Meta-Llama-3.1-405b-Instruct': '',
//   'Gemini-1.5-Pro-001': '',
//   'Meta-Llama-3.1-70b-Instruct': '',
//   'Yi-Large-preview': '',
//   'Deepseek-v2-API-0628': '',
//   'Gemma-2-27b-it': '',
//   'Yi-Large': '',
//   'Nemotron-4-340B-Instruct': '',
//   'GLM-4-0520': '',
//   'Llama-3-70b-Instruct': '',
//   'Reka-Core-20240501': '',
//   'Command R+': '',
//   'Gemma-2-9b-it': '',
//   'Qwen2-72B-Instruct': '',
//   'GLM-4-0116': '',
//   'Qwen-Max-0428': '',
//   'DeepSeek-Coder-V2-Instruct': '',
//   'Reka-Flash-Preview-20240611': '',
//   'Meta-Llama-3.1-8b-Instruct': '',
//   'Qwen1.5-110B-Chat': '',
//   'Yi-1.5-34B-Chat': '',
//   'Reka-Flash-21B-online': '',
//   'Llama-3-8b-Instruct': '',
//   'Command R': '',
//   'Reka-Flash-21B': '',
//   'Qwen1.5-72B-Chat': '',
//   'Mixtral-8x22b-Instruct-v0.1': '',
//   'Zephyr-ORPO-141b-A35b-v0.1': '',
//   'Qwen1.5-32B-Chat': '',
//   'Mistral-Next': '',
//   'Phi-3-Medium-4k-Instruct': '',
//   'Starling-LM-7B-beta': '',
//   'Yi-34B-Chat': '',
//   'Qwen1.5-14B-Chat': '',
//   'WizardLM-70B-v1.0': '',
//   'Tulu-2-DPO-70B': '',
//   'DBRX-Instruct-Preview': '',
//   'Phi-3-Small-8k-Instruct': '',
//   'Llama-2-70b-chat': '',
//   'OpenChat-3.5-0106': '',
//   'Vicuna-33B': '',
//   'Snowflake Arctic Instruct': '',
//   'Starling-LM-7B-alpha': '',
// };


================================================
FILE: src/modules/llms/server/openai/openai.router.ts
================================================
import * as z from 'zod/v4';
import { TRPCError } from '@trpc/server';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { env } from '~/server/env';
import { fetchJsonOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';
import { serverCapitalizeFirstLetter } from '~/server/wire';

import type { T2ICreateImageAsyncStreamOp } from '~/modules/t2i/t2i.server';
import { heartbeatsWhileAwaiting } from '~/modules/aix/server/dispatch/heartbeatsWhileAwaiting';

import { Brand } from '~/common/app.config';

import { OpenAIWire_API_Images_Generations, OpenAIWire_API_Models_List, OpenAIWire_API_Moderations_Create } from '~/modules/aix/server/dispatch/wiretypes/openai.wiretypes';

import { ListModelsResponse_schema, ModelDescriptionSchema } from '../llm.server.types';
import { alibabaModelSort, alibabaModelToModelDescription } from './models/alibaba.models';
import { azureDeploymentFilter, azureDeploymentToModelDescription, azureParseFromDeploymentsAPI } from './models/azure.models';
import { chutesAIHeuristic, chutesAIModelsToModelDescriptions } from './models/chutesai.models';
import { deepseekModelFilter, deepseekModelSort, deepseekModelToModelDescription } from './models/deepseek.models';
import { fastAPIHeuristic, fastAPIModels } from './models/fastapi.models';
import { fireworksAIHeuristic, fireworksAIModelsToModelDescriptions } from './models/fireworksai.models';
import { groqModelFilter, groqModelSortFn, groqModelToModelDescription } from './models/groq.models';
import { lmStudioModelToModelDescription, localAIModelSortFn, localAIModelToModelDescription } from './models/models.data';
import { mistralModels } from './models/mistral.models';
import { openAIModelFilter, openAIModelToModelDescription, openAISortModels } from './models/openai.models';
import { openPipeModelDescriptions, openPipeModelSort, openPipeModelToModelDescriptions } from './models/openpipe.models';
import { openRouterInjectVariants, openRouterModelFamilySortFn, openRouterModelToModelDescription } from './models/openrouter.models';
import { perplexityAIModelDescriptions, perplexityInjectVariants } from './models/perplexity.models';
import { togetherAIModelsToModelDescriptions } from './models/together.models';
import { wireLocalAIModelsApplyOutputSchema, wireLocalAIModelsAvailableOutputSchema, wireLocalAIModelsListOutputSchema } from './localai.wiretypes';
import { xaiModelDescriptions, xaiModelSort } from './models/xai.models';


const openAIDialects = z.enum([
  'alibaba', 'azure', 'deepseek', 'groq', 'lmstudio', 'localai', 'mistral', 'openai', 'openpipe', 'openrouter', 'perplexity', 'togetherai', 'xai',
]);
export type OpenAIDialects = z.infer<typeof openAIDialects>;

export const openAIAccessSchema = z.object({
  dialect: openAIDialects,
  oaiKey: z.string().trim(),
  oaiOrg: z.string().trim(), // [OpenPipe] we have a hack here, where we put the tags stringinfied JSON in here - cleanup in the future
  oaiHost: z.string().trim(),
  heliKey: z.string().trim(),
  moderationCheck: z.boolean(),
});
export type OpenAIAccessSchema = z.infer<typeof openAIAccessSchema>;

// export const openAIModelSchema = z.object({
//   id: z.string(),
//   temperature: z.number().min(0).max(2).optional(),
//   maxTokens: z.number().min(1).optional(),
// });
// export type OpenAIModelSchema = z.infer<typeof openAIModelSchema>;

// export const openAIHistorySchema = z.array(z.object({
//   role: z.enum(['assistant', 'system', 'user'/*, 'function'*/]),
//   content: z.string(),
// }));
// export type OpenAIHistorySchema = z.infer<typeof openAIHistorySchema>;


// Fixup host function

/** Add https if missing, and remove trailing slash if present and the path starts with a slash. */
export function fixupHost(host: string, apiPath: string): string {
  if (!host.startsWith('http'))
    host = `https://${host}`;
  if (host.endsWith('/') && apiPath.startsWith('/'))
    host = host.slice(0, -1);
  return host;
}


// Router Input Schemas

const listModelsInputSchema = z.object({
  access: openAIAccessSchema,
});


const _createImageConfigBase = z.object({
  // prompt: z.string().max(32000),
  count: z.number().min(1).max(10),
  user: z.string().optional(),
});

// GPT Image
const createImageConfigGI = _createImageConfigBase.extend({
  model: z.literal('gpt-image-1'),
  prompt: z.string().max(32000),
  size: z.enum([/*'auto',*/ '1024x1024', '1536x1024', '1024x1536']),
  quality: z.enum(['high', 'medium', 'low']).optional(),
  background: z.enum(['auto', 'transparent', 'opaque']).optional(),
  output_format: z.enum(['png', 'jpeg', 'webp']).optional(),
  output_compression: z.number().min(0).max(100).int().optional(),
  moderation: z.enum(['low', 'auto']).optional(),
});

// DALL-E 3
const createImageConfigD3 = _createImageConfigBase.extend({
  model: z.literal('dall-e-3'),
  count: z.number().min(1).max(1), // DALL-E 3 only supports n=1
  prompt: z.string().max(4000),
  quality: z.enum(['standard', 'hd']),
  size: z.enum(['1024x1024', '1792x1024', '1024x1792']),
  style: z.enum(['vivid', 'natural']).optional(),
  response_format: z.enum([/*'url',*/ 'b64_json']).optional(),
});

// DALL-E 2
const createImageConfigD2 = _createImageConfigBase.extend({
  model: z.literal('dall-e-2'),
  prompt: z.string().max(1000),
  quality: z.literal('standard').optional(),
  size: z.enum(['256x256', '512x512', '1024x1024']),
  response_format: z.enum([/*'url',*/ 'b64_json']).optional(),
});

const createImagesInputSchema = z.object({
  access: openAIAccessSchema,
  // for this object sync with <> OpenAIWire_API_Images_Generations.Request_schema
  generationConfig: z.discriminatedUnion('model', [
    createImageConfigGI,
    createImageConfigD3,
    createImageConfigD2,
  ]),
  editConfig: z.object({
    /**
     * This is the exact copy of AixWire_Parts.InlineImagePart_schema, but somehow we must keep
     * this module separate for now, or we'll get circular dependencies during the build.
     */
    inputImages: z.array(z.object({
      pt: z.literal('inline_image'),
      mimeType: z.enum(['image/jpeg', 'image/png', 'image/webp']),
      base64: z.string(),
    })),
    maskImage: z.object({
      pt: z.literal('inline_image'),
      mimeType: z.enum(['image/jpeg', 'image/png', 'image/webp']),
      base64: z.string(),
    }).optional(),
  }).optional(),
});


const moderationInputSchema = z.object({
  access: openAIAccessSchema,
  text: z.string(),
});


export const llmOpenAIRouter = createTRPCRouter({

  /* [OpenAI] List the Models available */
  listModels: publicProcedure
    .input(listModelsInputSchema)
    .output(ListModelsResponse_schema)
    .query(async ({ input: { access } }): Promise<{ models: ModelDescriptionSchema[] }> => {

      let models: ModelDescriptionSchema[];

      // [Azure]: use an older 'deployments' API to enumerate the models, and a modified OpenAI id to description mapping
      if (access.dialect === 'azure') {
        const azureOpenAIDeploymentsResponse = await openaiGETOrThrow(access, `/openai/deployments?api-version=2023-03-15-preview`);
        const azureOpenAIDeployments = azureParseFromDeploymentsAPI(azureOpenAIDeploymentsResponse);
        models = azureOpenAIDeployments
          .filter(azureDeploymentFilter)
          .map(azureDeploymentToModelDescription)
          .sort(openAISortModels);
        return { models };
      }

      // [Perplexity]: there's no API for models listing (upstream: https://docs.perplexity.ai/guides/model-cards)
      if (access.dialect === 'perplexity') {
        models = perplexityAIModelDescriptions()
          .reduce(perplexityInjectVariants, [] as ModelDescriptionSchema[]);
        return { models };
      }

      // [xAI]: custom models listing
      if (access.dialect === 'xai')
        return { models: (await xaiModelDescriptions(access)).sort(xaiModelSort) };

      // [OpenAI-dialects]: fetch openAI-style for all but Azure (will be then used in each dialect)
      const openAIWireModelsResponse = await openaiGETOrThrow<OpenAIWire_API_Models_List.Response>(access, '/v1/models');

      // [Together] missing the .data property
      if (access.dialect === 'togetherai')
        return { models: togetherAIModelsToModelDescriptions(openAIWireModelsResponse) };

      let openAIModels = openAIWireModelsResponse.data || [];

      // de-duplicate by ids (can happen for local servers.. upstream bugs)
      const preCount = openAIModels.length;
      openAIModels = openAIModels.filter((model, index) => openAIModels.findIndex(m => m.id === model.id) === index);
      if (preCount !== openAIModels.length)
        console.warn(`openai.router.listModels: removed ${preCount - openAIModels.length} duplicate models for dialect ${access.dialect}`);

      // sort by id
      openAIModels.sort((a, b) => a.id.localeCompare(b.id));

      // every dialect has a different way to enumerate models - we execute the mapping on the server side
      switch (access.dialect) {

        case 'alibaba':
          models = openAIModels
            .map(({ id, created }) => alibabaModelToModelDescription(id, created))
            .sort(alibabaModelSort);
          break;

        case 'deepseek':
          models = openAIModels
            .filter(({ id }) => deepseekModelFilter(id))
            .map(({ id }) => deepseekModelToModelDescription(id))
            .sort(deepseekModelSort);
          break;

        case 'groq':
          models = openAIModels
            .filter(groqModelFilter)
            .map(groqModelToModelDescription)
            .sort(groqModelSortFn);
          break;

        case 'lmstudio':
          models = openAIModels
            .map(({ id }) => lmStudioModelToModelDescription(id));
          break;

        // [LocalAI]: map id to label
        case 'localai':
          models = openAIModels
            .map(({ id }) => localAIModelToModelDescription(id))
            .sort(localAIModelSortFn);
          break;

        case 'mistral':
          models = mistralModels(openAIModels);
          break;

        // [OpenAI]: chat-only models, custom sort, manual mapping
        case 'openai':

          // [ChutesAI] special case for model enumeration
          if (chutesAIHeuristic(access.oaiHost))
            return { models: chutesAIModelsToModelDescriptions(openAIModels) };

          // [FireworksAI] special case for model enumeration
          if (fireworksAIHeuristic(access.oaiHost))
            return { models: fireworksAIModelsToModelDescriptions(openAIModels) };

          // [FastChat] make the best of the little info
          if (fastAPIHeuristic(openAIModels))
            return { models: fastAPIModels(openAIModels) };

          models = openAIModels

            // limit to only 'gpt' and 'non instruct' models
            .filter(openAIModelFilter)

            // to model description
            .map((model): ModelDescriptionSchema => openAIModelToModelDescription(model.id, model.created))

            // custom OpenAI sort
            .sort(openAISortModels);
          break;

        case 'openpipe':
          models = [
            ...openAIModels.map(openPipeModelToModelDescriptions),
            ...openPipeModelDescriptions().sort(openPipeModelSort),
          ];
          break;

        case 'openrouter':
          // openRouterStatTokenizers(openAIModels);
          models = openAIModels
            .sort(openRouterModelFamilySortFn)
            .map(openRouterModelToModelDescription)
            .filter(desc => !!desc)
            .reduce(openRouterInjectVariants, [] as ModelDescriptionSchema[]);
          break;

      }

      return { models };
    }),


  /* [OpenAI/LocalAI] images/generations */
  createImages: publicProcedure
    .input(createImagesInputSchema)
    .mutation(async function* ({ input }): AsyncGenerator<T2ICreateImageAsyncStreamOp> {

      const { access, generationConfig: config, editConfig } = input;

      // Determine if this is an edit request
      const isEdit = !!editConfig?.inputImages?.length && config.model === 'gpt-image-1';

      // validate input
      if (isEdit && config.model !== 'gpt-image-1')
        throw new TRPCError({ code: 'BAD_REQUEST', message: `Image editing is only supported for GPT Image models` });
      if (config.model === 'dall-e-3' && config.count > 1)
        throw new TRPCError({ code: 'BAD_REQUEST', message: `[OpenAI Issue] dall-e-3 model does not support more than 1 image` });
      // if (config.model !== 'gpt-image-1' && (config.background || config.moderation || config.output_compression || config.output_format))
      //   throw new TRPCError({ code: 'BAD_REQUEST', message: `[OpenAI Issue] background, moderation, output_compression, output_format are only supported for gpt-image-1` });
      // if (config.model !== 'dall-e-3' && config.style)
      //   throw new TRPCError({ code: 'BAD_REQUEST', message: `[OpenAI Issue] style is only supported for dall-e-3` });


      // Prepare request body (JSON for generation, FormData for edit)
      let requestBody: OpenAIWire_API_Images_Generations.Request | FormData;
      let genImageMimeType = 'image/png'; // assume as default

      if (!isEdit) {

        const { count, ...restConfig } = config;
        requestBody = {
          ...restConfig, // includes response_format for dall-e-3 and dall-e-2 models
          n: count,
          user: config.user || 'Big-AGI',
        };

        // [LocalAI] Fix: LocalAI does not want the 'response_format' field
        if (access.dialect === 'localai' && 'response_format' in requestBody)
          delete requestBody['response_format'];

        // auto-selects the output image mime type - or defaults to the first one
        if (requestBody.output_format === 'jpeg')
          genImageMimeType = 'image/jpeg';
        else if (requestBody.output_format === 'webp')
          genImageMimeType = 'image/webp';

      } else {
        requestBody = new FormData();

        // append required & optional fields
        const { prompt, model, count, quality, size, user } = config;
        requestBody.append('prompt', prompt);
        requestBody.append('model', model);
        if (count > 1) requestBody.append('n', '' + count);
        if (quality && (quality as string) !== 'auto') requestBody.append('quality', quality);
        if (size && (size as string) !== 'auto') requestBody.append('size', size);
        // if (model === 'dall-e-2') requestBody.append('response_format', 'b64_json');
        requestBody.append('user', user || 'Big-AGI');

        // append input images
        const imagesCount = editConfig.inputImages.length;
        for (let i = 0; i < imagesCount; i++) {
          const { base64, mimeType } = editConfig.inputImages[i];
          requestBody.append(
            imagesCount === 1 ? 'image' : 'image[]',
            server_base64ToBlob(base64, mimeType),
            `image_${i}.${mimeType.split('/')[1] || 'png'}`, // important to be a unique filename
          );
        }

        // append mask image if provided
        if (editConfig.maskImage)
          requestBody.append(
            'mask',
            server_base64ToBlob(editConfig.maskImage.base64, editConfig.maskImage.mimeType),
            `mask.${editConfig.maskImage.mimeType.split('/')[1] || 'png'}`,
          );
      }

      // -> state.started
      yield { p: 'state', state: 'started' };

      // -> heartbeats, while waiting for the generation response
      const wireOpenAICreateImageOutput = yield* heartbeatsWhileAwaiting(
        openaiPOSTOrThrow<OpenAIWire_API_Images_Generations.Response, OpenAIWire_API_Images_Generations.Request | FormData>(
          access,
          config.model,  // modelRefId not really needed for these endpoints
          requestBody,
          isEdit ? '/v1/images/edits' : '/v1/images/generations',
        ),
      );

      // common image fields
      const [width, height] = (config.size as any) === 'auto'
        ? [1024, 1024] // NOTE: this is broken, bad assumption, but so that we don't throw an error
        : config.size.split('x').map(nStr => parseInt(nStr));
      if (!width || !height) {
        console.error(`openai.router.createImages: invalid size ${config.size}`);
        throw new TRPCError({ code: 'INTERNAL_SERVER_ERROR', message: `[OpenAI Issue] Invalid size ${config.size}` });
      }
      const { count: _ignoreCount, prompt: origPrompt, ...parameters } = config;

      // parse the response and emit all images in the response
      const { data: images, usage: tokens } = OpenAIWire_API_Images_Generations.Response_schema.parse(wireOpenAICreateImageOutput);
      for (const image of images) {
        if (!('b64_json' in image))
          throw new TRPCError({ code: 'INTERNAL_SERVER_ERROR', message: `[OpenAI Issue] Expected a b64_json, got a url` });

        // -> createImage
        yield {
          p: 'createImage',
          image: {
            mimeType: genImageMimeType,
            base64Data: image.b64_json!,
            altText: image.revised_prompt || origPrompt,
            width,
            height,
            ...(tokens?.input_tokens !== undefined ? { inputTokens: tokens.input_tokens } : {}),
            ...(tokens?.output_tokens !== undefined ? { outputTokens: tokens.output_tokens } : {}),
            generatorName: config.model,
            parameters: parameters,
            generatedAt: new Date().toISOString(),
          },
        };
      }
    }),


  /* [OpenAI] check for content policy violations */
  moderation: publicProcedure
    .input(moderationInputSchema)
    .mutation(async ({ input: { access, text } }): Promise<OpenAIWire_API_Moderations_Create.Response> => {
      try {

        return await openaiPOSTOrThrow<OpenAIWire_API_Moderations_Create.Response, OpenAIWire_API_Moderations_Create.Request>(access, null, {
          input: text,
          model: 'text-moderation-latest',
        }, '/v1/moderations');

      } catch (error: any) {
        if (error.code === 'ECONNRESET')
          throw new TRPCError({ code: 'CLIENT_CLOSED_REQUEST', message: 'Connection reset by the client.' });

        console.error('api/openai/moderation error:', error);
        throw new TRPCError({ code: 'BAD_REQUEST', message: `Error: ${error?.message || error?.toString() || 'Unknown error'}` });
      }
    }),


  /// Dialect-specific procedures ///

  /* [LocalAI] List all Model Galleries */
  dialectLocalAI_galleryModelsAvailable: publicProcedure
    .input(listModelsInputSchema)
    .query(async ({ input: { access } }) => {
      const wireLocalAIModelsAvailable = await openaiGETOrThrow(access, '/models/available');
      return wireLocalAIModelsAvailableOutputSchema.parse(wireLocalAIModelsAvailable);
    }),

  /* [LocalAI] Download a model from a Model Gallery */
  dialectLocalAI_galleryModelsApply: publicProcedure
    .input(z.object({
      access: openAIAccessSchema,
      galleryName: z.string(),
      modelName: z.string(),
    }))
    .mutation(async ({ input: { access, galleryName, modelName } }) => {
      const galleryModelId = `${galleryName}@${modelName}`;
      const wireLocalAIModelApply = await openaiPOSTOrThrow(access, null, { id: galleryModelId }, '/models/apply');
      return wireLocalAIModelsApplyOutputSchema.parse(wireLocalAIModelApply);
    }),

  /* [LocalAI] Poll for a Model download Job status */
  dialectLocalAI_galleryModelsJob: publicProcedure
    .input(z.object({
      access: openAIAccessSchema,
      jobId: z.string(),
    }))
    .query(async ({ input: { access, jobId } }) => {
      const wireLocalAIModelsJobs = await openaiGETOrThrow(access, `/models/jobs/${jobId}`);
      return wireLocalAIModelsListOutputSchema.parse(wireLocalAIModelsJobs);
    }),

});


const DEFAULT_ALIBABA_HOST = 'https://dashscope-intl.aliyuncs.com/compatible-mode';
const DEFAULT_HELICONE_OPENAI_HOST = 'oai.hconeai.com';
const DEFAULT_DEEPSEEK_HOST = 'https://api.deepseek.com';
const DEFAULT_GROQ_HOST = 'https://api.groq.com/openai';
const DEFAULT_LOCALAI_HOST = 'http://127.0.0.1:8080';
const DEFAULT_MISTRAL_HOST = 'https://api.mistral.ai';
const DEFAULT_OPENAI_HOST = 'api.openai.com';
const DEFAULT_OPENPIPE_HOST = 'https://app.openpipe.ai/api';
const DEFAULT_OPENROUTER_HOST = 'https://openrouter.ai/api';
const DEFAULT_PERPLEXITY_HOST = 'https://api.perplexity.ai';
const DEFAULT_TOGETHERAI_HOST = 'https://api.together.xyz';
const DEFAULT_XAI_HOST = 'https://api.x.ai';


/**
 * Get a random key from a comma-separated list of API keys
 * @param multiKeyString Comma-separated string of API keys
 * @returns A randomly selected single API key
 */
function getRandomKeyFromMultiKey(multiKeyString: string): string {
  if (!multiKeyString.includes(','))
    return multiKeyString;

  const multiKeys = multiKeyString
    .split(',')
    .map(key => key.trim())
    .filter(Boolean);

  if (!multiKeys.length)
    return '';

  return multiKeys[Math.floor(Math.random() * multiKeys.length)];
}

export function openAIAccess(access: OpenAIAccessSchema, modelRefId: string | null, apiPath: string): { headers: HeadersInit, url: string } {
  switch (access.dialect) {

    case 'alibaba':
      let alibabaOaiKey = access.oaiKey || env.ALIBABA_API_KEY || '';
      const alibabaOaiHost = fixupHost(access.oaiHost || env.ALIBABA_API_HOST || DEFAULT_ALIBABA_HOST, apiPath);

      // Use function to select a random key if multiple keys are provided
      alibabaOaiKey = getRandomKeyFromMultiKey(alibabaOaiKey);

      if (!alibabaOaiKey || !alibabaOaiHost)
        throw new Error('Missing Alibaba API Key. Add it on the UI or server side (your deployment).');

      return {
        headers: {
          'Authorization': `Bearer ${alibabaOaiKey}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json',
        },
        url: alibabaOaiHost + apiPath,
      };

    case 'azure':
      const azureKey = access.oaiKey || env.AZURE_OPENAI_API_KEY || '';
      const azureHost = fixupHost(access.oaiHost || env.AZURE_OPENAI_API_ENDPOINT || '', apiPath);
      if (!azureKey || !azureHost)
        throw new Error('Missing Azure API Key or Host. Add it on the UI (Models Setup) or server side (your deployment).');

      let url = azureHost;
      if (apiPath.startsWith('/v1/')) {
        if (!modelRefId)
          throw new Error('Azure OpenAI API needs a deployment id');
        url += `/openai/deployments/${modelRefId}/${apiPath.replace('/v1/', '')}?api-version=2025-02-01-preview`;
      } else if (apiPath.startsWith('/openai/deployments'))
        url += apiPath;
      else
        throw new Error('Azure OpenAI API path not supported: ' + apiPath);

      return {
        headers: {
          'Content-Type': 'application/json',
          'api-key': azureKey,
        },
        url,
      };


    case 'deepseek':
      // https://platform.deepseek.com/api-docs/
      let deepseekKey = access.oaiKey || env.DEEPSEEK_API_KEY || '';
      const deepseekHost = fixupHost(access.oaiHost || DEFAULT_DEEPSEEK_HOST, apiPath);

      // Use function to select a random key if multiple keys are provided
      deepseekKey = getRandomKeyFromMultiKey(deepseekKey);

      if (!deepseekKey || !deepseekHost)
        throw new Error('Missing Deepseek API Key or Host. Add it on the UI (Models Setup) or server side (your deployment).');

      return {
        headers: {
          'Authorization': `Bearer ${deepseekKey}`,
          'Content-Type': 'application/json',
        },
        url: deepseekHost + apiPath,
      };


    case 'lmstudio':
    case 'openai':
      const oaiKey = access.oaiKey || env.OPENAI_API_KEY || '';
      const oaiOrg = access.oaiOrg || env.OPENAI_API_ORG_ID || '';
      let oaiHost = fixupHost(access.oaiHost || env.OPENAI_API_HOST || DEFAULT_OPENAI_HOST, apiPath);
      // warn if no key - only for default (non-overridden) hosts
      if (!oaiKey && oaiHost.indexOf(DEFAULT_OPENAI_HOST) !== -1)
        throw new Error('Missing OpenAI API Key. Add it on the UI or server side (your deployment).');

      // [Helicone]
      // We don't change the host (as we do on Anthropic's), as we expect the user to have a custom host.
      let heliKey = access.heliKey || env.HELICONE_API_KEY || false;
      if (heliKey) {
        if (oaiHost.includes(DEFAULT_OPENAI_HOST)) {
          oaiHost = `https://${DEFAULT_HELICONE_OPENAI_HOST}`;
        } else if (!oaiHost.includes(DEFAULT_HELICONE_OPENAI_HOST)) {
          // throw new Error(`The Helicone OpenAI Key has been provided, but the host is not set to https://${DEFAULT_HELICONE_OPENAI_HOST}. Please fix it in the Models Setup page.`);
          heliKey = false;
        }
      }

      // [Cloudflare OpenAI AI Gateway support]
      // Adapts the API path when using a 'universal' or 'openai' Cloudflare AI Gateway endpoint in the "API Host" field
      if (oaiHost.includes('https://gateway.ai.cloudflare.com')) {
        const parsedUrl = new URL(oaiHost);
        const pathSegments = parsedUrl.pathname.split('/').filter(segment => segment.length > 0);

        // The expected path should be: /v1/<ACCOUNT_TAG>/<GATEWAY_URL_SLUG>/<PROVIDER_ENDPOINT>
        if (pathSegments.length < 3 || pathSegments.length > 4 || pathSegments[0] !== 'v1')
          throw new Error('Cloudflare AI Gateway API Host is not valid. Please check the API Host field in the Models Setup page.');

        const [_v1, accountTag, gatewayName, provider] = pathSegments;
        if (provider && provider !== 'openai')
          throw new Error('Cloudflare AI Gateway only supports OpenAI as a provider.');

        if (apiPath.startsWith('/v1'))
          apiPath = apiPath.replace('/v1', '');

        oaiHost = 'https://gateway.ai.cloudflare.com';
        apiPath = `/v1/${accountTag}/${gatewayName}/${provider || 'openai'}${apiPath}`;
      }

      return {
        headers: {
          'Content-Type': 'application/json',
          ...(oaiKey && { Authorization: `Bearer ${oaiKey}` }),
          ...(oaiOrg && { 'OpenAI-Organization': oaiOrg }),
          ...(heliKey && { 'Helicone-Auth': `Bearer ${heliKey}` }),
        },
        url: oaiHost + apiPath,
      };

    case 'groq':
      let groqKey = access.oaiKey || env.GROQ_API_KEY || '';
      const groqHost = fixupHost(access.oaiHost || DEFAULT_GROQ_HOST, apiPath);

      // Use function to select a random key if multiple keys are provided
      groqKey = getRandomKeyFromMultiKey(groqKey);

      if (!groqKey)
        throw new Error('Missing Groq API Key. Add it on the UI (Models Setup) or server side (your deployment).');

      return {
        headers: {
          'Content-Type': 'application/json',
          'Accept': 'application/json',
          'Authorization': `Bearer ${groqKey}`,
        },
        url: groqHost + apiPath,
      };


    case 'localai':
      const localAIKey = access.oaiKey || env.LOCALAI_API_KEY || '';
      let localAIHost = fixupHost(access.oaiHost || env.LOCALAI_API_HOST || DEFAULT_LOCALAI_HOST, apiPath);
      return {
        headers: {
          'Content-Type': 'application/json',
          ...(localAIKey && { Authorization: `Bearer ${localAIKey}` }),
        },
        url: localAIHost + apiPath,
      };


    case 'mistral':
      // https://docs.mistral.ai/platform/client
      let mistralKey = access.oaiKey || env.MISTRAL_API_KEY || '';
      const mistralHost = fixupHost(access.oaiHost || DEFAULT_MISTRAL_HOST, apiPath);

      // Use function to select a random key if multiple keys are provided
      mistralKey = getRandomKeyFromMultiKey(mistralKey);

      return {
        headers: {
          'Content-Type': 'application/json',
          'Accept': 'application/json',
          'Authorization': `Bearer ${mistralKey}`,
        },
        url: mistralHost + apiPath,
      };


    case 'openpipe':
      const openPipeKey = access.oaiKey || env.OPENPIPE_API_KEY || '';
      if (!openPipeKey)
        throw new Error('Missing OpenPipe API Key or Host. Add it on the UI or server side (your deployment).');

      return {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${openPipeKey}`,
          'op-log-request': 'true',
          ...(access.oaiOrg && { 'op-tags': access.oaiOrg }),
        },
        url: fixupHost(DEFAULT_OPENPIPE_HOST, apiPath) + apiPath,
      };

    case 'openrouter':
      let orKey = access.oaiKey || env.OPENROUTER_API_KEY || '';
      const orHost = fixupHost(access.oaiHost || DEFAULT_OPENROUTER_HOST, apiPath);

      // Use function to select a random key if multiple keys are provided
      orKey = getRandomKeyFromMultiKey(orKey);

      if (!orKey || !orHost)
        throw new Error('Missing OpenRouter API Key or Host. Add it on the UI or server side (your deployment).');

      return {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${orKey}`,
          'HTTP-Referer': Brand.URIs.Home,
          'X-Title': Brand.Title.Base,
        },
        url: orHost + apiPath,
      };

    case 'perplexity':
      let perplexityKey = access.oaiKey || env.PERPLEXITY_API_KEY || '';
      const perplexityHost = fixupHost(access.oaiHost || DEFAULT_PERPLEXITY_HOST, apiPath);

      // Use function to select a random key if multiple keys are provided
      perplexityKey = getRandomKeyFromMultiKey(perplexityKey);

      if (!perplexityKey || !perplexityHost)
        throw new Error('Missing Perplexity API Key or Host. Add it on the UI (Models Setup) or server side (your deployment).');

      if (apiPath.startsWith('/v1'))
        apiPath = apiPath.replace('/v1', '');

      return {
        headers: {
          'Content-Type': 'application/json',
          'Accept': 'application/json',
          'Authorization': `Bearer ${perplexityKey}`,
        },
        url: perplexityHost + apiPath,
      };


    case 'togetherai':
      let togetherKey = access.oaiKey || env.TOGETHERAI_API_KEY || '';
      const togetherHost = fixupHost(access.oaiHost || DEFAULT_TOGETHERAI_HOST, apiPath);

      // Use function to select a random key if multiple keys are provided
      togetherKey = getRandomKeyFromMultiKey(togetherKey);

      if (!togetherKey || !togetherHost)
        throw new Error('Missing TogetherAI API Key or Host. Add it on the UI (Models Setup) or server side (your deployment).');

      return {
        headers: {
          'Authorization': `Bearer ${togetherKey}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json',
        },
        url: togetherHost + apiPath,
      };


    case 'xai':
      let xaiKey = access.oaiKey || env.XAI_API_KEY || '';

      // Use function to select a random key if multiple keys are provided
      xaiKey = getRandomKeyFromMultiKey(xaiKey);

      if (!xaiKey)
        throw new Error('Missing xAI API Key. Add it on the UI (Models Setup) or server side (your deployment).');
      return {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${xaiKey}`,
        },
        url: DEFAULT_XAI_HOST + apiPath,
      };

  }
}


async function openaiGETOrThrow<TOut extends object>(access: OpenAIAccessSchema, apiPath: string /*, signal?: AbortSignal*/): Promise<TOut> {
  const { headers, url } = openAIAccess(access, null, apiPath);
  return await fetchJsonOrTRPCThrow<TOut>({ url, headers, name: `OpenAI/${serverCapitalizeFirstLetter(access.dialect)}` });
}

async function openaiPOSTOrThrow<TOut extends object, TPostBody extends object | FormData>(access: OpenAIAccessSchema, modelRefId: string | null, body: TPostBody, apiPath: string /*, signal?: AbortSignal*/): Promise<TOut> {
  const { headers, url } = openAIAccess(access, modelRefId, apiPath);
  return await fetchJsonOrTRPCThrow<TOut, TPostBody>({ url, method: 'POST', headers, body, name: `OpenAI/${serverCapitalizeFirstLetter(access.dialect)}` });
}


/** @serverSide Buffer is a Node.js API, not a Browser API. */
function server_base64ToBlob(base64Data: string, mimeType: string) {
  const buffer = Buffer.from(base64Data, 'base64');
  return new Blob([buffer], { type: mimeType });
}



================================================
FILE: src/modules/llms/server/openai/openpipe.wiretypes.ts
================================================
import * as z from 'zod/v4';


// @upstream: https://docs.openpipe.ai/api-reference/get-listModels

const openpipeSchema = z.object({
  baseModel: z.string(),
  status: z.enum(['PENDING', 'TRAINING', 'DEPLOYED', 'ERROR', 'DEPRECATED']),
  datasetId: z.string(),
  errorMessage: z.string().nullable(),
});


export const wireOpenPipeModelOutputSchema = z.object({
  id: z.string(),
  name: z.string(),
  description: z.string().nullable(),
  created: z.string(),  // ISO string
  updated: z.string(),  // ISO string
  openpipe: openpipeSchema,
  contextWindow: z.number(),
  maxCompletionTokens: z.number(),
  capabilities: z.array(z.enum(['chat', 'tools', 'json'])),
  pricing: z.object({
    chatIn: z.number(),
    chatOut: z.number(),
  }).optional(),
});


================================================
FILE: src/modules/llms/server/openai/openrouter.wiretypes.ts
================================================
import * as z from 'zod/v4';


export const wireOpenrouterModelsListOutputSchema = z.object({
  id: z.string(),
  name: z.string(),
  description: z.string(),
  // NOTE: for 'openrouter/auto', this is:  {
  //   "prompt": "-1",
  //   "completion": "-1"
  // }
  pricing: z.object({
    prompt: z.string(),
    completion: z.string(),
    image: z.string().optional(),
    request: z.string().optional(),
  }),
  context_length: z.number(),
  architecture: z.object({
    modality: z.string(), // z.enum(['text', 'multimodal', 'text+image->text]),
    tokenizer: z.string(), // e.g. 'Mistral', 'Claude'
    instruct_type: z.string().nullable(),
  }),
  top_provider: z.object({
    max_completion_tokens: z.number().nullable(),
    is_moderated: z.boolean(), // false means that the user will need to do moderation, and likely this has lower latency
  }),

  // when logged in
  per_request_limits: z.object({
    prompt_tokens: z.string(),
    completion_tokens: z.string(),
  }).nullable(), // null on 'openrouter/auto'
});


================================================
FILE: src/modules/llms/server/openai/togetherai.wiretypes.ts
================================================
import * as z from 'zod/v4';


// [Together AI] Models List API - Response

export const wireTogetherAIListOutputSchema = z.array(z.object({
  id: z.string(),
  object: z.literal('model'),
  created: z.number(),
  type: z.string(), // e.g., 'chat', 'language', 'image', 'embedding'
  running: z.boolean(),
  display_name: z.string(),

  organization: z.string().nullable().optional(),
  link: z.string().nullable().optional(),
  license: z.string().nullable().optional(),
  context_length: z.number().optional(),

  // Configuration object
  // config: z.object({
  //   chat_template: z.string().nullable(),
  //   stop: z.array(z.string()),
  //   bos_token: z.string().nullable(),
  //   eos_token: z.string().nullable(),
  // }).optional(),

  // Pricing information
  pricing: z.object({
    hourly: z.number(),
    input: z.number(),
    output: z.number(),
    base: z.number(),
    finetune: z.number(),
  }),
}));

// export type WireTogetherAIListOutput = z.infer<typeof wireTogetherAIListOutputSchema>;



================================================
FILE: src/modules/llms/server/openai/models/alibaba.models.ts
================================================
import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';

import { fromManualMapping, ManualMappings } from './models.data';

// - Models: https://www.alibabacloud.com/help/en/model-studio/getting-started/models
// - Pricing: https://www.alibabacloud.com/en/product/modelstudio?_p_lc=1&spm=a3c0i.11852017.6791778070.50.46f07ac9erixlG#J_9325669630

const _knownAlibabaChatModels: ManualMappings = [
  // Commercial Models
  {
    idPrefix: 'qwen-max',
    label: 'Qwen-Max',
    description: 'Best inference performance among Qwen models, especially for complex tasks. 32K context.',
    contextWindow: 32768,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    maxCompletionTokens: 8192,
    chatPrice: { input: 1.6, output: 6.4 },
    benchmark: { cbaElo: 1340 },
  },
  {
    idPrefix: 'qwen-plus',
    label: 'Qwen-Plus',
    description: 'Balanced performance, speed, and cost. 131K context.',
    contextWindow: 131072,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    maxCompletionTokens: 8192,
    chatPrice: { input: 0.4, output: 1.2 },
    benchmark: { cbaElo: 1310 },
  },
  {
    idPrefix: 'qwen-turbo',
    label: 'Qwen-Turbo',
    description: 'Fast speed and low cost, suitable for simple tasks. 1M context.',
    contextWindow: 1000000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    maxCompletionTokens: 8192,
    chatPrice: { input: 0.05, output: 0.2 },
    // unknown/unreported benchmark
  },

  // Vision Models
  {
    idPrefix: 'qwen-vl-max',
    label: 'Qwen-VL Max',
    description: 'Enhanced visual reasoning and instruction-following capabilities.',
    contextWindow: 7500,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision],
    maxCompletionTokens: 1500,
    chatPrice: { input: 'free', output: 'free' }, // Time-limited free trial
  },
  {
    idPrefix: 'qwen-vl-plus',
    label: 'Qwen-VL Plus',
    description: 'Enhanced detail and text recognition for visual tasks.',
    contextWindow: 7500,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision],
    maxCompletionTokens: 1500,
    chatPrice: { input: 'free', output: 'free' }, // Time-limited free trial
  },

  // Open Source Models - Qwen2.5
  {
    idPrefix: 'qwen2.5-72b-instruct',
    label: 'Qwen 2.5 72B',
    description: 'Latest Qwen series, 131K context.',
    contextWindow: 131072,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    maxCompletionTokens: 8192,
    chatPrice: { input: 'free', output: 'free' }, // Time-limited free trial
  },
  {
    idPrefix: 'qwen2.5-14b-instruct-1m',
    label: 'Qwen 2.5 14B (1M)',
    description: 'Latest Qwen series with 1M context.',
    contextWindow: 1000000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    maxCompletionTokens: 8192,
    chatPrice: { input: 'free', output: 'free' }, // Time-limited free trial
  },
  {
    idPrefix: 'qwen2.5-7b-instruct-1m',
    label: 'Qwen 2.5 7B (1M)',
    description: 'Latest Qwen series with 1M context.',
    contextWindow: 1000000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    maxCompletionTokens: 8192,
    chatPrice: { input: 'free', output: 'free' }, // Time-limited free trial
  },

  // Open Source Models - Qwen2
  {
    idPrefix: 'qwen2-7b-instruct',
    label: 'Qwen 2 7B',
    description: 'Open source Qwen2 model.',
    contextWindow: 131072,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    maxCompletionTokens: 6144,
    chatPrice: { input: 'free', output: 'free' }, // Time-limited free trial
  },
] as const;


export function alibabaModelToModelDescription(alibabaModelId: string, created?: number): ModelDescriptionSchema {
  // create is a number like '1728632029' - convert to Month/Year
  // const createdDate = created ? new Date(created * 1000) : undefined;
  // const createdStr = createdDate?.toLocaleString('en-US', { month: 'short', year: 'numeric' });
  // NOTE: as of Feb 2025, reports that the 4 Qwen models were created in Oct 2024.
  // So we're not using the created date for now, as to not confuse Users.
  return fromManualMapping(_knownAlibabaChatModels, alibabaModelId, created, undefined, {
    idPrefix: alibabaModelId,
    label: alibabaModelId.replaceAll(/[_-]/g, ' '),
    description: 'New Alibaba Model',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision], // assume..
  });
}

export function alibabaModelSort(a: ModelDescriptionSchema, b: ModelDescriptionSchema) {
  // sort by the order in the known models list
  const aIndex = _knownAlibabaChatModels.findIndex(m => a.id.startsWith(m.idPrefix));
  const bIndex = _knownAlibabaChatModels.findIndex(m => b.id.startsWith(m.idPrefix));
  if (aIndex !== -1 && bIndex !== -1)
    return aIndex - bIndex;
  return a.id.localeCompare(b.id);
}


================================================
FILE: src/modules/llms/server/openai/models/azure.models.ts
================================================
import * as z from 'zod/v4';

// import { LLM_IF_HOTFIX_NoTemperature, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { LLM_IF_OAI_Chat } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';

import { fromManualMapping, ManualMappings } from './models.data';
import { _knownOpenAIChatModels } from './openai.models';


// [Azure]
const _knownAzureChatModels: ManualMappings = [
  // ... if you have your own models, map them here ...
  //
  // NOTE: the ManualMapping object is similar to ModelDescriptionSchema,
  // with a renamed id field and other flags (isPreview, isLegacy, etc.), only used for
  // a consistent labeling of the model when fromManualMapping is invoked.
  //
  // Example:
  // {
  //   idPrefix: 'my-deployment-name',
  //   label: 'This is THE Model (25.12)',
  //   description: 'Top-tier reasoning.',
  //   contextWindow: 200 * 1024, // 200K tokens
  //   maxCompletionTokens: 8192, // 8K tokens
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Json, LLM_IF_OAI_Fn, /* <- flags | fixes -> */ LLM_IF_HOTFIX_NoTemperature],
  //   chatPrice: { input: 2, output: 6 },
  // },
  //

  // [Azure] variants: Azure names these differently compared to OpenAI (no dots) - also: obsolete
  {
    idPrefix: 'gpt-35-turbo-16k',
    label: '3.5-Turbo 16k',
    hidden: true, // OLD
    description: 'Fair speed and smarts, large context',
    contextWindow: 16384,
    interfaces: [LLM_IF_OAI_Chat], // as azure doesn't version model id's (in the deployments), let's assume no function calling
  },
  {
    idPrefix: 'gpt-35-turbo',
    label: '3.5-Turbo',
    contextWindow: 4096,
    hidden: true, // OLD
    description: 'Fair speed and smarts',
    interfaces: [LLM_IF_OAI_Chat], // as azure doesn't version model id's (in the deployments), let's assume no function calling
  },

];


// parser for Azure models - 2025-03-14: verified
const _azureOpenAIDeployment_schema = z.object({
  object: z.literal('deployment'),
  model: z.string(), // the OpenAI model id
  owner: z.string(), // relaxed from z.enum(['organization-owner']) for #774
  id: z.string(), // the deployment name
  status: z.string(), // relaxed from z.enum(['succeeded']) for #744
  // scale_settings: z.object({ ... }), // unused
  created_at: z.number(),
  updated_at: z.number(),
});
type AzureOpenAIDeployment = z.infer<typeof _azureOpenAIDeployment_schema>;

const _azureOpenAIDeploymentsList_schema = z.object({
  object: z.literal('list'),
  data: z.array(_azureOpenAIDeployment_schema),
});


export function azureParseFromDeploymentsAPI(deploymentsApiResponse: object): AzureOpenAIDeployment[] {
  return _azureOpenAIDeploymentsList_schema.parse(deploymentsApiResponse).data;
}


const _azureDenyListPrefix = [
  // unsupported for chat: text embedding models
  'text-embedding-',
];

export function azureDeploymentFilter({ id }: AzureOpenAIDeployment) {
  // filter out models that are not chat models
  return !_azureDenyListPrefix.some(prefix => id.startsWith(prefix));
}


export function azureDeploymentToModelDescription(deployment: AzureOpenAIDeployment): ModelDescriptionSchema {
  const {
    id: deploymentName, // the model ID to invoke on Azure (set by the user during deployment, 'name')
    model: likelyTheOpenAIModel, // the base model that should map to OpenAI
    created_at: modelCreated,
    updated_at: modelUpdated = undefined,
  } = deployment;

  // MAPPING of Deployment -> ModelDescription
  const allModels = [..._knownAzureChatModels, ..._knownOpenAIChatModels];

  /**
   * Fallback: heuristics to map op OpenAI follow:
   *  1. if the name of the model (set by the user) matches exactly a known OpenAI model, use that
   *  2. otherwise match the 'model' field, which SHOULD be the real OpenAI model id
   */
  const isNameAKnownOpenAIModel = !!allModels.find(({ idPrefix: id }) => deploymentName == id);

  const { id: _ignoreThisId, label, hidden: _allVisible, ...restOfModelDescription } = fromManualMapping(
    allModels,
    isNameAKnownOpenAIModel ? deploymentName : likelyTheOpenAIModel,
    modelCreated,
    modelUpdated,
    undefined,
    true,
  );

  // if the user has set a custom name, show it in the label in addition to the generic OpenAI model name
  const preciseLabel = (deploymentName !== likelyTheOpenAIModel) ?
    `${label} (${deploymentName})` : label;

  return {
    id: deploymentName,
    label: preciseLabel,
    ...restOfModelDescription,
  };
}



================================================
FILE: src/modules/llms/server/openai/models/chutesai.models.ts
================================================
import * as z from 'zod/v4';

import { DModelInterfaceV1, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';

import { serverCapitalizeFirstLetter } from '~/server/wire';

import type { ModelDescriptionSchema } from '../../llm.server.types';

import { fromManualMapping, ManualMappings } from './models.data';


export function chutesAIHeuristic(hostname: string) {
  return hostname.includes('.chutes.ai');
}


const _wireChutesAIListOutputSchema = z.array(z.object({

  id: z.string(),
  object: z.literal('model'),
  created: z.number(),
  owned_by: z.string().optional().nullable(),
  root: z.string().optional().nullable(),

  // ChutesAI specific field for context length
  max_model_len: z.number().optional().nullable(),

  // Optional fields that may be present
  parent: z.string().nullable().optional(),
  // permission: z.array(z.object({
  //   id: z.string(),
  //   object: z.literal('model_permission'),
  //   created: z.number(),
  //   allow_create_engine: z.boolean(),
  //   allow_sampling: z.boolean(),
  //   allow_logprobs: z.boolean(),
  //   allow_search_indices: z.boolean(),
  //   allow_view: z.boolean(),
  //   allow_fine_tuning: z.boolean(),
  //   organization: z.string(),
  //   group: z.string().nullable(),
  //   is_blocking: z.boolean(),
  // })).optional(),
}));

const _chutesKnownModels: ManualMappings = [
  // NOTE: we don't need manual patching as we have enough info for now
] as const;

const _chutesDenyListContains: string[] = [
  // nothing to deny for now
] as const;


function _prettyModelId(id: string): string {
  // example: "chutesai/Llama-4-Scout-17B-16E-Instruct" => "ChutesAI · Llama 4 Scout 17B 16E Instruct"
  // example: "deepseek-ai/DeepSeek-R1" => "Deepseek AI · DeepSeek R1"
  // example: "unsloth/Llama-3.2-1B-Instruct" => "Unsloth · Llama 3.2 1B Instruct"

  return id
    .replaceAll(/[_-]/g, ' ') // replace underscores or dashes with spaces
    .replace('/', ' · ') // turn the first "/" into " · "
    .split(' ')
    .map(piece => {
      // Handle special cases like version numbers
      if (piece.match(/^\d+(\.\d+)*$/)) return piece; // keep version numbers as-is
      if (piece.toLowerCase() === 'ai') return 'AI';
      if (piece.toLowerCase() === 'v1' || piece.toLowerCase() === 'v2' || piece.toLowerCase() === 'v3') return piece.toUpperCase();
      return serverCapitalizeFirstLetter(piece);
    })
    .join(' ')
    .replace('Deepseek AI · DeepSeek', 'Deepseek AI · ') // special case for Deepseek
    .trim();
}


export function chutesAIModelsToModelDescriptions(wireModels: unknown): ModelDescriptionSchema[] {
  return _wireChutesAIListOutputSchema.parse(wireModels)

    .filter((model) => {
      return !_chutesDenyListContains.some(contains => model.id.includes(contains));
    })

    .map((model): ModelDescriptionSchema => {

      // heuristics
      const label = _prettyModelId(model.id);
      const description = model.owned_by ? `${serverCapitalizeFirstLetter(model.owned_by)} model via ChutesAI.` : 'Model via ChutesAI.';

      // Use max_model_len if available, otherwise fallback to 8192
      const contextWindow = model.max_model_len || 8192;

      const interfaces: DModelInterfaceV1[] = [
        LLM_IF_OAI_Chat, // Assume all are chat models
        LLM_IF_OAI_Vision, // Assume we can send them
        LLM_IF_OAI_Fn, // Most models support function calling
      ];

      // Check for vision capabilities based on model name patterns
      // if (model.id.toLowerCase().includes('vision') || model.id.toLowerCase().includes('vl')) {
      //   interfaces.push(LLM_IF_OAI_Vision);
      // }

      // Most modern models support function calling
      // interfaces.push(LLM_IF_OAI_Fn);

      return fromManualMapping(_chutesKnownModels, model.id, model.created, undefined, {
        idPrefix: model.id,
        label,
        description,
        contextWindow,
        interfaces,
        hidden: false,
      });
    })

    .sort((a: ModelDescriptionSchema, b: ModelDescriptionSchema): number => {
      // Sort by creation date (newer first), then by id
      if (a.created !== b.created)
        return (b.created || 0) - (a.created || 0);
      return a.id.localeCompare(b.id);
    });
}



================================================
FILE: src/modules/llms/server/openai/models/deepseek.models.ts
================================================
import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';

import { fromManualMapping, ManualMappings } from './models.data';


const _knownDeepseekChatModels: ManualMappings = [
  // [Models and Pricing](https://api-docs.deepseek.com/quick_start/pricing)
  // [List Models](https://api-docs.deepseek.com/api/list-models)
  {
    idPrefix: 'deepseek-reasoner',
    label: 'DeepSeek R1 (0528)',
    description: 'Reasoning model with Chain-of-Thought capabilities, 64K context length. Supports JSON output and function calling.',
    contextWindow: 65536,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning],
    maxCompletionTokens: 32768, // default, max: 65536,
    chatPrice: { input: 0.55, output: 2.19, cache: { cType: 'oai-ac', read: 0.14 } },
    benchmark: { cbaElo: 1358 },
  },
  {
    idPrefix: 'deepseek-chat',
    label: 'DeepSeek V3 (0324)',
    description: 'General-purpose model with 64K context length. Supports JSON output and function calling.',
    contextWindow: 65536,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    maxCompletionTokens: 8192, // default is 4096, max is 8192
    chatPrice: { input: 0.27, output: 1.10, cache: { cType: 'oai-ac', read: 0.07 } },
    benchmark: { cbaElo: 1372 }, // note: this is for V3-0324, before V3 was 1318
  },
];

const _unsupportedModelIds = [
  'deepseek-coder',
];

export function deepseekModelFilter(deepseekModelId: string) {
  return !_unsupportedModelIds.includes(deepseekModelId);
}

export function deepseekModelToModelDescription(deepseekModelId: string): ModelDescriptionSchema {
  return fromManualMapping(_knownDeepseekChatModels, deepseekModelId, undefined, undefined, {
    idPrefix: deepseekModelId,
    label: deepseekModelId.replaceAll(/[_-]/g, ' '),
    description: 'New Deepseek Model',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    interfaces: [LLM_IF_OAI_Chat],
    hidden: true,
  });
}

export function deepseekModelSort(a: ModelDescriptionSchema, b: ModelDescriptionSchema) {
  // sort by the order in the known models list
  const aIndex = _knownDeepseekChatModels.findIndex(m => a.id.startsWith(m.idPrefix));
  const bIndex = _knownDeepseekChatModels.findIndex(m => b.id.startsWith(m.idPrefix));
  if (aIndex !== -1 && bIndex !== -1)
    return aIndex - bIndex;
  return a.id.localeCompare(b.id);
}



================================================
FILE: src/modules/llms/server/openai/models/fastapi.models.ts
================================================
import type { OpenAIWire_API_Models_List } from '~/modules/aix/server/dispatch/wiretypes/openai.wiretypes';

import { DModelInterfaceV1, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';
import { fromManualMapping, ManualMappings } from './models.data';


const _fastAPIKnownModels: ManualMappings = [
  // NOTE: we don't need manual patching as we have enough info for now
] as const;

const _fastAPIDenyListContains: string[] = [
  // nothing to deny for now
] as const;


// const fastAPIListOutputSchema = z.object({
//   id: z.string(),
//   object: z.literal('model'),
//   created: z.number(),
//   owned_by: z.string(),
//   root: z.string(),
//   parent: z.unknown(),
//   permission: z.array(ModelPermissionSchema ... ),
// });

/**
 * FastAPI models - minimal heuristics for enumeration using as much data as we can get.
 */
export function fastAPIHeuristic(models: OpenAIWire_API_Models_List.Model[]) {
  if (!models.length) return false;
  return models.some(model => model.owned_by === 'fastchat');
}

/**
 * NOTES:
 * - we assume all models are chat models that support the OpenAI ChatCompletion API
 * - we assume all models can take image inputs and produce function calls
 * - we don't have context window information
 */
export function fastAPIModels(models: OpenAIWire_API_Models_List.Model[]): ModelDescriptionSchema[] {
  return models
    .filter((model) => !_fastAPIDenyListContains.some(contains => model.id.includes(contains)))
    .map((model): ModelDescriptionSchema => {

      // heuristics
      const label = model.id; // assume the model ID is the label - as-is, don't even improve case/hyphens
      const description = 'FastAPI model. No additional information is provided by the API (capabilities, context window size, parameters, etc.).';
      const contextWindow = null; // NOTE: this is the worst part
      const interfaces: DModelInterfaceV1[] = [
        LLM_IF_OAI_Chat,    // assume all models are chat models
        // we can't know these permissions, so we unblock them from preventive warning, but some models won't support these
        LLM_IF_OAI_Vision,  // assume image inputs
        LLM_IF_OAI_Fn,      // assume can output function calls
        // LLM_IF_OAI_Json,    // assume can output json
      ];

      return fromManualMapping(_fastAPIKnownModels, model.id, model.created, undefined, {
        idPrefix: model.id,
        label,
        description,
        contextWindow,
        interfaces,
        // parameterSpecs: ...
        // maxCompletionTokens: ...
        // trainingDataCutoff: ...
        // benchmark: ...
        // chatPrice,
        hidden: false,
      });

    });
}



================================================
FILE: src/modules/llms/server/openai/models/fireworksai.models.ts
================================================
import { DModelInterfaceV1, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';

import { serverCapitalizeFirstLetter } from '~/server/wire';

import type { ModelDescriptionSchema } from '../../llm.server.types';

import { fromManualMapping, ManualMappings } from './models.data';
import { wireFireworksAIListOutputSchema } from '../fireworksai.wiretypes';


export function fireworksAIHeuristic(hostname: string) {
  return hostname.includes('fireworks.ai/');
}


const _fireworksKnownModels: ManualMappings = [
  // NOTE: we don't need manual patching as we have enough info for now
] as const;

const _fireworksDenyListContains: string[] = [
  // nothing to deny for now
] as const;


function _prettyModelId(id: string, isVision: boolean): string {
  // example: "accounts/fireworks/models/llama-v3p1-405b-instruct" => "Fireworks · Llama V3p1 405b Instruct"
  let prettyName = id
    .replace(/^accounts\//, '') // remove the leading "accounts/" if present
    .replace(/\/models\//, ' · ') // turn the next "/models/" into " · "
    .replaceAll(/[_-]/g, ' ') // replace underscores or dashes with spaces
    .split(' ')
    .filter(piece => piece !== 'instruct')
    .map(serverCapitalizeFirstLetter)
    .join(' ')
    .replaceAll('/', ' · ') // replace any additional slash with " · "
    .trim();
  // add "Vision" to the name if it's a vision model
  if (isVision && !id.includes('-vision'))
    prettyName += ' Vision';
  prettyName = prettyName.replace(' Vision', ' (Vision)');
  return prettyName;
}


export function fireworksAIModelsToModelDescriptions(wireModels: unknown): ModelDescriptionSchema[] {
  return wireFireworksAIListOutputSchema
    .parse(wireModels)

    .filter((model) => {
      // filter-out non-llms
      if (model.supports_chat === false)
        return false;

      return !_fireworksDenyListContains.some(contains => model.id.includes(contains));
    })

    .map((model): ModelDescriptionSchema => {

      // heuristics
      const label = _prettyModelId(model.id, !!model.supports_image_input);
      const description = `${model.owned_by} \`${model.kind || 'unknown'}\` type.`;
      const contextWindow = model.context_length || null;
      const interfaces: DModelInterfaceV1[] = [LLM_IF_OAI_Chat];
      if (model.supports_image_input)
        interfaces.push(LLM_IF_OAI_Vision);
      if (model.supports_tools)
        interfaces.push(LLM_IF_OAI_Fn);

      return fromManualMapping(_fireworksKnownModels, model.id, model.created, undefined, {
        idPrefix: model.id,
        label,
        description,
        contextWindow,
        interfaces,
        // parameterSpecs: ...
        // maxCompletionTokens: ...
        // trainingDataCutoff: ...
        // benchmark: ...
        // chatPrice,
        hidden: false,
      });
    })

    .sort((a: ModelDescriptionSchema, b: ModelDescriptionSchema): number => {
      if (a.created !== b.created)
        return (b.created || 0) - (a.created || 0);
      return a.id.localeCompare(b.id);
    });
}



================================================
FILE: src/modules/llms/server/openai/models/groq.models.ts
================================================
import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';
import { fromManualMapping, ManualMappings } from './models.data';
import { wireGroqModelsListOutputSchema } from '../groq.wiretypes';


/**
 * Groq models.
 * - models list: https://console.groq.com/docs/models
 * - pricing: https://groq.com/pricing/
 */
const _knownGroqModels: ManualMappings = [

  // Preview Models
  {
    isPreview: true,
    idPrefix: 'meta-llama/llama-4-maverick-17b-128e-instruct',
    label: 'Llama 4 Maverick · 17B × 128E (Preview)',
    description: 'Llama 4 Maverick 17B with 128 experts, featuring a 131,072 token context window and up to 8,192 completion tokens. Preview model.',
    contextWindow: 131072,
    maxCompletionTokens: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.20, output: 0.60 },
  },
  {
    isPreview: true,
    idPrefix: 'meta-llama/llama-4-scout-17b-16e-instruct',
    label: 'Llama 4 Scout · 17B × 16E (Preview)',
    description: 'Llama 4 Scout 17B with 16 experts, featuring a 131,072 token context window and up to 8,192 completion tokens. Preview model.',
    contextWindow: 131072,
    maxCompletionTokens: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.11, output: 0.34 },
  },
  {
    isPreview: true,
    idPrefix: 'deepseek-r1-distill-llama-70b',
    label: 'DeepSeek R1 Distill Llama 70B (Preview)',
    description: 'DeepSeek R1 Distill Llama 70B with a context window of 128K tokens. Preview model.',
    contextWindow: 131072,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.75, output: 0.99 },
  },
  {
    isPreview: true,
    idPrefix: 'qwen-qwq-32b',
    label: 'Qwen QwQ 32B (Preview)',
    description: 'Qwen QwQ 32B developed by Alibaba Cloud with a context window of 128K tokens. Preview model.',
    contextWindow: 131072,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.29, output: 0.39 },
  },
  {
    isPreview: true,
    idPrefix: 'mistral-saba-24b',
    label: 'Mistral Saba 24B (Preview)',
    description: 'Mistral Saba 24B with a context window of 32K tokens. Preview model.',
    contextWindow: 32768,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.79, output: 0.79 },
  },
  {
    isPreview: true,
    idPrefix: 'allam-2-7b',
    label: 'ALLaM 2 7B (Preview)',
    description: 'ALLaM 2 7B developed by Saudi Data and AI Authority (SDAIA) with a context window of 4,096 tokens. Preview model.',
    contextWindow: 4096,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    hidden: true, // Pricing unknown
  },
  {
    isPreview: true,
    idPrefix: 'compound-beta',
    label: 'Compound Beta (Preview System)',
    description: 'Groq\'s agentic system with web search and code execution capabilities. Preview system with a context window of 128K tokens, up to 8,192 completion tokens.',
    contextWindow: 8192,
    // maxCompletionTokens: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    hidden: true, // Pricing unknown
  },
  {
    isPreview: true,
    idPrefix: 'compound-beta-mini',
    label: 'Compound Beta Mini (Preview System)',
    description: 'Lighter version of Groq\'s agentic system with web search and code execution capabilities. Preview system with a context window of 128K tokens, up to 8,192 completion tokens.',
    contextWindow: 8192,
    // maxCompletionTokens: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    hidden: true, // Pricing unknown
  },


  // Production Models
  {
    idPrefix: 'gemma2-9b-it',
    label: 'Gemma 2 · 9B Instruct',
    description: 'Gemma 2 9B developed by Google with a context window of 8,192 tokens. Production model.',
    contextWindow: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.20, output: 0.20 },
  },
  {
    idPrefix: 'llama-3.3-70b-versatile',
    label: 'Llama 3.3 · 70B Versatile',
    description: 'LLaMA 3.3 70B developed by Meta with a context window of 128K tokens, up to 32,768 completion tokens. Production model.',
    contextWindow: 131072,
    maxCompletionTokens: 32768,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.59, output: 0.79 },
  },
  {
    idPrefix: 'llama-3.1-8b-instant',
    label: 'Llama 3.1 · 8B Instant',
    description: 'LLaMA 3.1 8B developed by Meta with a context window of 128K tokens, up to 8,192 completion tokens. Production model.',
    contextWindow: 131072,
    maxCompletionTokens: 131072,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.05, output: 0.08 },
  },
  {
    idPrefix: 'llama-guard-3-8b',
    label: 'Llama Guard 3 · 8B',
    description: 'LLaMA Guard 3 8B developed by Meta with a context window of 8,192 tokens. Production model.',
    contextWindow: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.20, output: 0.20 },
  },
  {
    idPrefix: 'llama3-70b-8192',
    label: 'Llama 3 · 70B',
    description: 'LLaMA 3 70B developed by Meta with a context window of 8,192 tokens. Production model.',
    contextWindow: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.59, output: 0.79 },
  },
  {
    idPrefix: 'llama3-8b-8192',
    label: 'Llama 3 · 8B',
    description: 'LLaMA 3 8B developed by Meta with a context window of 8,192 tokens. Production model.',
    contextWindow: 8192,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.05, output: 0.08 },
  },

];


const groqDenyList: string[] = [
  'whisper-',
  'playai-tts',
  'distil-whisper',
];

export function groqModelFilter(model: { id: string }): boolean {
  return !groqDenyList.some(prefix => model.id.includes(prefix));
}

export function groqModelToModelDescription(_model: unknown): ModelDescriptionSchema {
  const model = wireGroqModelsListOutputSchema.parse(_model);

  // warn if the context window parsed is different than the mapped
  const knownModel = _knownGroqModels.find(base => model.id.startsWith(base.idPrefix));
  if (!knownModel)
    console.log(`groq.models: unknown model ${model.id}`, model);
  if (knownModel && model.context_window !== knownModel.contextWindow)
    console.warn(`groq.models: context window mismatch for ${model.id}: expected ${model.context_window} !== ${knownModel.contextWindow}`);
  if (knownModel?.maxCompletionTokens && model.max_completion_tokens !== knownModel.maxCompletionTokens)
    console.warn(`groq.models: max completion tokens mismatch for ${model.id}: expected ${model.max_completion_tokens} !== ${knownModel.maxCompletionTokens}`);

  const description = fromManualMapping(_knownGroqModels, model.id, model.created, undefined, {
    idPrefix: model.id,
    label: model.id.replaceAll(/[_-]/g, ' '),
    description: 'New Model',
    contextWindow: model.context_window || 32768,
    interfaces: [LLM_IF_OAI_Chat],
    hidden: true,
  });

  // prepend [model.owned_by] to the label
  if (model?.owned_by?.length)
    description.label = `[${model.owned_by}] ${description.label}`;

  return description;
}

export function groqModelSortFn(a: ModelDescriptionSchema, b: ModelDescriptionSchema): number {
  // sort hidden at the end
  if (a.hidden && !b.hidden)
    return 1;
  if (!a.hidden && b.hidden)
    return -1;

  // sort as per their order in the known models
  const aIndex = _knownGroqModels.findIndex(base => a.id.startsWith(base.idPrefix));
  const bIndex = _knownGroqModels.findIndex(base => b.id.startsWith(base.idPrefix));
  if (aIndex !== -1 && bIndex !== -1)
    return aIndex - bIndex;

  return a.id.localeCompare(b.id);
}


================================================
FILE: src/modules/llms/server/openai/models/mistral.models.ts
================================================
import * as z from 'zod/v4';

import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { Release } from '~/common/app.release';

import type { ModelDescriptionSchema } from '../../llm.server.types';


// configuration
const MISTRAL_DEV_SHOW_GAPS = Release.IsNodeDevBuild;


// [Mistral]
// Updated 2025-06-25
// - models on: https://docs.mistral.ai/getting-started/models/models_overview/
// - pricing on: https://mistral.ai/pricing#api-pricing
// - benchmark elo on CBA

const _knownMistralModelDetails: Record<string, {
  chatPrice?: { input: number; output: number };
  benchmark?: { cbaElo: number };
}> = {

  // Premier models
  'mistral-medium-2505': { chatPrice: { input: 0.4, output: 2 }, benchmark: { cbaElo: 1369 } },
  'mistral-medium-latest': { chatPrice: { input: 0.4, output: 2 }, benchmark: { cbaElo: 1369 } },
  'mistral-medium': { chatPrice: { input: 0.4, output: 2 }, benchmark: { cbaElo: 1165 } },

  'magistral-medium-2506': { chatPrice: { input: 2, output: 5 } },
  'magistral-medium-latest': { chatPrice: { input: 2, output: 5 } },

  'mistral-large-2411': { chatPrice: { input: 2, output: 6 }, benchmark: { cbaElo: 1266 } },
  'mistral-large-2407': { chatPrice: { input: 2, output: 6 }, benchmark: { cbaElo: 1269 } },
  'mistral-large-latest': { chatPrice: { input: 2, output: 6 }, benchmark: { cbaElo: 1266 } },

  'pixtral-large-2411': { chatPrice: { input: 2, output: 6 } },
  'pixtral-large-latest': { chatPrice: { input: 2, output: 6 } },

  'mistral-saba-2502': { chatPrice: { input: 0.2, output: 0.6 } },
  'mistral-saba-latest': { chatPrice: { input: 0.2, output: 0.6 } },

  'codestral-2501': { chatPrice: { input: 0.3, output: 0.9 } },
  'codestral-latest': { chatPrice: { input: 0.3, output: 0.9 } },

  'ministral-8b-2410': { chatPrice: { input: 0.1, output: 0.1 }, benchmark: { cbaElo: 1200 } },
  'ministral-8b-latest': { chatPrice: { input: 0.1, output: 0.1 }, benchmark: { cbaElo: 1200 } },

  'ministral-3b-2410': { chatPrice: { input: 0.04, output: 0.04 } },
  'ministral-3b-latest': { chatPrice: { input: 0.04, output: 0.04 } },

  // Open models
  'mistral-small-2506': { chatPrice: { input: 0.1, output: 0.3 } },
  'mistral-small-2503': { chatPrice: { input: 0.1, output: 0.3 }, benchmark: { cbaElo: 1271 } },
  'mistral-small-2501': { chatPrice: { input: 0.1, output: 0.3 }, benchmark: { cbaElo: 1235 } },
  'mistral-small-2409': { chatPrice: { input: 0.1, output: 0.3 } },
  'mistral-small-latest': { chatPrice: { input: 0.1, output: 0.3 } },
  'mistral-small': { chatPrice: { input: 0.1, output: 0.3 } },

  'magistral-small-2506': { chatPrice: { input: 0.5, output: 1.5 } },
  'magistral-small-latest': { chatPrice: { input: 0.5, output: 1.5 } },

  'devstral-small-2505': { chatPrice: { input: 0.1, output: 0.3 } },
  'devstral-small-latest': { chatPrice: { input: 0.1, output: 0.3 } },

  'pixtral-12b-2409': { chatPrice: { input: 0.15, output: 0.15 } },
  'pixtral-12b-latest': { chatPrice: { input: 0.15, output: 0.15 } },
  'pixtral-12b': { chatPrice: { input: 0.15, output: 0.15 } },

  'open-mistral-nemo-2407': { chatPrice: { input: 0.15, output: 0.15 } },
  'open-mistral-nemo': { chatPrice: { input: 0.15, output: 0.15 } },

  // Legacy models
  'open-mixtral-8x22b-2404': { chatPrice: { input: 2, output: 6 }, benchmark: { cbaElo: 1165 } },
  'open-mixtral-8x22b': { chatPrice: { input: 2, output: 6 }, benchmark: { cbaElo: 1165 } },
  'open-mixtral-8x7b': { chatPrice: { input: 0.7, output: 0.7 }, benchmark: { cbaElo: 1131 } },
  'open-mistral-7b': { chatPrice: { input: 0.25, output: 0.25 } },
};


const mistralModelFamilyOrder = [
  // Premier
  'magistral-medium',
  'mistral-medium',
  'mistral-large',
  'pixtral-large',
  'codestral',
  'magistral-small',
  'mistral-small',
  'devstral-small',
  'mistral-saba',
  'mistral-embed',
  'mistral-ocr',
  'ministral-8b',
  'ministral-3b',
  'codestral-embed',
  'mistral-moderation',
  // Open
  'open-codestral-mamba',
  'pixtral-12b',
  'open-mistral-nemo',
  // Legacy
  'open-mixtral-8x22b',
  'open-mixtral-8x7b',
  'mistral-small-2312', // note: this is set here explicitly, because otherwise it would show up earlier in the list due to its real name being the open mixtral 8x7b
  'open-mistral-7b',
  // Deprecated
  'mistral-tiny',
  // Symlinks at the bottom
  '🔗',
];


function _mistralModelsSort(a: ModelDescriptionSchema, b: ModelDescriptionSchema): number {
  if (a.label.startsWith('🔗') && !b.label.startsWith('🔗')) return 1;
  if (!a.label.startsWith('🔗') && b.label.startsWith('🔗')) return -1;
  let aIndex = mistralModelFamilyOrder.findIndex(id => a.id === id);
  if (aIndex === -1)
    aIndex = mistralModelFamilyOrder.findIndex(prefix => a.id.startsWith(prefix));
  let bIndex = mistralModelFamilyOrder.findIndex(id => b.id === id);
  if (bIndex === -1)
    bIndex = mistralModelFamilyOrder.findIndex(prefix => b.id.startsWith(prefix));
  if (aIndex !== -1 && bIndex !== -1) {
    if (aIndex !== bIndex)
      return aIndex - bIndex;
    return b.label.localeCompare(a.label);
  }
  return aIndex !== -1 ? 1 : -1;
}


function _prettyMistralName(name: string): string {
  return name
    // .replace(/^(mistral|codestral|pixtral|magistral|ministral|devstral)-/, '')
    .replace(/-(2\d{3})$/, ' ($1)')
    .replace(/-(latest|embed)$/, ' ($1)')
    .replaceAll(/[_-]/g, ' ')
    .split(' ')
    .map(word => word.charAt(0).toUpperCase() + word.slice(1))
    .join(' ');
}

function _mistralCapabilitiesToInterfaces(capabilities: WireMistralModel['capabilities'], modelId: string) {
  // everyone gets Chat
  const interfaces = [LLM_IF_OAI_Chat];
  if (!capabilities || capabilities.function_calling)
    interfaces.push(LLM_IF_OAI_Fn);
  if (!capabilities || capabilities.vision)
    interfaces.push(LLM_IF_OAI_Vision);
  // Add reasoning interface for magistral models
  if (modelId.includes('magistral'))
    interfaces.push(LLM_IF_OAI_Reasoning);
  return interfaces;
}


export function mistralModels(wireModels: unknown): ModelDescriptionSchema[] {

  // 1. Parse and filter the API response
  const mistralModels = wireMistralModelsListSchema.parse(wireModels)
    .filter(m => !m.capabilities || m.capabilities.completion_chat); // removes: *-embed, *-moderation, *-ocr


  // 2. Auto-hide models based on alias groups
  const aliasGroups = mistralModels.reduce((accGroups: Set<string>[], model) => {
    const modelIds = new Set([model.id, ...(model.aliases || [])]);

    // partition existing groups into those connected to the current model
    const connected = accGroups.filter(g => [...g].some(id => modelIds.has(id)));
    const unconnected = accGroups.filter(g => !connected.includes(g));

    // merge all connected groups with the current model's IDs into a single new group
    const mergedGroup = connected.reduce((merged, group) => {
      group.forEach(id => merged.add(id));
      return merged;
    }, modelIds);

    return [...unconnected, mergedGroup];
  }, []);

  // 2B. remove the latest entries from the groups
  const notSymlinks = aliasGroups.map(group => {
    const sortedIds = Array.from(group).sort();

    const yymmModels = sortedIds.filter(id => /-\d{4}$/.test(id));

    // pick the newest YYMM model if exists, otherwise pick the 2nd element otherwise the 1st
    return !yymmModels.length ? sortedIds[sortedIds.length > 1 ? 1 : 0]
      : yymmModels.sort((a, b) => parseInt(b.slice(-4), 10) - parseInt(a.slice(-4), 10))[0];
  }).filter(Boolean);


  // 3. Map the API models to our ModelDescriptionSchema
  const models = mistralModels.map((mistralModel): ModelDescriptionSchema => {
    const { id, created, capabilities, name, description, max_context_length } = mistralModel;

    const isSymlink = !notSymlinks.includes(id);
    const prettyName = _prettyMistralName(name);

    const extraDetails = _knownMistralModelDetails[id] || {};

    return {
      id: id,
      label: !isSymlink ? prettyName : `🔗 ${id} → ${prettyName}`,
      created: created || 0,
      updated: /*updated ||*/ created || 0,
      description: description,
      contextWindow: max_context_length ?? 32768,
      interfaces: _mistralCapabilitiesToInterfaces(capabilities, id),
      // parameterSpecs: ...
      // maxCompletionTokens: ...
      // trainingDataCutoff: ...
      // benchmark, chatPrice: provided by extraDetails below:
      ...extraDetails,
      hidden: !notSymlinks.includes(id),
    };
  });

  // 4. Sort
  models.sort(_mistralModelsSort);

  // 5. Hide - pass 2 - hide earlier models versions
  for (let i = 1; i < models.length; i++) {
    const currentModel = models[i];
    const prevModel = models[i - 1];
    // if (prevModel.hidden) continue;

    if (currentModel.id.length > 4 && prevModel.id.length > 4 &&
      currentModel.id.slice(0, -4) === prevModel.id.slice(0, -4)) {
      currentModel.hidden = true;
    }
  }

  // 6. [DEV] find items in _knownMistralModelDetails that are not in the models list
  if (MISTRAL_DEV_SHOW_GAPS) {

    // show missing pricing
    const knownModelIds = Object.keys(_knownMistralModelDetails);
    const missingPricing = knownModelIds.filter(id => !_knownMistralModelDetails[id].chatPrice);
    if (missingPricing.length > 0)
      console.warn('[DEV] Mistral models missing pricing:', missingPricing);

    // show extra pricing
    const missingModels = knownModelIds.filter(id => !models.some(m => m.id === id));
    if (missingModels.length > 0)
      console.log('[DEV] Mistral models not in the list:', missingModels);
  }

  return models;
}


/// Mistral Wire Parsers

type WireMistralModel = z.infer<typeof wireMistralModelSchema>;
const wireMistralModelSchema = z.object({

  id: z.string(),
  object: z.literal('model'),

  created: z.number(),  // it's the same number for all models...
  owned_by: z.string(), // not useful, always 'mistralai'
  type: z.string(), // 'base'

  capabilities: z.object({
    completion_chat: z.boolean(), // used to remove other models
    completion_fim: z.boolean().nullish(),
    function_calling: z.boolean().nullish(),
    fine_tuning: z.boolean().nullish(),
    vision: z.boolean().nullish(),
    classification: z.boolean().nullish(),
  }).nullish(),

  // UI description fields
  name: z.string(),
  description: z.string(),
  aliases: z.array(z.string()),

  // very useful
  max_context_length: z.number(),

  // misc, not used
  default_model_temperature: z.number().nullish(),
  // deprecation: z.any(),
  // deprecation_replacement_model: z.string().nullable(),
});

const wireMistralModelsListSchema = z.array(wireMistralModelSchema);



================================================
FILE: src/modules/llms/server/openai/models/models.data.ts
================================================
import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { capitalizeFirstLetter } from '~/common/util/textUtils';

import type { ModelDescriptionSchema } from '../../llm.server.types';


// [LM Studio]
export function lmStudioModelToModelDescription(modelId: string): ModelDescriptionSchema {

  // LM Studio model ID's are the file names of the model files
  function getFileName(filePath: string): string {
    const normalizedPath = filePath.replace(/\\/g, '/');
    return normalizedPath.split('/').pop() || '';
  }

  return fromManualMapping([], modelId, undefined, undefined, {
    idPrefix: modelId,
    label: getFileName(modelId)
      .replace('.gguf', '')
      .replace('.bin', ''),
    // .replaceAll('-', ' '),
    description: `Unknown LM Studio model. File: ${modelId}`,
    contextWindow: null, // 'not provided'
    interfaces: [LLM_IF_OAI_Chat], // assume..
    chatPrice: { input: 'free', output: 'free' },
  });
}


// [LocalAI]
const _knownLocalAIChatModels: ManualMappings = [];
const _knownLocalAIPrice = { input: 'free', output: 'free' } as const;
const _hideLocalAIModels = [
  'jina-reranker-v1-base-en', // vector search
  'stablediffusion', // text-to-image
  'text-embedding-ada-002', // embedding generator
  'tts-1', // text-to-speech
  'whisper-1', // speech-to-text
];

export function localAIModelSortFn(a: ModelDescriptionSchema, b: ModelDescriptionSchema): number {
  // hidden to the bottom
  if (a.hidden && !b.hidden) return 1;
  if (!a.hidden && b.hidden) return -1;

  // keep the order from the API
  return 0;
}


export function localAIModelToModelDescription(modelId: string): ModelDescriptionSchema {

  // heurisics to extract a label from the model ID
  const label = modelId
    .replace('.gguf', '')
    .replace('ggml-', '')
    .replace('.bin', '')
    .replaceAll('-', ' ')
    .replace(' Q4_K_M', ' (Q4_K_M)')
    .replace(' F16', ' (F16)')
    .split(' ')
    .map(capitalizeFirstLetter)
    .join(' ');

  const description = `LocalAI model. File: ${modelId}`;

  // very dull heuristics
  const interfaces = [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn];
  if (modelId.includes('vision') || modelId.includes('llava'))
    interfaces.push(LLM_IF_OAI_Vision);
  if (modelId.includes('r1'))
    interfaces.push(LLM_IF_OAI_Reasoning);

  return fromManualMapping(_knownLocalAIChatModels, modelId, undefined, undefined, {
    idPrefix: modelId,
    label,
    description,
    contextWindow: null, // 'not provided'
    interfaces,
    // parameterSpecs
    // maxCompletionTokens
    // trainingDataCutoff
    // benchmark
    chatPrice: _knownLocalAIPrice,
    hidden: _hideLocalAIModels.includes(modelId),
  });
}

// Helpers

export type ManualMapping = ({
  idPrefix: string,
  isLatest?: boolean,
  isPreview?: boolean,
  isLegacy?: boolean,
  symLink?: string
} & Omit<ModelDescriptionSchema, 'id' | 'created' | 'updated'>);

export type ManualMappings = ManualMapping[];

export function fromManualMapping(mappings: ManualMappings, id: string, created?: number, updated?: number, fallback?: ManualMapping, disableSymLink?: boolean): ModelDescriptionSchema {

  // find the closest known model, or fall back, or take the last
  const known = mappings.find(base => id === base.idPrefix)
    || mappings.find(base => id.startsWith(base.idPrefix))
    || fallback
    || mappings[mappings.length - 1];

  // label for symlinks
  let label = known.label;
  if (!disableSymLink && known.symLink && id === known.idPrefix)
    label = `🔗 ${known.label} → ${known.symLink/*.replace(known.idPrefix, '')*/}`;

  // check whether this is a partial map, which indicates an unknown/new variant
  const suffix = id.slice(known.idPrefix.length).trim();

  // full label
  label = label
    + (suffix ? ` [${suffix.replaceAll('-', ' ').trim()}]` : '')
    // + (known.isLatest ? ' 🌟' : '') // DISABLED: annoying emoji
    + (known.isLegacy ? /*' 💩'*/ ' [legacy]' : '');

  // set the date in YYYY-MM-DD format if available and requested
  // if (label.indexOf('{{Created}}') !== -1) {
  //   const targetDate = updated || created;
  //   if (targetDate)
  //     label = label.replace('{{Created}}', `(${new Date(targetDate * 1000).toISOString().slice(0, 10)})`);
  //   else
  //     label = label.replace('{{Created}}', '');
  // }

  // create the model description
  const md: ModelDescriptionSchema = {
    id,
    label,
    created: created || 0,
    updated: updated || created || 0,
    description: known.description,
    contextWindow: known.contextWindow,
    interfaces: known.interfaces,
  };

  // apply optional fields
  if (known.maxCompletionTokens)
    md.maxCompletionTokens = known.maxCompletionTokens;
  if (known.trainingDataCutoff)
    md.trainingDataCutoff = known.trainingDataCutoff;
  if (known.parameterSpecs)
    md.parameterSpecs = known.parameterSpecs;
  if (known.benchmark)
    md.benchmark = known.benchmark;
  if (known.chatPrice)
    md.chatPrice = known.chatPrice;
  if (known.hidden)
    md.hidden = true;

  return md;
}


================================================
FILE: src/modules/llms/server/openai/models/openai.models.ts
================================================
import type { OpenAIWire_API_Models_List } from '~/modules/aix/server/dispatch/wiretypes/openai.wiretypes';

import { LLM_IF_HOTFIX_NoTemperature, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_NeedsAudio, LLM_IF_OAI_PromptCaching, LLM_IF_OAI_Realtime, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Responses, LLM_IF_OAI_Vision, LLM_IF_Tools_WebSearch } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';
import { fromManualMapping, ManualMappings } from './models.data';


// [OpenAI] Known Chat Models
// https://platform.openai.com/docs/models
// https://platform.openai.com/docs/pricing
// NOTES:
// - "Structured Outputs" is LLM_IF_OAI_Json
export const _knownOpenAIChatModels: ManualMappings = [

  /// [OpenAI, 2025-03-11] NEW `v1/responses` API MODELS - UNSUPPORTED YET

  // Computer Use Preview - INTERNAL MODEL FOR AGENTS - UNSUPPORTED YET
  {
    hidden: true, // UNSUPPORTED YET
    // isLatest: true, // preview doesn't get highlighted
    idPrefix: 'computer-use-preview-2025-03-11',
    label: 'Computer Use Preview (2025-03-11)',
    description: 'Specialized model for computer use tool. Optimized for computer interaction capabilities.',
    contextWindow: 8192,
    maxCompletionTokens: 1024,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_HOTFIX_NoTemperature, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 3, output: 12 },
    isPreview: true,
  },
  {
    idPrefix: 'computer-use-preview',
    label: 'Computer Use Preview',
    description: 'Preview release for computer interaction capabilities. Points to computer-use-preview-2025-03-11.',
    symLink: 'computer-use-preview-2025-03-11',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 8192,
    maxCompletionTokens: 1024,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_HOTFIX_NoTemperature, LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 3, output: 12 },
    isPreview: true,
  },
  {
    hidden: true, // RESPONSES API UNSUPPORTED YET
    idPrefix: 'codex-mini-latest',
    label: 'Codex Mini Latest',
    description: 'Fast reasoning model optimized for the Codex CLI. A fine-tuned version of o4-mini.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_HOTFIX_NoTemperature, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 1.5, cache: { cType: 'oai-ac', read: 0.375 }, output: 6 },
  },


  /// Reasoning models - o-series

  // o4-mini-deep-research - (v1/responses API)
  {
    idPrefix: 'o4-mini-deep-research-2025-06-26',
    label: 'o4 Mini Deep Research (2025-06-26)',
    description: 'Faster, more affordable deep research model for complex, multi-step research tasks.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    // parameterSpecs: deep research models do not support search context, nor location, nor reasoning effort
    chatPrice: { input: 2, cache: { cType: 'oai-ac', read: 0.5 }, output: 8 },
  },
  {
    idPrefix: 'o4-mini-deep-research',
    label: 'o4 Mini Deep Research',
    description: 'Faster, more affordable deep research model. Points to o4-mini-deep-research-2025-06-26.',
    symLink: 'o4-mini-deep-research-2025-06-26',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    // parameterSpecs: deep research models do not support search context, nor location, nor reasoning effort
    chatPrice: { input: 2, cache: { cType: 'oai-ac', read: 0.5 }, output: 8 },
  },

  /// o4-mini
  {
    isLatest: true,
    idPrefix: 'o4-mini-2025-04-16',
    label: 'o4 Mini (2025-04-16)',
    description: 'Latest o4-mini model. Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 1.1, cache: { cType: 'oai-ac', read: 0.275 }, output: 4.4 },
    // benchmark: { cbaElo: 1351 /* unknown variant */ },
  },
  {
    idPrefix: 'o4-mini',
    label: 'o4 Mini',
    description: 'Faster, more affordable reasoning model. Points to o4-mini-2025-04-16.',
    symLink: 'o4-mini-2025-04-16',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 1.1, cache: { cType: 'oai-ac', read: 0.275 }, output: 4.4 },
    // benchmarks not available yet, as of 2025-04-16 (intro)
  },

  // o3-deep-research - (v1/responses API)
  {
    idPrefix: 'o3-deep-research-2025-06-26',
    label: 'o3 Deep Research (2025-06-26)',
    description: 'Our most powerful deep research model for complex, multi-step research tasks.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    // parameterSpecs: deep research models do not support search context, nor location, nor reasoning effort
    chatPrice: { input: 10, cache: { cType: 'oai-ac', read: 2.5 }, output: 40 },
  },
  {
    idPrefix: 'o3-deep-research',
    label: 'o3 Deep Research',
    description: 'Our most powerful deep research model. Points to o3-deep-research-2025-06-26.',
    symLink: 'o3-deep-research-2025-06-26',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    // parameterSpecs: deep research models do not support search context, nor location, nor reasoning effort
    chatPrice: { input: 10, cache: { cType: 'oai-ac', read: 2.5 }, output: 40 },
  },

  // o3-pro - (v1/responses API)
  {
    idPrefix: 'o3-pro-2025-06-10',
    label: 'o3 Pro (2025-06-10)',
    description: 'Version of o3 with more compute for better responses. Provides consistently better answers for complex tasks.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_HOTFIX_NoTemperature],
    parameterSpecs: [{ paramId: 'llmForceNoStream' }, { paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 20, output: 80 },
    // benchmark: has not been measured yet
  },
  {
    idPrefix: 'o3-pro',
    label: 'o3 Pro',
    description: 'Version of o3 with more compute for better responses. Points to o3-pro-2025-06-10.',
    symLink: 'o3-pro-2025-06-10',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_HOTFIX_NoTemperature],
    parameterSpecs: [{ paramId: 'llmForceNoStream' }, { paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 20, output: 80 },
    // benchmark: has not been measured yet
  },

  /// o3
  {
    isLatest: true,
    idPrefix: 'o3-2025-04-16',
    label: 'o3 (2025-04-16)',
    description: 'A well-rounded and powerful model across domains. Sets a new standard for math, science, coding, and visual reasoning tasks.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmForceNoStream' }, { paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 2, cache: { cType: 'oai-ac', read: 0.5 }, output: 8 },
    // benchmark: { cbaElo: 1413 /* unknown variant, as of 2025-05-12 */ },
  },
  {
    idPrefix: 'o3',
    label: 'o3',
    description: 'Our most powerful reasoning model. Points to o3-2025-04-16.',
    symLink: 'o3-2025-04-16',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmForceNoStream' }, { paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 2, cache: { cType: 'oai-ac', read: 0.5 }, output: 8 },
    // benchmarks not available yet, as of 2025-04-16 (intro)
  },

  // o3-mini
  {
    idPrefix: 'o3-mini-2025-01-31',
    label: 'o3 Mini (2025-01-31)',
    description: 'Latest o3-mini model snapshot. High intelligence at the same cost and latency targets of o1-mini. Excels at science, math, and coding tasks.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching, LLM_IF_HOTFIX_StripImages],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 1.1, cache: { cType: 'oai-ac', read: 0.55 }, output: 4.4 },
    benchmark: { cbaElo: 1305 /* the -high variant has 1325 */ },
  },
  {
    idPrefix: 'o3-mini',
    label: 'o3 Mini',
    description: 'A small model alternative to o3. Points to the most recent o3-mini snapshot: o3-mini-2025-01-31',
    symLink: 'o3-mini-2025-01-31',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching, LLM_IF_HOTFIX_StripImages],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 1.1, cache: { cType: 'oai-ac', read: 0.55 }, output: 4.4 },
    benchmark: { cbaElo: 1305 },
  },

  // o1-pro - (v1/responses API) 💎💰
  {
    hidden: true,
    idPrefix: 'o1-pro-2025-03-19',
    label: 'o1 Pro (2025-03-19)',
    description: 'A version of o1 with more compute for better responses. Provides consistently better answers for complex tasks.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_HOTFIX_NoTemperature],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 150, output: 600 },
    // benchmark: has not been measured yet by third parties
  },
  {
    idPrefix: 'o1-pro',
    label: 'o1 Pro',
    description: 'Version of o1 with more compute for better responses. Points to o1-pro-2025-03-19.',
    symLink: 'o1-pro-2025-03-19',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Responses, LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_HOTFIX_NoTemperature],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }],
    chatPrice: { input: 150, output: 600 },
    // benchmark: has not been measured yet by third parties
  },

  // o1
  {
    idPrefix: 'o1-2024-12-17',
    label: 'o1 (2024-12-17)',
    description: 'Previous full o-series reasoning model.',
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Vision, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }, { paramId: 'llmVndOaiRestoreMarkdown' }],
    chatPrice: { input: 15, cache: { cType: 'oai-ac', read: 7.5 }, output: 60 },
    benchmark: { cbaElo: 1350 },
  },
  {
    idPrefix: 'o1',
    label: 'o1',
    description: 'Previous full o-series reasoning model. Points to the most recent snapshot: o1-2024-12-17',
    symLink: 'o1-2024-12-17',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 200000,
    maxCompletionTokens: 100000,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Vision, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching],
    parameterSpecs: [{ paramId: 'llmVndOaiReasoningEffort' }, { paramId: 'llmVndOaiRestoreMarkdown' }],
    chatPrice: { input: 15, cache: { cType: 'oai-ac', read: 7.5 }, output: 60 },
    benchmark: { cbaElo: 1350 },
  },

  // o1-preview (deprecated)
  {
    hidden: true, // OUTDATED
    idPrefix: 'o1-preview-2024-09-12',
    label: 'o1 Preview (2024-09-12)', // ⏱️
    description: 'Latest o1 preview model snapshot. This model takes longer to run and does not support streaming. New reasoning model for complex tasks that require broad general knowledge.',
    contextWindow: 128000,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: { input: 15, cache: { cType: 'oai-ac', read: 7.5 }, output: 60 },
    benchmark: { cbaElo: 1335 },
    isPreview: true,
    isLegacy: true,
  },
  {
    idPrefix: 'o1-preview',
    label: 'o1 Preview',
    description: 'Points to the most recent snapshot of the o1 preview model: o1-preview-2024-09-12',
    symLink: 'o1-preview-2024-09-12',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: { input: 15, cache: { cType: 'oai-ac', read: 7.5 }, output: 60 },
    benchmark: { cbaElo: 1335 },
    isPreview: true,
    isLegacy: true,
  },

  // o1-mini (deprecated)
  {
    hidden: true, // DEPRECATED
    idPrefix: 'o1-mini-2024-09-12',
    label: 'o1 Mini (2024-09-12)', // ⏱️
    description: 'Deprecated. Fast, cost-efficient reasoning model tailored to coding, math, and science use cases.',
    contextWindow: 128000,
    maxCompletionTokens: 65536,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: { input: 1.1, cache: { cType: 'oai-ac', read: 0.55 }, output: 4.4 },
    benchmark: { cbaElo: 1304 },
    isLegacy: true,
  },
  {
    idPrefix: 'o1-mini',
    label: 'o1 Mini',
    description: 'Deprecated. A small model alternative to o1. Points to the most recent o1-mini snapshot: o1-mini-2024-09-12',
    symLink: 'o1-mini-2024-09-12',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 65536,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_OAI_PromptCaching, LLM_IF_HOTFIX_StripImages, LLM_IF_HOTFIX_Sys0ToUsr0],
    chatPrice: { input: 1.1, cache: { cType: 'oai-ac', read: 0.55 }, output: 4.4 },
    benchmark: { cbaElo: 1304 },
    isLegacy: true,
  },

  /// GPT-4.1 series

  // GPT-4.1
  {
    isLatest: true,
    idPrefix: 'gpt-4.1-2025-04-14',
    label: 'GPT-4.1 (2025-04-14)',
    description: 'Flagship GPT model for complex tasks. Major improvements on coding, instruction following, and long context with 1M token context window.',
    contextWindow: 1047576,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 2, cache: { cType: 'oai-ac', read: 0.5 }, output: 8 },
    benchmark: { cbaElo: 1366 },
  },
  {
    idPrefix: 'gpt-4.1',
    label: 'GPT-4.1',
    description: 'Flagship GPT model for complex tasks. Currently points to gpt-4.1-2025-04-14.',
    symLink: 'gpt-4.1-2025-04-14',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 1047576,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 2, cache: { cType: 'oai-ac', read: 0.5 }, output: 8 },
    // benchmarks: will be available soon, hopefully
  },

  // GPT-4.1 mini
  {
    isLatest: true,
    idPrefix: 'gpt-4.1-mini-2025-04-14',
    label: 'GPT-4.1 Mini (2025-04-14)',
    description: 'Balanced for intelligence, speed, and cost. Matches or exceeds GPT-4o in intelligence while reducing latency by nearly half and cost by 83%.',
    contextWindow: 1047576,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 0.4, cache: { cType: 'oai-ac', read: 0.1 }, output: 1.6 },
    benchmark: { cbaElo: 1322 },
  },
  {
    idPrefix: 'gpt-4.1-mini',
    label: 'GPT-4.1 Mini',
    description: 'Balanced for intelligence, speed, and cost. Currently points to gpt-4.1-mini-2025-04-14.',
    symLink: 'gpt-4.1-mini-2025-04-14',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 1047576,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 0.4, cache: { cType: 'oai-ac', read: 0.1 }, output: 1.6 },
    // benchmarks: will be available soon, hopefully
  },

  // GPT-4.1 nano
  {
    isLatest: true,
    idPrefix: 'gpt-4.1-nano-2025-04-14',
    label: 'GPT-4.1 Nano (2025-04-14)',
    description: 'Fastest, most cost-effective GPT 4.1 model. Delivers exceptional performance with low latency, ideal for tasks like classification or autocompletion.',
    contextWindow: 1047576,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 0.1, cache: { cType: 'oai-ac', read: 0.025 }, output: 0.4 },
    // benchmarks: will be available soon, hopefully
  },
  {
    idPrefix: 'gpt-4.1-nano',
    label: 'GPT-4.1 Nano',
    description: 'Fastest, most cost-effective GPT 4.1 model. Currently points to gpt-4.1-nano-2025-04-14.',
    symLink: 'gpt-4.1-nano-2025-04-14',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 1047576,
    maxCompletionTokens: 32768,
    trainingDataCutoff: 'May 31, 2024',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 0.1, cache: { cType: 'oai-ac', read: 0.025 }, output: 0.4 },
    // benchmarks: will be available soon, hopefully
  },

  // GPT-4.5-Preview - will be removed soon, inferior to 4.1
  {
    hidden: true, // OBSOLETE
    idPrefix: 'gpt-4.5-preview-2025-02-27',
    label: 'GPT-4.5 Preview (2025-02-27)', //  [deprecated]
    description: 'Will be shut down on 2025-07-14. Research preview of GPT-4.5, our largest and most capable GPT model yet. Deep world knowledge and better understanding of user intent makes it good at creative tasks and agentic planning.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 75, cache: { cType: 'oai-ac', read: 37.5 }, output: 150 },
    benchmark: { cbaElo: 1398 },
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4.5-preview',
    label: 'GPT-4.5 Preview', //  [deprecated]
    description: 'Largest GPT model, good for creative tasks and agentic planning. Currently points to gpt-4.5-preview-2025-02-27.',
    symLink: 'gpt-4.5-preview-2025-02-27',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 75, cache: { cType: 'oai-ac', read: 37.5 }, output: 150 },
    benchmark: { cbaElo: 1398 },
    isPreview: true,
  },


  /// GPT-4/4o series

  // GPT-4o
  {
    idPrefix: 'gpt-4o-2024-11-20',
    label: 'GPT-4o (2024-11-20)',
    description: 'Snapshot of gpt-4o from November 20th, 2024.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 2.5, cache: { cType: 'oai-ac', read: 1.25 }, output: 10 },
    benchmark: { cbaElo: 1265 + 1 }, // not reported; using gpt-4o-2024-08-06 + 1
  },
  {
    idPrefix: 'gpt-4o-2024-08-06',
    label: 'GPT-4o (2024-08-06)',
    hidden: true, // previous version
    description: 'Snapshot that supports Structured Outputs. gpt-4o currently points to this version.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 2.5, cache: { cType: 'oai-ac', read: 1.25 }, output: 10 },
    benchmark: { cbaElo: 1265 },
  },
  {
    idPrefix: 'gpt-4o-2024-05-13',
    label: 'GPT-4o (2024-05-13)',
    hidden: true, // previous version
    description: 'Original gpt-4o snapshot from May 13, 2024.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: { input: 5, output: 15 },
    benchmark: { cbaElo: 1285 },
  },
  {
    idPrefix: 'gpt-4o',
    label: 'GPT-4o',
    description: 'High-intelligence flagship model. Currently points to gpt-4o-2024-08-06.',
    symLink: 'gpt-4o-2024-08-06',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 2.5, cache: { cType: 'oai-ac', read: 1.25 }, output: 10 },
    benchmark: { cbaElo: 1265 },
  },
  {
    idPrefix: 'chatgpt-4o-latest',
    label: 'ChatGPT-4o Latest',
    description: 'The chatgpt-4o-latest model version continuously points to the version of GPT-4o used in ChatGPT, and is updated frequently.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Json], // does not support Tools
    chatPrice: { input: 5, output: 15 },
    benchmark: { cbaElo: 1408 },
  },

  // GPT-4o Search Preview: When using Chat Completions, the model always retrieves information from the web before responding to your query.
  {
    // isLatest: true, // preview doesn't get highlighted
    idPrefix: 'gpt-4o-search-preview-2025-03-11',
    label: 'GPT-4o Search Preview (2025-03-11) 🌐',
    description: 'Latest snapshot of the GPT-4o model optimized for web search capabilities.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Json, LLM_IF_HOTFIX_NoTemperature, LLM_IF_Tools_WebSearch], // NOTE: 2025-03-15: confirmed on 'playground' that this model does not support images
    parameterSpecs: [{ paramId: 'llmVndOaiWebSearchContext' }, { paramId: 'llmVndOaiWebSearchGeolocation' }],
    chatPrice: { input: 2.5, output: 10 },
    // benchmarks don't apply to search models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-search-preview',
    label: 'GPT-4o Search Preview 🌐',
    description: 'GPT model for web search in Chat Completions. Currently points to gpt-4o-search-preview-2025-03-11.',
    symLink: 'gpt-4o-search-preview-2025-03-11',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Json, LLM_IF_HOTFIX_NoTemperature, LLM_IF_Tools_WebSearch], // NOTE: 2025-03-15: confirmed on 'playground' that this model does not support images
    parameterSpecs: [{ paramId: 'llmVndOaiWebSearchContext' }, { paramId: 'llmVndOaiWebSearchGeolocation' }],
    chatPrice: { input: 2.5, output: 10 },
    // benchmarks don't apply to search models
    isPreview: true,
  },

  // GPT-4o Audio Preview
  {
    hidden: true, // UNSUPPORTED yet (audio output model)
    idPrefix: 'gpt-4o-audio-preview-2025-06-03',
    label: 'GPT-4o Audio Preview (2025-06-03)',
    description: 'Latest snapshot for the Audio API model.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_NeedsAudio],
    chatPrice: { input: 2.5, output: 10 /* AUDIO PRICING UNSUPPORTED 40/80 */ },
    // benchmarks don't apply to audio models
    isPreview: true,
  },
  {
    hidden: true, // UNSUPPORTED yet (audio output model)
    idPrefix: 'gpt-4o-audio-preview-2024-12-17',
    label: 'GPT-4o Audio Preview (2024-12-17)',
    description: 'Snapshot for the Audio API model.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_NeedsAudio],
    chatPrice: { input: 2.5, output: 10 /* AUDIO PRICING UNSUPPORTED 40/80 */ },
    // benchmarks don't apply to audio models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-audio-preview-2024-10-01',
    label: 'GPT-4o Audio Preview (2024-10-01)',
    hidden: true, // previous version
    description: 'Snapshot for the Audio API model.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_NeedsAudio],
    chatPrice: { input: 2.5, output: 10 /* AUDIO PRICING UNSUPPORTED IS 40/80 */ },
    // benchmarks don't apply to audio models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-audio-preview',
    label: 'GPT-4o Audio Preview',
    description: 'Preview release for audio inputs in chat completions.',
    symLink: 'gpt-4o-audio-preview-2024-12-17', // still points to 12-17 as of 2025-06-11
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_NeedsAudio],
    chatPrice: { input: 2.5, output: 10 /* AUDIO PRICING UNSUPPORTED 40/80 */ },
    // benchmarks don't apply to audio models
    isPreview: true,
  },

  // GPT-4o Realtime Preview
  {
    hidden: true, // UNSUPPORTED yet - REALTIME API
    idPrefix: 'gpt-4o-realtime-preview-2025-06-03',
    label: 'GPT-4o Realtime Preview (2025-06-03)',
    description: 'Latest snapshot for the Realtime API model.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Realtime],
    chatPrice: { input: 5, cache: { cType: 'oai-ac', read: 2.5 }, output: 20 /* AUDIO PRICING UNSUPPORTED 40/80 */ },
    // benchmarks don't apply to realtime models
    isPreview: true,
  },
  {
    hidden: true, // UNSUPPORTED yet - REALTIME API
    idPrefix: 'gpt-4o-realtime-preview-2024-12-17',
    label: 'GPT-4o Realtime Preview (2024-12-17)',
    description: 'Snapshot for the Realtime API model.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Realtime],
    chatPrice: { input: 5, cache: { cType: 'oai-ac', read: 2.5 }, output: 20 /* AUDIO PRICING UNSUPPORTED 40/80 */ },
    // benchmarks don't apply to realtime models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-realtime-preview-2024-10-01',
    label: 'GPT-4o Realtime Preview (2024-10-01)',
    hidden: true, // previous version
    description: 'Snapshot for the Realtime API model.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Realtime],
    chatPrice: { input: 5, cache: { cType: 'oai-ac', read: 2.5 }, output: 20 /* AUDIO PRICING UNSUPPORTED 40/80 */ },
    // benchmarks don't apply to realtime models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-realtime-preview',
    label: 'GPT-4o Realtime Preview',
    description: 'Preview release for the Realtime API. Points to: gpt-4o-realtime-preview-2024-12-17.',
    symLink: 'gpt-4o-realtime-preview-2024-12-17',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Realtime],
    chatPrice: { input: 5, cache: { cType: 'oai-ac', read: 2.5 }, output: 20 /* AUDIO PRICING UNSUPPORTED 40/80 */ },
    // benchmarks don't apply to realtime models
    isPreview: true,
  },

  // GPT-4o mini
  {
    idPrefix: 'gpt-4o-mini-2024-07-18',
    label: 'GPT-4o Mini (2024-07-18)',
    description: 'Affordable model for fast, lightweight tasks. GPT-4o Mini is cheaper and more capable than GPT-3.5 Turbo.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 0.15, cache: { cType: 'oai-ac', read: 0.075 }, output: 0.6 },
    benchmark: { cbaElo: 1272 },
  },
  {
    idPrefix: 'gpt-4o-mini',
    label: 'GPT-4o mini',
    description: 'gpt-4o-mini currently points to this version.',
    symLink: 'gpt-4o-mini-2024-07-18',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_PromptCaching],
    chatPrice: { input: 0.15, cache: { cType: 'oai-ac', read: 0.075 }, output: 0.6 },
    benchmark: { cbaElo: 1272 },
  },
  {
    hidden: true, // UNSUPPORTED yet (audio output model)
    idPrefix: 'gpt-4o-mini-audio-preview-2024-12-17',
    label: 'GPT-4o Mini Audio Preview (2024-12-17)',
    description: 'Snapshot for the Audio API model.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_NeedsAudio],
    chatPrice: { input: 0.15, output: 0.6 /* AUDIO PRICING UNSUPPORTED 10/20 */ },
    // benchmarks don't apply to audio models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-mini-audio-preview',
    label: 'GPT-4o Mini Audio Preview',
    description: 'Preview release for audio inputs in chat completions.',
    symLink: 'gpt-4o-mini-audio-preview-2024-12-17',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_NeedsAudio],
    chatPrice: { input: 0.15, output: 0.6 /* AUDIO PRICING UNSUPPORTED 10/20 */ },
    // benchmarks don't apply to audio models
    isPreview: true,
  },
  {
    hidden: true, // UNSUPPORTED yet - REALTIME API
    idPrefix: 'gpt-4o-mini-realtime-preview-2024-12-17',
    label: 'GPT-4o Mini Realtime Preview (2024-12-17)',
    description: 'Snapshot for the Realtime API model.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Realtime],
    chatPrice: { input: 0.6, cache: { cType: 'oai-ac', read: 0.3 }, output: 2.4 },
    // benchmarks don't apply to realtime api models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-mini-realtime-preview',
    label: 'GPT-4o Mini Realtime Preview',
    description: 'Preview release for the Realtime API. Points to: gpt-4o-mini-realtime-preview-2024-12-17.',
    symLink: 'gpt-4o-mini-realtime-preview-2024-12-17',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Realtime],
    chatPrice: { input: 0.6, cache: { cType: 'oai-ac', read: 0.3 }, output: 2.4 },
    // benchmarks don't apply to realtime api models
    isPreview: true,
  },
  // GPT-4o Mini Search Preview: When using Chat Completions, the model always retrieves information from the web before responding to your query.
  {
    // isLatest: true, // preview doesn't get highlighted
    idPrefix: 'gpt-4o-mini-search-preview-2025-03-11',
    label: 'GPT-4o Mini Search Preview (2025-03-11) 🌐',
    description: 'Latest snapshot of the GPT-4o Mini model optimized for web search capabilities.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Json, LLM_IF_HOTFIX_NoTemperature, LLM_IF_Tools_WebSearch], // NOTE: this support function calling, but only its own, not a Custom Function
    parameterSpecs: [{ paramId: 'llmVndOaiWebSearchContext' }, { paramId: 'llmVndOaiWebSearchGeolocation' }],
    chatPrice: { input: 0.15, output: 0.6 },
    // benchmarks don't apply to search models
    isPreview: true,
  },
  {
    idPrefix: 'gpt-4o-mini-search-preview',
    label: 'GPT-4o Mini Search Preview 🌐',
    description: 'Fast, affordable small model for web search. Currently points to gpt-4o-mini-search-preview-2025-03-11.',
    symLink: 'gpt-4o-mini-search-preview-2025-03-11',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Sep 30, 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Json, LLM_IF_HOTFIX_NoTemperature, LLM_IF_Tools_WebSearch], // NOTE: this support function calling, but only its own, not a Custom Function
    parameterSpecs: [{ paramId: 'llmVndOaiWebSearchContext' }, { paramId: 'llmVndOaiWebSearchGeolocation' }],
    chatPrice: { input: 0.15, output: 0.6 },
    // benchmarks don't apply to search models
    isPreview: true,
  },

  // GPT-4 Turbo
  {
    idPrefix: 'gpt-4-turbo-2024-04-09',
    label: 'GPT-4 Turbo (2024-04-09)',
    hidden: true, // OLD
    description: 'GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Dec 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: { input: 10, output: 30 },
    benchmark: { cbaElo: 1256 },
  },
  {
    idPrefix: 'gpt-4-turbo',
    label: 'GPT-4 Turbo',
    description: 'GPT-4 Turbo with Vision. Currently points to gpt-4-turbo-2024-04-09.',
    symLink: 'gpt-4-turbo-2024-04-09',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Dec 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: { input: 10, output: 30 },
    benchmark: { cbaElo: 1256 },
  },
  {
    idPrefix: 'gpt-4-0125-preview',
    label: 'GPT-4 Turbo (0125)',
    hidden: true, // OLD
    description: 'GPT-4 Turbo preview model intended to reduce cases of "laziness" where the model doesn\'t complete a task.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Dec 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: { input: 10, output: 30 },
    benchmark: { cbaElo: 1245 },
  },
  {
    idPrefix: 'gpt-4-1106-preview', // GPT-4 Turbo preview model
    label: 'GPT-4 Turbo (1106)',
    hidden: true, // OLD
    description: 'GPT-4 Turbo preview model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Apr 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: { input: 10, output: 30 },
    benchmark: { cbaElo: 1250 },
  },
  {
    idPrefix: 'gpt-4-turbo-preview',
    label: 'GPT-4 Turbo Preview',
    description: 'GPT-4 Turbo preview model. Currently points to gpt-4-0125-preview.',
    symLink: 'gpt-4-0125-preview',
    hidden: true, // prefer versioned
    isLegacy: true,
    // copied from symlinked
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Dec 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: { input: 10, output: 30 },
    benchmark: { cbaElo: 1245 },
  },

  // GPT4-32k's
  {
    idPrefix: 'gpt-4-32k-0613',
    label: 'GPT-4 32k (0613)',
    hidden: true, // OLD
    description: 'Snapshot of gpt-4-32k from June 13th 2023 with improved function calling support. This model was never rolled out widely in favor of GPT-4 Turbo.',
    contextWindow: 32768,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat],
    chatPrice: { input: 60, output: 120 },
    // benchmarks never came out of these older models
    isLegacy: true,
  },
  {
    idPrefix: 'gpt-4-32k-0314',
    label: 'GPT-4 32k (0314)',
    hidden: true, // OLD
    description: 'Snapshot of gpt-4-32k from March 14th 2023. Will be deprecated on June 13th 2024 at the earliest.',
    contextWindow: 32768,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat],
    chatPrice: { input: 60, output: 120 },
    // benchmarks never came out of these older models
    isLegacy: true,
  },
  {
    idPrefix: 'gpt-4-32k',
    label: 'GPT-4 32k',
    description: 'Currently points to gpt-4-32k-0613. This model was never rolled out widely in favor of GPT-4 Turbo.',
    symLink: 'gpt-4-32k-0613',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 32768,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat],
    chatPrice: { input: 60, output: 120 },
    // benchmarks never came out of these older models
    isLegacy: true,
  },
  // GPT4's
  {
    idPrefix: 'gpt-4-0613',
    label: 'GPT-4 (0613)',
    hidden: true, // OLD
    description: 'Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Data up to Sep 2021.',
    contextWindow: 8192,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 30, output: 60 },
    benchmark: { cbaElo: 1163 },
    isLegacy: true,
  },
  {
    idPrefix: 'gpt-4-0314',
    label: 'GPT-4 (0314)',
    hidden: true, // OLD
    description: 'Snapshot of gpt-4 from March 14th 2023 with function calling data. Data up to Sep 2021.',
    contextWindow: 8192,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 30, output: 60 },
    benchmark: { cbaElo: 1186 },
    isLegacy: true,
  },
  {
    idPrefix: 'gpt-4',
    label: 'GPT-4',
    description: 'Currently points to gpt-4-0613.',
    symLink: 'gpt-4-0613',
    hidden: true, // prefer versioned
    // copied from symlinked
    contextWindow: 8192,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 30, output: 60 },
    benchmark: { cbaElo: 1163 },
    isLegacy: true,
  },


  // 3.5
  // Note: As of July 2024, gpt-4o-mini should be used in place of gpt-3.5-turbo, as it is cheaper, more capable, multimodal, and just as fast.
  // As such, many 3.5 models are in the 'deny list' below, and not even returned to the UI.
  {
    idPrefix: 'gpt-3.5-turbo-0125',
    label: '3.5-Turbo (2024-01-25)',
    hidden: true, // OLD
    description: 'The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls.',
    contextWindow: 16385,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.5, output: 1.5 },
    benchmark: { cbaElo: 1106 },
  },
  {
    idPrefix: 'gpt-3.5-turbo-1106',
    label: '3.5-Turbo (1106)',
    hidden: true, // OLD
    description: 'GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.',
    contextWindow: 16385,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 1, output: 2 },
    benchmark: { cbaElo: 1068 },
  },
  {
    idPrefix: 'gpt-3.5-turbo',
    label: '3.5-Turbo',
    description: 'Currently points to gpt-3.5-turbo-0125. As of July 2024, gpt-4o-mini should be used in place of gpt-3.5-turbo, as it is cheaper, more capable, multimodal, and just as fast.',
    symLink: 'gpt-3.5-turbo-0125',
    hidden: true, // prefer versioned
    // copied
    contextWindow: 16385,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 0.5, output: 1.5 },
    benchmark: { cbaElo: 1106 },
  },


  // Fallback - unknown
  {
    idPrefix: '',
    label: '?',
    description: 'Unknown, please let us know the ID. Assuming a context window of 128k tokens, and a maximum output of 4k tokens.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    interfaces: [LLM_IF_OAI_Chat],
    // hidden: true,
  },

];

const openAIModelsDenyList: string[] = [
  // [OpenAI, 2025-03-11] FIXME: NOT YET SUPPORTED - "RESPONSES API"
  'computer-use-preview', 'computer-use-preview-2025-03-11', // FIXME: support these

  // Legacy GPT models
  'gpt-3.5-turbo-0301',
  'gpt-3.5-turbo-0613',
  'gpt-3.5-turbo-16k',
  'gpt-3.5-turbo-16k-0613',

  // Other unwanted GPT models
  'gpt-4-turbo-preview',

  // Non-chat GPT models
  '-turbo-instruct', 'davinci-', 'babbage-',

  // Embedding models: /v1/embeddings
  'text-embedding-3-small', 'text-embedding-3-large', 'text-embedding-ada-002',

  // TTS Models: /v1/audio/speech
  'tts-1-hd', 'tts-1', 'gpt-4o-mini-tts', // FIXME: support these

  // STT models: /v1/audio/transcriptions, /v1/audio/translations
  'whisper-1', 'gpt-4o-transcribe', 'gpt-4o-mini-transcribe', // FIXME: support these

  // Image models: /v1/images/generations
  'gpt-image-1', 'dall-e-3', 'dall-e-2',

  // Moderation models
  'omni-moderation-latest', 'omni-moderation-2024-09-26', 'text-moderation-latest',
];

export function openAIModelFilter(model: OpenAIWire_API_Models_List.Model) {
  return !openAIModelsDenyList.some(deny => model.id.includes(deny));
}

export function openAIModelToModelDescription(modelId: string, modelCreated: number | undefined, modelUpdated?: number): ModelDescriptionSchema {
  return fromManualMapping(_knownOpenAIChatModels, modelId, modelCreated, modelUpdated);
}


const _manualOrderingIdPrefixes = [
  // Reasoning models
  'o5-20',
  'o5-mini-20',
  'o5-',
  'o4-pro-20',
  'o4-pro',
  'o4-mini-deep-research-20',
  'o4-mini-deep-research',
  'o4-20',
  'o4-mini-20',
  'o4-',
  'o3-pro-20',
  'o3-pro',
  'o3-deep-research-20',
  'o3-deep-research',
  'o3-20',
  'o3-mini-20',
  'o3-',
  'o1-pro-20',
  'o1-pro',
  'o1-20',
  'o1-preview-',
  'o1-mini-',
  'o1-',
  // GPT-4.5
  'gpt-4.5-20',
  'gpt-4.5-preview',
  'gpt-4.5-',
  // GPT-4.1
  'gpt-4.1-20',
  'gpt-4.1-mini-20',
  'gpt-4.1-mini',
  'gpt-4.1-nano-20',
  'gpt-4.1-nano',
  'gpt-4.1',
  // Preferred models
  'gpt-4o-20',
  'gpt-4o-search-20',
  'gpt-4o-search-preview',
  'gpt-4o-mini-20',
  'gpt-4o-mini-search-20',
  'gpt-4o-mini-search-preview',
  'gpt-4o-mini',
  'gpt-4o-',
  // ChatGPT models
  'chatgpt-',
  // Codex
  'codex-',
  // Computer use models
  'computer-use-20',
  'computer-use-preview',
  'computer-use',
  // ...rest
  // 'gpt-4-turbo-',
  // 'gpt-4-',
  // ...
];


export function openAISortModels(a: ModelDescriptionSchema, b: ModelDescriptionSchema) {
  // bottom: links
  const aLink = a.label.startsWith('🔗');
  const bLink = b.label.startsWith('🔗');
  if (aLink !== bLink) return aLink ? 1 : -1;

  // bottom: non-chatGenerate
  const aChat = a.interfaces.includes(LLM_IF_OAI_Chat);
  const bChat = b.interfaces.includes(LLM_IF_OAI_Chat);
  if (aChat !== bChat) return aChat ? -1 : 1;

  // sort by manual ordering (if not present is implicitly at the bottom)
  const aOrder = _manualOrderingIdPrefixes.findIndex(prefix => a.id.startsWith(prefix));
  const bOrder = _manualOrderingIdPrefixes.findIndex(prefix => b.id.startsWith(prefix));
  if (aOrder !== bOrder) {
    if (aOrder === -1) return 1;
    if (bOrder === -1) return -1;
    return aOrder - bOrder;
  }

  // fix the OpenAI model names to be chronologically sorted
  function remapReleaseDate(id: string): string {
    return id
      .replace('0314', '2023-03-14')
      .replace('0613', '2023-06-13')
      .replace('1106', '2023-11-06')
      .replace('0125', '2024-01-25')
      .replace('0409', '2024-04-09');
  }

  // due to using by-label, sorting doesn't require special cases anymore
  return remapReleaseDate(b.label).localeCompare(remapReleaseDate(a.label));
}



================================================
FILE: src/modules/llms/server/openai/models/openpipe.models.ts
================================================
import type { ModelDescriptionSchema } from '~/modules/llms/server/llm.server.types';
import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { _knownOpenAIChatModels } from '~/modules/llms/server/openai/models/openai.models';
import { wireOpenPipeModelOutputSchema } from '~/modules/llms/server/openai/openpipe.wiretypes';
import { fromManualMapping, ManualMapping } from '~/modules/llms/server/openai/models/models.data';

const _knownOpenPipeChatModels: ModelDescriptionSchema[] = [

  /* OpenPipe models - by default it's OpenAI models, through the proxy service. */

  // OpenAI models: these work
  {
    id: 'gpt-4o-mini-2024-07-18',
    label: '💾➜ GPT-4o Mini (2024-07-18)',
    description: 'Affordable model for fast, lightweight tasks. GPT-4o mini is cheaper and more capable than GPT-3.5 Turbo.',
    contextWindow: 128000,
    maxCompletionTokens: 16384,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: _knownOpenAIChatModels.find(m => m.idPrefix === 'gpt-4o-mini-2024-07-18')?.chatPrice,
    benchmark: { cbaMmlu: 82.0 },
  },
  {
    id: 'gpt-4o-2024-05-13',
    label: '💾➜ GPT-4o (2024-05-13)',
    description: 'Advanced, multimodal flagship model that\'s cheaper and faster than GPT-4 Turbo.',
    contextWindow: 128000,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Oct 2023',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: _knownOpenAIChatModels.find(m => m.idPrefix === 'gpt-4o-2024-05-13')?.chatPrice,
    benchmark: { cbaElo: 1287 },
  },
  {
    id: 'gpt-3.5-turbo-1106',
    label: '💾➜ GPT-3.5 Turbo (1106)',
    description: 'GPT-3.5 Turbo model from November 2023',
    contextWindow: 16385,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: _knownOpenAIChatModels.find(m => m.idPrefix === 'gpt-3.5-turbo-1106')?.chatPrice,
    benchmark: { cbaElo: 1072 },
  },
  {
    id: 'gpt-3.5-turbo-0125',
    label: '💾➜ GPT-3.5 Turbo (0125)',
    description: 'The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats',
    contextWindow: 16385,
    maxCompletionTokens: 4096,
    trainingDataCutoff: 'Sep 2021',
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: _knownOpenAIChatModels.find(m => m.idPrefix === 'gpt-3.5-turbo-0125')?.chatPrice,
    benchmark: { cbaElo: 1105 },
  },

  // Not supported yet "We don't support streaming responses for chat completions with Anthropic yet. Please email us at support@openpipe.ai if this is a feature you need!"
  // {
  //   id: 'claude-3-5-sonnet-20240620',
  //   label: '💾➜ Claude 3.5 Sonnet',
  //   description: 'The most intelligent Claude model',
  //   contextWindow: 200000, // Characters
  //   maxCompletionTokens: 8192,
  //   trainingDataCutoff: 'Apr 2024',
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision],
  //   pricing: { input: 3, output: 15 },
  // },

  // Default finetune, not available at the onset
  // {
  //   id: 'mistral-ft-optimized-1227',
  //   label: 'OpenPipe · Mistral FT Optimized',
  //   description: 'OpenPipe optimized Mistral fine-tuned model',
  //   contextWindow: 32768, // Assuming similar to Mixtral, as it's Mistral-based
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn], // Assuming similar to Mixtral
  // },

  // Finetune-able models, but not present
  // {
  //   id: 'meta-llama/Meta-Llama-3.1-8B-Instruct',
  //   label: 'Meta-Llama 3.1 · 8B Instruct',
  //   description: 'Meta-Llama 3.1 8B Instruct model',
  //   contextWindow: 128000, // Inferred from Llama 3 models in the original code
  //   maxCompletionTokens: 4096, // Inferred from Llama 3 models in the original code
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json], // Inferred from Llama 3 models
  // },
  // {
  //   id: 'meta-llama/Meta-Llama-3.1-70B-Instruct',
  //   label: 'Meta-Llama 3.1 · 70B Instruct',
  //   description: 'Meta-Llama 3.1 70B Instruct model',
  //   contextWindow: 128000, // Inferred from Llama 3 models in the original code
  //   maxCompletionTokens: 4096, // Inferred from Llama 3 models in the original code
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json], // Inferred from Llama 3 models
  // },
  // {
  //   id: 'mistralai/Mixtral-8x7B-Instruct-v0.1',
  //   label: 'Mixtral · 8x7B Instruct v0.1',
  //   description: 'Mixtral 8x7B Instruct v0.1 model',
  //   contextWindow: 32768, // Inferred from Mixtral model in the original code
  //   interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn], // Inferred from Mixtral model
  // },

];
const openPipeModelFamilyOrder = [
  'gpt-4o', 'gpt-3.5-turbo', 'mistral-ft', 'meta-llama', 'mistralai', '',
];

export function openPipeModelDescriptions() {
  return _knownOpenPipeChatModels;
}

export function openPipeModelSort(a: ModelDescriptionSchema, b: ModelDescriptionSchema): number {
  const aPrefixIndex = openPipeModelFamilyOrder.findIndex(prefix => a.id.startsWith(prefix));
  const bPrefixIndex = openPipeModelFamilyOrder.findIndex(prefix => b.id.startsWith(prefix));
  // Sort by family
  if (aPrefixIndex !== bPrefixIndex)
    return aPrefixIndex - bPrefixIndex;
  // Then by reverse label (newer versions first)
  return b.label.localeCompare(a.label);
}

export function openPipeModelToModelDescriptions(wireModel: object): ModelDescriptionSchema {
  // parse the model
  const model = wireOpenPipeModelOutputSchema.parse(wireModel);

  // note: model.id is a UUID, but when making the requests, this is the id we use
  const namedId = `openpipe:${model.name}`;

  // parse the ISO strings
  let created: number | undefined;
  let updated: number | undefined;
  try {
    created = Date.parse(model.created) || undefined;
    updated = Date.parse(model.updated) || undefined;
  } catch (e) {
    // .. prevent issues
  }

  // patch label and description based on the `.openpipe` field
  let label = 'OpenPipe · ' + model.name;
  let description = model.description || 'Fine-tuned model.';
  switch (model.openpipe?.status) {
    case 'PENDING':
      label = `🟦 ${label} (PENDING)`;
      break;
    case 'TRAINING':
      label = `🟦 ${label} (TRAINING)`;
      break;
    case 'DEPLOYED':
      label = `🟩 ${label}`;
      break;
    case 'ERROR':
      label = `🟥 ${label} (ERROR)`;
      break;
    case 'DEPRECATED':
      label = `🟨 ${label} (DEPRECATED)`;
      break;
  }

  if (model.openpipe?.baseModel)
    description += `\n\nBased on: ${model.openpipe.baseModel}`;
  if (model.openpipe?.datasetId)
    description += `\nDataset Id: ${model.openpipe.datasetId}`;
  if (model.openpipe?.errorMessage)
    description += `\n\nError: ${model.openpipe.errorMessage}\n`;
  description += `\n\nUUID: ${model.id}`;


  const manualMapping: ManualMapping = {
    idPrefix: namedId,
    label,
    description,
    contextWindow: model.contextWindow,
    maxCompletionTokens: model.maxCompletionTokens,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
  };

  if (model.pricing) {
    manualMapping.chatPrice = {
      input: model.pricing.chatIn,
      output: model.pricing.chatOut,
    };
  }

  return fromManualMapping([], namedId, created, updated, manualMapping);
}


================================================
FILE: src/modules/llms/server/openai/models/openrouter.models.ts
================================================
import type { ModelDescriptionSchema } from '~/modules/llms/server/llm.server.types';
import { wireOpenrouterModelsListOutputSchema } from '~/modules/llms/server/openai/openrouter.wiretypes';
import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';
import { fromManualMapping } from '~/modules/llms/server/openai/models/models.data';


// [OpenRouter] - enough API info to auto-detect models, we only decide what to show here
// - models: https://openrouter.ai/models
// - models list API: https://openrouter.ai/docs/models

const orOldModelIDs = [
  // Older OpenAI models
  'openai/gpt-3.5-turbo-0301', 'openai/gpt-3.5-turbo-0613', 'openai/gpt-4-0314', 'openai/gpt-4-32k-0314',
  // Older Anthropic models
  'anthropic/claude-1', 'anthropic/claude-1.2', 'anthropic/claude-instant-1.0', 'anthropic/claude-instant-1.1',
  'anthropic/claude-2', 'anthropic/claude-2:beta', 'anthropic/claude-2.0', 'anthropic/claude-2.1', 'anthropic/claude-2.0:beta',
  // Older Google models
  'google/palm-2-',
  // Older Meta models
  'meta-llama/llama-3-', 'meta-llama/llama-2-',
];

const orModelFamilyOrder = [
  // Leading models/organizations (based on capabilities and popularity)
  'anthropic/', 'deepseek/', 'google/', 'openai/', 'x-ai/',
  // Other major providers
  'mistralai/', 'meta-llama/', 'amazon/', 'cohere/',
  // Specialized/AI companies
  'perplexity/', 'phind/', 'qwen/', 'inflection/',
  // Research/open models
  'nvidia/', 'microsoft/', 'nousresearch/', 'openchat/', // 'huggingfaceh4/',
  // Community/other providers
  // 'gryphe/', 'thedrummer/', 'undi95/', 'cognitivecomputations/', 'sao10k/',
];

export function openRouterModelFamilySortFn(a: { id: string }, b: { id: string }): number {
  const aPrefixIndex = orModelFamilyOrder.findIndex(prefix => a.id.startsWith(prefix));
  const bPrefixIndex = orModelFamilyOrder.findIndex(prefix => b.id.startsWith(prefix));

  // If both have a prefix, sort by prefix first, and then alphabetically
  if (aPrefixIndex !== -1 && bPrefixIndex !== -1)
    return aPrefixIndex !== bPrefixIndex ? aPrefixIndex - bPrefixIndex : b.id.localeCompare(a.id);

  // If one has a prefix and the other doesn't, prioritize the one with prefix
  return aPrefixIndex !== -1 ? -1 : 1;
}

export function openRouterModelToModelDescription(wireModel: object): ModelDescriptionSchema | null {

  // parse the model
  const { data: model, error } = wireOpenrouterModelsListOutputSchema.safeParse(wireModel);
  if (error) {
    console.warn(`openRouterModelToModelDescription: Failed to parse model data`, { error });
    return null;
  }

  // parse pricing
  const inputPrice = parseFloat(model.pricing.prompt);
  const outputPrice = parseFloat(model.pricing.completion);
  const chatPrice: ModelDescriptionSchema['chatPrice'] = {
    input: inputPrice ? inputPrice * 1000 * 1000 : 'free',
    output: outputPrice ? outputPrice * 1000 * 1000 : 'free',
    // image...
    // request...
  };
  const seemsFree = chatPrice.input === 'free' && chatPrice.output === 'free';

  // openrouter provides the fields we need as part of the model object
  let label = model.name || model.id.replace('/', ' · ');
  if (seemsFree)
    label += ' · 🎁'; // Free? Discounted?
  // label = label.replace('(self-moderated)', '🔓');

  // hidden: hide by default older models or models not in known families; match with startsWith for both orOldModelIDs and orModelFamilyOrder
  const hidden = orOldModelIDs.some(prefix => model.id.startsWith(prefix))
    || !orModelFamilyOrder.some(prefix => model.id.startsWith(prefix));

  return fromManualMapping([], model.id, undefined, undefined, {
    idPrefix: model.id,
    // latest: ...
    label,
    // created: ...
    // updated: ...
    description: model.description,
    contextWindow: model.context_length || 4096,
    maxCompletionTokens: model.top_provider.max_completion_tokens || undefined,
    // trainingDataCutoff: ...
    interfaces: [LLM_IF_OAI_Chat],
    // benchmark: ...
    chatPrice,
    hidden,
  });
}

export function openRouterInjectVariants(models: ModelDescriptionSchema[], model: ModelDescriptionSchema): ModelDescriptionSchema[] {
  // keep the same list of models
  models.push(model);

  // inject thinking variants for Anthropic thinking models
  const antThinkingModels = ['anthropic/claude-opus-4', 'anthropic/claude-sonnet-4', 'anthropic/claude-3-7-sonnet'];
  if (antThinkingModels.includes(model.id)) {

    // create a thinking variant for the model, by setting 'idVariant' and modifying the label/description
    const thinkingVariant: ModelDescriptionSchema = {
      ...model,
      idVariant: 'thinking',
      label: `${model.label} (thinking)`,
      description: `(extended thinking mode) ${model.description}`,
      interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Vision, LLM_IF_OAI_Fn, LLM_IF_OAI_Reasoning],
      // this is what makes it a thinking variant
      parameterSpecs: [
        ...(model.parameterSpecs || []),
        { paramId: 'llmVndAntThinkingBudget', initialValue: 1024 },
      ],
    };

    models.push(thinkingVariant);
  }

  // no more variants to inject for now
  return models;
}

/*
export function openRouterStatTokenizers(openRouterModels: any[]): void {
  // parse all
  const tokenizersMap: Record<string, string[]> = {};
  for (const model of openRouterModels) {
    const { data, error } = wireOpenrouterModelsListOutputSchema.safeParse(model);
    if (error) continue;
    const tokenizer = data.architecture?.tokenizer || 'unknown';
    if (!tokenizersMap[tokenizer])
      tokenizersMap[tokenizer] = [];
    tokenizersMap[tokenizer].push(data.id);
  }
  console.log('\n=== Tokenizer Statistics ===');
  Object.entries(tokenizersMap)
    .sort(([, modelsA], [, modelsB]) => modelsB.length - modelsA.length)
    .forEach(([tokenizer, models]) => {
      console.log(`${tokenizer}: ${models.length} models`);
    });
}*/



================================================
FILE: src/modules/llms/server/openai/models/perplexity.models.ts
================================================
import type { ModelDescriptionSchema } from '../../llm.server.types';

import { LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_Tools_WebSearch } from '~/common/stores/llms/llms.types';


// configuration
const PERPLEXITY_ENABLE_VARIANTS = false; // enable variants for Perplexity models


const _knownPerplexityChatModels: ModelDescriptionSchema[] = [

  // Research Models
  {
    id: 'sonar-deep-research',
    label: 'Sonar Deep Research 🌐',
    description: 'Expert-level research model for exhaustive searches and comprehensive reports. 128k context.',
    contextWindow: 128000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_Tools_WebSearch],
    parameterSpecs: [
      { paramId: 'llmVndOaiReasoningEffort' }, // REUSE!
      { paramId: 'llmVndOaiWebSearchContext', initialValue: 'low' }, // REUSE!
      { paramId: 'llmVndPerplexitySearchMode' },
      { paramId: 'llmVndPerplexityDateFilter' },
    ],
    chatPrice: {
      input: 2,
      output: 8,
      // Full pricing: $2/1M input, $8/1M output, $2/1M citation, $5/1k searches, $3/1M reasoning tokens
    },
  },

  // Reasoning Models
  {
    id: 'sonar-reasoning-pro',
    label: 'Sonar Reasoning Pro 🌐',
    description: 'Premier reasoning model (DeepSeek R1) with Chain of Thought. 128k context.',
    contextWindow: 128000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_Tools_WebSearch],
    parameterSpecs: [
      { paramId: 'llmVndOaiWebSearchContext', initialValue: 'low' }, // REUSE!
      { paramId: 'llmVndPerplexitySearchMode' },
      { paramId: 'llmVndPerplexityDateFilter' },
    ],
    chatPrice: {
      input: 2,
      output: 8,
      // Per-request pricing: $14(High), $10(Medium), $6(Low) per 1k requests
    },
  },
  {
    id: 'sonar-reasoning',
    label: 'Sonar Reasoning 🌐',
    description: 'Fast, real-time reasoning model for quick problem-solving with search. 128k context.',
    contextWindow: 128000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Reasoning, LLM_IF_Tools_WebSearch],
    parameterSpecs: [
      { paramId: 'llmVndOaiWebSearchContext', initialValue: 'low' }, // REUSE!
      { paramId: 'llmVndPerplexitySearchMode' },
      { paramId: 'llmVndPerplexityDateFilter' },
    ],
    chatPrice: {
      input: 1,
      output: 5,
      // Per-request pricing: $12(High), $8(Medium), $5(Low) per 1k requests
    },
  },

  // Search Models
  {
    id: 'sonar-pro',
    label: 'Sonar Pro 🌐',
    description: 'Advanced search model for complex queries and deep content understanding. 200k context.',
    contextWindow: 200000,
    maxCompletionTokens: 8000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_Tools_WebSearch],
    parameterSpecs: [
      { paramId: 'llmVndOaiWebSearchContext', initialValue: 'low' }, // REUSE!
      { paramId: 'llmVndPerplexitySearchMode' },
      { paramId: 'llmVndPerplexityDateFilter' },
    ],
    chatPrice: {
      input: 3,
      output: 15,
      // Per-request pricing: $14(High), $10(Medium), $6(Low) per 1k requests
    },
  },
  {
    id: 'sonar',
    label: 'Sonar 🌐',
    description: 'Lightweight, cost-effective search model for quick, grounded answers. 128k context.',
    contextWindow: 128000,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_Tools_WebSearch],
    parameterSpecs: [
      { paramId: 'llmVndOaiWebSearchContext', initialValue: 'low' }, // REUSE!
      { paramId: 'llmVndPerplexitySearchMode' },
      { paramId: 'llmVndPerplexityDateFilter' },
    ],
    chatPrice: {
      input: 1,
      output: 1,
      // Per-request pricing: $12(High), $8(Medium), $5(Low) per 1k requests
    },
  },

  // Offline Models
  {
    id: 'r1-1776',
    label: 'R1-1776',
    description: 'Offline chat model (DeepSeek R1) for uncensored, unbiased, and factual information. 128k context.',
    contextWindow: 128000,
    interfaces: [LLM_IF_OAI_Chat],
    chatPrice: {
      input: 2,
      output: 8,
      // No search cost
    },
  },

];

export function perplexityInjectVariants(models: ModelDescriptionSchema[], model: ModelDescriptionSchema): ModelDescriptionSchema[] {

  // Variant: academic deep research
  if (PERPLEXITY_ENABLE_VARIANTS && model.id === 'sonar-deep-research') {
    models.push({
      ...model,
      idVariant: 'academic',
      label: 'Sonar Deep Research (Academic) 🌐',
      description: 'Expert-level research model with academic sources only. Searches scholarly databases, peer-reviewed papers, and academic publications. 128k context.',
      parameterSpecs: [
        // Fixed parameters for academic search
        { paramId: 'llmVndOaiWebSearchContext', initialValue: 'medium', hidden: true },
        { paramId: 'llmVndPerplexitySearchMode', initialValue: 'academic', hidden: true },
        { paramId: 'llmForceNoStream', initialValue: true, hidden: true },
        // Free parameters
        // { paramId: 'llmVndOaiReasoningEffort', initialValue: 'medium' },
        { paramId: 'llmVndPerplexityDateFilter' },
      ],
    } satisfies ModelDescriptionSchema);
  }

  // Add the base model
  models.push(model);

  return models;
}

export function perplexityAIModelDescriptions() {
  // Returns the list of known Perplexity models
  return _knownPerplexityChatModels;
}



================================================
FILE: src/modules/llms/server/openai/models/together.models.ts
================================================
import { LLM_IF_OAI_Chat, LLM_IF_OAI_Vision } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';
import { fromManualMapping, ManualMappings } from './models.data';
import { wireTogetherAIListOutputSchema } from '../togetherai.wiretypes';


// Note: 2025-01-28 - we used to have harcoded models here, but now we have a dynamic
// list from the API, so we don't need to hardcode them here anymore.
const _knownTogetherAIChatModels: ManualMappings = [
  // {
  //   idPrefix: 'meta-llama/Llama-3.3-70B-Instruct-Turbo',
  //   label: 'Llama 3.3 70B Instruct Turbo',
  //   description: 'Llama 3.3 70B Instruct Turbo is an advanced model from Meta with a context length of 131072 tokens, using FP8 quantization.',
  //   contextWindow: 131072,
  //   interfaces: [LLM_IF_OAI_Chat],
  // },
] as const;

// allow list patterns
const _togetherAllowTypes = [
  'chat',
];

const _togetherAIDenyList: string[] = [
  'devuser/test',
  'test-lora',
  'test/test',
];

export function togetherAIModelsToModelDescriptions(wireModels: unknown): ModelDescriptionSchema[] {

  function togetherAIModelsSort(a: ModelDescriptionSchema, b: ModelDescriptionSchema): number {
    if (a.hidden && !b.hidden)
      return 1;
    if (!a.hidden && b.hidden)
      return -1;
    if (a.created !== b.created)
      return (b.created || 0) - (a.created || 0);
    return a.id.localeCompare(b.id);
  }

  return wireTogetherAIListOutputSchema
    .parse(wireModels)

    .filter((model) => {
      // filter-out non-llms
      if (!_togetherAllowTypes.includes(model.type))
        return false;

      // NOTE: shall we filter out the non-running models?

      // filter-out deny list (testing models mainly)
      return !_togetherAIDenyList.some(prefix => model.id.includes(prefix));
    })

    .map((model): ModelDescriptionSchema => {

      // heuristics for names
      const label = model.display_name || model.id.replaceAll('/', ' · ').replaceAll(/[_-]/g, ' ');
      const description = `${model.organization || 'Toghether AI'} ${model.type} model. ${model.link || ''}`;
      const contextWindow = model.context_length || null;
      let chatPrice: ModelDescriptionSchema['chatPrice'] | undefined = undefined;
      if (typeof model.pricing?.input === 'number' && typeof model.pricing?.output === 'number') {
        const inputPrice = parseFloat('' + model.pricing.input);
        const outputPrice = parseFloat('' + model.pricing.output);
        if (inputPrice >= 0 && outputPrice >= 0)
          chatPrice = {
            input: model.pricing.input,
            output: model.pricing.output,
          };
      }
      const interfaces = [LLM_IF_OAI_Chat];
      if (model.id.indexOf('vision') !== -1)
        interfaces.push(LLM_IF_OAI_Vision);

      return fromManualMapping(_knownTogetherAIChatModels, model.id, model.created, undefined, {
        idPrefix: model.id,
        label,
        description,
        contextWindow,
        interfaces,
        // parameterSpecs: ...
        // maxCompletionTokens: ...
        // trainingDataCutoff: ...
        // benchmark: ...
        chatPrice,
        hidden: false,
      });
    })

    .sort(togetherAIModelsSort);
}



================================================
FILE: src/modules/llms/server/openai/models/xai.models.ts
================================================
import * as z from 'zod/v4';

import { fetchJsonOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_OAI_Reasoning, LLM_IF_OAI_Vision, LLM_IF_Tools_WebSearch } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../../llm.server.types';
import { fromManualMapping, ManualMapping, ManualMappings } from './models.data';
import { openAIAccess, OpenAIAccessSchema } from '../openai.router';


// Known xAI Models - Manual Mappings
// List on: https://docs.x.ai/docs/models?cluster=us-east-1
const _knownXAIChatModels: ManualMappings = [

  // Grok 4
  {
    idPrefix: 'grok-4-0709',
    label: 'Grok 4 (0709)',
    description: 'xAI\'s most advanced model, offering state-of-the-art reasoning and problem-solving capabilities over a massive 256k context window. Supports text and image inputs.',
    contextWindow: 256000,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_Tools_WebSearch, LLM_IF_OAI_Reasoning],
    parameterSpecs: [{ paramId: 'llmVndXaiSearchMode' }, { paramId: 'llmVndXaiSearchSources' }, { paramId: 'llmVndXaiSearchDateFilter' }],
    chatPrice: { input: 3, output: 15, cache: { cType: 'oai-ac', read: 0.75 } },
    benchmark: { cbaElo: 1409 + 1 /* still unreported! assuming on top of grok-3 */ },
  },

  // Grok 3
  {
    idPrefix: 'grok-3',
    label: 'Grok 3',
    description: 'xAI flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.',
    contextWindow: 131072,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_Tools_WebSearch],
    parameterSpecs: [{ paramId: 'llmVndXaiSearchMode' }, { paramId: 'llmVndXaiSearchSources' }, { paramId: 'llmVndXaiSearchDateFilter' }],
    chatPrice: { input: 3, output: 15, cache: { cType: 'oai-ac', read: 0.75 } },
    benchmark: { cbaElo: 1409 /* grok-3-preview-02-24 */},
  },
  {
    idPrefix: 'grok-3-fast',
    label: 'Grok 3 Fast',
    description: 'Faster version of the xAI flagship model with identical response quality but significantly reduced latency. Ideal for latency-sensitive applications.',
    contextWindow: 131072,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_Tools_WebSearch],
    parameterSpecs: [{ paramId: 'llmVndXaiSearchMode' }, { paramId: 'llmVndXaiSearchSources' }, { paramId: 'llmVndXaiSearchDateFilter' }],
    chatPrice: { input: 5, output: 25, cache: { cType: 'oai-ac', read: 1.25 } },
    benchmark: { cbaElo: 1409 - 1 /* still unreported! assuming below grok-3 just for cost */ },
  },
  {
    idPrefix: 'grok-3-mini',
    label: 'Grok 3 Mini',
    description: 'A lightweight model that thinks before responding. Fast, smart, and great for logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible.',
    contextWindow: 131072,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_Tools_WebSearch, LLM_IF_OAI_Reasoning],
    parameterSpecs: [
      { paramId: 'llmVndOaiReasoningEffort' },
      { paramId: 'llmVndXaiSearchMode' }, { paramId: 'llmVndXaiSearchSources' }, { paramId: 'llmVndXaiSearchDateFilter' }
    ],
    chatPrice: { input: 0.3, output: 0.5, cache: { cType: 'oai-ac', read: 0.075 } },
    benchmark: { cbaElo: 1354 /* grok-3-mini-beta */},
  },
  {
    idPrefix: 'grok-3-mini-fast',
    label: 'Grok 3 Mini Fast',
    description: 'Faster version of the Grok 3 Mini model with identical response quality but significantly reduced latency. Ideal for latency-sensitive applications.',
    contextWindow: 131072,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json, LLM_IF_Tools_WebSearch, LLM_IF_OAI_Reasoning],
    parameterSpecs: [
      { paramId: 'llmVndOaiReasoningEffort' },
      { paramId: 'llmVndXaiSearchMode' }, { paramId: 'llmVndXaiSearchSources' }, { paramId: 'llmVndXaiSearchDateFilter' }
    ],
    chatPrice: { input: 0.6, output: 4, cache: { cType: 'oai-ac', read: 0.15 } },
    benchmark: { cbaElo: 1354 - 1 /* still unreported! assuming below grok-3-mini just for cost */ },
  },

  // Grok 2
  {
    idPrefix: 'grok-2-vision-1212',
    label: 'Grok 2 Vision (1212)',
    description: 'xAI model grok-2-vision-1212 with image and text input capabilities. Supports text generation with a 32,768 token context window.',
    contextWindow: 32768,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision, LLM_IF_OAI_Json],
    chatPrice: { input: 2, output: 10 },
    // Fuzzy matched with "grok-2-2024-08-13" (1288) => wrong, but still we need a fallback
    benchmark: { cbaElo: 1288 },
  },
  {
    hidden: true, // IMAGE model - does not chat (!) - is actually not returned by the list endpoint, but we have it anyway for our records
    idPrefix: 'grok-2-image-1212',
    label: 'Grok 2 Image (1212)',
    description: 'xAI model for image generation. Each generated image costs $0.07.',
    contextWindow: 131072,
    maxCompletionTokens: undefined,
    interfaces: [],
  },
  {
    idPrefix: 'grok-2-1212',
    label: 'Grok 2 (1212)',
    description: 'xAI model grok-2-1212 with text input capabilities. Supports text generation with a 131,072 token context window.',
    contextWindow: 131072,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Json],
    chatPrice: { input: 2, output: 10 },
    // Fuzzy matched with "grok-2-2024-08-13" (1288) => wrong, but still we need a fallback
    benchmark: { cbaElo: 1288 },
  },

  // Grok Beta (all deprecated)
  {
    isLegacy: true,
    idPrefix: 'grok-vision-beta',
    label: 'Grok Vision Beta',
    description: 'xAI model grok-vision-beta with image and text input capabilities. Supports text generation with an 8,192 token context window.',
    contextWindow: 8192,
    maxCompletionTokens: undefined,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn, LLM_IF_OAI_Vision],
    chatPrice: { input: 5, output: 15 },
    hidden: true,
  },
  {
    isLegacy: true,
    idPrefix: 'grok-beta',
    label: 'Grok Beta',
    description: 'xAI model grok-beta (deprecated) with text input capabilities. Supports text generation with a 131,072 token context window.',
    contextWindow: 131072,
    maxCompletionTokens: 16384,
    interfaces: [LLM_IF_OAI_Chat, LLM_IF_OAI_Fn],
    chatPrice: { input: 5, output: 15 },
    hidden: true,
  },
];


// xAI Model Descriptions
export async function xaiModelDescriptions(access: OpenAIAccessSchema): Promise<ModelDescriptionSchema[]> {

  // List models
  const { headers, url } = openAIAccess(access, null, '/v1/language-models');
  const modelsResponse = await fetchJsonOrTRPCThrow({ url, headers, name: 'xAI' });

  const xaiModels = wireXAIModelsListSchema.parse(modelsResponse);

  return xaiModels.models.reduce((acc, xm) => {

    // Fallback for unknown models
    const unknownModelFallback: ManualMapping = {
      idPrefix: xm.id,
      label: _xaiFormatNewModelLabel(xm.id),
      description: `xAI model ${xm.id}`,
      contextWindow: 16384,
      interfaces: [
        LLM_IF_OAI_Chat,
        LLM_IF_OAI_Fn,
        ...(xm.input_modalities?.includes('image') ? [LLM_IF_OAI_Vision] : []),
      ],
      ...(xm.prompt_text_token_price != null && xm.completion_text_token_price != null && {
        chatPrice: {
          input: xm.prompt_text_token_price / 10000, // Scaling factor applied as per API data
          output: xm.completion_text_token_price / 10000,
        },
      }),
    };

    // xAI model description
    const modelDescription = fromManualMapping(_knownXAIChatModels, xm.id, xm.created, undefined, unknownModelFallback);

    // quick validation for non-text modalities
    const knownInputModalities = ['text', 'image'];
    const knownOutputModalities = ['text'];
    const nonTextInput = xm.input_modalities?.filter(m => !knownInputModalities.includes(m)) || [];
    const nonTextOutput = xm.output_modalities?.filter(m => !knownOutputModalities.includes(m)) || [];
    if (nonTextInput.length > 0 || nonTextOutput.length > 0) {
      console.warn(`[xAI Model Check] Model '${xm.id}' has non-text modalities. Input: [${nonTextInput.join(', ')}], Output: [${nonTextOutput.join(', ')}]`);
      modelDescription.label += ' 🧩';
      let modalityDetails = '';
      if (nonTextInput.length > 0) modalityDetails += ` Input: ${nonTextInput.join(', ')}.`;
      if (nonTextOutput.length > 0) modalityDetails += ` Output: ${nonTextOutput.join(', ')}.`;
      modelDescription.description += ` Supports additional modalities.${modalityDetails}`;
    }

    acc.push(modelDescription);

    // NOTE: disabled, as this is not useful
    // if there are aliases, add them as 'symlinked' models
    // if (xm.aliases?.length) {
    //   xm.aliases.forEach((alias) => {
    //     const aliasedModel = fromManualMapping([{
    //       idPrefix: alias,
    //       label: alias,
    //       symLink: xm.id,
    //       description: `xAI model ${alias}`,
    //       contextWindow: 16384,
    //       interfaces: unknownModelFallback.interfaces,
    //     }], alias, xm.created, xm.updated, unknownModelFallback);
    //     acc.push(aliasedModel);
    //   });
    // }

    return acc;
  }, [] as ModelDescriptionSchema[]);
}

// manual sort order - your desired order
const _xaiIdStartsWithOrder = [
  'grok-4-0709',
  'grok-3-fast',
  'grok-3',
  'grok-3-mini-fast',
  'grok-3-mini',
  'grok-2-vision-1212',
  'grok-2-1212',
  'grok-vision-beta',
  'grok-beta',
];

export function xaiModelSort(a: ModelDescriptionSchema, b: ModelDescriptionSchema): number {
  // First try exact matches with the order array
  const aExact = _xaiIdStartsWithOrder.indexOf(a.id);
  const bExact = _xaiIdStartsWithOrder.indexOf(b.id);
  
  // If both have exact matches, use those positions
  if (aExact !== -1 && bExact !== -1)
    return aExact - bExact;
  
  // If only one has exact match, prioritize it
  if (aExact !== -1) return -1;
  if (bExact !== -1) return 1;
  
  // Fall back to prefix matching for unknown models
  const aStartsWith = _xaiIdStartsWithOrder.findIndex((prefix) => a.id.startsWith(prefix));
  const bStartsWith = _xaiIdStartsWithOrder.findIndex((prefix) => b.id.startsWith(prefix));

  if (aStartsWith !== bStartsWith)
    return aStartsWith - bStartsWith;

  return b.label.localeCompare(a.label);
}

function _xaiFormatNewModelLabel(modelId: string): string {
  if (!modelId) return 'Unknown Model';

  const parts = modelId.split('-');
  if (parts.length)
    parts[0] = parts[0].charAt(0).toUpperCase() + parts[0].slice(1);

  let hasBeta = false;
  const cleanedParts = parts.filter(part => {
    if (part.toLowerCase() === 'beta') {
      hasBeta = true;
      return false;
    }
    return true;
  });

  return '[new] ' + cleanedParts.join(' ') + (hasBeta ? ' (beta)' : '');
}


export const wireXAIModelSchema = z.object({
  id: z.string(),
  object: z.literal('model'),
  owned_by: z.literal('xai').or(z.string()),

  // timestamps
  created: z.number().optional(),
  updated: z.number().optional(),
  version: z.string().optional(),

  // modalities
  input_modalities: z.array(z.string()),    // 'text', 'image', etc.
  output_modalities: z.array(z.string()),   // 'text', 'image', etc.

  // pricing - FIXME: SCALE UNKNOWN for now
  prompt_text_token_price: z.number().optional(),
  prompt_image_token_price: z.number().optional(),
  completion_text_token_price: z.number().optional(),
  cached_prompt_text_token_price: z.number().optional(),

  // System information
  fingerprint: z.string().optional(),

  // Aliases for models
  aliases: z.array(z.string()).optional(),
});

export const wireXAIModelsListSchema = z.object({
  models: z.array(wireXAIModelSchema),
});



================================================
FILE: src/modules/llms/vendors/ApproximateCosts.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, Chip } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { formatModelsCost } from '~/common/util/costUtils';
import { useCostMetricsForLLMService } from '~/common/stores/metrics/store-metrics';
import { useIsMobile } from '~/common/components/useMatchMedia';


const _styles = {

  box: {
    // undo the padding of the parent
    m: 'calc(-1* var(--Card-padding))',
    mb: 0,
    p: 'var(--Card-padding)',

    // style
    fontSize: 'sm',
    backgroundColor: 'neutral.softBg',
    // boxShadow: 'inset 0px 1px 4px -2px rgba(0, 0, 0, 0.2)',

    // border
    borderBottom: '1px solid',
    borderBottomColor: 'divider',

    // layout
    display: 'grid',
    gap: 1,
  } as const,

  showCollapsed: {
    display: 'inline-flex',
    alignItems: 'center',
    gap: 1,
  } as const,

  chipLess: {
    ml: 1,
  } as const,

  chipMore: {
    ml: 'auto',
  } as const,

} as const;

export function ApproximateCosts(props: {
  serviceId?: DModelsServiceId,
  whoSaved?: string,
  children?: React.ReactNode,
}) {

  // state
  const [expanded, setExpanded] = React.useState(false);

  // external state
  const isMobile = useIsMobile();
  const { totalCosts, totalSavings, totalInputTokens, totalOutputTokens, firstUsageDate, usageCount, partialMessageUsages } =
    useCostMetricsForLLMService(props.serviceId);

  const hasSaved = totalSavings && totalSavings > 0;

  return React.useMemo(() => {
    if (!totalCosts)
      return !props.children ? undefined
        : <Box sx={_styles.box}>{props.children}</Box>;

    return (
      <Box sx={_styles.box}>
        {expanded ? <>
          <Box>
            Approximate costs: <b>{formatModelsCost(totalCosts)}</b>
            {' · '}<span style={{ opacity: 0.75 }}>Costs are partial,
            local to this instance, and may not reflect the latest pricing.
            Starting <TimeAgo date={firstUsageDate} /> we counted {usageCount?.toLocaleString()} requests
            {(partialMessageUsages > usageCount / 10) ? ` (${partialMessageUsages} of which were partial)` : ''}
            {' '}and {(totalInputTokens + totalOutputTokens).toLocaleString()} tokens.</span>
            {/*<ExternalLink href='https://console.anthropic.com/settings/usage'>Anthropic usage</ExternalLink>*/}
            <Chip
              size='sm'
              color={hasSaved ? 'success' : 'neutral'}
              variant='outlined'
              onClick={() => setExpanded(false)}
              sx={_styles.chipLess}
            >
              Less...
            </Chip>
          </Box>
          {!!hasSaved && <Box sx={{ display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
            <Box component='span' sx={{ color: 'success.plainColor' }}>Thanks to {props.whoSaved ? 'smart caching' : 'caching'}, {props.whoSaved || 'you saved '} approximately <b>{formatModelsCost(totalSavings)}</b>.</Box>
            {/*{advanced.on && <Button variant='outlined' size='sm' color='success' onClick={handleResetCosts}>*/}
            {/*  Reset*/}
            {/*</Button>}*/}
          </Box>}
        </> : (
          <Box sx={_styles.showCollapsed}>
            <div>
              {(hasSaved && isMobile) ? 'Spend' : 'Approximate costs'}: <b>{formatModelsCost(totalCosts)}</b>
              {!!hasSaved && <> · saved <Box component='span' sx={{ color: 'success.plainColor' }}><b>{formatModelsCost(totalSavings)}</b></Box></>}
            </div>
            {' '}<Chip
            size='sm'
            color={hasSaved ? 'success' : 'neutral'}
            variant='outlined'
            onClick={() => setExpanded(true)}
            sx={_styles.chipMore}
          >
            More...
          </Chip>
          </Box>
        )}
      </Box>
    );
  }, [expanded, firstUsageDate, hasSaved, isMobile, partialMessageUsages, props.children, props.whoSaved, totalCosts, totalInputTokens, totalOutputTokens, totalSavings, usageCount]);
}


================================================
FILE: src/modules/llms/vendors/IModelVendor.ts
================================================
import type { BackendCapabilities } from '~/modules/backend/store-backend-capabilities';

import type { DLLM } from '~/common/stores/llms/llms.types';

import type { ModelDescriptionSchema } from '../server/llm.server.types';
import type { ModelVendorId } from './vendors.registry';


export interface IModelVendor<TServiceSettings extends Record<string, any> = {}, TAccess = unknown> {
  readonly id: ModelVendorId;
  readonly name: string;
  readonly displayRank: number; // [10...] Foundation Models, [30...] 3rd party Clouds, [40...] Aggregators, [50...] Local Models
  readonly location: 'local' | 'cloud';
  readonly brandColor?: string;
  readonly instanceLimit?: number;
  readonly hasFreeModels?: boolean;
  readonly hasServerConfigFn?: (backendCapabilities: BackendCapabilities) => boolean; // used to show a 'green checkmark' in the list of vendors when adding services
  readonly hasServerConfigKey?: keyof BackendCapabilities;

  /// abstraction interface ///

  initializeSetup?(): TServiceSettings;

  validateSetup?(setup: TServiceSettings): boolean; // client-side only, accessed via useServiceSetup

  getTransportAccess(setup?: Partial<TServiceSettings>): TAccess;

  rateLimitChatGenerate?(llm: DLLM, setup: Partial<TServiceSettings>): Promise<void>;

  rpcUpdateModelsOrThrow(
    access: TAccess,
  ): Promise<{ models: ModelDescriptionSchema[] }>;

}



================================================
FILE: src/modules/llms/vendors/useServiceSetup.ts
================================================
import * as React from 'react';
import { useShallow } from 'zustand/react/shallow';

import type { DLLM } from '~/common/stores/llms/llms.types';
import type { DModelsService, DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { useShallowStabilizer } from '~/common/util/hooks/useShallowObject';
import { useModelsStore } from '~/common/stores/llms/store-llms';

import type { IModelVendor } from './IModelVendor';
import { vendorHasBackendCap } from './vendor.helpers';


const stableNoLlms: DLLM[] = [];

/**
 * Service-specific read/write - great time saver
 */
export function useServiceSetup<TServiceSettings extends object, TAccess>(serviceId: DModelsServiceId, vendor: IModelVendor<TServiceSettings, TAccess>): {
  service: DModelsService<TServiceSettings> | null;
  serviceAccess: TAccess;

  serviceHasCloudTenantConfig: boolean;
  serviceHasLLMs: boolean;
  serviceHasVisibleLLMs: boolean;
  serviceSetupValid: boolean;

  partialSettings: Partial<TServiceSettings> | null;
  updateSettings: (partialSettings: Partial<TServiceSettings>) => void;
} {

  // stabilize the transport access
  const stabilizeTransportAccess = useShallowStabilizer<TAccess>();

  // invalidates only when the setup changes
  const { updateServiceSettings, ...rest } = useModelsStore(useShallow(({ llms, sources, updateServiceSettings }) => {

    // find the service | null
    const service: DModelsService<TServiceSettings> | null = sources.find(s => s.id === serviceId) ?? null;

    // (safe) service-derived properties
    const serviceSetupValid = (service?.setup && vendor?.validateSetup) ? vendor.validateSetup(service.setup as TServiceSettings) : false;
    const serviceLLms = service ? llms.filter(llm => llm.sId === serviceId) : stableNoLlms;
    const serviceAccess = stabilizeTransportAccess(vendor.getTransportAccess(service?.setup));

    return {
      service,
      serviceAccess,

      serviceHasCloudTenantConfig: vendorHasBackendCap(vendor),
      serviceHasLLMs: !!serviceLLms.length,
      serviceHasVisibleLLMs: !!serviceLLms.find(llm => !llm.hidden),
      serviceSetupValid: serviceSetupValid,

      partialSettings: service?.setup ?? null, // NOTE: do not use - prefer ACCESS; only used in 1 edge case now
      updateServiceSettings,
    };
  }));

  // convenience functions
  const updateSettings = React.useCallback((partialSetup: Partial<TServiceSettings>) => {
    updateServiceSettings<TServiceSettings>(serviceId, partialSetup);
  }, [serviceId, updateServiceSettings]);

  return {
    ...rest,
    updateSettings,
  };
}


================================================
FILE: src/modules/llms/vendors/vendor.helpers.ts
================================================
import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { findModelsServiceOrNull } from '~/common/stores/llms/store-llms';

import type { IModelVendor } from './IModelVendor';
import { findModelVendor } from './vendors.registry';



export function findServiceAccessOrThrow<TServiceSettings extends object = {}, TAccess = unknown>(serviceId: DModelsServiceId) {

  const service = findModelsServiceOrNull<TServiceSettings>(serviceId);
  if (!service)
    throw new Error(`Models Service ${serviceId} not found`);

  const vendor = findModelVendor<TServiceSettings, TAccess>(service.vId);
  if (!vendor)
    throw new Error(`Model Service ${serviceId} has no vendor`);

  return {
    service,
    serviceSettings: service.setup,
    transportAccess: vendor.getTransportAccess(service.setup),
    vendor,
  };
}

export function vendorHasBackendCap<TServiceSettings extends Record<string, any> = {}, TAccess = unknown>(vendor: IModelVendor<TServiceSettings, TAccess>) {
  const backendCaps = getBackendCapabilities();
  return vendor.hasServerConfigFn ? vendor.hasServerConfigFn(backendCaps)
    : vendor.hasServerConfigKey ? !!backendCaps[vendor.hasServerConfigKey] : false;
}



================================================
FILE: src/modules/llms/vendors/vendors.registry.ts
================================================
import { ModelVendorAlibaba } from './alibaba/alibaba.vendor';
import { ModelVendorAnthropic } from './anthropic/anthropic.vendor';
import { ModelVendorAzure } from './azure/azure.vendor';
import { ModelVendorDeepseek } from './deepseek/deepseekai.vendor';
import { ModelVendorGemini } from './gemini/gemini.vendor';
import { ModelVendorGroq } from './groq/groq.vendor';
import { ModelVendorLMStudio } from './lmstudio/lmstudio.vendor';
import { ModelVendorLocalAI } from './localai/localai.vendor';
import { ModelVendorMistral } from './mistral/mistral.vendor';
import { ModelVendorOllama } from './ollama/ollama.vendor';
import { ModelVendorOpenAI } from './openai/openai.vendor';
import { ModelVendorOpenPipe } from './openpipe/openpipe.vendor';
import { ModelVendorOpenRouter } from './openrouter/openrouter.vendor';
import { ModelVendorPerplexity } from './perplexity/perplexity.vendor';
import { ModelVendorTogetherAI } from './togetherai/togetherai.vendor';
import { ModelVendorXAI } from './xai/xai.vendor';

import type { IModelVendor } from './IModelVendor';


export type ModelVendorId =
  | 'alibaba'
  | 'anthropic'
  | 'azure'
  | 'deepseek'
  | 'googleai'
  | 'groq'
  | 'lmstudio'
  | 'localai'
  | 'mistral'
  | 'ollama'
  | 'openai'
  | 'openpipe'
  | 'openrouter'
  | 'perplexity'
  | 'togetherai'
  | 'xai'
  ;

/** Global: Vendor Instances Registry **/
const MODEL_VENDOR_REGISTRY: Record<ModelVendorId, IModelVendor> = {
  alibaba: ModelVendorAlibaba,
  anthropic: ModelVendorAnthropic,
  azure: ModelVendorAzure,
  deepseek: ModelVendorDeepseek,
  googleai: ModelVendorGemini,
  groq: ModelVendorGroq,
  lmstudio: ModelVendorLMStudio,
  localai: ModelVendorLocalAI,
  mistral: ModelVendorMistral,
  ollama: ModelVendorOllama,
  openai: ModelVendorOpenAI,
  openpipe: ModelVendorOpenPipe,
  openrouter: ModelVendorOpenRouter,
  perplexity: ModelVendorPerplexity,
  togetherai: ModelVendorTogetherAI,
  xai: ModelVendorXAI,
} as Record<string, IModelVendor>;


export function findAllModelVendors(): IModelVendor[] {
  const modelVendors = Object.values(MODEL_VENDOR_REGISTRY);
  modelVendors.sort((a, b) => a.displayRank - b.displayRank);
  return modelVendors;
}

export function findModelVendor<TServiceSettings extends object = {}, TAccess = unknown>(
  vendorId?: ModelVendorId,
): IModelVendor<TServiceSettings, TAccess> | null {
  return vendorId ? (MODEL_VENDOR_REGISTRY[vendorId] as IModelVendor<TServiceSettings, TAccess>) ?? null : null;
}

// export function getDefaultModelVendor(): IModelVendor {
//   return MODEL_VENDOR_REGISTRY.openai;
// }


================================================
FILE: src/modules/llms/vendors/alibaba/alibaba.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';
import { ModelVendorOpenAI } from '../openai/openai.vendor';


interface DAlibabaServiceSettings {
  alibabaOaiKey: string;
  alibabaOaiHost: string;
}

export const ModelVendorAlibaba: IModelVendor<DAlibabaServiceSettings, OpenAIAccessSchema> = {
  id: 'alibaba',
  name: 'Alibaba Cloud',
  displayRank: 35,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmAlibaba',

  // functions
  initializeSetup: () => ({
    alibabaOaiKey: '',
    alibabaOaiHost: '',
  }),
  validateSetup: (setup) => {
    return setup.alibabaOaiKey?.length >= 32;
  },
  getTransportAccess: (partialSetup) => ({
    dialect: 'alibaba',
    oaiKey: partialSetup?.alibabaOaiKey || '',
    oaiOrg: '',
    oaiHost: partialSetup?.alibabaOaiHost || '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('alibaba' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,
};



================================================
FILE: src/modules/llms/vendors/alibaba/AlibabaServiceSetup.tsx
================================================
import * as React from 'react';

import { Typography } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { ExternalLink } from '~/common/components/ExternalLink';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormTextField } from '~/common/components/forms/FormTextField';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorAlibaba } from './alibaba.vendor';


const CLIENT_ALIBABA_DEFAULT_HOST = 'https://dashscope-intl.aliyuncs.com/compatible-mode';
const ALIBABA_REG_LINK = 'https://bailian.console.alibabacloud.com/?apiKey=1#/api-key';
const ALIBABA_MODELS = 'https://www.alibabacloud.com/help/en/model-studio/getting-started/models';


export function AlibabaServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const advanced = useToggleableBoolean();

  // external state
  const {
    service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs,
    serviceSetupValid, updateSettings,
  } = useServiceSetup(props.serviceId, ModelVendorAlibaba);

  // derived state
  const { oaiKey: alibabaOaiKey, oaiHost: alibabaOaiHost } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;
  const shallFetchSucceed = !needsUserKey || (!!alibabaOaiKey && serviceSetupValid);
  const showKeyError = !!alibabaOaiKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>

    <ApproximateCosts serviceId={service?.id}>
      <div>
        <Typography level='body-sm'>
          Alibaba Cloud supports the <ExternalLink href={ALIBABA_MODELS}>following models</ExternalLink> via
          the OpenAI-compatible endpoint.
        </Typography>
      </div>
    </ApproximateCosts>

    <FormInputKey
      autoCompleteId='alibaba-key' label='Alibaba Cloud API Key'
      rightLabel={needsUserKey
        ? alibabaOaiKey && <Link level='body-sm' href={ALIBABA_REG_LINK} target='_blank'>get API key</Link>
        : <AlreadySet />
      }
      value={alibabaOaiKey}
      onChange={value => updateSettings({ alibabaOaiKey: value })}
      required={needsUserKey} isError={showKeyError}
      placeholder={needsUserKey ? 'sk-...' : ''}
    />

    {/*<Typography level='body-sm'>*/}
    {/*  Alibaba Cloud Qwen models provide high-quality language model capabilities.*/}
    {/*  See the <ExternalLink href={ALIBABA_REG_LINK}>Alibaba Cloud Model Studio</ExternalLink> for more information.*/}
    {/*</Typography>*/}

    {advanced.on && <FormTextField
      autoCompleteId='alibaba-host'
      title='API Endpoint'
      tooltip={`The API endpoint for the Alibaba Cloud OpenAI service, to be used instead of the default endpoint.`}
      placeholder={`e.g., ${CLIENT_ALIBABA_DEFAULT_HOST}`}
      value={alibabaOaiHost}
      onChange={text => updateSettings({ alibabaOaiHost: text })}
    />}

    <SetupFormRefetchButton refetch={refetch} disabled={/*!shallFetchSucceed ||*/ isFetching} loading={isFetching} error={isError} advanced={advanced} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/anthropic/anthropic.vendor.ts
================================================
import { apiAsync } from '~/common/util/trpc.client';

import type { AnthropicAccessSchema } from '../../server/anthropic/anthropic.router';
import type { IModelVendor } from '../IModelVendor';


// special symbols
export const isValidAnthropicApiKey = (apiKey?: string) => !!apiKey && (apiKey.startsWith('sk-') ? apiKey.length >= 39 : apiKey.length > 1);

interface DAnthropicServiceSettings {
  anthropicKey: string;
  anthropicHost: string;
  heliconeKey: string;
}

export const ModelVendorAnthropic: IModelVendor<DAnthropicServiceSettings, AnthropicAccessSchema> = {
  id: 'anthropic',
  name: 'Anthropic',
  displayRank: 12,
  location: 'cloud',
  brandColor: '#cc785c',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmAnthropic',

  // functions
  getTransportAccess: (partialSetup): AnthropicAccessSchema => ({
    dialect: 'anthropic',
    anthropicKey: partialSetup?.anthropicKey || '',
    anthropicHost: partialSetup?.anthropicHost || null,
    heliconeKey: partialSetup?.heliconeKey || null,
  }),


  // List Models
  rpcUpdateModelsOrThrow: async (access) => await apiAsync.llmAnthropic.listModels.query({ access }),

};



================================================
FILE: src/modules/llms/vendors/anthropic/AnthropicServiceSetup.tsx
================================================
import * as React from 'react';

import { Alert, Box, FormControl, Typography } from '@mui/joy';

import { useChatAutoAI } from '../../../../apps/chat/store-app-chat';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { ExternalLink } from '~/common/components/ExternalLink';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormSwitchControl } from '~/common/components/forms/FormSwitchControl';
import { FormTextField } from '~/common/components/forms/FormTextField';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { isValidAnthropicApiKey, ModelVendorAnthropic } from './anthropic.vendor';


export function AnthropicServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const advanced = useToggleableBoolean();

  // external state
  const { service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorAnthropic);

  const { autoVndAntBreakpoints, setAutoVndAntBreakpoints } = useChatAutoAI();

  // derived state
  const { anthropicKey, anthropicHost, heliconeKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  const keyValid = isValidAnthropicApiKey(anthropicKey);
  const keyError = (/*needsUserKey ||*/ !!anthropicKey) && !keyValid;
  const shallFetchSucceed = anthropicKey ? keyValid : (!needsUserKey || !!anthropicHost);

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>

    <ApproximateCosts serviceId={service?.id} whoSaved='Big-AGI saved you'>
      <Box sx={{ level: 'body-sm' }}>
        Enjoy <b>Sonnet</b>, <b>Opus</b> and <b>Haiku</b>. Experiencing Issues? Check <Link href='https://status.anthropic.com/' level='body-sm' target='_blank'>Anthropic status</Link>.
      </Box>
    </ApproximateCosts>

    <FormInputKey
      autoCompleteId='anthropic-key' label={!!anthropicHost ? 'API Key' : 'Anthropic API Key'}
      rightLabel={<>{needsUserKey
        ? !anthropicKey && <Link level='body-sm' href='https://www.anthropic.com/earlyaccess' target='_blank'>request Key</Link>
        : <AlreadySet />
      } {anthropicKey && keyValid && <Link level='body-sm' href='https://console.anthropic.com/settings/usage' target='_blank'>show tokens usage</Link>}
      </>}
      value={anthropicKey} onChange={value => updateSettings({ anthropicKey: value })}
      required={needsUserKey} isError={keyError}
      placeholder='sk-...'
    />

    <FormSwitchControl
      title='Auto-Caching' on='Enabled' off='Disabled'
      tooltip='Auto-breakpoints: 3 breakpoints are always set on the System instruction and on the last 2 User messages. This leaves the user with 1 breakpoint of their choice. (max 4)'
      description={autoVndAntBreakpoints ? <>Last 2 user messages</> : 'Disabled'}
      checked={autoVndAntBreakpoints}
      onChange={setAutoVndAntBreakpoints}
    />


    <FormControl orientation='horizontal' sx={{ flexWrap: 'wrap', justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart
        title='Caching'
        description='Toggle per-Message'
        tooltip='You can turn on/off caching on the fly for each message. Caching makes new input a bit more expensive, and reusing the cached input much cheaper. See Anthropic docs for details and pricing.'
      />
      <Typography level='title-sm'>
        {autoVndAntBreakpoints ? 'User & Auto' : 'User-driven'}
      </Typography>
    </FormControl>

    {advanced.on && <FormTextField
      autoCompleteId='anthropic-host'
      title='API Host'
      description={<>e.g., <Link level='body-sm' href='https://github.com/enricoros/big-agi/blob/main/docs/config-aws-bedrock.md' target='_blank'>bedrock-claude</Link></>}
      placeholder='deployment.service.region.amazonaws.com'
      isError={false}
      value={anthropicHost || ''}
      onChange={text => updateSettings({ anthropicHost: text })}
    />}

    {advanced.on && <FormTextField
      autoCompleteId='anthropic-helicone-key'
      title='Helicone Key' disabled={!!anthropicHost}
      description={<>Generate <Link level='body-sm' href='https://www.helicone.ai/keys' target='_blank'>here</Link></>}
      placeholder='sk-...'
      value={heliconeKey || ''}
      onChange={text => updateSettings({ heliconeKey: text })}
    />}

    {!!heliconeKey && <Alert variant='soft' color='success'>
      Advanced: You set the Helicone key, and Anthropic text will be routed through Helicone.
    </Alert>}

    <SetupFormRefetchButton refetch={refetch} disabled={!shallFetchSucceed || isFetching} loading={isFetching} error={isError} advanced={advanced} />

    {isError && <InlineError error={error} />}

  </>;
}


================================================
FILE: src/modules/llms/vendors/azure/azure.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


// special symbols
export const isValidAzureApiKey = (apiKey?: string) => !!apiKey && apiKey.length >= 32;

interface DAzureServiceSettings {
  azureEndpoint: string;
  azureKey: string;
}

/** Implementation Notes for the Azure Vendor
 *
 * Listing models for Azure OpenAI is complex. The "Azure OpenAI Model List" API lists every model that can
 * be deployed, including numerous models that are not accessible by the user. What the users want are the
 * "deployed" models.
 *
 *   1. To list those, there was an API available in the past, but it was removed. It was about hitting the
 *      "/openai/deployments?api-version=2023-03-15-preview" path on the endpoint. See:
 *      https://github.com/openai/openai-python/issues/447#issuecomment-1730976835
 *
 *   2. Still looking for a solution - in the meantime the way to go seems to be to manually get the full URL
 *      of every "Deployment" (Model) and hit the URL directly. However the user will need to fill in the full
 *      model sheet, as details are not available just from the URL.
 *
 * Work in progress...
 */
export const ModelVendorAzure: IModelVendor<DAzureServiceSettings, OpenAIAccessSchema> = {
  id: 'azure',
  name: 'Azure OpenAI',
  displayRank: 30,
  location: 'cloud',
  instanceLimit: 2,
  hasServerConfigKey: 'hasLlmAzureOpenAI',

  // functions
  getTransportAccess: (partialSetup): OpenAIAccessSchema => ({
    dialect: 'azure',
    oaiKey: partialSetup?.azureKey || '',
    oaiOrg: '',
    oaiHost: partialSetup?.azureEndpoint || '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('azure' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};


================================================
FILE: src/modules/llms/vendors/azure/AzureServiceSetup.tsx
================================================
import * as React from 'react';

import { Chip, Typography } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { ExternalLink } from '~/common/components/ExternalLink';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormTextField } from '~/common/components/forms/FormTextField';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { asValidURL } from '~/common/util/urlUtils';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { isValidAzureApiKey, ModelVendorAzure } from './azure.vendor';


export function AzureServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const [checkboxExpanded, setCheckboxExpanded] = React.useState(false);

  // external state
  const { service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorAzure);

  // derived state
  const { oaiKey: azureKey, oaiHost: azureEndpoint } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  const keyValid = isValidAzureApiKey(azureKey);
  const keyError = (/*needsUserKey ||*/ !!azureKey) && !keyValid;
  const hostValid = !!asValidURL(azureEndpoint);
  const hostError = !!azureEndpoint && !hostValid;
  const shallFetchSucceed = azureKey ? keyValid : !needsUserKey;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>

    <ApproximateCosts>
      <div>
        <Typography level='body-sm'>
          We support the <ExternalLink href='https://learn.microsoft.com/en-us/azure/ai-services/openai/overview'>Azure OpenAI Service</ExternalLink>.
          See more for Azure AI Foundry.
          {checkboxExpanded && <>
            {' '}This is because the <ExternalLink href='https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio'>Azure
            AI Foundry</ExternalLink> requires a different model definition/enumeration, which <ExternalLink icon='issue' href='https://github.com/enricoros/big-AGI/issues/757'>not supported yet</ExternalLink> (PRs welcome).
          </>}
          <Chip component='span' variant='outlined' sx={{ ml: 1, fontSize: '0.75rem' }} onClick={() => setCheckboxExpanded(on => !on)}>
            Show {checkboxExpanded ? 'less' : 'more'}
          </Chip>
        </Typography>
      </div>
    </ApproximateCosts>

    <FormTextField
      autoCompleteId='azure-endpoint'
      title='Azure Endpoint'
      description={<Link level='body-sm' href='https://github.com/enricoros/big-agi/blob/main/docs/config-azure-openai.md' target='_blank'>configuration</Link>}
      placeholder='https://your-resource-name.openai.azure.com/'
      isError={hostError}
      value={azureEndpoint}
      onChange={text => updateSettings({ azureEndpoint: text })}
    />

    <FormInputKey
      autoCompleteId='azure-key' label='Azure Key'
      rightLabel={<>{needsUserKey
        ? !azureKey && <Link level='body-sm' href='https://azure.microsoft.com/en-us/products/ai-services/openai-service' target='_blank'>request Key</Link>
        : <AlreadySet />}
      </>}
      value={azureKey} onChange={value => updateSettings({ azureKey: value })}
      required={needsUserKey} isError={keyError}
      placeholder='...'
    />

    <SetupFormRefetchButton refetch={refetch} disabled={!shallFetchSucceed || isFetching} loading={isFetching} error={isError} />

    {isError && <InlineError error={error} />}

  </>;
}


================================================
FILE: src/modules/llms/vendors/deepseek/deepseekai.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


export interface DDeepseekServiceSettings {
  deepseekKey: string;
}

export const ModelVendorDeepseek: IModelVendor<DDeepseekServiceSettings, OpenAIAccessSchema> = {
  id: 'deepseek',
  name: 'Deepseek',
  displayRank: 16,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmDeepseek',

  // functions
  initializeSetup: () => ({
    deepseekKey: '',
  }),
  validateSetup: (setup) => {
    return setup.deepseekKey?.length >= 35;
  },
  getTransportAccess: (partialSetup) => ({
    dialect: 'deepseek',
    oaiKey: partialSetup?.deepseekKey || '',
    oaiOrg: '',
    oaiHost: '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('Deepseek' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};



================================================
FILE: src/modules/llms/vendors/deepseek/DeepseekAIServiceSetup.tsx
================================================
import * as React from 'react';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorDeepseek } from './deepseekai.vendor';


const DEEPSEEK_REG_LINK = 'https://platform.deepseek.com/api_keys';


export function DeepseekAIServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const advanced = useToggleableBoolean();

  // external state
  const {
    service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs,
    serviceSetupValid, updateSettings,
  } = useServiceSetup(props.serviceId, ModelVendorDeepseek);

  // derived state
  const { oaiKey: deepseekKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  // validate if url is a well formed proper url with zod
  const shallFetchSucceed = !needsUserKey || (!!deepseekKey && serviceSetupValid);
  const showKeyError = !!deepseekKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);


  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='deepseek-key' label='Deepseek Key'
      rightLabel={<>{needsUserKey
        ? !deepseekKey && <Link level='body-sm' href={DEEPSEEK_REG_LINK} target='_blank'>request Key</Link>
        : <AlreadySet />}
      </>}
      value={deepseekKey} onChange={value => updateSettings({ deepseekKey: value })}
      required={needsUserKey} isError={showKeyError}
      placeholder='...'
    />

    <SetupFormRefetchButton refetch={refetch} disabled={/*!shallFetchSucceed ||*/ isFetching} loading={isFetching} error={isError} advanced={advanced} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/gemini/gemini.vendor.ts
================================================
import { apiAsync } from '~/common/util/trpc.client';

import type { GeminiAccessSchema } from '../../server/gemini/gemini.router';
import type { GeminiWire_Safety } from '~/modules/aix/server/dispatch/wiretypes/gemini.wiretypes';
import type { IModelVendor } from '../IModelVendor';


interface DGeminiServiceSettings {
  geminiKey: string;
  geminiHost: string;
  minSafetyLevel: GeminiWire_Safety.HarmBlockThreshold;
}

// interface LLMOptionsGemini {
//   llmRef: string;
//   stopSequences: string[];  // up to 5 sequences that will stop generation (optional)
//   candidateCount: number;   // 1...8 number of generated responses to return (optional)
//   maxOutputTokens: number;  // if unset, this will default to outputTokenLimit (optional)
//   temperature: number;      // 0...1 Controls the randomness of the output. (optional)
//   topP: number;             // 0...1 The maximum cumulative probability of tokens to consider when sampling (optional)
//   topK: number;             // 1...100 The maximum number of tokens to consider when sampling (optional)
// }


export const ModelVendorGemini: IModelVendor<DGeminiServiceSettings, GeminiAccessSchema> = {
  id: 'googleai',
  name: 'Gemini',
  displayRank: 14,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmGemini',

  // functions
  initializeSetup: () => ({
    geminiKey: '',
    geminiHost: '',
    minSafetyLevel: 'HARM_BLOCK_THRESHOLD_UNSPECIFIED',
  }),
  validateSetup: (setup) => {
    return setup.geminiKey?.length > 0;
  },
  getTransportAccess: (partialSetup): GeminiAccessSchema => ({
    dialect: 'gemini',
    geminiKey: partialSetup?.geminiKey || '',
    geminiHost: partialSetup?.geminiHost || '',
    minSafetyLevel: partialSetup?.minSafetyLevel || 'HARM_BLOCK_THRESHOLD_UNSPECIFIED',
  }),

  // List Models
  rpcUpdateModelsOrThrow: async (access) => await apiAsync.llmGemini.listModels.query({ access }),

};



================================================
FILE: src/modules/llms/vendors/gemini/GeminiServiceSetup.tsx
================================================
import * as React from 'react';

import { FormControl, FormHelperText, Option, Select } from '@mui/joy';
import HealthAndSafetyIcon from '@mui/icons-material/HealthAndSafety';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormTextField } from '~/common/components/forms/FormTextField';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';

import type { GeminiWire_Safety } from '~/modules/aix/server/dispatch/wiretypes/gemini.wiretypes';
import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorGemini } from './gemini.vendor';


const GEMINI_API_KEY_LINK = 'https://aistudio.google.com/app/apikey';

const SAFETY_OPTIONS: { value: GeminiWire_Safety.HarmBlockThreshold, label: string }[] = [
  { value: 'HARM_BLOCK_THRESHOLD_UNSPECIFIED', label: 'Default' },
  { value: 'BLOCK_LOW_AND_ABOVE', label: 'Low and above' },
  { value: 'BLOCK_MEDIUM_AND_ABOVE', label: 'Medium and above' },
  { value: 'BLOCK_ONLY_HIGH', label: 'Only high' },
  { value: 'BLOCK_NONE', label: 'None' },
  { value: 'OFF', label: 'Safety Filter Off (2025)' },
];


export function GeminiServiceSetup(props: { serviceId: DModelsServiceId }) {

  // advanced mode
  const advanced = useToggleableBoolean(false);

  // external state
  const { service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs, serviceSetupValid, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorGemini);

  // derived state
  const { geminiKey, geminiHost, minSafetyLevel } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  const shallFetchSucceed = !needsUserKey || (!!geminiKey && serviceSetupValid);
  const showKeyError = !!geminiKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='gemini-key' label='Gemini API Key'
      rightLabel={<>{needsUserKey
        ? !geminiKey && <Link level='body-sm' href={GEMINI_API_KEY_LINK} target='_blank'>request Key</Link>
        : <AlreadySet />}
      </>}
      value={geminiKey} onChange={value => updateSettings({ geminiKey: value.trim() })}
      required={needsUserKey} isError={showKeyError}
      placeholder='...'
    />

    {advanced.on && <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Safety Settings'
                      description='Threshold' />
      <Select
        variant='outlined'
        value={minSafetyLevel} onChange={(_event, value) => value && updateSettings({ minSafetyLevel: value })}
        startDecorator={<HealthAndSafetyIcon sx={{ display: { xs: 'none', sm: 'inherit' } }} />}
        // indicator={<KeyboardArrowDownIcon />}
        slotProps={{
          root: { sx: { width: '100%' } },
          indicator: { sx: { opacity: 0.5 } },
          button: { sx: { whiteSpace: 'inherit' } },
        }}
      >
        {SAFETY_OPTIONS.map(option => (
          <Option key={'gemini-safety-' + option.value} value={option.value}>{option.label}</Option>
        ))}
      </Select>
    </FormControl>}

    {advanced.on && <FormHelperText sx={{ display: 'block' }}>
      Gemini has advanced <Link href='https://ai.google.dev/docs/safety_setting_gemini' target='_blank' noLinkStyle>
      safety settings</Link> on: harassment, hate speech,
      sexually explicit, civic integrity, and dangerous content, in addition to non-adjustable built-in filters.
      {/*By default, the model will block content with <em>medium and above</em> probability*/}
      {/*of being unsafe.*/}
    </FormHelperText>}

    {advanced.on && <FormTextField
      autoCompleteId='gemini-host'
      title='API Endpoint'
      placeholder={`https://generativelanguage.googleapis.com`}
      value={geminiHost}
      onChange={text => updateSettings({ geminiHost: text })}
    />}

    <SetupFormRefetchButton refetch={refetch} disabled={!shallFetchSucceed || isFetching} loading={isFetching} error={isError} advanced={advanced} />

    {isError && <InlineError error={error} />}

  </>;
}


================================================
FILE: src/modules/llms/vendors/groq/groq.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


interface DGroqServiceSettings {
  groqKey: string;
}

export const ModelVendorGroq: IModelVendor<DGroqServiceSettings, OpenAIAccessSchema> = {
  id: 'groq',
  name: 'Groq',
  displayRank: 32,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmGroq',

  // functions
  initializeSetup: () => ({
    groqKey: '',
  }),
  validateSetup: (setup) => {
    return setup.groqKey?.length >= 50;
  },
  getTransportAccess: (partialSetup) => ({
    dialect: 'groq',
    oaiKey: partialSetup?.groqKey || '',
    oaiOrg: '',
    oaiHost: '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('Groq' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};



================================================
FILE: src/modules/llms/vendors/groq/GroqServiceSetup.tsx
================================================
import * as React from 'react';

import { Typography } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';

import { ApproximateCosts } from '../ApproximateCosts';
import { ModelVendorGroq } from './groq.vendor';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';


const GROQ_REG_LINK = 'https://console.groq.com/keys';


export function GroqServiceSetup(props: { serviceId: DModelsServiceId }) {

  // external state
  const {
    service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs,
    serviceSetupValid, updateSettings,
  } = useServiceSetup(props.serviceId, ModelVendorGroq);

  // derived state
  const { oaiKey: groqKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  // key validation
  const shallFetchSucceed = !needsUserKey || (!!groqKey && serviceSetupValid);
  const showKeyError = !!groqKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);


  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='groq-key' label='Groq API Key'
      rightLabel={<>{needsUserKey
        ? !groqKey && <Link level='body-sm' href={GROQ_REG_LINK} target='_blank'>API keys</Link>
        : <AlreadySet />}
      </>}
      value={groqKey} onChange={value => updateSettings({ groqKey: value })}
      required={needsUserKey} isError={showKeyError}
      placeholder='...'
    />

    <Typography level='body-sm'>
      <Link href='https://console.groq.com/docs/quickstart'>Groq</Link> offers inference
      as a service for a variety of models. See the <Link href='https://www.groq.com/' target='_blank'>Groq</Link> website for more information.
    </Typography>

    <SetupFormRefetchButton refetch={refetch} disabled={/*!shallFetchSucceed ||*/ isFetching} loading={isFetching} error={isError} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/lmstudio/lmstudio.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


interface DLMStudioServiceSettings {
  oaiHost: string;  // use OpenAI-compatible non-default hosts (full origin path)
}

export const ModelVendorLMStudio: IModelVendor<DLMStudioServiceSettings, OpenAIAccessSchema> = {
  id: 'lmstudio',
  name: 'LM Studio',
  displayRank: 52,
  location: 'local',
  instanceLimit: 1,

  // functions
  initializeSetup: () => ({
    oaiHost: 'http://localhost:1234',
  }),
  getTransportAccess: (partialSetup) => ({
    dialect: 'lmstudio',
    oaiKey: '',
    oaiOrg: '',
    oaiHost: partialSetup?.oaiHost || '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('lmstudio' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};



================================================
FILE: src/modules/llms/vendors/lmstudio/LMStudioServiceSetup.tsx
================================================
import * as React from 'react';
import * as z from 'zod/v4';

import { Typography } from '@mui/joy';
import YouTubeIcon from '@mui/icons-material/YouTube';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { ExpanderAccordion } from '~/common/components/ExpanderAccordion';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { VideoPlayerYouTube } from '~/common/components/VideoPlayerYouTube';

import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorLMStudio } from './lmstudio.vendor';


export function LMStudioServiceSetup(props: { serviceId: DModelsServiceId }) {

  // external state
  const { service, serviceAccess, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorLMStudio);

  // derived state
  const { oaiHost } = serviceAccess;

  // validate if url is a well formed proper url with zod
  const urlSchema = z.url().startsWith('http');
  const { success: isValidHost } = urlSchema.safeParse(oaiHost);
  const shallFetchSucceed = isValidHost;

  // fetch models - the OpenAI way
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(false /* use button only (we don't have server-side conf) */, service);

  return <>

    <ExpanderAccordion
      title={<Typography level='title-sm' sx={{ mr: 'auto' }}>Video Tutorial</Typography>}
      icon={<YouTubeIcon sx={{ color: '#f00' }} />}
      expandedVariant='solid'
      startCollapsed
    >
      <VideoPlayerYouTube width='100%' height={360} youTubeVideoId='MqXzxVokMDk' playing={true} />
    </ExpanderAccordion>

    <Typography level='body-sm'>
      You can use a running <Link href='https://lmstudio.ai/' target='_blank'>LM Studio</Link> instance as a source
      for local models. Please refer to our <Link
      level='body-sm' href='https://github.com/enricoros/big-agi/blob/main/docs/config-local-lmstudio.md' target='_blank'>configuration guide</Link> for
      how to link to your LM Studio instance.
    </Typography>

    <FormInputKey
      autoCompleteId='lmstudio-url' label='LM Studio API'
      required noKey
      rightLabel={<Link level='body-sm' href='https://github.com/enricoros/big-agi/blob/main/docs/config-local-lmstudio.md' target='_blank'>Learn more</Link>}
      placeholder='e.g., http://127.0.0.1:1234'
      value={oaiHost} onChange={value => updateSettings({ oaiHost: value })}
    />

    <SetupFormRefetchButton refetch={refetch} disabled={!shallFetchSucceed || isFetching} loading={isFetching} error={isError} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/localai/localai.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


interface DLocalAIServiceSettings {
  localAIHost: string;  // use OpenAI-compatible non-default hosts (full origin path)
  localAIKey: string;   // use OpenAI-compatible API keys
}

export const ModelVendorLocalAI: IModelVendor<DLocalAIServiceSettings, OpenAIAccessSchema> = {
  id: 'localai',
  name: 'LocalAI',
  displayRank: 50,
  location: 'local',
  instanceLimit: 4,
  hasServerConfigKey: 'hasLlmLocalAIHost',
  hasServerConfigFn: (backendCapabilities) => {
    // this is to show the green mark on the vendor icon in the setup screen
    return backendCapabilities.hasLlmLocalAIHost || backendCapabilities.hasLlmLocalAIKey;
  },

  // functions
  initializeSetup: () => ({
    localAIHost: '',
    localAIKey: '',
  }),
  getTransportAccess: (partialSetup) => ({
    dialect: 'localai',
    oaiKey: partialSetup?.localAIKey || '',
    oaiOrg: '',
    oaiHost: partialSetup?.localAIHost || '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('localai' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};



================================================
FILE: src/modules/llms/vendors/localai/LocalAIAdmin.tsx
================================================
import * as React from 'react';

import { Alert, Box, Button, Card, CircularProgress, IconButton, LinearProgress, List, ListItem, Switch, Typography } from '@mui/joy';
import CloseRoundedIcon from '@mui/icons-material/CloseRounded';

import { ExpanderAccordion } from '~/common/components/ExpanderAccordion';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { apiQuery } from '~/common/util/trpc.client';
import { capitalizeFirstLetter } from '~/common/util/textUtils';

import type { OpenAIAccessSchema } from '../../server/openai/openai.router';


function ListItemSwitch(props: { title: string, checked: boolean, onChange: (checked: boolean) => void }) {
  return (
    <ListItem variant='soft'>
      <Box sx={{ display: 'flex', alignItems: 'center', flex: 1 }}>
        {props.title}
        <Switch
          checked={props.checked}
          onChange={event => props.onChange(event.target.checked)}
          endDecorator={props.checked ? 'Show' : 'Hide'}
          sx={{ ml: 'auto' }}
        />
      </Box>
    </ListItem>
  );
}


/**
 * Show the progress of a model install job by polling the server every 1 second until complete.
 *  - uses the LocalAI /models/jobs API
 */
function ModelJobStatusChecker(props: { access: OpenAIAccessSchema, jobId: string }) {

  // local state
  const [isPolling, setIsPolling] = React.useState(true);

  // external state
  const { data, error } = apiQuery.llmOpenAI.dialectLocalAI_galleryModelsJob.useQuery({ access: props.access, jobId: props.jobId }, {
    enabled: isPolling,
    refetchInterval: 1000,
  });

  // [effect] stop polling when job is done
  const isDone = data?.processed === true || data?.progress === 100;
  React.useEffect(() => {
    if (isDone)
      setIsPolling(false);
  }, [isDone]);

  return <>

    {!!error && <InlineError error={error} />}

    {data && <Box sx={{ display: 'grid', gap: 1, my: 1 }}>
      {data.message && <Typography component='div' level='body-sm'>Message: {data.message}</Typography>}
      {data.file_name && <Typography component='div' level='body-sm'>File: {data.file_name}</Typography>}
      {data.file_size && <Typography component='div' level='body-sm'>File size: {data.file_size}</Typography>}
      {data.downloaded_size && <Typography component='div' level='body-sm'>Downloaded: {data.downloaded_size}</Typography>}
    </Box>}

    {isPolling
      ? <Alert variant='soft' color='primary'>Installation has begun. This may take a very long time.</Alert>
      : <Alert variant='soft' color={error ? 'warning' : 'success'}>
        {error ? 'Installation failed' : 'Installation complete'}
      </Alert>}

    <LinearProgress determinate color={error ? 'warning' : isDone ? 'success' : 'primary'} value={data?.progress || 0} sx={{ mt: 1 }} />

  </>;
}

/**
 * Every model being installed has a panel showing the status.
 *  - uses the LocalAI /models/apply API
 */
function ModelInstallPanel(props: { access: OpenAIAccessSchema, modelName: string, galleryName: string }) {

  // state
  const [hideSelf, setHideSelf] = React.useState(false);

  // external state
  const { data, error, mutate } = apiQuery.llmOpenAI.dialectLocalAI_galleryModelsApply.useMutation();

  // [effect] auto-install
  React.useEffect(() => {
    mutate({ access: props.access, galleryName: props.galleryName, modelName: props.modelName });
  }, [mutate, props.access, props.galleryName, props.modelName]);

  if (hideSelf)
    return null;

  return (
    <Card sx={{ gap: 0, boxShadow: 'sm' }}>

      <Box sx={{ display: 'flex', alignItems: 'center' }}>
        <Typography level='title-sm'>
          Installing <strong>{props.modelName}</strong> from the <strong>{props.galleryName}</strong>
        </Typography>
        <IconButton size='sm' onClick={() => setHideSelf(true)} sx={{ ml: 'auto' }}>
          <CloseRoundedIcon />
        </IconButton>
      </Box>

      {!!error && <InlineError error={error} />}

      {!!data?.uuid && <ModelJobStatusChecker access={props.access} jobId={data.uuid} />}

    </Card>
  );
}


/**
 * Administration panel for LocalAI. Mainly to install models from the Gallery.
 */
export function LocalAIAdmin(props: { access: OpenAIAccessSchema, onClose: () => void }) {

  // state
  const [installModels, setInstallModels] = React.useState<{ galleryName: string; modelName: string; }[]>([]);
  const [showVoiceModels, setShowVoiceModels] = React.useState(false);

  // external state
  const { data, error } = apiQuery.llmOpenAI.dialectLocalAI_galleryModelsAvailable.useQuery({ access: props.access }, {
    staleTime: 1000 * 60,
  });

  // derived state
  const galleryNotConfigured = data === null;


  const handleAppendInstall = React.useCallback((galleryName: string, modelName: string) => {
    setInstallModels(prev => {
      // if already in list, do not add
      if (prev.some(p => p.galleryName === galleryName && p.modelName === modelName))
        return prev;
      return [...prev, { galleryName, modelName }];
    });
  }, []);


  return (
    <GoodModal title='LocalAI Administration' dividers open onClose={props.onClose}>
      <Box sx={{ display: 'grid', gap: 'var(--Card-padding)' }}>

        <Typography level='body-sm'>
          Install models from your LocalAI Model Gallery. <b>You need a properly configured LocalAI gallery.</b>
        </Typography>

        {/* Models being Installed */}
        {installModels.length > 0 && <>

          <Typography level='title-lg'>
            Model Installation
          </Typography>

          <List sx={{ gap: 1 }}>
            {installModels.map((params, index) =>
              <ModelInstallPanel key={'install-' + index} access={props.access} {...params} />,
            )}
          </List>

        </>}


        <Typography level='title-md'>
          Available Models in Gallery
        </Typography>

        {/* Errors */}
        {!!error && <InlineError error={error} />}
        {galleryNotConfigured && <InlineError error={<>
          Model galleries do not seem to be configured (null response).
          Please refer to the <Link href='https://localai.io/models/' target='_blank'>documentation</Link> for
          how to configure model galleries.
        </>} />}

        {/* List loading */}
        {!data ? (
          <CircularProgress color='success' />
        ) : (
          <List
            variant='outlined'
            sx={{
              '--ListItem-minHeight': '2.75rem',
              borderRadius: 'md',
              p: 0,
            }}
          >
            {data
              .filter(model => showVoiceModels || !model.name.startsWith('voice-'))
              .map((model) => (
                <ListItem key={model.name}>

                  {capitalizeFirstLetter(model.name)}

                  <Button
                    color='neutral'
                    size='sm'
                    disabled={installModels.some(p => p.galleryName === model.gallery.name && p.modelName === model.name)}
                    onClick={() => handleAppendInstall(model.gallery.name, model.name)}
                    sx={{
                      ml: 'auto',
                    }}
                  >
                    Install
                  </Button>
                </ListItem>
              ))}

            <ListItemSwitch title='Show Voice Models' checked={showVoiceModels} onChange={setShowVoiceModels} />

            <ExpanderAccordion title='Debug: show JSON' startCollapsed sx={{ fontSize: 'sm' }}>
              <Box sx={{ whiteSpace: 'break-spaces' }}>
                {JSON.stringify(data, null, 2)}
              </Box>
            </ExpanderAccordion>
          </List>
        )}

      </Box>
    </GoodModal>
  );
}


================================================
FILE: src/modules/llms/vendors/localai/LocalAIServiceSetup.tsx
================================================
import * as React from 'react';
import * as z from 'zod/v4';

import { Button, Chip, Typography } from '@mui/joy';

import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { ExpanderControlledBox } from '~/common/components/ExpanderControlledBox';
import { ExternalLink } from '~/common/components/ExternalLink';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { LocalAIAdmin } from './LocalAIAdmin';
import { ModelVendorLocalAI } from './localai.vendor';


const localAIHostSchema = z.url().startsWith('http');


export function LocalAIServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const [checkboxExpanded, setCheckboxExpanded] = React.useState(false);
  const [adminOpen, setAdminOpen] = React.useState(false);

  // external state
  const { hasLlmLocalAIHost: backendHasHost, hasLlmLocalAIKey: backendHasKey } = getBackendCapabilities();
  const { service, serviceAccess, serviceHasLLMs, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorLocalAI);

  // derived state
  const { oaiHost: localAIHost, oaiKey: localAIKey } = serviceAccess;

  // host validation
  const userHostRequired = !backendHasHost;
  const userHostValid = localAIHost.length >= 6 && localAIHostSchema.safeParse(localAIHost).success;
  const userHostError = !!localAIHost && !userHostValid;
  const shallFetchSucceed = localAIHost ? userHostValid : backendHasHost;

  // fetch models - the OpenAI way
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>
    <ApproximateCosts>
      <div>
        <Typography level='body-sm'>
          Please ensure your <ExternalLink href='https://localai.io'>LocalAI</ExternalLink> instance is correctly configured.
          {checkboxExpanded && <> Visit the <Link href='https://localai.io/basics/getting_started/' target='_blank'>LocalAI website</Link> for detailed setup instructions.</>}
          <Chip component='span' variant='outlined' sx={{ ml: 1, fontSize: '0.75rem' }} onClick={() => setCheckboxExpanded(on => !on)}>
            Show {checkboxExpanded ? 'less' : 'more'}
          </Chip>
        </Typography>

        <ExpanderControlledBox expanded={checkboxExpanded}>
          <Typography level='title-sm' sx={{ mt: 2 }}>LocalAI integration status:</Typography>
          <Typography level='body-xs' sx={{ whiteSpace: 'break-spaces', mt: 0.5, ml: '1px' }}>
            ✅{'  '}<Link href='https://localai.io/features/text-generation/' target='_blank'>Text generation</Link> with GPTs<br />
            ✅{'  '}<Link href='https://localai.io/features/openai-functions/' target='_blank'>Function calling</Link> by GPTs<br />
            ✅{'  '}<Link href='https://localai.io/models/' target='_blank'>Model Gallery</Link><br />
            ✅{'  '}<Link href='https://localai.io/features/gpt-vision/' target='_blank'>Vision API</Link> for image chats<br />
            ✅{'  '}<Link href='https://localai.io/features/constrained_grammars/' target='_blank'>JSON output</Link><br />
            ✖️{'  '}<Link href='https://localai.io/features/image-generation' target='_blank'>Image generation</Link> with stable diffusion<br />
            ✖️{'  '}<Link href='https://localai.io/features/audio-to-text/' target='_blank'>Speech transcription</Link><br />
            ✖️{'  '}<Link href='https://localai.io/features/text-to-audio/' target='_blank'>Text to speech</Link><br />
            ✖️{'  '}<Link href='https://localai.io/features/embeddings/' target='_blank'>Embeddings generation</Link><br />
            ✖️{'  '}Voice cloning
          </Typography>
        </ExpanderControlledBox>
      </div>
    </ApproximateCosts>

    <FormInputKey
      autoCompleteId='localai-host' label='LocalAI URL'
      placeholder='e.g. http://127.0.0.1:8080'
      noKey
      required={userHostRequired}
      isError={userHostError}
      rightLabel={backendHasHost ? <AlreadySet /> : <Link level='body-sm' href='https://localai.io' target='_blank'>Learn more</Link>}
      value={localAIHost} onChange={value => updateSettings({ localAIHost: value })}
    />

    <FormInputKey
      autoCompleteId='localai-api-key' label='Optional API Key'
      placeholder='...'
      required={false}
      rightLabel={backendHasKey ? '✔️ already set in server' : undefined}
      value={localAIKey} onChange={value => updateSettings({ localAIKey: value })}
    />

    <SetupFormRefetchButton
      refetch={refetch} disabled={!shallFetchSucceed || isFetching} loading={isFetching} error={isError}
      leftButton={
        <Button color='neutral' variant='solid' disabled={adminOpen} onClick={() => setAdminOpen(true)}>
          Gallery Admin
        </Button>
      }
    />

    {isError && <InlineError error={error} />}

    {adminOpen && <LocalAIAdmin access={serviceAccess} onClose={() => setAdminOpen(false)} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/mistral/mistral.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { DOpenAIServiceSettings, ModelVendorOpenAI } from '../openai/openai.vendor';


// special symbols

type DMistralServiceSettings = Pick<DOpenAIServiceSettings, 'oaiKey' | 'oaiHost'>;


/** Implementation Notes for the Mistral vendor
 */
export const ModelVendorMistral: IModelVendor<DMistralServiceSettings, OpenAIAccessSchema> = {
  id: 'mistral',
  name: 'Mistral',
  displayRank: 18,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmMistral',

  // functions
  initializeSetup: () => ({
    oaiHost: 'https://api.mistral.ai/',
    oaiKey: '',
  }),
  validateSetup: (setup) => {
    return setup.oaiKey?.length >= 32;
  },
  getTransportAccess: (partialSetup): OpenAIAccessSchema => ({
    dialect: 'mistral',
    oaiKey: partialSetup?.oaiKey || '',
    oaiOrg: '',
    oaiHost: partialSetup?.oaiHost || '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('mistral' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};


================================================
FILE: src/modules/llms/vendors/mistral/MistralServiceSetup.tsx
================================================
import * as React from 'react';

import { Typography } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorMistral } from './mistral.vendor';


const MISTRAL_REG_LINK = 'https://console.mistral.ai/';


export function MistralServiceSetup(props: { serviceId: DModelsServiceId }) {

  // external state
  const { service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs, serviceSetupValid, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorMistral);

  // derived state
  const { oaiKey: mistralKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  const shallFetchSucceed = !needsUserKey || (!!mistralKey && serviceSetupValid);
  const showKeyError = !!mistralKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='mistral-key' label='Mistral Key'
      rightLabel={<>{needsUserKey
        ? !mistralKey && <Link level='body-sm' href={MISTRAL_REG_LINK} target='_blank'>request Key</Link>
        : <AlreadySet />}
      </>}
      value={mistralKey} onChange={value => updateSettings({ oaiKey: value })}
      required={needsUserKey} isError={showKeyError}
      placeholder='...'
    />

    {/*<Typography level='body-sm'>*/}
    {/*  In order of capabilities we have Large, Medium, Small (Open 8x7B = Small 2312) and Tiny (Open 7B = Tiny 2312) models.*/}
    {/*  Note the elegance of the numbers, representing the Year and Month or release (YYMM).*/}
    {/*</Typography>*/}

    <SetupFormRefetchButton refetch={refetch} disabled={/*!shallFetchSucceed ||*/ isFetching} loading={isFetching} error={isError} />

    {isError && <InlineError error={error} />}

  </>;
}


================================================
FILE: src/modules/llms/vendors/ollama/ollama.vendor.ts
================================================
import { apiAsync } from '~/common/util/trpc.client';

import type { IModelVendor } from '../IModelVendor';
import type { OllamaAccessSchema } from '../../server/ollama/ollama.router';


interface DOllamaServiceSettings {
  ollamaHost: string;
  ollamaJson: boolean;
}


export const ModelVendorOllama: IModelVendor<DOllamaServiceSettings, OllamaAccessSchema> = {
  id: 'ollama',
  name: 'Ollama',
  displayRank: 54,
  location: 'local',
  instanceLimit: 2,
  hasServerConfigKey: 'hasLlmOllama',

  // functions
  getTransportAccess: (partialSetup): OllamaAccessSchema => ({
    dialect: 'ollama',
    ollamaHost: partialSetup?.ollamaHost || '',
    ollamaJson: partialSetup?.ollamaJson || false,
  }),

  // List Models
  rpcUpdateModelsOrThrow: async (access) => await apiAsync.llmOllama.listModels.query({ access }),

};



================================================
FILE: src/modules/llms/vendors/ollama/OllamaAdministration.tsx
================================================
import * as React from 'react';

import { Autocomplete, Box, Button, Chip, FormControl, IconButton, Option, Select, Typography } from '@mui/joy';
import LaunchIcon from '@mui/icons-material/Launch';
import FormatListNumberedRtlIcon from '@mui/icons-material/FormatListNumberedRtl';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { apiQuery } from '~/common/util/trpc.client';

import type { OllamaAccessSchema } from '../../server/ollama/ollama.router';


// configuration
const FALLBACK_PRESELECT_MODEL = 'llama3.3';


const _stableNoPullable = [] as const;
const _stableNoPullableTags = [] as const;

export function OllamaAdministration(props: { access: OllamaAccessSchema, onClose: () => void }) {

  // state
  const [sortByPulls, setSortByPulls] = React.useState<boolean>(false);
  const [_selectedModelName, setSelectedModelName] = React.useState<string | null>(null);
  // state for the autocomplete component
  const [modelTagValue, setModelTagValue] = React.useState<string | null>(null);
  const [modelTagInputValue, setModelTagInputValue] = React.useState<string>('');

  // external state
  const { data: pullableData } = apiQuery.llmOllama.adminListPullable.useQuery({ access: props.access }, {
    staleTime: 1000 * 60,
  });
  const { data: pullData, isPending: isPulling, status: pullStatus, error: pullError, mutate: pullMutate, reset: pullReset } = apiQuery.llmOllama.adminPull.useMutation();
  const { isPending: isDeleting, status: deleteStatus, error: deleteError, mutate: deleteMutate, reset: deleteReset } = apiQuery.llmOllama.adminDelete.useMutation();

  // derived state
  const selectedModelName = _selectedModelName // user selected
    || pullableData?.pullableModels?.[0]?.id // or the first in the list
    || FALLBACK_PRESELECT_MODEL; // or a fallback

  const handleModelPull = React.useCallback(() => {
    deleteReset();
    selectedModelName && pullMutate({ access: props.access, name: selectedModelName + (modelTagInputValue ? ':' + modelTagInputValue : '') });
  }, [selectedModelName, modelTagInputValue, pullMutate, props.access, deleteReset]);

  const handleModelDelete = React.useCallback(() => {
    pullReset();
    selectedModelName && deleteMutate({ access: props.access, name: selectedModelName + (modelTagInputValue ? ':' + modelTagInputValue : '') });
  }, [selectedModelName, modelTagInputValue, deleteMutate, props.access, pullReset]);


  // stabilize the derived arrays
  const { pullableModels, pullModelTags, pullModelDescription } = React.useMemo(() => {
    // optionally sort models by pulls
    let pullable = pullableData?.pullableModels || _stableNoPullable;
    if (sortByPulls)
      pullable = pullable.toSorted((a, b) => b.pulls - a.pulls);

    // return the tags and description for the selected model
    const selectedModel = pullable.find(p => p.id === selectedModelName) ?? null;
    return {
      pullableModels: pullable,
      pullModelDescription: selectedModel?.description || '',
      pullModelTags: selectedModel?.tags || _stableNoPullableTags,
    };
  }, [pullableData?.pullableModels, sortByPulls, selectedModelName]);


  return (
    <GoodModal title='Ollama Administration' dividers open onClose={props.onClose}>

      <Box sx={{ display: 'grid', gap: 'var(--Card-padding)' }}>
        <Typography level='body-sm'>
          We assume your Ollama host is running and models are already available.
          However we provide a way to pull models from the Ollama host, for convenience.
        </Typography>

        <Box sx={{ display: 'flex', flexFlow: 'row wrap', gap: 1 }}>
          <FormControl sx={{ flexGrow: 1, flexBasis: 0.55 }}>
            <FormLabelStart title={sortByPulls ? 'Model (Sorted by Downloads)' : 'Popular Model'} />
            <Box sx={{ display: 'flex', gap: 1 }}>
              <Select
                value={selectedModelName || ''}
                onChange={(_event: any, value: string | null) => setSelectedModelName(value)}
                sx={{ flexGrow: 1 }}
              >
                {pullableModels.map(p =>
                  <Option key={p.id} value={p.id} label={p.label}>
                    {p.isNew === true && <Chip size='sm' variant='solid'>NEW</Chip>} {p.label}{sortByPulls && ` (${p.pulls.toLocaleString()})`}
                  </Option>,
                )}
              </Select>
              <GoodTooltip title='Sort by Downloads'>
                <IconButton
                  variant={sortByPulls ? 'solid' : 'outlined'}
                  onClick={() => setSortByPulls(!sortByPulls)}
                >
                  <FormatListNumberedRtlIcon />
                </IconButton>
              </GoodTooltip>
            </Box>
          </FormControl>
          <FormControl sx={{ flexGrow: 1, flexBasis: 0.45 }}>
            <FormLabelStart title='Tag' />
            <Box sx={{ display: 'flex', gap: 1 }}>
              <Autocomplete
                freeSolo
                openOnFocus
                clearOnEscape
                placeholder='latest'
                options={pullModelTags}
                value={modelTagValue}
                onChange={(_event, newValue) => setModelTagValue(newValue)}
                inputValue={modelTagInputValue}
                onInputChange={(_event, newInputValue) => setModelTagInputValue(newInputValue)}
                sx={{ minWidth: 80, flexGrow: 1, boxShadow: 'none' }}
                slotProps={{ input: { size: 10 } }} // halve the min width*/
              />
              {/*<Input*/}
              {/*  variant='outlined' placeholder='latest'*/}
              {/*  value={modelTag || ''} onChange={event => setModelTag(event.target.value)}*/}
              {/*  sx={{ minWidth: 80, flexGrow: 1 }}*/}
              {/*  slotProps={{ input: { size: 10 } }} // halve the min width*/}
              {/*/>*/}
              {!!selectedModelName && (
                <IconButton component={Link} href={`https://ollama.ai/library/${selectedModelName}`} target='_blank'>
                  <LaunchIcon />
                </IconButton>
              )}
            </Box>
          </FormControl>
        </Box>


        {/* Status*/}
        {!!pullData && (pullData.error
          ? <Typography color='danger'>{pullData.error}</Typography>
          : <Typography color='success'>{pullData.status || 'Ok, but unkown status'}</Typography>)}
        {!!pullError && <InlineError error={pullError} />}
        {!!deleteError && <InlineError error={deleteError} />}


        {/* Description and Buttons */}
        <Box sx={{ display: 'flex', flexWrap: 'wrap', gap: 2, justifyContent: 'space-between' }}>

          <Typography level='body-sm' sx={{ flex: 1, minWidth: 250 }}>
            {pullModelDescription}
          </Typography>

          <Box sx={{ display: 'flex', flexWrap: 1, gap: 1, alignItems: 'start' }}>
            <Button
              variant='outlined'
              color={deleteStatus === 'error' ? 'danger' : deleteStatus === 'success' ? 'success' : 'primary'}
              loading={isDeleting} disabled={isPulling} onClick={handleModelDelete}
              sx={{ minWidth: 100 }}
            >
              Delete
            </Button>

            <Button
              color={pullStatus === 'error' ? 'danger' : pullStatus === 'success' ? 'success' : 'primary'}
              loading={isPulling} disabled={isDeleting} onClick={handleModelPull}
              sx={{ minWidth: 100 }}
            >
              Pull
            </Button>
          </Box>

        </Box>

        {/* Warnings */}
        {isPulling && <Typography color='warning' level='body-sm'>
          Pulling maybe slow and TIME OUT as the operation will download many GBs from the internet. In case of a
          timeout, the server is still downloading the model. Check back again later and the model should be available.
        </Typography>}

      </Box>

    </GoodModal>
  );
}


================================================
FILE: src/modules/llms/vendors/ollama/OllamaServiceSetup.tsx
================================================
import * as React from 'react';

import { Button, FormControl, Tooltip, Typography } from '@mui/joy';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormSwitchControl } from '~/common/components/forms/FormSwitchControl';
import { FormTextField } from '~/common/components/forms/FormTextField';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { OllamaIcon } from '~/common/components/icons/vendors/OllamaIcon';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { asValidURL } from '~/common/util/urlUtils';

import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorOllama } from './ollama.vendor';
import { OllamaAdministration } from './OllamaAdministration';


export function OllamaServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const [adminOpen, setAdminOpen] = React.useState(false);

  // external state
  const { service, serviceAccess, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorOllama);

  // derived state
  const { ollamaHost, ollamaJson } = serviceAccess;

  const hostValid = !!asValidURL(ollamaHost);
  const hostError = !!ollamaHost && !hostValid;
  const shallFetchSucceed = !hostError;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(false /* use button only (we don't have server-side conf) */, service);

  return <>

    <FormTextField
      autoCompleteId='ollama-host'
      title='Ollama Host'
      description={<Link level='body-sm' href='https://github.com/enricoros/big-agi/blob/main/docs/config-local-ollama.md' target='_blank'>Information</Link>}
      placeholder='http://127.0.0.1:11434'
      isError={hostError}
      value={ollamaHost || ''}
      onChange={text => updateSettings({ ollamaHost: text })}
    />

    <FormControl orientation='horizontal'>
      <FormLabelStart title='Image Input' description='PNG only' />
      <Typography level='body-sm'>
        Ollama supports PNG images (e.g. try Llama3.2-vision).
        For Image attachments, use the &quot;Original&quot; format option.
      </Typography>
    </FormControl>

    <FormSwitchControl
      title='JSON mode'
      on={<Typography level='title-sm' endDecorator={<WarningRoundedIcon sx={{ color: 'danger.solidBg' }} />}>Force JSON</Typography>}
      off='Off (default)'
      fullWidth
      description={
        <Tooltip arrow title='Models will output only JSON, including empty {} objects.'>
          <Link level='body-sm' href='https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-chat-completion' target='_blank'>Information</Link>
        </Tooltip>
      }
      checked={ollamaJson}
      onChange={on => {
        updateSettings({ ollamaJson: on });
        refetch();
      }}
    />

    <SetupFormRefetchButton
      refetch={refetch} disabled={!shallFetchSucceed || isFetching} loading={isFetching} error={isError}
      leftButton={
        <Button color='neutral' variant='solid' disabled={adminOpen} onClick={() => setAdminOpen(true)} startDecorator={<OllamaIcon sx={{ fontSize:'lg' }}/>}>
          Ollama Admin
        </Button>
      }
    />

    {isError && <InlineError error={error} />}

    {adminOpen && <OllamaAdministration access={serviceAccess} onClose={() => setAdminOpen(false)} />}

  </>;
}


================================================
FILE: src/modules/llms/vendors/openai/openai.vendor.ts
================================================
import { apiAsync } from '~/common/util/trpc.client';

import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';


// special symbols
// export const isValidOpenAIApiKey = (apiKey?: string) => !!apiKey && apiKey.startsWith('sk-') && apiKey.length > 40;

export interface DOpenAIServiceSettings {
  oaiKey: string;
  oaiOrg: string;
  oaiHost: string;  // use OpenAI-compatible non-default hosts (full origin path)
  heliKey: string;  // helicone key (works in conjunction with oaiHost)
  moderationCheck: boolean;
}

export const ModelVendorOpenAI: IModelVendor<DOpenAIServiceSettings, OpenAIAccessSchema> = {
  id: 'openai',
  name: 'OpenAI',
  displayRank: 10,
  location: 'cloud',
  instanceLimit: 5,
  hasServerConfigKey: 'hasLlmOpenAI',

  // functions
  getTransportAccess: (partialSetup): OpenAIAccessSchema => ({
    dialect: 'openai',
    oaiKey: '',
    oaiOrg: '',
    oaiHost: '',
    heliKey: '',
    moderationCheck: false,
    ...partialSetup,
  }),

  // List Models
  rpcUpdateModelsOrThrow: async (access) => await apiAsync.llmOpenAI.listModels.query({ access }),

};



================================================
FILE: src/modules/llms/vendors/openai/OpenAIServiceSetup.tsx
================================================
import * as React from 'react';

import { Alert } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { Brand } from '~/common/app.config';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormSwitchControl } from '~/common/components/forms/FormSwitchControl';
import { FormTextField } from '~/common/components/forms/FormTextField';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorOpenAI } from './openai.vendor';


// avoid repeating it all over
const HELICONE_OPENAI_HOST = 'oai.hconeai.com';


export function OpenAIServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const advanced = useToggleableBoolean(!!props.serviceId?.includes('-'));

  // external state
  const { service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorOpenAI);

  // derived state
  const { oaiKey, oaiOrg, oaiHost, heliKey, moderationCheck } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  const keyValid = true; //isValidOpenAIApiKey(oaiKey);
  const keyError = (/*needsUserKey ||*/ !!oaiKey) && !keyValid;
  const shallFetchSucceed = oaiKey ? keyValid : !needsUserKey;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='openai-key' label='API Key'
      rightLabel={<>{needsUserKey
        ? !oaiKey && <Link level='body-sm' href='https://platform.openai.com/account/api-keys' target='_blank'>create key</Link>
        : <AlreadySet />
      } {oaiKey && keyValid && <Link level='body-sm' href='https://platform.openai.com/account/usage' target='_blank'>check usage</Link>}
      </>}
      value={oaiKey} onChange={value => updateSettings({ oaiKey: value })}
      required={needsUserKey} isError={keyError}
      placeholder='sk-...'
    />

    {advanced.on && <FormTextField
      autoCompleteId='openai-host'
      title='API Endpoint'
      tooltip={`An OpenAI compatible endpoint to be used in place of 'api.openai.com'.\n\nCould be used for Helicone, Cloudflare, or other OpenAI compatible cloud or local services.\n\nExamples:\n - ${HELICONE_OPENAI_HOST}\n - localhost:1234`}
      description={<><Link level='body-sm' href='https://www.helicone.ai' target='_blank'>Helicone</Link>, <Link level='body-sm' href='https://developers.cloudflare.com/ai-gateway/' target='_blank'>Cloudflare</Link></>}
      placeholder={`e.g., ${HELICONE_OPENAI_HOST}, https://gateway.ai.cloudflare.com/v1/<ACCOUNT_TAG>/<GATEWAY_URL_SLUG>/openai, etc..`}
      value={oaiHost}
      onChange={text => updateSettings({ oaiHost: text })}
    />}

    {advanced.on && <FormTextField
      autoCompleteId='openai-org'
      title='Organization ID'
      description={<Link level='body-sm' href={Brand.URIs.OpenRepo + '/issues/63'} target='_blank'>What is this</Link>}
      placeholder='Optional, for enterprise users'
      value={oaiOrg}
      onChange={text => updateSettings({ oaiOrg: text })}
    />}

    {advanced.on && <FormTextField
      autoCompleteId='openai-helicone-key'
      title='Helicone Key'
      description={<>Generate <Link level='body-sm' href='https://www.helicone.ai/keys' target='_blank'>here</Link></>}
      placeholder='sk-...'
      value={heliKey}
      onChange={text => updateSettings({ heliKey: text })}
    />}

    {!!heliKey && <Alert variant='soft' color={oaiHost?.includes(HELICONE_OPENAI_HOST) ? 'success' : 'warning'}>
      Advanced: You set the Helicone key. {!oaiHost?.includes(HELICONE_OPENAI_HOST)
      ? `But you also need to set the OpenAI Host to ${HELICONE_OPENAI_HOST} to use Helicone.`
      : 'OpenAI traffic will now be routed through Helicone.'}
    </Alert>}

    {advanced.on && <FormSwitchControl
      title='Moderation' on='Enabled' fullWidth
      description={<>
        <Link level='body-sm' href='https://platform.openai.com/docs/guides/moderation/moderation' target='_blank'>Overview</Link>,
        {' '}<Link level='body-sm' href='https://openai.com/policies/usage-policies' target='_blank'>policy</Link>
      </>}
      checked={moderationCheck}
      onChange={on => updateSettings({ moderationCheck: on })}
    />}

    <SetupFormRefetchButton refetch={refetch} disabled={isFetching} error={isError} loading={isFetching} advanced={advanced} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/openpipe/openpipe.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


export interface DOpenPipeServiceSettings {
  openPipeKey: string;
  openPipeTags: string; // hack: this will travel as 'oaiOrg' in the access schema - then interpreted in the openAIAccess() function
}

export const ModelVendorOpenPipe: IModelVendor<DOpenPipeServiceSettings, OpenAIAccessSchema> = {
  id: 'openpipe',
  name: 'OpenPipe',
  displayRank: 42,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmOpenPipe',

  // functions
  initializeSetup: () => ({
    openPipeKey: '',
    openPipeTags: '',
  }),
  validateSetup: (setup) => {
    return setup.openPipeKey?.length >= 40;
  },
  getTransportAccess: (partialSetup) => ({
    dialect: 'openpipe',
    oaiKey: partialSetup?.openPipeKey || '',
    oaiOrg: partialSetup?.openPipeTags || '', // HACK: use tags for org - should use type discrimination
    oaiHost: '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('openpipe' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};



================================================
FILE: src/modules/llms/vendors/openpipe/OpenPipeServiceSetup.tsx
================================================
import * as React from 'react';

import { Typography } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { ExternalLink } from '~/common/components/ExternalLink';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorOpenPipe } from './openpipe.vendor';


const OPENPIPE_API_KEY_LINK = 'https://app.openpipe.ai/settings';


export function OpenPipeServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  // const advanced = useToggleableBoolean();

  // external state
  const {
    service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs,
    serviceSetupValid, updateSettings,
  } = useServiceSetup(props.serviceId, ModelVendorOpenPipe);

  // derived state
  const { oaiKey: openPipeKey, oaiOrg: openPipeTags } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  // validate if url is a well formed proper url with zod
  const shallFetchSucceed = !needsUserKey || (!!openPipeKey && serviceSetupValid);
  const showKeyError = !!openPipeKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);


  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='openpipe-key' label='OpenPipe Project API Key'
      rightLabel={<>{needsUserKey
        ? !openPipeKey && <Link level='body-sm' href={OPENPIPE_API_KEY_LINK} target='_blank'>Get API Key</Link>
        : <AlreadySet />}
      </>}
      value={openPipeKey} onChange={value => updateSettings({ openPipeKey: value })}
      required={needsUserKey} isError={showKeyError}
      placeholder='opk_...'
    />

    {/*<FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>*/}
    {/*  <FormLabelStart*/}
    {/*    title='Log Requests'*/}
    {/*    description='Sets op-log-request header'*/}
    {/*  />*/}
    {/*  <Checkbox size='sm' label='Log' disabled checked />*/}
    {/*</FormControl>*/}

    <FormInputKey
      autoCompleteId='openpipe-tags' label='OpenPipe Tags'
      noKey required={false}
      rightLabel={<Link level='body-sm' href='https://docs.openpipe.ai/features/request-logs/logging-requests' target='_blank'>Learn more</Link>}
      placeholder='e.g. {"prompt_id": "first_prompt"}'
      value={openPipeTags} onChange={value => updateSettings({ openPipeTags: value })}
    />

    <Typography level='body-sm'>
      <ExternalLink href='https://openpipe.ai/'>OpenPipe</ExternalLink> allows you to <strong>record your chats</strong>,
      and <strong>fine-tune</strong> and deploy custom models that outperform GPT-4 at a
      fraction of the cost.
    </Typography>

    <SetupFormRefetchButton refetch={refetch} disabled={/*!shallFetchSucceed ||*/ isFetching} loading={isFetching} error={isError} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/openrouter/openrouter.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


// special symbols
export const isValidOpenRouterKey = (apiKey?: string) => !!apiKey && apiKey.startsWith('sk-or-') && apiKey.length > 40;

// use OpenAI-compatible host and key
export interface DOpenRouterServiceSettings {
  oaiKey: string;
  oaiHost: string;
}

/**
 * NOTE: the support is just started and incomplete - in particular it depends on some code that
 * hasn't been merged yet.
 *
 * Completion:
 *  [x] raise instanceLimit from 0 to 1 to continue development
 *  [x] add support to the OpenAI Router and Streaming function to add the headers required by OpenRouter (done in the access function)
 *  [~] merge the server-side models remapping from Azure OpenAI - not needed, using client-side remapping for now
 *  [x] decide whether to do UI work to improve the appearance - prioritized models
 *  [x] works!
 */
export const ModelVendorOpenRouter: IModelVendor<DOpenRouterServiceSettings, OpenAIAccessSchema> = {
  id: 'openrouter',
  name: 'OpenRouter',
  displayRank: 40,
  location: 'cloud',
  instanceLimit: 1,
  hasFreeModels: true,
  hasServerConfigKey: 'hasLlmOpenRouter',

  // functions
  initializeSetup: (): DOpenRouterServiceSettings => ({
    oaiHost: 'https://openrouter.ai/api',
    oaiKey: '',
  }),
  getTransportAccess: (partialSetup): OpenAIAccessSchema => ({
    dialect: 'openrouter',
    oaiKey: partialSetup?.oaiKey || '',
    oaiOrg: '',
    oaiHost: partialSetup?.oaiHost || '',
    heliKey: '',
    moderationCheck: false,
  }),

  // there is delay for OpenRouter Free API calls
  rateLimitChatGenerate: async (llm) => {
    const now = Date.now();
    const elapsed = now - nextGenerationTs;
    const wait = llm.pricing?.chat?._isFree
      ? 5000 + 100 /* 5 seconds for free call, plus some safety margin */
      : 100;

    if (elapsed < wait) {
      const delay = wait - elapsed;
      nextGenerationTs = now + delay;
      await new Promise(resolve => setTimeout(resolve, delay));
    } else {
      nextGenerationTs = now;
    }
  },


  // OpenAI transport ('openrouter' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};

// rate limit timestamp
let nextGenerationTs = 0;



================================================
FILE: src/modules/llms/vendors/openrouter/OpenRouterServiceSetup.tsx
================================================
import * as React from 'react';

import { Box, Button, Typography } from '@mui/joy';
import VisibilityOffOutlinedIcon from '@mui/icons-material/VisibilityOffOutlined';
import VisibilityOutlinedIcon from '@mui/icons-material/VisibilityOutlined';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { getCallbackUrl } from '~/common/app.routes';
import { llmsStoreActions, llmsStoreState } from '~/common/stores/llms/store-llms';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { isValidOpenRouterKey, ModelVendorOpenRouter } from './openrouter.vendor';


export function OpenRouterServiceSetup(props: { serviceId: DModelsServiceId }) {

  // external state
  const { service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs, serviceHasVisibleLLMs, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorOpenRouter);

  // derived state
  const { oaiKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  const keyValid = isValidOpenRouterKey(oaiKey);
  const keyError = (/*needsUserKey ||*/ !!oaiKey) && !keyValid;
  const shallFetchSucceed = oaiKey ? keyValid : !needsUserKey;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);


  const handleOpenRouterLogin = () => {
    // replace the current page with the OAuth page
    const callbackUrl = getCallbackUrl('openrouter');
    const oauthUrl = 'https://openrouter.ai/auth?callback_url=' + encodeURIComponent(callbackUrl);
    window.open(oauthUrl, '_self');
    // ...bye / see you soon at the callback location...
  };

  const handleRemoveNonFreeLLMs = () => {
    // A bit of a hack
    const { llms } = llmsStoreState();
    const { removeLLM } = llmsStoreActions();
    llms
      .filter(llm => llm.sId === props.serviceId)
      .filter(llm => llm.pricing?.chat?._isFree === false)
      // .forEach(llm => updateLLM(llm.id, { hidden: true }));
      .forEach(llm => removeLLM(llm.id));
  };

  const handleSetVisibilityAll = React.useCallback((visible: boolean) => {
    const { llms } = llmsStoreState();
    const { updateLLM } = llmsStoreActions();
    llms
      .filter(llm => llm.sId === props.serviceId)
      .forEach(llm => updateLLM(llm.id, { hidden: !visible }));
  }, [props.serviceId]);

  return <>

    <ApproximateCosts serviceId={service?.id} />

    <Typography level='body-sm'>
      <Link href='https://openrouter.ai/keys' target='_blank'>OpenRouter</Link> is an independent service
      granting access to <Link href='https://openrouter.ai/docs#models' target='_blank'>exclusive models</Link> such
      as GPT-4 32k, Claude, and more. <Link
      href='https://github.com/enricoros/big-agi/blob/main/docs/config-openrouter.md' target='_blank'>
      Configuration &amp; documentation</Link>.
    </Typography>

    <FormInputKey
      autoCompleteId='openrouter-key' label='OpenRouter API Key'
      rightLabel={<>{needsUserKey
        ? !oaiKey && <Link level='body-sm' href='https://openrouter.ai/keys' target='_blank'>your keys</Link>
        : <AlreadySet />
      } {oaiKey && keyValid && <Link level='body-sm' href='https://openrouter.ai/activity' target='_blank'>check usage</Link>}
      </>}
      value={oaiKey} onChange={value => updateSettings({ oaiKey: value })}
      required={needsUserKey} isError={keyError}
      placeholder='sk-or-...'
    />

    <Typography level='body-sm'>
      🎁 A selection of <Link href='https://openrouter.ai/docs#models' target='_blank'>OpenRouter models</Link> are
      made available free of charge. You can get an API key by using the Login button below.
    </Typography>

    {/*<Typography level='body-sm'>*/}
    {/*  🔓 Some models are available free of moderation by OpenRouter.*/}
    {/*  These are usually moderated by the upstream provider (e.g. OpenAI).*/}
    {/*</Typography>*/}

    <SetupFormRefetchButton
      refetch={refetch} disabled={!shallFetchSucceed || isFetching} loading={isFetching} error={isError}
      leftButton={
        <Box sx={{ display: 'flex', flexWrap: 'wrap', gap: 1 }}>
          <Button
            color='neutral' variant={(needsUserKey && !keyValid) ? 'solid' : 'outlined'}
            onClick={handleOpenRouterLogin}
            endDecorator={(needsUserKey && !keyValid) ? '🎁' : undefined}
          >
            OpenRouter Login
          </Button>
          <Button
            color='neutral' variant='outlined' size='sm'
            onClick={handleRemoveNonFreeLLMs}
          >
            Only Free 🎁
          </Button>
          <Button
            color='neutral' variant='outlined' size='sm'
            onClick={() => handleSetVisibilityAll(!serviceHasVisibleLLMs)}
            endDecorator={serviceHasVisibleLLMs ? <VisibilityOffOutlinedIcon /> : <VisibilityOutlinedIcon />}
          >
            {serviceHasVisibleLLMs ? 'Hide' : 'Show'} All
          </Button>
        </Box>
      }
    />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/perplexity/perplexity.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


interface DPerpexityServiceSettings {
  perplexityKey: string;
}

export const ModelVendorPerplexity: IModelVendor<DPerpexityServiceSettings, OpenAIAccessSchema> = {
  id: 'perplexity',
  name: 'Perplexity',
  displayRank: 20,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmPerplexity',

  // functions
  initializeSetup: () => ({
    perplexityKey: '',
  }),
  validateSetup: (setup) => {
    return setup.perplexityKey?.length >= 50;
  },
  getTransportAccess: (partialSetup) => ({
    dialect: 'perplexity',
    oaiKey: partialSetup?.perplexityKey || '',
    oaiOrg: '',
    oaiHost: '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('perplexity' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};



================================================
FILE: src/modules/llms/vendors/perplexity/PerplexityServiceSetup.tsx
================================================
import * as React from 'react';

import { Typography } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';

import { ApproximateCosts } from '../ApproximateCosts';
import { ModelVendorPerplexity } from './perplexity.vendor';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';


const PERPLEXITY_REG_LINK = 'https://www.perplexity.ai/settings/api';


export function PerplexityServiceSetup(props: { serviceId: DModelsServiceId }) {

  // external state
  const {
    service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs,
    serviceSetupValid, updateSettings,
  } = useServiceSetup(props.serviceId, ModelVendorPerplexity);

  // derived state
  const { oaiKey: perplexityKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  // key validation
  const shallFetchSucceed = !needsUserKey || (!!perplexityKey && serviceSetupValid);
  const showKeyError = !!perplexityKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);


  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='perplexity-key' label='Perplexity API Key'
      rightLabel={<>{needsUserKey
        ? !perplexityKey && <Link level='body-sm' href={PERPLEXITY_REG_LINK} target='_blank'>API keys</Link>
        : <AlreadySet />}
      </>}
      value={perplexityKey} onChange={value => updateSettings({ perplexityKey: value })}
      required={needsUserKey} isError={showKeyError}
      placeholder='...'
    />

    <Typography level='body-sm'>
      The <Link href='https://docs.perplexity.ai/docs/getting-started'>Perplexity API</Link> offers inference
      as a service for a variety of models. See the <Link href='https://www.perplexity.ai/' target='_blank'>Perplexity AI</Link> website for more information.
      🌐 Online models are quite unique as they can make use of internet data.
    </Typography>

    <SetupFormRefetchButton refetch={refetch} disabled={/*!shallFetchSucceed ||*/ isFetching} loading={isFetching} error={isError} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/togetherai/togetherai.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


interface DTogetherAIServiceSettings {
  togetherKey: string;
  togetherHost: string;
  togetherFreeTrial: boolean;
}

export const ModelVendorTogetherAI: IModelVendor<DTogetherAIServiceSettings, OpenAIAccessSchema> = {
  id: 'togetherai',
  name: 'Together AI',
  displayRank: 34,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmTogetherAI',

  // functions
  initializeSetup: () => ({
    togetherKey: '',
    togetherHost: 'https://api.together.xyz',
    togetherFreeTrial: false,
  }),
  validateSetup: (setup) => {
    return setup.togetherKey?.length >= 64;
  },
  getTransportAccess: (partialSetup) => ({
    dialect: 'togetherai',
    oaiKey: partialSetup?.togetherKey || '',
    oaiOrg: '',
    oaiHost: partialSetup?.togetherHost || '',
    heliKey: '',
    moderationCheck: false,
  }),

  // there is delay for Together Free API calls
  rateLimitChatGenerate: async (_llm, partialSetup) => {
    const now = Date.now();
    const elapsed = now - nextGenerationTs;
    const wait = partialSetup?.togetherFreeTrial
      ? 1000 + 50 /* 1 seconds for free call, plus some safety margin */
      : 50;

    if (elapsed < wait) {
      const delay = wait - elapsed;
      nextGenerationTs = now + delay;
      await new Promise(resolve => setTimeout(resolve, delay));
    } else {
      nextGenerationTs = now;
    }
  },


  // OpenAI transport ('togetherai' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};

// rate limit timestamp
let nextGenerationTs = 0;



================================================
FILE: src/modules/llms/vendors/togetherai/TogetherAIServiceSetup.tsx
================================================
import * as React from 'react';

import { Alert, Typography } from '@mui/joy';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { FormSwitchControl } from '~/common/components/forms/FormSwitchControl';
import { InlineError } from '~/common/components/InlineError';
import { Link } from '~/common/components/Link';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorTogetherAI } from './togetherai.vendor';


const TOGETHERAI_REG_LINK = 'https://api.together.xyz/settings/api-keys';


export function TogetherAIServiceSetup(props: { serviceId: DModelsServiceId }) {

  // state
  const advanced = useToggleableBoolean();

  // external state
  const {
    service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs,
    partialSettings, serviceSetupValid, updateSettings,
  } = useServiceSetup(props.serviceId, ModelVendorTogetherAI);

  // derived state
  const { oaiKey: togetherKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  // validate if url is a well formed proper url with zod
  const shallFetchSucceed = !needsUserKey || (!!togetherKey && serviceSetupValid);
  const showKeyError = !!togetherKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);


  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='togetherai-key' label='Together AI Key'
      rightLabel={<>{needsUserKey
        ? !togetherKey && <Link level='body-sm' href={TOGETHERAI_REG_LINK} target='_blank'>request Key</Link>
        : <AlreadySet />}
      </>}
      value={togetherKey} onChange={value => updateSettings({ togetherKey: value })}
      required={needsUserKey} isError={showKeyError}
      placeholder='...'
    />

    <Typography level='body-sm'>
      The Together Inference platform allows you to run recent machine learning models with good speed and low
      cost. See the <Link href='https://www.together.ai/' target='_blank'>Together AI</Link> website for more
      information.
    </Typography>

    {advanced.on && <FormSwitchControl
      title='Rate Limiter' on='Enabled' off='Disabled'
      description={partialSettings?.togetherFreeTrial ? 'Free trial: 2 requests/2s' : 'Disabled'}
      checked={partialSettings?.togetherFreeTrial ?? false}
      onChange={on => updateSettings({ togetherFreeTrial: on })}
    />}

    {advanced.on && !!partialSettings?.togetherFreeTrial && <Alert variant='soft'>
      Note: Please refresh the models list if you toggle the rate limiter.
    </Alert>}

    <SetupFormRefetchButton refetch={refetch} disabled={/*!shallFetchSucceed ||*/ isFetching} loading={isFetching} error={isError} advanced={advanced} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/llms/vendors/xai/xai.vendor.ts
================================================
import type { IModelVendor } from '../IModelVendor';
import type { OpenAIAccessSchema } from '../../server/openai/openai.router';

import { ModelVendorOpenAI } from '../openai/openai.vendor';


export interface DXAIServiceSettings {
  xaiKey: string;
}

export const ModelVendorXAI: IModelVendor<DXAIServiceSettings, OpenAIAccessSchema> = {
  id: 'xai',
  name: 'xAI',
  displayRank: 15,
  location: 'cloud',
  instanceLimit: 1,
  hasServerConfigKey: 'hasLlmXAI',

  // functions
  initializeSetup: () => ({ xaiKey: '' }),
  validateSetup: setup => setup.xaiKey?.length >= 80, // we assume all API keys are 80 chars+ - we won't have a strict validation
  getTransportAccess: (partialSetup) => ({
    dialect: 'xai',
    oaiKey: partialSetup?.xaiKey || '',
    oaiOrg: '',
    oaiHost: '',
    heliKey: '',
    moderationCheck: false,
  }),

  // OpenAI transport ('xai' dialect in 'access')
  rpcUpdateModelsOrThrow: ModelVendorOpenAI.rpcUpdateModelsOrThrow,

};



================================================
FILE: src/modules/llms/vendors/xai/XAIServiceSetup.tsx
================================================
import * as React from 'react';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { AlreadySet } from '~/common/components/AlreadySet';
import { ExternalLink } from '~/common/components/ExternalLink';
import { FormInputKey } from '~/common/components/forms/FormInputKey';
import { InlineError } from '~/common/components/InlineError';
import { SetupFormRefetchButton } from '~/common/components/forms/SetupFormRefetchButton';

import { ApproximateCosts } from '../ApproximateCosts';
import { useLlmUpdateModels } from '../../llm.client.hooks';
import { useServiceSetup } from '../useServiceSetup';

import { ModelVendorXAI } from './xai.vendor';


// configuration
const EXTERNAL_LINK_XAI_API_KEYS = 'https://console.x.ai/';


export function XAIServiceSetup(props: { serviceId: DModelsServiceId }) {

  // external state
  const { service, serviceAccess, serviceHasCloudTenantConfig, serviceHasLLMs, serviceSetupValid, updateSettings } =
    useServiceSetup(props.serviceId, ModelVendorXAI);

  // derived state
  const { oaiKey: xaiKey } = serviceAccess;
  const needsUserKey = !serviceHasCloudTenantConfig;

  // key validation
  const shallFetchSucceed = !needsUserKey || (!!xaiKey && serviceSetupValid);
  const showKeyError = !!xaiKey && !serviceSetupValid;

  // fetch models
  const { isFetching, refetch, isError, error } =
    useLlmUpdateModels(!serviceHasLLMs && shallFetchSucceed, service);

  return <>

    <ApproximateCosts serviceId={service?.id} />

    <FormInputKey
      autoCompleteId='xai-key'
      label='API Key'
      rightLabel={<>{needsUserKey
        ? !xaiKey && <ExternalLink level='body-sm' href={EXTERNAL_LINK_XAI_API_KEYS}>get a key</ExternalLink>
        : <AlreadySet />}
      </>}
      value={xaiKey}
      onChange={(value) => updateSettings({ xaiKey: value })}
      required={needsUserKey}
      isError={showKeyError}
      placeholder='Your xAI API Key'
    />

    {/*<FormTextField*/}
    {/*  autoCompleteId='xai-host'*/}
    {/*  title='API Host'*/}
    {/*  placeholder='https://api.x.ai'*/}
    {/*  value={xaiHost}*/}
    {/*  onChange={(text) => updateSettings({ xaiHost: text })}*/}
    {/*/>*/}

    <SetupFormRefetchButton refetch={refetch} disabled={isFetching} error={isError} loading={isFetching} />

    {isError && <InlineError error={error} />}

  </>;
}



================================================
FILE: src/modules/persona/pmix/pmix.parameters.ts
================================================
/**
 * Prompt Mixer Parameter Registry
 *
 * This module provides a type-safe parameter management system for prompt variables.
 * It handles variable definitions, dependencies, and runtime replacements while
 * maintaining strict type safety throughout the application.
 *
 * Key concepts:
 * - Variables are categorized by their scope/type
 * - Each variable has a clear definition of its dependencies and replacement logic
 * - The system is extensible for future object-variable replacement
 */

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { findLLMOrThrow } from '~/common/stores/llms/store-llms';


/// Types

interface PVariableDefinition {

  scope: 'global' | 'system' | 'model';     // 'persona' | 'user';
  description: string;

  dependencies?: {
    assistantLlmId?: boolean;     // requires the LLM ID
    lowHourPrecision?: boolean;   // affects behavior with time
  };

  // replacement behavior
  wholeLine?: boolean;            // whether to remove the whole line if variable is undefined
  pattern?: RegExp;               // for variables that need regex replacement (e.g., {{LLM.LowRL:...}})

  // function to generate the replacement text
  replace: (context: PPromptMixerContext) => string | null;
}

export interface PPromptMixerContext {
  assistantLlmId?: DLLMId;
  deviceIsDesktop?: boolean;
  deviceBrowserLang?: string;
  lowHourPrecision?: boolean;
  fixupAutoSuggestHTMLUI?: boolean;
  customFields?: Record<string, string>;
}

export type PPromptVariable = keyof typeof PromptVariableRegistry;


// Registry

export const PromptVariableRegistry: Record<string, PVariableDefinition> = {

  // Date and Time

  '{{Today}}': {
    scope: 'global',
    description: 'Current date in YYYY-MM-DD format',
    replace: () => {
      const today = new Date();
      return `${today.getFullYear()}-${String(today.getMonth() + 1).padStart(2, '0')}-${String(today.getDate()).padStart(2, '0')}`;
    },
  },

  // {{LocaleNow}} - enough information to get on the same page with the user
  '{{LocaleNow}}': {
    scope: 'global',
    description: 'Locale-aware date and time',
    dependencies: { lowHourPrecision: true },
    replace: ({ lowHourPrecision, deviceBrowserLang }) => {
      const formatter = new Intl.DateTimeFormat(deviceBrowserLang, {
        weekday: 'short', // Full name of the day of the week
        year: 'numeric', // Numeric year
        month: 'short', // Full name of the month
        day: 'numeric', // Numeric day of the month
        hour: '2-digit', // 2-digit hour
        // NOTE: disable the minutes if we are using auto-breakpoints, as this will invalidate all every minute...
        minute: lowHourPrecision ? undefined : '2-digit', // 2-digit minute
        timeZoneName: 'short', // Short timezone name (e.g., GMT, CST)
        hour12: true, // Use 12-hour time format; set to false for 24-hour format if preferred
      });
      return formatter.format(new Date());
    },
  },

  // Rendering Capabilities

  '{{PreferTables}}': {
    scope: 'system',
    description: 'Instruct to prefer tabulated data',
    replace: () => 'Data presentation: prefer tables (auto-columns)',
  },

  '{{RenderMermaid}}': {
    scope: 'system',
    description: 'Enable Mermaid diagram rendering',
    replace: () => 'Mermaid rendering: Enabled for diagrams and pie charts and no other charts',
  },

  '{{RenderPlantUML}}': {
    scope: 'system',
    description: 'Enable PlantUML diagram rendering',
    replace: () => 'PlantUML rendering: Enabled',
  },

  '{{RenderSVG}}': {
    scope: 'system',
    description: 'Enable SVG rendering',
    replace: () => 'SVG in markdown rendering: Enabled',
  },

  '{{RenderHTML}}': {
    scope: 'system',
    description: 'Enable HTML rendering with device awareness',
    replace: ({ deviceIsDesktop }) =>
      `HTML in markdown rendering: Sleek HTML5 for ${deviceIsDesktop ? 'desktop' : 'mobile'} screens (self-contained with CSS/JS, leverage top libraries, external links OK)`,
  },

  '{{RenderChartJS}}': {
    scope: 'system',
    description: 'Enable ChartJS chart rendering',
    replace: () => `
When presenting data that would be better visualized as a chart, output a ChartJS configuration JSON in this format:
\`\`\`chartjs
{
  // Valid and complete ChartJS configuration JSON (DO NOT USE FUNCTIONS)
}
\`\`\`
Choose the most suitable chart type based on the data and context. Include only the JSON configuration, without any explanatory text. Ensure the JSON is valid and complete and can be parsed by ChartJS.
`.trim(),
  },

  // Model Capabilities

  '{{LLM.Cutoff}}': {
    scope: 'model',
    description: 'Model knowledge cutoff date',
    dependencies: { assistantLlmId: true },
    wholeLine: true,
    replace: ({ assistantLlmId }) => {
      try {
        if (assistantLlmId)
          return findLLMOrThrow(assistantLlmId).trainingDataCutoff || null;
      } catch (e) {
        // ignore...
      }
      return null;
    },
  },

  '{{LLM.LowRL:...}}': {
    scope: 'model',
    description: 'Conditional content for non-reasoning models',
    dependencies: { assistantLlmId: true },
    pattern: /{{LLM\.LowRL:(.*?)}}/gs,
    replace: ({ assistantLlmId }) => {
      const removeLineForDLLMIDs = [
        '-claude-3-5', '-claude-3-opus',    // [Anthropic]
        '-deepseek-chat',                   // [DeepSeek]
        '-gemini-1.5',                      // [Google]
        '-mistral-large',                   // [Mistral]
        '-o1', '-gpt-4o', '-gpt-4-turbo',   // [OpenAI]
      ];
      const shallRemoveLine = !assistantLlmId ? false : removeLineForDLLMIDs.some(model => assistantLlmId.includes(model));
      return shallRemoveLine ? null : '$1';
    },
  },

} as const;



================================================
FILE: src/modules/persona/pmix/pmix.ts
================================================
import { autoFollowUpUIMixin } from '~/modules/aifn/auto-chat-follow-ups/autoChatFollowUps';

import type { DLLMId } from '~/common/stores/llms/llms.types';
import { BrowserLang, Is } from '~/common/util/pwaUtils';

import { getChatAutoAI } from '../../../apps/chat/store-app-chat';

import { PPromptMixerContext, PromptVariableRegistry } from './pmix.parameters';


// configuration
const REMOVE_ALL_LINE_IF_MISSING_LLM = true; // remove all lines if LLM is missing


export function replacePromptVariables(template: string, context: PPromptMixerContext): string {
  let mixed = template;

  // auto-append Auto-Suggest features if enabled
  if (context.fixupAutoSuggestHTMLUI)
    mixed += (mixed.endsWith('\n') ? '' : '\n') + autoFollowUpUIMixin;
  // if (context.autoSuggestDiagrams)
  //   mixed += (mixed.endsWith('\n') ? '' : '\n') + '{{FixupAutoSuggestDiagrams}}';

  // process each variable in the registry
  for (const [variable, definition] of Object.entries(PromptVariableRegistry)) {

    // validate presence of dependencies
    if (definition.dependencies?.assistantLlmId && !context.assistantLlmId) {
      if (REMOVE_ALL_LINE_IF_MISSING_LLM)
        mixed = mixed.replaceAll(new RegExp(`.*${variable}.*\n?`, 'g'), '');
      else
        console.log(`[DEV] replacePromptVariables: skipping ${variable} due to missing LLM ID`);
      continue;
    }
    if (definition.dependencies?.lowHourPrecision && context.lowHourPrecision === undefined) {
      if (REMOVE_ALL_LINE_IF_MISSING_LLM)
        mixed = mixed.replaceAll(new RegExp(`.*${variable}.*\n?`, 'g'), '');
      else
        console.log(`[DEV] replacePromptVariables: skipping ${variable} due to missing lowHourPrecision`);
      continue;
    }

    // get the replacement text or the regex replacement pattern
    const replacementOrNull = definition.replace(context);

    // handle whole-line removal
    if (definition.wholeLine && replacementOrNull === null) {
      mixed = mixed.replaceAll(new RegExp(`.*${variable}.*\n?`, 'g'), '');
      continue;
    }

    // handle pattern-based replacement
    if (definition.pattern) {
      mixed = replacementOrNull === null
        ? mixed.replaceAll(definition.pattern, '')
        : mixed.replaceAll(definition.pattern, replacementOrNull);
      continue;
    }

    // Simple replacement
    if (replacementOrNull !== null)
      mixed = mixed.replaceAll(variable, replacementOrNull);
  }

  // Handle custom fields
  if (context.customFields)
    for (const [placeholder, replacement] of Object.entries(context.customFields))
      mixed = mixed.replaceAll(placeholder, replacement);

  // At most leave 2 newlines in a row
  mixed = mixed.replace(/\n{3,}/g, '\n\n');

  return mixed;
}


/**
 * This will be made a module and fully reactive in the future.
 * NOTE: think twice before changing the variables, as they can be in data at rest (can they?)
 */
export function bareBonesPromptMixer(_template: string, assistantLlmId: DLLMId | undefined, customFields: Record<string, string> | undefined = undefined) {
  const { autoSuggestHTMLUI, /*autoSuggestDiagrams,*/ autoVndAntBreakpoints } = getChatAutoAI();
  return replacePromptVariables(_template, {
    assistantLlmId,
    deviceIsDesktop: Is.Desktop,
    deviceBrowserLang: BrowserLang.orUS,
    lowHourPrecision: autoVndAntBreakpoints,
    fixupAutoSuggestHTMLUI: autoSuggestHTMLUI,
    customFields,
  });
}



================================================
FILE: src/modules/t2i/store-module-t2i.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';


interface TextToImageStore {

  selectedT2IProviderId: string | null; // null = auto-select, specific ID = user choice
  setSelectedT2IProviderId: (providerId: string | null) => void;

}

export const useTextToImageStore = create<TextToImageStore>()(
  persist(
    (_set) => ({

      selectedT2IProviderId: null, // null: auto-select highest priority configured provider
      setSelectedT2IProviderId: (selectedT2IProviderId: string | null) => _set({ selectedT2IProviderId }),

    }),
    {
      name: 'app-module-t2i',
      version: 1,
    }),
);


================================================
FILE: src/modules/t2i/t2i.client.ts
================================================
import * as React from 'react';

import type { AixParts_InlineImagePart } from '~/modules/aix/server/api/aix.wiretypes';
import type { ModelVendorId } from '~/modules/llms/vendors/vendors.registry';
import { resolveDalleModelId, useDalleStore } from '~/modules/t2i/dalle/store-module-dalle';

import { addDBImageAsset, DBlobDBScopeId } from '~/common/stores/blob/dblobs-portability';

import type { CapabilityTextToImage, TextToImageProvider } from '~/common/components/useCapabilities';
import type { DLLM } from '~/common/stores/llms/llms.types';
import type { DModelsService, DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { convert_Base64WithMimeType_To_Blob } from '~/common/util/blobUtils';
import { createDMessageDataRefDBlob, createImageContentFragment, DMessageContentFragment } from '~/common/stores/chat/chat.fragments';
import { llmsStoreState, useModelsStore } from '~/common/stores/llms/store-llms';
import { shallowEquals } from '~/common/util/hooks/useShallowObject';

import type { T2iCreateImageOutput } from './t2i.server';
import { openAIGenerateImagesOrThrow, openAIImageModelsCurrentGeneratorName } from './dalle/openaiGenerateImages';
import { useTextToImageStore } from './store-module-t2i';


// configuration
const T2I_ENABLE_LOCAL_AI = false; // Note: LocalAI t2i integration is experimental


// Capabilities API - used by Settings, and whomever wants to check if this is available

export function useCapabilityTextToImage(): CapabilityTextToImage {

  // external state

  const stableLlmsModelServices = React.useRef<T2ILlmsModelServices[]>(undefined);
  const llmsModelServices = useModelsStore(({ llms, sources }) => {
    const next = _findLlmsT2IServices(llms, sources);
    const prev = stableLlmsModelServices.current;
    if (prev
      && prev.length === next.length
      && prev.every((v, i) => shallowEquals(v, next[i]))
    ) return prev;
    return stableLlmsModelServices.current = next;
  });

  const userProviderId = useTextToImageStore(state => state.selectedT2IProviderId);

  const dalleModelId = useDalleStore(state => state.dalleModelId);



  // memo

  const { mayWork, mayEdit, providers, activeProvider } = React.useMemo(() => {
    const providers = _getTextToImageProviders(llmsModelServices);
    const activeProvider = _resolveActiveT2IProvider(userProviderId, providers);
    const mayWork = providers.some(p => p.configured);
    const resolvedDalleModelId = resolveDalleModelId(dalleModelId);
    const mayEdit = activeProvider?.vendor === 'openai' && resolvedDalleModelId === 'gpt-image-1';
    return {
      mayWork,
      mayEdit,
      providers,
      activeProvider,
    };
  }, [userProviderId, dalleModelId, llmsModelServices]);


  return {
    mayWork,
    mayEdit,
    providers,
    activeProviderId: activeProvider?.providerId || null,
    setActiveProviderId: useTextToImageStore.getState().setSelectedT2IProviderId,
  };
}


// T2I API

export function getActiveTextToImageProviderOrThrow() {

  // get user selection and available providers
  const { selectedT2IProviderId } = useTextToImageStore.getState();
  const { llms, sources: modelsServices } = llmsStoreState();
  const llmsModelServiceIDs = _findLlmsT2IServices(llms, modelsServices);
  const providers = _getTextToImageProviders(llmsModelServiceIDs);

  // resolve the active provider using pure function
  const activeProvider = _resolveActiveT2IProvider(selectedT2IProviderId, providers);
  if (!activeProvider)
    throw new Error('No Text-to-Image providers are configured');

  return activeProvider;
}

async function _t2iGenerateImagesOrThrow({ providerId, vendor }: TextToImageProvider, prompt: string, aixInlineImageParts: AixParts_InlineImagePart[], count: number): Promise<T2iCreateImageOutput[]> {
  switch (vendor) {

    case 'gemini':
      throw new Error('Gemini Imagen integration coming soon');

    case 'localai':
      // if (!provider.providerId)
      //   throw new Error('No LocalAI Model service configured for TextToImage');
      // return await localaiGenerateImages(provider.id, prompt, count);
      throw new Error('LocalAI t2i integration is not yet available');

    case 'openai':
      if (!providerId)
        throw new Error('No OpenAI Model Service configured for TextToImage');
      return await openAIGenerateImagesOrThrow(providerId, prompt, aixInlineImageParts, count);

    case 'xai':
      throw new Error('xAI image generation integration coming soon');

    default:
      throw new Error(`Unknown T2I vendor: ${vendor}`);
  }
}

/**
 * Generate image content fragments using the provided TextToImageProvider
 * If t2iprovider is null, the active provider will be used
 */
export async function t2iGenerateImageContentFragments(
  t2iProvider: TextToImageProvider | null,
  prompt: string,
  aixInlineImageParts: AixParts_InlineImagePart[],
  count: number,
  scopeId: DBlobDBScopeId,
): Promise<DMessageContentFragment[]> {

  // T2I: Use the active provider if null
  if (!t2iProvider)
    t2iProvider = getActiveTextToImageProviderOrThrow();

  // T2I: Generate
  const generatedImages = await _t2iGenerateImagesOrThrow(t2iProvider, prompt, aixInlineImageParts, count);
  if (!generatedImages?.length)
    throw new Error('No image generated');

  const imageFragments: DMessageContentFragment[] = [];
  for (const _i of generatedImages) {

    // base64 -> blob conversion
    const imageBlob = await convert_Base64WithMimeType_To_Blob(_i.base64Data, _i.mimeType, 't2iGenerateImageContentFragments');

    // NOTE: no resize/type conversion, store as-is

    // add the image to the DBlobs DB
    const dblobAssetId = await addDBImageAsset(scopeId, imageBlob, {
      label: prompt,
      metadata: {
        width: _i.width || 0,
        height: _i.height || 0,
        // description: '',
        // inputTokens: _i.inputTokens,
        // outputTokens: _i.outputTokens,
      },
      origin: {
        ot: 'generated',
        source: 'ai-text-to-image',
        generatorName: _i.generatorName,
        prompt: _i.altText,
        parameters: _i.parameters,
        generatedAt: _i.generatedAt,
      },
    });

    // create the DMessage _Content_ Fragment (not attachment)
    // so this is akin to the model-generated images
    const imageContentFragment = createImageContentFragment(
      createDMessageDataRefDBlob( // Data Reference {} for the image
        dblobAssetId,
        imageBlob.type,
        imageBlob.size,
      ),
      _i.altText,
      _i.width,
      _i.height,
    );

    imageFragments.push(imageContentFragment);
  }
  return imageFragments;
}


/// Private

interface T2ILlmsModelServices {
  label: string;
  modelVendorId: ModelVendorId;
  modelServiceId: DModelsServiceId;
  hasAnyModels: boolean;
}

function _findLlmsT2IServices(llms: ReadonlyArray<DLLM>, services: ReadonlyArray<DModelsService>) {
  return services
    .filter(s => (s.vId === 'openai' || (T2I_ENABLE_LOCAL_AI && s.vId === 'localai')))
    .map((s): T2ILlmsModelServices => ({
      label: s.label,
      modelVendorId: s.vId,
      modelServiceId: s.id,
      hasAnyModels: llms.some(m => m.sId === s.id),
    }));
}


// Vendor priority system for auto-selection (lower number = higher priority)
const T2I_VENDOR_PRIORITIES = {
  openai: 1,    // highest priority (mature, reliable)
  gemini: 2,    // second (Google Imagen - future)
  xai: 3,       // third (Grok vision - future reference)
  localai: 9,   // lowest (experimental)
} as const;


function _getTextToImageProviders(llmsModelServices: T2ILlmsModelServices[]) {
  const providers: TextToImageProvider[] = [];

  // add providers from model services
  for (const { modelVendorId, modelServiceId, label, hasAnyModels } of llmsModelServices) {
    switch (modelVendorId) {

      case 'openai':
        providers.push({
          providerId: modelServiceId,
          label: label,
          painter: openAIImageModelsCurrentGeneratorName(), // sync this with dMessageUtils.tsx
          // painter: 'DALL·E',
          description: 'OpenAI Image generation models',
          configured: hasAnyModels,
          vendor: 'openai',
        });
        break;

      case 'localai':
        providers.push({
          providerId: modelServiceId,
          label: label,
          painter: 'LocalAI',
          description: 'LocalAI\'s models',
          configured: hasAnyModels,
          vendor: 'localai',
        });
        break;

      default:
        console.error('Unknown model vendor', modelVendorId);
        break;
    }
  }

  // Insert other services here if needed (non-LLM/Service based)
  // ... (e.g. we used to have Prodia here)

  // Sort providers by vendor priority (then by label for deterministic ordering)
  return providers.sort((a, b) => {
    const priorityA = T2I_VENDOR_PRIORITIES[a.vendor] ?? 999;
    const priorityB = T2I_VENDOR_PRIORITIES[b.vendor] ?? 999;
    if (priorityA !== priorityB) return priorityA - priorityB;
    return a.label.localeCompare(b.label);
  });
}

function _resolveActiveT2IProvider(userSelectedId: string | null, prioritizedProviders: TextToImageProvider[]): TextToImageProvider | null {

  // if user explicitly chose a provider AND it's configured
  if (userSelectedId) {
    const chosen = prioritizedProviders.find(p => p.providerId === userSelectedId && p.configured);
    if (chosen) return chosen;
  }
  
  // Auto-select: find highest priority configured provider (providers are already sorted)
  return prioritizedProviders.find(p => p.configured) || null;
}


================================================
FILE: src/modules/t2i/t2i.server.ts
================================================
import * as z from 'zod/v4';


// Image generation output

export type T2ICreateImageAsyncStreamOp =
  | { p: '❤' } // heart beat
  | { p: 'state', state: 'started' }
  | { p: 'createImage', image: T2iCreateImageOutput };

export type T2iCreateImageOutput = z.infer<typeof t2iCreateImageOutputSchema>;
const t2iCreateImageOutputSchema = z.object({

  // separate mime and data instead of the data URL 'data:image/png;base64,...'
  mimeType: z.string(),
  base64Data: z.string(),

  // could be the revised prompt, or an alt textual description of the image
  altText: z.string(),

  // metadata
  width: z.number(),
  height: z.number(),

  // costs
  inputTokens: z.number().optional(),
  outputTokens: z.number().optional(),

  // origin
  generatorName: z.string(),
  parameters: z.record(z.string(), z.any()),
  generatedAt: z.string(),

});


/**
 * Finds out the mimetype and dimensions of an image from its bytes.
 */
export function getImageInformationFromBytes(arrayBuffer: ArrayBuffer): { width: number; height: number; mimeType: string } {
  const dataView = new DataView(arrayBuffer);

  // Check for PNG signature
  if (dataView.getUint8(0) === 0x89 && dataView.getUint8(1) === 0x50) {
    const dimensions = getPngDimensionsFromBytes(arrayBuffer);
    return { ...dimensions, mimeType: 'image/png' };
  }

  // Check for JPEG signature
  if (dataView.getUint8(0) === 0xFF && dataView.getUint8(1) === 0xD8) {
    const dimensions = getJpegDimensionsFromBytes(arrayBuffer);
    return { ...dimensions, mimeType: 'image/jpeg' };
  }

  throw new Error('Unsupported image format');
}


/**
 * Low-level function to extract the dimensions of a PNG image from its bytes.
 */
export function getPngDimensionsFromBytes(arrayBuffer: ArrayBuffer) {
  const dataView = new DataView(arrayBuffer);

  // Check the PNG signature (first 8 bytes)
  const pngSignature = [137, 80, 78, 71, 13, 10, 26, 10];
  for (let i = 0; i < pngSignature.length; i++) {
    if (dataView.getUint8(i) !== pngSignature[i]) {
      throw new Error('Not a valid PNG file');
    }
  }

  // The IHDR chunk starts at byte 8 after the signature
  const ihdrOffset = 8 + 4; // 8 bytes for signature, 4 bytes for chunk length
  const ihdrType = String.fromCharCode(
    dataView.getUint8(ihdrOffset),
    dataView.getUint8(ihdrOffset + 1),
    dataView.getUint8(ihdrOffset + 2),
    dataView.getUint8(ihdrOffset + 3),
  );

  if (ihdrType !== 'IHDR') {
    throw new Error('IHDR chunk not found');
  }

  // Width is 4 bytes starting from byte 16
  const width = dataView.getUint32(ihdrOffset + 4, false); // Big-endian

  // Height is 4 bytes starting from byte 20
  const height = dataView.getUint32(ihdrOffset + 8, false); // Big-endian

  return { width, height };
}

/**
 * Low-level function to extract the dimensions of a JPEG image from its bytes.
 * Used by the YouTube Transcription module to download and process the thumbnail.
 */
export function getJpegDimensionsFromBytes(arrayBuffer: ArrayBuffer): { width: number; height: number } {
  const dataView = new DataView(arrayBuffer);

  // Check for JPEG signature
  if (dataView.getUint8(0) !== 0xFF || dataView.getUint8(1) !== 0xD8) {
    throw new Error('Not a valid JPEG file');
  }

  let offset = 2;
  while (offset < dataView.byteLength) {
    // Check for the Start Of Frame (SOF) markers
    if (dataView.getUint8(offset) === 0xFF) {
      const marker = dataView.getUint8(offset + 1);

      // SOF markers are in the range 0xC0 - 0xCF, excluding 0xC4, 0xC8, and 0xCC
      if (marker >= 0xC0 && marker <= 0xCF && marker !== 0xC4 && marker !== 0xC8 && marker !== 0xCC) {
        // Height is at offset + 5 (2 bytes)
        const height = dataView.getUint16(offset + 5, false);
        // Width is at offset + 7 (2 bytes)
        const width = dataView.getUint16(offset + 7, false);

        return { width, height };
      } else {
        // Skip this segment
        offset += 2 + dataView.getUint16(offset + 2, false);
      }
    } else {
      throw new Error('Invalid JPEG structure');
    }
  }

  throw new Error('Could not find SOF marker in JPEG');
}



================================================
FILE: src/modules/t2i/T2ISettings.tsx
================================================
import * as React from 'react';

import { Alert } from '@mui/joy';

import { FormChipControl } from '~/common/components/forms/FormChipControl';
import { FormRadioOption } from '~/common/components/forms/FormRadioControl';
import { useCapabilityTextToImage } from '~/common/components/useCapabilities';


export function T2ISettings() {

  // external state
  const {
    mayWork,
    providers,
    activeProviderId,
    setActiveProviderId,
  } = useCapabilityTextToImage();


  // derived state
  const providerOptions = React.useMemo(() => {
    const options: FormRadioOption<string>[] = [];
    providers.forEach(provider => {
      options.push({
        label: provider.label,
        value: provider.providerId,
        disabled: !provider.configured,
      });
    });
    return options.toReversed();
  }, [providers]);


  return <>

    {!mayWork ? (

      <Alert variant='soft'>
        There are no configured services for text-to-image generation.
        Please configure one service, such as an OpenAI LLM service, below.
      </Alert>

    ) : (

      <FormChipControl
        title='Text-to-Image'
        description='Active Service'
        // tooltip='Select the service to use for text-to-image generation.'
        disabled={!mayWork}
        options={providerOptions}
        value={activeProviderId ?? undefined} onChange={setActiveProviderId}
      />

    )}

  </>;
}


================================================
FILE: src/modules/t2i/dalle/DallESettings.tsx
================================================
import * as React from 'react';

import { FormControl, Option, Select, Slider, Switch, Typography } from '@mui/joy';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { FormLabelStart } from '~/common/components/forms/FormLabelStart';
import { FormRadioControl } from '~/common/components/forms/FormRadioControl';
import { Link } from '~/common/components/Link';
import { useToggleableBoolean } from '~/common/util/hooks/useToggleableBoolean';

import { DALLE_DEFAULT_IMAGE_SIZE, DalleImageSize, DalleModelSelection, resolveDalleModelId, useDalleStore } from './store-module-dalle';
import { openAIImageModelsPricing } from './openaiGenerateImages';
import { FormChipControl } from '~/common/components/forms/FormChipControl';


const CONF = {

  MODEL_OPTS: [
    { value: 'dall-e-2', label: 'DALL·E 2' },
    { value: 'dall-e-3', label: 'DALL·E 3' },
    { value: 'gpt-image-1', label: 'GPT Image' },
    { value: null, label: 'Auto' },
  ] as { value: DalleModelSelection; label: string }[],

  RES_D2: ['256x256', '512x512', '1024x1024'] as DalleImageSize[],
  RES_D3: ['1024x1024', '1792x1024', '1024x1792'] as DalleImageSize[],
  RES_GI: ['1024x1024', '1536x1024', '1024x1536'] as DalleImageSize[],

  QUALITY_GI: [
    { value: 'low', label: 'Low' },
    { value: 'medium', label: 'Medium' },
    { value: 'high', label: 'High' },
  ],
  BACKGROUND_GI: [
    // { value: 'opaque', label: 'Opaque' },
    { value: 'transparent', label: 'Transparent' },
    { value: 'auto', label: 'Auto' },
  ],
  OUT_FORMAT_GI: [
    { value: 'jpeg', label: 'JPEG' },
    { value: 'png', label: 'PNG' },
    { value: 'webp', label: 'WebP' },
  ],
  MODERATION_GI: [
    { value: 'auto', label: 'Standard' },
    { value: 'low', label: 'Less Strict' },
  ],

  STYLE_D3: [
    { value: 'natural', label: 'Natural' },
    { value: 'vivid', label: 'Vivid' },
  ],

} as const;


export function DallESettings() {

  // state
  const advanced = useToggleableBoolean(false, 'DallESettings');

  // external state
  const {
    dalleModelId, setDalleModelId,
    dalleQualityD3, setDalleQualityD3,
    dalleQualityGI, setDalleQualityGI,
    dalleSizeD3, setDalleSizeD3,
    dalleSizeD2, setDalleSizeD2,
    dalleSizeGI, setDalleSizeGI,
    dalleStyleD3, setDalleStyleD3,
    dalleNoRewrite, setDalleNoRewrite,
    dalleBackgroundGI, setDalleBackgroundGI,
    dalleOutputFormatGI, setDalleOutputFormatGI,
    dalleOutputCompressionGI, setDalleOutputCompressionGI,
    dalleModerationGI, setDalleModerationGI,
  } = useDalleStore();


  const handleDalleQualityD3Change = (event: React.ChangeEvent<HTMLInputElement>) =>
    setDalleQualityD3(event.target.checked ? 'hd' : 'standard');

  const handleDalleNoRewriteChange = (event: React.ChangeEvent<HTMLInputElement>) =>
    setDalleNoRewrite(!event.target.checked);

  const handleResolutionD3Change = (_event: any, value: DalleImageSize | null) =>
    value && setDalleSizeD3(value as any);

  const handleResolutionD2Change = (_event: any, value: DalleImageSize | null) =>
    value && setDalleSizeD2(value as any);

  const handleResolutionGIChange = (_event: any, value: DalleImageSize | null) =>
    value && setDalleSizeGI(value as any);

  const handleCompressionChange = (_event: Event, newValue: number | number[]) =>
    setDalleOutputCompressionGI(newValue as number);

  const handleModerationGIChange = (event: React.ChangeEvent<HTMLInputElement>) =>
    setDalleModerationGI(!event.target.checked ? 'low' : 'auto');


  // derived state - resolve the actual model
  const resolvedDalleModelId = resolveDalleModelId(dalleModelId);
  const isGI = resolvedDalleModelId === 'gpt-image-1';
  const isD3 = resolvedDalleModelId === 'dall-e-3';
  const isD2 = resolvedDalleModelId === 'dall-e-2';

  const isD3HD = isD3 && dalleQualityD3 === 'hd';


  // Select resolution options based on model

  const resolutions = isD2 ? CONF.RES_D2 : isD3 ? CONF.RES_D3 : CONF.RES_GI;
  const currentResolution = isD2 ? dalleSizeD2 : isD3 ? dalleSizeD3 : dalleSizeGI;
  const hasResolution = resolutions.includes(currentResolution);

  const isGICompressible = dalleOutputFormatGI === 'webp' || dalleOutputFormatGI === 'jpeg';

  const showTransparencyWarning = isGI
    && dalleBackgroundGI === 'transparent'
    && dalleOutputFormatGI !== 'png'
    && dalleOutputFormatGI !== 'webp';

  const costPerImage = openAIImageModelsPricing(resolvedDalleModelId,
    isD3 ? dalleQualityD3 : isGI ? dalleQualityGI : 'standard',
    currentResolution);


  return <>

    <FormChipControl
      title='Model'
      description={dalleModelId === null ? `Latest (${resolvedDalleModelId})` : isGI ? 'Latest' : isD3 ? 'Good' : 'Older'}
      options={CONF.MODEL_OPTS.map(opt => ({ ...opt, value: opt.value || 'auto' }))}
      value={dalleModelId || 'auto'} 
      onChange={(value) => setDalleModelId(value === 'auto' ? null : value as DalleModelSelection)}
    />

    <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
      <FormLabelStart title='Resolution'
                      description={!hasResolution
                        ? 'Unsupported'
                        : currentResolution === DALLE_DEFAULT_IMAGE_SIZE ? 'Default' : 'Custom'
                      } />
      <Select
        variant='outlined'
        // color='primary'
        value={currentResolution}
        onChange={isD2 ? handleResolutionD2Change : isD3 ? handleResolutionD3Change : handleResolutionGIChange}
        startDecorator={hasResolution ? undefined : <WarningRoundedIcon color='warning' />}
        slotProps={{
          root: { sx: { minWidth: '120px' } },
          indicator: { sx: { opacity: 0.5 } },
          button: { sx: { whiteSpace: 'inherit' } },
        }}
      >
        {resolutions.map((resolution) =>
          <Option key={'res-' + resolution} value={resolution}>
            {resolution.replace('x', ' x ')}
          </Option>,
        )}
      </Select>
    </FormControl>

    {/* GPT-Image specific settings */}
    {isGI && <>
      <FormChipControl
        title='Quality'
        // color='primary'
        description='Higher quality takes longer'
        options={CONF.QUALITY_GI}
        value={dalleQualityGI} onChange={setDalleQualityGI}
      />

      <FormChipControl
        title='Background'
        // color='primary'
        description={
          !showTransparencyWarning
            ? 'Transparency'
            : <Typography level='body-xs' color='warning'>
              Transparent background requires PNG or WebP format
            </Typography>
        }
        options={CONF.BACKGROUND_GI}
        value={dalleBackgroundGI} onChange={setDalleBackgroundGI}
      />

      {advanced.on && <FormChipControl
        title='File Format'
        // color='primary'
        description='File format for the generated image'
        options={CONF.OUT_FORMAT_GI}
        value={dalleOutputFormatGI} onChange={setDalleOutputFormatGI}
      />}

      {advanced.on && /*(dalleOutputFormatGI === 'webp' || dalleOutputFormatGI === 'jpeg') &&*/ (
        <FormControl disabled={!isGICompressible} orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center' }}>
          <FormLabelStart title='File Quality'
                          description={(isGICompressible && dalleOutputCompressionGI !== 100) ? `${100 - dalleOutputCompressionGI}% compression` : 'Uncompressed'} />
          <Slider
            aria-label='File Quality'
            color='neutral'
            disabled={dalleOutputFormatGI !== 'webp' && dalleOutputFormatGI !== 'jpeg'}
            value={!isGICompressible ? 0 : dalleOutputCompressionGI}
            onChange={handleCompressionChange}
            min={5}
            max={100}
            step={5}
            // valueLabelDisplay='auto'
            sx={{ width: '180px', mr: 1 }}
          />
        </FormControl>
      )}

      {advanced.on && <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
        <FormLabelStart title='Moderation'
                        description='Content filter strictness'
          // description={dalleModerationGI === 'low' ? 'Less Restrictive' : 'Standard (default)'}
        />
        <Switch checked={dalleModerationGI === 'auto'} onChange={handleModerationGIChange}
                startDecorator={dalleModerationGI === 'low' ? 'Less Strict' : 'Standard'} />
      </FormControl>}

    </>}


    {isD3 && <>
      <FormRadioControl
        title='Style'
        description={(isD3 && dalleStyleD3 === 'vivid') ? 'Hyper-Real' : 'Realistic'}
        disabled={!isD3}
        options={CONF.STYLE_D3}
        value={isD3 ? dalleStyleD3 : 'natural'} onChange={setDalleStyleD3}
      />

      <FormControl orientation='horizontal' disabled={!isD3} sx={{ justifyContent: 'space-between' }}>
        <FormLabelStart title='Quality'
                        description={isD3HD ? 'Detailed' : 'Default'} />
        <Switch checked={isD3HD} onChange={handleDalleQualityD3Change}
                startDecorator={isD3HD ? 'HD' : 'Standard'} />
      </FormControl>
    </>}


    {advanced.on && (isD3 || isD2) && <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title='Better Prompt'
                      description={dalleNoRewrite ? 'No Rewrite' : 'Rewrite (default)'}
                      tooltip={<>
                        OpenAI improves the prompt by rewriting it by default.
                        This can be disabled to get more control over the prompt.
                        See <Link href='https://platform.openai.com/docs/guides/images-vision' target='_blank'>
                        This OpenAI document </Link>
                      </>}
      />
      <Switch checked={!dalleNoRewrite} onChange={handleDalleNoRewriteChange}
              startDecorator={dalleNoRewrite ? 'No' : 'Improve'} />
    </FormControl>}

    {advanced.on && <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between' }}>
      <FormLabelStart title='Cost per Image'
                      tooltip={!isGI ? undefined : 'OpenAI gpt-image-1 and similar models will also be charged for the input text tokens'}
        // description={<Link href='https://platform.openai.com/docs/pricing' target='_blank' noLinkStyle sx={{ textDecoration: 'none' }}>OpenAI Pricing </Link>}
      />
      <Typography>$ {costPerImage}</Typography>
    </FormControl>}


    <FormLabelStart title={advanced.on ? 'Hide Advanced' : 'Advanced'} onClick={advanced.toggle} />

  </>;
}



================================================
FILE: src/modules/t2i/dalle/openaiGenerateImages.ts
================================================
import type { AixParts_InlineImagePart } from '~/modules/aix/server/api/aix.wiretypes';

import { apiStream } from '~/common/util/trpc.client';

import type { OpenAIAccessSchema } from '../../llms/server/openai/openai.router';

import type { DModelsServiceId } from '~/common/stores/llms/llms.service.types';
import { findServiceAccessOrThrow } from '~/modules/llms/vendors/vendor.helpers';

import type { T2iCreateImageOutput } from '../t2i.server';
import { DalleImageQuality, DalleModelId, DalleSize, resolveDalleModelId, useDalleStore } from './store-module-dalle';


/**
 * Client function to call the OpenAI image generation API.
 */
export async function openAIGenerateImagesOrThrow(modelServiceId: DModelsServiceId, prompt: string, aixInlineImageParts: AixParts_InlineImagePart[], count: number): Promise<T2iCreateImageOutput[]> {

  // Use the current settings
  const {
    dalleModelId: dalleModelSelection,
    dalleNoRewrite,
    // -- GI
    dalleSizeGI,
    dalleQualityGI,
    dalleBackgroundGI,
    dalleOutputFormatGI,
    dalleOutputCompressionGI,
    dalleModerationGI,
    // -- D3
    dalleSizeD3,
    dalleQualityD3,
    dalleStyleD3,
    // -- D2
    dalleSizeD2,
  } = useDalleStore.getState();

  // Resolve the actual model to use (null = latest)
  const dalleModelId = resolveDalleModelId(dalleModelSelection);

  // This trick is explained on: https://platform.openai.com/docs/guides/images/usage?context=node
  if (dalleNoRewrite && (dalleModelId === 'dall-e-3' || dalleModelId === 'dall-e-2'))
    prompt = 'I NEED to test how the tool works with extremely simple prompts. DO NOT add any detail, just use it AS-IS: ' + prompt;

  // Warn about a misconfiguration
  if (aixInlineImageParts?.length && (dalleModelId === 'dall-e-3' || dalleModelId === 'dall-e-2'))
    throw new Error('Image transformation is not available with this model. Please use GPT-Image-1 instead.');

  // Function to generate images in batches
  async function generateImagesBatch(imageCount: number): Promise<T2iCreateImageOutput[]> {

    // we use an async generator to stream heartbeat events while waiting for the images
    const operations = await apiStream.llmOpenAI.createImages.mutate({
      access: findServiceAccessOrThrow<{}, OpenAIAccessSchema>(modelServiceId).transportAccess,
      generationConfig: dalleModelId === 'gpt-image-1' ? {
        model: 'gpt-image-1',
        prompt: prompt.slice(0, 32000 - 1), // GPT-Image-1 accepts much longer prompts
        count: imageCount,
        size: dalleSizeGI,
        quality: dalleQualityGI,
        background: dalleBackgroundGI,
        output_format: dalleOutputFormatGI,
        output_compression: dalleOutputCompressionGI,
        moderation: dalleModerationGI,
        // response_format: 'b64_json', unsupported, as it's the default
      } : dalleModelId === 'dall-e-3' ? {
        model: 'dall-e-3',
        prompt: prompt.slice(0, 4000 - 1), // DALL-E 3 has a 4000 char limit
        count: imageCount,
        size: dalleSizeD3,
        quality: dalleQualityD3,
        style: dalleStyleD3,
        response_format: 'b64_json',
      } : {
        model: 'dall-e-2',
        prompt: prompt.slice(0, 1000 - 1), // DALL-E 2 has a 1000 char limit
        count: imageCount,
        quality: 'standard',
        size: dalleSizeD2,
        response_format: 'b64_json',
      },
      ...(aixInlineImageParts?.length && {
        editConfig: {
          inputImages: aixInlineImageParts,
          // maskImage: ...
        },
      }),
    });

    const createdImages: T2iCreateImageOutput[] = [];
    for await (const op of operations)
      if (op.p === 'createImage')
        createdImages.push(op.image);

    return createdImages;
  }


  // Calculate the number of batches required
  const isD3 = dalleModelId === 'dall-e-3';
  const maxBatchSize = isD3 ? 1 : 10; // DALL-E 3 only supports n=1, so we parallelize the requests instead

  // Operate in batches of maxBatchSize
  const batchPromises: Promise<T2iCreateImageOutput[]>[] = [];
  for (let i = 0; i < count; i += maxBatchSize) {
    const batchSize = Math.min(maxBatchSize, count - i);
    batchPromises.push(generateImagesBatch(batchSize));
  }

  // Run all image generation requests in parallel and handle all results
  const imageRefsBatchesResults = await Promise.allSettled(batchPromises);


  // Throw if ALL promises were rejected
  const allRejected = imageRefsBatchesResults.every(result => result.status === 'rejected');
  if (allRejected) {
    const errorMessages = imageRefsBatchesResults
      .map(result => {
        const reason = (result as PromiseRejectedResult).reason as any; // TRPCClientError<TRPCErrorShape>;
        return reason?.shape?.message || reason?.message || '';
      })
      .filter(message => !!message)
      .join(', ');

    throw new Error(`OpenAI image generation: ${errorMessages}`);
  }

  // Take successful results and return as a flat array
  return imageRefsBatchesResults
    .filter(result => result.status === 'fulfilled')
    .map(result => (result as PromiseFulfilledResult<T2iCreateImageOutput[]>).value) // Get the value
    .flat();
}


export function openAIImageModelsCurrentGeneratorName() {
  const dalleModelSelection = useDalleStore.getState().dalleModelId;
  const dalleModelId = resolveDalleModelId(dalleModelSelection);
  if (dalleModelId === 'gpt-image-1') return 'GPT Image';
  else if (dalleModelId === 'dall-e-3') return 'DALL·E 3';
  else if (dalleModelId === 'dall-e-2') return 'DALL·E 2';
  return 'OpenAI Image generator';
}

function openAIImageModelsPrice(modelId: DalleModelId): undefined | { inputText: number, inputImage: number, outputImage: number } {
  if (modelId === 'gpt-image-1')
    return { inputText: 5.00, inputImage: 10.0, outputImage: 40.0 };
  return undefined;
}

/**
 * Return the pricing for the OpenAI image generation API.
 * TODO: update this when the OpenAI pricing changes.
 */
export function openAIImageModelsPricing(modelId: DalleModelId, quality: DalleImageQuality, size: DalleSize): string {
  if (modelId === 'gpt-image-1') {

    // GPT-Image-1 output tokens table
    // https://platform.openai.com/docs/guides/image-generation?image-generation-model=gpt-image-1
    // NOTE: when size='auto', assume the largest size
    let outTokens = 0;
    if (quality === 'high') {
      if (size === '1024x1024') outTokens = 4160;
      else if (size === '1024x1536') outTokens = 6240;
      else if (size === '1536x1024' /*|| size === 'auto'*/) outTokens = 6208;
    } else if (quality === 'medium') {
      if (size === '1024x1024') outTokens = 1056;
      else if (size === '1024x1536') outTokens = 1584;
      else if (size === '1536x1024' /*|| size === 'auto'*/) outTokens = 1568;
    } else if (quality === 'low') {
      if (size === '1024x1024') outTokens = 272;
      else if (size === '1024x1536') outTokens = 408;
      else if (size === '1536x1024' /*|| size === 'auto'*/) outTokens = 400;
    }
    if (!outTokens) {
      console.log('[DEV] No gpt-image-1 token mapping for', quality, size);
      return 'varies by size';
    }
    const price = openAIImageModelsPrice(modelId);
    if (!price || !price.outputImage) {
      console.warn('[DEV] No gpt-image-1 pricing found for', quality, size);
      return 'varies by tokens';
    }
    const outputImageCost = price.outputImage * outTokens / 1_000_000;
    return outputImageCost.toFixed(2) + ' +'; // e.g. 0.17 for high/square
  } else if (modelId === 'dall-e-3') {
    if (quality === 'hd') {
      if (size === '1024x1024') return '0.08';
      if (size === '1792x1024' || size === '1024x1792') return '0.12';
    } else if (quality === 'standard') {
      if (size === '1024x1024') return '0.04';
      if (size === '1792x1024' || size === '1024x1792') return '0.08';
    }
  } else if (modelId === 'dall-e-2') {
    if (size === '256x256') return '0.016';
    if (size === '512x512') return '0.018';
    if (size === '1024x1024') return '0.02';
  }
  return '?';
}


================================================
FILE: src/modules/t2i/dalle/store-module-dalle.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';


// NOTE: keep all the following type definitions in sync with the server-side
//       router types, in `openai.router.ts`, which in turn is a
//       strict subset of OpenAIWire_API_Images_Generations.Request


export const DALLE_DEFAULT_IMAGE_SIZE: DalleImageSize = '1024x1024'; // this works in all
export type DalleImageSize = DalleSizeGI | DalleSizeD3 | DalleSizeD2;

export type DalleModelId = 'gpt-image-1' | 'dall-e-3' | 'dall-e-2';
export type DalleModelSelection = DalleModelId | null; // null = auto-select latest

/**
 * Resolve the actual DALL-E model to use
 * @param selection - User's selection (null = auto-select latest)
 * @returns The concrete model ID to use
 */
export function resolveDalleModelId(selection: DalleModelSelection): DalleModelId {
  // Auto-select latest model when null
  if (selection === null) {
    return 'gpt-image-1'; // Current latest model
  }
  return selection;
}

export type DalleImageQuality = DalleImageQualityGI | DalleImageQualityD3;
type DalleImageQualityGI = 'high' | 'medium' | 'low'; // gpt-image-1
type DalleImageQualityD3 = 'hd' | 'standard'; // DALL-E 3

type DalleImageStyleD3 = 'vivid' | 'natural';

type DalleBackgroundGI = 'auto' | 'transparent' | 'opaque';
type DalleOutputFormatGI = 'png' | 'jpeg' | 'webp';
type DalleModerationGI = 'auto' | 'low';

export type DalleSize = DalleSizeGI | DalleSizeD3 | DalleSizeD2;
export type DalleSizeGI = '1024x1024' | '1536x1024' | '1024x1536'; // 'auto': would force w/h inference in the server, so we remove it
export type DalleSizeD3 = '1024x1024' | '1792x1024' | '1024x1792';
export type DalleSizeD2 = '256x256' | '512x512' | '1024x1024';


interface ModuleDalleStore {

  dalleModelId: DalleModelSelection, // null = auto-select latest
  setDalleModelId: (modelId: DalleModelSelection) => void;

  dalleNoRewrite: boolean;
  setDalleNoRewrite: (noRewrite: boolean) => void;

  // -- added for gpt-image-1 [2025-04-24] --

  dalleSizeGI: DalleSizeGI;
  setDalleSizeGI: (size: DalleSizeGI) => void;

  dalleQualityGI: DalleImageQualityGI;
  setDalleQualityGI: (quality: DalleImageQualityGI) => void;

  dalleBackgroundGI: DalleBackgroundGI;
  setDalleBackgroundGI: (background: DalleBackgroundGI) => void;

  dalleOutputFormatGI: DalleOutputFormatGI;
  setDalleOutputFormatGI: (format: DalleOutputFormatGI) => void;

  dalleOutputCompressionGI: number;
  setDalleOutputCompressionGI: (compression: number) => void;

  dalleModerationGI: DalleModerationGI;
  setDalleModerationGI: (moderation: DalleModerationGI) => void;

  // -- Dall-E 3 settings --

  dalleSizeD3: DalleSizeD3,
  setDalleSizeD3: (size: DalleSizeD3) => void;

  dalleQualityD3: DalleImageQualityD3,
  setDalleQualityD3: (quality: DalleImageQualityD3) => void;

  dalleStyleD3: DalleImageStyleD3;
  setDalleStyleD3: (style: DalleImageStyleD3) => void;

  // -- Dall-E 2 settings --

  dalleSizeD2: DalleSizeD2,
  setDalleSizeD2: (size: DalleSizeD2) => void;

}

export const useDalleStore = create<ModuleDalleStore>()(
  persist(
    (set) => ({

      dalleModelId: null, // auto-select latest
      setDalleModelId: (dalleModelId) => set({ dalleModelId }),

      dalleNoRewrite: false,
      setDalleNoRewrite: (dalleNoRewrite) => set({ dalleNoRewrite }),

      // -- added for gpt-image-1 [2025-04-24] --

      dalleSizeGI: '1024x1024',
      setDalleSizeGI: (dalleSizeGI) => set({ dalleSizeGI }),

      dalleQualityGI: 'high',
      setDalleQualityGI: (dalleQualityGI) => set({ dalleQualityGI }),

      dalleBackgroundGI: 'auto',
      setDalleBackgroundGI: (dalleBackgroundGI) => set({ dalleBackgroundGI }),

      dalleOutputFormatGI: 'webp',
      setDalleOutputFormatGI: (dalleOutputFormatGI) => set({ dalleOutputFormatGI }),

      dalleOutputCompressionGI: 100,
      setDalleOutputCompressionGI: (dalleOutputCompressionGI) => set({ dalleOutputCompressionGI }),

      dalleModerationGI: 'low',
      setDalleModerationGI: (dalleModerationGI) => set({ dalleModerationGI }),

      // -- Dall-E 3 settings --

      dalleSizeD3: '1024x1024',
      setDalleSizeD3: (dalleSizeD3) => set({ dalleSizeD3 }),

      dalleQualityD3: 'hd', // was: dalleQuality: 'standard',
      setDalleQualityD3: (dalleQualityD3) => set({ dalleQualityD3 }),

      dalleStyleD3: 'vivid', // was: dalleStyle: 'vivid'
      setDalleStyleD3: (dalleStyleD3) => set({ dalleStyleD3 }),

      // -- Dall-E 2 settings --

      dalleSizeD2: '1024x1024', // was: dalleSize: DALLE_DEFAULT_IMAGE_SIZE
      setDalleSizeD2: (dalleSizeD2) => set({ dalleSizeD2 }),

    }),
    {
      name: 'app-module-dalle',
      version: 3,

      migrate: (state: unknown, fromVersion) => {

        // 2: upgrade model to gpt-image-1
        if (state && fromVersion < 2)
          state = {
            ...(state as ModuleDalleStore),
            dalleModelId: 'gpt-image-1',
          } satisfies ModuleDalleStore;

        // 3: change to auto-select latest (null)
        if (state && fromVersion < 3)
          state = {
            ...(state as ModuleDalleStore),
            dalleModelId: null, // auto-select latest
          } satisfies ModuleDalleStore;

        return state;
      },

    },
  ),
);


================================================
FILE: src/modules/t2i/localai/localaiGenerateImages.ts
================================================
// import { apiAsync } from '~/common/util/trpc.client';
//
// import type { DModelsServiceId } from '~/modules/llms/store-llms';
// import { findAccessForSourceOrThrow } from '~/modules/llms/vendors/vendors.registry';
//
// /*
//  * FIXME: LocalAI t2i integration is VERY experimental and WILL NOT WORK at this time.
//  * This is just a skeleton that uses the OpenAI Transport to perform the same API call.
//  *
//  * To be continued.
//  */
//
// export async function localaiGenerateImages(modelsServiceId: DModelsServiceId, prompt: string, _count: number): Promise<string[]> {
//
//   // parallelize the image generation depending on how many images can a model generate
//   const imagePromises: Promise<string[]>[] = [];
//   while (_count > 0) {
//
//     // per-request count
//     const perRequestCount = 1; // Math.min(_count, isD3 ? 1 : 10);
//
//     const imageRefPromise = apiAsync.llmOpenAI.createImages.mutate({
//       access: findAccessForSourceOrThrow(modelsServiceId),
//       config: {
//         prompt: prompt,
//         count: perRequestCount,
//         model: 'stablediffusion' as any, //  dalleModelId,
//         quality: 'hd', // dalleQuality,
//         responseFormat: 'b64_json',
//         size: '512x512', // dalleSize,
//         style: 'vivid', // dalleStyle,
//       },
//     }).then(images =>
//       // convert to markdown image references
//       images.map(({ imageUrl, altText }) => `![${altText}](${imageUrl})`),
//     );
//
//     imagePromises.push(imageRefPromise);
//     _count -= perRequestCount;
//   }
//
//   // run all image generation requests
//   const imageRefsBatchesResults = await Promise.allSettled(imagePromises);
//
//   // throw if ALL promises were rejected
//   const allRejected = imageRefsBatchesResults.every(result => result.status === 'rejected');
//   if (allRejected) {
//     const errorMessages = imageRefsBatchesResults
//       .map(result => {
//         const reason = (result as PromiseRejectedResult).reason as any; // TRPCClientError<TRPCErrorShape>;
//         return reason?.shape?.message || reason?.message || '';
//       })
//       .filter(message => !!message)
//       .join(', ');
//
//     throw new Error(`LocalAI image generation: ${errorMessages}`);
//   }
//
//   // take successful results and return as string[]
//   return imageRefsBatchesResults
//     .filter(result => result.status === 'fulfilled') // Only take fulfilled promises
//     .map(result => (result as PromiseFulfilledResult<string[]>).value) // Extract the value
//     .flat();
// }


================================================
FILE: src/modules/trade/BackupRestore.tsx
================================================
// noinspection ExceptionCaughtLocallyJS

import * as React from 'react';
import { fileOpen, fileSave, FileWithHandle } from 'browser-fs-access';

import { Box, Button, Checkbox, Divider, FormControl, FormLabel, Sheet, Switch, Typography } from '@mui/joy';
import DownloadIcon from '@mui/icons-material/Download';
import DoneIcon from '@mui/icons-material/Done';
import ErrorIcon from '@mui/icons-material/Error';
import RestoreIcon from '@mui/icons-material/Restore';
import WarningRoundedIcon from '@mui/icons-material/WarningRounded';

import { GoodModal } from '~/common/components/modals/GoodModal';
import { Is } from '~/common/util/pwaUtils';
import { Release } from '~/common/app.release';
import { createModuleLogger } from '~/common/logger';
import { downloadBlob } from '~/common/util/downloadUtils';


// configuration
const BACKUP_FILE_FORMAT = 'Big-AGI Flash File';
const BACKUP_FORMAT_VERSION = '1.2';
const BACKUP_FORMAT_VERSION_NUMBER = 102000;
const WINDOW_RELOAD_DELAY = 200;
const EXCLUDED_LOCAL_STORAGE_KEYS = [
  'agi-logger-log', // the log cannot be restored as it's in-mem and being persisted while this is running
];
const EXCLUDED_IDB_DATABASES = [
  'Big-AGI', // exclude DBlobs IDB
];
const INCLUDED_IDB_KEYS: { [dbName: string]: { [storeName: string]: string[]; }; } = {
  'keyval-store': { 'keyval': ['app-chats'] }, // include ONLY the chats IDB
};


// Flashing Backup Schema
// NOTE: ABSOLUTELY NOT CHANGE WITHOUT CHANGING THE saveFlashObjectOrThrow_Streaming TOO (!)
interface DFlashSchema {
  _t: 'agi.flash-backup';
  _v: number;
  metadata: {
    version: string;
    timestamp: string;
    application: string;
    backupType: 'full' | 'partial' | 'auto-before-restore';
  };
  storage: {
    localStorage: Record<string, any>;
    indexedDB: Record<string, any>; // DBName -> StoreName -> { key: any, value: any }[]
  };
}


// -- Utility Functions --

const logger = createModuleLogger('client', 'flash');

function _getErrorText(error: unknown): string {
  if (error instanceof Error) return error.message;
  if (typeof error === 'string') return error;
  return 'Unknown error';
}


// -- LocalStorage Read --

async function getAllLocalStorageKeyValues(): Promise<Record<string, any>> {
  const data: Record<string, any> = {};
  try {
    for (let i = 0; i < localStorage.length; i++) {
      const key = localStorage.key(i);
      if (!key || EXCLUDED_LOCAL_STORAGE_KEYS.includes(key)) continue;
      try {
        const value = localStorage.getItem(key);
        if (value !== null) {
          try {
            data[key] = JSON.parse(value);
          } catch {
            data[key] = value; // Store as string if not valid JSON
          }
        }
      } catch (error) {
        console.error(`Error reading localStorage key "${key}":`, error);
      }
    }
  } catch (error) {
    console.error('Error accessing localStorage:', error);
    // return what we have
  }
  return data;
}


// -- IndexedDB Read --

async function getAllIndexedDBData(ignoreExclusions: boolean): Promise<Record<string, any>> {
  const data: Record<string, any> = {};
  try {
    const dbNames = await listIndexedDBDatabaseNames();
    for (const dbName of dbNames) {
      if (!ignoreExclusions && EXCLUDED_IDB_DATABASES.includes(dbName)) continue;
      try {
        data[dbName] = await getIndexedDBContent(dbName);
      } catch (error) {
        console.error(`Error getting content for IndexedDB "${dbName}":`, error);
      }
    }
  } catch (error) {
    console.error('Error processing IndexedDB databases:', error);
    // return what we have
  }
  return data;
}

async function listIndexedDBDatabaseNames(): Promise<string[]> {
  try {
    // use the modern API to list all
    if ('databases' in indexedDB) {
      const dbs = await window.indexedDB.databases() as IDBDatabaseInfo[];
      return dbs.map(db => db.name || '').filter(Boolean);
    }

    // fallback: try-open (and close right away) known names
    const existingDbs: string[] = [];
    for (const dbName of ['keyval-store']) {
      try {
        const idb = window.indexedDB;
        const request = idb.open(dbName);
        await new Promise<void>((resolve) => {
          request.onblocked = () => resolve();
          request.onerror = () => resolve(); // not an error for us
          request.onsuccess = () => {
            request.result.close();
            existingDbs.push(dbName);
            resolve();
          };
        });
      } catch {
      }
    }

    return existingDbs;
  } catch (error) {
    logger.error('Error listing IndexedDB databases:', error);
    return [];
  }
}

function getIndexedDBContent(dbName: string): Promise<Record<string, { key: any; value: any }[]>> {
  return new Promise((resolve, reject) => {
    let dbRequest: IDBOpenDBRequest | null = null;

    // set a 5 seconds timeout to prevent hanging on open if it never does
    const timeout = setTimeout(() => {
      if (dbRequest) {
        try {
          // Try to abort the request if possible
          if ('abort' in dbRequest) {
            (dbRequest as any).abort();
          }
        } catch {
        }
        reject(new Error(`Timeout opening IndexedDB "${dbName}"`));
      }
    }, 5000); // 5 second timeout

    try {
      dbRequest = window.indexedDB.open(dbName);

      dbRequest.onerror = (event) => {
        clearTimeout(timeout);
        const target = event.target as IDBRequest;
        const errorMsg = target.error ? target.error.message : 'Unknown error';
        reject(new Error(`Failed to open IndexedDB "${dbName}": ${errorMsg}`));
      };

      dbRequest.onsuccess = (event) => {
        clearTimeout(timeout);
        const db = (event.target as IDBOpenDBRequest).result;
        const storeNames = Array.from(db.objectStoreNames);
        const dbData: Record<string, { key: any; value: any }[]> = {};

        if (storeNames.length === 0) {
          db.close();
          resolve(dbData);
          return;
        }

        let transactionError = false;
        const transaction = db.transaction(storeNames, 'readonly');

        transaction.onerror = (event) => {
          transactionError = true;
          const target = event.target as IDBTransaction;
          const errorMsg = target.error ? target.error.message : 'Unknown error';
          logger.error(`transaction error in "${dbName}": ${errorMsg}`);
          // Don't reject - we'll resolve with partial data at completion
        };

        transaction.oncomplete = () => {
          db.close();
          if (transactionError)
            logger.warn(`transaction for "${dbName}" completed with some errors. Data may be incomplete.`);
          resolve(dbData);
        };

        storeNames.forEach(storeName => {
          dbData[storeName] = [];
          try {
            const store = transaction.objectStore(storeName);
            const keyInclusionList = INCLUDED_IDB_KEYS[dbName]?.[storeName] ?? undefined;
            const hasInclusionFilters = !!keyInclusionList && keyInclusionList.length > 0;

            store.openCursor().onsuccess = (event) => {
              const cursor = (event.target as IDBRequest<IDBCursorWithValue>).result;
              if (cursor) {
                // convert key to string for matching if needed
                const keyAsString = typeof cursor.key === 'string' ? cursor.key : cursor.key !== null ? String(cursor.key) : null;

                // if no inclusion filters include everything, otherwise include only keys that include the pattern
                const shouldInclude = !hasInclusionFilters || (keyAsString && keyInclusionList!.some(pattern => keyAsString.includes(pattern)));
                if (shouldInclude)
                  dbData[storeName].push({ key: cursor.key, value: cursor.value });
                try {
                  cursor.continue();
                } catch (error) {
                  logger.error(`Error continuing cursor for store "${storeName}":`, error);
                  // Can't continue but we have some data
                }
              }
            };
          } catch (error) {
            logger.error(`Error processing store "${storeName}":`, error);
            // Continue with other stores
          }
        });
      };
    } catch (error) {
      clearTimeout(timeout);
      reject(new Error(`Error setting up IndexedDB request for "${dbName}": ${_getErrorText(error)}`));
    }
  });
}


// --- Data Restore Functions ---

async function restoreLocalStorage(data: Record<string, any>): Promise<void> {
  try {
    localStorage.clear();
    for (const key in data) {
      try {
        const value = data[key];
        localStorage.setItem(key, typeof value === 'string' ? value : JSON.stringify(value));
      } catch (error) {
        logger.error(`Error restoring localStorage key "${key}":`, error);
      }
    }
  } catch (error) {
    throw new Error(`Failed to restore localStorage: ${_getErrorText(error)}`);
  }
}

async function restoreIndexedDB(allDbData: Record<string, any>): Promise<void> {
  // expected local DBs to restore over, from the latest `v2-dev` (2025-05-14)
  const dbTargetVersions: { [dbName: string]: number } = {
    'keyval-store': 1,
    'Big-AGI': 10, // Dexie multiplied the version (1) by 10 (https://github.com/dexie/Dexie.js/issues/59)
  };

  // process each database in sequence
  for (const dbName in allDbData) {
    try {
      const dbStoresData = allDbData[dbName] as Record<string, { key: any; value: any }[]>;
      const dbStoreNames = Object.keys(dbStoresData);
      const dbStoreVersion = dbTargetVersions[dbName] || 1;

      await new Promise<void>((resolve, reject) => {
        try {
          const openRequest = window.indexedDB.open(dbName, dbStoreVersion);

          // If the DB was not there, it means we're loading the flash over the new architecture (ZYNC). In this case, we need to recreate
          // the stores inside this new DB first.
          openRequest.onupgradeneeded = (event) => {
            const db = (event.target as IDBOpenDBRequest).result;
            logger.debug(`onupgradeneeded triggered for DB "${dbName}" (oldVersion: ${event.oldVersion}, newVersion: ${event.newVersion})`);

            // Create object stores based on the database name
            if (dbName === 'keyval-store') {
              // Create the keyval object store if it doesn't exist
              if (!db.objectStoreNames.contains('keyval')) {
                db.createObjectStore('keyval');
                logger.info(`Created keyval object store in keyval-store database`);
              }
            } else if (dbName === 'Big-AGI') {
              // Create the largeAssets object store with all its indices if it doesn't exist
              if (!db.objectStoreNames.contains('largeAssets')) {
                const largeAssetsStore = db.createObjectStore('largeAssets', { keyPath: 'id' });
                // Create all the indices as defined in dblobs.db.ts
                // Index common properties (and compound indexes)
                largeAssetsStore.createIndex('[contextId+scopeId]', ['contextId', 'scopeId']);
                largeAssetsStore.createIndex('assetType', 'assetType');
                largeAssetsStore.createIndex('[assetType+contextId+scopeId]', ['assetType', 'contextId', 'scopeId']);
                largeAssetsStore.createIndex('data.mimeType', 'data.mimeType');
                largeAssetsStore.createIndex('origin.ot', 'origin.ot');
                largeAssetsStore.createIndex('origin.source', 'origin.source');
                largeAssetsStore.createIndex('createdAt', 'createdAt');
                largeAssetsStore.createIndex('updatedAt', 'updatedAt');
                logger.info(`Created largeAssets object store with all indices in Big-AGI database`);
              }
            } else {
              // For any unknown database, try to create the object stores that are in the backup
              for (const storeName of dbStoreNames) {
                if (!db.objectStoreNames.contains(storeName)) {
                  logger.warn(`Creating object store "${storeName}" in unknown DB "${dbName}" without schema`);
                  try {
                    db.createObjectStore(storeName);
                  } catch (error) {
                    logger.error(`Failed to create object store "${storeName}" in DB "${dbName}":`, error);
                  }
                }
              }
            }
          };

          openRequest.onerror = (event) => {
            const target = event.target as IDBOpenDBRequest;
            const errorMsg = target.error ? target.error.message : 'Unknown error';
            reject(new Error(`Failed to open "${dbName}": ${errorMsg}`));
          };

          openRequest.onsuccess = (event) => {
            const db = (event.target as IDBOpenDBRequest).result;
            const existingStoreNames = Array.from(db.objectStoreNames);
            const storesToRestore = dbStoreNames.filter(name => existingStoreNames.includes(name));

            if (storesToRestore.length < dbStoreNames.length)
              logger.error(`No matching stores found in ${dbName}, expected '${dbStoreNames.join(', ')}' but found '${existingStoreNames.join(', ')}'`);
            if (storesToRestore.length === 0) {
              db.close();
              resolve();
              return;
            }

            // Create a transaction to clear and then restore each store
            try {
              const transaction = db.transaction(storesToRestore, 'readwrite');
              let transactionFailed = false;

              transaction.onerror = (event) => {
                transactionFailed = true;
                const target = event.target as IDBTransaction;
                const errorMsg = target.error ? target.error.message : 'Unknown error';
                logger.error(`Transaction error during restore of "${dbName}": ${errorMsg}`);
                // Don't reject - we'll resolve at completion
              };

              transaction.oncomplete = () => {
                db.close();
                if (transactionFailed) {
                  logger.warn(`Transaction for "${dbName}" completed with some errors. Restore may be incomplete.`);
                } else {
                  logger.warn(`Successfully restored database: ${dbName}`);
                }
                resolve();
              };

              // Process each store sequentially
              let completedStores = 0;
              const processNextStore = (storeIndex: number) => {
                if (storeIndex >= storesToRestore.length) return;

                const storeName = storesToRestore[storeIndex];
                const store = transaction.objectStore(storeName);
                const items = dbStoresData[storeName] || [];

                // 1. Clear the store
                const clearRequest = store.clear();
                clearRequest.onsuccess = () => {
                  // logger.debug(`Cleared store "${storeName}" in "${dbName}"`);

                  // 2. Add all items back
                  let itemsProcessed = 0;

                  // Add each item from the backup
                  items.forEach(item => {
                    try {
                      // Handle possible cases:
                      // 1. Store with keyPath - add value directly
                      // 2. Store without keyPath - add value with explicit key
                      let request: IDBRequest;

                      // Special handling for keyval-store which has no keyPath
                      if (dbName === 'keyval-store' && storeName === 'keyval') {
                        request = store.add(item.value, item.key);
                      } else if (store.keyPath !== null) {
                        // Store has a keyPath, add value directly
                        request = store.add(item.value);
                      } else {
                        // Store has no keyPath, add with explicit key
                        request = store.add(item.value, item.key);
                      }

                      request.onsuccess = () => {
                        itemsProcessed++;
                        if (itemsProcessed === items.length) {
                          logger.info(`Restored ${items.length} items to store "${storeName}" in "${dbName}"`);
                          completedStores++;

                          // Process next store
                          processNextStore(storeIndex + 1);
                        }
                      };

                      request.onerror = (event) => {
                        const error = (event.target as IDBRequest).error;
                        logger.error(`Error adding item to "${storeName}" in "${dbName}" (Key: ${
                          typeof item.key === 'object' ? JSON.stringify(item.key) : item.key
                        }): ${error?.message || 'Unknown error'}`);

                        itemsProcessed++;
                        if (itemsProcessed === items.length) {
                          logger.warn(`Restored ${items.length} items to store "${storeName}" with some errors`);
                          completedStores++;

                          // Process next store
                          processNextStore(storeIndex + 1);
                        }
                      };
                    } catch (error) {
                      logger.error(`Error processing item in "${storeName}": ${_getErrorText(error)}`);
                      itemsProcessed++;
                      if (itemsProcessed === items.length) {
                        processNextStore(storeIndex + 1);
                      }
                    }
                  });

                  // Handle empty store case
                  if (items.length === 0) {
                    logger.warn(`No items to restore for store "${storeName}"`);
                    completedStores++;
                    processNextStore(storeIndex + 1);
                  }
                };

                clearRequest.onerror = (event) => {
                  logger.error(`Error clearing store "${storeName}": ${(event.target as IDBRequest).error?.message || 'Unknown error'}`);
                  // Try to continue anyway
                  completedStores++;
                  processNextStore(storeIndex + 1);
                };
              };

              // Start processing the first store
              processNextStore(0);
            } catch (error) {
              db.close();
              reject(new Error(`Error setting up transaction for "${dbName}": ${_getErrorText(error)}`));
            }
          };

          openRequest.onblocked = () => {
            logger.warn(`Open request for "${dbName}" is blocked, but continuing anyway`);
            // Let onsuccess or onerror handle it
          };
        } catch (error) {
          reject(new Error(`Error setting up database open request for "${dbName}": ${_getErrorText(error)}`));
        }
      });

      // logger.log(`Completed restore process for: ${dbName}`);
    } catch (error) {
      logger.error(`Error restoring database "${dbName}": ${_getErrorText(error)}`);
      // Continue with other databases even if one fails
    }
  }
}

// --- Validation and Utility Functions ---

function isValidBackup(data: any): data is DFlashSchema {
  return !!(
    data &&
    typeof data === 'object' &&
    data.metadata &&
    typeof data.metadata === 'object' &&
    typeof data.metadata.version === 'string' &&
    typeof data.metadata.timestamp === 'string' &&
    typeof data.metadata.application === 'string' &&
    data.storage &&
    typeof data.storage === 'object' &&
    typeof data.storage.localStorage === 'object' &&
    typeof data.storage.indexedDB === 'object'
  );
}

/**
 * Creates a backup object and optionally saves it to a file
 */
async function saveFlashObjectOrThrow(backupType: 'full' | 'auto-before-restore', forceDownloadOverFileSave: boolean, ignoreExclusions: boolean, saveToFileName: string) {

  // for mobile, try with the download link approach - we keep getting truncated JSON save-files in other paths, streaming or not
  if (forceDownloadOverFileSave || !Is.Desktop)
    return createFlashObject(backupType, ignoreExclusions)
      .then(JSON.stringify)
      .then((flashString) => {
        logger.info(`Expected flash file size: ${flashString.length.toLocaleString()} bytes`);
        downloadBlob(new Blob([flashString], { type: 'application/json' }), saveToFileName);
        return undefined;
      });

  // for mobile, try a different implementation, with streaming creation, to hopefully avoid truncation
  // if (forceStreaming || !Is.Desktop)
  //   return saveFlashObjectOrThrow_Streaming(backupType, ignoreExclusions, saveToFileName);

  // run after the file picker has confirmed a file
  const flashBlobPromise = new Promise<Blob>(async (resolve) => {
    // create the backup object (heavy operation)
    const flashObject = await createFlashObject(backupType, ignoreExclusions);

    // WARNING: on Mobile, the JSON serialization could fail silently - we disable pretty-print to conserve space
    const flashString = !Is.Desktop ? JSON.stringify(flashObject)
      : JSON.stringify(flashObject, null, 2);

    logger.info(`Expected flash file size: ${flashString.length.toLocaleString()} bytes`);

    resolve(new Blob([flashString], { type: 'application/json' }));
  });

  return await fileSave(flashBlobPromise, {
    description: BACKUP_FILE_FORMAT,
    extensions: ['.agi.json', '.json'],
    fileName: saveToFileName,
  });
}

// async function saveFlashObjectOrThrow_Streaming(backupType: 'full' | 'auto-before-restore', ignoreExclusions: boolean, saveToFileName: string) {
//
//   // on mobile, stringify without spaces
//   const spacesForMobile = Is.Desktop ? 2 : undefined;
//
//   // create JSON in chunks without ever holding the entire string in memory
//   const encoder = new TextEncoder();
//
//   // create a streaming response - this is the key to avoiding truncation
//   const response = new Response(
//     new ReadableStream({
//       async start(controller) {
//         try {
//           // start the JSON object
//           controller.enqueue(encoder.encode('{\n'));
//           controller.enqueue(encoder.encode(`  "_t": "agi.flash-backup",\n`));
//           controller.enqueue(encoder.encode(`  "_v": ${BACKUP_FORMAT_VERSION_NUMBER},\n`));
//           controller.enqueue(encoder.encode(`  "metadata": ${JSON.stringify({
//             version: BACKUP_FORMAT_VERSION,
//             timestamp: new Date().toISOString(),
//             application: 'Big-AGI',
//             backupType,
//           }, null, spacesForMobile).replace(/^/gm, '  ')},\n`));
//
//           // stream storage section
//           controller.enqueue(encoder.encode('  "storage": {\n'));
//
//           // add localStorage (usually smaller)
//           const localStorage = await getAllLocalStorageKeyValues();
//           controller.enqueue(encoder.encode('    "localStorage": '));
//           controller.enqueue(encoder.encode(JSON.stringify(localStorage, null, spacesForMobile).replace(/^/gm, '    ')));
//           controller.enqueue(encoder.encode(',\n'));
//
//           // add indexedDB with manual chunking for large objects
//           controller.enqueue(encoder.encode('    "indexedDB": {\n'));
//
//           const indexedDB = await getAllIndexedDBData(ignoreExclusions);
//           const dbNames = Object.keys(indexedDB);
//           for (let i = 0; i < dbNames.length; i++) {
//             const dbName = dbNames[i];
//             const isLast = i === dbNames.length - 1;
//
//             controller.enqueue(encoder.encode(`      "${dbName}": `));
//
//             // clean nulls and control characters
//             const sanitized = JSON.stringify(indexedDB[dbName], (_key, value) => {
//               if (typeof value === 'string')
//                 return value.replace(/\u0000/g, '');
//               return value;
//             }, spacesForMobile).replace(/^/gm, '      ');
//
//             controller.enqueue(encoder.encode(sanitized));
//             controller.enqueue(encoder.encode(isLast ? '\n' : ',\n'));
//           }
//
//           // close all objects
//           controller.enqueue(encoder.encode('    }\n'));
//           controller.enqueue(encoder.encode('  }\n'));
//           controller.enqueue(encoder.encode('}\n'));
//
//           controller.close();
//         } catch (error) {
//           console.error('Error creating stream:', error);
//           controller.error(error);
//         }
//       },
//     }),
//     {
//       headers: {
//         'Content-Type': 'application/json',
//         'Content-Disposition': `attachment; filename="${saveToFileName}"`,
//       },
//     },
//   );
//
//   // the fileSave implementation will use the body.pipeTo(writable) code path
//   // which is perfect for large files as it streams directly to disk
//   await fileSave(response, {
//     description: BACKUP_FILE_FORMAT,
//     extensions: ['.agi.json', '.json'],
//     fileName: saveToFileName,
//   });
// }

async function createFlashObject(backupType: 'full' | 'auto-before-restore', ignoreExclusions: boolean): Promise<DFlashSchema> {
  return {
    _t: 'agi.flash-backup',
    _v: BACKUP_FORMAT_VERSION_NUMBER,
    metadata: {
      version: BACKUP_FORMAT_VERSION,
      timestamp: new Date().toISOString(),
      application: 'Big-AGI',
      backupType,
    },
    storage: {
      localStorage: await getAllLocalStorageKeyValues(),
      indexedDB: await getAllIndexedDBData(ignoreExclusions),
    },
  };
}


/**
 * Backup and Restore (Flashing) functionality for Big-AGI client-side data.
 * Saves and fully restores localStorage and IndexedDB data.
 */
export function FlashRestore(props: { unlockRestore?: boolean }) {

  // state
  const [restoreState, setRestoreState] = React.useState<'idle' | 'processing' | 'confirm' | 'success' | 'error'>('idle');
  const [errorMessage, setErrorMessage] = React.useState<string | null>(null);
  const [backupDataForRestore, setBackupDataForRestore] = React.useState<DFlashSchema | null>(null);
  const [restoreLocalStorageEnabled, setRestoreLocalStorageEnabled] = React.useState(false);
  const [restoreIndexedDBEnabled, setRestoreIndexedDBEnabled] = React.useState(false);

  // derived state
  const isUnlocked = !!props.unlockRestore;
  const isBusy = restoreState === 'processing';


  // handlers

  const handleRestoreLoad = React.useCallback(async () => {
    setBackupDataForRestore(null);
    setRestoreState('idle');
    setErrorMessage(null);

    // user selects a file
    let file: FileWithHandle;
    try {
      file = await fileOpen({
        extensions: ['.agi.json', '.json'],
        description: BACKUP_FILE_FORMAT,
        mimeTypes: ['application/json'],
      });
    } catch (error: any) {
      // handle an error saving
      if (error?.name !== 'AbortError') {
        setRestoreState('error');
        setErrorMessage(`Restore failed: ${_getErrorText(error)}`);
      }
      return;
    }

    try {
      setRestoreState('processing');
      const content = await file.text();
      let data;
      try {
        data = JSON.parse(content);
      } catch (error) {
        throw new Error(`Restore failed: Invalid JSON in Flash file: ${_getErrorText(error)}`);
      }

      // validations
      if (!isValidBackup(data))
        throw new Error(`Invalid Flash file format. This does not appear to be a valid ${BACKUP_FILE_FORMAT}.`);
      if (data.metadata.application !== 'Big-AGI' || !data.storage.indexedDB || !data.storage.localStorage)
        throw new Error(`Incompatible Flash file. Found application "${data.metadata.application}" but expected "Big-AGI".`);

      // load data purely into state, and ready for confirmation
      setBackupDataForRestore(data);
      setRestoreState('confirm');
      // Reset checkboxes to OFF by default for safety
      setRestoreLocalStorageEnabled(false);
      setRestoreIndexedDBEnabled(false);
    } catch (error: any) {
      logger.error('Restore preparation failed:', error);
      setRestoreState('error');
      setErrorMessage(`Restore failed: ${_getErrorText(error)}`);
    }
  }, []);

  const handleRestoreFlashConfirmed = React.useCallback(async () => {
    if (!backupDataForRestore) return;
    setRestoreState('processing');
    setErrorMessage(null);
    try {
      // 1. Auto-backup current state (best effort)
      // NOTE: disabled: more confusing/harmful than useful
      // try {
      //   const dateStr = new Date().toISOString().split('.')[0].replace('T', '-');
      //   await saveFlashObjectOrThrow(
      //     'auto-before-restore',
      //     true, // auto-backup with streaming
      //     false, // auto-backup without images
      //     `Big-AGI-auto-pre-flash-${dateStr}.json`,
      //   );
      //   logger.info('Created auto-backup before restore');
      // } catch (error: any) {
      //   if (error?.name === 'AbortError')
      //     logger.warn('Auto-backup before restore dismissed by the user');
      //   else
      //     logger.warn('Auto-backup before restore failed:', error);
      //   // non-fatal, proceed with restore
      // }

      // 2. Restore data based on user selections
      if (restoreLocalStorageEnabled) {
        await restoreLocalStorage(backupDataForRestore.storage.localStorage);
        logger.info('localStorage restore complete');
      }
      if (restoreIndexedDBEnabled) {
        await restoreIndexedDB(backupDataForRestore.storage.indexedDB);
        logger.info('indexedDB restore complete');
      }

      // Check if nothing was selected
      if (!restoreLocalStorageEnabled && !restoreIndexedDBEnabled)
        throw new Error('No data was selected for restore. Please select at least one option.');

      setRestoreState('success');

      // 3. Alert and reload
      setTimeout(() => {
        alert('Backup restored successfully.\n\nThe application will now reload to apply the changes.');
        window.location.reload();
      }, WINDOW_RELOAD_DELAY);

    } catch (error: any) {
      logger.error('Restore operation failed:', error);
      setRestoreState('error');
      setErrorMessage(`Restore failed: ${_getErrorText(error)}`);
    } finally {
      setBackupDataForRestore(null);
    }
  }, [backupDataForRestore, restoreIndexedDBEnabled, restoreLocalStorageEnabled]);

  const handleCancelRestore = React.useCallback(() => {
    setRestoreState('idle');
    setBackupDataForRestore(null);
  }, []);

  return <>

    <Typography level='body-sm' mt={2}>
      Restore a full installation:
    </Typography>
    <Button
      variant='soft'
      aria-label='Restore from flash file'
      color={restoreState === 'success' ? 'success' : restoreState === 'error' ? 'danger' : 'primary'}
      disabled={isBusy || !isUnlocked}
      loading={restoreState === 'processing'}
      endDecorator={restoreState === 'success' ? <DoneIcon /> : restoreState === 'error' ? <ErrorIcon /> : <RestoreIcon />}
      onClick={handleRestoreLoad}
      sx={{
        boxShadow: 'md',
        backgroundColor: 'background.popup',
        justifyContent: 'space-between',
      }}
    >
      {restoreState === 'success' ? 'Restore Complete' : restoreState === 'error' ? 'Restore Failed' : restoreState === 'processing' ? 'Restoring...' : 'Re-Flash from File'}
    </Button>
    {/*{!errorMessage && <Typography level='body-xs'>*/}
    {/*  Warning: Replaces current data.<br />Requires page reload.*/}
    {/*</Typography>}*/}

    {/* Error Display */}
    {errorMessage && (
      <Sheet variant='soft' color='danger' sx={{ px: 1.5, py: 1, borderRadius: 'sm', display: 'grid', gap: 1 }}>
        <Typography color='danger' level='body-sm'>
          {errorMessage}
        </Typography>
        <Button variant='soft' color='danger' size='sm' onClick={() => setErrorMessage(null)}>
          Dismiss
        </Button>
      </Sheet>
    )}

    {/* Confirmation Dialog */}
    <GoodModal
      title={`Confirm ${Release.App.versionName} Restore`}
      strongerTitle
      dividers
      hideBottomClose
      open={restoreState === 'confirm'}
      onClose={handleCancelRestore}
    >
      <Typography textColor='text.secondary'>
        This will <Typography fontWeight='lg' color='danger'>replace all current application data</Typography> with the content from the selected flash file.&nbsp;
        <Typography fontWeight='lg' color='danger'>WARNING: This is a destructive operation that may break the app.</Typography>
      </Typography>
      {/*<Typography fontWeight='md'>*/}
      {/*  An automatic backup of your current data will be attempted before proceeding.*/}
      {/*</Typography>*/}
      {backupDataForRestore?.metadata && (
        <Box sx={{ mt: 1, p: 1.5, bgcolor: 'background.level1', borderRadius: 'sm', border: '1px solid', borderColor: 'neutral.outlinedBorder', fontSize: 'sm' }}>
          <Box fontWeight='md' mb={1}>Flash File Details:</Box>
          <Divider sx={{ my: 1 }} />
          Created: {new Date(backupDataForRestore.metadata.timestamp).toLocaleString()}<br />
          Backup Type: {backupDataForRestore.metadata.backupType}<br />
          Version: {backupDataForRestore.metadata.version}<br />
          <Divider sx={{ my: 1 }} />
          Full Databases: {Object.keys(backupDataForRestore.storage.indexedDB).length}<br />
          Setting Groups: {Object.keys(backupDataForRestore.storage.localStorage).length}<br />
        </Box>
      )}
      <Box sx={{ mt: 2 }}>
        <Typography level='body-sm' sx={{ mb: 1 }} color={!restoreLocalStorageEnabled && !restoreIndexedDBEnabled ? 'danger' : undefined}>
          Select what to restore:
        </Typography>
        <Sheet variant='soft' sx={{ p: 2, borderRadius: 'md', border: '1px solid', borderColor: 'neutral.outlinedBorder', display: 'flex', flexDirection: { xs: 'column', sm: 'row' }, gap: 2 }}>
          <FormControl orientation='horizontal' sx={{ gap: 1, flex: 1 }}>
            <Checkbox
              size='md'
              color='neutral'
              checked={restoreLocalStorageEnabled}
              onChange={(event) => setRestoreLocalStorageEnabled(event.target.checked)}
            />
            <FormLabel sx={{ fontWeight: 'sm', display: 'flex', flexDirection: 'column', alignItems: 'flex-start' }}>
              App Settings
              <Typography level='body-xs' sx={{ fontWeight: 'normal', color: 'text.secondary' }}>
                (preferences, models)
              </Typography>
            </FormLabel>
          </FormControl>
          <FormControl orientation='horizontal' sx={{ gap: 1, flex: 1 }}>
            <Checkbox
              size='md'
              color='neutral'
              checked={restoreIndexedDBEnabled}
              onChange={(event) => setRestoreIndexedDBEnabled(event.target.checked)}
            />
            <FormLabel sx={{ fontWeight: 'sm', display: 'flex', flexDirection: 'column', alignItems: 'flex-start' }}>
              Conversations
              <Typography level='body-xs' sx={{ fontWeight: 'normal', color: 'text.secondary' }}>
                (chats, attachments)
              </Typography>
            </FormLabel>
          </FormControl>
        </Sheet>
      </Box>
      <Box sx={{ display: 'flex', gap: 1, justifyContent: 'flex-end', pt: 2 }}>
        <Button variant='plain' color='neutral' onClick={handleCancelRestore}>
          Cancel
        </Button>
        <Button
          variant='solid'
          color='danger'
          onClick={handleRestoreFlashConfirmed}
          loading={restoreState === 'processing'}
          disabled={!restoreLocalStorageEnabled && !restoreIndexedDBEnabled}
        >
          Replace Selected Data
        </Button>
      </Box>
    </GoodModal>

  </>;
}


export function FlashBackup(props: {
  onStartedBackup?: () => void;
}) {

  // state
  const [includeImages, setIncludeImages] = React.useState(false);
  const [backupState, setBackupState] = React.useState<'idle' | 'processing' | 'success' | 'error'>('idle');
  const [errorMessage, setErrorMessage] = React.useState<string | null>(null);

  // derived state
  const { onStartedBackup } = props;
  const isProcessing = backupState === 'processing';

  // handlers

  const handleFullBackup = React.useCallback(async (event: React.MouseEvent) => {
    setBackupState('processing');
    setErrorMessage(null);
    try {
      onStartedBackup?.();
      const dateStr = new Date().toISOString().split('.')[0].replace('T', '-');
      const success = await saveFlashObjectOrThrow(
        'full',
        event.ctrlKey, // control forces a traditional browser download - default: fileSave
        includeImages,
        `Big-AGI-flash${includeImages ? '+images' : ''}${event.ctrlKey ? '-download' : ''}-${dateStr}.json`,
      );
      setBackupState(success ? 'success' : 'idle');
    } catch (error: any) {
      if (error?.name === 'AbortError') {
        // the user has closed the file picker, most likely - do nothing
        setBackupState('idle');
      } else {
        logger.error(`Backup failed:`, error);
        setBackupState('error');
        setErrorMessage(`Backup failed: ${_getErrorText(error)}`);
      }
    }
  }, [includeImages, onStartedBackup]);


  return <>

    <Typography level='body-sm' mt={3}>
      Save <strong>all settings and chats</strong>:
    </Typography>
    <Button
      variant='soft'
      aria-label='Download full flash file'
      color={backupState === 'success' ? 'success' : backupState === 'error' ? 'warning' : 'primary'}
      disabled={isProcessing}
      loading={isProcessing}
      endDecorator={backupState === 'success' ? <DoneIcon /> : backupState === 'error' ? <ErrorIcon /> : <DownloadIcon />}
      onClick={handleFullBackup}
      onDoubleClick={console.log}
      sx={{
        boxShadow: 'md',
        backgroundColor: 'background.popup',
        justifyContent: 'space-between',
      }}
    >
      {backupState === 'success' ? 'Backup Saved' : backupState === 'error' ? 'Backup Failed' : isProcessing ? 'Backing Up...' : 'Export All'}
    </Button>
    {!errorMessage && <>
      <FormControl orientation='horizontal' sx={{ justifyContent: 'space-between', alignItems: 'center', ml: 2, mr: 1.25, mt: 0.25 }}>
        <FormLabel sx={{ fontWeight: 'md' }}>Include Binary Images</FormLabel>
        <Switch size='sm' color={includeImages ? 'danger' : undefined} checked={includeImages} onChange={(event) => setIncludeImages(event.target.checked)} />
      </FormControl>
      {includeImages && <Typography level='body-xs' color='danger' ml={2} endDecorator={<WarningRoundedIcon />}>
        Files too large may get corrupted.
      </Typography>}
    </>}

    {errorMessage && (
      <Sheet variant='soft' color='danger' sx={{ px: 1.5, py: 1, borderRadius: 'sm', display: 'grid', gap: 1 }}>
        <Typography color='danger' level='body-sm'>
          {errorMessage}
        </Typography>
        <Button variant='soft' color='danger' size='sm' onClick={() => setErrorMessage(null)}>
          Dismiss
        </Button>
      </Sheet>
    )}

  </>;
}



================================================
FILE: src/modules/trade/ExportChats.tsx
================================================
import * as React from 'react';

import { Box, Button, Grid, Typography } from '@mui/joy';
import DoneIcon from '@mui/icons-material/Done';
import FileDownloadIcon from '@mui/icons-material/FileDownload';

import { getBackendCapabilities } from '~/modules/backend/store-backend-capabilities';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { KeyStroke } from '~/common/components/KeyStroke';
import { getConversation } from '~/common/stores/chat/store-chats';

import { ChatLinkExport } from './link/ChatLinkExport';
import { FlashBackup } from './BackupRestore';
import { PublishExport } from './publish/PublishExport';
import { downloadAllJsonV1B, downloadSingleChat } from './trade.client';


export type ExportConfig = {
  dir: 'export',
  conversationId: DConversationId | null,
  exportAll: boolean,
};


/**
 * Export Buttons and functionality
 */
export function ExportChats(props: { config: ExportConfig, onClose: () => void }) {

  // state
  const [downloadedJSONState, setDownloadedJSONState] = React.useState<'ok' | 'fail' | null>(null);
  const [downloadedMarkdownState, setDownloadedMarkdownState] = React.useState<'ok' | 'fail' | null>(null);
  const [downloadedAllState, setDownloadedAllState] = React.useState<'ok' | 'fail' | null>(null);

  // external state
  const enableSharing = getBackendCapabilities().hasDB;

  // derived state
  const { exportAll } = props.config;


  // download chats

  const handleDownloadConversationJSON = () => {
    if (!props.config.conversationId) return;
    const conversation = getConversation(props.config.conversationId);
    if (!conversation) return;
    downloadSingleChat(conversation, 'json')
      .then(() => setDownloadedJSONState('ok'))
      .catch(() => setDownloadedJSONState('fail'));
  };

  const handleDownloadConversationMarkdown = () => {
    if (!props.config.conversationId) return;
    const conversation = getConversation(props.config.conversationId);
    if (!conversation) return;
    downloadSingleChat(conversation, 'markdown')
      .then(() => setDownloadedMarkdownState('ok'))
      .catch(() => setDownloadedMarkdownState('fail'));
  };

  const handleDownloadAllConversationsJSON = () => {
    downloadAllJsonV1B()
      .then(() => setDownloadedAllState('ok'))
      .catch(() => setDownloadedAllState('fail'));
  };


  const hasConversation = !!props.config.conversationId;

  return <>

    <Grid container spacing={3}>

      {/* Current Chat */}
      <Grid xs={12} md={6} sx={{ display: 'flex', alignItems: 'flex-start', py: 2 }}>
        <Box sx={{ display: 'grid', gap: 1, mx: 'auto' }}>

          {exportAll && (
            <Typography level='body-sm'>
              Download or share <strong>this chat</strong>:
            </Typography>
          )}

          <GoodTooltip title={<KeyStroke variant='solid' combo='Ctrl + S' />}>
            <Button
              variant='soft' disabled={!hasConversation}
              color={downloadedJSONState === 'ok' ? 'success' : downloadedJSONState === 'fail' ? 'warning' : 'primary'}
              endDecorator={downloadedJSONState === 'ok' ? <DoneIcon /> : downloadedJSONState === 'fail' ? '✘' : <FileDownloadIcon />}
              sx={{ minWidth: 240, justifyContent: 'space-between' }}
              onClick={handleDownloadConversationJSON}
            >
              Download · JSON
            </Button>
          </GoodTooltip>

          <Button
            variant='soft' disabled={!hasConversation}
            color={downloadedMarkdownState === 'ok' ? 'success' : downloadedMarkdownState === 'fail' ? 'warning' : 'primary'}
            endDecorator={downloadedMarkdownState === 'ok' ? <DoneIcon /> : downloadedMarkdownState === 'fail' ? '✘' : <FileDownloadIcon />}
            sx={{ minWidth: 240, justifyContent: 'space-between' }}
            onClick={handleDownloadConversationMarkdown}
          >
            Export · Markdown
          </Button>

          {enableSharing && (
            <ChatLinkExport
              conversationId={props.config.conversationId}
              enableSharing={enableSharing}
              onClose={props.onClose}
            />
          )}

          <PublishExport
            conversationId={props.config.conversationId}
            onClose={props.onClose}
          />

          {/*<Button*/}
          {/*  variant='soft'*/}
          {/*  endDecorator={<ExitToAppIcon />}*/}
          {/*  sx={{ minWidth: 240, justifyContent: 'space-between' }}*/}
          {/*>*/}
          {/*  Share Copy · ShareGPT*/}
          {/*</Button>*/}

        </Box>
      </Grid>

      {/* All Chats */}
      {exportAll && (
        <Grid xs={12} md={6} sx={{ display: 'flex', alignItems: 'flex-start', py: 2 }}>
          <Box sx={{ display: 'grid', gap: 1, mx: 'auto' }}>

            <Typography level='body-sm'>
              Backup or transfer <strong>all chats</strong>:
            </Typography>

            <Button
              variant='soft'
              color={downloadedAllState === 'ok' ? 'success' : downloadedAllState === 'fail' ? 'warning' : 'primary'}
              endDecorator={downloadedAllState === 'ok' ? <DoneIcon /> : downloadedAllState === 'fail' ? '✘' : <FileDownloadIcon />}
              sx={{ minWidth: 240, justifyContent: 'space-between' }}
              onClick={handleDownloadAllConversationsJSON}
            >
              Backup All Chats
            </Button>

            {/* Insert to Download a Flash */}
            <FlashBackup />

          </Box>
        </Grid>
      )}

    </Grid>

  </>;
}


================================================
FILE: src/modules/trade/ImportChats.tsx
================================================
import * as React from 'react';

import { Box, Button, FormControl, Input, Sheet, Textarea, Typography } from '@mui/joy';
import FileUploadIcon from '@mui/icons-material/FileUpload';

import { Brand } from '~/common/app.config';
import { FormRadioOption } from '~/common/components/forms/FormRadioControl';
import { GoodTooltip } from '~/common/components/GoodTooltip';
import { InlineError } from '~/common/components/InlineError';
import { KeyStroke } from '~/common/components/KeyStroke';
import { OpenAIIcon } from '~/common/components/icons/vendors/OpenAIIcon';
import { apiAsyncNode } from '~/common/util/trpc.client';
import { createDConversation, DConversationId } from '~/common/stores/chat/chat.conversation';
import { createDMessageTextContent, DMessage } from '~/common/stores/chat/chat.message';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useFormRadio } from '~/common/components/forms/useFormRadio';

import type { ChatGptSharedChatSchema } from './server/chatgpt';
import { importConversationsFromFilesAtRest, openConversationsAtRestPicker } from './trade.client';

import { FlashRestore } from './BackupRestore';
import { ImportedOutcome, ImportOutcomeModal } from './ImportOutcomeModal';


export type ImportConfig = { dir: 'import' };


const chatGptMedia: FormRadioOption<'source' | 'link'>[] = [
  { label: 'Shared Chat URL', value: 'link' },
  { label: 'Page Source', value: 'source' },
];

/**
 * Components and functionality to import conversations
 * Supports our own JSON files, and ChatGPT Share Links
 */
export function ImportChats(props: { onConversationActivate: (conversationId: DConversationId) => void, onClose: () => void }) {

  // state
  const [importMedia, importMediaControl] = useFormRadio('link', chatGptMedia);
  const [chatGptEdit, setChatGptEdit] = React.useState(false);
  const [chatGptUrl, setChatGptUrl] = React.useState('');
  const [chatGptSource, setChatGptSource] = React.useState('');
  const [importJson, setImportJson] = React.useState<string | null>(null);
  const [importOutcome, setImportOutcome] = React.useState<ImportedOutcome | null>(null);

  // derived state
  const isUrl = importMedia === 'link';
  const isSource = importMedia === 'source';
  const chatGptUrlValid = (chatGptUrl.startsWith('https://chat.openai.com/share/') || chatGptUrl.startsWith('https://chatgpt.com/share/')) && chatGptUrl.length > 40;


  const handleImportFromFiles = async () => {
    const outcome = await openConversationsAtRestPicker().then(importConversationsFromFilesAtRest);

    // activate the last (most recent) imported conversation
    if (outcome?.activateConversationId)
      props.onConversationActivate(outcome.activateConversationId);

    // show the outcome of the import
    setImportOutcome(outcome);
  };


  const handleChatGptToggleShown = () => setChatGptEdit(!chatGptEdit);

  const handleChatGptLoad = async () => {
    setImportJson(null);
    if ((isUrl && !chatGptUrlValid) || (isSource && !chatGptSource))
      return;

    const outcome: ImportedOutcome = { conversations: [], activateConversationId: null };

    // load the conversation
    let conversationId: DConversationId, data: ChatGptSharedChatSchema;
    try {
      ({ conversationId, data } = await apiAsyncNode.trade.importChatGptShare.mutate(isUrl ? { url: chatGptUrl } : { htmlPage: chatGptSource }));
    } catch (error) {
      outcome.conversations.push({ fileName: 'chatgpt', success: false, error: (error as any)?.message || error?.toString() || 'unknown error' });
      setImportOutcome(outcome);
      return;
    }

    // save as JSON
    setImportJson(JSON.stringify(data, null, 2));

    // transform to our data structure
    const conversation = createDConversation();
    conversation.id = conversationId;
    conversation.created = Math.round(data.create_time * 1000);
    conversation.updated = Math.round(data.update_time * 1000);
    conversation.autoTitle = data.title;
    conversation.messages = data.linear_conversation.map(msgNode => {
      const message = msgNode.message;
      if (message?.content.parts) {
        const role = message.author.role;
        const joinedText = message.content.parts.join('\n');
        if ((role === 'user' || role === 'assistant') && joinedText.length >= 1) {
          const dMessage = createDMessageTextContent(role, joinedText); // [state] import role:text from ChatGPT
          dMessage.id = message.id;
          if (message.create_time)
            dMessage.created = Math.round(message.create_time * 1000);
          return dMessage;
        }
      }
      return null;
    }).filter(msg => !!msg) as DMessage[];

    // outcome
    const success = conversation.messages.length >= 1;
    if (success) {
      useChatStore.getState().importConversation(conversation, false);
      props.onConversationActivate(conversationId);
      outcome.conversations.push({ success: true, fileName: 'chatgpt', conversation });
    } else
      outcome.conversations.push({ success: false, fileName: 'chatgpt', error: `Empty conversation` });
    setImportOutcome(outcome);
  };

  const handleImportOutcomeClosed = () => {
    setImportOutcome(null);
    props.onClose();
  };


  return <>

    <Box sx={{ display: 'grid', gap: 1, mx: 'auto' }}>

      <Typography level='body-sm'>
        Select where to <strong>import from</strong>:
      </Typography>

      <GoodTooltip title={<KeyStroke variant='solid' combo='Ctrl + O' />}>
        <Button
          variant='soft' endDecorator={<FileUploadIcon />} sx={{ minWidth: 240, justifyContent: 'space-between' }}
          onClick={handleImportFromFiles}
        >
          {Brand.Title.Base} · JSON
        </Button>
      </GoodTooltip>

      {!chatGptEdit && (
        <Button
          variant='soft' endDecorator={<OpenAIIcon />} sx={{ minWidth: 240, justifyContent: 'space-between' }}
          color={chatGptEdit ? 'neutral' : 'primary'}
          onClick={handleChatGptToggleShown}
        >
          ChatGPT · Shared Link
        </Button>
      )}

      {/* Insert to Restore a Flash */}
      <FlashRestore unlockRestore={true} />

    </Box>

    {/* [chatgpt] data & controls */}
    {chatGptEdit && <Sheet variant='soft' color='primary' sx={{ display: 'flex', flexDirection: 'column', borderRadius: 'md', p: 1, gap: 1 }}>

      <Box sx={{ display: 'flex', flexDirection: 'row', alignItems: 'center', gap: 1 }}>
        {importMediaControl}
        <OpenAIIcon sx={{ ml: 'auto', my: 1 }} />
      </Box>

      <FormControl>
        {isUrl && <Input
          variant='outlined' placeholder='https://chatgpt.com/share/...'
          required error={!chatGptUrlValid && chatGptUrl.length > 0}
          value={chatGptUrl} onChange={event => setChatGptUrl(event.target.value)}
        />}
        {isSource && <Textarea
          variant='outlined' placeholder='Paste the page source here'
          required
          minRows={4} maxRows={8}
          value={chatGptSource} onChange={event => setChatGptSource(event.target.value)}
        />}
      </FormControl>

      {isUrl && chatGptUrlValid && <InlineError error='Note: OpenAI may be blocking imports. Try anyways.' severity='warning' sx={{ mt: 0, boxShadow: 'sm' }} />}

      <Box sx={{ display: 'flex', gap: 1 }}>
        <Button variant='soft' color='primary' onClick={handleChatGptToggleShown} sx={{ mr: 'auto' }}>
          Cancel
        </Button>
        <Button color='primary' disabled={(isUrl && !chatGptUrlValid) || (isSource && chatGptSource?.length < 100)} onClick={handleChatGptLoad} sx={{ minWidth: 150 }}>
          Import Chat
        </Button>
      </Box>

    </Sheet>}

    {/* import outcome */}
    {!!importOutcome && <ImportOutcomeModal outcome={importOutcome} rawJson={importJson} onClose={handleImportOutcomeClosed} />}

  </>;
}


================================================
FILE: src/modules/trade/ImportOutcomeModal.tsx
================================================
import * as React from 'react';

import { Alert, Box, Divider, IconButton, List, ListItem, Tooltip, Typography } from '@mui/joy';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';

import type { DConversation, DConversationId } from '~/common/stores/chat/chat.conversation';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { copyToClipboard } from '~/common/util/clipboardUtils';


type ConversationOutcome = {
  success: true;
  fileName: string;
  conversation: DConversation;
  importedConversationId?: DConversationId;
} | {
  success: false;
  fileName: string;
  error: string;
}


export interface ImportedOutcome {
  conversations: ConversationOutcome[];
  activateConversationId: DConversationId | null;
}


/**
 * Displays the result of an import operation as a modal dialog.
 */
export function ImportOutcomeModal(props: { outcome: ImportedOutcome, rawJson: string | null, onClose: () => void }) {
  const { conversations } = props.outcome;

  const successes = conversations.filter(c => c.success);
  const failures = conversations.filter(c => !c.success);
  const hasAnyResults = successes.length > 0 || failures.length > 0;
  const hasAnyFailures = failures.length > 0;

  const handleCopyRawJson = () => {
    if (props.rawJson)
      copyToClipboard(props.rawJson, 'ChatGPT JSON');
  };

  return (
    <GoodModal open title={hasAnyResults ? hasAnyFailures ? 'Import issues' : 'Import successful' : 'Import failed'} strongerTitle onClose={props.onClose}>

      <Divider />

      {successes.length >= 1 && <>
        <Alert variant='soft' color='success'>
          <Typography>
            Imported {successes.length} conversation{successes.length === 1 ? '' : 's'}.
          </Typography>
          {!!props.rawJson && (
            <Tooltip title='Copy JSON to clipboard'>
              <IconButton variant='outlined' onClick={handleCopyRawJson} sx={{ ml: 'auto' }}>
                <ContentCopyIcon />
              </IconButton>
            </Tooltip>
          )}
        </Alert>
        <Typography>
          The conversation{successes.length === 1 ? '' : 's'} can be found in the menu,
          and {successes.length === 1 ? 'it' : 'the last one'} is now active.
        </Typography>
      </>}

      {failures.length >= 1 && <Box>
        <Alert variant='soft' color='danger'>
          <Typography>
            Issues importing {failures.length} conversation{failures.length === 1 ? '' : 's'}:
          </Typography>
        </Alert>
        <List>
          {failures.map((f, idx) =>
            <ListItem variant='soft' color='warning' key={'fail-' + idx} sx={{ display: 'list-item' }}>
              <b>{f.fileName}</b>: {(f as any).error}
            </ListItem>,
          )}
        </List>
      </Box>}

    </GoodModal>
  );
}


================================================
FILE: src/modules/trade/trade.client.ts
================================================
import { fileOpen, fileSave, FileWithHandle } from 'browser-fs-access';

import { SystemPurposeId, SystemPurposes } from '../../data';

import { Brand } from '~/common/app.config';
import { DataAtRestV1 } from '~/common/stores/chat/chats.converters';
import { capitalizeFirstLetter } from '~/common/util/textUtils';
import { conversationTitle, DConversation, excludeSystemMessages } from '~/common/stores/chat/chat.conversation';
import { llmsStoreState } from '~/common/stores/llms/store-llms';
import { messageFragmentsReduceText } from '~/common/stores/chat/chat.message';
import { prettyShortChatModelName } from '~/common/util/dMessageUtils';
import { prettyTimestampForFilenames } from '~/common/util/timeUtils';
import { useChatStore } from '~/common/stores/chat/store-chats';
import { useFolderStore } from '~/common/stores/folders/store-chat-folders';

import type { ImportedOutcome } from './ImportOutcomeModal';


/// IMPORT ///

/**
 * Load conversations from the given Files (we don't need/use the handle here, as no LiveFile is involved in the import)
 * @param files The files to import, if null the user may have cancelled the request
 * @param preventClash If true, the importer will not overwrite existing conversations with the same ID
 */
export async function importConversationsFromFilesAtRest(files: File[] | null, preventClash: boolean = false): Promise<ImportedOutcome> {
  const outcome: ImportedOutcome = { conversations: [], activateConversationId: null };

  // user cancelled
  if (!files)
    return outcome;

  // unroll files to conversations
  for (const file of files) {
    const fileName = file.name || 'unknown file';
    try {
      const fileString = await file.text();
      const fileObject = JSON.parse(fileString);
      loadConversationsFromAtRestV1(fileName, fileObject, outcome);
    } catch (error: any) {
      outcome.conversations.push({
        success: false,
        fileName,
        error: `Issue loading file: ${error?.message || error?.toString() || 'unknown error'}`,
      });
    }
  }

  // import conversations
  for (const cOutcome of [...outcome.conversations].reverse()) {
    if (!cOutcome.success)
      continue;
    cOutcome.importedConversationId = useChatStore.getState().importConversation(cOutcome.conversation, preventClash);
    // the last successfully imported is the one to activate
    if (cOutcome.importedConversationId)
      outcome.activateConversationId = cOutcome.importedConversationId;
  }

  return outcome;
}

/**
 * Show a file picker dialog, then return the selected files
 * - this chains well with `importConversationsFromFilesAtRest`
 */
export async function openConversationsAtRestPicker(): Promise<FileWithHandle[] | null> {
  try {
    return await fileOpen({
      description: `${Brand.Title.Base} JSON Conversations`,
      mimeTypes: ['application/json', 'application/big-agi'],
      multiple: true,
    });
  } catch (error) {
    // User closed the dialog
    return null;
  }
}


/**
 * Restores all conversations in a JSON
 *  - supports both  DataAtRestV1.RestAllJsonV1B, and DataAtRestV1.RestChatJsonV1 files
 */
function loadConversationsFromAtRestV1(fileName: string, obj: any, outcome: ImportedOutcome) {
  // heuristics
  const hasConversations = obj.hasOwnProperty('conversations');
  const hasMessages = obj.hasOwnProperty('messages');

  switch (true) {

    // Heuristic (backup): DataAtRestV1.RestAllJsonV1B
    case hasConversations && !hasMessages:
      const { conversations, folders } = obj as DataAtRestV1.RestAllJsonV1B;
      for (const conversation of conversations)
        loadSingleChatFromAtRestV1(fileName, conversation, outcome);

      // in ExportedAllJsonV1b+, folders weren't there before
      if (folders?.folders) {
        const dFolders = DataAtRestV1.recreateFolders(folders.folders);
        if (dFolders.length)
          useFolderStore.getState().importFoldersAppend(dFolders, folders.enableFolders);
      }
      break;

    // Heuristic (single):
    case hasMessages && !hasConversations:
      const conversation = obj as DataAtRestV1.RestChatJsonV1;
      loadSingleChatFromAtRestV1(fileName, conversation, outcome);
      break;

    default:
      outcome.conversations.push({ success: false, fileName, error: `Invalid file: ${fileName}` });
      break;

  }
}

function loadSingleChatFromAtRestV1(fileName: string, part: DataAtRestV1.RestChatJsonV1, outcome: ImportedOutcome) {
  const restored = DataAtRestV1.recreateConversation(part);
  if (!restored)
    outcome.conversations.push({ success: false, fileName, error: `Invalid conversation: ${part.id}` });
  else
    outcome.conversations.push({ success: true, fileName, conversation: restored });
}


/// EXPORT ///

/**
 * Download all conversations as a JSON file, for backup and future restore
 * @throws {Error} if the user closes the dialog, or file could not be saved
 */
export async function downloadAllJsonV1B() {
  // conversations and
  const { folders, enableFolders } = useFolderStore.getState();
  const payload = DataAtRestV1.formatAllToJsonV1B(
    useChatStore.getState().conversations,
    llmsStoreState().sources,
    folders, enableFolders,
  );
  const json = JSON.stringify(payload);
  const blob = new Blob([json], { type: 'application/json' });

  // save file
  await fileSave(blob, {
    fileName: `backup_chats_${window?.location?.hostname || 'all'}_${payload.conversations.length}_${prettyTimestampForFilenames(false)}.agi.json`,
    // mimeTypes: ['application/json', 'application/big-agi'],
    extensions: ['.json'],
  }).catch(() => null);
}

/**
 * Download a conversation as a JSON file, for backup and future restore
 * @throws {Error} if the user closes the dialog, or file could not be saved
 */
export async function downloadSingleChat(conversation: DConversation, format: 'json' | 'markdown') {

  let blob: Blob;
  let extension: string;

  if (format == 'json') {

    // remove fields (abortController, etc.) from the export
    const exportableConversation = DataAtRestV1.formatChatToJsonV1(conversation);
    const json = JSON.stringify(exportableConversation, null, 2);
    blob = new Blob([json], { type: 'application/json' });
    extension = '.json';

  } else if (format == 'markdown') {

    const exportableMarkdown = conversationToMarkdown(conversation, false, true, (name: string) => `## ${name} ##`);
    blob = new Blob([exportableMarkdown], { type: 'text/markdown' });
    extension = '.md';

  } else {
    throw new Error(`Invalid download format: ${format}`);
  }

  // const fileConvId = conversation.id.slice(0, 8);
  const fileTitle = conversationTitle(conversation).replace(/[^a-z0-9]/gi, '-').toLowerCase() || 'untitled';

  // save file
  await fileSave(blob, {
    fileName: `conversation_${fileTitle}_${prettyTimestampForFilenames(false)}.agi${extension}`,
    extensions: [extension],
  }).catch(() => null);
}

/**
 * Primitive rendering of a Conversation to Markdown
 */
export function conversationToMarkdown(conversation: DConversation, hideSystemMessage: boolean, exportTitle: boolean, senderWrap?: (text: string) => string): string {
  const mdTitle = exportTitle
    ? `# ${capitalizeFirstLetter(conversationTitle(conversation, Brand.Title.Common + ' Chat'))}\nA ${Brand.Title.Common} conversation, updated on ${(new Date(conversation.updated || conversation.created)).toLocaleString()}.\n\n`
    : '';
  return mdTitle + excludeSystemMessages(conversation.messages, !hideSystemMessage).map(message => {
    let senderName: string = message.role === 'user' ? 'You' : 'Bot'; // from role
    let text = messageFragmentsReduceText(message.fragments);
    switch (message.role) {
      case 'system':
        // senderName = '✨ System message';
        senderName = 'System message';
        text = `*${text}*`;
        break;
      case 'assistant':
        const purpose = message.purposeId || conversation.systemPurposeId || null;
        senderName = `${purpose || 'Assistant'} · *${prettyShortChatModelName(message.generator?.name || '')}*`.trim();
        if (purpose && purpose in SystemPurposes)
          senderName = `${SystemPurposes[purpose as SystemPurposeId]?.symbol || ''} ${senderName}`.trim();
        break;
      case 'user':
        senderName = '👤 You';
        break;
    }
    return (senderWrap?.(senderName) || `### ${senderName}`) + `\n\n${text}\n\n`;
  }).join('---\n\n');

}



================================================
FILE: src/modules/trade/TradeModal.tsx
================================================
import * as React from 'react';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { GoodModal } from '~/common/components/modals/GoodModal';

import { ExportChats, ExportConfig } from './ExportChats';
import { ImportChats, ImportConfig } from './ImportChats';

export type TradeConfig = ImportConfig | ExportConfig;

export function TradeModal(props: { config: TradeConfig, onConversationActivate: (conversationId: DConversationId) => void, onClose: () => void }) {
  return (
    <GoodModal
      open onClose={props.onClose}
      dividers
      title={<>
        <b>{props.config.dir === 'import' ? 'Import ' : props.config.dir === 'export' ? 'Export ' : ''}</b> {(props.config.dir === 'export' && !props.config.exportAll) ? 'conversation' : 'conversations'}
      </>}
    >

      {props.config.dir === 'import' && (
        <ImportChats onConversationActivate={props.onConversationActivate} onClose={props.onClose} />
      )}

      {props.config.dir === 'export' && (
        <ExportChats config={props.config} onClose={props.onClose} />
      )}

    </GoodModal>
  );
}


================================================
FILE: src/modules/trade/link/ChatLinkDetails.tsx
================================================
import * as React from 'react';
import TimeAgo from 'react-timeago';

import { Box, Button, Card, IconButton, Input, Stack, Tooltip, Typography } from '@mui/joy';
import ContentCopyIcon from '@mui/icons-material/ContentCopy';
import DeleteForeverIcon from '@mui/icons-material/DeleteForever';
import DoneIcon from '@mui/icons-material/Done';
import EditRoundedIcon from '@mui/icons-material/EditRounded';
import IosShareIcon from '@mui/icons-material/IosShare';
import LaunchIcon from '@mui/icons-material/Launch';
import LinkIcon from '@mui/icons-material/Link';

import { Brand } from '~/common/app.config';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { GoodModal } from '~/common/components/modals/GoodModal';
import { InlineError } from '~/common/components/InlineError';
import { InlineTextarea } from '~/common/components/InlineTextarea';
import { Link } from '~/common/components/Link';
import { apiAsyncNode } from '~/common/util/trpc.client';
import { copyToClipboard } from '~/common/util/clipboardUtils';
import { getChatLinkRelativePath } from '~/common/app.routes';
import { getOriginUrl } from '~/common/util/urlUtils';
import { webShare, webSharePresent } from '~/common/util/pwaUtils';

import type { StorageDeleteSchema, StoragePutSchema } from '../server/link';
import { forgetChatLinkItem } from './store-share-link';


export function ChatLinkDetails(props: {
  open: boolean,
  onClose: () => void,
  storageItem: StoragePutSchema,
  onChangeDeletionKey: (deletionKey: string) => void,
}) {

  // state
  const [opened, setOpened] = React.useState(false);
  const [copied, setCopied] = React.useState(false);
  const [native, setNative] = React.useState(false);
  const [isEditingDeletionKey, setIsEditingDeletionKey] = React.useState(false);
  const [confirmDeletion, setConfirmDeletion] = React.useState(false);
  const [deletionResponse, setDeletionResponse] = React.useState<StorageDeleteSchema | null>(null);

  // in case of 'put' error, just display the message
  if (props.storageItem.type === 'error') {
    return (
      <GoodModal title='❌ Upload Error' dividers open={props.open} onClose={props.onClose}>
        <InlineError error={props.storageItem.error} />
      </GoodModal>
    );
  }

  // success
  const { objectId, deletionKey, expiresAt, dataTitle } = props.storageItem;
  const relativeUrl = getChatLinkRelativePath(objectId);
  const fullUrl = getOriginUrl() + relativeUrl;


  // Deletion Key Edit

  const handleKeyEditBegin = () => setIsEditingDeletionKey(true);

  const handleKeyEditCancel = () => setIsEditingDeletionKey(false);

  const handleKeyEditChange = (text: string) => {
    if (text) {
      setIsEditingDeletionKey(false);
      props.onChangeDeletionKey(text.trim());
    }
  };

  // Deletion Key Copy

  const handleKeyCopy = () => {
    copyToClipboard(deletionKey, 'Link Deletion Key');
  };


  const onOpen = () => setOpened(true);

  const onCopy = () => {
    copyToClipboard(fullUrl, 'Public link');
    setCopied(true);
  };

  const onNativeShare = () => webShare(
    Brand.Title.Base + (dataTitle ? ` - ${dataTitle}` : ' - Shared Chat'),
    'Check this out!',
    fullUrl,
    () => setNative(true),
  );

  const onDeleteNow = () => setConfirmDeletion(true);

  const onDeleteCancelled = () => setConfirmDeletion(false);

  const onConfirmedDeletion = async () => {
    const result: StorageDeleteSchema = await apiAsyncNode.trade.storageDelete.mutate({ objectId, deletionKey });
    setDeletionResponse(result);
    if (result.type === 'success')
      forgetChatLinkItem(objectId);
    setConfirmDeletion(false);
  };

  const tryDeleted = !!deletionResponse;
  const isDeleted = deletionResponse?.type === 'success';


  return (
    <GoodModal title='🔗 Link created' strongerTitle noTitleBar={isDeleted} dividers={!isDeleted} open onClose={props.onClose}>

      {/* Success */}
      {!tryDeleted && <Card variant='solid' color='primary' invertedColors>

        <Typography level='title-md'>
          🚀 Ready to share
        </Typography>
        <Typography level='body-sm'>
          {fullUrl}
        </Typography>

        <Stack direction='row' gap={1}>
          <Tooltip title='Open the link in a new tab'>
            <Button
              variant={opened ? 'soft' : 'solid'} onClick={onOpen}
              color={opened ? 'success' : undefined} endDecorator={opened ? <DoneIcon /> : <LaunchIcon />}
              component={Link} href={relativeUrl} noLinkStyle
              sx={{ flexGrow: 1 }}
            >
              Open
            </Button>
          </Tooltip>

          <Tooltip title='Copy the link to your clipboard'>
            <Button
              variant={copied ? 'soft' : 'solid'} onClick={onCopy}
              color={copied ? 'success' : undefined} endDecorator={copied ? <DoneIcon /> : <LinkIcon />}
              sx={{ flexGrow: 1 }}
            >
              Copy
            </Button>
          </Tooltip>

          {webSharePresent() &&
            <Tooltip title='Share the link using your device'>
              <Button
                variant={native ? 'soft' : 'solid'} onClick={onNativeShare}
                color={native ? 'success' : undefined} endDecorator={native ? <DoneIcon /> : <IosShareIcon />}
                sx={{ flexGrow: 1 }}
              >
                Share
              </Button>
            </Tooltip>}
        </Stack>

      </Card>}

      {/* Deleted */}
      {isDeleted && <Card variant='solid' color='danger' invertedColors>
        <Typography level='title-md'>
          🗑️ Link deleted
        </Typography>
        <Typography level='body-sm'>
          This link has been deleted
        </Typography>
      </Card>}

      {/* Deletion and Expiration */}
      {!isDeleted && <Card variant='soft'>

        <Typography level='title-sm'>
          Deletion Key
        </Typography>

        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
          {isEditingDeletionKey ? (
            <InlineTextarea
              invertedColors
              initialText={deletionKey}
              onEdit={handleKeyEditChange}
              onCancel={handleKeyEditCancel}
              sx={{
                flexGrow: 1,
                ml: -1.5, mr: -0.5,
              }}
            />
          ) : (
            <Input
              readOnly
              variant='plain'
              value={deletionKey}
              endDecorator={
                <Box sx={{ display: 'flex', gap: 2 }}>
                  <Tooltip title='Edit Deletion Key'>
                    <IconButton
                      variant='soft'
                      color='primary'
                      disabled={isEditingDeletionKey}
                      onClick={handleKeyEditBegin}
                    >
                      <EditRoundedIcon />
                    </IconButton>
                  </Tooltip>
                  <IconButton
                    variant='soft'
                    color='primary'
                    disabled={isEditingDeletionKey}
                    onClick={handleKeyCopy}
                  >
                    <ContentCopyIcon />
                  </IconButton>
                </Box>
              }
              sx={{ flexGrow: 1 }}
            />
          )}
        </Box>


        <Typography level='body-sm'>
          IMPORTANT - <b>keep this key safe</b>, you will need it if you decide to delete the link at a later time,
          and it will not appear again once you close this dialog.
        </Typography>

        <Stack direction='row' gap={1} sx={{ alignItems: 'center', justifyContent: 'space-between' }}>
          {!!expiresAt && (
            <Typography level='title-sm'>
              This chat will auto-expire <TimeAgo date={expiresAt} />.
            </Typography>
          )}
          <Button variant='outlined' color='neutral' endDecorator={<DeleteForeverIcon />} onClick={onDeleteNow}>
            Delete Now
          </Button>
        </Stack>

      </Card>}

      {/* Delete confirmation */}
      <ConfirmationModal
        open={confirmDeletion} onClose={onDeleteCancelled} onPositive={onConfirmedDeletion}
        confirmationText={'Are you sure you want to delete this link?'} positiveActionText={'Yes, Delete'}
      />

    </GoodModal>
  );
}


================================================
FILE: src/modules/trade/link/ChatLinkExport.tsx
================================================
import * as React from 'react';

import { Button } from '@mui/joy';
import DoneIcon from '@mui/icons-material/Done';
import ShareOutlinedIcon from '@mui/icons-material/ShareOutlined';

import { Brand } from '~/common/app.config';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { DataAtRestV1 } from '~/common/stores/chat/chats.converters';
import { Link } from '~/common/components/Link';
import { addSnackbar } from '~/common/components/snackbar/useSnackbarsStore';
import { apiAsyncNode } from '~/common/util/trpc.client';
import { conversationTitle, DConversationId } from '~/common/stores/chat/chat.conversation';
import { getConversation } from '~/common/stores/chat/store-chats';

import type { StoragePutSchema, StorageUpdateDeletionKeySchema } from '../server/link';
import { ChatLinkDetails } from './ChatLinkDetails';
import { rememberChatLinkItem, updateChatLinkDeletionKey, useLinkStorageOwnerId } from './store-share-link';


export function ChatLinkExport(props: {
  conversationId: DConversationId | null;
  enableSharing: boolean;
  onClose: () => void;
}) {

  // state
  const [confirmConversationId, setConfirmConversationId] = React.useState<DConversationId | null>(null);
  const [isUploading, setIsUploading] = React.useState(false);
  const [linkPutResult, setLinkPutResult] = React.useState<StoragePutSchema | null>(null);

  // external state
  const { linkStorageOwnerId, setLinkStorageOwnerId } = useLinkStorageOwnerId();


  const handleConfirm = () => setConfirmConversationId(props.conversationId);

  const handleCancel = () => setConfirmConversationId(null);

  const handleCreate = async () => {
    if (!confirmConversationId) return;

    const conversation = getConversation(confirmConversationId);
    setConfirmConversationId(null);
    if (!conversation) return;

    setIsUploading(true);
    try {
      const chatV1 = DataAtRestV1.formatChatToJsonV1(conversation);
      const chatTitle = conversationTitle(conversation) || undefined;
      const response: StoragePutSchema = await apiAsyncNode.trade.storagePut.mutate({
        ownerId: linkStorageOwnerId,
        dataType: 'CHAT_V1',
        dataTitle: chatTitle,
        dataObject: chatV1,
      });
      setLinkPutResult(response);
      if (response.type === 'success') {
        if (!linkStorageOwnerId)
          setLinkStorageOwnerId(response.ownerId);
        rememberChatLinkItem(chatTitle, response.objectId, response.createdAt, response.expiresAt, response.deletionKey);
      }
    } catch (error: any) {
      setLinkPutResult({
        type: 'error',
        error: error?.message ?? error?.toString() ?? 'unknown error',
      });
    }
    setIsUploading(false);
  };

  const handleChangeDeletionKey = async (newKey: string) => {
    if (!linkPutResult || linkPutResult.type !== 'success') return;
    const { objectId, deletionKey: formerKey } = linkPutResult;
    if (!objectId || !formerKey || !newKey || formerKey === newKey) return;

    // update it in the Storage
    try {
      const response: StorageUpdateDeletionKeySchema = await apiAsyncNode.trade.storageUpdateDeletionKey.mutate({
        objectId,
        formerKey,
        newKey,
      });
      if (response.type === 'error') {
        addSnackbar({
          key: 'chatlink-deletion-key-update-error',
          type: 'issue',
          message: `Failed to update deletion key: ${response.error}`,
        });
        return;
      }
    } catch (error: any) {
      addSnackbar({
        key: 'chatlink-deletion-key-update-exception',
        type: 'issue',
        message: `Failed to update deletion key: ${error?.message ?? error?.toString() ?? 'unknown error'}`,
      });
      return;
    }

    // update it in the local storage
    updateChatLinkDeletionKey(objectId, newKey);

    // update it in the status
    setLinkPutResult({
      ...linkPutResult,
      deletionKey: newKey,
    });
  };

  const handleCloseDetails = () => setLinkPutResult(null);


  const hasConversation = !!props.conversationId;


  return <>

    <Button
      variant='soft' disabled={!hasConversation || isUploading}
      loading={isUploading}
      color={linkPutResult ? 'success' : 'primary'}
      endDecorator={linkPutResult ? <DoneIcon /> : <ShareOutlinedIcon />}
      sx={{ minWidth: 240, justifyContent: 'space-between' }}
      onClick={handleConfirm}
    >
      Share Link · {Brand.Title.Base}
    </Button>

    {/* [chat link] confirmation */}
    {!!confirmConversationId && (
      <ConfirmationModal
        open onClose={handleCancel} onPositive={handleCreate}
        title='Upload Confirmation'
        confirmationText={<>
          Everyone who has the unlisted link will be able to access this chat.
          It will be automatically deleted after 30 days.
          For more information, please see the <Link href={Brand.URIs.PrivacyPolicy} target='_blank'>privacy
          policy</Link> of this server. <br />
          Do you wish to continue?
        </>}
        positiveActionText={'Yes, Create Link'}
      />
    )}

    {/* [chat link] response */}
    {!!linkPutResult && (
      <ChatLinkDetails
        open
        storageItem={linkPutResult}
        onClose={handleCloseDetails}
        onChangeDeletionKey={handleChangeDeletionKey}
      />
    )}

  </>;
}


================================================
FILE: src/modules/trade/link/store-share-link.ts
================================================
import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import { useShallow } from 'zustand/react/shallow';


export interface SharedChatLinkItem {
  chatTitle?: string;
  objectId: string;
  createdAt: string;
  expiresAt: string | null;
  deletionKey: string;
}

interface LinkStore {

  // exported items
  chatLinkItems: SharedChatLinkItem[];
  chatLinkItemAdd: (chatTitle: string | undefined, objectId: string, createdAt: Date, expiresAt: Date | null, deletionKey: string) => void;
  chatLinkItemRemove: (objectId: string) => void;
  chatLinkItemChangeDeletionKey: (objectId: string, deletionKey: string) => void;

  // ID assigned by the server upon first PUT
  linkStorageOwnerId: string | undefined;
  setLinkStorageOwnerId: (linkStorageOwnerId: string) => void;

}

const useShareLinkStore = create<LinkStore>()(
  persist(
    (set) => ({

      chatLinkItems: [],
      chatLinkItemAdd: (chatTitle: string | undefined, objectId: string, createdAt: Date, expiresAt: Date | null, deletionKey: string) => set(state => ({
        chatLinkItems: [...state.chatLinkItems, { chatTitle, objectId, createdAt: createdAt.toISOString(), expiresAt: expiresAt?.toISOString() ?? null, deletionKey }],
      })),
      chatLinkItemRemove: (objectId: string) => set(state => ({
        chatLinkItems: state.chatLinkItems.filter(item => item.objectId !== objectId),
      })),
      chatLinkItemChangeDeletionKey: (objectId: string, deletionKey: string) => set(state => ({
        chatLinkItems: state.chatLinkItems.map(item => item.objectId === objectId ? { ...item, deletionKey } : item),
      })),

      linkStorageOwnerId: undefined,
      setLinkStorageOwnerId: (linkStorageOwnerId: string) => set({ linkStorageOwnerId }),

    }),
    {
      name: 'app-sharing',
    },
  ),
);


// by AppChatLink
export const useSharedChatLinkItems = () => useShareLinkStore(useShallow(state => state.chatLinkItems));

// by ChatLinkExport/ChatLinkDetails
export const rememberChatLinkItem = useShareLinkStore.getState().chatLinkItemAdd;
export const updateChatLinkDeletionKey = useShareLinkStore.getState().chatLinkItemChangeDeletionKey;
export const forgetChatLinkItem = useShareLinkStore.getState().chatLinkItemRemove;
export const useLinkStorageOwnerId = () => useShareLinkStore(useShallow(state => ({
  linkStorageOwnerId: state.linkStorageOwnerId,
  setLinkStorageOwnerId: state.setLinkStorageOwnerId,
})));

// by Nav
export function hasNoChatLinkItems() {
  return !useShareLinkStore.getState().chatLinkItems.length;
}



================================================
FILE: src/modules/trade/publish/PublishDetails.tsx
================================================
import * as React from 'react';

import { Alert, Box, Button, Divider, Input, Modal, ModalDialog, Stack, Typography } from '@mui/joy';

import { Link } from '~/common/components/Link';

import type { PublishedSchema } from '../server/pastegg';


/**
 * Displays the result of a Paste.gg paste as a modal dialog.
 * This is to give the user the chance to write down the deletion key, mainly.
 */
export function PublishDetails(props: { onClose: () => void, response: PublishedSchema, open: boolean }) {
  if (!props.response?.url)
    return null;

  const { url, deletionKey, expires } = props.response;

  return (
    <Modal open={props.open} onClose={props.onClose}>
      <ModalDialog variant='outlined' color='neutral' sx={{ maxWidth: '100vw' }}>

        <Typography level='title-lg'>
          Your conversation is live!
        </Typography>

        <Divider sx={{ my: 2 }} />

        <Typography>
          This is your link (opens in a new window)
        </Typography>
        <Typography sx={{ mt: 1 }}>
          <Link noLinkStyle href={url} target='_blank' sx={{ wordBreak: 'break-all' }}>
            {url}
          </Link>
        </Typography>

        <Alert variant='soft' color='neutral' sx={{ mt: 3, mb: 1 }}>
          <Stack>
            <Typography level='body-sm'>
              <b>Deletion key</b>
            </Typography>
            <Input readOnly variant='plain' value={deletionKey} sx={{ mt: 1, mb: 2 }} />
            <Typography level='body-sm' sx={{ mb: 1 }}>
              IMPORTANT - Keep this key safe! You will need it if you decide to delete the paste, and it will not appear again once you close this dialog.
            </Typography>
          </Stack>
        </Alert>

        {expires?.length >= 10 && (
          <Typography sx={{ mt: 1 }}>
            The conversation will be deleted on {new Date(expires).toLocaleString()}.
          </Typography>
        )}

        <Box sx={{ display: 'flex', gap: 1, justifyContent: 'flex-end', mt: 2 }}>
          <Button variant='soft' color='neutral' onClick={props.onClose}>
            Close
          </Button>
        </Box>
      </ModalDialog>
    </Modal>
  );
}


================================================
FILE: src/modules/trade/publish/PublishExport.tsx
================================================
import * as React from 'react';

import { Button } from '@mui/joy';
import ShareOutlinedIcon from '@mui/icons-material/ShareOutlined';

import { getChatShowSystemMessages } from '../../../apps/chat/store-app-chat';

import type { DConversationId } from '~/common/stores/chat/chat.conversation';
import { Brand } from '~/common/app.config';
import { ConfirmationModal } from '~/common/components/modals/ConfirmationModal';
import { Link } from '~/common/components/Link';
import { apiAsyncNode } from '~/common/util/trpc.client';
import { getConversation } from '~/common/stores/chat/store-chats';
import { isBrowser } from '~/common/util/pwaUtils';

import type { PublishedSchema } from '../server/pastegg';
import { PublishDetails } from './PublishDetails';
import { conversationToMarkdown } from '../trade.client';


/// Returns a pretty link to the current page, for promo
function linkToOrigin() {
  let origin = isBrowser ? window.location.href : '';
  if (!origin || origin.includes('//localhost'))
    origin = Brand.URIs.OpenRepo;
  origin = origin.replace('https://', '');
  if (origin.endsWith('/'))
    origin = origin.slice(0, -1);
  return origin;
}


export function PublishExport(props: {
  conversationId: DConversationId | null;
  onClose: () => void;
}) {

  // local state
  const [publishConversationId, setPublishConversationId] = React.useState<DConversationId | null>(null);
  const [publishUploading, setPublishUploading] = React.useState(false);
  const [publishResponse, setPublishResponse] = React.useState<PublishedSchema | null>(null);


  const handlePublishConversation = () => setPublishConversationId(props.conversationId);

  const handlePublishConfirmed = async () => {
    if (!publishConversationId) return;

    const conversation = getConversation(publishConversationId);
    setPublishConversationId(null);
    if (!conversation) return;

    setPublishUploading(true);
    const showSystemMessages = getChatShowSystemMessages();
    const markdownContent = conversationToMarkdown(conversation, !showSystemMessages, false);
    try {
      const paste = await apiAsyncNode.trade.publishTo.mutate({
        to: 'paste.gg',
        title: '🤖💬 Chat Conversation',
        fileContent: markdownContent,
        fileName: 'my-chat.md',
        origin: linkToOrigin(),
      });
      setPublishResponse(paste);
    } catch (error: any) {
      alert(`Failed to publish conversation: ${error?.message ?? error?.toString() ?? 'unknown error'}`);
      setPublishResponse(null);
    }
    setPublishUploading(false);
  };

  const handlePublishResponseClosed = () => {
    setPublishResponse(null);
    props.onClose();
  };


  const hasConversation = !!props.conversationId;


  return <>

    <Button
      variant='soft' disabled={!hasConversation || publishUploading}
      loading={publishUploading}
      color={publishResponse ? 'success' : 'primary'}
      endDecorator={<ShareOutlinedIcon />}
      sx={{ minWidth: 240, justifyContent: 'space-between' }}
      onClick={handlePublishConversation}
    >
      Share Copy · Paste.gg
    </Button>

    {/* [publish] confirmation */}
    {publishConversationId && (
      <ConfirmationModal
        open onClose={() => setPublishConversationId(null)} onPositive={handlePublishConfirmed}
        confirmationText={<>
          Share your conversation anonymously on <Link href='https://paste.gg' target='_blank'>paste.gg</Link>?
          It will be unlisted and available to share and read for 30 days. Keep in mind, deletion may not be possible.
          Do you wish to continue?
        </>} positiveActionText={'Understood, Upload to Paste.gg'}
      />
    )}

    {/* [publish] response */}
    {!!publishResponse && (
      <PublishDetails open onClose={handlePublishResponseClosed} response={publishResponse} />
    )}

  </>;
}


================================================
FILE: src/modules/trade/server/chatgpt.ts
================================================
import { TRPCError } from '@trpc/server';
import * as z from 'zod/v4';


const chatGptMessageSchema = z.object({
  id: z.string(),
  author: z.object({
    role: z.enum(['user', 'assistant', 'system', 'tool']),
    metadata: z.record(z.string(), z.unknown()),
  }),
  create_time: z.optional(z.number()),
  content: z.object({
    content_type: z.enum(['text', 'code', 'execution_output', 'model_editable_context']),
    parts: z.optional(z.array(z.string())), // [''] if author.role === 'system', optional if content_type === 'code'
  }),
  status: z.string(),
  end_turn: z.optional(z.boolean()),
  weight: z.number(),
  metadata: z.record(z.string(), z.unknown()),
  recipient: z.string(), // wazs: z.enum(['all', 'python']), but can be a plugin full name too
});

const chatGptNodeSchema = z.object({
  id: z.string(),
  message: chatGptMessageSchema.optional(),
  parent: z.optional(z.string()),
  children: z.array(z.string()),
});

export const chatGptSharedChatSchema = z.object({
  title: z.string(),
  create_time: z.number(),
  update_time: z.number(),
  // mapping: z.record(z.string(), chatGptNodeSchema), // comment out, to reduce the data transfer - 'duplicate' of linear_conversation
  moderation_results: z.array(z.unknown()),
  current_node: z.string(),
  is_public: z.boolean(),
  linear_conversation: z.array(chatGptNodeSchema),
  has_user_editable_context: z.boolean(),
  continue_conversation_url: z.string(),
  model: z.object({
    slug: z.string(),
    max_tokens: z.number(),
    title: z.string(),
    description: z.string(),
    tags: z.array(z.string()),
  }),
  moderation_state: z.record(z.string(), z.unknown()),
});

export type ChatGptSharedChatSchema = z.infer<typeof chatGptSharedChatSchema>;

const chatGptSharedChatPage = z.object({
  props: z.object({
    // [... omit ...]
    pageProps: z.object({
      // [... omit ...]
      continueMode: z.boolean(),
      moderationMode: z.boolean(),
      serverResponse: z.object({
        data: chatGptSharedChatSchema,
      }),
      sharedConversationId: z.string(),
    }),
  }),
});


export function chatGptParseConversation(htmlPage: string) {
  // extract embedded JSON string
  const jsonString = htmlPage.match(/<script id="__NEXT_DATA__" type="application\/json"[^>]*>(.*?)<\/script>/s)?.[1];
  if (!jsonString)
    throw new TRPCError({
      code: 'BAD_REQUEST',
      message: 'Failed to extract JSON object from HTML page',
    });

  // parse the string to JSON
  let jsonObject: object;
  try {
    jsonObject = JSON.parse(jsonString);
  } catch (error: any) {
    throw new TRPCError({
      code: 'BAD_REQUEST',
      message: `Failed to parse JSON object: ${error?.message}`,
    });
  }

  // validate the JSON object
  const safeJson = chatGptSharedChatPage.safeParse(jsonObject);
  if (!safeJson.success)
    throw new TRPCError({
      code: 'BAD_REQUEST',
      message: `Failed to validate JSON object: ${safeJson.error.message}`,
    });

  // just return the conversation data
  return safeJson.data;
}



================================================
FILE: src/modules/trade/server/link.ts
================================================
import * as z from 'zod/v4';

import { LinkStorageDataType, LinkStorageVisibility } from '@prisma/client';

import { prismaDb } from '~/server/prisma/prismaDb';
import { publicProcedure } from '~/server/trpc/trpc.server';

import { agiUuid } from '~/common/util/idUtils';


// configuration
const DEFAULT_EXPIRES_SECONDS = 60 * 60 * 24 * 30; // 30 days


/// Zod schemas

const dataTypesSchema = z.enum([LinkStorageDataType.CHAT_V1]);


const storagePutInputSchema = z.object({
  ownerId: z.string().optional(),
  dataType: dataTypesSchema,
  dataTitle: z.string().optional(),
  dataObject: z.any(), // was .passthrough()
  expiresSeconds: z.number().optional(),
});

export const storagePutOutputSchema = z.union([
  z.object({
    type: z.literal('success'),
    objectId: z.string(),
    ownerId: z.string(),
    createdAt: z.date(),
    expiresAt: z.date().nullable(),
    deletionKey: z.string(),
    dataTitle: z.string().nullable(),
  }),
  z.object({
    type: z.literal('error'),
    error: z.string(),
  }),
]);

const storageGetInputSchema = z.object({
  objectId: z.string(),
  ownerId: z.string().optional(),
});

export const storageGetOutputSchema = z.union([
  z.object({
    type: z.literal('success'),
    dataType: dataTypesSchema,
    dataTitle: z.string().nullable(),
    dataObject: z.any(), // was .passthrough()
    storedAt: z.date(),
    expiresAt: z.date().nullable(),
  }),
  z.object({
    type: z.literal('error'),
    error: z.string(),
  }),
]);

const storageDeleteInputSchema = z.object({
  objectId: z.string(),
  ownerId: z.string().optional(),
  deletionKey: z.string(),
});

export const storageDeleteOutputSchema = z.object({
  type: z.enum(['success', 'error']),
  error: z.string().optional(),
});

const storageUpdateDeletionKeyInputSchema = z.object({
  objectId: z.string(),
  ownerId: z.string().optional(),
  formerKey: z.string(),
  newKey: z.string(),
});

export const storageUpdateDeletionKeyOutputSchema = z.object({
  type: z.enum(['success', 'error']),
  error: z.string().optional(),
});


export type StoragePutSchema = z.infer<typeof storagePutOutputSchema>;
export type StorageDeleteSchema = z.infer<typeof storageDeleteOutputSchema>;
export type StorageUpdateDeletionKeySchema = z.infer<typeof storageUpdateDeletionKeyOutputSchema>;


/// tRPC procedures

/**
 * Writes dataObject to DB, returns ownerId, objectId, and deletionKey
 */
export const storagePutProcedure =
  publicProcedure
    .input(storagePutInputSchema)
    .output(storagePutOutputSchema)
    .mutation(async ({ input }) => {

      const { ownerId, dataType, dataTitle, dataObject, expiresSeconds } = input;

      const { id: objectId, ...rest } = await prismaDb.linkStorage.create({
        select: {
          id: true,
          ownerId: true,
          createdAt: true,
          expiresAt: true,
          deletionKey: true,
        },
        data: {
          id: agiUuid('server-storage-id'),
          ownerId: ownerId || agiUuid('server-storage-owner'),
          visibility: LinkStorageVisibility.UNLISTED,
          dataType,
          dataTitle,
          dataSize: JSON.stringify(dataObject).length, // data size estimate
          data: dataObject,
          expiresAt: expiresSeconds === 0
            ? undefined // never expires
            : new Date(Date.now() + 1000 * (expiresSeconds || DEFAULT_EXPIRES_SECONDS)), // default
          deletionKey: agiUuid('server-storage-deletion-key'),
          isDeleted: false,
        },
      });

      return {
        type: 'success',
        objectId,
        dataTitle: dataTitle || null,
        ...rest,
      };

    });


/**
 * Reads an object from DB, if it exists, and is not expired, and is not marked as deleted
 */
export const storageGetProcedure =
  publicProcedure
    .input(storageGetInputSchema)
    .output(storageGetOutputSchema)
    .query(async ({ input: { objectId, ownerId } }) => {

      // read object
      const result = await prismaDb.linkStorage.findUnique({
        select: {
          dataType: true,
          dataTitle: true,
          data: true,
          createdAt: true,
          expiresAt: true,
        },
        where: {
          id: objectId,
          ownerId: ownerId || undefined,
          isDeleted: false,
          OR: [
            { expiresAt: null },
            { expiresAt: { gt: new Date() } },
          ],
        },
      });

      // if not found, return error
      if (!result)
        return {
          type: 'error',
          error: 'Not found',
        };

      if (typeof result.data !== 'object' || result.data === null)
        return {
          type: 'error',
          error: 'Invalid data',
        };

      // increment the read count
      // NOTE: fire-and-forget; we don't care about the result
      {
        prismaDb.linkStorage.update({
          select: {
            id: true,
          },
          where: {
            id: objectId,
          },
          data: {
            readCount: {
              increment: 1,
            },
          },
        }).catch(() => null);
      }

      return {
        type: 'success',
        dataType: result.dataType,
        dataTitle: result.dataTitle,
        dataObject: result.data as any,
        storedAt: result.createdAt,
        expiresAt: result.expiresAt,
      };

    });


/**
 * Mark a public object as deleted, if it exists, and is not expired, and is not deleted
 */
export const storageMarkAsDeletedProcedure =
  publicProcedure
    .input(storageDeleteInputSchema)
    .output(storageDeleteOutputSchema)
    .mutation(async ({ input: { objectId, ownerId, deletionKey } }) => {

      const result = await prismaDb.linkStorage.updateMany({
        where: {
          id: objectId,
          ownerId: ownerId || undefined,
          deletionKey,
          // isDeleted: false,
        },
        data: {
          isDeleted: true,
          deletedAt: new Date(),
        },
      });

      const success = result.count === 1;

      return {
        type: success ? 'success' : 'error',
        error: success ? undefined : 'invalid deletion key?',
      };
    });


/**
 * Update the deletion Key of a public object by ID and deletion key
 */
export const storageUpdateDeletionKeyProcedure =
  publicProcedure
    .input(storageUpdateDeletionKeyInputSchema)
    .output(storageUpdateDeletionKeyOutputSchema)
    .mutation(async ({ input: { objectId, ownerId, formerKey, newKey } }) => {

      const result = await prismaDb.linkStorage.updateMany({
        where: {
          id: objectId,
          ownerId: ownerId || undefined,
          deletionKey: formerKey,
          // isDeleted: false,
        },
        data: {
          deletionKey: newKey,
        },
      });

      const success = result.count === 1;

      return {
        type: success ? 'success' : 'error',
        error: success ? undefined : 'invalid former key',
      };
    });


================================================
FILE: src/modules/trade/server/pastegg.ts
================================================
import * as z from 'zod/v4';

import { fetchJsonOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';


export const publishToInputSchema = z.object({
  to: z.enum(['paste.gg']),
  title: z.string(),
  fileContent: z.string(),
  fileName: z.string(),
  origin: z.string(),
});

export const publishToOutputSchema = z.object({
  url: z.string(),
  expires: z.string(),
  deletionKey: z.string(),
  created: z.string(),
});

export type PublishedSchema = z.infer<typeof publishToOutputSchema>;

/**
 * Post a paste to paste.gg
 * [called by the API]
 *  - API description: https://github.com/ascclemens/paste/blob/master/api.md
 *
 * @param title Title of the paste
 * @param fileName File with extension, e.g. 'conversation.md'
 * @param fileContent Textual content (e.g. markdown text)
 * @param origin the URL of the page that generated the paste
 * @param expireDays Number of days after which the paste will expire (0 = never expires, default = 30)
 */
export async function postToPasteGGOrThrow(title: string, fileName: string, fileContent: string, origin: string, expireDays: number = 30): Promise<PasteGGWire.PasteResponse> {

  // Default: expire in 30 days
  let expires = null;
  if (expireDays && expireDays >= 1) {
    const expirationDate = new Date();
    expirationDate.setDate(expirationDate.getDate() + expireDays);
    expires = expirationDate.toISOString();
  }

  const pasteData: PasteGGWire.PasteRequest = {
    name: title,
    description: `Generated by ${origin} 🚀`,
    visibility: 'unlisted',
    ...(expires && { expires }),
    files: [{
      name: fileName,
      content: {
        format: 'text',
        value: fileContent,
      },
    }],
  };

  return await fetchJsonOrTRPCThrow<PasteGGWire.PasteResponse, PasteGGWire.PasteRequest>({
    url: 'https://api.paste.gg/v1/pastes',
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: pasteData,
    name: 'PasteGG',
  });
}


namespace PasteGGWire {

  export interface PasteRequest {
    name?: string;
    description?: string;
    visibility?: 'public' | 'unlisted' | 'private';
    expires?: string;
    files: PasteFile[];
  }

  interface PasteFile {
    name?: string;
    content: {
      format: 'text' | 'base64' | 'gzip' | 'xz';
      highlight_language?: string | null;
      value: string;
    };
  }

  export type PasteResponse = {
    status: 'success'
    result: PasteRequest & {
      id: string;
      created_at: string;
      updated_at: string;
      files: {
        id: string;
        name: string;
        highlight_language?: string | null;
      }[];
      deletion_key?: string;
    };
  } | {
    status: 'error';
    error: string;
    message?: string;
  }

}


================================================
FILE: src/modules/trade/server/trade.router.ts
================================================
import { TRPCError } from '@trpc/server';
import * as z from 'zod/v4';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { fetchTextOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { chatGptParseConversation, chatGptSharedChatSchema } from './chatgpt';
import { postToPasteGGOrThrow, publishToInputSchema, publishToOutputSchema } from './pastegg';
import { storageGetProcedure, storageMarkAsDeletedProcedure, storagePutProcedure, storageUpdateDeletionKeyProcedure } from './link';


export const importChatGptShareInputSchema = z.union([
  z.object({
    url: z.url().startsWith('https://chatgpt.com/share/'),
  }),
  z.object({
    htmlPage: z.string(),
  }),
]);


export const tradeRouter = createTRPCRouter({

  /** ChatGPT Shared Chats Importer */
  importChatGptShare: publicProcedure
    .input(importChatGptShareInputSchema)
    .output(z.object({ data: chatGptSharedChatSchema, conversationId: z.string() }))
    .mutation(async ({ input }) => {

      // download the page if URL is given, else use the source
      let htmlPage: string;

      if ('htmlPage' in input) {
        htmlPage = input.htmlPage;
      } else {
        // add headers that make it closest to a browser request
        htmlPage = await fetchTextOrTRPCThrow({
          url: input.url,
          headers: {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept-Language': 'en-US,en;q=0.9',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
          },
          name: 'ChatGPT Importer',
        });
      }

      const data = chatGptParseConversation(htmlPage);

      return {
        data: data.props.pageProps.serverResponse.data,
        conversationId: data.props.pageProps.sharedConversationId,
      };
    }),

  /**
   * Write an object to storage, and return the ID, owner, and deletion key
   */
  storagePut: storagePutProcedure,

  /**
   * Read a stored object by ID (optional owner)
   */
  storageGet: storageGetProcedure,

  /**
   * Delete a stored object by ID and deletion key
   */
  storageDelete: storageMarkAsDeletedProcedure,

  /**
   * Update the deletion Key of a stored object by ID and deletion key
   */
  storageUpdateDeletionKey: storageUpdateDeletionKeyProcedure,

  /**
   * Publish a text file (with title, content, name) to a sharing service
   * For now only 'paste.gg' is supported
   */
  publishTo: publicProcedure
    .input(publishToInputSchema)
    .output(publishToOutputSchema)
    .mutation(async ({ input: { to, title, fileContent, fileName, origin } }) => {
      if (to !== 'paste.gg' || !title || !fileContent || !fileName)
        throw new Error('Invalid options');

      const paste = await postToPasteGGOrThrow(title, fileName, fileContent, origin);
      if (paste?.status !== 'success')
        throw new TRPCError({
          code: 'BAD_REQUEST',
          message: `${paste?.error || 'Unknown error'}. ${paste?.message || 'Unknown cause'}`.trim(),
        });

      const result = paste.result;
      return {
        url: `https://paste.gg/${result.id}`,
        expires: result.expires || 'never',
        deletionKey: result.deletion_key || 'none',
        created: result.created_at,
      };
    }),

});


================================================
FILE: src/modules/youtube/useYouTubeTranscript.tsx
================================================
// Copyright (c) 2023-2024 Enrico Ros
// This subsystem is responsible for fetching the transcript of a YouTube video.
// It is used by the Big-AGI Persona Creator to create a character sheet.

import * as React from 'react';
import { useQuery } from '@tanstack/react-query';

// import { fetchYouTubeTranscript } from './youtube.fetcher';
import { apiAsync } from '~/common/util/trpc.client';

import type { YouTubeVideoData } from './youtube.types';


// configuration
const USE_FRONTEND_FETCH = false;


export interface YTVideoTranscript {
  title: string;
  transcript: string;
  thumbnailUrl: string;
}

export async function youTubeGetVideoData(videoId: string): Promise<YouTubeVideoData> {
  if (USE_FRONTEND_FETCH) {
    // return fetchYouTubeTranscript(videoId, url => frontendSideFetch(url).then(res => res.text()));
    throw new Error('Big-AGI: Browser youtube transcript download is disabled.');
  }
  return apiAsync.youtube.getTranscript.query({ videoId });
}


export function useYouTubeTranscript(videoID: string | null, onNewTranscript: (transcript: YTVideoTranscript) => void) {

  // state
  const [transcript, setTranscript] = React.useState<YTVideoTranscript | null>(null);

  // data
  const { data, isFetching, isError, error } = useQuery({
    enabled: !!videoID,
    queryKey: ['transcript', videoID],
    queryFn: async () => youTubeGetVideoData(videoID!),
    staleTime: Infinity,
  });

  // update the transcript when the underlying data changes
  React.useEffect(() => {
    if (!data) {
      // setTranscript(null);
      return;
    }
    const transcript = {
      title: data.videoTitle,
      transcript: data.transcript,
      thumbnailUrl: data.thumbnailUrl,
    };
    setTranscript(transcript);
    onNewTranscript(transcript);
  }, [data, onNewTranscript]);


  return {
    transcript,
    isFetching,
    isError,
    error,
  };
}


================================================
FILE: src/modules/youtube/youtube.router.ts
================================================
// Copyright (c) 2023-2024 Enrico Ros
// This subsystem is responsible for fetching the transcript of a YouTube video.
// It is used by the Big-AGI Persona Creator to create a character sheet.

import * as z from 'zod/v4';

import { createTRPCRouter, publicProcedure } from '~/server/trpc/trpc.server';
import { fetchTextOrTRPCThrow } from '~/server/trpc/trpc.router.fetchers';

import { downloadYouTubeVideoData } from './youtube.server';


const inputSchema = z.object({
  videoId: z.string().min(1),
});


export const youtubeRouter = createTRPCRouter({

  /**
   * Get the transcript for a YouTube video ID
   */
  getTranscript: publicProcedure
    .input(inputSchema)
    .query(async ({ input }) => {
      const { videoId } = input;
      return await downloadYouTubeVideoData(videoId, (url) => fetchTextOrTRPCThrow({ url, name: 'YouTube Transcript' }));
    }),

});


/*

"Analyze the provided YouTube transcript, identifying and interpreting key characteristics such as the speaker's professional background, personality traits, style of communication, and core motivations, while specifically focusing on their age, industry knowledge, and narrative context. From this analysis, create a succinct yet comprehensive 'You are a...' character sheet that encapsulates the persona's multifaceted traits. Be sure to infuse the sheet with vivid illustrations drawn from the transcript that bring the character to life, equipping an actor with enough actionable insights for an accurate, engaging portrayal of the persona. The ultimate objective is to transform the text analysis into a tangible character, capturing the essence and complexities of the persona in one complete character sheet."


1. Analysis: "Conduct a comprehensive study of the YouTube transcript. Pinpoint and document key attributes of the speaker, such as age, professional expertise, standout personality traits, unique style of communication, narrative context, and levels of self-awareness. Scrutinize tone, language use, industry knowledge depth, humour usage, and motivations. Your deliverable is a detailed written analysis that effectively chronicles all aspects of the speaker's persona."

2. Character Sheet Drafting: "Translate the completed written analysis into a draft 'You are a...' character sheet. Ensure your draft covers all notable characteristics of the persona, including personality traits, professional background, communication style, knowledge base, context, self-awareness, and motivational aspects. The deliverable at this stage is a comprehensive draft of the character sheet."

3. Validation and Refinement: "Perform a detailed comparison of your character sheet draft and the original transcript. Ensure the sheet captures the speaker's essence and aligns with the transcript content. Integrate distinctive examples from the transcript for tangible, actionable references and refine as necessary for clarity and authenticity. Your final product is a perfected 'You are a...' character sheet, serving as a definitive guide for an actor embodying the persona."


1. Analysis: Conduct comprehensive research on the provided transcript. Identify key characteristics of the speaker, including age, professional field, distinct personality traits, style of communication, narrative context, and self-awareness. Additionally, consider any unique aspects such as their use of humor, their cultural background, core values, passions, fears, personal history, and social interactions. Your output for this stage is an in-depth written analysis that exhibits an understanding of both the superficial and more profound aspects of the speaker's persona.

2. Character Sheet Drafting: Craft your documented analysis into a draft of the 'You are a...' character sheet. It should encapsulate all crucial personality dimensions, along with the motivations and aspirations of the persona. Keep in mind to balance succinctness and depth of detail for each dimension. The deliverable here is a comprehensive draft of the character sheet that captures the speaker's unique essence.

3. Validation and Refinement: Compare the draft character sheet with the original transcript, validating its content and ensuring it captures both the speaker’s overt characteristics and the subtler undertones. Fine-tune any areas that require clarity, have been overlooked, or require more authenticity. Use clear and illustrative examples from the transcript to refine your sheet and offer meaningful, tangible reference points. Your finalized deliverable is a coherent, comprehensive, and nuanced 'You are a...' character sheet that serves as a go-to guide for an actor recreating the persona.

 */


================================================
FILE: src/modules/youtube/youtube.server.ts
================================================
import * as z from 'zod/v4';

import { getImageInformationFromBytes } from '~/modules/t2i/t2i.server';

import type { YouTubeVideoData } from './youtube.types';


/// THIS IS NORMALLY SERVER-SIDE CODE - do not include/invoke in the frontend ///


function extractFromTo(html: string, from: string, to: string, label: string): string {
  const indexStart = html.indexOf(from);
  const indexEnd = html.indexOf(to, indexStart);
  if (indexStart < 0 || indexEnd <= indexStart)
    throw new Error(`[YouTube API Issue] Could not find '${label}'`);
  return html.substring(indexStart, indexEnd);
}


function decodeHtmlEntities(text: string): string {
  const entities: { [key: string]: string } = {
    '&amp;': '&',
    '&lt;': '<',
    '&gt;': '>',
    '&quot;': '"',
    '&#39;': '\'',
    '&#x2F;': '/',
    '&#x60;': '`',
    '&#x3D;': '=',
  };
  return text.replace(/&(?:#x?[0-9a-f]+|[a-z]+);/gi, (match) =>
    entities[match] || match,
  );
}

export async function downloadYouTubeVideoData(videoId: string, fetchTextFn: (url: string) => Promise<string>): Promise<YouTubeVideoData> {

  // 1. find the captions URL within the video HTML page
  const html = await fetchTextFn(`https://www.youtube.com/watch?v=${videoId}`);

  const captionsUrlEnc = extractFromTo(html, 'https://www.youtube.com/api/timedtext', '"', 'Captions URL');
  const captionsUrl = decodeURIComponent(captionsUrlEnc.replaceAll('\\u0026', '&'));

  const thumbnailUrl = extractFromTo(html, 'https://i.ytimg.com/vi/', '"', 'Thumbnail URL').replaceAll('maxres', 'hq');
  const videoTitle = decodeHtmlEntities(extractFromTo(html, '<title>', '</title>', 'Video Title').slice(7).replaceAll(' - YouTube', '').trim());
  const videoDescription = extractFromTo(html, ',"shortDescription":"', '","', 'Video Description').slice(21);

  // 2. fetch the captions
  // note: the desktop player appends this much: &fmt=json3&xorb=2&xobt=3&xovt=3&cbr=Chrome&cbrver=114.0.0.0&c=WEB&cver=2.20230628.07.00&cplayer=UNIPLAYER&cos=Windows&cosver=10.0&cplatform=DESKTOP
  const captions = await fetchTextFn(captionsUrl + `&fmt=json3`);

  // parse json
  let captionsJson: any;
  try {
    captionsJson = JSON.parse(captions);
  } catch (e) {
    console.error(e);
    throw new Error('[YouTube API Issue] Could not parse the captions');
  }

  // validate object
  const youtubeTranscriptionSchema = z.object({
    wireMagic: z.literal('pb3'),
    events: z.array(
      z.object({
        tStartMs: z.number(),
        dDurationMs: z.number().optional(),
        aAppend: z.number().optional(),
        segs: z.array(
          z.object({
            utf8: z.string(),
            tOffsetMs: z.number().optional(),
          }),
        ).optional(),
      }),
    ),
  });
  const safeData = youtubeTranscriptionSchema.safeParse(captionsJson);
  if (!safeData.success) {
    console.error(safeData.error);
    throw new Error('[YouTube API Issue] Could not verify the captions');
  }

  // 3. flatten to text
  const transcript = safeData.data.events
    .flatMap(event => event.segs ?? [])
    .map(seg => seg.utf8)
    .join('');

  // 4. fetch and process the thumbnail image
  let thumbnailImage: YouTubeVideoData['thumbnailImage'] = null;
  try {
    thumbnailImage = await _downloadAndConvertThumbnail(thumbnailUrl);
  } catch (error) {
    console.error('Error fetching or processing thumbnail:', error);
  }

  return {
    videoId,
    videoTitle,
    videoDescription,
    thumbnailUrl,
    thumbnailImage,
    transcript,
  };
}


async function _downloadAndConvertThumbnail(url: string): Promise<YouTubeVideoData['thumbnailImage']> {
  try {
    const response = await fetch(url);
    if (!response.ok) {
      console.warn(`Failed to fetch thumbnail: HTTP ${response.status}`);
      return null;
    }
    // get low-level image information
    const imageBuffer = await response.arrayBuffer();
    const base64Image = Buffer.from(imageBuffer).toString('base64');
    const imgInfo = getImageInformationFromBytes(imageBuffer);
    // return the image dataurl and its information
    return {
      mimeType: imgInfo.mimeType,
      imgDataUrl: `data:${imgInfo.mimeType};base64,${base64Image}`,
      width: imgInfo.width,
      height: imgInfo.height,
    };
  } catch (error) {
    console.error('Error downloading or processing thumbnail:', error);
    return null;
  }
}



================================================
FILE: src/modules/youtube/youtube.types.ts
================================================
export interface YouTubeVideoData {
  videoId: string;
  videoTitle: string;
  videoDescription: string;
  thumbnailUrl: string;
  thumbnailImage: null | {
    imgDataUrl: string;
    mimeType: string;
    width: number;
    height: number;
  };
  transcript: string;
}


================================================
FILE: src/modules/youtube/youtube.utils.ts
================================================
export function extractYoutubeVideoIDFromURL(testYTUrl: string): string | null {

  /* NOTE: We had this approach before, but changing to using the URL class for parsing.
   * const regExpInitial = /^(?:https?:\/\/)?(?:www\.)?(?:youtube\.com\/(?:watch\?v=|embed\/|v\/)|youtu\.be\/)([\w-]{11})(?:\S+)?$/;
   * const regExpProbOkay = /^(?:https?:\/\/)?(?:www\.|m\.)?(?:youtube\.com\/(?:watch\?v=|embed\/|v\/|shorts\/|live\/|clip\/)|youtu\.be\/)([\w-]{11})(?:\S+)?$/;
   * const match = videoURL.match(regExp);
   * return match ? match[1] : null;
   */
  try {
    testYTUrl = testYTUrl.trim();
    if (!testYTUrl)
      return null;

    // relax protocol
    // noinspection HttpUrlsUsage
    if (!testYTUrl.startsWith('http://') && !testYTUrl.startsWith('https://'))
      testYTUrl = 'https://' + testYTUrl;

    const url = new URL(testYTUrl);

    // require a YouTube hostname
    const youtubeDomainPatterns = [
      /^(?:www\.)?youtube\.com$/,                    // Main domain
      /^(?:.*\.)?youtube\.com$/,                     // Any subdomain
      /^youtu\.be$/,                                 // Short links
      /^youtube\.[a-z]{2,3}(?:\.[a-z]{2})?$/,        // Country-specific domains
    ] as const;
    const isYoutubeHostname = youtubeDomainPatterns.some(pattern => pattern.test(url.hostname));
    if (!isYoutubeHostname)
      return null;

    // YouTube video ID validation pattern
    const videoIdPattern = /^[\w-]{11}$/;

    // SHORTLINK path match
    if (url.hostname === 'youtu.be') {
      const possibleID = url.pathname.slice(1).split('/')[0]; // Get first path segment
      if (videoIdPattern.test(possibleID))
        return possibleID;
      // console.log('[DEV]: Invalid youtu.be video ID:', possibleID);
      return null;
    }

    // QUERY match - Check for video ID in query parameters - both 'v' and 'video_id'
    const queryVideoId = url.searchParams.get('v') || url.searchParams.get('video_id');
    if (queryVideoId && videoIdPattern.test(queryVideoId))
      return queryVideoId;

    // PATH match - Handle various YouTube path patterns
    const validPaths = ['watch', 'embed', 'shorts', 'live', 'clip', 'v'];
    const pathSegments = url.pathname.split('/').filter(Boolean);

    // If the first segment is a known path type, look for ID in the next segment
    if (pathSegments.length >= 2 && validPaths.includes(pathSegments[0])) {
      const possibleID = pathSegments[1];
      if (videoIdPattern.test(possibleID))
        return possibleID;
    }

    // Check each path segment for a valid video ID
    for (const segment of pathSegments)
      if (videoIdPattern.test(segment))
        return segment;

    return null;
  } catch (e) {
    return null;
  }
}


================================================
FILE: src/modules/youtube/YouTubeURLInput.tsx
================================================
import * as React from 'react';
import { useQuery } from '@tanstack/react-query';

import type { SxProps } from '@mui/joy/styles/types';
import { Box, Button, Input } from '@mui/joy';
import YouTubeIcon from '@mui/icons-material/YouTube';

import { InlineError } from '~/common/components/InlineError';

import type { YouTubeVideoData } from './youtube.types';
import { extractYoutubeVideoIDFromURL } from './youtube.utils';
import { youTubeGetVideoData } from './useYouTubeTranscript';


interface YouTubeURLInputProps {
  onSubmit: (transcript: string) => void;
  sx?: SxProps;
}

export const YouTubeURLInput: React.FC<YouTubeURLInputProps> = ({ onSubmit, sx }) => {

  // state
  const [url, setUrl] = React.useState('');

  // derived state
  const validVideoId = extractYoutubeVideoIDFromURL(url);

  // query
  const { isFetching: isTranscriptFetching, refetch: refetchTranscript, isError, error, isSuccess } = useQuery({
    enabled: false,
    queryKey: ['videoData', validVideoId],
    queryFn: async (): Promise<YouTubeVideoData> => youTubeGetVideoData(validVideoId!),
    staleTime: Infinity,
  });


  const handleChange = React.useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    setUrl(event.target.value);
  }, [setUrl]);

  const handleSubmit = React.useCallback(async (event: React.FormEvent<HTMLFormElement>) => {
    event.preventDefault(); // Prevent form from causing a page reload

    const result = await refetchTranscript();
    if (result.data)
      onSubmit(result.data.transcript);

  }, [onSubmit, refetchTranscript]);


  return (
    <Box sx={sx}>
      <form onSubmit={handleSubmit}>
        <Box sx={{ display: 'flex', gap: 1, alignItems: 'center' }}>
          <Input
            required
            type='url'
            fullWidth
            disabled={isTranscriptFetching}
            variant='outlined'
            placeholder='Enter YouTube Video URL'
            value={url}
            onChange={handleChange}
            startDecorator={<YouTubeIcon sx={{ color: '#f00' }} />}
            sx={{ backgroundColor: 'background.popup' }}
          />
          <Button
            type='submit'
            color={isSuccess ? 'success' : isTranscriptFetching ? 'neutral' : 'primary'}
            variant={isSuccess ? 'soft' : !validVideoId ? 'outlined' : 'solid'}
            disabled={!validVideoId}
            loading={isTranscriptFetching}
            sx={{ minWidth: 140 }}
            // endDecorator={isSuccess ? '✓' : undefined}
          >
            Get Transcript
          </Button>
        </Box>
      </form>
      {isError && <InlineError error={`Error fetching transcript. Please try again. ${error.message}`}></InlineError>}
    </Box>
  );
};


================================================
FILE: src/server/env.ts
================================================
// noinspection ES6PreferShortImport - because the build would not find this file with ~/...
import { createEnv } from '../modules/3rdparty/t3-env';
import * as z from 'zod/v4';

export const env = createEnv({

  /*
   * Serverside Environment variables, not available on the client.
   * Will throw if you access these variables on the client.
   */
  server: {

    // Backend Postgres, for optional storage via Prisma
    POSTGRES_PRISMA_URL: z.string().optional(),
    POSTGRES_URL_NON_POOLING: z.string().optional(),
    // Backend MongoDB, for a more complete developer data platform.
    MDB_URI: z.string().optional(),


    // LLM: OpenAI
    OPENAI_API_KEY: z.string().optional(),
    OPENAI_API_HOST: z.url().optional(),
    OPENAI_API_ORG_ID: z.string().optional(),

    // LLM: Alibaba (OpenAI)
    ALIBABA_API_HOST: z.url().optional(),
    ALIBABA_API_KEY: z.string().optional(),

    // LLM: Azure OpenAI
    AZURE_OPENAI_API_ENDPOINT: z.url().optional(),
    AZURE_OPENAI_API_KEY: z.string().optional(),

    // LLM: Anthropic
    ANTHROPIC_API_KEY: z.string().optional(),
    ANTHROPIC_API_HOST: z.url().optional(),

    // LLM: Deepseek AI
    DEEPSEEK_API_KEY: z.string().optional(),

    // LLM: Google AI's Gemini
    GEMINI_API_KEY: z.string().optional(),

    // LLM: Groq
    GROQ_API_KEY: z.string().optional(),

    // LLM: LocalAI
    LOCALAI_API_HOST: z.url().optional(),
    LOCALAI_API_KEY: z.string().optional(),

    // LLM: Mistral
    MISTRAL_API_KEY: z.string().optional(),

    // LLM: Ollama
    OLLAMA_API_HOST: z.url().optional(),

    // LLM: OpenPipe
    OPENPIPE_API_KEY: z.string().optional(),

    // LLM: OpenRouter
    OPENROUTER_API_KEY: z.string().optional(),

    // LLM: Perplexity
    PERPLEXITY_API_KEY: z.string().optional(),

    // LLM: Together AI
    TOGETHERAI_API_KEY: z.string().optional(),

    // LLM: xAI
    XAI_API_KEY: z.string().optional(),


    // Helicone - works on both OpenAI and Anthropic vendors
    HELICONE_API_KEY: z.string().optional(),


    // Browsing Service
    PUPPETEER_WSS_ENDPOINT: z.url().optional(),

    // Google Custom Search
    GOOGLE_CLOUD_API_KEY: z.string().optional(),
    GOOGLE_CSE_ID: z.string().optional(),


    // Text-To-Speech: ElevenLabs - speech.ts
    ELEVENLABS_API_KEY: z.string().optional(),
    ELEVENLABS_API_HOST: z.url().optional(),
    ELEVENLABS_VOICE_ID: z.string().optional(),


    // Backend: HTTP Basic Authentication
    HTTP_BASIC_AUTH_USERNAME: z.string().optional(),
    HTTP_BASIC_AUTH_PASSWORD: z.string().optional(),

    // Build-time configuration (ignore)
    BIG_AGI_BUILD: z.enum(['standalone', 'static']).optional(),

  },

  /*
   * Environment variables available on the client (and server).
   * You'll get type errors if these are not prefixed with NEXT_PUBLIC_.
   *
   * NOTE: they must be set at build time, not runtime(!)
   */
  client: {

    // Frontend: Google Analytics GA4 Measurement ID
    NEXT_PUBLIC_GA4_MEASUREMENT_ID: z.string().optional(),

    // Frontend: server to use for PlantUML rendering
    NEXT_PUBLIC_PLANTUML_SERVER_URL: z.url().optional(),

  },

  // matches user expectations - see https://github.com/enricoros/big-AGI/issues/279
  emptyStringAsUndefined: true,

  // with Noext.JS >= 13.4.4 we'd only need to destructure client variables
  experimental__runtimeEnv: {
    NEXT_PUBLIC_GA4_MEASUREMENT_ID: process.env.NEXT_PUBLIC_GA4_MEASUREMENT_ID,
    NEXT_PUBLIC_PLANTUML_SERVER_URL: process.env.NEXT_PUBLIC_PLANTUML_SERVER_URL,
  },
});

/**
 * Dummy function to validate any build-time environment variables.
 * Does nothing really, but forces the creation of the `env` object.
 *
 * At runtime the `env` object is actually used.
 */
export function verifyBuildTimeVars(): number {
  return Object.keys(env).length;
}



================================================
FILE: src/server/wire.ts
================================================
/// set this to true to see the tRPC and fetch requests made by the server
export const SERVER_DEBUG_WIRE = false; //


export class ServerFetchError extends Error {
  public statusCode: number;

  constructor({ statusCode, message }: { statusCode: number, message: string }) {
    super(message);
    this.statusCode = statusCode;
    this.name = 'ServerFetchError';
  }
}


/**
 * Fetches a URL, but throws an Error if the response is not ok.
 */
export async function nonTrpcServerFetchOrThrow(url: string, method: 'GET' | 'POST', headers: HeadersInit, body: object | undefined, signal?: AbortSignal): Promise<Response> {
  // create the upstream request object
  const response = await fetch(url, {
    method,
    headers,
    ...(body !== undefined ? { body: JSON.stringify(body) } : {}),
    ...(signal !== undefined ? { signal } : {}),
  });

  // Throws an error if the response is not ok
  // Use in server-side code, and not tRPC code (which has utility functions in trpc.serverutils.ts)
  if (!response.ok) {
    let payload: any | null = await response.json().catch(() => null);
    if (payload === null)
      payload = await response.text().catch(() => null);
    const errorPayloadString = payload ? ': ' + JSON.stringify(payload, null, 2).slice(1, -1) : '';
    throw new ServerFetchError({
      message: `${response.statusText} (${response.status})${errorPayloadString}`,
      statusCode: response.status,
    });
  }

  return response;
}


/**
 * Safely convert a typical exception/error to a string.
 */
export function safeErrorString(error: any): string | null {
  // skip nulls
  if (!error)
    return null;

  // handle AggregateError
  if (error instanceof AggregateError) {
    const errors = error.errors.map(e => safeErrorString(e)).filter(Boolean);
    return `AggregateError: ${errors.join('; ')}`;
  }

  // descend into an 'error' object
  if (error.error)
    return safeErrorString(error.error);

  // choose the 'message' property if available
  if (error.message) {
    if (error.message === 'AggregateError' && error.stack)
      return `AggregateError: ${safeErrorString(error.stack)}`;
    return safeErrorString(error.message);
  }
  if (typeof error === 'string')
    return error;
  if (typeof error === 'object') {
    try {
      return JSON.stringify(error, null, 2).slice(1, -1);
    } catch (error) {
      // ignore
    }
  }

  // unlikely fallback
  return error.toString();
}

export function serverCapitalizeFirstLetter(string: string) {
  return string?.length ? (string.charAt(0).toUpperCase() + string.slice(1)) : string;
}


/**
 * Weak (meaning the string could be encoded poorly) function that returns a string that can be used to debug a request
 */
export function debugGenerateCurlCommand(method: 'GET' | 'POST' | 'DELETE' | 'PUT', url: string, headers?: HeadersInit, body?: object): string {
  let curl = `curl -X ${method} '${url}' `;

  const headersRecord = (headers || {}) as Record<string, string>;

  for (const header in headersRecord)
    curl += `-H '${header}: ${headersRecord[header]}' `;

  if (method === 'POST' && body) {
    if (body instanceof FormData) {
      for (const [key, value] of body.entries()) {
        if (value instanceof File) {
          curl += `-F '${key}=@${value.name}' `;
        } else {
          curl += `-F '${key}=${value}' `;
        }
      }
    } else
      curl += `-d '${JSON.stringify(body)}'`;
  }

  return curl;
}

export function createEmptyReadableStream<T = Uint8Array>(): ReadableStream<T> {
  return new ReadableStream({
    start: (controller) => controller.close(),
  });
}


/**
 * Small debugging utility to log train of events, used on the server-side
 * for incoming packets (e.g. SSE).
 */
export class ServerDebugWireEvents {
  private sequenceNumber: number = 0;
  private lastMs: number | null = null;

  onMessage(message: any) {
    this.sequenceNumber++;
    if (SERVER_DEBUG_WIRE) {
      const nowMs = Date.now();
      const elapsedMs = this.lastMs ? nowMs - this.lastMs : 0;
      this.lastMs = nowMs;
      console.log(`<- SSE (${this.sequenceNumber}, ${elapsedMs} ms):`, message);
    }
  }
}

export const createServerDebugWireEvents = () => SERVER_DEBUG_WIRE ? new ServerDebugWireEvents() : null;


/** Utility to escape XML, for example to avoid XSS attacks. */
export function escapeXml(unsafe: string): string {
  return unsafe.replace(/[&<>"']/g, (match) => {
    switch (match) {
      case '&':
        return '&amp;';
      case '<':
        return '&lt;';
      case '>':
        return '&gt;';
      case '"':
        return '&quot;';
      case '\'':
        return '&#39;';
      default:
        return match;
    }
  });
}


================================================
FILE: src/server/posthog/posthog.server.ts
================================================
/**
 * PostHog server-side client for error tracking
 * Automatically uses the right implementation for Edge vs Node.js runtime
 */
import { PostHog } from 'posthog-node';


// Singleton instance - PostHog client handles batching internally
let _posthogServer: PostHog | null = null;

function _getPosthogServer(): PostHog | null {
  if (!process.env.NEXT_PUBLIC_POSTHOG_KEY) return null;
  if (_posthogServer) return _posthogServer;
  return _posthogServer = new PostHog(process.env.NEXT_PUBLIC_POSTHOG_KEY, {
    host: 'https://us.i.posthog.com', // server exceptions host
    // enableExceptionAutocapture: true, // untested, so disabled for now
    // for server-side, we want immediate flushing
    flushAt: 1,
    flushInterval: 0,
  });
}


// Note: captureServerEvent functionality may be added in the future
// For now, we focus on error tracking only


/**
 * Captures an exception to PostHog from server-side code
 * The posthog-node library automatically uses the right implementation for Edge vs Node.js
 */
export async function posthogCaptureServerException(
  error: Error | unknown,
  context: {
    runtime: 'edge' | 'nodejs';
    endpoint: string;
    method?: string;
    url?: string;
    distinctId?: string;
    additionalProperties?: Record<string, any>;
  },
): Promise<void> {
  const client = _getPosthogServer();
  if (!client) return;

  try {
    const distinctId = context.distinctId || `server_${context.runtime}_${Date.now()}`;

    // Use the immediate variant for better performance in serverless environments
    await client.captureExceptionImmediate(error, distinctId, {
      // Error source identification
      $exception_source: 'server',
      $exception_runtime: context.runtime,
      // Context properties
      runtime: context.runtime,
      endpoint: context.endpoint,
      method: context.method,
      url: context.url,
      // Any additional properties
      ...context.additionalProperties,
    });

  } catch (captureError) {
    // Don't throw errors from error tracking itself
    console.error('[PostHog] Error capturing exception:', captureError);
  }
}



================================================
FILE: src/server/prisma/prismaDb.ts
================================================
import { PrismaClient } from '@prisma/client';


const globalForPrisma = globalThis as unknown as {
  prisma: PrismaClient | undefined;
};

export const prismaDb =
  globalForPrisma.prisma ??
  new PrismaClient({
    log: process.env.NODE_ENV === 'development' ? ['query', 'error', 'warn'] : ['error'],
  });

if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prismaDb;



================================================
FILE: src/server/prisma/schema.prisma
================================================
// Prisma is the ORM for server-side (API) access to the database
//
// This file defines the schema for the database.
//  - make sure to run 'prisma generate' after making changes to this file
//  - make sure to run 'prisma db push' to sync the remote database with the schema
//
// Database is optional: when the environment variables are not set, the database is not used at all,
// and the storage of data in Big-AGI is limited to client-side (browser) storage.
//
// The database is used for:
//  - the 'sharing' function, to let users share the chats with each other

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider  = "postgresql"
  url       = env("POSTGRES_PRISMA_URL") // uses connection pooling
  directUrl = env("POSTGRES_URL_NON_POOLING") // uses a direct connection
}

//
// Storage of Linked Data
//
model LinkStorage {
  id String @id @default(uuid())

  ownerId    String
  visibility LinkStorageVisibility

  dataType  LinkStorageDataType
  dataTitle String?
  dataSize  Int
  data      Json

  upVotes    Int @default(0)
  downVotes  Int @default(0)
  flagsCount Int @default(0)
  readCount  Int @default(0)
  writeCount Int @default(1)

  // time-based expiration
  expiresAt DateTime?

  // manual deletion
  deletionKey String
  isDeleted   Boolean   @default(false)
  deletedAt   DateTime?

  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
}

enum LinkStorageVisibility {
  PUBLIC
  UNLISTED
  PRIVATE
}

enum LinkStorageDataType {
  CHAT_V1
}



================================================
FILE: src/server/trpc/trpc.nanoid.ts
================================================
import { nanoid } from 'nanoid';

/**
 * There's a copy of this function in src/common/util/idUtils.ts, but that one is for client-side use.
 * This one is for server-side use.
 */
export function serverSideId(_serverScope: 'aix-tool-call-id' | 'aix-tool-response-id', digits?: number) {
  return 'aix_' + nanoid(digits);
}



================================================
FILE: src/server/trpc/trpc.next-edge.ts
================================================
/// Next.js Edge Runtime check - won't activate otherwise
declare global {
  // noinspection ES6ConvertVarToLetConst
  var EdgeRuntime: string | undefined;
}

/**
 * 2025-05-22: Workaround an issue that appeared in all Vercel deployments.
 * https://github.com/enricoros/big-AGI/issues/805
 *
 * This is an emergency workaround for the 'Stream closed' issue, while the 6 Exceptions are still
 * thrown on each tRPC call.
 *
 * Analysis:
 * - the server side saw the following exceptions on Vercel, during the call to this server-side tRPC
 *   streaming chatGenerateContent function:
 *
 *   TypeError: Cannot read properties of undefined (reading 'return')
 *     at (node_modules/@trpc/server/dist/unstable-core-do-not-import/stream/utils/disposable.mjs:38:0)
 *     at (node_modules/@trpc/server/dist/unstable-core-do-not-import/stream/jsonl.mjs:204:0)
 *
 * - we haven't isolated the cause, but seems that awaiting for the next event loop cycle suppresses
 *   the issue.
 *
 * Ext refs: posted to the tRCP Discord on the streaming channel if anyone else saw this issue.
 */
export function delayPostAsyncGeneratorOnEdge<TArgs, TYield>(
  delayMs: number,
  originalAsyncGeneratorFn: (args: TArgs) => AsyncGenerator<TYield>,
): (args: TArgs) => AsyncGenerator<TYield> {
  return async function* wrappedAsyncGenerator(args: TArgs): AsyncGenerator<TYield> {

    yield* originalAsyncGeneratorFn(args);

    // [EdgeRuntime]
    if (typeof EdgeRuntime === 'string') {
      if (delayMs >= 0)
        await new Promise((resolve) => setTimeout(resolve, delayMs));
    }

    // explicitly return void
    return;
  };
}



================================================
FILE: src/server/trpc/trpc.router-cloud.ts
================================================
import { createTRPCRouter } from './trpc.server';

import { browseRouter } from '~/modules/browse/browse.router';
import { tradeRouter } from '~/modules/trade/server/trade.router';

/**
 * Cloud rooter, which is geolocated in 1 location and separate from the other routers.
 * NOTE: at the time of writing, the location is aws|us-east-1
 */
export const appRouterCloud = createTRPCRouter({
  browse: browseRouter,
  trade: tradeRouter,
});

// export type definition of API
export type AppRouterCloud = typeof appRouterCloud;


================================================
FILE: src/server/trpc/trpc.router-edge.ts
================================================
import { createTRPCRouter } from './trpc.server';

import { aixRouter } from '~/modules/aix/server/api/aix.router';
import { backendRouter } from '~/modules/backend/backend.router';
import { elevenlabsRouter } from '~/modules/elevenlabs/elevenlabs.router';
import { googleSearchRouter } from '~/modules/google/search.router';
import { llmAnthropicRouter } from '~/modules/llms/server/anthropic/anthropic.router';
import { llmGeminiRouter } from '~/modules/llms/server/gemini/gemini.router';
import { llmOllamaRouter } from '~/modules/llms/server/ollama/ollama.router';
import { llmOpenAIRouter } from '~/modules/llms/server/openai/openai.router';
import { youtubeRouter } from '~/modules/youtube/youtube.router';

/**
 * Primary rooter, and will be sitting on an Edge Runtime.
 */
export const appRouterEdge = createTRPCRouter({
  aix: aixRouter,
  backend: backendRouter,
  elevenlabs: elevenlabsRouter,
  googleSearch: googleSearchRouter,
  llmAnthropic: llmAnthropicRouter,
  llmGemini: llmGeminiRouter,
  llmOllama: llmOllamaRouter,
  llmOpenAI: llmOpenAIRouter,
  youtube: youtubeRouter,
});

// export type definition of API
export type AppRouterEdge = typeof appRouterEdge;


================================================
FILE: src/server/trpc/trpc.router.fetchers.ts
================================================
import { TRPCError } from '@trpc/server';

import { debugGenerateCurlCommand, safeErrorString, SERVER_DEBUG_WIRE } from '~/server/wire';


//
// NOTE: This file is used in the server-side code, and not in the client-side code.
//
// It is used to fetch data from external APIs, and throw TRPC errors on failure.
//
// It handles connection errors, HTTP errors, and parsing errors.
//

// JSON fetcher
export async function fetchJsonOrTRPCThrow<TOut extends object = object, TBody extends object | undefined | FormData = undefined>(config: RequestConfig<TBody>): Promise<TOut> {
  return _fetchFromTRPC<TBody, TOut>(config, async (response) => await response.json(), 'json');
}

// Text fetcher
export async function fetchTextOrTRPCThrow<TBody extends object | undefined = undefined>(config: RequestConfig<TBody>): Promise<string> {
  return _fetchFromTRPC<TBody, string>(config, async (response) => await response.text(), 'text');
}

// Response fetcher
export async function fetchResponseOrTRPCThrow<TBody extends object | undefined = undefined>(config: RequestConfig<TBody>): Promise<Response> {
  return _fetchFromTRPC<TBody, Response>(config, async (response) => response, 'response');
}


type RequestConfig<TBody extends object | undefined | FormData> = {
  url: string;
  headers?: HeadersInit;
  signal?: AbortSignal;
  name: string;
  throwWithoutName?: boolean; // when throwing, do not add the module name (the caller will improve the output)
} & (
  | { method?: 'GET' /* in case of GET, the method is optional, and no body */ }
  | { method: 'POST'; body: TBody }
  | { method: 'PUT'; body: TBody }      // [fred-sync] added PUT
  | { method: 'DELETE'; body?: TBody }  // [Ollama] Violates the spec and has a body on DELETE requests
  );


/**
 * Internal fetcher
 * - Parses errors on connection, http responses, and parsing
 * - Throws TRPCErrors (as this is used within tRPC procedures)
 */
async function _fetchFromTRPC<TBody extends object | undefined | FormData, TOut>(
  config: RequestConfig<TBody>,
  responseParser: (response: Response) => Promise<TOut>,
  parserName: 'json' | 'text' | 'response',
): Promise<TOut> {

  const { url, method = 'GET', headers: configHeaders, name: moduleName, signal, throwWithoutName = false } = config;
  const body = 'body' in config ? config.body : undefined;

  // 1. Fetch a Response object
  let response: Response;
  try {

    // handle FormData automatically
    const isFormData = method === 'POST' && body instanceof FormData;

    // prepare headers, DO NOT set Content-Type for FormData, let the browser do it
    const headers: HeadersInit | undefined = !configHeaders ? undefined : { ...configHeaders };
    if (isFormData && headers) {
      delete (headers as any)['Content-Type'];
      delete (headers as any)['content-type']; // case-insensitive check
    }
    // else if (body !== undefined && !isFormData && !(headers as any)['Content-Type'])
    //   (headers as any)['Content-Type'] = 'application/json';

    if (SERVER_DEBUG_WIRE)
      console.log('-> fetch:', debugGenerateCurlCommand(method, url, headers, body));

    // upstream request
    const request: RequestInit = {
      method,
      headers,
      body: body === undefined ? undefined : isFormData ? body : JSON.stringify(body),
      signal,
    };

    // upstream fetch
    response = await fetch(url, request);

  } catch (error: any) {

    // [logging - Connection error] candidate for the logging system
    const errorCause: object | undefined = error ? error?.cause ?? undefined : undefined;

    // NOTE: This may log too much - for instance a 404 not found, etc.. - so we're putting it under the flag
    //       Consider we're also throwing the same, so there will likely be further logging.
    if (SERVER_DEBUG_WIRE)
      console.warn(`[${method}] ${moduleName} error (network):`, errorCause || error /* circular struct, don't use JSON.stringify.. */);

    // Handle Connection errors - HTTP 400
    throw new TRPCError({
      code: 'BAD_REQUEST',
      message: (throwWithoutName ? '' : `[${moduleName} network issue]: `)
        + (safeErrorString(error) || 'unknown fetch error')
        + (errorCause
          ? ` - ${safeErrorString(errorCause)}`
          : '')
        + ((errorCause && (errorCause as any)?.code === 'ECONNREFUSED')
          ? ` - is "${url}" accessible by the server?`
          : ''),
      cause: errorCause,
    });
  }

  // 2. Check for non-200s
  // These are the MOST FREQUENT errors, application level response. Such as:
  //  - 400 when requesting an invalid size to Dall-E-3, etc..
  //  - 403 when requesting a localhost URL from a public server, etc..
  if (!response.ok) {
    // try to parse a json or text payload, which frequently contains the error, if present
    const responseCloneIfJsonFails = response.clone();
    let payload: any | null = await response.json().catch(() => null);
    if (payload === null)
      payload = await responseCloneIfJsonFails.text().catch(() => null);

    // [logging - HTTP error] candidate for the logging system
    console.error(`[${method}] ${moduleName} error (upstream): ${response.status} (${response.statusText}):`, safeErrorString(payload));

    // HTTP 400
    throw new TRPCError({
      code: 'BAD_REQUEST',
      message: (throwWithoutName ? '' : `[${moduleName} issue]: `)
        + (response.statusText || '')
        + (payload
          ? ` - ${safeErrorString(payload)}` : '')
        + (payload?.error?.failed_generation // [Groq]
          ? ` - failed_generation: ${payload.error.failed_generation}` : '')
        + (response.status === 403 && !url.includes('app.openpipe.ai' /* [OpenPipe] 403 when the model is associated to the project  */)
          ? ` - is "${url}" accessible by the server?` : '')
        + (response.status === 404 && !url.includes('app.openpipe.ai' /* [OpenPipe] 404 when the model is not found - don't add error details */)
          ? ` - "${url}" cannot be found by the server` : '')
        + (response.status === 502 ?
          ` - is "${url}" not available?` : ''),
    });
  }

  // 3. Safe Parse
  let value: TOut;
  try {
    value = await responseParser(response);
  } catch (error: any) {
    // [logging - Parsing error] candidate for the logging system
    console.error(`[${method}] ${moduleName} error (parse, ${parserName}):`, error);

    // HTTP 422
    throw new TRPCError({
      code: 'UNPROCESSABLE_CONTENT',
      message: (throwWithoutName ? `cannot parse ${parserName}: ` : `[${moduleName} parsing issue]: `)
        + (safeErrorString(error) || 'unknown error'),
    });
  }

  return value;
}



================================================
FILE: src/server/trpc/trpc.server.ts
================================================
/**
 * YOU PROBABLY DON'T NEED TO EDIT THIS FILE, UNLESS:
 * 1. You want to modify request context (see Part 1).
 * 2. You want to create a new middleware or type of procedure (see Part 3).
 *
 * TL;DR - This is where all the tRPC server stuff is created and plugged in. The pieces you will
 * need to use are documented accordingly near the end.
 */
import type { FetchCreateContextFnOptions } from '@trpc/server/adapters/fetch';
import * as z from 'zod/v4';
import { initTRPC } from '@trpc/server';
import { transformer } from '~/server/trpc/trpc.transformer';

/**
 * 1. CONTEXT
 *
 * This section defines the "contexts" that are available in the backend API.
 *
 * These allow you to access things when processing a request, like the database, the session, etc.
 */
export const createTRPCFetchContext = async ({ req }: FetchCreateContextFnOptions) => {
  // const user = { name: req.headers.get('username') ?? 'anonymous' };
  // return { req, resHeaders };
  return {
    // only used by Backend Analytics
    hostName: req.headers?.get('host') ?? 'localhost',
    // enables cancelling upstream requests when the downstream request is aborted
    reqSignal: req.signal,
  };
};


/**
 * 2. SERVER-SIDE INITIALIZATION
 *
 * This is where the tRPC API is initialized, connecting the context and transformer. We also parse
 * ZodErrors so that you get typesafety on the frontend if your procedure fails due to validation
 * errors on the backend.
 */
const t = initTRPC.context<typeof createTRPCFetchContext>().create({
  // server transformer - serialize: -> client, deserialize: <- client
  transformer: transformer,
  errorFormatter({ shape, error }) {
    return {
      ...shape,
      data: {
        ...shape.data,
        zodError:
          error.cause instanceof z.ZodError ? z.treeifyError(error.cause) : null,
      },
    };
  },
});

/**
 * 3. ROUTER & PROCEDURE (THE IMPORTANT BIT)
 *
 * These are the pieces you use to build your tRPC API. You should import these a lot in the
 * "/src/server/api/routers" directory.
 */

/**
 * This is how you create new routers and sub-routers in your tRPC API.
 *
 * @link https://trpc.io/docs/v11/router
 */
export const createTRPCRouter = t.router;

/**
 * Public (unprotected) procedure
 *
 * This is the base piece you use to build new queries and mutations on your tRPC API. It does not
 * guarantee that a user querying is authorized, but you can still access user session data if they
 * are logged in.
 *
 * @link https://trpc.io/docs/v11/procedures
 */
export const publicProcedure = t.procedure;

// /**
//  * Create a server-side caller
//  * @link https://trpc.io/docs/v11/server/server-side-calls
//  */
// export const createCallerFactory = t.createCallerFactory;



================================================
FILE: src/server/trpc/trpc.transformer.ts
================================================
/**
 * If you need to add transformers for special data types like `Temporal.Instant` or `Temporal.Date`, `Decimal.js`, etc you can do so here.
 * Make sure to import this file rather than `superjson` directly.
 * @link https://github.com/blitz-js/superjson#recipes
 */
import superjson from 'superjson';

/**
 * WORKAROUND: an incredibly weird bug with NextJS-14.2.4 + tRPC v11 + SuperJSON
 *
 * If the serialized object has 'undefined' values (e.g. {json.name: null, meta.values.name=['undefined']},
 * superjson will try to apply the format conversion from the 'null' to the 'undefined' value directly to the input object.
 *
 * This somehow fails with tRPC-11 and NextJS-14.2.4. There may be immutability somewhere.
 *
 * While a slot workaround would be to deepcopy (JSON.parse(JSON.stringify(object)) the object
 * we use a more lightweight approach that only works on top-level properties.
 *
 * May be related to https://github.com/blitz-js/superjson/issues/242 ?
 * May be related to https://github.com/blitz-js/superjson/issues/283 ?
 *
 * NOTEs:
 * - 2024-08-10 (1): this doesn't seem to be needed anymore, as such we use plain `superjson` as-is
 * - 2024-08-10 (2): this is actually still needed: the issue is when delivering input data to tRPC calls,
 *     where nulls won't be converted to `undefined`. Furthermore, add the `shallowClone` function to handle
 *     the case of arrays, in addition to objects.
 */
function deserializeWithWorkaround<T = unknown>(object: any): T {

  // Second-level (object.json: {..}) mutability workaround
  // This triggers when both `meta` and `json` are present, which means SuperJSON has
  // special instructionf for the `json` object.
  if (object && object instanceof Object && object?.meta && object?.json)
    object = { ...object, json: shallowClone(object.json) };

  return superjson.deserialize<T>(object);
}

function shallowClone(obj: any): any {
  if (obj === null || typeof obj !== 'object')
    return obj;
  if (Array.isArray(obj))
    return [...obj];
  return { ...obj };
}

export const transformer = {
  serialize: superjson.serialize,
  deserialize: deserializeWithWorkaround,

  // The following commented code is here just to let us place breakpoints quickly

  // serialize: (object: any): any => {
  //   const serialized = superjson.serialize(object);
  //   return serialized;
  // }

  // deserialize: (object: any): any => {
  //   const des = superjson.deserialize(object);
  //   return des;
  // }
};



================================================
FILE: tools/ai/README.md
================================================
## `repo-structure.sh`

This tool creates a compact, hierarchical representation of your Git repository that you can
paste directly into an assistant prompt to provide immediate context. Uses the XML format of
Claude Code.

### Remote Execution

```bash
# Run this from the ROOT of your git repository
curl -fsSL https://raw.githubusercontent.com/enricoros/big-AGI/v2-dev/tools/ai/repo-structure.sh | sh
```

## Options

- `-a, --all`: Include hidden files and directories
- `-o, --output FILE`: Save output to a file
- `-h, --help`: Show help message

Example with options (include hidden files):

- `curl -fsSL https://raw.githubusercontent.com/enricoros/big-AGI/v2-dev/tools/ai/repo-structure.sh | sh -s -- -a`

## Requirements

- Bash 4+ (for associative arrays)
- Git (the repository must be initialized)
- For clipboard functionality:
  - macOS: pbcopy (built-in)
  - Linux: xclip or xsel
  - Windows: clip (Git Bash)

## How does the output look?

The output is specifically formatted for easy consumption by AI assistants:

```xml
<context name="directoryStructure" description="Below is a snapshot of this project root file structure (git ls-files) at the start of the conversation. This snapshot will NOT update during the conversation.">
- README.md
- src/
  - app/
    - components/
      - Button.tsx
  ...
</context>
```

Just paste this into your AI assistant's prompt for instant context about the codebase structure.



================================================
FILE: tools/ai/repo-structure.sh
================================================
#!/usr/bin/env bash
# Generate repository structure for AI assistant memory
# Wraps output in <context name="directoryStructure"> tags.
# Hides dotfiles by default, use -a/--all to show them.

# Default settings
INCLUDE_HIDDEN=false
COPY_TO_CLIPBOARD=true

# Function to print usage
print_usage() {
  echo "Usage: $0 [options]"
  echo "Options:"
  echo "  -a, --all         Include hidden files and directories (starting with '.')"
  echo "  -o, --output      Output to a file instead of stdout (e.g., -o structure.xml)"
  echo "  -h, --help        Show this help message"
}

# Parse arguments
OUTPUT_FILE=""
while [[ "$#" -gt 0 ]]; do
  case $1 in
    -a|--all) INCLUDE_HIDDEN=true ;;
    -o|--output) OUTPUT_FILE="$2"; shift ;;
    -h|--help) print_usage; exit 0 ;;
    *) echo "Unknown parameter: $1"; print_usage; exit 1 ;;
  esac
  shift
done

# Check if we're in a git repository
if ! git rev-parse --is-inside-work-tree &>/dev/null; then
  echo "Error: This script must be run from within a Git repository." >&2
  echo "Please navigate to your repository and try again." >&2
  exit 1
fi


# Try to find the clipboard command for the current OS
clipboard_cmd=""
if [[ "$OSTYPE" == "darwin"* ]]; then
  # macOS
  clipboard_cmd="pbcopy"
elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
  # Linux with X11
  if command -v xclip &>/dev/null; then
    clipboard_cmd="xclip -selection clipboard"
  elif command -v xsel &>/dev/null; then
    clipboard_cmd="xsel --clipboard --input"
  fi
elif [[ "$OSTYPE" == "msys" || "$OSTYPE" == "win32" ]]; then
  # Windows Git Bash or similar
  clipboard_cmd="clip"
fi


# Generate the structure
generate_structure() {
  # Use XML-like tags instead of markdown code fences
  echo '<context name="directoryStructure" description="Below is a snapshot of this project root file structure (git ls-files) at the start of the conversation. This snapshot will NOT update during the conversation.">'
  echo ""

  # Create temporary files
  TMP_FILE=$(mktemp)
  PROCESSED_DIRS_FILE=$(mktemp)

  # Get all Git-tracked files, filtering hidden ones if needed
  if [[ "$INCLUDE_HIDDEN" == false ]]; then
    # Filter out hidden files/dirs using grep -vE
    git ls-files | grep -vE '(^|/)\.' | sort > "$TMP_FILE"
  else
    # Include all files
    git ls-files | sort > "$TMP_FILE"
  fi

  # Check if TMP_FILE is empty after filtering
  if [[ ! -s "$TMP_FILE" ]]; then
      echo "# (No files found matching criteria)"
      rm "$TMP_FILE" "$PROCESSED_DIRS_FILE"
      echo '</context>' # Close the tag even if empty
      return
  fi

  # Process each file
  while IFS= read -r file; do
    # Skip empty lines
    if [[ -z "$file" ]]; then
      continue
    fi
    
    # Extract directory parts using dirname and basename
    filename=$(basename "$file")
    dirpath=$(dirname "$file")
    
    # Process the directory path
    if [[ "$dirpath" != "." ]]; then
      # Split directory path into parts
      current_path=""
      dir_parts=""
      
      # Use a safer method to split the path
      IFS='/' dir_parts=($dirpath)
      
      # Process each directory level
      for ((i=0; i<${#dir_parts[@]}; i++)); do
        part="${dir_parts[$i]}"
        if [[ -z "$part" ]]; then
          continue
        fi
        
        if [[ -z "$current_path" ]]; then
          current_path="$part"
        else
          current_path="$current_path/$part"
        fi
        
        # Check if we've already processed this directory
        if ! grep -q "^$current_path\$" "$PROCESSED_DIRS_FILE" 2>/dev/null; then
          echo "$current_path" >> "$PROCESSED_DIRS_FILE"
          indent=$((i * 2))
          
          # Fix the printf issue by ensuring the format string doesn't start with "-"
          if [ $indent -eq 0 ]; then
            echo "- $part/"
          else
            printf "%${indent}s- %s/\n" "" "$part"
          fi
        fi
      done
      
      # Output the file with proper indentation
      level=${#dir_parts[@]}
      indent=$((level * 2))
      
      # Fix the printf issue for files too
      if [ $indent -eq 0 ]; then
        echo "- $filename"
      else
        printf "%${indent}s- %s\n" "" "$filename"
      fi
    else
      # File is in the root directory - avoid printf issue
      echo "- $filename"
    fi
  done < "$TMP_FILE"
  
  # Clean up
  rm "$TMP_FILE" "$PROCESSED_DIRS_FILE"

  # Close the XML-like tag
  echo '</context>'
}


# Handle output to file, clipboard, or stdout
if [[ -n "$OUTPUT_FILE" ]]; then
  generate_structure > "$OUTPUT_FILE"
  echo "Repository structure saved to $OUTPUT_FILE"

  if [[ "$COPY_TO_CLIPBOARD" == true ]]; then
    if [[ -n "$clipboard_cmd" ]]; then
      cat "$OUTPUT_FILE" | eval "$clipboard_cmd"
      echo "Also copied to clipboard!"
    else
      echo "Warning: Clipboard copy requested but no clipboard command found for your OS." >&2
    fi
  fi
elif [[ "$COPY_TO_CLIPBOARD" == true ]]; then
  if [[ -n "$clipboard_cmd" ]]; then
    generate_structure | tee >(eval "$clipboard_cmd" > /dev/null)
    echo -e "\nStructure copied to clipboard!"
  else
    echo "Warning: No clipboard command found for your OS. Displaying output instead." >&2
    generate_structure
  fi
else
  generate_structure
fi



================================================
FILE: .claude/settings.local.json
================================================
{
  "permissions": {
    "allow": [
      "Bash(cat:*)",
      "Bash(cp:*)",
      "Bash(find:*)",
      "Bash(git branch:*)",
      "Bash(grep:*)",
      "Bash(ls:*)",
      "Bash(node:*)",
      "Bash(npm install)",
      "Bash(npm install:*)",
      "Bash(npm run:*)",
      "Bash(npx tsc:*)",
      "Bash(rg:*)",
      "Bash(rm:*)",
      "Bash(sed:*)",
      "WebFetch(domain:big-agi.com)",
      "WebFetch(domain:github.com)",
      "mcp__ide__getDiagnostics"
    ],
    "deny": [
      "Read(node_modules)",
      "Read(node_modules/**)"
    ]
  }
}


================================================
FILE: .github/FUNDING.yml
================================================
# These are supported funding model platforms

github: enricoros # Replace with up to 4 GitHub Sponsors-enabled usernames e.g., [user1, user2]
patreon: # Replace with a single Patreon username
open_collective: # Replace with a single Open Collective username
ko_fi: # Replace with a single Ko-fi username
tidelift: # Replace with a single Tidelift platform-name/package-name e.g., npm/babel
community_bridge: # Replace with a single Community Bridge project-name e.g., cloud-foundry
liberapay: # Replace with a single Liberapay username
issuehunt: # Replace with a single IssueHunt username
otechie: # Replace with a single Otechie username
lfx_crowdfunding: # Replace with a single LFX Crowdfunding project-name e.g., cloud-foundry
custom: # Replace with up to 4 custom sponsorship URLs e.g., ['link1', 'link2']



================================================
FILE: .github/ISSUE_TEMPLATE/bug_report.yml
================================================
name: 🐞 Bug Report
description: Create a report to help us improve
title: '[BUG]'
labels: [ 'type: bug' ]
body:
  - type: markdown
    attributes:
      value: Thank you for reporting a bug. Please help us by providing accurate environment information.

  - type: dropdown
    attributes:
      label: Environment
      description: (required) Where are you experiencing this issue?
      options:
        - big-agi.com (production website)
        - GitHub v2-dev branch
        - GitHub other branch (specify in description)
        - Docker container (specify in description)
        - Local development
        - Other
    validations:
      required: true

  - type: textarea
    attributes:
      label: Description
      description: (required) Please provide a clear description and **steps to reproduce**.
      placeholder: 'Concise description + steps to reproduce.'
    validations:
      required: true

  - type: textarea
    attributes:
      label: Device and browser
      description: '(required) Please specify your Mobile/Desktop device, OS version, browser.'
      placeholder: 'Device: (e.g., iPhone 16, Pixel 9, PC, Macbook...), OS: (e.g., iOS 17, Windows 12), Browser: (e.g., Chrome 119, Safari 18, Firefox..)'
    validations:
      required: true

  - type: textarea
    attributes:
      label: Screenshots and more
      placeholder: 'Attach screenshots, or add any additional context here.'

  - type: checkboxes
    attributes:
      label: Willingness to Contribute
      description: We appreciate contributions - would you be willing to submit a pull request?
      options:
        - label: '🙋‍♂️ Yes, I would like to contribute a fix.'



================================================
FILE: .github/ISSUE_TEMPLATE/maintainers-release.md
================================================
---
name: Maintainers-Release
about: Maintainers
title: Release 1.2.3
labels: ''
assignees: enricoros

---

## Release checklist:

- [x] Create a new [Release Issue](https://github.com/enricoros/big-AGI/issues/new?assignees=enricoros&projects=enricoros/4&template=maintainers-release.md&title=Release+1.2.3)
  - [ ] Replace 1.1.0 with the _former_ release, and _1.2.3_ with THIS
- [ ] Update the [Roadmap](https://github.com/users/enricoros/projects/4/views/2) calling out shipped features
- [ ] Create and update a [Milestone](https://github.com/enricoros/big-agi/milestones) for the release
  - [ ] Assign this task
  - [ ] Assign all the shipped roadmap Issues
  - [ ] Assign the relevant [recently closed Isssues](https://github.com/enricoros/big-agi/issues?q=is%3Aclosed+sort%3Aupdated-desc)
- Code changes:
  - [ ] Create a release branch 'release-x.y.z': `git checkout -b release-1.2.3`
  - [ ] Create a temporary tag `git tag v1.2.3 && git push opensource --tags`
  - [ ] Create a [New Draft GitHub Release](https://github.com/enricoros/big-agi/releases/new), and generate the automated changelog (for new contributors)
  - [ ] Update the release version in package.json, and `npm i`
  - [ ] Update the in-app News version number
  - [ ] Update in-app News [src/apps/news/news.data.tsx](/src/apps/news/news.data.tsx)
  - [ ] Update in-app Cover graphics
  - [ ] Update the README.md with the new release
  - [ ] Copy the highlights to the [docs/changelog.md](/docs/changelog.md)
- Release:
  - [ ] merge onto main `git checkout main && git merge --no-ff release-1.2.3`
  - [ ] re-tag `git tag -f v1.2.3 && git push opensource --tags -f`
  - [ ] verify deployment on Vercel
  - [ ] verify container on GitHub Packages
  - [ ] update the GitHub release
  - [ ] push as stable `git push opensource main:main-stable`
- Announce:
  - [ ] Discord announcement
  - [ ] Twitter announcement

### Links

- Milestone: https://github.com/enricoros/big-AGI/milestone/X
- GitHub release: https://github.com/enricoros/big-AGI/releases/tag/v1.2.3
- Former release task: #...

## Artifacts Generation

```markdown
You help me generate the following collateral for the new release of my opensource application called big-AGI. The new release is 1.2.3.
To familiarize yourself with the application, the following are the Website and the GitHub README.md.
```

- paste the URL: https://big-agi.com
- drag & drop: [README.md](https://raw.githubusercontent.com/enricoros/big-AGI/v2-dev/README.md)

```markdown
I am announcing a new version, 1.2.3.
For reference, the following was the collateral for 1.1.0 (Discord announcement, GitHub Release, in-app-news file news.data.tsx).
```

- paste the former: `discord announcement`,
- `GitHub release`,
- `news.data.tsx`,
- `changelog.md`

```markdown
The following are the new developments for 1.2.3:

- ...
- git log --pretty=format:"%h %an %B" v1.1.0..v1.2.3 | clip
```

- paste the link to the milestone (closed) and each individual issue (content will be downloaded)
- paste the output of the git log command

### news.data.tsx

```markdown
I need the following from you:

1. a table summarizing all the new features in 1.2.3 with the following columns: 4 words description (exactly what it is), short description, usefulness (what it does for the user), significance, link to the issue number (not the commit)), which will be used for the artifacts later
2. then double-check the git log to see if there are any features of significance that are not in the table
3. then score each feature in terms of importance for users (1-10), relative impact of the feature (1-10, where 10 applies to the broadest user base), and novelty and uniqueness (1-10, where 10 is truly unique and novel from what exists already)
4. then improve the table, in decreasing order of importance for features, fixing any detail that's missing, in particular check if there are commits of significance from a user or developer point of view, which are not contained in the table
5. then I want you then to update the news.data.tsx for the new release
```

### release name

```markdown
please brainstorm 10 different names for this release. see the former names here: https://big-agi.com/blog
```

You can follow with 'What do you think of Modelmorphic?' or other selected name

### cover images

```markdown
Great, now I need to generate images for this. Before I used the following prompts (2 releases before).

// An image of a capybara sculpted entirely from black cotton candy, set against a minimalist backdrop with splashes of bright, contrasting sparkles. The capybara is using a computer with split screen made of origami, split keyboard and is wearing origami sunglasses with very different split reflections. Split halves are very contrasting. Close up photography, bokeh, white background.
import coverV113 from '../../../public/images/covers/release-cover-v1.13.0.png';
// An image of a capybara sculpted entirely from black cotton candy, set against a minimalist backdrop with splashes of bright, contrasting sparkles. The capybara is calling on a 3D origami old-school pink telephone and the camera is zooming on the telephone. Close up photography, bokeh, white background.
import coverV112 from '../../../public/images/covers/release-cover-v1.12.0.png';

What can I do now as far as images? Give me 4 prompt ideas with the same style as looks as the former, but different scene or action
```

### Readme (and Changelog)

```markdown
I need you to update the README.md and the with the new release.
Attaching the in-app news, with my language for you to improve on, but keep the tone.
```

### GitHub release

```markdown
Please create the 1.2.3 Release Notes for GitHub, following the format of the 1.1.0 GitHub release notes attached before.
Use a truthful and honest tone, understanding that people's time and attention span is short.
Today is 2024-XXXX-YYYY.
```

Now paste-attachment the former release notes (or 1.5.0 which was accurate and great), including the new contributors and
some stats (# of commits, etc.), and roll it for the new release.

### Discord announcement

```markdown
Can you generate my 1.2.3 big-AGI discord announcement from the GitHub Release announcement?
Please keep the formatting and stye of the discord announcement for 1.1.0, but with the new messaging above.
```



================================================
FILE: .github/ISSUE_TEMPLATE/roadmap-request.md
================================================
---
name: Roadmap request
about: Suggest a roadmap item
title: "[Roadmap]"
labels: ''
assignees: ''

---

**Why**
(replace this text with yours) The reason behind the request - we love it to be framed for "users will be able to do x" rather than quick-aging hype-tech-of-the-day requests

**Description**
Clear and concise description of what you want to happen.

**Requirements**
If you can, Please break-down the changes use cases, UX, technology, architecture, etc.
- [ ] ...



================================================
FILE: .github/workflows/docker-image.yml
================================================
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# GitHub recommends pinning actions to a commit SHA.
# To get a newer version, you will need to update the SHA.
# You can also reference a tag or branch, but the action may change without warning.

name: Create and publish Docker images

on:
  push:
    branches:
      - v2-dev
      #- v1-stable  # Disabled as the v* tag is used for stable releases
    tags:
      - 'v*'  # Trigger on version tags (e.g., v1.7.0)

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push-image:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      security-events: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata (tags, labels) for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=raw,value=development,enable=${{ github.ref == 'refs/heads/v2-dev' }} # For v2-dev branch
            type=raw,value=stable,enable=${{ github.ref == 'refs/heads/v1-stable' }}
            type=ref,event=tag  # Use the tag name as a tag for tag builds
            type=semver,pattern={{version}}  # Generate semantic versioning tags for tag builds
            type=sha,format=short,prefix=sha- # Just in case none of the above applies
          labels: |
            org.opencontainers.image.title=Big-AGI
            org.opencontainers.image.description=Generative AI suite powered by state-of-the-art models
            org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.documentation=https://big-agi.com

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          build-args: |
            NEXT_PUBLIC_GA4_MEASUREMENT_ID=${{ secrets.GA4_MEASUREMENT_ID }}
            NEXT_PUBLIC_BUILD_HASH=${{ github.sha }}
            NEXT_PUBLIC_BUILD_REF_NAME=${{ github.ref_name }}
          # Enable build cache (future)
          #cache-from: type=gha
          #cache-to: type=gha,mode=max
          # Enable provenance and SBOM (future)
          #provenance: true
          #sbom: true

